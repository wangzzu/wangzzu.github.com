<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
    
    <entry>
      <title><![CDATA[Apache Calcite 处理流程详解（一）]]></title>
      <url>http://matt33.com/2019/03/07/apache-calcite-process-flow/</url>
      <content type="html"><![CDATA[<p>关于 Apache Calcite 的简单介绍可以参考 <a href="https://www.infoq.cn/article/new-big-data-hadoop-query-engine-apache-calcite" target="_blank" rel="external">Apache Calcite：Hadoop 中新型大数据查询引擎</a> 这篇文章，Calcite 一开始设计的目标就是 <strong>one size fits all</strong>，它希望能为不同计算存储引擎提供统一的 SQL 查询引擎，当然 Calcite 并不仅仅是一个简单的 SQL 查询引擎，在论文 <a href="https://arxiv.org/pdf/1802.10233.pdf" target="_blank" rel="external">Apache Calcite: A Foundational Framework for Optimized Query Processing Over Heterogeneous Data Sources</a> 的摘要（摘要见下面）部分，关于 Calcite 的核心点有简单的介绍，Calcite 的架构有三个特点：flexible, embeddable, and extensible，就是灵活性、组件可插拔、可扩展，它的 SQL Parser 层、Optimizer 层等都可以单独使用，这也是 Calcite 受总多开源框架欢迎的原因之一。</p>
<blockquote>
<p>Apache Calcite is a foundational software framework that provides <strong>query processing, optimization, and query language</strong> support to many popular open-source data processing systems such as Apache Hive, Apache Storm, Apache Flink, Druid, and MapD. Calcite’s architecture consists of </p>
<ol>
<li>a modular and extensible query optimizer with hundreds of built-in optimization rules, </li>
<li>a query processor capable of processing a variety of query languages, </li>
<li>an adapter architecture designed for extensibility, </li>
<li>and support for heterogeneous data models and stores (relational, semi-structured, streaming, and geospatial).<br><strong>This flexible, embeddable, and extensible architecture</strong> is what makes Calcite an attractive choice for adoption in bigdata frameworks. It is an active project that continues to introduce support for the new types of data sources, query languages, and approaches to query processing and optimization.</li>
</ol>
</blockquote>
<h1 id="Calcite-概念"><a href="#Calcite-概念" class="headerlink" title="Calcite 概念"></a>Calcite 概念</h1><p>在介绍 Calcite 架构之前，先来看下与 Calcite 相关的基础性内容。</p>
<h2 id="关系代数的基本知识"><a href="#关系代数的基本知识" class="headerlink" title="关系代数的基本知识"></a>关系代数的基本知识</h2><p>关系代数是关系型数据库操作的理论基础，关系代数支持并、差、笛卡尔积、投影和选择等基本运算。关系代数也是 Calcite 的核心，任何一个查询都可以表示成由关系运算符组成的树。在 Calcite 中，它会先将 SQL 转换成关系表达式（relational expression），然后通过规则匹配（rules match）进行相应的优化，优化会有一个成本（cost）模型为参考。</p>
<p>这里先看下关系代数相关内容，这对于理解 Calcite 很有帮助，特别是 Calcite Optimizer 这块的内容，关系代数的基础可以参考这篇文章 <a href="https://blog.csdn.net/QuinnNorris/article/details/70739094" target="_blank" rel="external">SQL 形式化语言——关系代数</a>，简单总结如下：</p>
<table>
<thead>
<tr>
<th>名称</th>
<th>英文</th>
<th>符号</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>选择</td>
<td>select</td>
<td>σ</td>
<td>类似于 SQL 中的 where</td>
</tr>
<tr>
<td>投影</td>
<td>project</td>
<td>Π</td>
<td>类似于 SQL 中的 select</td>
</tr>
<tr>
<td>并</td>
<td>union</td>
<td>∪</td>
<td>类似于 SQL 中的 union</td>
</tr>
<tr>
<td>集合差</td>
<td>set-difference</td>
<td>-</td>
<td>SQL中没有对应的操作符</td>
</tr>
<tr>
<td>笛卡儿积</td>
<td>Cartesian-product</td>
<td>×</td>
<td>类似于 SQL 中不带 on 条件的 inner join</td>
</tr>
<tr>
<td>重命名</td>
<td>rename</td>
<td>ρ</td>
<td>类似于 SQL 中的 as</td>
</tr>
<tr>
<td>集合交</td>
<td>intersection</td>
<td>∩</td>
<td>SQL中没有对应的操作符</td>
</tr>
<tr>
<td>自然连接</td>
<td>natural join</td>
<td>⋈</td>
<td>类似于 SQL 中的 inner join</td>
</tr>
<tr>
<td>赋值</td>
<td>assignment</td>
<td>←</td>
</tr>
</tbody>
</table>
<h3 id="查询优化"><a href="#查询优化" class="headerlink" title="查询优化"></a>查询优化</h3><p>查询优化主要是围绕着 <strong>等价交换</strong> 的原则做相应的转换，这部分可以参考【《数据库系统概念（中文第六版）》第13章——查询优化】，关于查询优化理论知识，这里就不再详述，列出一些个人不错不错的博客，大家可以参考一下：</p>
<ol>
<li><a href="https://www.jianshu.com/p/edf503a2a1e7" target="_blank" rel="external">数据库查询优化入门: 代数与物理优化基础</a>；</li>
<li><a href="https://blog.csdn.net/u013007900/article/details/78978271" target="_blank" rel="external">高级数据库十五：查询优化器（一）</a>；</li>
<li><a href="https://blog.csdn.net/u013007900/article/details/78993101" target="_blank" rel="external">高级数据库十六：查询优化器（二）</a>；</li>
<li><a href="http://www.ptbird.cn/optimization-of-relational-algebraic-expression.html" target="_blank" rel="external">「 数据库原理 」查询优化（关系代数表达式优化）</a>；</li>
<li><a href="http://book.51cto.com/art/201306/400084.htm" target="_blank" rel="external">4.1.3 关系数据库系统的查询优化（1）</a>；</li>
<li><a href="http://book.51cto.com/art/201306/400085.htm" target="_blank" rel="external">4.1.3 关系数据库系统的查询优化（10）</a>；</li>
</ol>
<h2 id="Calcite-中的一些概念"><a href="#Calcite-中的一些概念" class="headerlink" title="Calcite 中的一些概念"></a>Calcite 中的一些概念</h2><p>Calcite 抛出的概念非常多，笔者最开始在看代码时就被这些概念绕得云里雾里，这时候先从代码的细节里跳出来，先把这些概念理清楚、归归类后再去看代码，思路就清晰很多，因此，在介绍 Calcite 整体实现前，先把这些概念梳理一下，需要对这些概念有个基本的理解，相关的概念如下图所示：</p>
<p><img src="/images/calcite/0-calcite.png" alt="calcite 基本概念"></p>
<p>整理如下表所示：</p>
<table>
<thead>
<tr>
<th>类型</th>
<th>描述</th>
<th>特点</th>
</tr>
</thead>
<tbody>
<tr>
<td>RelOptRule</td>
<td>transforms an expression into another。对 expression 做等价转换</td>
<td>根据传递给它的 RelOptRuleOperand 来对目标 RelNode 树进行规则匹配，匹配成功后，会再次调用 <code>matches()</code> 方法（默认返回真）进行进一步检查。如果 <code>mathes()</code> 结果为真，则调用 <code>onMatch()</code> 进行转换。</td>
</tr>
<tr>
<td>ConverterRule</td>
<td>Abstract base class for a rule which converts from one calling convention to another without changing semantics.</td>
<td>它是 RelOptRule 的子类，专门用来做数据源之间的转换（Calling convention），<strong>ConverterRule 一般会调用对应的 Converter 来完成工作</strong>，比如说：JdbcToSparkConverterRule 调用 JdbcToSparkConverter 来完成对 JDBC Table 到 Spark RDD 的转换。</td>
</tr>
<tr>
<td>RelNode</td>
<td>relational expression，RelNode 会标识其 input RelNode 信息，这样就构成了一棵 RelNode 树</td>
<td>代表了<strong>对数据的一个处理操作</strong>，常见的操作有 Sort、Join、Project、Filter、Scan 等。它蕴含的是对整个 Relation 的操作，而不是对具体数据的处理逻辑。</td>
</tr>
<tr>
<td>Converter</td>
<td>A relational expression implements the interface <code>Converter</code> to indicate that it converts a physical attribute, or RelTrait of a relational expression from one value to another.</td>
<td><strong>用来把一种 RelTrait 转换为另一种 RelTrait 的 RelNode</strong>。如 JdbcToSparkConverter 可以把 JDBC 里的 table 转换为 Spark RDD。如果需要在一个 RelNode 中处理来源于异构系统的逻辑表，Calcite 要求先用 Converter 把异构系统的逻辑表转换为同一种 Convention。</td>
</tr>
<tr>
<td>RexNode</td>
<td>Row-level expression</td>
<td>行表达式（标量表达式），蕴含的是对一行数据的处理逻辑。每个行表达式都有数据的类型。这是因为在 Valdiation 的过程中，编译器会推导出表达式的结果类型。常见的行表达式包括字面量 RexLiteral， 变量 RexVariable， 函数或操作符调用 RexCal l等。 RexNode 通过 RexBuilder 进行构建。</td>
</tr>
<tr>
<td>RelTrait</td>
<td>RelTrait represents the manifestation of a relational expression trait within a trait definition.</td>
<td>用来定义逻辑表的物理相关属性（physical property），三种主要的 trait 类型是：Convention、RelCollation、RelDistribution；</td>
</tr>
<tr>
<td>Convention</td>
<td>Calling convention used to repressent a single data source, inputs must be in the same convention</td>
<td>继承自 RelTrait，类型很少，代表一个单一的数据源，一个  relational expression 必须在同一个 convention 中；</td>
</tr>
<tr>
<td>RelTraitDef</td>
<td></td>
<td>主要有三种：ConventionTraitDef：用来代表数据源 RelCollationTraitDef：用来定义参与排序的字段；RelDistributionTraitDef：用来定义数据在物理存储上的分布方式（比如：single、hash、range、random 等）；</td>
</tr>
<tr>
<td>RelOptCluster</td>
<td>An environment for related relational expressions during the optimization of a query.</td>
<td>palnner 运行时的环境，保存上下文信息；</td>
</tr>
<tr>
<td>RelOptPlanner</td>
<td>A RelOptPlanner is a query optimizer: it transforms a relational expression into a semantically equivalent relational expression, according to a given set of rules and a cost model.</td>
<td>也就是<strong>优化器</strong>，Calcite 支持RBO（Rule-Based Optimizer） 和 CBO（Cost-Based Optimizer）。Calcite 的 RBO （HepPlanner）称为启发式优化器（heuristic implementation ），它简单地按 AST 树结构匹配所有已知规则，直到没有规则能够匹配为止；Calcite 的 CBO 称为火山式优化器（VolcanoPlanner）成本优化器也会匹配并应用规则，当整棵树的成本降低趋于稳定后，优化完成，成本优化器依赖于比较准确的成本估算。RelOptCost 和 Statistic 与成本估算相关；</td>
</tr>
<tr>
<td>RelOptCost</td>
<td>defines an interface for optimizer cost in terms of number of rows processed, CPU cost, and I/O cost.</td>
<td>优化器成本模型会依赖；</td>
</tr>
</tbody>
</table>
<h1 id="Calcite-架构"><a href="#Calcite-架构" class="headerlink" title="Calcite 架构"></a>Calcite 架构</h1><p>关于 Calcite 的架构，可以参考下图（图片来自前面那篇论文），它与传统数据库管理系统有一些相似之处，相比而言，它将数据存储、数据处理算法和元数据存储这些部分忽略掉了，这样设计带来的好处是：对于涉及多种数据源和多种计算引擎的应用而言，Calcite 因为可以兼容多种存储和计算引擎，使得 Calcite 可以提供统一查询服务，Calcite 将会是这些应用的最佳选择。</p>
<p><img src="/images/calcite/1-calcite.png" alt="Calcite Architecture，图片来自论文"></p>
<p>在 Calcite 架构中，最核心地方就是 Optimizer，也就是优化器，一个 Optimization Engine 包含三个组成部分：</p>
<ol>
<li>rules：也就是匹配规则，Calcite 内置上百种 Rules 来优化 relational expression，当然也支持自定义 rules；</li>
<li>metadata providers：主要是向优化器提供信息，这些信息会有助于指导优化器向着目标（减少整体 cost）进行优化，信息可以包括行数、table 哪一列是唯一列等，也包括计算 RelNode 树中执行 subexpression cost 的函数；</li>
<li>planner engines：它的主要目标是进行触发 rules 来达到指定目标，比如像 cost-based optimizer（CBO）的目标是减少cost（Cost 包括处理的数据行数、CPU cost、IO cost 等）。</li>
</ol>
<h1 id="Calcite-处理流程"><a href="#Calcite-处理流程" class="headerlink" title="Calcite 处理流程"></a>Calcite 处理流程</h1><p>Sql 的执行过程一般可以分为下图中的四个阶段，Calcite 同样也是这样：</p>
<p><img src="/images/calcite/dataflow.png" alt="Sql 执行过程"></p>
<p>但这里为了讲述方便，把 SQL 的执行分为下面五个阶段（跟上面比比又独立出了一个阶段）：</p>
<ol>
<li>解析 SQL， 把 SQL 转换成为 AST （抽象语法树），在 Calcite 中用 SqlNode 来表示；</li>
<li>语法检查，根据数据库的元数据信息进行语法验证，验证之后还是用 SqlNode 表示 AST 语法树；</li>
<li>语义分析，根据 SqlNode 及元信息构建 RelNode 树，也就是最初版本的逻辑计划（Logical Plan）；</li>
<li>逻辑计划优化，优化器的核心，根据前面生成的逻辑计划按照相应的规则（Rule）进行优化；</li>
<li>物理执行，生成物理计划，物理执行计划执行。</li>
</ol>
<p>这里我们只关注前四步的内容，会配合源码实现以及一个示例来讲解。</p>
<h2 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h2><p>示例 SQL 如下：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">select</span> u.id <span class="keyword">as</span> user_id, u.name <span class="keyword">as</span> user_name, j.company <span class="keyword">as</span> user_company, u.age <span class="keyword">as</span> user_age </div><div class="line"><span class="keyword">from</span> <span class="keyword">users</span> u <span class="keyword">join</span> jobs j <span class="keyword">on</span> u.name=j.name</div><div class="line"><span class="keyword">where</span> u.age &gt; <span class="number">30</span> <span class="keyword">and</span> j.id&gt;<span class="number">10</span></div><div class="line"><span class="keyword">order</span> <span class="keyword">by</span> user_id</div></pre></td></tr></table></figure>
<p>这里有两张表，其表各个字段及类型定义如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div></pre></td><td class="code"><pre><div class="line">SchemaPlus rootSchema = Frameworks.createRootSchema(<span class="keyword">true</span>);</div><div class="line">rootSchema.add(<span class="string">"USERS"</span>, <span class="keyword">new</span> AbstractTable() &#123; <span class="comment">//note: add a table</span></div><div class="line">    <span class="meta">@Override</span></div><div class="line">    <span class="function"><span class="keyword">public</span> RelDataType <span class="title">getRowType</span><span class="params">(<span class="keyword">final</span> RelDataTypeFactory typeFactory)</span> </span>&#123;</div><div class="line">        RelDataTypeFactory.Builder builder = typeFactory.builder();</div><div class="line"></div><div class="line">        builder.add(<span class="string">"ID"</span>, <span class="keyword">new</span> BasicSqlType(<span class="keyword">new</span> RelDataTypeSystemImpl() &#123;&#125;, SqlTypeName.INTEGER));</div><div class="line">        builder.add(<span class="string">"NAME"</span>, <span class="keyword">new</span> BasicSqlType(<span class="keyword">new</span> RelDataTypeSystemImpl() &#123;&#125;, SqlTypeName.CHAR));</div><div class="line">        builder.add(<span class="string">"AGE"</span>, <span class="keyword">new</span> BasicSqlType(<span class="keyword">new</span> RelDataTypeSystemImpl() &#123;&#125;, SqlTypeName.INTEGER));</div><div class="line">        <span class="keyword">return</span> builder.build();</div><div class="line">    &#125;</div><div class="line">&#125;);</div><div class="line"></div><div class="line">rootSchema.add(<span class="string">"JOBS"</span>, <span class="keyword">new</span> AbstractTable() &#123;</div><div class="line">    <span class="meta">@Override</span></div><div class="line">    <span class="function"><span class="keyword">public</span> RelDataType <span class="title">getRowType</span><span class="params">(<span class="keyword">final</span> RelDataTypeFactory typeFactory)</span> </span>&#123;</div><div class="line">        RelDataTypeFactory.Builder builder = typeFactory.builder();</div><div class="line"></div><div class="line">        builder.add(<span class="string">"ID"</span>, <span class="keyword">new</span> BasicSqlType(<span class="keyword">new</span> RelDataTypeSystemImpl() &#123;&#125;, SqlTypeName.INTEGER));</div><div class="line">        builder.add(<span class="string">"NAME"</span>, <span class="keyword">new</span> BasicSqlType(<span class="keyword">new</span> RelDataTypeSystemImpl() &#123;&#125;, SqlTypeName.CHAR));</div><div class="line">        builder.add(<span class="string">"COMPANY"</span>, <span class="keyword">new</span> BasicSqlType(<span class="keyword">new</span> RelDataTypeSystemImpl() &#123;&#125;, SqlTypeName.CHAR));</div><div class="line">        <span class="keyword">return</span> builder.build();</div><div class="line">    &#125;</div><div class="line">&#125;);</div></pre></td></tr></table></figure>
<h2 id="Step1-SQL-解析阶段（SQL–-gt-SqlNode）"><a href="#Step1-SQL-解析阶段（SQL–-gt-SqlNode）" class="headerlink" title="Step1: SQL 解析阶段（SQL–&gt;SqlNode）"></a>Step1: SQL 解析阶段（SQL–&gt;SqlNode）</h2><p>使用 Calcite 进行 Sql 解析的代码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">SqlParser parser = SqlParser.create(sql, SqlParser.Config.DEFAULT);</div><div class="line">SqlNode sqlNode = parser.parseStmt();</div></pre></td></tr></table></figure>
<p>Calcite 使用 JavaCC 做 SQL 解析，JavaCC 根据 Calcite 中定义的 <a href="https://github.com/apache/calcite/blob/master/core/src/main/codegen/templates/Parser.jj" target="_blank" rel="external">Parser.jj</a> 文件，生成一系列的 java 代码，生成的 Java 代码会把 SQL 转换成 AST 的数据结构（这里是 SqlNode 类型）。</p>
<blockquote>
<p>与 Javacc 相似的工具还有 ANTLR，JavaCC 中的 jj 文件也跟 ANTLR 中的 G4文件类似，Apache Spark 中使用这个工具做类似的事情。</p>
</blockquote>
<h3 id="Javacc"><a href="#Javacc" class="headerlink" title="Javacc"></a>Javacc</h3><p>关于 Javacc 内容可以参考下面这几篇文章，这里就不再详细展开，可以通过下面文章的例子把 JavaCC 的语法了解一下，这样我们也可以自己设计一个 DSL（Doomain Specific Language）。</p>
<ul>
<li><a href="https://www.cnblogs.com/Gavin_Liu/archive/2009/03/07/1405029.html" target="_blank" rel="external">JavaCC 研究与应用( 8000字 心得 源程序)</a>；</li>
<li><a href="https://www.ibm.com/developerworks/cn/xml/x-javacc/part1/index.html" target="_blank" rel="external">JavaCC、解析树和 XQuery 语法，第 1 部分</a>；</li>
<li><a href="https://www.ibm.com/developerworks/cn/xml/x-javacc/part2/index.html" target="_blank" rel="external">JavaCC、解析树和 XQuery 语法，第 2 部分</a>；</li>
<li><a href="https://www.yangguo.info/2014/12/13/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86-Javacc%E4%BD%BF%E7%94%A8/" target="_blank" rel="external">编译原理之Javacc使用</a>；</li>
<li><a href="http://www.engr.mun.ca/~theo/JavaCC-Tutorial/javacc-tutorial.pdf" target="_blank" rel="external">javacc tutorial</a>；</li>
</ul>
<p>回到 Calcite，Javacc 这里要实现一个 SQL Parser，它的功能有以下两个，这里都是需要在 jj 文件中定义的。</p>
<ol>
<li>设计词法和语义，定义 SQL 中具体的元素；</li>
<li>实现词法分析器（Lexer）和语法分析器（Parser），完成对 SQL 的解析，完成相应的转换。</li>
</ol>
<h3 id="SQL-Parser-流程"><a href="#SQL-Parser-流程" class="headerlink" title="SQL Parser 流程"></a>SQL Parser 流程</h3><p>当 SqlParser 调用 <code>parseStmt()</code> 方法后，其相应的逻辑如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// org.apache.calcite.sql.parser.SqlParser</span></div><div class="line"><span class="function"><span class="keyword">public</span> SqlNode <span class="title">parseStmt</span><span class="params">()</span> <span class="keyword">throws</span> SqlParseException </span>&#123;</div><div class="line">  <span class="keyword">return</span> parseQuery();</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">public</span> SqlNode <span class="title">parseQuery</span><span class="params">()</span> <span class="keyword">throws</span> SqlParseException </span>&#123;</div><div class="line">  <span class="keyword">try</span> &#123;</div><div class="line">    <span class="keyword">return</span> parser.parseSqlStmtEof(); <span class="comment">//note: 解析sql语句</span></div><div class="line">  &#125; <span class="keyword">catch</span> (Throwable ex) &#123;</div><div class="line">    <span class="keyword">if</span> (ex <span class="keyword">instanceof</span> CalciteContextException) &#123;</div><div class="line">      <span class="keyword">final</span> String originalSql = parser.getOriginalSql();</div><div class="line">      <span class="keyword">if</span> (originalSql != <span class="keyword">null</span>) &#123;</div><div class="line">        ((CalciteContextException) ex).setOriginalStatement(originalSql);</div><div class="line">      &#125;</div><div class="line">    &#125;</div><div class="line">    <span class="keyword">throw</span> parser.normalizeException(ex);</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>其中 SqlParser 中 parser 指的是 <code>SqlParserImpl</code> 类（<code>SqlParser.Config.DEFAULT</code> 指定的），它就是由 JJ 文件生成的解析类，其处理流程如下，具体解析逻辑还是要看 JJ 文件中的定义。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//org.apache.calcite.sql.parser.impl.SqlParserImpl</span></div><div class="line"><span class="function"><span class="keyword">public</span> SqlNode <span class="title">parseSqlStmtEof</span><span class="params">()</span> <span class="keyword">throws</span> Exception</span></div><div class="line">&#123;</div><div class="line">  <span class="keyword">return</span> SqlStmtEof();</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="comment">/**</span></div><div class="line"> * Parses an SQL statement followed by the end-of-file symbol.</div><div class="line"> * note:解析SQL语句(后面有文件结束符号)</div><div class="line"> */</div><div class="line"><span class="function"><span class="keyword">final</span> <span class="keyword">public</span> SqlNode <span class="title">SqlStmtEof</span><span class="params">()</span> <span class="keyword">throws</span> ParseException </span>&#123;</div><div class="line">  SqlNode stmt;</div><div class="line">  stmt = SqlStmt();</div><div class="line">  jj_consume_token(<span class="number">0</span>);</div><div class="line">      &#123;<span class="keyword">if</span> (<span class="keyword">true</span>) <span class="keyword">return</span> stmt;&#125;</div><div class="line">  <span class="keyword">throw</span> <span class="keyword">new</span> Error(<span class="string">"Missing return statement in function"</span>);</div><div class="line">&#125;</div><div class="line"></div><div class="line"> <span class="comment">//note: 解析 SQL statement</span></div><div class="line"><span class="function"><span class="keyword">final</span> <span class="keyword">public</span> SqlNode <span class="title">SqlStmt</span><span class="params">()</span> <span class="keyword">throws</span> ParseException </span>&#123;</div><div class="line">  SqlNode stmt;</div><div class="line">  <span class="keyword">if</span> (jj_2_34(<span class="number">2</span>)) &#123;</div><div class="line">    stmt = SqlSetOption(Span.of(), <span class="keyword">null</span>);</div><div class="line">  &#125; <span class="keyword">else</span> <span class="keyword">if</span> (jj_2_35(<span class="number">2</span>)) &#123;</div><div class="line">    stmt = SqlAlter();</div><div class="line">  &#125; <span class="keyword">else</span> <span class="keyword">if</span> (jj_2_36(<span class="number">2</span>)) &#123;</div><div class="line">    stmt = OrderedQueryOrExpr(ExprContext.ACCEPT_QUERY);</div><div class="line">  &#125; <span class="keyword">else</span> <span class="keyword">if</span> (jj_2_37(<span class="number">2</span>)) &#123;</div><div class="line">    stmt = SqlExplain();</div><div class="line">  &#125; <span class="keyword">else</span> <span class="keyword">if</span> (jj_2_38(<span class="number">2</span>)) &#123;</div><div class="line">    stmt = SqlDescribe();</div><div class="line">  &#125; <span class="keyword">else</span> <span class="keyword">if</span> (jj_2_39(<span class="number">2</span>)) &#123;</div><div class="line">    stmt = SqlInsert();</div><div class="line">  &#125; <span class="keyword">else</span> <span class="keyword">if</span> (jj_2_40(<span class="number">2</span>)) &#123;</div><div class="line">    stmt = SqlDelete();</div><div class="line">  &#125; <span class="keyword">else</span> <span class="keyword">if</span> (jj_2_41(<span class="number">2</span>)) &#123;</div><div class="line">    stmt = SqlUpdate();</div><div class="line">  &#125; <span class="keyword">else</span> <span class="keyword">if</span> (jj_2_42(<span class="number">2</span>)) &#123;</div><div class="line">    stmt = SqlMerge();</div><div class="line">  &#125; <span class="keyword">else</span> <span class="keyword">if</span> (jj_2_43(<span class="number">2</span>)) &#123;</div><div class="line">    stmt = SqlProcedureCall();</div><div class="line">  &#125; <span class="keyword">else</span> &#123;</div><div class="line">    jj_consume_token(-<span class="number">1</span>);</div><div class="line">    <span class="keyword">throw</span> <span class="keyword">new</span> ParseException();</div><div class="line">  &#125;</div><div class="line">      &#123;<span class="keyword">if</span> (<span class="keyword">true</span>) <span class="keyword">return</span> stmt;&#125;</div><div class="line">  <span class="keyword">throw</span> <span class="keyword">new</span> Error(<span class="string">"Missing return statement in function"</span>);</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>示例中 SQL 经过前面的解析之后，会生成一个 SqlNode，这个 SqlNode 是一个 SqlOrder 类型，DEBUG 后的 SqlOrder 对象如下图所示。</p>
<p><img src="/images/calcite/2-calciter.jpg" alt="SqlNode 结果"> </p>
<h2 id="Step2-SqlNode-验证（SqlNode–-gt-SqlNode）"><a href="#Step2-SqlNode-验证（SqlNode–-gt-SqlNode）" class="headerlink" title="Step2: SqlNode 验证（SqlNode–&gt;SqlNode）"></a>Step2: SqlNode 验证（SqlNode–&gt;SqlNode）</h2><p>经过上面的第一步，会生成一个 SqlNode 对象，它是一个<strong>未经验证</strong>的抽象语法树，下面就进入了一个<strong>语法检查</strong>阶段，语法检查前需要知道元数据信息，这个检查会包括表名、字段名、函数名、数据类型的检查。进行语法检查的实现如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//note: 二、sql validate（会先通过Catalog读取获取相应的metadata和namespace）</span></div><div class="line"><span class="comment">//note: get metadata and namespace</span></div><div class="line">SqlTypeFactoryImpl factory = <span class="keyword">new</span> SqlTypeFactoryImpl(RelDataTypeSystem.DEFAULT);</div><div class="line">CalciteCatalogReader calciteCatalogReader = <span class="keyword">new</span> CalciteCatalogReader(</div><div class="line">    CalciteSchema.from(rootScheme),</div><div class="line">    CalciteSchema.from(rootScheme).path(<span class="keyword">null</span>),</div><div class="line">    factory,</div><div class="line">    <span class="keyword">new</span> CalciteConnectionConfigImpl(<span class="keyword">new</span> Properties()));</div><div class="line"></div><div class="line"><span class="comment">//note: 校验（包括对表名，字段名，函数名，字段类型的校验。）</span></div><div class="line">SqlValidator validator = SqlValidatorUtil.newValidator(SqlStdOperatorTable.instance(), calciteCatalogReader, factory,</div><div class="line">    conformance(frameworkConfig));</div><div class="line">SqlNode validateSqlNode = validator.validate(sqlNode);</div></pre></td></tr></table></figure>
<p>我们知道 Calcite 本身是不管理和存储元数据的，在检查之前，需要先把元信息注册到 Calcite 中，一般的操作方法是实现 SchemaFactory，由它去创建相应的 Schema，在 Schema 中可以注册相应的元数据信息（如：通过 <code>getTableMap()</code> 方法注册表信息），如下所示：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//org.apache.calcite.schema.impl.AbstractSchema</span></div><div class="line"><span class="comment">/**</span></div><div class="line"> * Returns a map of tables in this schema by name.</div><div class="line"> *</div><div class="line"> * &lt;p&gt;The implementations of &#123;<span class="doctag">@link</span> #getTableNames()&#125;</div><div class="line"> * and &#123;<span class="doctag">@link</span> #getTable(String)&#125; depend on this map.</div><div class="line"> * The default implementation of this method returns the empty map.</div><div class="line"> * Override this method to change their behavior.&lt;/p&gt;</div><div class="line"> *</div><div class="line"> * <span class="doctag">@return</span> Map of tables in this schema by name</div><div class="line"> */</div><div class="line"><span class="function"><span class="keyword">protected</span> Map&lt;String, Table&gt; <span class="title">getTableMap</span><span class="params">()</span> </span>&#123;</div><div class="line">  <span class="keyword">return</span> ImmutableMap.of();</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="comment">//org.apache.calcite.adapter.csvorg.apache.calcite.adapter.csv.CsvSchemasvSchema</span></div><div class="line"><span class="comment">//note: 创建表</span></div><div class="line"><span class="meta">@Override</span> <span class="function"><span class="keyword">protected</span> Map&lt;String, Table&gt; <span class="title">getTableMap</span><span class="params">()</span> </span>&#123;</div><div class="line">  <span class="keyword">if</span> (tableMap == <span class="keyword">null</span>) &#123;</div><div class="line">    tableMap = createTableMap();</div><div class="line">  &#125;</div><div class="line">  <span class="keyword">return</span> tableMap;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>CsvSchemasvSchema 中的 <code>getTableMap()</code> 方法通过 <code>createTableMap()</code> 来注册相应的表信息。</p>
<p>结合前面的例子再来分析，在前面定义了 CalciteCatalogReader 实例，该实例就是用来读取 Schema 中的元数据信息的。真正检查的逻辑是在 <code>SqlValidatorImpl</code> 类中实现的，这个 check 的逻辑比较复杂，在看代码时通过两种手段来看：</p>
<ol>
<li>DEBUG 的方式，可以看到其方法调用的过程；</li>
<li>测试程序中故意构造一些 Case，观察其异常栈。</li>
</ol>
<p>比如，在示例中 SQL 中，如果把一个字段名写错，写成 ids，其报错信息如下：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div></pre></td><td class="code"><pre><div class="line">org.apache.calcite.runtime.CalciteContextException: From line 1, column 156 to line 1, column 158: Column <span class="string">'IDS'</span> not found <span class="keyword">in</span> table <span class="string">'J'</span></div><div class="line">    at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)</div><div class="line">    at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)</div><div class="line">    at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)</div><div class="line">    at java.lang.reflect.Constructor.newInstance(Constructor.java:423)</div><div class="line">    at org.apache.calcite.runtime.Resources<span class="variable">$ExInstWithCause</span>.ex(Resources.java:463)</div><div class="line">    at org.apache.calcite.sql.SqlUtil.newContextException(SqlUtil.java:787)</div><div class="line">    at org.apache.calcite.sql.SqlUtil.newContextException(SqlUtil.java:772)</div><div class="line">    at org.apache.calcite.sql.validate.SqlValidatorImpl.newValidationError(SqlValidatorImpl.java:4788)</div><div class="line">    at org.apache.calcite.sql.validate.DelegatingScope.fullyQualify(DelegatingScope.java:439)</div><div class="line">    at org.apache.calcite.sql.validate.SqlValidatorImpl<span class="variable">$Expander</span>.visit(SqlValidatorImpl.java:5683)</div><div class="line">    at org.apache.calcite.sql.validate.SqlValidatorImpl<span class="variable">$Expander</span>.visit(SqlValidatorImpl.java:5665)</div><div class="line">    at org.apache.calcite.sql.SqlIdentifier.accept(SqlIdentifier.java:334)</div><div class="line">    at org.apache.calcite.sql.util.SqlShuttle<span class="variable">$CallCopyingArgHandler</span>.visitChild(SqlShuttle.java:134)</div><div class="line">    at org.apache.calcite.sql.util.SqlShuttle<span class="variable">$CallCopyingArgHandler</span>.visitChild(SqlShuttle.java:101)</div><div class="line">    at org.apache.calcite.sql.SqlOperator.acceptCall(SqlOperator.java:865)</div><div class="line">    at org.apache.calcite.sql.validate.SqlValidatorImpl<span class="variable">$Expander</span>.visitScoped(SqlValidatorImpl.java:5701)</div><div class="line">    at org.apache.calcite.sql.validate.SqlScopedShuttle.visit(SqlScopedShuttle.java:50)</div><div class="line">    at org.apache.calcite.sql.validate.SqlScopedShuttle.visit(SqlScopedShuttle.java:33)</div><div class="line">    at org.apache.calcite.sql.SqlCall.accept(SqlCall.java:138)</div><div class="line">    at org.apache.calcite.sql.util.SqlShuttle<span class="variable">$CallCopyingArgHandler</span>.visitChild(SqlShuttle.java:134)</div><div class="line">    at org.apache.calcite.sql.util.SqlShuttle<span class="variable">$CallCopyingArgHandler</span>.visitChild(SqlShuttle.java:101)</div><div class="line">    at org.apache.calcite.sql.SqlOperator.acceptCall(SqlOperator.java:865)</div><div class="line">    at org.apache.calcite.sql.validate.SqlValidatorImpl<span class="variable">$Expander</span>.visitScoped(SqlValidatorImpl.java:5701)</div><div class="line">    at org.apache.calcite.sql.validate.SqlScopedShuttle.visit(SqlScopedShuttle.java:50)</div><div class="line">    at org.apache.calcite.sql.validate.SqlScopedShuttle.visit(SqlScopedShuttle.java:33)</div><div class="line">    at org.apache.calcite.sql.SqlCall.accept(SqlCall.java:138)</div><div class="line">    at org.apache.calcite.sql.validate.SqlValidatorImpl.expand(SqlValidatorImpl.java:5272)</div><div class="line">    at org.apache.calcite.sql.validate.SqlValidatorImpl.validateWhereClause(SqlValidatorImpl.java:3977)</div><div class="line">    at org.apache.calcite.sql.validate.SqlValidatorImpl.validateSelect(SqlValidatorImpl.java:3305)</div><div class="line">    at org.apache.calcite.sql.validate.SelectNamespace.validateImpl(SelectNamespace.java:60)</div><div class="line">    at org.apache.calcite.sql.validate.AbstractNamespace.validate(AbstractNamespace.java:84)</div><div class="line">    at org.apache.calcite.sql.validate.SqlValidatorImpl.validateNamespace(SqlValidatorImpl.java:977)</div><div class="line">    at org.apache.calcite.sql.validate.SqlValidatorImpl.validateQuery(SqlValidatorImpl.java:953)</div><div class="line">    at org.apache.calcite.sql.SqlSelect.validate(SqlSelect.java:216)</div><div class="line">    at org.apache.calcite.sql.validate.SqlValidatorImpl.validateScopedExpression(SqlValidatorImpl.java:928)</div><div class="line">    at org.apache.calcite.sql.validate.SqlValidatorImpl.validate(SqlValidatorImpl.java:632)</div><div class="line">    at com.matt.test.calcite.test.SqlTest3.sqlToRelNode(SqlTest3.java:200)</div><div class="line">    at com.matt.test.calcite.test.SqlTest3.main(SqlTest3.java:117)</div><div class="line">Caused by: org.apache.calcite.sql.validate.SqlValidatorException: Column <span class="string">'IDS'</span> not found <span class="keyword">in</span> table <span class="string">'J'</span></div><div class="line">    at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)</div><div class="line">    at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)</div><div class="line">    at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)</div><div class="line">    at java.lang.reflect.Constructor.newInstance(Constructor.java:423)</div><div class="line">    at org.apache.calcite.runtime.Resources<span class="variable">$ExInstWithCause</span>.ex(Resources.java:463)</div><div class="line">    at org.apache.calcite.runtime.Resources<span class="variable">$ExInst</span>.ex(Resources.java:572)</div><div class="line">    ... 33 more</div><div class="line">java.lang.NullPointerException</div><div class="line">    at org.apache.calcite.plan.hep.HepPlanner.addRelToGraph(HepPlanner.java:806)</div><div class="line">    at org.apache.calcite.plan.hep.HepPlanner.setRoot(HepPlanner.java:152)</div><div class="line">    at com.matt.test.calcite.test.SqlTest3.main(SqlTest3.java:124)</div></pre></td></tr></table></figure>
<h3 id="SqlValidatorImpl-检查过程"><a href="#SqlValidatorImpl-检查过程" class="headerlink" title="SqlValidatorImpl 检查过程"></a>SqlValidatorImpl 检查过程</h3><p>语法检查验证是通过 SqlValidatorImpl 的 <code>validate()</code> 方法进行操作的，其实现如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line">org.apache.calcite.sql.validate.SqlValidatorImpl</div><div class="line"><span class="comment">//note: 做相应的语法树校验</span></div><div class="line"><span class="function"><span class="keyword">public</span> SqlNode <span class="title">validate</span><span class="params">(SqlNode topNode)</span> </span>&#123;</div><div class="line">  <span class="comment">//note: root 对应的 Scope</span></div><div class="line">  SqlValidatorScope scope = <span class="keyword">new</span> EmptyScope(<span class="keyword">this</span>);</div><div class="line">  scope = <span class="keyword">new</span> CatalogScope(scope, ImmutableList.of(<span class="string">"CATALOG"</span>));</div><div class="line">  <span class="comment">//note: 1.rewrite expression</span></div><div class="line">  <span class="comment">//note: 2.做相应的语法检查</span></div><div class="line">  <span class="keyword">final</span> SqlNode topNode2 = validateScopedExpression(topNode, scope); <span class="comment">//note: 验证</span></div><div class="line">  <span class="keyword">final</span> RelDataType type = getValidatedNodeType(topNode2);</div><div class="line">  Util.discard(type);</div><div class="line">  <span class="keyword">return</span> topNode2;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>主要的实现是在 <code>validateScopedExpression()</code> 方法中，其实现如下</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">private</span> SqlNode <span class="title">validateScopedExpression</span><span class="params">(</span></span></div><div class="line">    SqlNode topNode,</div><div class="line">    SqlValidatorScope scope) &#123;</div><div class="line">  <span class="comment">//note: 1. rewrite expression，将其标准化，便于后面的逻辑计划优化</span></div><div class="line">  SqlNode outermostNode = performUnconditionalRewrites(topNode, <span class="keyword">false</span>);</div><div class="line">  cursorSet.add(outermostNode);</div><div class="line">  top = outermostNode;</div><div class="line">  TRACER.trace(<span class="string">"After unconditional rewrite: &#123;&#125;"</span>, outermostNode);</div><div class="line">  <span class="comment">//note: 2. Registers a query in a parent scope.</span></div><div class="line">  <span class="comment">//note: register scopes and namespaces implied a relational expression</span></div><div class="line">  <span class="keyword">if</span> (outermostNode.isA(SqlKind.TOP_LEVEL)) &#123;</div><div class="line">    registerQuery(scope, <span class="keyword">null</span>, outermostNode, outermostNode, <span class="keyword">null</span>, <span class="keyword">false</span>);</div><div class="line">  &#125;</div><div class="line">  <span class="comment">//note: 3. catalog 验证，调用 SqlNode 的 validate 方法，</span></div><div class="line">  outermostNode.validate(<span class="keyword">this</span>, scope);</div><div class="line">  <span class="keyword">if</span> (!outermostNode.isA(SqlKind.TOP_LEVEL)) &#123;</div><div class="line">    <span class="comment">// force type derivation so that we can provide it to the</span></div><div class="line">    <span class="comment">// caller later without needing the scope</span></div><div class="line">    deriveType(scope, outermostNode);</div><div class="line">  &#125;</div><div class="line">  TRACER.trace(<span class="string">"After validation: &#123;&#125;"</span>, outermostNode);</div><div class="line">  <span class="keyword">return</span> outermostNode;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>它的处理逻辑主要分为三步：</p>
<ol>
<li>rewrite expression，将其标准化，便于后面的逻辑计划优化；</li>
<li>注册这个 relational expression 的 scopes 和 namespaces（这两个对象代表了其元信息）；</li>
<li>进行相应的验证，这里会依赖第二步注册的 scopes 和 namespaces 信息。</li>
</ol>
<h4 id="Rewrite"><a href="#Rewrite" class="headerlink" title="Rewrite"></a>Rewrite</h4><p>关于 Rewrite 这一步，一直困惑比较，因为根据 <code>After unconditional rewrite:</code> 这条日志的结果看，其实前后 SqlNode 并没有太大变化，看 <code>performUnconditionalRewrites()</code> 这部分代码时，看得不是很明白，不过还是注意到了 SqlOrderBy 的注释（注释如下），它的意思是 SqlOrderBy 通过 <code>performUnconditionalRewrites()</code> 方法已经被 SqlSelect 对象中的 <code>ORDER_OPERAND</code> 取代了。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/**</span></div><div class="line"> * Parse tree node that represents an &#123;<span class="doctag">@code</span> ORDER BY&#125; on a query other than a</div><div class="line"> * &#123;<span class="doctag">@code</span> SELECT&#125; (e.g. &#123;<span class="doctag">@code</span> VALUES&#125; or &#123;<span class="doctag">@code</span> UNION&#125;).</div><div class="line"> *</div><div class="line"> * &lt;p&gt;It is a purely syntactic operator, and is eliminated by</div><div class="line"> * &#123;<span class="doctag">@link</span> org.apache.calcite.sql.validate.SqlValidatorImpl#performUnconditionalRewrites&#125;</div><div class="line"> * and replaced with the ORDER_OPERAND of SqlSelect.&lt;/p&gt;</div><div class="line"> */</div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">SqlOrderBy</span> <span class="keyword">extends</span> <span class="title">SqlCall</span> </span>&#123;</div></pre></td></tr></table></figure>
<p>注意到 SqlOrderBy 的原因是因为在 <code>performUnconditionalRewrites()</code> 方法前面都是递归对每个对象进行处理，在后面进行真正的 ransform 时，主要在围绕着 ORDER_BY 这个类型做处理，而且从代码中可以看出，将其类型从 SqlOrderBy 转换成了 SqlSelect，BUDEG 前面的示例，发现 outermostNode 与 topNode 的类型确实发生了变化，如下图所示。</p>
<p><img src="/images/calcite/3-calcite.png" alt="Rewrite 前后的对比"></p>
<p>这个方法有个好的地方就是，在不改变原有 SQL Parser 的逻辑的情况下，可以在这个方法里做一些改动，当然如果 SQL Parser 的结果如果直接可用当然是最好的，就不需要再进行一次 Rewrite 了。</p>
<h4 id="registerQuery"><a href="#registerQuery" class="headerlink" title="registerQuery"></a>registerQuery</h4><p>这里的功能主要就是将[元数据]转换成 SqlValidator 内部的 对象 进行表示，也就是 SqlValidatorScope 和 SqlValidatorNamespace 两种类型的对象：</p>
<ol>
<li>SqlValidatorNamespace：a description of a data source used in a query，它代表了 SQL 查询的数据源，它是一个逻辑上数据源，可以是一张表，也可以是一个子查询；</li>
<li>SqlValidatorScope：describes the tables and columns accessible at a particular point in the query，代表了在某一个程序运行点，当前可见的字段名和表名。</li>
</ol>
<p>这个理解起来并不是那么容易，在 SelectScope 类中有一个示例讲述，这个示例对这两个概念的理解很有帮助。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/**</span></div><div class="line"> * &lt;h3&gt;Scopes&lt;/h3&gt;</div><div class="line"> *</div><div class="line"> * &lt;p&gt;In the query&lt;/p&gt;</div><div class="line"> *</div><div class="line"> * &lt;blockquote&gt;</div><div class="line"> * &lt;pre&gt;</div><div class="line"> * SELECT expr1</div><div class="line"> * FROM t1,</div><div class="line"> *     t2,</div><div class="line"> *     (SELECT expr2 FROM t3) AS q3</div><div class="line"> * WHERE c1 IN (SELECT expr3 FROM t4)</div><div class="line"> * ORDER BY expr4&lt;/pre&gt;</div><div class="line"> * &lt;/blockquote&gt;</div><div class="line"> *</div><div class="line"> * &lt;p&gt;The scopes available at various points of the query are as follows:&lt;/p&gt;</div><div class="line"> *</div><div class="line"> * &lt;ul&gt;</div><div class="line"> * &lt;li&gt;expr1 can see t1, t2, q3&lt;/li&gt;</div><div class="line"> * &lt;li&gt;expr2 can see t3&lt;/li&gt;</div><div class="line"> * &lt;li&gt;expr3 can see t4, t1, t2&lt;/li&gt;</div><div class="line"> * &lt;li&gt;expr4 can see t1, t2, q3, plus (depending upon the dialect) any aliases</div><div class="line"> * defined in the SELECT clause&lt;/li&gt;</div><div class="line"> * &lt;/ul&gt;</div><div class="line"> *</div><div class="line"> * &lt;h3&gt;Namespaces&lt;/h3&gt;</div><div class="line"> *</div><div class="line"> * &lt;p&gt;In the above query, there are 4 namespaces:&lt;/p&gt;</div><div class="line"> *</div><div class="line"> * &lt;ul&gt;</div><div class="line"> * &lt;li&gt;t1&lt;/li&gt;</div><div class="line"> * &lt;li&gt;t2&lt;/li&gt;</div><div class="line"> * &lt;li&gt;(SELECT expr2 FROM t3) AS q3&lt;/li&gt;</div><div class="line"> * &lt;li&gt;(SELECT expr3 FROM t4)&lt;/li&gt;</div><div class="line"> */</div></pre></td></tr></table></figure>
<h4 id="validate-验证"><a href="#validate-验证" class="headerlink" title="validate 验证"></a>validate 验证</h4><p>接着回到最复杂的一步，就是 outermostNode 实例调用 <code>validate(this, scope)</code> 方法进行验证的部分，对于我们这个示例，这里最后调用的是 SqlSelect 的 <code>validate()</code> 方法，如下所示：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">validate</span><span class="params">(SqlValidator validator, SqlValidatorScope scope)</span> </span>&#123;</div><div class="line">  validator.validateQuery(<span class="keyword">this</span>, scope, validator.getUnknownType());</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>它调用的是 SqlValidatorImpl 的 <code>validateQuery()</code> 方法</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">validateQuery</span><span class="params">(SqlNode node, SqlValidatorScope scope,</span></span></div><div class="line">    RelDataType targetRowType) &#123;</div><div class="line">  <span class="keyword">final</span> SqlValidatorNamespace ns = getNamespace(node, scope);</div><div class="line">  <span class="keyword">if</span> (node.getKind() == SqlKind.TABLESAMPLE) &#123;</div><div class="line">    List&lt;SqlNode&gt; operands = ((SqlCall) node).getOperandList();</div><div class="line">    SqlSampleSpec sampleSpec = SqlLiteral.sampleValue(operands.get(<span class="number">1</span>));</div><div class="line">    <span class="keyword">if</span> (sampleSpec <span class="keyword">instanceof</span> SqlSampleSpec.SqlTableSampleSpec) &#123;</div><div class="line">      validateFeature(RESOURCE.sQLFeature_T613(), node.getParserPosition());</div><div class="line">    &#125; <span class="keyword">else</span> <span class="keyword">if</span> (sampleSpec</div><div class="line">        <span class="keyword">instanceof</span> SqlSampleSpec.SqlSubstitutionSampleSpec) &#123;</div><div class="line">      validateFeature(RESOURCE.sQLFeatureExt_T613_Substitution(),</div><div class="line">          node.getParserPosition());</div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  validateNamespace(ns, targetRowType);<span class="comment">//note: 检查</span></div><div class="line">  <span class="keyword">switch</span> (node.getKind()) &#123;</div><div class="line">  <span class="keyword">case</span> EXTEND:</div><div class="line">    <span class="comment">// Until we have a dedicated namespace for EXTEND</span></div><div class="line">    deriveType(scope, node);</div><div class="line">  &#125;</div><div class="line">  <span class="keyword">if</span> (node == top) &#123;</div><div class="line">    validateModality(node);</div><div class="line">  &#125;</div><div class="line">  validateAccess(</div><div class="line">      node,</div><div class="line">      ns.getTable(),</div><div class="line">      SqlAccessEnum.SELECT);</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="comment">/**</span></div><div class="line"> * Validates a namespace.</div><div class="line"> *</div><div class="line"> * <span class="doctag">@param</span> namespace Namespace</div><div class="line"> * <span class="doctag">@param</span> targetRowType Desired row type, must not be null, may be the data</div><div class="line"> *                      type 'unknown'.</div><div class="line"> */</div><div class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">validateNamespace</span><span class="params">(<span class="keyword">final</span> SqlValidatorNamespace namespace,</span></span></div><div class="line">    RelDataType targetRowType) &#123;</div><div class="line">  namespace.validate(targetRowType);<span class="comment">//note: 验证</span></div><div class="line">  <span class="keyword">if</span> (namespace.getNode() != <span class="keyword">null</span>) &#123;</div><div class="line">    setValidatedNodeType(namespace.getNode(), namespace.getType());</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>这部分的调用逻辑非常复杂，主要的语法验证是 SqlValidatorScope 部分（它里面有相应的表名、字段名等信息），而 namespace 表示需要进行验证的数据源，最开始的这个 SqlNode 有一个 root namespace，上面的 <code>validateNamespace()</code> 方法会首先调用其 namespace 的 <code>validate()</code> 方法进行验证，以前面的示例为例，这里是 SelectNamespace，其实现如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//org.apache.calcite.sql.validate.AbstractNamespace</span></div><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">final</span> <span class="keyword">void</span> <span class="title">validate</span><span class="params">(RelDataType targetRowType)</span> </span>&#123;</div><div class="line">  <span class="keyword">switch</span> (status) &#123;</div><div class="line">  <span class="keyword">case</span> UNVALIDATED: <span class="comment">//note: 还没开始 check</span></div><div class="line">    <span class="keyword">try</span> &#123;</div><div class="line">      status = SqlValidatorImpl.Status.IN_PROGRESS; <span class="comment">//note: 更新当前 namespace 的状态</span></div><div class="line">      Preconditions.checkArgument(rowType == <span class="keyword">null</span>,</div><div class="line">          <span class="string">"Namespace.rowType must be null before validate has been called"</span>);</div><div class="line">      RelDataType type = validateImpl(targetRowType); <span class="comment">//note: 检查验证</span></div><div class="line">      Preconditions.checkArgument(type != <span class="keyword">null</span>,</div><div class="line">          <span class="string">"validateImpl() returned null"</span>);</div><div class="line">      setType(type);</div><div class="line">    &#125; <span class="keyword">finally</span> &#123;</div><div class="line">      status = SqlValidatorImpl.Status.VALID;</div><div class="line">    &#125;</div><div class="line">    <span class="keyword">break</span>;</div><div class="line">  <span class="keyword">case</span> IN_PROGRESS: <span class="comment">//note: 已经开始 check 了，死循环了</span></div><div class="line">    <span class="keyword">throw</span> <span class="keyword">new</span> AssertionError(<span class="string">"Cycle detected during type-checking"</span>);</div><div class="line">  <span class="keyword">case</span> VALID:<span class="comment">//note: 检查结束</span></div><div class="line">    <span class="keyword">break</span>;</div><div class="line">  <span class="keyword">default</span>:</div><div class="line">    <span class="keyword">throw</span> Util.unexpected(status);</div><div class="line">  &#125;</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="comment">//org.apache.calcite.sql.validate.SelectNamespace</span></div><div class="line"><span class="comment">//note: 检查，还是调用 SqlValidatorImpl 的方法</span></div><div class="line"><span class="function"><span class="keyword">public</span> RelDataType <span class="title">validateImpl</span><span class="params">(RelDataType targetRowType)</span> </span>&#123;</div><div class="line">  validator.validateSelect(select, targetRowType);</div><div class="line">  <span class="keyword">return</span> rowType;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>最后验证方法的实现是 SqlValidatorImpl 的 <code>validateSelect()</code> 方法（对本示例而言），其调用过程如下图所示：</p>
<p><img src="/images/calcite/4-sqlvalidator.png" alt="验证部分的处理流程"> </p>
<h2 id="Step3-语义分析（SqlNode–-gt-RelNode-RexNode）"><a href="#Step3-语义分析（SqlNode–-gt-RelNode-RexNode）" class="headerlink" title="Step3: 语义分析（SqlNode–&gt;RelNode/RexNode）"></a>Step3: 语义分析（SqlNode–&gt;RelNode/RexNode）</h2><p>经过第二步之后，这里的 SqlNode 就是经过语法校验的 SqlNode 树，接下来这一步就是将 SqlNode 转换成 RelNode/RexNode，也就是生成相应的逻辑计划（Logical Plan），示例的代码实现如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// create the rexBuilder</span></div><div class="line"><span class="keyword">final</span> RexBuilder rexBuilder =  <span class="keyword">new</span> RexBuilder(factory);</div><div class="line"><span class="comment">// init the planner</span></div><div class="line"><span class="comment">// 这里也可以注册 VolcanoPlanner，这一步 planner 并没有使用</span></div><div class="line">HepProgramBuilder builder = <span class="keyword">new</span> HepProgramBuilder();</div><div class="line">RelOptPlanner planner = <span class="keyword">new</span> HepPlanner(builder.build());</div><div class="line"></div><div class="line"><span class="comment">//note: init cluster: An environment for related relational expressions during the optimization of a query.</span></div><div class="line"><span class="keyword">final</span> RelOptCluster cluster = RelOptCluster.create(planner, rexBuilder);</div><div class="line"><span class="comment">//note: init SqlToRelConverter</span></div><div class="line"><span class="keyword">final</span> SqlToRelConverter.Config config = SqlToRelConverter.configBuilder()</div><div class="line">    .withConfig(frameworkConfig.getSqlToRelConverterConfig())</div><div class="line">    .withTrimUnusedFields(<span class="keyword">false</span>)</div><div class="line">    .withConvertTableAccess(<span class="keyword">false</span>)</div><div class="line">    .build(); <span class="comment">//note: config</span></div><div class="line"><span class="comment">// 创建 SqlToRelConverter 实例，cluster、calciteCatalogReader、validator 都传进去了，SqlToRelConverter 会缓存这些对象</span></div><div class="line"><span class="keyword">final</span> SqlToRelConverter sqlToRelConverter = <span class="keyword">new</span> SqlToRelConverter(<span class="keyword">new</span> DogView(), validator, calciteCatalogReader, cluster, StandardConvertletTable.INSTANCE, config);</div><div class="line"><span class="comment">// convert to RelNode</span></div><div class="line">RelRoot root = sqlToRelConverter.convertQuery(validateSqlNode, <span class="keyword">false</span>, <span class="keyword">true</span>);</div><div class="line"></div><div class="line">root = root.withRel(sqlToRelConverter.flattenTypes(root.rel, <span class="keyword">true</span>));</div><div class="line"><span class="keyword">final</span> RelBuilder relBuilder = config.getRelBuilderFactory().create(cluster, <span class="keyword">null</span>);</div><div class="line">root = root.withRel(RelDecorrelator.decorrelateQuery(root.rel, relBuilder));</div><div class="line"></div><div class="line">RelNode relNode = root.rel;</div><div class="line"></div><div class="line"><span class="comment">//DogView 的实现</span></div><div class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">DogView</span> <span class="keyword">implements</span> <span class="title">RelOptTable</span>.<span class="title">ViewExpander</span> </span>&#123;</div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="title">DogView</span><span class="params">()</span> </span>&#123;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="meta">@Override</span></div><div class="line">    <span class="function"><span class="keyword">public</span> RelRoot <span class="title">expandView</span><span class="params">(RelDataType rowType, String queryString, List&lt;String&gt; schemaPath,</span></span></div><div class="line">                              List&lt;String&gt; viewPath) &#123;</div><div class="line">        <span class="keyword">return</span> <span class="keyword">null</span>;</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>为了方便分析，这里也把上面的过程分为以下几步：</p>
<ol>
<li>初始化 RexBuilder；</li>
<li>初始化 RelOptPlanner;</li>
<li>初始化 RelOptCluster；</li>
<li>初始化 SqlToRelConverter；</li>
<li>进行转换；</li>
</ol>
<p>第1、2、4步在上述代码已经有相应的注释，这里不再介绍，下面从第三步开始讲述。</p>
<h3 id="初始化-RelOptCluster"><a href="#初始化-RelOptCluster" class="headerlink" title="初始化 RelOptCluster"></a>初始化 RelOptCluster</h3><p>RelOptCluster 初始化的代码如下，这里基本都走默认的参数配置。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div></pre></td><td class="code"><pre><div class="line">org.apache.calcite.plan.RelOptCluster</div><div class="line"></div><div class="line"><span class="comment">/** Creates a cluster. */</span></div><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> RelOptCluster <span class="title">create</span><span class="params">(RelOptPlanner planner,</span></span></div><div class="line">    RexBuilder rexBuilder) &#123;</div><div class="line">  <span class="keyword">return</span> <span class="keyword">new</span> RelOptCluster(planner, rexBuilder.getTypeFactory(),</div><div class="line">      rexBuilder, <span class="keyword">new</span> AtomicInteger(<span class="number">0</span>), <span class="keyword">new</span> HashMap&lt;&gt;());</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="comment">/**</span></div><div class="line"> * Creates a cluster.</div><div class="line"> *</div><div class="line"> * &lt;p&gt;For use only from &#123;<span class="doctag">@link</span> #create&#125; and &#123;<span class="doctag">@link</span> RelOptQuery&#125;.</div><div class="line"> */</div><div class="line">RelOptCluster(RelOptPlanner planner, RelDataTypeFactory typeFactory,</div><div class="line">    RexBuilder rexBuilder, AtomicInteger nextCorrel,</div><div class="line">    Map&lt;String, RelNode&gt; mapCorrelToRel) &#123;</div><div class="line">  <span class="keyword">this</span>.nextCorrel = nextCorrel;</div><div class="line">  <span class="keyword">this</span>.mapCorrelToRel = mapCorrelToRel;</div><div class="line">  <span class="keyword">this</span>.planner = Objects.requireNonNull(planner);</div><div class="line">  <span class="keyword">this</span>.typeFactory = Objects.requireNonNull(typeFactory);</div><div class="line">  <span class="keyword">this</span>.rexBuilder = rexBuilder;</div><div class="line">  <span class="keyword">this</span>.originalExpression = rexBuilder.makeLiteral(<span class="string">"?"</span>);</div><div class="line"></div><div class="line">  <span class="comment">// set up a default rel metadata provider,</span></div><div class="line">  <span class="comment">// giving the planner first crack at everything</span></div><div class="line">  <span class="comment">//note: 默认的 metadata provider</span></div><div class="line">  setMetadataProvider(DefaultRelMetadataProvider.INSTANCE);</div><div class="line">  <span class="comment">//note: trait（对于 HepPlaner 和 VolcanoPlanner 不一样)</span></div><div class="line">  <span class="keyword">this</span>.emptyTraitSet = planner.emptyTraitSet();</div><div class="line">  <span class="keyword">assert</span> emptyTraitSet.size() == planner.getRelTraitDefs().size();</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h3 id="SqlToRelConverter-转换"><a href="#SqlToRelConverter-转换" class="headerlink" title="SqlToRelConverter 转换"></a>SqlToRelConverter 转换</h3><p>SqlToRelConverter 中的 <code>convertQuery()</code> 将 SqlNode 转换为 RelRoot，其实现如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/**</span></div><div class="line"> * Converts an unvalidated query's parse tree into a relational expression.</div><div class="line"> * note：把一个 parser tree 转换为 relational expression</div><div class="line"> * <span class="doctag">@param</span> query           Query to convert</div><div class="line"> * <span class="doctag">@param</span> needsValidation Whether to validate the query before converting;</div><div class="line"> *                        &lt;code&gt;false&lt;/code&gt; if the query has already been</div><div class="line"> *                        validated.</div><div class="line"> * <span class="doctag">@param</span> top             Whether the query is top-level, say if its result</div><div class="line"> *                        will become a JDBC result set; &lt;code&gt;false&lt;/code&gt; if</div><div class="line"> *                        the query will be part of a view.</div><div class="line"> */</div><div class="line"><span class="function"><span class="keyword">public</span> RelRoot <span class="title">convertQuery</span><span class="params">(</span></span></div><div class="line">    SqlNode query,</div><div class="line">    <span class="keyword">final</span> <span class="keyword">boolean</span> needsValidation,</div><div class="line">    <span class="keyword">final</span> <span class="keyword">boolean</span> top) &#123;</div><div class="line">  <span class="keyword">if</span> (needsValidation) &#123; <span class="comment">//note: 是否需要做相应的校验（如果校验过了，这里就不需要了）</span></div><div class="line">    query = validator.validate(query);</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  <span class="comment">//note: 设置 MetadataProvider</span></div><div class="line">  RelMetadataQuery.THREAD_PROVIDERS.set(</div><div class="line">      JaninoRelMetadataProvider.of(cluster.getMetadataProvider()));</div><div class="line">  <span class="comment">//note: 得到 RelNode(relational expression)</span></div><div class="line">  RelNode result = convertQueryRecursive(query, top, <span class="keyword">null</span>).rel;</div><div class="line">  <span class="keyword">if</span> (top) &#123;</div><div class="line">    <span class="keyword">if</span> (isStream(query)) &#123;<span class="comment">//note: 如果 stream 的话</span></div><div class="line">      result = <span class="keyword">new</span> LogicalDelta(cluster, result.getTraitSet(), result);</div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line">  RelCollation collation = RelCollations.EMPTY;</div><div class="line">  <span class="keyword">if</span> (!query.isA(SqlKind.DML)) &#123; <span class="comment">//note: 如果是 DML 语句</span></div><div class="line">    <span class="keyword">if</span> (isOrdered(query)) &#123; <span class="comment">//note: 如果需要做排序的话</span></div><div class="line">      collation = requiredCollation(result);</div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line">  <span class="comment">//note: 对转换前后的 RelDataType 做验证</span></div><div class="line">  checkConvertedType(query, result);</div><div class="line"></div><div class="line">  <span class="keyword">if</span> (SQL2REL_LOGGER.isDebugEnabled()) &#123;</div><div class="line">    SQL2REL_LOGGER.debug(</div><div class="line">        RelOptUtil.dumpPlan(<span class="string">"Plan after converting SqlNode to RelNode"</span>,</div><div class="line">            result, SqlExplainFormat.TEXT,</div><div class="line">            SqlExplainLevel.EXPPLAN_ATTRIBUTES));</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  <span class="keyword">final</span> RelDataType validatedRowType = validator.getValidatedNodeType(query);</div><div class="line">  <span class="keyword">return</span> RelRoot.of(result, validatedRowType, query.getKind())</div><div class="line">      .withCollation(collation);</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>真正的实现是在 <code>convertQueryRecursive()</code> 方法中完成的，如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/**</span></div><div class="line"> * Recursively converts a query to a relational expression.</div><div class="line"> * note：递归地讲一个 query 转换为 relational expression</div><div class="line"> *</div><div class="line"> * <span class="doctag">@param</span> query         Query</div><div class="line"> * <span class="doctag">@param</span> top           Whether this query is the top-level query of the</div><div class="line"> *                      statement</div><div class="line"> * <span class="doctag">@param</span> targetRowType Target row type, or null</div><div class="line"> * <span class="doctag">@return</span> Relational expression</div><div class="line"> */</div><div class="line"><span class="function"><span class="keyword">protected</span> RelRoot <span class="title">convertQueryRecursive</span><span class="params">(SqlNode query, <span class="keyword">boolean</span> top,</span></span></div><div class="line">    RelDataType targetRowType) &#123;</div><div class="line">  <span class="keyword">final</span> SqlKind kind = query.getKind();</div><div class="line">  <span class="keyword">switch</span> (kind) &#123;</div><div class="line">  <span class="keyword">case</span> SELECT:</div><div class="line">    <span class="keyword">return</span> RelRoot.of(convertSelect((SqlSelect) query, top), kind);</div><div class="line">  <span class="keyword">case</span> INSERT:</div><div class="line">    <span class="keyword">return</span> RelRoot.of(convertInsert((SqlInsert) query), kind);</div><div class="line">  <span class="keyword">case</span> DELETE:</div><div class="line">    <span class="keyword">return</span> RelRoot.of(convertDelete((SqlDelete) query), kind);</div><div class="line">  <span class="keyword">case</span> UPDATE:</div><div class="line">    <span class="keyword">return</span> RelRoot.of(convertUpdate((SqlUpdate) query), kind);</div><div class="line">  <span class="keyword">case</span> MERGE:</div><div class="line">    <span class="keyword">return</span> RelRoot.of(convertMerge((SqlMerge) query), kind);</div><div class="line">  <span class="keyword">case</span> UNION:</div><div class="line">  <span class="keyword">case</span> INTERSECT:</div><div class="line">  <span class="keyword">case</span> EXCEPT:</div><div class="line">    <span class="keyword">return</span> RelRoot.of(convertSetOp((SqlCall) query), kind);</div><div class="line">  <span class="keyword">case</span> WITH:</div><div class="line">    <span class="keyword">return</span> convertWith((SqlWith) query, top);</div><div class="line">  <span class="keyword">case</span> VALUES:</div><div class="line">    <span class="keyword">return</span> RelRoot.of(convertValues((SqlCall) query, targetRowType), kind);</div><div class="line">  <span class="keyword">default</span>:</div><div class="line">    <span class="keyword">throw</span> <span class="keyword">new</span> AssertionError(<span class="string">"not a query: "</span> + query);</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>依然以前面的示例为例，因为是 SqlSelect 类型，这里会调用下面的方法做相应的转换：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/**</span></div><div class="line"> * Converts a SELECT statement's parse tree into a relational expression.</div><div class="line"> * note：将一个 Select parse tree 转换成一个关系表达式</div><div class="line"> */</div><div class="line"><span class="function"><span class="keyword">public</span> RelNode <span class="title">convertSelect</span><span class="params">(SqlSelect select, <span class="keyword">boolean</span> top)</span> </span>&#123;</div><div class="line">  <span class="keyword">final</span> SqlValidatorScope selectScope = validator.getWhereScope(select);</div><div class="line">  <span class="keyword">final</span> Blackboard bb = createBlackboard(selectScope, <span class="keyword">null</span>, top);</div><div class="line">  convertSelectImpl(bb, select);<span class="comment">//note: 做相应的转换</span></div><div class="line">  <span class="keyword">return</span> bb.root;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>在 <code>convertSelectImpl()</code> 方法中会依次对 SqlSelect 的各个部分做相应转换，其实现如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/**</span></div><div class="line"> * Implementation of &#123;<span class="doctag">@link</span> #convertSelect(SqlSelect, boolean)&#125;;</div><div class="line"> * derived class may override.</div><div class="line"> */</div><div class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">convertSelectImpl</span><span class="params">(</span></span></div><div class="line">    <span class="keyword">final</span> Blackboard bb,</div><div class="line">    SqlSelect select) &#123;</div><div class="line">  <span class="comment">//note: convertFrom</span></div><div class="line">  convertFrom(</div><div class="line">      bb,</div><div class="line">      select.getFrom());</div><div class="line">  <span class="comment">//note: convertWhere</span></div><div class="line">  convertWhere(</div><div class="line">      bb,</div><div class="line">      select.getWhere());</div><div class="line"></div><div class="line">  <span class="keyword">final</span> List&lt;SqlNode&gt; orderExprList = <span class="keyword">new</span> ArrayList&lt;&gt;();</div><div class="line">  <span class="keyword">final</span> List&lt;RelFieldCollation&gt; collationList = <span class="keyword">new</span> ArrayList&lt;&gt;();</div><div class="line">  <span class="comment">//note: 有 order by 操作时</span></div><div class="line">  gatherOrderExprs(</div><div class="line">      bb,</div><div class="line">      select,</div><div class="line">      select.getOrderList(),</div><div class="line">      orderExprList,</div><div class="line">      collationList);</div><div class="line">  <span class="keyword">final</span> RelCollation collation =</div><div class="line">      cluster.traitSet().canonize(RelCollations.of(collationList));</div><div class="line"></div><div class="line">  <span class="keyword">if</span> (validator.isAggregate(select)) &#123;</div><div class="line">    <span class="comment">//note: 当有聚合操作时，也就是含有 group by、having 或者 Select 和 order by 中含有聚合函数</span></div><div class="line">    convertAgg(</div><div class="line">        bb,</div><div class="line">        select,</div><div class="line">        orderExprList);</div><div class="line">  &#125; <span class="keyword">else</span> &#123; <span class="comment">//note: 对 select list 部分的处理</span></div><div class="line">    convertSelectList(</div><div class="line">        bb,</div><div class="line">        select,</div><div class="line">        orderExprList);</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  <span class="keyword">if</span> (select.isDistinct()) &#123; <span class="comment">//note: select 后面含有 DISTINCT 关键字时（去重）</span></div><div class="line">    distinctify(bb, <span class="keyword">true</span>);</div><div class="line">  &#125;</div><div class="line">  <span class="comment">//note: Converts a query's ORDER BY clause, if any.</span></div><div class="line">  convertOrder(</div><div class="line">      select, bb, collation, orderExprList, select.getOffset(),</div><div class="line">      select.getFetch());</div><div class="line">  bb.setRoot(bb.root, <span class="keyword">true</span>);</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>这里以示例中的 From 部分为例介绍 SqlNode 到 RelNode 的逻辑，按照示例 DEUBG 后的结果如下图所示，因为 form 部分是一个 join 操作，会进入 join 相关的处理中。</p>
<p><img src="/images/calcite/5-calcite.jpg" alt="convertFrom 之 Join 的情况"> </p>
<p>这部分方法调用过程是：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">convertQuery --&gt;</div><div class="line">convertQueryRecursive --&gt;</div><div class="line">convertSelect --&gt;</div><div class="line">convertSelectImpl --&gt;</div><div class="line">convertFrom &amp; convertWhere &amp; convertSelectList</div></pre></td></tr></table></figure>
<p>到这里 SqlNode 到 RelNode 过程就完成了，生成的逻辑计划如下：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">LogicalSort(sort0=[<span class="variable">$0</span>], dir0=[ASC])</div><div class="line">  LogicalProject(USER_ID=[<span class="variable">$0</span>], USER_NAME=[<span class="variable">$1</span>], USER_COMPANY=[<span class="variable">$5</span>], USER_AGE=[<span class="variable">$2</span>])</div><div class="line">    LogicalFilter(condition=[AND(&gt;(<span class="variable">$2</span>, 30), &gt;(<span class="variable">$3</span>, 10))])</div><div class="line">      LogicalJoin(condition=[=(<span class="variable">$1</span>, <span class="variable">$4</span>)], joinType=[inner])</div><div class="line">        LogicalTableScan(table=[[USERS]])</div><div class="line">        LogicalTableScan(table=[[JOBS]])</div></pre></td></tr></table></figure>
<p>到这里前三步就算全部完成了。</p>
<h2 id="Step4-优化阶段（RelNode–-gt-RelNode）"><a href="#Step4-优化阶段（RelNode–-gt-RelNode）" class="headerlink" title="Step4: 优化阶段（RelNode–&gt;RelNode）"></a>Step4: 优化阶段（RelNode–&gt;RelNode）</h2><p>终于来来到了第四阶段，也就是 Calcite 的核心所在，优化器进行优化的地方，前面 sql 中有一个明显可以优化的地方就是过滤条件的下压（push down），在进行 join 操作前，先进行 filter 操作，这样的话就不需要在 join 时进行全量 join，减少参与 join 的数据量。</p>
<p>关于filter 操作下压，在 Calcite 中已经有相应的 Rule 实现，就是 <code>FilterJoinRule.FilterIntoJoinRule.FILTER_ON_JOIN</code>，这里使用 HepPlanner 作为示例的 planer，并注册 FilterIntoJoinRule 规则进行相应的优化，其代码实现如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">HepProgramBuilder builder = <span class="keyword">new</span> HepProgramBuilder();</div><div class="line">builder.addRuleInstance(FilterJoinRule.FilterIntoJoinRule.FILTER_ON_JOIN); <span class="comment">//note: 添加 rule</span></div><div class="line">HepPlanner hepPlanner = <span class="keyword">new</span> HepPlanner(builder.build());</div><div class="line">hepPlanner.setRoot(relNode);</div><div class="line">relNode = hepPlanner.findBestExp();</div></pre></td></tr></table></figure>
<p>在 Calcite 中，提供了两种 planner：HepPlanner 和 VolcanoPlanner，关于这块内容可以参考【Drill/Calcite查询优化系列】这几篇文章（讲述得非常详细，赞），这里先简单介绍一下 HepPlanner 和 VolcanoPlanner，后面会关于这两个 planner 的代码实现做深入的讲述。</p>
<h3 id="HepPlanner"><a href="#HepPlanner" class="headerlink" title="HepPlanner"></a>HepPlanner</h3><p>特点（来自 <a href="https://www.slideshare.net/JordanHalterman/introduction-to-apache-calcite" target="_blank" rel="external">Apache Calcite介绍</a>）：</p>
<ol>
<li>HepPlanner is a heuristic optimizer similar to Spark’s optimizer，与 spark 的优化器相似，HepPlanner 是一个 heuristic 优化器；</li>
<li>Applies all matching rules until none can be applied：将会匹配所有的 rules 直到一个 rule 被满足；</li>
<li>Heuristic optimization is faster than cost- based optimization：它比 CBO 更快；</li>
<li>Risk of infinite recursion if rules make opposing changes to the plan：如果没有每次都不匹配规则，可能会有无限递归风险；</li>
</ol>
<h3 id="VolcanoPlanner"><a href="#VolcanoPlanner" class="headerlink" title="VolcanoPlanner"></a>VolcanoPlanner</h3><p>特点（来自 <a href="https://www.slideshare.net/JordanHalterman/introduction-to-apache-calcite" target="_blank" rel="external">Apache Calcite介绍</a>）：</p>
<ol>
<li>VolcanoPlanner is a cost-based optimizer：VolcanoPlanner是一个CBO优化器；</li>
<li>Applies matching rules iteratively, selecting the plan with the cheapest cost on each iteration：迭代地应用 rules，直到找到cost最小的plan；</li>
<li>Costs are provided by relational expressions；</li>
<li>Not all possible plans can be computed：不会计算所有可能的计划；</li>
<li>Stops optimization when the cost does not significantly improve through a determinable number of iterations：根据已知的情况，如果下面的迭代不能带来提升时，这些计划将会停止优化；</li>
</ol>
<h3 id="示例运行结果"><a href="#示例运行结果" class="headerlink" title="示例运行结果"></a>示例运行结果</h3><p>经过 HepPlanner 优化后的逻辑计划为：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">LogicalSort(sort0=[<span class="variable">$0</span>], dir0=[ASC])</div><div class="line">  LogicalProject(USER_ID=[<span class="variable">$0</span>], USER_NAME=[<span class="variable">$1</span>], USER_COMPANY=[<span class="variable">$5</span>], USER_AGE=[<span class="variable">$2</span>])</div><div class="line">    LogicalJoin(condition=[=(<span class="variable">$1</span>, <span class="variable">$4</span>)], joinType=[inner])</div><div class="line">      LogicalFilter(condition=[&gt;(<span class="variable">$2</span>, 30)])</div><div class="line">        EnumerableTableScan(table=[[USERS]])</div><div class="line">      LogicalFilter(condition=[&gt;(<span class="variable">$0</span>, 10)])</div><div class="line">        EnumerableTableScan(table=[[JOBS]])</div></pre></td></tr></table></figure>
<p>可以看到优化的结果是符合我们预期的，HepPlanner 和 VolcanoPlanner 详细流程比较复杂，后面会有单独的文章进行讲述。</p>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>Calcite 本身的架构比较好理解，但是具体到代码层面就不是那么好理解了，它抛出了很多的概念，如果不把这些概念搞明白，代码基本看得也是云里雾里，特别是之前没有接触过这块内容的同学（我最开始看 Calcite 代码时是真的头大），入门的门槛确实高一些，但是当这些流程梳理清楚之后，其实再回头看，也没有多少东西，在生产中用的时候主要也是针对具体的业务场景扩展相应的 SQL 语法、进行具体的规则优化。</p>
<p>Calcite 架构设计得比较好，其中各个组件都可以单独使用，Rule（规则）扩展性很强，用户可以根据业务场景自定义相应的优化规则，它支持标准的 SQL，支持不同的存储和计算引擎，目前在业界应用也比较广泛，这也证明其牛叉之处。</p>
<blockquote>
<p>本文只是个人理解的总结，由于本人也是刚接触这块，理解有偏差的地方，欢迎指正~</p>
</blockquote>
<hr>
<h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><ol>
<li><a href="https://www.infoq.cn/article/new-big-data-hadoop-query-engine-apache-calcite" target="_blank" rel="external">Apache Calcite：Hadoop 中新型大数据查询引擎</a>；</li>
<li><a href="https://www.slideshare.net/JordanHalterman/introduction-to-apache-calcite" target="_blank" rel="external">Apache Calcite介绍</a>；</li>
<li><a href="https://arxiv.org/pdf/1802.10233.pdf" target="_blank" rel="external">Apache Calcite: A Foundational Framework for Optimized Query Processing Over Heterogeneous Data Sources</a>；</li>
<li><a href="http://calcite.apache.org/docs/tutorial.html" target="_blank" rel="external">Calcite Tutorial</a>；</li>
</ol>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[如何高效学习]]></title>
      <url>http://matt33.com/2018/11/21/effective-learning/</url>
      <content type="html"><![CDATA[<p>在这个知识爆炸、科技日新月异的时代，技术的变化远比我们想象的要快很多，这就对工程师的要求就提高了很多，特别是对于那些在技术上有所追求的工程师而言。对于一些互联网大厂，学习能力也成了面试中重点考察的内容。如何快速学习、掌握一门新的技术，如何提高自己的学习效率，对于有一定工作经验的人来说，可能每个人都有一个自己的学习方法论，但是我们也需要去学习借鉴别人（特别是那些有一定技术影响力的技术大咖）的经验，来不断更新和完善自己的方法轮。今天这篇《高效学习》，就是与大家一起探讨技术学习的方法论，本文的内容主要来自耗子叔的《左耳听风 —— 高效学习篇》，中间会穿插个人的一些经验，算是对这个系列的一个总结。如果想看原文内容，欢迎订阅耗子叔的这个专栏，这个专栏质量还是非常高的，耗子叔推荐了很多优秀的学习资源（通过文章末尾处的二维码链接购买）。</p>
<h2 id="端正学习态度"><a href="#端正学习态度" class="headerlink" title="端正学习态度"></a>端正学习态度</h2><p>对于大多数人来说，我们并不是那种天赋异禀的天才，所以那些速成的学习方法并不适合我们，因为，<strong>对于非天才的我们来说，学习是不可能速成的</strong>，学习本来就是一件【逆人性】的事，就像锻炼身体一样，<strong>需要人持续付出，会让人感到痛苦，并随时想找理由放弃，实际上，痛苦是成长的必经阶段</strong>。</p>
<p>大部分人都认为自己热爱学习，但是有多少能真正付出实践、并一直坚持下去，能做到实践和坚持的人，一般运气都不会太差。如果我们去研究一下古今中外的成功人士，就会发现，他们基本上都是非常自律的，也都是非常热爱学习的，他们可以沉得下心来不断学习，在学习中不断地思考、探索和实践。懒，是人类的天性，如果不能克服自己 DNA 中的弱点，不能端正自己的态度，不能自律，不能坚持，不能举一反三，不能不断追问等，那么，无论多好的方法，你都不可能学好。所以，<strong>有正确的态度非常重要</strong>。</p>
<blockquote>
<p>当然只做到上面说的，并不一定能保证能够实现所谓的成功，但是完全可以让你在某个领域做到足够优秀。</p>
</blockquote>
<h3 id="主动学习和被动学习"><a href="#主动学习和被动学习" class="headerlink" title="主动学习和被动学习"></a>主动学习和被动学习</h3><p>下面这张图，大部分人应该都见过，这张图又称为学习金字塔：</p>
<p><img src="/images/share/learn.png" alt="学习效率"></p>
<p>人的学习，可以分为【被动学习】和【主动学习】两个层次：</p>
<ul>
<li><strong>被动学习</strong>：如听讲、阅读、视听、演示，学习内容的平均留存率为 5%、10%、20% 和 30%；</li>
<li><strong>主动学习</strong>：如通过讨论、实践、教授给他人，会将原来被动学习的内容留存率从 5% 提升到 50%、75%、90%。</li>
</ul>
<p>关于这个，我是深有体会的，如果我们只是看书或听一下别人的分享，不去实践，可能不到半个月，能记住 10% 的内容就不错了，我认为最好的学习方法是 <strong>实践，总结，教授给别人（要让别人听明白，教授的过程要有深度的讨论，而不是 PPT 走一遍）</strong> 。</p>
<p>过去一年多，很幸运的是，遇到了几个热爱学习的小伙伴，我们经常周末一起组织分享，每次分享只涉及很少的一块内容，分享过程中我们以讨论为主，这对分享者的能力锻炼有很好的效果（通过讨论听众也能收获很多），首先他需要自己能够理解这个问题，其次他需要把自己的理解给别人讲清楚，还需要回答其他人提出的问题（这些问题可能是分享者压根没注意的问题）。我也一直想在团队内部推广这种学习方法（这种方法人数太多的话就不太适合了），但是在团队内部去推，效果没有想象中得那么好，而且在团队内部反而很难坚持下去（大家的时间都比较有限，如果占据了别人的工作时间，别人可能需要加班才能完成自己的工作，所以大家兴趣并没有那么高昂）。相反，如果能找几个愿意一起学习的小伙伴一同学习、成长，这样反而效果好很多，如果你能找到这样的一群小伙伴，我是非常推荐这种学习方式，把自己学习的内容分享给其他人（大家一起学习、讨论这种学习效果，考虑问题的深度要比自己独自学习高出很多）。</p>
<h3 id="浅度学习和深度学习"><a href="#浅度学习和深度学习" class="headerlink" title="浅度学习和深度学习"></a>浅度学习和深度学习</h3><p><strong>学习并不是努力读更多的书，盲目追求阅读的速度和数量，这会让人产生低层次的勤奋和成长的感觉，这只是在使蛮力。要思辩，要践行，要总结和归纳，否则，你只是在机械地重复某件事，而不会有质的成长。</strong></p>
<p>在知识的领域其实也有阶层之分（类似于富人和穷人在财富方面的阶层之分，阶层的跨越非常难，但不是没有可能），那么长期在底层知识阶层的人，需要等着高层的人来喂养，他们长期陷入各种谣言和不准确的信息环境中，于是就导致错误和幼稚的认知，并习惯于哪些不费劲儿的轻度学习方式，<strong>从而一点点地丧失了深度学习的独立思考能力，从而再也没有能力打破知识阶层的限制，被困在认知底层翻不了身</strong>（就像我们经常说的，美国那些在穷人区生活的人们，他们在没有受到很好教育的前提下想突破自己的阶层，真的很难）。</p>
<p>对于知识的学习，我们应该如何进行深度学习呢？下面几点是关键：</p>
<ol>
<li><strong>高质量的信息源和第一手的知识</strong>；</li>
<li><strong>把知识连成地图，将自己的理解反述出来</strong>；</li>
<li><strong>不断地反思和思辩，与不同年龄段的人讨论</strong>：讨论、交流很多情况下，比自己看书、看代码收获要多很多；</li>
<li><strong>举一反三，并践行之，把知识转换成技能</strong>。</li>
</ol>
<p>学习有三个步骤：</p>
<ol>
<li><strong>知识采集</strong>：信息源是非常重要的，<strong>获取信息源头、破解表面信息的内在本质、多方数据印证</strong>，是这个步骤的关键；</li>
<li><strong>知识缝合</strong>：所谓缝合就是把信息组织起来，成为结构体的知识，这里，<strong>连接记忆，逻辑推理，知识梳理</strong> 是很重要的三部分；</li>
<li><strong>技能转换</strong>：通过 <strong>举一反三、实践和练习</strong>，以及<strong>教授传导</strong>，把知识转换成自己的技能，这种技能可以让你进入更高的阶层；</li>
</ol>
<h3 id="学习的目的"><a href="#学习的目的" class="headerlink" title="学习的目的"></a>学习的目的</h3><p>学习目的是什么呢？</p>
<ol>
<li><strong>学习是为了找到方法</strong>：学习不仅仅是为了找到答案，而更是为了<strong>找到方法</strong>，掌握了通往答案的路径和方法之后，便拥有了无师自通的能力；</li>
<li><strong>学习是为了找到原理</strong>：学习不仅仅是为了知道，而更是为了<strong>思考和理解</strong>（真正的学习，从来都不是轻松的，而是那种你知道得越多，你的问题就会越多，你的问题越多，你就会思考得越多，你思考得越多，你就会觉得自己直到越少，于是你就会想要了解更多，这是一种螺旋式上升上下求索的状态），一旦掌握了这些本质的东西，你就会发现，整个复杂多变的世界在变得越来越简单；</li>
<li><strong>学习是为了了解自己</strong>：学习不仅仅是为了开拓眼界，而更是为了找到自己的未知，为了了解自己，开拓眼界的目的就是为了发现自己的不足和上升空间，从而才能让自己成长；</li>
<li><strong>学习是为了改变自己</strong>：学习不仅仅是为了成长，而更是为了改变自己（改变自己的思考方式和思维方式，改变自己与生俱来的那些垃圾和低效的算法）。</li>
</ol>
<h2 id="源头、原理和知识地图"><a href="#源头、原理和知识地图" class="headerlink" title="源头、原理和知识地图"></a>源头、原理和知识地图</h2><h3 id="挑选知识和信息源"><a href="#挑选知识和信息源" class="headerlink" title="挑选知识和信息源"></a>挑选知识和信息源</h3><p>对于计算机知识来说，<strong>学习英文</strong>是是否能够成长的关键，如果我们能用 Google 英文关键词就可以找到自己想要的知识，那么我们只是算得上能跟得上这个时代，但如果能在社区里跟社区里的大牛交流得到答案，这样才算是领先于这个时代。</p>
<p>信息源应该有以下几个特质：</p>
<ol>
<li><strong>第一手的资料</strong>，不是被别人理解过、消化过的二手资料，尤其对于知识性的东西来说，更是这样；</li>
<li>应该是有佐证、有数据、有引用的，或是有权威人士或大公司生产系统背书的资料，应该是被时间和实践检验过的，或是小心求证过的，不是拍脑袋野路子或是道听途说的资料；</li>
<li>应该是加入了一些自己的经验和思考，可以引发人深思的，是所谓信息的密集很大的文章。</li>
</ol>
<p>耗子叔比较推荐 Medium 上的文章，这个上面的文章质量比较高。</p>
<h3 id="注重基础和原理"><a href="#注重基础和原理" class="headerlink" title="注重基础和原理"></a>注重基础和原理</h3><p><strong>基础知识和原理性的东西是无比重要的</strong>，无论是 JVM 还是 Node，或者是 Python 解释器里干了什么，它都无法逾越底层操作系统 API 对 『物理世界』的限制。</p>
<p>比如，当学习一门新的语言时，除了看每个语言都有的 if-else、for/while-loop、function 等东西外，还需要重点看的就是：</p>
<ul>
<li>出错处理是怎么玩的？</li>
<li>内存管理是怎么玩的？</li>
<li>数据封装和扩展是怎么玩的？</li>
<li>多态和泛型是怎么搞的？</li>
<li>运行时识别和反射是怎么玩的？</li>
<li>并发编程是怎么玩的？</li>
<li>…</li>
</ul>
<p>所以，最关键的是，<strong>这些基础知识和原理性的东西和技术，都是经历过长时间的考验的，这些基础技术也有很多人类历史上的智慧结晶，会给你很多启示和帮助</strong>（基础知识虽然很枯燥不实用、工作上用不到，学习这些知识是为了学得更快，基础打牢，学什么都快，而学得快就会学得多，学得多，就会思考得多，思考得多，就会学得更快…）。</p>
<h3 id="使用知识图"><a href="#使用知识图" class="headerlink" title="使用知识图"></a>使用知识图</h3><p>耗子叔在这里介绍一个<strong>知识图</strong>的学习方式，通过这种方式可以让我们从一个技术最重要的主干的地方开始出发遍历所有的技术细节，以 C++ 为例，分为三部分：</p>
<ol>
<li>C++ 是用来解决 C 语言问题的，那么 C 语言有什么问题呢？指针、宏、错误处理、数据拷贝…C++是用什么技术来解决这些问题的？</li>
<li>C++ 的面向对象特性：封装、继承、多态。封装，让我想起了构造函数、析构函数等。析构函数让我想起了初始化列表，想到了默认构造函数，想到了拷贝构造函数，想到了 new…多态，让我想到了虚函数，想到了 RTTI，RTTI 让我想起了 <code>dynamic_cast</code> 和 <code>typeid</code> 等；</li>
<li>C++ 的泛型编程，我想到了 <code>templete</code>，想到了操作符重载，想到了函数对象，想到了 STL，想到数据容器，想到了 iterator，想到了通用算法等等。</li>
</ol>
<p>有了这样一颗知识树之后，当出现一些不知道的知识点时，可以往这棵知识树上挂，而这样一来，也使得我们的学习更为系统和全面。</p>
<h2 id="深度、归纳和坚持实践"><a href="#深度、归纳和坚持实践" class="headerlink" title="深度、归纳和坚持实践"></a>深度、归纳和坚持实践</h2><h3 id="系统地学习"><a href="#系统地学习" class="headerlink" title="系统地学习"></a>系统地学习</h3><p>在系统性地学习一项技术时，耗子叔总结了一个<strong>学习模板</strong>，模板内容如下：</p>
<ol>
<li><strong>这个技术出现的背景、初衷和要达到什么样的目标或是要解决什么样的问题</strong>，这是这个技术的成因和目标（设计理念），也是这个技术的灵魂；</li>
<li><strong>这个技术的优势和劣势分别是什么，或者说，这个技术的 tradeoff 是什么</strong>，任何技术都有其好坏，在解决一个问题的时候，也会带来新的问题，一般来说，任何设计都有 tradeoff，所以，需要知道这个技术的优势和劣势，以及带来的挑战；</li>
<li><strong>这个技术的适用场景</strong>，要注意没有一个技术是普适的，每个技术都其特别适合的场景，所谓的场景一般分为两个：一个是业务场景，一个是技术场景；</li>
<li><strong>技术的组成部分和关键点</strong>，这是技术的核心思想，也是这个技术的灵魂所在，学习技术的核心部分是快速掌握的关键；</li>
<li><strong>技术的底层原理和关键实现</strong>，任何一个技术都有其底层的关键基础技术，学习这些关键的底层技术，可以让我们未来很快地掌握其他技术；</li>
<li><strong>已有的实现和它之间的对比</strong>，一般来说，任何一个技术都会有不同的实现，不同的实现都会有不同的侧重，学习不同的实现，可以让你得到不同的想法和思路，对于开阔思维、深入细节是非常重要的。</li>
</ol>
<h3 id="举一反三"><a href="#举一反三" class="headerlink" title="举一反三"></a>举一反三</h3><p>重点是如何才能让自己拥有举一反三的能力，在这方面，耗子叔对自己训练如下：</p>
<ol>
<li>对于一个场景，制造出各种不同的问题或难题；</li>
<li>对于一个问题，努力寻找尽可能多的解，并比较这些解的优劣；</li>
<li>对于一个解，努力寻找各种不同的测试案例，以图让其健壮。</li>
</ol>
<p>举一反三的能力，可以分解为：</p>
<ol>
<li><strong>联想能力</strong>：这种能力的锻炼需要你平时就在不停地思考同一个事物的不同的用法，或是联想与之有关的别的事物。对于软件开发和技术学习也一样；</li>
<li><strong>抽象能力</strong>：抽象能力是举一反三的基本技能。平时你解决问题的时候，如果你能对这个问题进行抽象，你就可以获得更多的表现形式。抽象能力需要找到解决问题的通用模型，比如数学就是对现实世界的一种抽象。只要我们能把现实世界的各种问题建立成数据模型（如，建立各种维度的向量），我们就可以用数学来求解，这也是机器学习的本质；</li>
<li><strong>自省能力</strong>：所谓自省能力就是自己找自己的难看。当你得到一个解的时候，要站在自己的对立面来找这个解的漏洞。有点像左右手互博。这种自己和自己辩论的能力又叫思辨能力。将自己分裂成正反方，左右方，甚至多方，站在不同的立场上来和自己辩论，从而做到不漏过一个 case，从而获得完整全面的问题分析能力。</li>
</ol>
<p>如果要获得这三种能力，除了你要很喜欢思考和找其它人来辩论或讨论以外，还要看你自己是否真的善于思考，是否有好奇心，是否喜欢打破沙锅问到底，是否喜欢关注细节，做事是否认真，是否严谨……</p>
<h3 id="总结和归纳"><a href="#总结和归纳" class="headerlink" title="总结和归纳"></a>总结和归纳</h3><p>我们把学到的东西用自己的语言和理解重新组织并表达出来，本质上是对信息进行消化和再加工的过程，这个过程可能会有信息损失，但也可能会有新信息加入，本质上是信息重构的过程。<strong>我们积累的知识越多，在知识间进行联系和区辨的能力就越强，对知识进行总结和归纳也就越轻松</strong>。而想要提高总结归纳的能力，首先要多阅读，多积累素材，扩大自己的知识面，多和别人讨论，多思辨，从而见多识广。</p>
<p>不过，我们需要注意的是，如果只学了部分知识或者还没有学透，就开始对知识进行总结归纳，那么总结归纳出来的知识结构也只能是混乱和幼稚的。因此，学习的开始阶段，可以不急于总结归纳，不急于下判断，做结论，而应该<strong>保留部分知识的不确定性，保持对知识的开放状态</strong>。当对整个知识的理解更深入，自己站的位置更高以后，总结和归纳才会更有条理。总结归纳更多是在复习中对知识的回顾和重组，而不是一边学习一边就总结归纳。</p>
<p>最后再总结一下做总结归纳的方法：<strong>把你看到和学习到的信息，归整好，排列好，关联好，总之把信息碎片给结构化掉，然后在结构化的信息中，找到规律，找到相通之处，找到共同之处，进行简化、归纳和总结，最终形成一种套路，一种模式，一种通用方法</strong>。</p>
<h3 id="实践出真知"><a href="#实践出真知" class="headerlink" title="实践出真知"></a>实践出真知</h3><p><strong>实践是很累很痛苦的事，但只有痛苦才会让人反思，而反思则是学习和改变自己的动力。Grow up through the pain，是非常有道理的。</strong></p>
<h3 id="坚持不懈"><a href="#坚持不懈" class="headerlink" title="坚持不懈"></a>坚持不懈</h3><p>坚持本来也是一件反人性的事情，关于坚持的问题，大家应该都见过很多相似的文章，总之，坚持是一件看似简单、但是完成率非常低的事情。如果想要让自己能够坚持下去，最好能够让自己处于一个<strong>正反馈的循环</strong>中，比如，学习一个技术之后，与大家去分享自己的经验，或者整理出一篇博客让其他学习，都是一种很好的学习方法。</p>
<h2 id="如何学习和阅读代码"><a href="#如何学习和阅读代码" class="headerlink" title="如何学习和阅读代码"></a>如何学习和阅读代码</h2><h3 id="读书还是读代码？"><a href="#读书还是读代码？" class="headerlink" title="读书还是读代码？"></a>读书还是读代码？</h3><p>关于书/文档和代码的关系：</p>
<ul>
<li>代码：What、How &amp; Details；</li>
<li>书/文档：What、How &amp; Why；</li>
</ul>
<p>代码是具体的实现，但是并不能告诉你为什么？<strong>书和文档是人对人说的话，代码是人对机器说的话</strong>：</p>
<ol>
<li><strong>如果想知道为什么要这么搞，应该去看书、看文档</strong>：特别当我们想了解一种思想、一种方法、一种原理、一种经验时，书和文档是最佳的方式、更有效率一些；</li>
<li><strong>如果想知道是怎么实现的，实现的细节，应该去看代码</strong>：对于具体的实现，比如：某协程的实现、某模块的性能、某个算法的实现，这时候最好的方式就是去读代码；</li>
</ol>
<p>至于从代码中收获大还是从书中收获大，不同的场景、不同的目的下，会有不同的答案，我个人对这部分的想法是：</p>
<ol>
<li>工作的前几年，更多的时候应该关注代码、关注细节的实现、多写代码（当然不是说完全不看书，书是必须要看的，特别是当有了相关实战经验之后再去看书看，效果会更好），这个阶段，Google、Stack Overflow、Github 将会是最好的学习渠道，如果在过程中，还能获得一些技术影响力，那将再好不过了；</li>
<li>有一定经验之后，这时候需要更多的【理性认识】，在这个阶段，我们的想法不再是实现某个功能，可能是想做出更牛逼的东西来，这时候应该多读那些大牛的书、与大牛交流、关注国际顶级会议的论文，应该让自己往技术 leader 这个方向发展。</li>
</ol>
<h3 id="如何阅读源代码"><a href="#如何阅读源代码" class="headerlink" title="如何阅读源代码"></a>如何阅读源代码</h3><p>关于如何阅读源代码，耗子叔分享了一些干货，我这里简单总结一下</p>
<p>首先是阅读代码之前，最好先有以下了解：</p>
<ol>
<li>基础知识：相关的语言和基础技术的知识；</li>
<li>软件功能：需要知道这个软件是做什么的、有哪些特性、哪些配置项，最好能够读一遍用户手册，然后让软件跑起来，自己先用一下感受一下；</li>
<li>相关文档：读一下相关的内部文档；</li>
<li>代码的组织结构：先简单看下源码的组织结构。</li>
</ol>
<p>接下来，就是详细地看代码的实现，这里耗子叔分享了一个源代码阅读的经验：</p>
<ol>
<li><strong>接口抽象定义</strong>：任何代码都会有很多接口或抽象定义，其描述了代码需要处理的数据结构或者业务实体，以及它们之间的关系，理清楚这些关系是非常重要的；</li>
<li><strong>模块粘合层</strong>：我们的代码有很多都是用来粘合代码的，比如中间件（middleware）、Promises 模式、回调（Callback）、代理委托、依赖注入等。这些代码模块间的粘合技术是非常重要的，因为它们会把本来平铺直述的代码给分裂开来，让你不容易看明白它们的关系；</li>
<li><strong>业务流程</strong>：这是代码运行的过程。<strong>一开始，我们不要进入细节，但需要在高层搞清楚整个业务的流程是什么样的</strong>，在这个流程中，数据是怎么被传递和处理的。一般来说，我们需要<strong>画程序流程图或者时序处理图</strong>；</li>
<li><strong>具体实现</strong>：了解上述的三个方面的内容，相信你对整个代码的框架和逻辑已经有了总体认识。这个时候，你就可以深入细节，开始阅读具体实现的代码了。对于代码的具体实现，一般来说，你需要知道下面一些事实，这样有助于你在阅读代码时找到重点。<ul>
<li><strong>代码逻辑</strong>：代码有两种逻辑，一种是<strong>业务逻辑</strong>，这种逻辑是真正的业务处理逻辑；另一种是<strong>控制逻辑</strong>，这种逻辑只是用控制程序流转的，不是业务逻辑。比如：flag 之类的控制变量，多线程处理的代码，异步控制的代码，远程通讯的代码，对象序列化反序列化的代码等。这两种逻辑你要分开，很多代码之所以混乱就是把这两种逻辑混在一起了；</li>
<li><strong>出错处理</strong>：根据 2：8 原则，20% 的代码是正常的逻辑，80% 的代码是在处理各种错误，所以，你在读代码的时候，完全可以把处理错误的代码全部删除掉，这样就会留下比较干净和简单的正常逻辑的代码。排除干扰因素，可以更高效地读代码；</li>
<li><strong>数据处理</strong>：只要你认真观察，就会发现，我们好多代码就是在那里倒腾数据。比如 DAO、DTO，比如 JSON、XML，这些代码冗长无聊，不是主要逻辑，可以不理；</li>
<li><strong>重要的算法</strong>：一般来说，我们的代码里会有很多重要的算法，我说的并不一定是什么排序或是搜索算法，可能会是一些其它的核心算法，比如一些索引表的算法，全局唯一 ID 的算法，信息推荐的算法、统计算法、通读算法（如 Gossip）等。这些比较核心的算法可能会非常难读，但它们往往是最有技术含量的部分；</li>
<li><strong>底层交互</strong>：有一些代码是和底层系统的交互，一般来说是和操作系统或是 JVM 的交互。因此，读这些代码通常需要一定的底层技术知识，不然，很难读懂；</li>
</ul>
</li>
<li><strong>运行时调试</strong>：很多时候，代码只有运行起来了，才能知道具体发生了什么事，所以，我们让代码运行进来，然后用日志也好，debug 设置断点跟踪也好。实际看一下代码的运行过程，是了解代码的一种很好的方式。</li>
</ol>
<p>总结一下，阅读代码的方法如下。</p>
<ul>
<li>一般采用自顶向下，从总体到细节的【剥洋葱皮】的读法；</li>
<li>画图是必要的，程序流程图，调用时序图，模块组织图；</li>
<li>代码逻辑归一下类，排除杂音，主要逻辑才会更清楚；</li>
<li>debug 跟踪一下代码是了解代码在执行中发生了什么的最好方式。</li>
</ul>
<h2 id="面对枯燥和量大的知识"><a href="#面对枯燥和量大的知识" class="headerlink" title="面对枯燥和量大的知识"></a>面对枯燥和量大的知识</h2><p>知识很多，在学习的时候要<strong>抓住本质，关注本质和原理</strong>，这些才是不容易改变的，是经得住时间考验的。<strong>带着问题去学习</strong>也是一种非常好的学习方式，耗子叔根据自己经验在专栏中分享以下几个 tips：</p>
<ol>
<li><strong>认真阅读文档</strong>：使用前之前看文档，跟遇到问题之后再看一遍使用文档，收获可能会完全不一样；</li>
<li><strong>用不同的方式学习同一个东西</strong>：比如，看书、听课、写博客、讲课等；</li>
<li><strong>不要被打断</strong>：被打断简直是学习天敌，保持自己注意力的集中；</li>
<li><strong>总结压缩信息</strong>：面对太多的信息时，用一个自己的【压缩算法】抓住问题的关键点；</li>
<li><strong>把未知关联到已知</strong>：把新学的知识关联到已知的事物上来；</li>
<li><strong>用教的方式学习</strong>：这种方式对自己的能力会是一个极大的提升；</li>
<li><strong>学以致用</strong>：把学到的东西用起来，在实践中深化自己的学习效果；</li>
<li><strong>不要记忆</strong>：聪明的人不会记忆知识的，他们会找方法，那些可以推导出知识或答案的方法；</li>
<li><strong>多犯错误</strong>：犯错会让你学到更多，通过错误总结教训。</li>
</ol>
<blockquote>
<p>这里有一个 TED 的演讲，<a href="https://weibo.com/tv/v/Gj1tol62s?fid=1034:3e9bbb1d315b62c5deb90e13efd09981" target="_blank" rel="external">TED演讲：只需20个小时，你就能学会任何事情！</a>，保证自己全身心投入、不受外界打扰的情况下，只要20个小时，我们就能达到这里 <a href="http://matt33.com/2018/08/01/system-learn-summary/#3-%E5%8E%9F%E7%90%86%E7%A0%94%E7%A9%B6">如何学习开源项目-第三步</a>，当然这20个小时要求是一个非常专注的20个小时，我还没有尝试过这种学习方法，近期准备尝试一次这种学习方法，到时候会写一篇文章来总结一下自己的经验。</p>
</blockquote>
<p>最后，以矮大紧的一句话作为结束：【时代变来变去，确实有一些新的东西，但是在这样一个时代里，有一样东西没有变，就是有这样一群人，然后我们都读了一点书，受过不错的教育，然后对自己的心灵能长出什么东西，虽然不知道具体会长什么东西，但是拒绝全部种玉米、拒绝全部长土豆，希望心里有一亩田，有一天能长出一朵不知道是什么的花。（—来自《晓说》）】（这段话好像跟文章的主题没有什么关系，但不知为何突然想到了这段话，这里就列了出来）。</p>
<p><img src="/images/share/zuoer-tingfeng.jpeg" alt="《极客时间-左耳听风》专栏，这里订阅有优惠"></p>
<hr>
<p>参考：</p>
<ul>
<li>极客时间-左耳听风-《高效学习》系列整理；</li>
</ul>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[Kafka Exactly-Once 之事务性实现]]></title>
      <url>http://matt33.com/2018/11/04/kafka-transaction/</url>
      <content type="html"><![CDATA[<p>这篇文章是 Kafka Exactly-Once 实现系列的第二篇，主要讲述 Kafka 事务性的实现，这部分的实现要比幂等性的实现复杂一些，幂等性实现是事务性实现的基础，幂等性提供了单会话单 Partition Exactly-Once 语义的实现，正是因为 Idempotent Producer 不提供跨多个 Partition 和跨会话场景下的保证，因此，我们是需要一种更强的事务保证，能够原子处理多个 Partition 的写入操作，数据要么全部写入成功，要么全部失败，不期望出现中间状态。这就是 Kafka Transactions 希望解决的问题，简单来说就是能够实现 <code>atomic writes across partitions</code>，本文以 Apache Kafka 2.0.0 代码实现为例，深入分析一下 Kafka 是如何实现这一机制的。</p>
<p>Apache Kafka 在 Exactly-Once Semantics（EOS）上三种粒度的保证如下（来自 <a href="https://www.slideshare.net/ConfluentInc/exactlyonce-semantics-in-apache-kafka" target="_blank" rel="external">Exactly-once Semantics in Apache Kafka</a>）：</p>
<ol>
<li>Idempotent Producer：Exactly-once，in-order，delivery per partition；</li>
<li>Transactions：Atomic writes across partitions；</li>
<li>Exactly-Once stream processing across read-process-write tasks；</li>
</ol>
<p>第二种情况就是本文讲述的主要内容，在讲述整个事务处理流程时，也顺便分析第三种情况。</p>
<h2 id="Kafka-Transactions"><a href="#Kafka-Transactions" class="headerlink" title="Kafka Transactions"></a>Kafka Transactions</h2><p>Kafka 事务性最开始的出发点是为了在 Kafka Streams 中实现 Exactly-Once 语义的数据处理，这个问题提出之后，在真正的方案讨论阶段，社区又挖掘了更多的应用场景，也为了尽可能覆盖更多的应用场景，在真正的实现中，在很多地方做了相应的 tradeoffs，后面会写篇文章对比一下 RocketMQ 事务性的实现，就能明白 Kafka 事务性实现及应用场景的复杂性了。</p>
<p>Kafka 的事务处理，主要是允许应用可以把消费和生产的 batch 处理（涉及多个 Partition）在一个原子单元内完成，操作要么全部完成、要么全部失败。为了实现这种机制，我们需要应用能提供一个唯一 id，即使故障恢复后也不会改变，这个 id 就是 TransactionnalId（也叫 txn.id，后面会详细讲述），txn.id 可以跟内部的 PID 1:1 分配，它们不同的是 txn.id 是用户提供的，而 PID 是 Producer 内部自动生成的（并且故障恢复后这个 PID 会变化），有了 txn.id 这个机制，就可以实现多 partition、跨会话的 EOS 语义。</p>
<p>当用户使用 Kafka 的事务性时，Kafka 可以做到的保证：</p>
<ol>
<li>跨会话的幂等性写入：即使中间故障，恢复后依然可以保持幂等性；</li>
<li>跨会话的事务恢复：如果一个应用实例挂了，启动的下一个实例依然可以保证上一个事务完成（commit 或者 abort）；</li>
<li>跨多个 Topic-Partition 的幂等性写入，Kafka 可以保证跨多个 Topic-Partition 的数据要么全部写入成功，要么全部失败，不会出现中间状态。</li>
</ol>
<p>上面是从 Producer 的角度来看，那么如果从 Consumer 角度呢？Consumer 端很难保证一个已经 commit 的事务的所有 msg 都会被消费，有以下几个原因：</p>
<ol>
<li>对于 compacted topic，在一个事务中写入的数据可能会被新的值覆盖；</li>
<li>一个事务内的数据，可能会跨多个 log segment，如果旧的 segmeng 数据由于过期而被清除，那么这个事务的一部分数据就无法被消费到了；</li>
<li>Consumer 在消费时可以通过 seek 机制，随机从一个位置开始消费，这也会导致一个事务内的部分数据无法消费；</li>
<li>Consumer 可能没有订阅这个事务涉及的全部 Partition。</li>
</ol>
<p>简单总结一下，关于 Kafka 事务性语义提供的保证主要以下三个：</p>
<ol>
<li>Atomic writes across multiple partitions.</li>
<li>All messages in a transaction are made visible together, or none are.</li>
<li>Consumers must be configured to skip uncommitted messages.</li>
</ol>
<h2 id="事务性示例"><a href="#事务性示例" class="headerlink" title="事务性示例"></a>事务性示例</h2><p>Kafka 事务性的使用方法也非常简单，用户只需要在 Producer 的配置中配置 <code>transactional.id</code>，通过 <code>initTransactions()</code> 初始化事务状态信息，再通过 <code>beginTransaction()</code> 标识一个事务的开始，然后通过 <code>commitTransaction()</code> 或 <code>abortTransaction()</code> 对事务进行 commit 或 abort，示例如下所示：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div></pre></td><td class="code"><pre><div class="line">Properties props = <span class="keyword">new</span> Properties();</div><div class="line">props.put(<span class="string">"key.serializer"</span>, <span class="string">"org.apache.kafka.common.serialization.StringSerializer"</span>);</div><div class="line">props.put(<span class="string">"value.serializer"</span>, <span class="string">"org.apache.kafka.common.serialization.StringSerializer"</span>);</div><div class="line">props.put(<span class="string">"client.id"</span>, <span class="string">"ProducerTranscationnalExample"</span>);</div><div class="line">props.put(<span class="string">"bootstrap.servers"</span>, <span class="string">"localhost:9092"</span>);</div><div class="line">props.put(<span class="string">"transactional.id"</span>, <span class="string">"test-transactional"</span>);</div><div class="line">props.put(<span class="string">"acks"</span>, <span class="string">"all"</span>);</div><div class="line">KafkaProducer producer = <span class="keyword">new</span> KafkaProducer(props);</div><div class="line">producer.initTransactions();</div><div class="line"></div><div class="line"><span class="keyword">try</span> &#123;</div><div class="line">    String msg = <span class="string">"matt test"</span>;</div><div class="line">    producer.beginTransaction();</div><div class="line">    producer.send(<span class="keyword">new</span> ProducerRecord(topic, <span class="string">"0"</span>, msg.toString()));</div><div class="line">    producer.send(<span class="keyword">new</span> ProducerRecord(topic, <span class="string">"1"</span>, msg.toString()));</div><div class="line">    producer.send(<span class="keyword">new</span> ProducerRecord(topic, <span class="string">"2"</span>, msg.toString()));</div><div class="line">    producer.commitTransaction();</div><div class="line">&#125; <span class="keyword">catch</span> (ProducerFencedException e1) &#123;</div><div class="line">    e1.printStackTrace();</div><div class="line">    producer.close();</div><div class="line">&#125; <span class="keyword">catch</span> (KafkaException e2) &#123;</div><div class="line">    e2.printStackTrace();</div><div class="line">    producer.abortTransaction();</div><div class="line">&#125;</div><div class="line">producer.close();</div></pre></td></tr></table></figure>
<p>事务性的 API 也同样保持了 Kafka 一直以来的简洁性，使用起来是非常方便的。</p>
<h2 id="事务性要解决的问题"><a href="#事务性要解决的问题" class="headerlink" title="事务性要解决的问题"></a>事务性要解决的问题</h2><p>回想一下，前面一篇文章中关于幂等性要解决的问题（<a href="http://matt33.com/2018/10/24/kafka-idempotent/#%E5%B9%82%E7%AD%89%E6%80%A7%E8%A6%81%E8%A7%A3%E5%86%B3%E7%9A%84%E9%97%AE%E9%A2%98">幂等性要解决的问题</a>），事务性其实更多的是解决幂等性中没有解决的问题，比如：</p>
<ol>
<li>在写多个 Topic-Partition 时，执行的一批写入操作，有可能出现部分 Topic-Partition 写入成功，部分写入失败（比如达到重试次数），这相当于出现了中间的状态，这并不是我们期望的结果；</li>
<li>Producer 应用中间挂之后再恢复，无法做到 Exactly-Once 语义保证；</li>
</ol>
<p>再来分析一下，Kafka 提供的事务性是如何解决上面两个问题的：</p>
<ol>
<li>如果启用事务性的话，涉及到多个 Topic-Partition 的写入时，这个事务操作要么会全部成功，要么会全部失败，不会出现上面的情况（部分成功、部分失败），如果有 Topic-Partition 无法写入，那么当前这个事务操作会直接 abort；</li>
<li>其实应用做到端到端的 Exactly-Once，仅仅靠 Kafka 是无法做到的，还需要应用本身做相应的容错设计，以 Flink 为例，其容错设计就是 checkpoint 机制，作业保证在每次 checkpoint 成功时，它之前的处理都是 Exactly-Once 的，如果中间作业出现了故障，恢复之后，只需要接着上次 checkpoint 的记录做恢复即可，对于失败前那个未完成的事务执行回滚操作（abort）就可以了，这样的话就是实现了 Flink + Kafka 端到端的 Exactly-Once（这只是设计的思想，具体的实现后续会有文章详细解揭秘）。</li>
</ol>
<h2 id="事务性实现的关键"><a href="#事务性实现的关键" class="headerlink" title="事务性实现的关键"></a>事务性实现的关键</h2><p>对于 Kafka 的事务性实现，最关键的就是其事务操作原子性的实现。对于一个事务操作而言，其会涉及到多个 Topic-Partition 数据的写入，如果是一个 long transaction 操作，可能会涉及到非常多的数据，如何才能保证这个事务操作的原子性（要么全部完成，要么全部失败）呢？</p>
<ol>
<li>关于这点，最容易想到的应该是引用 2PC 协议（它主要是解决分布式系统数据一致性的问题）中协调者的角色，它的作用是统计所有参与者的投票结果，如果大家一致认为可以 commit，那么就执行 commit，否则执行 abort：<ul>
<li>我们来想一下，Kafka 是不是也可以引入一个类似的角色来管理事务的状态，只有当 Producer 真正 commit 时，事务才会提交，否则事务会还在进行中（实际的实现中还需要考虑 timeout 的情况），不会处于完成状态；</li>
<li>Producer 在开始一个事务时，告诉【协调者】事务开始，然后开始向多个 Topic-Partition 写数据，只有这批数据全部写完（中间没有出现异常），Producer 会调用 commit 接口进行 commit，然后事务真正提交，否则如果中间出现异常，那么事务将会被 abort（Producer 通过 abort 接口告诉【协调者】执行 abort 操作）；</li>
<li>这里的协调者与 2PC 中的协调者略有不同，主要为了管理事务相关的状态信息，这就是 Kafka Server 端的 <strong>TransactionCoordinator</strong> 角色；</li>
</ul>
</li>
<li>有了上面的机制，是不是就可以了？很容易想到的问题就是 TransactionCoordinator 挂的话怎么办？TransactionCoordinator 如何实现高可用？<ul>
<li>TransactionCoordinator 需要管理事务的状态信息，如果一个事务的 TransactionCoordinator 挂的话，需要转移到其他的机器上，这里关键是在 <strong>事务状态信息如何恢复？</strong> 也就是事务的状态信息需要<strong>很强的容错性、一致性</strong>；</li>
<li>关于数据的强容错性、一致性，存储的容错性方案基本就是多副本机制，而对于一致性，就有很多的机制实现，其实这个在 Kafka 内部已经实现（不考虑数据重复问题），那就是 <code>min.isr + ack</code> 机制；</li>
<li>分析到这里，对于 Kafka 熟悉的同学应该就知道，这个是不是跟 <code>__consumer_offset</code> 这个内部的 topic 很像，TransactionCoordinator 也跟 GroupCoordinator 类似，而对应事务数据（transaction log）就是 <code>__transaction_state</code> 这个内部 topic，所有事务状态信息都会持久化到这个 topic，TransactionCoordinator 在做故障恢复也是从这个 topic 中恢复数据；</li>
</ul>
</li>
<li>有了上面的机制，就够了么？我们再来考虑一种情况，我们期望一个 Producer 在 Fail 恢复后能主动 abort 上次未完成的事务（接上之前未完成的事务），然后重新开始一个事务，这种情况应该怎么办？之前幂等性引入的 PID 是无法解决这个问题的，因为每次 Producer 在重启时，PID 都会更新为一个新值：<ul>
<li>Kafka 在 Producer 端引入了一个 <strong>TransactionalId</strong> 来解决这个问题，这个 txn.id 是由应用来配置的；</li>
<li>TransactionalId 的引入还有一个好处，就是跟 consumer group 类似，它可以用来标识一个事务操作，便于这个事务的所有操作都能在一个地方（同一个 TransactionCoordinator）进行处理；</li>
</ul>
</li>
<li>再来考虑一个问题，在具体的实现时，我们应该如何标识一个事务操作的开始、进行、完成的状态？正常来说，一个事务操作是由很多操作组成的一个操作单元，对于 TransactionCoordinator 而言，是需要准确知道当前的事务操作处于哪个阶段，这样在容错恢复时，新选举的 TransactionCoordinator 才能恢复之前的状态：<ul>
<li>这个就是<strong>事务状态转移</strong>，一个事务从开始，都会有一个相应的状态标识，直到事务完成，有了事务的状态转移关系之后，TransactionCoordinator 对于事务的管理就会简单很多，TransactionCoordinator 会将当前事务的状态信息都会缓存起来，每当事务需要进行转移，就更新缓存中事务的状态（前提是这个状态转移是有效的）。</li>
</ul>
</li>
</ol>
<blockquote>
<p>上面的分析都是个人见解，有问题欢迎指正~</p>
</blockquote>
<p>下面这节就讲述一下事务性实现的一些关键的实现机制（对这些细节不太感兴趣或者之前没有深入接触过 Kafka，可以直接跳过，直接去看下一节的事务流程处理，先去了解一下一个事务操作的主要流程步骤）。</p>
<h3 id="TransactionCoordinator"><a href="#TransactionCoordinator" class="headerlink" title="TransactionCoordinator"></a>TransactionCoordinator</h3><p>TransactionCoordinator 与 GroupCoordinator 有一些相似之处，它主要是处理来自 Transactional Producer 的一些与事务相关的请求，涉及的请求如下表所示（关于这些请求处理的详细过程会在下篇文章详细讲述，这里先有个大概的认识即可）：</p>
<table>
<thead>
<tr>
<th>请求类型</th>
<th>用途说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>ApiKeys.FIND_COORDINATOR</td>
<td>Transaction Producer 会发送这个 FindCoordinatorRequest 请求，来查询当前事务（txn.id）对应的 TransactionCoordinator，这个与 GroupCoordinator 查询类似，是根据 txn.id 的 hash 值取模找到对应 Partition 的 leader，这个 leader 就是该事务对应的 TransactionCoordinator</td>
</tr>
<tr>
<td>ApiKeys.INIT_PRODUCER_ID</td>
<td>Producer 初始化时，会发送一个 InitProducerIdRequest 请求，来获取其分配的 PID 信息，对于幂等性的 Producer，会随机选择一台 broker 发送请求，而对于 Transaction Producer 会选择向其对应的 TransactionCoordinator 发送该请求（目的是为了根据 txn.id 对应的事务状态做一些判断）</td>
</tr>
<tr>
<td>ApiKeys.ADD_PARTITIONS_TO_TXN</td>
<td>将这个事务涉及到的 topic-partition 列表添加到事务的 meta 信息中（通过 AddPartitionsToTxnRequest 请求），事务 meta 信息需要知道当前的事务操作涉及到了哪些 Topic-Partition 的写入</td>
</tr>
<tr>
<td>ApiKeys.ADD_OFFSETS_TO_TXN</td>
<td>Transaction Producer 的这个 AddOffsetsToTxnRequest 请求是由 <code>sendOffsetsToTransaction()</code> 接口触发的，它主要是用在 consume-process-produce 的场景中，这时候 consumer 也是整个事务的一部分，只有这个事务 commit 时，offset 才会被真正 commit（主要还是用于 Failover）</td>
</tr>
<tr>
<td>ApiKeys.END_TXN</td>
<td>当提交事务时， Transaction Producer 会向 TransactionCoordinator 发送一个 EndTxnRequest 请求，来 commit 或者 abort 事务</td>
</tr>
</tbody>
</table>
<p>TransactionCoordinator 对象中还有两个关键的对象，分别是:</p>
<ol>
<li>TransactionStateManager：这个对象，从名字应该就能大概明白其作用是关于事务的状态管理，它会维护分配到这个 TransactionCoordinator 的所有事务的 meta 信息；</li>
<li>TransactionMarkerChannelManager：这个主要是用于向其他的 Broker 发送 Transaction Marker 数据，关于 Transaction Marker，第一次接触的人，可能会有一些困惑，什么是 Transaction Marker，Transaction Marker 是用来解决什么问题的呢？这里先留一个疑问，后面会来解密。</li>
</ol>
<p>总结一下，TransactionCoordinator 主要的功能有三个，分别是：</p>
<ol>
<li>处理事务相关的请求；</li>
<li>维护事务的状态信息；</li>
<li>向其他 Broker 发送 Transaction Marker 数据。</li>
</ol>
<h3 id="Transaction-Log（-transaction-state）"><a href="#Transaction-Log（-transaction-state）" class="headerlink" title="Transaction Log（__transaction_state）"></a>Transaction Log（__transaction_state）</h3><p>在前面分析中，讨论过一个问题，那就是如果 TransactionCoordinator 故障的话应该怎么恢复？怎么恢复之前的状态？我们知道 Kafka 内部有一个事务 topic <code>__transaction_state</code>，一个事务应该由哪个 TransactionCoordinator 来处理，是根据其 txn.id 的 hash 值与 <code>__transaction_state</code> 的 partition 数取模得到，<code>__transaction_state</code> Partition 默认是50个，假设取模之后的结果是2，那么这个 txn.id 应该由 <code>__transaction_state</code> Partition 2 的 leader 来处理。</p>
<p>对于 <code>__transaction_state</code> 这个 topic 默认是由 Server 端的 <code>transaction.state.log.replication.factor</code> 参数来配置，默认是3，如果当前 leader 故障，需要进行 leader 切换，也就是对应的 TransactionCoordinator 需要迁移到新的 leader 上，迁移之后，如何恢复之前的事务状态信息呢？</p>
<p>正如 GroupCoordinator 的实现一样，TransactionCoordinator 的恢复也是通过 <code>__transaction_state</code> 中读取之前事务的日志信息，来恢复其状态信息，前提是要求事务日志写入做相应的不丢配置。这也是 <code>__transaction_state</code> 一个重要作用之一，用于 TransactionCoordinator 的恢复，<code>__transaction_state</code>  与 <code>__consumer_offsets</code> 一样是 compact 类型的 topic，其 scheme 如下：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line">Key =&gt; Version TransactionalId</div><div class="line">    Version =&gt; 0 (int16)</div><div class="line">    TransactionalId =&gt; String</div><div class="line"></div><div class="line">Value =&gt; Version ProducerId ProducerEpoch TxnTimeoutDuration TxnStatus [TxnPartitions] TxnEntryLastUpdateTime TxnStartTime</div><div class="line">    Version =&gt; 0 (int16)</div><div class="line">    ProducerId =&gt; int64</div><div class="line">    ProducerEpoch =&gt; int16</div><div class="line">    TxnTimeoutDuration =&gt; int32</div><div class="line">    TxnStatus =&gt; int8</div><div class="line">    TxnPartitions =&gt; [Topic [Partition]]</div><div class="line">        Topic =&gt; String</div><div class="line">        Partition =&gt; int32</div><div class="line">    TxnLastUpdateTime =&gt; int64</div><div class="line">    TxnStartTime =&gt; int64</div></pre></td></tr></table></figure>
<h3 id="Transaction-Marker"><a href="#Transaction-Marker" class="headerlink" title="Transaction Marker"></a>Transaction Marker</h3><p>终于讲到了 Transaction Marker，这也是前面留的一个疑问，什么是 Transaction Marker？Transaction Marker 是用来解决什么问题的呢？</p>
<p>Transaction Marker 也叫做 control messages，它的作用主要是告诉这个事务操作涉及的 Topic-Partition Set 的 leaders 当前的事务操作已经完成，可以执行 commit 或者 abort（Marker 主要的内容就是 commit 或 abort），这个 marker 数据由该事务的 TransactionCoordinator 来发送的。我们来假设一下：如果没有 Transaction Marker，一个事务在完成后，如何执行 commit 操作？（以这个事务涉及多个 Topic-Partition 写入为例）</p>
<ol>
<li>Transactional Producer 在进行 commit 时，需要先告诉 TransactionCoordinator 这个事务可以 commit 了（因为 TransactionCoordinator 记录这个事务对应的状态信息），然后再去告诉这些 Topic-Partition 的 leader 当前已经可以 commit，也就是 Transactional Producer 在执行 commit 时，至少需要做两步操作；</li>
<li><p>在 Transactional Producer 通知这些 Topic-Partition 的 leader 事务可以 commit 时，这些 Topic-Partition 应该怎么处理呢？难道是 commit 时再把数据持久化到磁盘，abort 时就直接丢弃不做持久化？这明显是问题的，如果这是一个 long transaction 操作，写数据非常多，内存中无法存下，数据肯定是需要持久化到硬盘的，如果数据已经持久化到硬盘了，假设这个时候收到了一个 abort 操作，是需要把数据再从硬盘清掉？</p>
<ul>
<li>这种方案有一个问题是：已经持久化的数据是持久化到本身的日志文件，还是其他文件？如果持久化本来的日志文件中，那么 consumer 消费到一个未 commit 的数据怎么办？这些数据是有可能 abort 的，如果是持久化到其他文件中，这会涉及到数据多次写磁盘、从磁盘清除的操作，会影响其 server 端的性能；</li>
</ul>
<p>再看下如果有了 Transaction Marker 这个机制后，情况会变成什么样？</p>
<ol>
<li>首先 Transactional Producer 只需要告诉 TransactionCoordinator 当前事务可以 commit，然后再由 TransactionCoordinator 来向其涉及到的 Topic-Partition 的 leader 发送 Transaction Marker 数据，这里减轻了 Client 的压力，而且 TransactionCoordinator 会做一些优化，如果这个目标 Broker 涉及到多个事务操作，是可以共享这个 TCP 连接的；</li>
<li>有了 Transaction Marker 之后，Producer 在持久化数据时就简单很多，写入的数据跟之前一样，按照条件持久化到硬盘（数据会有一个标识，标识这条或这批数据是不是事务写入的数据），当收到 Transaction Marker 时，把这个 Transaction Marker 数据也直接写入这个 Partition 中，这样在处理 Consumer 消费时，就可以根据 marker 信息做相应的处理。</li>
</ol>
</li>
</ol>
<p>Transaction Marker 的数据格式如下，其中 ControlMessageType 为 0 代表是 COMMIT，为 1 代表是 ABORT：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">ControlMessageKey =&gt; Version ControlMessageType</div><div class="line">    Version =&gt; int16</div><div class="line">    ControlMessageType =&gt; int16</div><div class="line"></div><div class="line">TransactionControlMessageValue =&gt; Version CoordinatorEpoch</div><div class="line">    Version =&gt; int16</div><div class="line">    CoordinatorEpoch =&gt; int32</div></pre></td></tr></table></figure>
<p>这里再讲一个额外的内容，对于事务写入的数据，为了给消息添加一个标识（标识这条消息是不是来自事务写入的），<strong>数据格式（消息协议）发生了变化</strong>，这个改动主要是在 Attribute 字段，对于 MessageSet，Attribute 是16位，新的格式如下：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">| Unused (6-15) | Control (5) | Transactional (4) | Timestamp Type (3) | Compression Type (0-2) |</div></pre></td></tr></table></figure>
<p>对于 Message，也就是单条数据存储时（其中 Marker 数据都是单条存储的），在 Kafka 中，只有 MessageSet 才可以做压缩，所以 Message 就没必要设置压缩字段，其格式如下：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">| Unused (1-7) | Control Flag(0) |</div></pre></td></tr></table></figure>
<h3 id="Server-端事务状态管理"><a href="#Server-端事务状态管理" class="headerlink" title="Server 端事务状态管理"></a>Server 端事务状态管理</h3><p>TransactionCoordinator 会维护相应的事务的状态信息（也就是 TxnStatus），对于一个事务，总共有以下几种状态：</p>
<table>
<thead>
<tr>
<th>状态</th>
<th>状态码</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>Empty</td>
<td>0</td>
<td>Transaction has not existed yet</td>
</tr>
<tr>
<td>Ongoing</td>
<td>1</td>
<td>Transaction has started and ongoing</td>
</tr>
<tr>
<td>PrepareCommit</td>
<td>2</td>
<td>Group is preparing to commit</td>
</tr>
<tr>
<td>PrepareAbort</td>
<td>3</td>
<td>Group is preparing to abort</td>
</tr>
<tr>
<td>CompleteCommit</td>
<td>4</td>
<td>Group has completed commit</td>
</tr>
<tr>
<td>CompleteAbort</td>
<td>5</td>
<td>Group has completed abort</td>
</tr>
<tr>
<td>Dead</td>
<td>6</td>
<td>TransactionalId has expired and is about to be removed from the transaction cache</td>
</tr>
<tr>
<td>PrepareEpochFence</td>
<td>7</td>
<td>We are in the middle of bumping the epoch and fencing out older producers</td>
</tr>
</tbody>
</table>
<p>其相应有效的状态转移图如下：</p>
<p><img src="/images/kafka/server-txn.png" alt="Server 端 Transaction 的状态转移图"></p>
<p>正常情况下，对于一个事务而言，其状态状态流程应该是 Empty –&gt; Ongoing –&gt; PrepareCommit –&gt; CompleteCommit –&gt; Empty 或者是 Empty –&gt; Ongoing –&gt; PrepareAbort –&gt; CompleteAbort –&gt; Empty。</p>
<h3 id="Client-端事务状态管理"><a href="#Client-端事务状态管理" class="headerlink" title="Client 端事务状态管理"></a>Client 端事务状态管理</h3><p>Client 的事务状态信息主要记录本地事务的状态，当然跟其他的系统类似，本地的状态信息与 Server 端的状态信息并不完全一致（状态的设置，就像 GroupCoodinator 会维护一个 Group 的状态，每个 Consumer 也会维护本地的 Consumer 对象的状态一样）。Client 端的事务状态信息主要用于 Client 端的事务状态处理，其主要有以下几种：</p>
<ol>
<li>UNINITIALIZED：Transactional Producer 初始化时的状态，此时还没有事务处理；</li>
<li>INITIALIZING：Transactional Producer 调用 <code>initTransactions()</code> 方法初始化事务相关的内容，比如发送 InitProducerIdRequest 请求；</li>
<li>READY：对于新建的事务，Transactional Producer 收到来自 TransactionCoordinator 的 InitProducerIdResponse 后，其状态会置为 READY（对于已有的事务而言，是当前事务完成后 Client 的状态会转移为 READY）；</li>
<li>IN_TRANSACTION：Transactional Producer 调用 <code>beginTransaction()</code> 方法，开始一个事务，标志着一个事务开始初始化；</li>
<li>COMMITTING_TRANSACTION：Transactional Producer 调用 <code>commitTransaction()</code> 方法时，会先更新本地的状态信息；</li>
<li>ABORTING_TRANSACTION：Transactional Producer 调用 <code>abortTransaction()</code> 方法时，会先更新本地的状态信息；</li>
<li>ABORTABLE_ERROR：在一个事务操作中，如果有数据发送失败，本地状态会转移到这个状态，之后再自动 abort 事务；</li>
<li>FATAL_ERROR：转移到这个状态之后，再进行状态转移时，会抛出异常；</li>
</ol>
<p>Client 端状态如下图：</p>
<p><img src="/images/kafka/client-txn.png" alt="Client 端 Transaction 的状态转移图"></p>
<h2 id="事务性的整体流程"><a href="#事务性的整体流程" class="headerlink" title="事务性的整体流程"></a>事务性的整体流程</h2><p>有了前面对 Kafka 事务性关键实现的讲述之后，这里详细讲述一个事务操作的处理流程，当然这里只是重点讲述事务性相关的内容，官方版的流程图可参考<a href="https://cwiki.apache.org/confluence/display/KAFKA/KIP-98+-+Exactly+Once+Delivery+and+Transactional+Messaging#KIP-98-ExactlyOnceDeliveryandTransactionalMessaging-DataFlow" target="_blank" rel="external">Kafka Exactly-Once Data Flow</a>，这里我做了一些改动，其流程图如下：</p>
<p><img src="/images/kafka/txn-data-flow.png" alt="consume-process-produce 事务的处理流程"></p>
<p>这个流程是以 consume-process-produce 场景为例（主要是 kafka streams 的场景），图中红虚框及 4.3a 部分是关于 consumer 的操作，去掉这部分的话，就是只考虑写入情况的场景。这种只考虑写入场景的事务操作目前在业内应用也是非常广泛的，比如 Flink + Kafka 端到端的 Exactly-Once 实现就是这种场景，下面来详细讲述一下整个流程。</p>
<h3 id="1-Finding-a-TransactionCoordinator"><a href="#1-Finding-a-TransactionCoordinator" class="headerlink" title="1. Finding a TransactionCoordinator"></a>1. Finding a TransactionCoordinator</h3><p>对于事务性的处理，第一步首先需要做的就是找到这个事务 txn.id 对应的 TransactionCoordinator，Transaction Producer 会向 Broker （随机选择一台 broker，一般选择本地连接最少的这台 broker）发送 FindCoordinatorRequest 请求，获取其 TransactionCoordinator。</p>
<p>怎么找到对应的 TransactionCoordinator 呢？这个前面已经讲过了，主要是通过下面的方法获取 <code>__transaction_state</code> 的 Partition，该 Partition 对应的 leader 就是这个 txn.id 对应的 TransactionCoordinator。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">partitionFor</span></span>(transactionalId: <span class="type">String</span>): <span class="type">Int</span> = <span class="type">Utils</span>.abs(transactionalId.hashCode) % transactionTopicPartitionCount</div></pre></td></tr></table></figure>
<h3 id="2-Getting-a-PID"><a href="#2-Getting-a-PID" class="headerlink" title="2. Getting a PID"></a>2. Getting a PID</h3><p>PID 这里就不再介绍了，不了解的可以看前面那篇文章（<a href="http://matt33.com/2018/10/24/kafka-idempotent/#PID">Producer ID</a>）。</p>
<p>Transaction Producer 在 <code>initializeTransactions()</code> 方法中会向 TransactionCoordinator 发送 InitPidRequest 请求获取其分配的 PID，有了 PID，事务写入时可以保证幂等性，PID 如何分配可以参考 <a href="http://matt33.com/2018/10/24/kafka-idempotent/#Producer-PID-%E7%94%B3%E8%AF%B7">PID 分配</a>，但是 TransactionCoordinator 在给事务 Producer 分配 PID 会做一些判断，主要的内容是：</p>
<ol>
<li>如果这个 txn.id 之前没有相应的事务状态（new txn.id），那么会初始化其事务 meta 信息 TransactionMetadata（会给其分配一个 PID，初始的 epoch 为-1），如果有事务状态，获取之前的状态；</li>
<li>校验其 TransactionMetadata 的状态信息（参考下面代码中 <code>prepareInitProduceIdTransit()</code> 方法）：<ol>
<li>如果前面还有状态转移正在进行，直接返回 CONCURRENT_TRANSACTIONS 异常；</li>
<li>如果此时的状态为 PrepareAbort 或 PrepareCommit，返回 CONCURRENT_TRANSACTIONS 异常；</li>
<li>如果之前的状态为 CompleteAbort、CompleteCommit 或 Empty，那么先将状态转移为 Empty，然后更新一下 epoch 值；</li>
<li>如果之前的状态为 Ongoing，状态会转移成 PrepareEpochFence，然后再 abort 当前的事务，并向 client 返回 CONCURRENT_TRANSACTIONS 异常；</li>
<li>如果状态为 Dead 或 PrepareEpochFence，直接抛出相应的 FATAL 异常；</li>
</ol>
</li>
<li>将 txn.id 与相应的 TransactionMetadata 持久化到事务日志中，对于 new txn.id，这个持久化的数据主要时 txn.id 与 pid 关系信息，如图中的 3a 所示。</li>
</ol>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//note: producer 启用事务性的情况下，检测此时事务的状态信息</span></div><div class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">prepareInitProduceIdTransit</span></span>(transactionalId: <span class="type">String</span>,</div><div class="line">                                        transactionTimeoutMs: <span class="type">Int</span>,</div><div class="line">                                        coordinatorEpoch: <span class="type">Int</span>,</div><div class="line">                                        txnMetadata: <span class="type">TransactionMetadata</span>): <span class="type">ApiResult</span>[(<span class="type">Int</span>, <span class="type">TxnTransitMetadata</span>)] = &#123;</div><div class="line">  <span class="keyword">if</span> (txnMetadata.pendingTransitionInProgress) &#123;</div><div class="line">    <span class="comment">// return a retriable exception to let the client backoff and retry</span></div><div class="line">    <span class="type">Left</span>(<span class="type">Errors</span>.<span class="type">CONCURRENT_TRANSACTIONS</span>)</div><div class="line">  &#125; <span class="keyword">else</span> &#123;</div><div class="line">    <span class="comment">// caller should have synchronized on txnMetadata already</span></div><div class="line">    txnMetadata.state <span class="keyword">match</span> &#123;</div><div class="line">      <span class="keyword">case</span> <span class="type">PrepareAbort</span> | <span class="type">PrepareCommit</span> =&gt;</div><div class="line">        <span class="comment">// reply to client and let it backoff and retry</span></div><div class="line">        <span class="type">Left</span>(<span class="type">Errors</span>.<span class="type">CONCURRENT_TRANSACTIONS</span>)</div><div class="line"></div><div class="line">      <span class="keyword">case</span> <span class="type">CompleteAbort</span> | <span class="type">CompleteCommit</span> | <span class="type">Empty</span> =&gt; <span class="comment">//note: 此时需要将状态转移到 Empty（此时状态并没有转移，只是在 PendingState 记录了将要转移的状态）</span></div><div class="line">        <span class="keyword">val</span> transitMetadata = <span class="keyword">if</span> (txnMetadata.isProducerEpochExhausted) &#123;</div><div class="line">          <span class="keyword">val</span> newProducerId = producerIdManager.generateProducerId()</div><div class="line">          txnMetadata.prepareProducerIdRotation(newProducerId, transactionTimeoutMs, time.milliseconds())</div><div class="line">        &#125; <span class="keyword">else</span> &#123; <span class="comment">//note: 增加 producer 的 epoch 值</span></div><div class="line">          txnMetadata.prepareIncrementProducerEpoch(transactionTimeoutMs, time.milliseconds())</div><div class="line">        &#125;</div><div class="line"></div><div class="line">        <span class="type">Right</span>(coordinatorEpoch, transitMetadata)</div><div class="line"></div><div class="line">      <span class="keyword">case</span> <span class="type">Ongoing</span> =&gt; <span class="comment">//note: abort 当前的事务，并返回一个 CONCURRENT_TRANSACTIONS 异常，强制 client 去重试</span></div><div class="line">        <span class="comment">// indicate to abort the current ongoing txn first. Note that this epoch is never returned to the</span></div><div class="line">        <span class="comment">// user. We will abort the ongoing transaction and return CONCURRENT_TRANSACTIONS to the client.</span></div><div class="line">        <span class="comment">// This forces the client to retry, which will ensure that the epoch is bumped a second time. In</span></div><div class="line">        <span class="comment">// particular, if fencing the current producer exhausts the available epochs for the current producerId,</span></div><div class="line">        <span class="comment">// then when the client retries, we will generate a new producerId.</span></div><div class="line">        <span class="type">Right</span>(coordinatorEpoch, txnMetadata.prepareFenceProducerEpoch())</div><div class="line"></div><div class="line">      <span class="keyword">case</span> <span class="type">Dead</span> | <span class="type">PrepareEpochFence</span> =&gt; <span class="comment">//note: 返回错误</span></div><div class="line">        <span class="keyword">val</span> errorMsg = <span class="string">s"Found transactionalId <span class="subst">$transactionalId</span> with state <span class="subst">$&#123;txnMetadata.state&#125;</span>. "</span> +</div><div class="line">          <span class="string">s"This is illegal as we should never have transitioned to this state."</span></div><div class="line">        fatal(errorMsg)</div><div class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">IllegalStateException</span>(errorMsg)</div><div class="line"></div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h3 id="3-Starting-a-Transaction"><a href="#3-Starting-a-Transaction" class="headerlink" title="3. Starting a Transaction"></a>3. Starting a Transaction</h3><p>前面两步都是 Transaction Producer 调用 <code>initTransactions()</code> 部分，到这里，Producer 可以调用 <code>beginTransaction()</code> 开始一个事务操作，其实现方法如下面所示：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//KafkaProducer</span></div><div class="line"><span class="comment">//note: 应该在一个事务操作之前进行调用</span></div><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">beginTransaction</span><span class="params">()</span> <span class="keyword">throws</span> ProducerFencedException </span>&#123;</div><div class="line">    throwIfNoTransactionManager();</div><div class="line">    transactionManager.beginTransaction();</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="comment">// TransactionManager</span></div><div class="line"><span class="comment">//note: 在一个事务开始之前进行调用，这里实际上只是转换了状态（只在 producer 本地记录了状态的开始）</span></div><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">synchronized</span> <span class="keyword">void</span> <span class="title">beginTransaction</span><span class="params">()</span> </span>&#123;</div><div class="line">    ensureTransactional();</div><div class="line">    maybeFailWithError();</div><div class="line">    transitionTo(State.IN_TRANSACTION);</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>这里只是将本地事务状态转移成 IN_TRANSACTION，并没有与 Server 端进行交互，所以在流程图中没有体现出来（TransactionManager 初始化时，其状态为 UNINITIALIZED，Producer 调用 <code>initializeTransactions()</code> 方法，其状态转移成 INITIALIZING）。</p>
<h3 id="4-Consume-Porcess-Produce-Loop"><a href="#4-Consume-Porcess-Produce-Loop" class="headerlink" title="4. Consume-Porcess-Produce Loop"></a>4. Consume-Porcess-Produce Loop</h3><p>在这个阶段，Transaction Producer 会做相应的处理，主要包括：从 consumer 拉取数据、对数据做相应的处理、通过 Producer 写入到下游系统中（对于只有写入场景，忽略前面那一步即可），下面有一个示例（start 和 end 中间的部分），是一个典型的 consume-process-produce 场景：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">while</span> (<span class="keyword">true</span>) &#123;</div><div class="line">    ConsumerRecords records = consumer.poll(Long.MAX_VALUE);</div><div class="line">    producer.beginTransaction();</div><div class="line">    <span class="comment">//start</span></div><div class="line">    <span class="keyword">for</span> (ConsumerRecord record : records)&#123;</div><div class="line">        producer.send(producerRecord(“outputTopic1”, record));</div><div class="line">        producer.send(producerRecord(“outputTopic2”, record));</div><div class="line">    &#125;</div><div class="line">    producer.sendOffsetsToTransaction(currentOffsets(consumer), group);</div><div class="line">    <span class="comment">//end</span></div><div class="line">    producer.commitTransaction();</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>下面来结合前面的流程图来讲述一下这部分的实现。</p>
<h4 id="4-1-AddPartitionsToTxnRequest"><a href="#4-1-AddPartitionsToTxnRequest" class="headerlink" title="4.1. AddPartitionsToTxnRequest"></a>4.1. AddPartitionsToTxnRequest</h4><p>Producer 在调用 <code>send()</code> 方法时，Producer 会将这个对应的 Topic—Partition 添加到 TransactionManager 的记录中，如下所示：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//note: 如何开启了幂等性或事务性，需要做一些处理</span></div><div class="line"><span class="keyword">if</span> (transactionManager != <span class="keyword">null</span> &amp;&amp; transactionManager.isTransactional())</div><div class="line">    transactionManager.maybeAddPartitionToTransaction(tp);</div></pre></td></tr></table></figure>
<p>如果这个 Topic-Partition 之前不存在，那么就添加到 newPartitionsInTransaction 集合中，如下所示：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//note: 将 tp 添加到 newPartitionsInTransaction 中，记录当前进行事务操作的 tp</span></div><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">synchronized</span> <span class="keyword">void</span> <span class="title">maybeAddPartitionToTransaction</span><span class="params">(TopicPartition topicPartition)</span> </span>&#123;</div><div class="line">    failIfNotReadyForSend();</div><div class="line"></div><div class="line">    <span class="comment">//note: 如果 partition 已经添加到 partitionsInTransaction、pendingPartitionsInTransaction、newPartitionsInTransaction中</span></div><div class="line">    <span class="keyword">if</span> (isPartitionAdded(topicPartition) || isPartitionPendingAdd(topicPartition))</div><div class="line">        <span class="keyword">return</span>;</div><div class="line"></div><div class="line">    log.debug(<span class="string">"Begin adding new partition &#123;&#125; to transaction"</span>, topicPartition);</div><div class="line">    newPartitionsInTransaction.add(topicPartition);</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>Producer 端的 Sender 线程会将这个信息通过 AddPartitionsToTxnRequest 请求发送给 TransactionCoordinator，也就是图中的 4.1 过程，TransactionCoordinator 会将这个 Topic-Partition 列表更新到 txn.id 对应的 TransactionMetadata 中，并且会持久化到事务日志中，也就是图中的 4.1 a 部分，这里持久化的数据主要是 txn.id 与其涉及到的 Topic-Partition 信息。</p>
<h4 id="4-2-ProduceRequest"><a href="#4-2-ProduceRequest" class="headerlink" title="4.2. ProduceRequest"></a>4.2. ProduceRequest</h4><p>这一步与正常 Producer 写入基本上一样，就是相应的 Leader 在持久化数据时会在头信息中标识这条数据是不是来自事务 Producer 的写入（主要是数据协议有变动，Server 处理并不需要做额外的处理）。</p>
<h4 id="4-3-AddOffsetsToTxnRequest"><a href="#4-3-AddOffsetsToTxnRequest" class="headerlink" title="4.3. AddOffsetsToTxnRequest"></a>4.3. AddOffsetsToTxnRequest</h4><p>Producer 在调用 <code>sendOffsetsToTransaction()</code> 方法时，第一步会首先向 TransactionCoordinator 发送相应的 AddOffsetsToTxnRequest 请求，如下所示：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//class KafkaProcducer</span></div><div class="line"><span class="comment">//note: 当你需要 batch 的消费-处理-写入消息，这个方法需要被使用</span></div><div class="line"><span class="comment">//note: 发送指定的 offset 给 group coordinator，用来标记这些 offset 是作为当前事务的一部分，只有这次事务成功时</span></div><div class="line"><span class="comment">//note: 这些 offset 才会被认为 commit 了</span></div><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">sendOffsetsToTransaction</span><span class="params">(Map&lt;TopicPartition, OffsetAndMetadata&gt; offsets,</span></span></div><div class="line">                                     String consumerGroupId) <span class="keyword">throws</span> ProducerFencedException &#123;</div><div class="line">    throwIfNoTransactionManager();</div><div class="line">    TransactionalRequestResult result = transactionManager.sendOffsetsToTransaction(offsets, consumerGroupId);</div><div class="line">    sender.wakeup();</div><div class="line">    result.await();</div><div class="line">&#125;</div><div class="line"></div><div class="line"></div><div class="line"><span class="comment">// class TransactionManager</span></div><div class="line"><span class="comment">//note: 发送 AddOffsetsToTxRequest</span></div><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">synchronized</span> TransactionalRequestResult <span class="title">sendOffsetsToTransaction</span><span class="params">(Map&lt;TopicPartition, OffsetAndMetadata&gt; offsets,</span></span></div><div class="line">                                                                        String consumerGroupId) &#123;</div><div class="line">    ensureTransactional();</div><div class="line">    maybeFailWithError();</div><div class="line">    <span class="keyword">if</span> (currentState != State.IN_TRANSACTION)</div><div class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> KafkaException(<span class="string">"Cannot send offsets to transaction either because the producer is not in an "</span> +</div><div class="line">                <span class="string">"active transaction"</span>);</div><div class="line"></div><div class="line">    log.debug(<span class="string">"Begin adding offsets &#123;&#125; for consumer group &#123;&#125; to transaction"</span>, offsets, consumerGroupId);</div><div class="line">    AddOffsetsToTxnRequest.Builder builder = <span class="keyword">new</span> AddOffsetsToTxnRequest.Builder(transactionalId,</div><div class="line">            producerIdAndEpoch.producerId, producerIdAndEpoch.epoch, consumerGroupId);</div><div class="line">    AddOffsetsToTxnHandler handler = <span class="keyword">new</span> AddOffsetsToTxnHandler(builder, offsets);</div><div class="line">    enqueueRequest(handler);</div><div class="line">    <span class="keyword">return</span> handler.result;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>TransactionCoordinator 在收到这个请求时，处理方法与 4.1 中的一样，把这个 group.id 对应的 <code>__consumer_offsets</code> 的 Partition （与写入涉及的 Topic-Partition 一样）保存到事务对应的 meta 中，之后会持久化相应的事务日志，如图中 4.3a 所示。</p>
<h4 id="4-4-TxnOffsetsCommitRequest"><a href="#4-4-TxnOffsetsCommitRequest" class="headerlink" title="4.4. TxnOffsetsCommitRequest"></a>4.4. TxnOffsetsCommitRequest</h4><p>Producer 在收到 TransactionCoordinator 关于 AddOffsetsToTxnRequest 请求的结果后，后再次发送 TxnOffsetsCommitRequest 请求给对应的 GroupCoordinator，AddOffsetsToTxnHandler 的 <code>handleResponse()</code> 的实现如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div></pre></td><td class="code"><pre><div class="line"><span class="meta">@Override</span></div><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">handleResponse</span><span class="params">(AbstractResponse response)</span> </span>&#123;</div><div class="line">    AddOffsetsToTxnResponse addOffsetsToTxnResponse = (AddOffsetsToTxnResponse) response;</div><div class="line">    Errors error = addOffsetsToTxnResponse.error();</div><div class="line"></div><div class="line">    <span class="keyword">if</span> (error == Errors.NONE) &#123;</div><div class="line">        log.debug(<span class="string">"Successfully added partition for consumer group &#123;&#125; to transaction"</span>, builder.consumerGroupId());</div><div class="line"></div><div class="line">        <span class="comment">// note the result is not completed until the TxnOffsetCommit returns</span></div><div class="line">        <span class="comment">//note: AddOffsetsToTnxRequest 之后，还会再发送 TxnOffsetCommitRequest</span></div><div class="line">        pendingRequests.add(txnOffsetCommitHandler(result, offsets, builder.consumerGroupId()));</div><div class="line">        transactionStarted = <span class="keyword">true</span>;</div><div class="line">    &#125; <span class="keyword">else</span> <span class="keyword">if</span> (error == Errors.COORDINATOR_NOT_AVAILABLE || error == Errors.NOT_COORDINATOR) &#123;</div><div class="line">        lookupCoordinator(FindCoordinatorRequest.CoordinatorType.TRANSACTION, transactionalId);</div><div class="line">        reenqueue();</div><div class="line">    &#125; <span class="keyword">else</span> <span class="keyword">if</span> (error == Errors.COORDINATOR_LOAD_IN_PROGRESS || error == Errors.CONCURRENT_TRANSACTIONS) &#123;</div><div class="line">        reenqueue();</div><div class="line">    &#125; <span class="keyword">else</span> <span class="keyword">if</span> (error == Errors.INVALID_PRODUCER_EPOCH) &#123;</div><div class="line">        fatalError(error.exception());</div><div class="line">    &#125; <span class="keyword">else</span> <span class="keyword">if</span> (error == Errors.TRANSACTIONAL_ID_AUTHORIZATION_FAILED) &#123;</div><div class="line">        fatalError(error.exception());</div><div class="line">    &#125; <span class="keyword">else</span> <span class="keyword">if</span> (error == Errors.GROUP_AUTHORIZATION_FAILED) &#123;</div><div class="line">        abortableError(<span class="keyword">new</span> GroupAuthorizationException(builder.consumerGroupId()));</div><div class="line">    &#125; <span class="keyword">else</span> &#123;</div><div class="line">        fatalError(<span class="keyword">new</span> KafkaException(<span class="string">"Unexpected error in AddOffsetsToTxnResponse: "</span> + error.message()));</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>GroupCoordinator 在收到相应的请求后，会将 offset 信息持久化到 consumer offsets log 中（包含对应的 PID 信息），但是<strong>不会更新到缓存</strong>中，除非这个事务 commit 了，这样的话就可以保证这个 offset 信息对 consumer 是不可见的（没有更新到缓存中的数据是不可见的，通过接口是获取的，这是 GroupCoordinator 本身来保证的）。</p>
<h3 id="5-Committing-or-Aborting-a-Transaction"><a href="#5-Committing-or-Aborting-a-Transaction" class="headerlink" title="5.Committing or Aborting a Transaction"></a>5.Committing or Aborting a Transaction</h3><p>在一个事务操作处理完成之后，Producer 需要调用 <code>commitTransaction()</code> 或者 <code>abortTransaction()</code> 方法来 commit 或者 abort 这个事务操作。</p>
<h4 id="5-1-EndTxnRequest"><a href="#5-1-EndTxnRequest" class="headerlink" title="5.1. EndTxnRequest"></a>5.1. EndTxnRequest</h4><p>无论是 Commit 还是 Abort，对于 Producer 而言，都是向 TransactionCoordinator 发送 EndTxnRequest 请求，这个请求的内容里会标识是 commit 操作还是 abort 操作，Producer 的 <code>commitTransaction()</code> 方法实现如下所示：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//class KafkaProducer</span></div><div class="line"><span class="comment">//note: commit 正在进行的事务操作，这个方法在真正发送 commit 之后将会 flush 所有未发送的数据</span></div><div class="line"><span class="comment">//note: 如果在发送中遇到任何一个不能修复的错误，这个方法抛出异常，事务也不会被提交，所有 send 必须成功，这个事务才能 commit 成功</span></div><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">commitTransaction</span><span class="params">()</span> <span class="keyword">throws</span> ProducerFencedException </span>&#123;</div><div class="line">    throwIfNoTransactionManager();</div><div class="line">    TransactionalRequestResult result = transactionManager.beginCommit();</div><div class="line">    sender.wakeup();</div><div class="line">    result.await();</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="comment">// class TransactionManager</span></div><div class="line"><span class="comment">//note: 开始 commit，转移本地本地保存的状态以及发送相应的请求</span></div><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">synchronized</span> TransactionalRequestResult <span class="title">beginCommit</span><span class="params">()</span> </span>&#123;</div><div class="line">    ensureTransactional();</div><div class="line">    maybeFailWithError();</div><div class="line">    transitionTo(State.COMMITTING_TRANSACTION);</div><div class="line">    <span class="keyword">return</span> beginCompletingTransaction(TransactionResult.COMMIT);</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>Producer 的 <code>abortTransaction()</code> 方法实现如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//class KafkaProducer</span></div><div class="line"><span class="comment">//note: 取消正在进行事务，任何没有 flush 的数据都会被丢弃</span></div><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">abortTransaction</span><span class="params">()</span> <span class="keyword">throws</span> ProducerFencedException </span>&#123;</div><div class="line">    throwIfNoTransactionManager();</div><div class="line">    TransactionalRequestResult result = transactionManager.beginAbort();</div><div class="line">    sender.wakeup();</div><div class="line">    result.await();</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="comment">// class TransactionManager</span></div><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">synchronized</span> TransactionalRequestResult <span class="title">beginAbort</span><span class="params">()</span> </span>&#123;</div><div class="line">    ensureTransactional();</div><div class="line">    <span class="keyword">if</span> (currentState != State.ABORTABLE_ERROR)</div><div class="line">        maybeFailWithError();</div><div class="line">    transitionTo(State.ABORTING_TRANSACTION);</div><div class="line"></div><div class="line">    <span class="comment">// We're aborting the transaction, so there should be no need to add new partitions</span></div><div class="line">    newPartitionsInTransaction.clear();</div><div class="line">    <span class="keyword">return</span> beginCompletingTransaction(TransactionResult.ABORT);</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>它们最终都是调用了 TransactionManager 的 <code>beginCompletingTransaction()</code> 方法，这个方法会向其 待发送请求列表 中添加 EndTxnRequest 请求，其实现如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//note: 发送 EndTxnRequest 请求，添加到 pending 队列中</span></div><div class="line"><span class="function"><span class="keyword">private</span> TransactionalRequestResult <span class="title">beginCompletingTransaction</span><span class="params">(TransactionResult transactionResult)</span> </span>&#123;</div><div class="line">    <span class="keyword">if</span> (!newPartitionsInTransaction.isEmpty())</div><div class="line">        enqueueRequest(addPartitionsToTransactionHandler());</div><div class="line">    EndTxnRequest.Builder builder = <span class="keyword">new</span> EndTxnRequest.Builder(transactionalId, producerIdAndEpoch.producerId,</div><div class="line">            producerIdAndEpoch.epoch, transactionResult);</div><div class="line">    EndTxnHandler handler = <span class="keyword">new</span> EndTxnHandler(builder);</div><div class="line">    enqueueRequest(handler);</div><div class="line">    <span class="keyword">return</span> handler.result;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>TransactionCoordinator 在收到 EndTxnRequest 请求后，会做以下处理：</p>
<ol>
<li>更新事务的 meta 信息，状态转移成 PREPARE_COMMIT 或 PREPARE_ABORT，并将事务状态信息持久化到事务日志中；</li>
<li>根据事务 meta 信息，向其涉及到的所有 Topic-Partition 的 leader 发送 Transaction Marker 信息（也就是 WriteTxnMarkerRquest 请求，见下面的 5.2 分析）；</li>
<li>最后将事务状态更新为 COMMIT 或者 ABORT，并将事务的 meta 持久化到事务日志中，也就是 5.3 步骤。</li>
</ol>
<h4 id="5-2-WriteTxnMarkerRquest"><a href="#5-2-WriteTxnMarkerRquest" class="headerlink" title="5.2. WriteTxnMarkerRquest"></a>5.2. WriteTxnMarkerRquest</h4><p>WriteTxnMarkerRquest 是 TransactionCoordinator 收到 Producer 的 EndTxnRequest 请求后向其他 Broker 发送的请求，主要是告诉它们事务已经完成。不论是普通的 Topic-Partition 还是 <code>__consumer_offsets</code>，在收到这个请求后，都会把事务结果（Transaction Marker 的格数据式见前面）持久化到对应的日志文件中，这样下游 Consumer 在消费这个数据时，就知道这个事务是 commit 还是 abort。</p>
<h4 id="5-3-Writing-the-Final-Commit-or-Abort-Message"><a href="#5-3-Writing-the-Final-Commit-or-Abort-Message" class="headerlink" title="5.3. Writing the Final Commit or Abort Message"></a>5.3. Writing the Final Commit or Abort Message</h4><p>当这个事务涉及到所有 Topic-Partition 都已经把这个 marker 信息持久化到日志文件之后，TransactionCoordinator 会将这个事务的状态置为 COMMIT 或 ABORT，并持久化到事务日志文件中，到这里，这个事务操作就算真正完成了，TransactionCoordinator 缓存的很多关于这个事务的数据可以被清除了。</p>
<h2 id="小思考"><a href="#小思考" class="headerlink" title="小思考"></a>小思考</h2><p>在上面讲述完 Kafka 事务性处理之后，我们来思考一下以下这些问题，上面的流程可能会出现下面这些问题或者很多人可能会有下面的疑问：</p>
<ol>
<li>txn.id 是否可以被多 Producer 使用，如果有多个 Producer 使用了这个 txn.id 会出现什么问题？</li>
<li>TransactionCoordinator Fencing 和 Producer Fencing 分别是什么，它们是用来解决什么问题的？</li>
<li>对于事务的数据，Consumer 端是如何消费的，一个事务可能会 commit，也可能会 abort，这个在 Consumer 端是如何体现的？</li>
<li>对于一个 Topic，如果既有事务数据写入又有其他 topic 数据写入，消费时，其顺序性时怎么保证的？</li>
<li>如果 txn.id 长期不使用，server 端怎么处理？</li>
<li>PID Snapshot 是做什么的？是用来解决什么问题？</li>
</ol>
<p>下面，来详细分析一下上面提到的这些问题。</p>
<h3 id="如果多个-Producer-使用同一个-txn-id-会出现什么情况？"><a href="#如果多个-Producer-使用同一个-txn-id-会出现什么情况？" class="headerlink" title="如果多个 Producer 使用同一个 txn.id 会出现什么情况？"></a>如果多个 Producer 使用同一个 txn.id 会出现什么情况？</h3><p>对于这个情况，我们这里直接做了一个相应的实验，两个 Producer 示例都使用了同一个 txn.id（为 test-transactional-matt），Producer 1 先启动，然后过一会再启动 Producer 2，这时候会发现一个现象，那就是 Producer 1 进程会抛出异常退出进程，其异常信息为：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">org.apache.kafka.common.KafkaException: Cannot execute transactional method because we are <span class="keyword">in</span> an error state</div><div class="line">	at org.apache.kafka.clients.producer.internals.TransactionManager.maybeFailWithError(TransactionManager.java:784)</div><div class="line">	at org.apache.kafka.clients.producer.internals.TransactionManager.beginTransaction(TransactionManager.java:215)</div><div class="line">	at org.apache.kafka.clients.producer.KafkaProducer.beginTransaction(KafkaProducer.java:606)</div><div class="line">	at com.matt.test.kafka.producer.ProducerTransactionExample.main(ProducerTransactionExample.java:68)</div><div class="line">Caused by: org.apache.kafka.common.errors.ProducerFencedException: Producer attempted an operation with an old epoch. Either there is a newer producer with the same transactionalId, or the producer<span class="string">'s transaction has been expired by the broker.</span></div></pre></td></tr></table></figure>
<p>这里抛出了 ProducerFencedException 异常，如果打开相应的 Debug 日志，在 Producer 1 的日志文件会看到下面的日志信息</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div></pre></td><td class="code"><pre><div class="line">[2018-11-03 12:48:52,495] DEBUG [Producer clientId=ProducerTransactionExample, transactionalId=<span class="built_in">test</span>-transactional-matt] Transition from state COMMITTING_TRANSACTION to error state FATAL_ERROR (org.apache.kafka.clients.producer.internals.TransactionManager)</div><div class="line">org.apache.kafka.common.errors.ProducerFencedException: Producer attempted an operation with an old epoch. Either there is a newer producer with the same transactionalId, or the producer<span class="string">'s transaction has been expired by the broker.</span></div><div class="line">[2018-11-03 12:48:52,498] ERROR [Producer clientId=ProducerTransactionExample, transactionalId=test-transactional-matt] Aborting producer batches due to fatal error (org.apache.kafka.clients.producer.internals.Sender)</div><div class="line">org.apache.kafka.common.errors.ProducerFencedException: Producer attempted an operation with an old epoch. Either there is a newer producer with the same transactionalId, or the producer's transaction has been expired by the broker.</div><div class="line">[2018-11-03 12:48:52,599] INFO [Producer clientId=ProducerTransactionExample, transactionalId=<span class="built_in">test</span>-transactional-matt] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms. (org.apache.kafka.clients.producer.KafkaProducer)</div><div class="line">[2018-11-03 12:48:52,599] DEBUG [Producer clientId=ProducerTransactionExample, transactionalId=<span class="built_in">test</span>-transactional-matt] Beginning shutdown of Kafka producer I/O thread, sending remaining records. (org.apache.kafka.clients.producer.internals.Sender)</div><div class="line">[2018-11-03 12:48:52,601] DEBUG Removed sensor with name connections-closed: (org.apache.kafka.common.metrics.Metrics)</div><div class="line">[2018-11-03 12:48:52,601] DEBUG Removed sensor with name connections-created: (org.apache.kafka.common.metrics.Metrics)</div><div class="line">[2018-11-03 12:48:52,602] DEBUG Removed sensor with name successful-authentication: (org.apache.kafka.common.metrics.Metrics)</div><div class="line">[2018-11-03 12:48:52,602] DEBUG Removed sensor with name failed-authentication: (org.apache.kafka.common.metrics.Metrics)</div><div class="line">[2018-11-03 12:48:52,602] DEBUG Removed sensor with name bytes-sent-received: (org.apache.kafka.common.metrics.Metrics)</div><div class="line">[2018-11-03 12:48:52,603] DEBUG Removed sensor with name bytes-sent: (org.apache.kafka.common.metrics.Metrics)</div><div class="line">[2018-11-03 12:48:52,603] DEBUG Removed sensor with name bytes-received: (org.apache.kafka.common.metrics.Metrics)</div><div class="line">[2018-11-03 12:48:52,604] DEBUG Removed sensor with name select-time: (org.apache.kafka.common.metrics.Metrics)</div><div class="line">[2018-11-03 12:48:52,604] DEBUG Removed sensor with name io-time: (org.apache.kafka.common.metrics.Metrics)</div><div class="line">[2018-11-03 12:48:52,604] DEBUG Removed sensor with name node--1.bytes-sent (org.apache.kafka.common.metrics.Metrics)</div><div class="line">[2018-11-03 12:48:52,605] DEBUG Removed sensor with name node--1.bytes-received (org.apache.kafka.common.metrics.Metrics)</div><div class="line">[2018-11-03 12:48:52,605] DEBUG Removed sensor with name node--1.latency (org.apache.kafka.common.metrics.Metrics)</div><div class="line">[2018-11-03 12:48:52,605] DEBUG Removed sensor with name node-33.bytes-sent (org.apache.kafka.common.metrics.Metrics)</div><div class="line">[2018-11-03 12:48:52,606] DEBUG Removed sensor with name node-33.bytes-received (org.apache.kafka.common.metrics.Metrics)</div><div class="line">[2018-11-03 12:48:52,606] DEBUG Removed sensor with name node-33.latency (org.apache.kafka.common.metrics.Metrics)</div><div class="line">[2018-11-03 12:48:52,606] DEBUG Removed sensor with name node-35.bytes-sent (org.apache.kafka.common.metrics.Metrics)</div><div class="line">[2018-11-03 12:48:52,606] DEBUG Removed sensor with name node-35.bytes-received (org.apache.kafka.common.metrics.Metrics)</div><div class="line">[2018-11-03 12:48:52,606] DEBUG Removed sensor with name node-35.latency (org.apache.kafka.common.metrics.Metrics)</div><div class="line">[2018-11-03 12:48:52,607] DEBUG [Producer clientId=ProducerTransactionExample, transactionalId=<span class="built_in">test</span>-transactional-matt] Shutdown of Kafka producer I/O thread has completed. (org.apache.kafka.clients.producer.internals.Sender)</div><div class="line">[2018-11-03 12:48:52,607] DEBUG [Producer clientId=ProducerTransactionExample, transactionalId=<span class="built_in">test</span>-transactional-matt] Kafka producer has been closed (org.apache.kafka.clients.producer.KafkaProducer)</div><div class="line">[2018-11-03 12:48:52,808] ERROR Forcing producer close! (com.matt.test.kafka.producer.ProducerTransactionExample)</div><div class="line">[2018-11-03 12:48:52,808] INFO [Producer clientId=ProducerTransactionExample, transactionalId=<span class="built_in">test</span>-transactional-matt] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms. (org.apache.kafka.clients.producer.KafkaProducer)</div><div class="line">[2018-11-03 12:48:52,808] DEBUG [Producer clientId=ProducerTransactionExample, transactionalId=<span class="built_in">test</span>-transactional-matt] Kafka producer has been closed (org.apache.kafka.clients.producer.KafkaProducer)</div></pre></td></tr></table></figure>
<p>Producer 1 本地事务状态从 COMMITTING_TRANSACTION 变成了 FATAL_ERROR 状态，导致 Producer 进程直接退出了，出现这个异常的原因，就是抛出的 ProducerFencedException 异常，简单来说 Producer 1 被 Fencing 了（这是 Producer Fencing 的情况）。因此，这个问题的答案就很清除了，如果多个 Producer 共用一个 txn.id，那么最后启动的 Producer 会成功运行，会它之前启动的 Producer 都 Fencing 掉（至于为什么会 Fencing 下一小节会做分析）。</p>
<h3 id="Fencing"><a href="#Fencing" class="headerlink" title="Fencing"></a>Fencing</h3><p>关于 Fencing 这个机制，在分布式系统还是很常见的，我第一个见到这个机制是在 HDFS 中，可以参考我之前总结的一篇文章 <a href="http://matt33.com/2018/07/15/hdfs-architecture-learn/#HDFS-%E8%84%91%E8%A3%82%E9%97%AE%E9%A2%98">HDFS NN 脑裂问题</a>，Fencing 机制解决的主要也是这种类型的问题 —— 脑裂问题，简单来说就是，本来系统这个组件在某个时刻应该只有一个处于 active 状态的，但是在实际生产环境中，特别是切换期间，可能会同时出现两个组件处于 active 状态，这就是脑裂问题，在 Kafka 的事务场景下，用到 Fencing 机制有两个地方：</p>
<ol>
<li>TransactionCoordinator Fencing；</li>
<li>Producer Fencing；</li>
</ol>
<h4 id="TransactionCoordinator-Fencing"><a href="#TransactionCoordinator-Fencing" class="headerlink" title="TransactionCoordinator Fencing"></a>TransactionCoordinator Fencing</h4><p>TransactionCoordinator 在遇到上 long FGC 时，可能会导致 脑裂 问题，FGC 时会 stop-the-world，这时候可能会与 zk 连接超时导致临时节点消失进而触发 leader 选举，如果 <code>__transaction_state</code> 发生了 leader 选举，TransactionCoordinator 就会切换，如果此时旧的 TransactionCoordinator FGC 完成，在还没来得及同步到最细 meta 之前，会有一个短暂的时刻，对于一个 txn.id 而言就是这个时刻可能出现了两个 TransactionCoordinator。</p>
<p>相应的解决方案就是 TransactionCoordinator Fencing，这里 Fencing 策略不像离线场景 HDFS 这种直接 Kill 旧的 NN 进程或者强制切换状态这么暴力，而是通过 CoordinatorEpoch 来判断，每个 TransactionCoordinator 都有其 CoordinatorEpoch 值，这个值就是对应 <code>__transaction_state</code> Partition 的 Epoch 值（每当 leader 切换一次，该值就会自增1）。</p>
<p>明白了 TransactionCoordinator 脑裂问题发生情况及解决方案之后，来分析下，Fencing 机制会在哪里发挥作用？仔细想想，是可以推断出来的，只可能是 TransactionCoordinator 向别人发请求时影响才会比较严重（特别是乱发 admin 命令）。有了 CoordinatorEpoch 之后，其他 Server 在收到请求时做相应的判断，如果发现 CoordinatorEpoch 值比缓存的最新的值小，那么 Fencing 就生效，拒绝这个请求，也就是 TransactionCoordinator 发送 WriteTxnMarkerRequest 时可能会触发这一机制。</p>
<h4 id="Producer-Fencing"><a href="#Producer-Fencing" class="headerlink" title="Producer Fencing"></a>Producer Fencing</h4><p>Producer Fencing 与前面的类似，如果对于相同 PID 和 txn.id 的 Producer，Server 端会记录最新的 Epoch 值，拒绝来自 zombie Producer （Epoch 值小的 Producer）的请求。前面第一个问题的情况，Producer 2 在启动时，会向 TransactionCoordinator 发送 InitPIDRequest 请求，此时 TransactionCoordinator 已经有了这个 txn.id 对应的 meta，会返回之前分配的 PID，并把 Epoch 自增 1 返回，这样 Producer 2 就被认为是最新的 Producer，而 Producer 1 就会被认为是 zombie Producer，因此，TransactionCoordinator 在处理 Producer 1 的事务请求时，会返回相应的异常信息。</p>
<h3 id="Consumer-端如何消费事务数据"><a href="#Consumer-端如何消费事务数据" class="headerlink" title="Consumer 端如何消费事务数据"></a>Consumer 端如何消费事务数据</h3><p>在讲述这个问题之前，需要先介绍一下事务场景下，Consumer 的消费策略，Consumer 有一个 <code>isolation.level</code> 配置，这个是配置对于事务性数据的消费策略，有以下两种可选配置：</p>
<ol>
<li><code>read_committed</code>: only consume non-­transactional messages or transactional messages that are already committed, in offset ordering.</li>
<li><code>read_uncommitted</code>: consume all available messages in offset ordering. This is the <strong>default value</strong>.</li>
</ol>
<p>简单来说就是，read_committed 只会读取 commit 的数据，而 abort 的数据不会向 consumer 显现，对于 read_uncommitted 这种模式，consumer 可以读取到所有数据（control msg 会过滤掉），这种模式与普通的消费机制基本没有区别，就是做了一个 check，过滤掉 control msg（也就是 marker 数据），这部分的难点在于 read_committed 机制的实现。</p>
<h4 id="Last-Stable-Offset（LSO）"><a href="#Last-Stable-Offset（LSO）" class="headerlink" title="Last Stable Offset（LSO）"></a>Last Stable Offset（LSO）</h4><p>在事务机制的实现中，Kafka 又设置了一个新的 offset 概念，那就是 Last Stable Offset，简称 LSO（其他的 Offset 概念可参考 <a href="http://matt33.com/2017/01/16/kafka-group/#offset-%E9%82%A3%E4%BA%9B%E4%BA%8B">Kafka Offset 那些事</a>），先看下 LSO 的定义：</p>
<blockquote>
<p>The LSO is defined as the latest offset such that the status of all transactional messages at lower offsets have been determined (i.e. committed or aborted).</p>
</blockquote>
<p>对于一个 Partition 而言，offset 小于 LSO 的数据，全都是已经确定的数据，这个主要是对于事务操作而言，在这个 offset 之前的事务操作都是已经完成的事务（已经 commit 或 abort），如果这个 Partition 没有涉及到事务数据，那么 LSO 就是其 HW（水位）。</p>
<h4 id="Server-处理-read-committed-类型的-Fetch-请求"><a href="#Server-处理-read-committed-类型的-Fetch-请求" class="headerlink" title="Server 处理 read_committed 类型的 Fetch 请求"></a>Server 处理 read_committed 类型的 Fetch 请求</h4><p>如果 Consumer 的消费策略设置的是 read_committed，其在向 Server 发送 Fetch 请求时，Server 端<strong>只会返回 LSO 之前的数据</strong>，在 LSO 之后的数据不会返回。</p>
<p>这种机制有没有什么问题呢？我现在能想到的就是如果有一个 long transaction，比如其 first offset 是 1000，另外有几个已经完成的小事务操作，比如：txn1（offset：1100~1200）、txn2（offset：1400~1500），假设此时的 LSO 是 1000，也就是说这个 long transaction 还没有完成，那么已经完成的 txn1、txn2 也会对 consumer 不可见（假设都是 commit 操作），此时<strong>受 long transaction 的影响可能会导致数据有延迟</strong>。</p>
<p>那么我们再来想一下，如果不设计 LSO，又会有什么问题呢？可能分两种情况：</p>
<ol>
<li>允许读未完成的事务：那么 Consumer 可以直接读取到 Partition 的 HW 位置，对于未完成的事务，因为设置的是 read_committed 机制，所以不能对用户可见，需要在 Consumer 端做缓存，这个缓存应该设置多大？（不限制肯定会出现 OOM 的情况，当然也可以现在 client 端持久化到硬盘，这样的设计太过于复杂，还需要考虑 client 端 IO、磁盘故障等风险），明显这种设计方案是不可行的；</li>
<li>如果不允许读未完成的事务：相当于还是在 Server 端处理，与前面的区别是，这里需要先把示例中的 txn1、txn2 的数据发送给 Consumer，这样的设计会带来什么问题呢？<ol>
<li>假设这个 long transaction commit 了，其 end offset 是 2000，这时候有两种方案：第一种是把 1000-2000 的数据全部读出来（可能是磁盘读），把这个 long transaction 的数据过滤出来返回给 Consumer；第二种是随机读，只读这个 long transaction 的数据，无论哪种都有多触发一次磁盘读的风险，可能影响影响 Server 端的性能；</li>
<li>Server 端需要维护每个 consumer group 有哪些事务读了、哪些事务没读的 meta 信息，因为 consumer 是随机可能挂掉，需要接上次消费的，这样实现就复杂很多了；</li>
<li>还有一个问题是，消费的顺序性无法保证，两次消费其读取到的数据顺序可能是不同的（两次消费启动时间不一样）；</li>
</ol>
</li>
</ol>
<p>从这些分析来看，个人认为 LSO 机制还是一种相当来说 实现起来比较简单、而且不影响原来 server 端性能、还能保证顺序性的一种设计方案，它不一定是最好的，但也不会差太多。在实际的生产场景中，尽量避免 long transaction 这种操作，而且 long transaction可能也会容易触发事务超时。</p>
<h4 id="Consumer-如何过滤-abort-的事务数据"><a href="#Consumer-如何过滤-abort-的事务数据" class="headerlink" title="Consumer 如何过滤 abort 的事务数据"></a>Consumer 如何过滤 abort 的事务数据</h4><p>Consumer 在拉取到相应的数据之后，后面该怎么处理呢？它拉取到的这批数据并不能保证都是完整的事务数据，很有可能是拉取到一个事务的部分数据（marker 数据还没有拉取到），这时候应该怎么办？难道 Consumer 先把这部分数据缓存下来，等后面的 marker 数据到来时再确认数据应该不应该丢弃？（还是又 OOM 的风险）有没有更好的实现方案？</p>
<p>Kafka 的设计总是不会让我们失望，这部分做的优化也是非常高明，Broker 会追踪每个 Partition 涉及到的 abort transactions，Partition 的每个 log segment 都会有一个单独只写的文件（append-only file）来存储 abort transaction 信息，因为 abort transaction 并不是很多，所以这个开销是可以可以接受的，之所以要持久化到磁盘，主要是为了故障后快速恢复，要不然 Broker 需要把这个 Partition 的所有数据都读一遍，才能直到哪些事务是 abort 的，这样的话，开销太大（如果这个 Partition 没有事务操作，就不会生成这个文件）。这个持久化的文件是以 <code>.txnindex</code> 做后缀，前面依然是这个 log segment 的 offset 信息，存储的数据格式如下：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">TransactionEntry =&gt;</div><div class="line">    Version =&gt; int16</div><div class="line">    PID =&gt; int64</div><div class="line">    FirstOffset =&gt; int64</div><div class="line">    LastOffset =&gt; int64</div><div class="line">    LastStableOffset =&gt; int64</div></pre></td></tr></table></figure>
<p>有了这个设计，Consumer 在拉取数据时，Broker 会把这批数据涉及到的所有 abort transaction 信息都返回给 Consumer，Server 端会根据拉取的 offset 范围与 abort transaction 的 offset 做对比，返回涉及到的 abort transaction 集合，其实现如下：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">collectAbortedTxns</span></span>(fetchOffset: <span class="type">Long</span>, upperBoundOffset: <span class="type">Long</span>): <span class="type">TxnIndexSearchResult</span> = &#123;</div><div class="line">  <span class="keyword">val</span> abortedTransactions = <span class="type">ListBuffer</span>.empty[<span class="type">AbortedTxn</span>]</div><div class="line">  <span class="keyword">for</span> ((abortedTxn, _) &lt;- iterator()) &#123;</div><div class="line">    <span class="keyword">if</span> (abortedTxn.lastOffset &gt;= fetchOffset &amp;&amp; abortedTxn.firstOffset &lt; upperBoundOffset)</div><div class="line">      abortedTransactions += abortedTxn <span class="comment">//note: 这个 abort 的事务有在在这个范围内，就返回</span></div><div class="line"></div><div class="line">    <span class="keyword">if</span> (abortedTxn.lastStableOffset &gt;= upperBoundOffset)</div><div class="line">      <span class="keyword">return</span> <span class="type">TxnIndexSearchResult</span>(abortedTransactions.toList, isComplete = <span class="literal">true</span>)</div><div class="line">  &#125;</div><div class="line">  <span class="type">TxnIndexSearchResult</span>(abortedTransactions.toList, isComplete = <span class="literal">false</span>)</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>Consumer 在拿到这些数据之后，会进行相应的过滤，大概的判断逻辑如下（Server 端返回的 abort transaction 列表就保存在 <code>abortedTransactions</code>  集合中，<code>abortedProducerIds</code>  最开始时是为空的）：</p>
<ol>
<li>如果这个数据是 control msg（也即是 marker 数据），是 ABORT 的话，那么与这个事务相关的 PID 信息从 <code>abortedProducerIds</code> 集合删掉，是 COMMIT 的话，就忽略（每个这个 PID 对应的 marker 数据收到之后，就从 <code>abortedProducerIds</code> 中清除这个 PID 信息）；</li>
<li>如果这个数据是正常的数据，把它的 PID 和 offset 信息与 <code>abortedTransactions</code> 队列（有序队列，头部 transaction 的 first offset 最小）第一个 transaction 做比较，如果 PID 相同，并且 offset 大于等于这个 transaction 的 first offset，就将这个 PID 信息添加到 <code>abortedProducerIds</code> 集合中，同时从 <code>abortedTransactions</code> 队列中删除这个 transaction，最后再丢掉这个 batch（它是 abort transaction 的数据）；</li>
<li>检查这个 batch 的 PID 是否在 <code>abortedProducerIds</code> 集合中，在的话，就丢弃，不在的话就返回上层应用。</li>
</ol>
<p>这部分的实现确实有些绕（有兴趣的可以慢慢咀嚼一下），它严重依赖了 Kafka 提供的下面两种保证：</p>
<ol>
<li>Consumer 拉取到的数据，在处理时，其 offset 是严格有序的；</li>
<li>同一个 txn.id（PID 相同）在某一个时刻最多只能有一个事务正在进行；</li>
</ol>
<p>这部分代码实现如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">private</span> Record <span class="title">nextFetchedRecord</span><span class="params">()</span> </span>&#123;</div><div class="line">    <span class="keyword">while</span> (<span class="keyword">true</span>) &#123;</div><div class="line">        <span class="keyword">if</span> (records == <span class="keyword">null</span> || !records.hasNext()) &#123; <span class="comment">//note: records 为空（数据全部丢掉了），records 没有数据（是 control msg）</span></div><div class="line">            maybeCloseRecordStream();</div><div class="line"></div><div class="line">            <span class="keyword">if</span> (!batches.hasNext()) &#123;</div><div class="line">                <span class="comment">// Message format v2 preserves the last offset in a batch even if the last record is removed</span></div><div class="line">                <span class="comment">// through compaction. By using the next offset computed from the last offset in the batch,</span></div><div class="line">                <span class="comment">// we ensure that the offset of the next fetch will point to the next batch, which avoids</span></div><div class="line">                <span class="comment">// unnecessary re-fetching of the same batch (in the worst case, the consumer could get stuck</span></div><div class="line">                <span class="comment">// fetching the same batch repeatedly).</span></div><div class="line">                <span class="keyword">if</span> (currentBatch != <span class="keyword">null</span>)</div><div class="line">                    nextFetchOffset = currentBatch.nextOffset();</div><div class="line">                drain();</div><div class="line">                <span class="keyword">return</span> <span class="keyword">null</span>;</div><div class="line">            &#125;</div><div class="line"></div><div class="line">            currentBatch = batches.next();</div><div class="line">            maybeEnsureValid(currentBatch);</div><div class="line"></div><div class="line">            <span class="keyword">if</span> (isolationLevel == IsolationLevel.READ_COMMITTED &amp;&amp; currentBatch.hasProducerId()) &#123;</div><div class="line">                <span class="comment">//note: 需要做相应的判断</span></div><div class="line">                <span class="comment">// remove from the aborted transaction queue all aborted transactions which have begun</span></div><div class="line">                <span class="comment">// before the current batch's last offset and add the associated producerIds to the</span></div><div class="line">                <span class="comment">// aborted producer set</span></div><div class="line">                <span class="comment">//note: 如果这个 batch 的 offset 已经大于等于 abortedTransactions 中第一事务的 first offset</span></div><div class="line">                <span class="comment">//note: 那就证明下个 abort transaction 的数据已经开始到来，将 PID 添加到 abortedProducerIds 中</span></div><div class="line">                consumeAbortedTransactionsUpTo(currentBatch.lastOffset());</div><div class="line"></div><div class="line">                <span class="keyword">long</span> producerId = currentBatch.producerId();</div><div class="line">                <span class="keyword">if</span> (containsAbortMarker(currentBatch)) &#123;</div><div class="line">                    abortedProducerIds.remove(producerId); <span class="comment">//note: 这个 PID（当前事务）涉及到的数据已经处理完</span></div><div class="line">                &#125; <span class="keyword">else</span> <span class="keyword">if</span> (isBatchAborted(currentBatch)) &#123; <span class="comment">//note: 丢弃这个数据</span></div><div class="line">                    log.debug(<span class="string">"Skipping aborted record batch from partition &#123;&#125; with producerId &#123;&#125; and "</span> +</div><div class="line">                                  <span class="string">"offsets &#123;&#125; to &#123;&#125;"</span>,</div><div class="line">                              partition, producerId, currentBatch.baseOffset(), currentBatch.lastOffset());</div><div class="line">                    nextFetchOffset = currentBatch.nextOffset();</div><div class="line">                    <span class="keyword">continue</span>;</div><div class="line">                &#125;</div><div class="line">            &#125;</div><div class="line"></div><div class="line">            records = currentBatch.streamingIterator(decompressionBufferSupplier);</div><div class="line">        &#125; <span class="keyword">else</span> &#123;</div><div class="line">            Record record = records.next();</div><div class="line">            <span class="comment">// skip any records out of range</span></div><div class="line">            <span class="keyword">if</span> (record.offset() &gt;= nextFetchOffset) &#123;</div><div class="line">                <span class="comment">// we only do validation when the message should not be skipped.</span></div><div class="line">                maybeEnsureValid(record);</div><div class="line"></div><div class="line">                <span class="comment">// control records are not returned to the user</span></div><div class="line">                <span class="keyword">if</span> (!currentBatch.isControlBatch()) &#123; <span class="comment">//note: 过滤掉 marker 数据</span></div><div class="line">                    <span class="keyword">return</span> record;</div><div class="line">                &#125; <span class="keyword">else</span> &#123;</div><div class="line">                    <span class="comment">// Increment the next fetch offset when we skip a control batch.</span></div><div class="line">                    nextFetchOffset = record.offset() + <span class="number">1</span>;</div><div class="line">                &#125;</div><div class="line">            &#125;</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h3 id="Consumer-消费数据时，其顺序如何保证"><a href="#Consumer-消费数据时，其顺序如何保证" class="headerlink" title="Consumer 消费数据时，其顺序如何保证"></a>Consumer 消费数据时，其顺序如何保证</h3><p>有了前面的分析，这个问题就很好回答了，顺序性还是严格按照 offset 的，只不过遇到 abort trsansaction 的数据时就丢弃掉，其他的与普通 Consumer 并没有区别。</p>
<h3 id="如果-txn-id-长期不使用，server-端怎么处理？"><a href="#如果-txn-id-长期不使用，server-端怎么处理？" class="headerlink" title="如果 txn.id 长期不使用，server 端怎么处理？"></a>如果 txn.id 长期不使用，server 端怎么处理？</h3><p>Producer 在开始一个事务操作时，可以设置其事务超时时间（参数是 <code>transaction.timeout.ms</code>，默认60s），而且 Server 端还有一个最大可允许的事务操作超时时间（参数是 <code>transaction.timeout.ms</code>，默认是15min），Producer 设置超时时间不能超过 Server，否则的话会抛出异常。</p>
<p>上面是关于事务操作的超时设置，而对于 txn.id，我们知道 TransactionCoordinator 会缓存 txn.id 的相关信息，如果没有超时机制，这个 meta 大小是无法预估的，Server 端提供了一个 <code>transaction.id.expiration.ms</code> 参数来配置这个超时时间（默认是7天），如果超过这个时间没有任何事务相关的请求发送过来，那么 TransactionCoordinator 将会使这个 txn.id 过期。</p>
<h3 id="PID-Snapshot-是做什么的？用来解决什么问题？"><a href="#PID-Snapshot-是做什么的？用来解决什么问题？" class="headerlink" title="PID Snapshot 是做什么的？用来解决什么问题？"></a>PID Snapshot 是做什么的？用来解决什么问题？</h3><p>对于每个 Topic-Partition，Broker 都会在内存中维护其 PID 与 sequence number（最后成功写入的 msg 的 sequence number）的对应关系（这个在上面幂等性文章应讲述过，主要是为了不丢补充的实现）。</p>
<p>Broker 重启时，如果想恢复上面的状态信息，那么它读取所有的 log 文件。相比于之下，定期对这个 state 信息做 checkpoint（Snapshot），明显收益是非常大的，此时如果 Broker 重启，只需要读取最近一个 Snapshot 文件，之后的数据再从 log 文件中恢复即可。</p>
<p>这个 PID Snapshot 样式如 00000000000235947656.snapshot，以 <code>.snapshot</code> 作为后缀，其数据格式如下：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">[matt@XXX-35 app.matt_test_transaction_json_3-2]$ /usr/<span class="built_in">local</span>/java18/bin/java -Djava.ext.dirs=/XXX/kafka/libs kafka.tools.DumpLogSegments --files 00000000000235947656.snapshot</div><div class="line">Dumping 00000000000235947656.snapshot</div><div class="line">producerId: 2000 producerEpoch: 1 coordinatorEpoch: 4 currentTxnFirstOffset: None firstSequence: 95769510 lastSequence: 95769511 lastOffset: 235947654 offsetDelta: 1 timestamp: 1541325156503</div><div class="line">producerId: 3000 producerEpoch: 5 coordinatorEpoch: 6 currentTxnFirstOffset: None firstSequence: 91669662 lastSequence: 91669666 lastOffset: 235947651 offsetDelta: 4 timestamp: 1541325156454</div></pre></td></tr></table></figure>
<p>在实际的使用中，这个 snapshot 文件一般只会保存最近的两个文件。</p>
<h3 id="中间流程故障如何恢复"><a href="#中间流程故障如何恢复" class="headerlink" title="中间流程故障如何恢复"></a>中间流程故障如何恢复</h3><p>对于上面所讲述的一个事务操作流程，实际生产环境中，任何一个地方都有可能出现的失败：</p>
<ol>
<li>Producer 在发送 <code>beginTransaction()</code> 时，如果出现 timeout 或者错误：Producer 只需要重试即可；</li>
<li>Producer 在发送数据时出现错误：Producer 应该 abort 这个事务，如果 Produce 没有 abort（比如设置了重试无限次，并且 batch 超时设置得非常大），TransactionCoordinator 将会在这个事务超时之后 abort 这个事务操作；</li>
<li>Producer 发送 <code>commitTransaction()</code> 时出现 timeout 或者错误：Producer 应该重试这个请求；</li>
<li>Coordinator Failure：如果 Transaction Coordinator 发生切换（事务 topic leader 切换），Coordinator 可以从日志中恢复。如果发送事务有处于 PREPARE_COMMIT 或 PREPARE_ABORT 状态，那么直接执行 commit 或者 abort 操作，如果是一个正在进行的事务，Coordinator 的失败并不需要 abort 事务，producer 只需要向新的 Coordinator 发送请求即可。</li>
</ol>
<p>陆陆续续写了几天，终于把这篇文章总结完了。</p>
<hr>
<p>参考：</p>
<ol>
<li><a href="https://docs.google.com/document/d/11Jqy_GjUGtdXJK94XGsEIK7CP1SnQGdp2eF0wSw9ra8/edit" target="_blank" rel="external">Exactly Once Delivery and Transactional Messaging in Kafka</a>；</li>
<li><a href="https://cwiki.apache.org/confluence/display/KAFKA/Idempotent+Producer" target="_blank" rel="external">Idempotent Producer</a>；</li>
<li><a href="https://www.slideshare.net/ConfluentInc/exactlyonce-semantics-in-apache-kafka" target="_blank" rel="external">Exactly-once Semantics in Apache Kafka</a>；</li>
<li><a href="https://cwiki.apache.org/confluence/display/KAFKA/Transactional+Messaging+in+Kafka" target="_blank" rel="external">Transactional Messaging in Kafka</a>；</li>
<li><a href="https://www.confluent.io/blog/transactions-apache-kafka/" target="_blank" rel="external">Transactions in Apache Kafka</a>；</li>
</ol>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[Kafka 事务性之幂等性实现]]></title>
      <url>http://matt33.com/2018/10/24/kafka-idempotent/</url>
      <content type="html"><![CDATA[<p>Apache Kafka 从 0.11.0 开始，支持了一个非常大的 feature，就是对事务性的支持，在 Kafka 中关于事务性，是有三种层面上的含义：一是幂等性的支持；二是事务性的支持；三是 Kafka Streams 的 exactly once 的实现，关于 Kafka 事务性系列的文章我们只重点关注前两种层面上的事务性，与 Kafka Streams 相关的内容暂时不做讨论。社区从开始讨论事务性，前后持续近半年时间，相关的设计文档有六十几页（参考 <a href="https://docs.google.com/document/d/11Jqy_GjUGtdXJK94XGsEIK7CP1SnQGdp2eF0wSw9ra8/edit" target="_blank" rel="external">Exactly Once Delivery and Transactional Messaging in Kafka</a>）。事务性这部分的实现也是非常复杂的，之前 Producer 端的代码实现其实是非常简单的，增加事务性的逻辑之后，这部分代码复杂度提高了很多，本篇及后面几篇关于事务性的文章会以 2.0.0 版的代码实现为例，对这部分做了一下分析，计划分为五篇文章：</p>
<ol>
<li>第一篇：Kafka 幂等性实现；</li>
<li>第二篇：Kafka 事务性实现；</li>
<li>第三篇：Kafka 事务性相关处理请求在 Server 端如何处理及其实现细节；</li>
<li>第四篇：关于 Kafka 事务性实现的一些思考，也会简单介绍一下 RocketMQ 事务性的实现，做一下对比；</li>
<li>第五篇：Flink + Kafka 如何实现 Exactly Once；</li>
</ol>
<p>这篇是 Kafka 事务性系列的第一篇文章，主要讲述幂等性实现的整体流程，幂等性的实现相对于事务性的实现简单很多，也是事务性实现的基础。</p>
<h2 id="Producer-幂等性"><a href="#Producer-幂等性" class="headerlink" title="Producer 幂等性"></a>Producer 幂等性</h2><p>Producer 的幂等性指的是当发送同一条消息时，数据在 Server 端只会被持久化一次，数据不丟不重，但是这里的幂等性是有条件的：</p>
<ul>
<li>只能保证 Producer 在单个会话内不丟不重，如果 Producer 出现意外挂掉再重启是无法保证的（幂等性情况下，是无法获取之前的状态信息，因此是无法做到跨会话级别的不丢不重）;</li>
<li>幂等性不能跨多个 Topic-Partition，只能保证单个 partition 内的幂等性，当涉及多个 Topic-Partition 时，这中间的状态并没有同步。</li>
</ul>
<p>如果需要跨会话、跨多个 topic-partition 的情况，需要使用 Kafka 的事务性来实现。</p>
<h2 id="幂等性示例"><a href="#幂等性示例" class="headerlink" title="幂等性示例"></a>幂等性示例</h2><p>Producer 使用幂等性的示例非常简单，与正常情况下 Producer 使用相比变化不大，只需要把 Producer 的配置 enable.idempotence 设置为 true 即可，如下所示：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">Properties props = <span class="keyword">new</span> Properties();</div><div class="line">props.put(ProducerConfig.ENABLE_IDEMPOTENCE_CONFIG, <span class="string">"true"</span>);</div><div class="line">props.put(<span class="string">"acks"</span>, <span class="string">"all"</span>); <span class="comment">// 当 enable.idempotence 为 true，这里默认为 all</span></div><div class="line">props.put(<span class="string">"bootstrap.servers"</span>, <span class="string">"localhost:9092"</span>);</div><div class="line">props.put(<span class="string">"key.serializer"</span>, <span class="string">"org.apache.kafka.common.serialization.StringSerializer"</span>);</div><div class="line">props.put(<span class="string">"value.serializer"</span>, <span class="string">"org.apache.kafka.common.serialization.StringSerializer"</span>);</div><div class="line"></div><div class="line">KafkaProducer producer = <span class="keyword">new</span> KafkaProducer(props);</div><div class="line"></div><div class="line">producer.send(<span class="keyword">new</span> ProducerRecord(topic, <span class="string">"test"</span>);</div></pre></td></tr></table></figure>
<p>Prodcuer 幂等性对外保留的接口非常简单，其底层的实现对上层应用做了很好的封装，应用层并不需要去关心具体的实现细节，对用户非常友好。</p>
<h2 id="幂等性要解决的问题"><a href="#幂等性要解决的问题" class="headerlink" title="幂等性要解决的问题"></a>幂等性要解决的问题</h2><p>在看 Producer 是如何实现幂等性之前，首先先考虑一个问题：<strong>幂等性是来解决什么问题的？</strong> 在 0.11.0 之前，Kafka 通过 Producer 端和 Server 端的相关配置可以做到<strong>数据不丢</strong>，也就是 at least once，但是在一些情况下，可能会导致数据重复，比如：网络请求延迟等导致的重试操作，在发送请求重试时 Server 端并不知道这条请求是否已经处理（没有记录之前的状态信息），所以就会有可能导致数据请求的重复发送，这是 Kafka 自身的机制（异常时请求重试机制）导致的数据重复。</p>
<p>对于大多数应用而言，数据保证不丢是可以满足其需求的，但是对于一些其他的应用场景（比如支付数据等），它们是要求精确计数的，这时候如果上游数据有重复，下游应用只能在消费数据时进行相应的去重操作，应用在去重时，最常用的手段就是根据唯一 id 键做 check 去重。</p>
<p>在这种场景下，因为上游生产导致的数据重复问题，会导致所有有精确计数需求的下游应用都需要做这种复杂的、重复的去重处理。试想一下：如果在发送时，系统就能保证 exactly once，这对下游将是多么大的解脱。这就是幂等性要解决的问题，主要是解决数据重复的问题，正如前面所述，数据重复问题，通用的解决方案就是加唯一 id，然后根据 id 判断数据是否重复，Producer 的幂等性也是这样实现的，这一小节就让我们看下 Kafka 的 Producer 如何保证数据的 exactly once 的。</p>
<h2 id="幂等性的实现原理"><a href="#幂等性的实现原理" class="headerlink" title="幂等性的实现原理"></a>幂等性的实现原理</h2><p>在讲述幂等性处理流程之前，先看下 Producer 是如何来保证幂等性的，正如前面所述，幂等性要解决的问题是：Producer 设置 at least once 时，由于异常触发重试机制导致数据重复，幂等性的目的就是为了解决这个数据重复的问题，简单来说就是：</p>
<p><strong>at least once + 幂等 = exactly once</strong></p>
<p>通过在 al least once 的基础上加上 幂等性来坐到 exactly once，当然这个层面的 exactly once 是有限制的，比如它会要求单会话内有效或者跨会话使用事务性有效等。这里我们先分析最简单的情况，那就是在单会话内如何做到幂等性，进而保证 exactly once。</p>
<p>要做到幂等性，要解决下面的问题：</p>
<ol>
<li>系统需要有能力鉴别一条数据到底是不是重复的数据？常用的手段是通过 <strong>唯一键/唯一 id</strong> 来判断，这时候系统一般是需要缓存已经处理的唯一键记录，这样才能更有效率地判断一条数据是不是重复；</li>
<li>唯一键应该选择什么粒度？对于分布式存储系统来说，肯定不能用全局唯一键（全局是针对集群级别），核心的解决思路依然是 <strong>分而治之</strong>，数据密集型系统为了实现分布式都是有分区概念的，而分区之间是有相应的隔离，对于 Kafka 而言，这里的解决方案就是在分区的维度上去做，重复数据的判断让 partition 的 leader 去判断处理，前提是 Produce 请求需要把唯一键值告诉 leader；</li>
<li>分区粒度实现唯一键会不会有其他问题？这里需要考虑的问题是当一个 Partition 有来自多个 client 写入的情况，这些 client 之间是很难做到使用同一个唯一键（一个是它们之间很难做到唯一键的实时感知，另一个是这样实现是否有必要）。而如果系统在实现时做到了  <strong>client + partition</strong> 粒度，这样实现的好处是每个 client 都是完全独立的（它们之间不需要有任何的联系，这是非常大的优点），只是在 Server 端对不同的 client 做好相应的区分即可，当然同一个 client 在处理多个 Topic-Partition 时是完全可以使用同一个 PID 的。</li>
</ol>
<p>有了上面的分析（都是个人见解，如果有误，欢迎指教），就不难理解 Producer 幂等性的实现原理，Kafka Producer 在实现时有以下两个重要机制：</p>
<ol>
<li>PID（Producer ID），用来标识每个 producer client；</li>
<li>sequence numbers，client 发送的每条消息都会带相应的 sequence number，Server 端就是根据这个值来判断数据是否重复。</li>
</ol>
<p>下面详细讲述这两个实现机制。</p>
<h3 id="PID"><a href="#PID" class="headerlink" title="PID"></a>PID</h3><p>每个 Producer 在初始化时都会被分配一个唯一的 PID，这个 PID 对应用是透明的，完全没有暴露给用户。对于一个给定的 PID，sequence number 将会从0开始自增，每个 Topic-Partition 都会有一个独立的 sequence number。Producer 在发送数据时，将会给每条 msg 标识一个 sequence number，Server 也就是通过这个来验证数据是否重复。这里的 PID 是全局唯一的，Producer 故障后重新启动后会被分配一个新的 PID，这也是幂等性无法做到跨会话的一个原因。</p>
<h4 id="Producer-PID-申请"><a href="#Producer-PID-申请" class="headerlink" title="Producer PID 申请"></a>Producer PID 申请</h4><p>这里看下 PID 在 Server 端是如何分配的？Client 通过向 Server 发送一个 InitProducerIdRequest 请求获取 PID（幂等性时，是选择一台连接数最少的 Broker 发送这个请求），这里看下 Server 端是如何处理这个请求的？KafkaApis 中 <code>handleInitProducerIdRequest()</code> 方法的实现如下：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">handleInitProducerIdRequest</span></span>(request: <span class="type">RequestChannel</span>.<span class="type">Request</span>): <span class="type">Unit</span> = &#123;</div><div class="line">  <span class="keyword">val</span> initProducerIdRequest = request.body[<span class="type">InitProducerIdRequest</span>]</div><div class="line">  <span class="keyword">val</span> transactionalId = initProducerIdRequest.transactionalId</div><div class="line"></div><div class="line">  <span class="keyword">if</span> (transactionalId != <span class="literal">null</span>) &#123; <span class="comment">//note: 设置 txn.id 时，验证对 txn.id 的权限</span></div><div class="line">    <span class="keyword">if</span> (!authorize(request.session, <span class="type">Write</span>, <span class="type">Resource</span>(<span class="type">TransactionalId</span>, transactionalId, <span class="type">LITERAL</span>))) &#123;</div><div class="line">      sendErrorResponseMaybeThrottle(request, <span class="type">Errors</span>.<span class="type">TRANSACTIONAL_ID_AUTHORIZATION_FAILED</span>.exception)</div><div class="line">      <span class="keyword">return</span></div><div class="line">    &#125;</div><div class="line">  &#125; <span class="keyword">else</span> <span class="keyword">if</span> (!authorize(request.session, <span class="type">IdempotentWrite</span>, <span class="type">Resource</span>.<span class="type">ClusterResource</span>)) &#123; <span class="comment">//note: 没有设置 txn.id 时，验证对集群是否有幂等性权限</span></div><div class="line">    sendErrorResponseMaybeThrottle(request, <span class="type">Errors</span>.<span class="type">CLUSTER_AUTHORIZATION_FAILED</span>.exception)</div><div class="line">    <span class="keyword">return</span></div><div class="line">  &#125;</div><div class="line"></div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">sendResponseCallback</span></span>(result: <span class="type">InitProducerIdResult</span>): <span class="type">Unit</span> = &#123;</div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">createResponse</span></span>(requestThrottleMs: <span class="type">Int</span>): <span class="type">AbstractResponse</span> = &#123;</div><div class="line">      <span class="keyword">val</span> responseBody = <span class="keyword">new</span> <span class="type">InitProducerIdResponse</span>(requestThrottleMs, result.error, result.producerId, result.producerEpoch)</div><div class="line">      trace(<span class="string">s"Completed <span class="subst">$transactionalId</span>'s InitProducerIdRequest with result <span class="subst">$result</span> from client <span class="subst">$&#123;request.header.clientId&#125;</span>."</span>)</div><div class="line">      responseBody</div><div class="line">    &#125;</div><div class="line">    sendResponseMaybeThrottle(request, createResponse)</div><div class="line">  &#125;</div><div class="line">  <span class="comment">//note: 生成相应的了 pid，返回给 producer</span></div><div class="line">  txnCoordinator.handleInitProducerId(transactionalId, initProducerIdRequest.transactionTimeoutMs, sendResponseCallback)</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>这里实际上是调用了 TransactionCoordinator （Broker 在启动 server 服务时都会初始化这个实例）的 <code>handleInitProducerId()</code> 方法做了相应的处理，其实现如下（这里只关注幂等性的处理）：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">handleInitProducerId</span></span>(transactionalId: <span class="type">String</span>,</div><div class="line">                         transactionTimeoutMs: <span class="type">Int</span>,</div><div class="line">                         responseCallback: <span class="type">InitProducerIdCallback</span>): <span class="type">Unit</span> = &#123;</div><div class="line"></div><div class="line">  <span class="keyword">if</span> (transactionalId == <span class="literal">null</span>) &#123; <span class="comment">//note: 只设置幂等性时，直接分配 pid 并返回</span></div><div class="line">    <span class="comment">// if the transactional id is null, then always blindly accept the request</span></div><div class="line">    <span class="comment">// and return a new producerId from the producerId manager</span></div><div class="line">    <span class="keyword">val</span> producerId = producerIdManager.generateProducerId()</div><div class="line">    responseCallback(<span class="type">InitProducerIdResult</span>(producerId, producerEpoch = <span class="number">0</span>, <span class="type">Errors</span>.<span class="type">NONE</span>))</div><div class="line">  &#125;</div><div class="line">  ...</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>Server 在给一个 client 初始化 PID 时，实际上是通过 ProducerIdManager 的 <code>generateProducerId()</code> 方法产生一个 PID。</p>
<h4 id="Server-PID-管理"><a href="#Server-PID-管理" class="headerlink" title="Server PID 管理"></a>Server PID 管理</h4><p>如前面所述，在幂等性的情况下，直接通过 ProducerIdManager 的 <code>generateProducerId()</code> 方法产生一个 PID，其中 ProducerIdManager 是在 TransactionCoordinator 对象初始化时初始化的，这个对象主要是用来管理 PID 信息：</p>
<ul>
<li>在本地的 PID 端用完了或者处于新建状态时，申请 PID 段（默认情况下，每次申请 1000 个 PID）；</li>
<li>TransactionCoordinator 对象通过 <code>generateProducerId()</code> 方法获取下一个可以使用的 PID；</li>
</ul>
<p><strong>PID 端申请是向 ZooKeeper 申请</strong>，zk 中有一个 <code>/latest_producer_id_block</code> 节点，每个 Broker 向 zk 申请一个 PID 段后，都会把自己申请的 PID 段信息写入到这个节点，这样当其他 Broker 再申请 PID 段时，会首先读写这个节点的信息，然后根据 block_end 选择一个 PID 段，最后再把信息写会到 zk 的这个节点，这个节点信息格式如下所示：</p>
<figure class="highlight json"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">&#123;<span class="attr">"version"</span>:<span class="number">1</span>,<span class="attr">"broker"</span>:<span class="number">35</span>,<span class="attr">"block_start"</span>:<span class="string">"4000"</span>,<span class="attr">"block_end"</span>:<span class="string">"4999"</span>&#125;</div></pre></td></tr></table></figure>
<p>ProducerIdManager 向 zk 申请 PID 段的方法如下：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">getNewProducerIdBlock</span></span>(): <span class="type">Unit</span> = &#123;</div><div class="line">  <span class="keyword">var</span> zkWriteComplete = <span class="literal">false</span></div><div class="line">  <span class="keyword">while</span> (!zkWriteComplete) &#123; <span class="comment">//note: 直到从 zk 拿取到分配的 PID 段</span></div><div class="line">    <span class="comment">// refresh current producerId block from zookeeper again</span></div><div class="line">    <span class="keyword">val</span> (dataOpt, zkVersion) = zkClient.getDataAndVersion(<span class="type">ProducerIdBlockZNode</span>.path)</div><div class="line"></div><div class="line">    <span class="comment">// generate the new producerId block</span></div><div class="line">    currentProducerIdBlock = dataOpt <span class="keyword">match</span> &#123;</div><div class="line">      <span class="keyword">case</span> <span class="type">Some</span>(data) =&gt;</div><div class="line">        <span class="comment">//note: 从 zk 获取当前最新的 pid 信息，如果后面更新失败，这里也会重新从 zk 获取</span></div><div class="line">        <span class="keyword">val</span> currProducerIdBlock = <span class="type">ProducerIdManager</span>.parseProducerIdBlockData(data)</div><div class="line">        debug(<span class="string">s"Read current producerId block <span class="subst">$currProducerIdBlock</span>, Zk path version <span class="subst">$zkVersion</span>"</span>)</div><div class="line"></div><div class="line">        <span class="keyword">if</span> (currProducerIdBlock.blockEndId &gt; <span class="type">Long</span>.<span class="type">MaxValue</span> - <span class="type">ProducerIdManager</span>.<span class="type">PidBlockSize</span>) &#123;<span class="comment">//note: 不足以分配1000个 PID</span></div><div class="line">          <span class="comment">// we have exhausted all producerIds (wow!), treat it as a fatal error</span></div><div class="line">          <span class="comment">//note: 当 PID 分配超过限制时，直接报错了（每秒分配1个，够用2百亿年了）</span></div><div class="line">          fatal(<span class="string">s"Exhausted all producerIds as the next block's end producerId is will has exceeded long type limit (current block end producerId is <span class="subst">$&#123;currProducerIdBlock.blockEndId&#125;</span>)"</span>)</div><div class="line">          <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">KafkaException</span>(<span class="string">"Have exhausted all producerIds."</span>)</div><div class="line">        &#125;</div><div class="line"></div><div class="line">        <span class="type">ProducerIdBlock</span>(brokerId, currProducerIdBlock.blockEndId + <span class="number">1</span>L, currProducerIdBlock.blockEndId + <span class="type">ProducerIdManager</span>.<span class="type">PidBlockSize</span>)</div><div class="line">      <span class="keyword">case</span> <span class="type">None</span> =&gt; <span class="comment">//note: 该节点还不存在，第一次初始化</span></div><div class="line">        debug(<span class="string">s"There is no producerId block yet (Zk path version <span class="subst">$zkVersion</span>), creating the first block"</span>)</div><div class="line">        <span class="type">ProducerIdBlock</span>(brokerId, <span class="number">0</span>L, <span class="type">ProducerIdManager</span>.<span class="type">PidBlockSize</span> - <span class="number">1</span>)</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="keyword">val</span> newProducerIdBlockData = <span class="type">ProducerIdManager</span>.generateProducerIdBlockJson(currentProducerIdBlock)</div><div class="line"></div><div class="line">    <span class="comment">// try to write the new producerId block into zookeeper</span></div><div class="line">    <span class="comment">//note: 将新的 pid 信息写入到 zk，如果写入失败（写入之前会比对 zkVersion，如果这个有变动，证明这期间有别的 Broker 在操作，那么写入失败），重新申请</span></div><div class="line">    <span class="keyword">val</span> (succeeded, version) = zkClient.conditionalUpdatePath(<span class="type">ProducerIdBlockZNode</span>.path,</div><div class="line">      newProducerIdBlockData, zkVersion, <span class="type">Some</span>(checkProducerIdBlockZkData))</div><div class="line">    zkWriteComplete = succeeded</div><div class="line"></div><div class="line">    <span class="keyword">if</span> (zkWriteComplete)</div><div class="line">      info(<span class="string">s"Acquired new producerId block <span class="subst">$currentProducerIdBlock</span> by writing to Zk with path version <span class="subst">$version</span>"</span>)</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>ProducerIdManager 申请 PID 段的流程如下：</p>
<ol>
<li>先从 zk 的 <code>/latest_producer_id_block</code> 节点读取最新已经分配的 PID 段信息；</li>
<li>如果该节点不存在，直接从 0 开始分配，选择 0~1000 的 PID 段（ProducerIdManager 的 PidBlockSize 默认为 1000，即是每次申请的 PID 段大小）；</li>
<li>如果该节点存在，读取其中数据，根据 block_end 选择 <block_end+1, block_end+1000=""> 这个 PID 段（如果 PID 段超过 Long 类型的最大值，这里会直接返回一个异常）；</block_end+1,></li>
<li>在选择了相应的 PID 段后，将这个 PID 段信息写回到 zk 的这个节点中，如果写入成功，那么 PID 段就证明申请成功，如果写入失败（写入时会判断当前节点的 zkVersion 是否与步骤1获取的 zkVersion 相同，如果相同，那么可以成功写入，否则写入就会失败，证明这个节点被修改过），证明此时可能其他的 Broker 已经更新了这个节点（当前的 PID 段可能已经被其他 Broker 申请），那么从步骤 1 重新开始，直到写入成功。</li>
</ol>
<p>明白了 ProducerIdManager 如何申请 PID 段之后，再看 <code>generateProducerId()</code> 这个方法就简单很多了，这个方法在每次调用时，都会更新 nextProducerId 值（下一次可以使用 PID 值），如下所示：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">generateProducerId</span></span>(): <span class="type">Long</span> = &#123;</div><div class="line">  <span class="keyword">this</span> synchronized &#123;</div><div class="line">    <span class="comment">// grab a new block of producerIds if this block has been exhausted</span></div><div class="line">    <span class="keyword">if</span> (nextProducerId &gt; currentProducerIdBlock.blockEndId) &#123;</div><div class="line">      <span class="comment">//note: 如果分配的 pid 用完了，重新再向 zk 申请一批</span></div><div class="line">      getNewProducerIdBlock()</div><div class="line">      nextProducerId = currentProducerIdBlock.blockStartId + <span class="number">1</span></div><div class="line">    &#125; <span class="keyword">else</span> &#123;</div><div class="line">      nextProducerId += <span class="number">1</span></div><div class="line">    &#125;</div><div class="line"></div><div class="line">    nextProducerId - <span class="number">1</span> <span class="comment">//note: 返回当前分配的 pid</span></div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>这里就是 Producer PID 如何申请（事务性情况下 PID 的申请会复杂一些，下篇文章再讲述）以及 Server 端如何管理 PID 的。</p>
<h3 id="sequence-numbers"><a href="#sequence-numbers" class="headerlink" title="sequence numbers"></a>sequence numbers</h3><p>再有了 PID 之后，在 PID + Topic-Partition 级别上添加一个 sequence numbers 信息，就可以实现 Producer 的幂等性了。ProducerBatch 也提供了一个 <code>setProducerState()</code> 方法，它可以给一个 batch 添加一些 meta 信息（pid、baseSequence、isTransactional），这些信息是会伴随着 ProduceRequest 发到 Server 端，Server 端也正是通过这些 meta 来做相应的判断，如下所示：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// ProducerBatch</span></div><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setProducerState</span><span class="params">(ProducerIdAndEpoch producerIdAndEpoch, <span class="keyword">int</span> baseSequence, <span class="keyword">boolean</span> isTransactional)</span> </span>&#123;</div><div class="line">    recordsBuilder.setProducerState(producerIdAndEpoch.producerId, producerIdAndEpoch.epoch, baseSequence, isTransactional);</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="comment">// MemoryRecordsBuilder</span></div><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setProducerState</span><span class="params">(<span class="keyword">long</span> producerId, <span class="keyword">short</span> producerEpoch, <span class="keyword">int</span> baseSequence, <span class="keyword">boolean</span> isTransactional)</span> </span>&#123;</div><div class="line">    <span class="keyword">if</span> (isClosed()) &#123;</div><div class="line">        <span class="comment">// Sequence numbers are assigned when the batch is closed while the accumulator is being drained.</span></div><div class="line">        <span class="comment">// If the resulting ProduceRequest to the partition leader failed for a retriable error, the batch will</span></div><div class="line">        <span class="comment">// be re queued. In this case, we should not attempt to set the state again, since changing the producerId and sequence</span></div><div class="line">        <span class="comment">// once a batch has been sent to the broker risks introducing duplicates.</span></div><div class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> IllegalStateException(<span class="string">"Trying to set producer state of an already closed batch. This indicates a bug on the client."</span>);</div><div class="line">    &#125;</div><div class="line">    <span class="keyword">this</span>.producerId = producerId;</div><div class="line">    <span class="keyword">this</span>.producerEpoch = producerEpoch;</div><div class="line">    <span class="keyword">this</span>.baseSequence = baseSequence;</div><div class="line">    <span class="keyword">this</span>.isTransactional = isTransactional;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h2 id="幂等性实现整体流程"><a href="#幂等性实现整体流程" class="headerlink" title="幂等性实现整体流程"></a>幂等性实现整体流程</h2><p>在前面讲述完 Kafka 幂等性的两个实现机制（PID+sequence numbers）之后，这里详细讲述一下，幂等性时其整体的处理流程，主要讲述幂等性相关的内容，其他的部分会简单介绍（可以参考前面【Kafka 源码分析系列文章】了解 Producer 端处理流程以及 Server 端关于 ProduceRequest 请求的处理流程），其流程如下图所示：</p>
<p><img src="/images/kafka/kafka-idemoptent.png" alt="Producer 幂等性时处理流程"></p>
<p>这个图只展示了幂等性情况下，Producer 的大概流程，很多部分在前面的文章中做过分析，本文不再讲述，这里重点关注与幂等性相关的内容（事务性实现更加复杂，后面的文章再讲述），首先 KafkaProducer 在初始化时会初始化一个 TransactionManager 实例，它的作用有以下几个部分：</p>
<ol>
<li>记录本地的事务状态（事务性时必须）；</li>
<li>记录一些状态信息以保证幂等性，比如：每个 topic-partition 对应的下一个 sequence numbers 和 last acked batch（最近一个已经确认的 batch）的最大的 sequence number 等；</li>
<li>记录 ProducerIdAndEpoch 信息（PID 信息）。</li>
</ol>
<h3 id="Client-幂等性时发送流程"><a href="#Client-幂等性时发送流程" class="headerlink" title="Client 幂等性时发送流程"></a>Client 幂等性时发送流程</h3><p>如前面图中所示，幂等性时，Producer 的发送流程如下：</p>
<ol>
<li>应用通过 KafkaProducer 的 <code>send()</code> 方法将数据添加到 RecordAccumulator 中，添加时会判断是否需要新建一个 ProducerBatch，这时这个 ProducerBatch 还是没有 PID 和 sequence number 信息的；</li>
<li>Producer 后台发送线程 Sender，在 <code>run()</code> 方法中，会先根据 TransactionManager 的 <code>shouldResetProducerStateAfterResolvingSequences()</code> 方法判断当前的 PID 是否需要重置，重置的原因是因为：如果有 topic-partition 的 batch 重试多次失败最后因为超时而被移除，这时 sequence number 将无法做到连续，因为 sequence number 有部分已经分配出去，这时系统依赖自身的机制无法继续进行下去（因为幂等性是要保证不丢不重的），相当于程序遇到了一个 fatal 异常，PID 会进行重置，TransactionManager 相关的缓存信息被清空（Producer 不会重启），只是保存状态信息的 TransactionManager 做了 <code>clear+new</code> 操作，遇到这个问题时是无法保证 exactly once 的（有数据已经发送失败了，并且超过了重试次数）；</li>
<li>Sender 线程通过 <code>maybeWaitForProducerId()</code> 方法判断是否需要申请 PID，如果需要的话，这里会阻塞直到获取到相应的 PID 信息；</li>
<li>Sender 线程通过 <code>sendProducerData()</code> 方法发送数据，整体流程与之前的 Producer 流程相似，不同的地方是在 RecordAccumulator 的 <code>drain()</code> 方法中，在加了幂等性之后，<code>drain()</code> 方法多了如下几步判断：<ol>
<li>常规的判断：判断这个 topic-partition 是否可以继续发送（如果出现前面2中的情况是不允许发送的）、判断 PID 是否有效、如果这个 batch 是重试的 batch，那么需要判断这个 batch 之前是否还有 batch 没有发送完成，如果有，这里会先跳过这个 Topic-Partition 的发送，直到前面的 batch 发送完成，<strong>最坏情况下，这个 Topic-Partition 的 in-flight request 将会减少到1</strong>（这个涉及也是考虑到 server 端的一个设置，文章下面会详细分析）；</li>
<li>如果这个 ProducerBatch 还没有这个相应的 PID 和 sequence number 信息，会在这里进行相应的设置；</li>
</ol>
</li>
<li>最后 Sender 线程再调用 <code>sendProduceRequests()</code> 方法发送 ProduceRequest 请求，后面的就跟之前正常的流程保持一致了。</li>
</ol>
<p>这里看下几个关键方法的实现，首先是 Sender 线程获取 PID 信息的方法  <code>maybeWaitForProducerId()</code> ，其实现如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//note: 等待直到 Producer 获取到相应的 PID 和 epoch 信息</span></div><div class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">maybeWaitForProducerId</span><span class="params">()</span> </span>&#123;</div><div class="line">    <span class="keyword">while</span> (!transactionManager.hasProducerId() &amp;&amp; !transactionManager.hasError()) &#123;</div><div class="line">        <span class="keyword">try</span> &#123;</div><div class="line">            Node node = awaitLeastLoadedNodeReady(requestTimeoutMs); <span class="comment">//note: 选取 node（本地连接数最少的 node）</span></div><div class="line">            <span class="keyword">if</span> (node != <span class="keyword">null</span>) &#123;</div><div class="line">                ClientResponse response = sendAndAwaitInitProducerIdRequest(node); <span class="comment">//note: 发送 InitPidRequest</span></div><div class="line">                InitProducerIdResponse initProducerIdResponse = (InitProducerIdResponse) response.responseBody();</div><div class="line">                Errors error = initProducerIdResponse.error();</div><div class="line">                <span class="keyword">if</span> (error == Errors.NONE) &#123; <span class="comment">//note: 更新 Producer 的 PID 和 epoch 信息</span></div><div class="line">                    ProducerIdAndEpoch producerIdAndEpoch = <span class="keyword">new</span> ProducerIdAndEpoch(</div><div class="line">                            initProducerIdResponse.producerId(), initProducerIdResponse.epoch());</div><div class="line">                    transactionManager.setProducerIdAndEpoch(producerIdAndEpoch);</div><div class="line">                    <span class="keyword">return</span>;</div><div class="line">                &#125; <span class="keyword">else</span> <span class="keyword">if</span> (error.exception() <span class="keyword">instanceof</span> RetriableException) &#123;</div><div class="line">                    log.debug(<span class="string">"Retriable error from InitProducerId response"</span>, error.message());</div><div class="line">                &#125; <span class="keyword">else</span> &#123;</div><div class="line">                    transactionManager.transitionToFatalError(error.exception());</div><div class="line">                    <span class="keyword">break</span>;</div><div class="line">                &#125;</div><div class="line">            &#125; <span class="keyword">else</span> &#123;</div><div class="line">                log.debug(<span class="string">"Could not find an available broker to send InitProducerIdRequest to. "</span> +</div><div class="line">                        <span class="string">"We will back off and try again."</span>);</div><div class="line">            &#125;</div><div class="line">        &#125; <span class="keyword">catch</span> (UnsupportedVersionException e) &#123;</div><div class="line">            transactionManager.transitionToFatalError(e);</div><div class="line">            <span class="keyword">break</span>;</div><div class="line">        &#125; <span class="keyword">catch</span> (IOException e) &#123;</div><div class="line">            log.debug(<span class="string">"Broker &#123;&#125; disconnected while awaiting InitProducerId response"</span>, e);</div><div class="line">        &#125;</div><div class="line">        log.trace(<span class="string">"Retry InitProducerIdRequest in &#123;&#125;ms."</span>, retryBackoffMs);</div><div class="line">        time.sleep(retryBackoffMs);</div><div class="line">        metadata.requestUpdate();</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>再看下 RecordAccumulator 的 <code>drain()</code> 方法，重点需要关注的是关于幂等性和事务性相关的处理，具体如下所示，这里面关于事务性相关的判断在上面的流程中已经讲述。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div><div class="line">113</div><div class="line">114</div><div class="line">115</div><div class="line">116</div><div class="line">117</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/**</span></div><div class="line"> * Drain all the data for the given nodes and collate them into a list of batches that will fit within the specified</div><div class="line"> * size on a per-node basis. This method attempts to avoid choosing the same topic-node over and over.</div><div class="line"> *</div><div class="line"> * <span class="doctag">@param</span> cluster The current cluster metadata</div><div class="line"> * <span class="doctag">@param</span> nodes The list of node to drain</div><div class="line"> * <span class="doctag">@param</span> maxSize The maximum number of bytes to drain</div><div class="line"> * <span class="doctag">@param</span> now The current unix time in milliseconds</div><div class="line"> * <span class="doctag">@return</span> A list of &#123;<span class="doctag">@link</span> ProducerBatch&#125; for each node specified with total size less than the requested maxSize.</div><div class="line"> */</div><div class="line"><span class="keyword">public</span> Map&lt;Integer, List&lt;ProducerBatch&gt;&gt; drain(Cluster cluster,</div><div class="line">                                               Set&lt;Node&gt; nodes,</div><div class="line">                                               <span class="keyword">int</span> maxSize,</div><div class="line">                                               <span class="keyword">long</span> now) &#123;</div><div class="line">    <span class="keyword">if</span> (nodes.isEmpty())</div><div class="line">        <span class="keyword">return</span> Collections.emptyMap();</div><div class="line"></div><div class="line">    Map&lt;Integer, List&lt;ProducerBatch&gt;&gt; batches = <span class="keyword">new</span> HashMap&lt;&gt;();</div><div class="line">    <span class="keyword">for</span> (Node node : nodes) &#123;</div><div class="line">        <span class="keyword">int</span> size = <span class="number">0</span>;</div><div class="line">        List&lt;PartitionInfo&gt; parts = cluster.partitionsForNode(node.id());</div><div class="line">        List&lt;ProducerBatch&gt; ready = <span class="keyword">new</span> ArrayList&lt;&gt;();</div><div class="line">        <span class="comment">/* to make starvation less likely this loop doesn't start at 0 */</span></div><div class="line">        <span class="keyword">int</span> start = drainIndex = drainIndex % parts.size();</div><div class="line">        <span class="keyword">do</span> &#123;</div><div class="line">            PartitionInfo part = parts.get(drainIndex);</div><div class="line">            TopicPartition tp = <span class="keyword">new</span> TopicPartition(part.topic(), part.partition());</div><div class="line">            <span class="comment">// Only proceed if the partition has no in-flight batches.</span></div><div class="line">            <span class="keyword">if</span> (!isMuted(tp, now)) &#123;</div><div class="line">                Deque&lt;ProducerBatch&gt; deque = getDeque(tp);</div><div class="line">                <span class="keyword">if</span> (deque != <span class="keyword">null</span>) &#123;</div><div class="line">                    <span class="keyword">synchronized</span> (deque) &#123; <span class="comment">//note: 先判断有没有数据，然后后面真正处理时再加锁处理</span></div><div class="line">                        ProducerBatch first = deque.peekFirst();</div><div class="line">                        <span class="keyword">if</span> (first != <span class="keyword">null</span>) &#123;</div><div class="line">                            <span class="keyword">boolean</span> backoff = first.attempts() &gt; <span class="number">0</span> &amp;&amp; first.waitedTimeMs(now) &lt; retryBackoffMs;</div><div class="line">                            <span class="comment">// Only drain the batch if it is not during backoff period.</span></div><div class="line">                            <span class="keyword">if</span> (!backoff) &#123;</div><div class="line">                                <span class="keyword">if</span> (size + first.estimatedSizeInBytes() &gt; maxSize &amp;&amp; !ready.isEmpty()) &#123;</div><div class="line">                                    <span class="comment">// there is a rare case that a single batch size is larger than the request size due</span></div><div class="line">                                    <span class="comment">// to compression; in this case we will still eventually send this batch in a single</span></div><div class="line">                                    <span class="comment">// request</span></div><div class="line">                                    <span class="keyword">break</span>;</div><div class="line">                                &#125; <span class="keyword">else</span> &#123;</div><div class="line">                                    ProducerIdAndEpoch producerIdAndEpoch = <span class="keyword">null</span>;</div><div class="line">                                    <span class="keyword">boolean</span> isTransactional = <span class="keyword">false</span>;</div><div class="line">                                    <span class="keyword">if</span> (transactionManager != <span class="keyword">null</span>) &#123; <span class="comment">//note: 幂等性或事务性时， 做一些检查判断</span></div><div class="line">                                        <span class="keyword">if</span> (!transactionManager.isSendToPartitionAllowed(tp))</div><div class="line">                                            <span class="keyword">break</span>;</div><div class="line"></div><div class="line">                                        producerIdAndEpoch = transactionManager.producerIdAndEpoch();</div><div class="line">                                        <span class="keyword">if</span> (!producerIdAndEpoch.isValid()) <span class="comment">//note: pid 是否有效</span></div><div class="line">                                            <span class="comment">// we cannot send the batch until we have refreshed the producer id</span></div><div class="line">                                            <span class="keyword">break</span>;</div><div class="line"></div><div class="line">                                        isTransactional = transactionManager.isTransactional();</div><div class="line"></div><div class="line">                                        <span class="keyword">if</span> (!first.hasSequence() &amp;&amp; transactionManager.hasUnresolvedSequence(first.topicPartition))</div><div class="line">                                            <span class="comment">//note: 当前这个 topic-partition 的数据出现过超时,不能发送,如果是新的 batch 数据直接跳过（没有 seq  number 信息）</span></div><div class="line">                                            <span class="comment">// Don't drain any new batches while the state of previous sequence numbers</span></div><div class="line">                                            <span class="comment">// is unknown. The previous batches would be unknown if they were aborted</span></div><div class="line">                                            <span class="comment">// on the client after being sent to the broker at least once.</span></div><div class="line">                                            <span class="keyword">break</span>;</div><div class="line"></div><div class="line">                                        <span class="keyword">int</span> firstInFlightSequence = transactionManager.firstInFlightSequence(first.topicPartition);</div><div class="line">                                        <span class="keyword">if</span> (firstInFlightSequence != RecordBatch.NO_SEQUENCE &amp;&amp; first.hasSequence()</div><div class="line">                                                &amp;&amp; first.baseSequence() != firstInFlightSequence)</div><div class="line">                                            <span class="comment">//note: 重试操作（seq number 不为0）,如果这个 batch 的 baseSequence 与 in-flight</span></div><div class="line">                                            <span class="comment">//note: queue 中第一个 request batch 的 baseSequence不同的话（证明它前面还有请求未成功）,</span></div><div class="line">                                            <span class="comment">//note: 会等待下次循环再判断, 最坏的情况下会导致 in-flight request 为1（只影响这个 partition）</span></div><div class="line">                                            <span class="comment">//note: 这种情况下,继续发送这个是没有意义的,因为幂等性时保证顺序的,只有前面的都成功,后面的再发送才有意义</span></div><div class="line">                                            <span class="comment">//note: 这里是 break,相当于在这次发送中直接跳过了这个 topic-partition 的发送</span></div><div class="line">                                            <span class="comment">// If the queued batch already has an assigned sequence, then it is being</span></div><div class="line">                                            <span class="comment">// retried. In this case, we wait until the next immediate batch is ready</span></div><div class="line">                                            <span class="comment">// and drain that. We only move on when the next in line batch is complete (either successfully</span></div><div class="line">                                            <span class="comment">// or due to a fatal broker error). This effectively reduces our</span></div><div class="line">                                            <span class="comment">// in flight request count to 1.</span></div><div class="line">                                            <span class="keyword">break</span>;</div><div class="line">                                    &#125;</div><div class="line"></div><div class="line">                                    ProducerBatch batch = deque.pollFirst();</div><div class="line">                                    <span class="keyword">if</span> (producerIdAndEpoch != <span class="keyword">null</span> &amp;&amp; !batch.hasSequence()) &#123;<span class="comment">//note: batch 的相关信息（seq id）是在这里设置的</span></div><div class="line">                                        <span class="comment">//note: 这个 batch 还没有 seq number 信息</span></div><div class="line">                                        <span class="comment">// If the batch already has an assigned sequence, then we should not change the producer id and</span></div><div class="line">                                        <span class="comment">// sequence number, since this may introduce duplicates. In particular,</span></div><div class="line">                                        <span class="comment">// the previous attempt may actually have been accepted, and if we change</span></div><div class="line">                                        <span class="comment">// the producer id and sequence here, this attempt will also be accepted,</span></div><div class="line">                                        <span class="comment">// causing a duplicate.</span></div><div class="line">                                        <span class="comment">//</span></div><div class="line">                                        <span class="comment">// Additionally, we update the next sequence number bound for the partition,</span></div><div class="line">                                        <span class="comment">// and also have the transaction manager track the batch so as to ensure</span></div><div class="line">                                        <span class="comment">// that sequence ordering is maintained even if we receive out of order</span></div><div class="line">                                        <span class="comment">// responses.</span></div><div class="line">                                        <span class="comment">//note: 给这个 batch 设置相应的 pid、seq id 等信息</span></div><div class="line">                                        batch.setProducerState(producerIdAndEpoch, transactionManager.sequenceNumber(batch.topicPartition), isTransactional);</div><div class="line">                                        transactionManager.incrementSequenceNumber(batch.topicPartition, batch.recordCount); <span class="comment">//note: 增加 partition 对应的下一个 seq id 值</span></div><div class="line">                                        log.debug(<span class="string">"Assigned producerId &#123;&#125; and producerEpoch &#123;&#125; to batch with base sequence "</span> +</div><div class="line">                                                        <span class="string">"&#123;&#125; being sent to partition &#123;&#125;"</span>, producerIdAndEpoch.producerId,</div><div class="line">                                                producerIdAndEpoch.epoch, batch.baseSequence(), tp);</div><div class="line"></div><div class="line">                                        transactionManager.addInFlightBatch(batch);</div><div class="line">                                    &#125;</div><div class="line">                                    batch.close();</div><div class="line">                                    size += batch.records().sizeInBytes();</div><div class="line">                                    ready.add(batch);</div><div class="line">                                    batch.drained(now);</div><div class="line">                                &#125;</div><div class="line">                            &#125;</div><div class="line">                        &#125;</div><div class="line">                    &#125;</div><div class="line">                &#125;</div><div class="line">            &#125;</div><div class="line">            <span class="keyword">this</span>.drainIndex = (<span class="keyword">this</span>.drainIndex + <span class="number">1</span>) % parts.size();</div><div class="line">        &#125; <span class="keyword">while</span> (start != drainIndex);</div><div class="line">        batches.put(node.id(), ready);</div><div class="line">    &#125;</div><div class="line">    <span class="keyword">return</span> batches;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h3 id="幂等性时-Server-端如何处理-ProduceRequest-请求"><a href="#幂等性时-Server-端如何处理-ProduceRequest-请求" class="headerlink" title="幂等性时 Server 端如何处理 ProduceRequest 请求"></a>幂等性时 Server 端如何处理 ProduceRequest 请求</h3><p>如前面途中所示，当 Broker 收到 ProduceRequest 请求之后，会通过 <code>handleProduceRequest()</code> 做相应的处理，其处理流程如下（这里只讲述关于幂等性相关的内容）：</p>
<ol>
<li>如果请求是事务请求，检查是否对 TXN.id 有 Write 权限，没有的话返回 TRANSACTIONAL_ID_AUTHORIZATION_FAILED；</li>
<li>如果请求设置了幂等性，检查是否对 ClusterResource 有 IdempotentWrite 权限，没有的话返回 CLUSTER_AUTHORIZATION_FAILED；</li>
<li>验证对 topic 是否有 Write 权限以及 Topic 是否存在，否则返回 TOPIC_AUTHORIZATION_FAILED 或 UNKNOWN_TOPIC_OR_PARTITION 异常；</li>
<li>检查是否有 PID 信息，没有的话走正常的写入流程；</li>
<li>LOG 对象会在 <code>analyzeAndValidateProducerState()</code> 方法先根据 batch 的 sequence number 信息检查这个 batch 是否重复（server 端会缓存 PID 对应这个 Topic-Partition 的最近5个 batch 信息），如果有重复，这里当做写入成功返回（不更新 LOG 对象中相应的状态信息，比如这个 replica 的 the end offset 等）；</li>
<li>有了 PID 信息，并且不是重复 batch 时，在更新 producer 信息时，会做以下校验：<ol>
<li>检查该 PID 是否已经缓存中存在（主要是在 ProducerStateManager 对象中检查）；</li>
<li>如果不存在，那么判断 sequence number 是否 从0 开始，是的话，在缓存中记录 PID 的 meta（PID，epoch， sequence number），并执行写入操作，否则返回 UnknownProducerIdException（PID 在 server 端已经过期或者这个 PID 写的数据都已经过期了，但是 Client 还在接着上次的 sequence number 发送数据）；</li>
<li>如果该 PID 存在，先检查 PID epoch 与 server 端记录的是否相同；</li>
<li>如果不同并且 sequence number 不从 0 开始，那么返回 OutOfOrderSequenceException 异常；</li>
<li>如果不同并且 sequence number 从 0 开始，那么正常写入；</li>
<li>如果相同，那么根据缓存中记录的最近一次 sequence number（currentLastSeq）检查是否为连续（会区分为 0、Int.MaxValue 等情况），不连续的情况下返回 OutOfOrderSequenceException 异常。</li>
</ol>
</li>
<li>下面与正常写入相同。</li>
</ol>
<p>幂等性时，Broker 在处理 ProduceRequest 请求时，多了一些校验操作，这里重点看一下其中一些重要实现，先看下 <code>analyzeAndValidateProducerState()</code> 方法的实现，如下所示：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">analyzeAndValidateProducerState</span></span>(records: <span class="type">MemoryRecords</span>, isFromClient: <span class="type">Boolean</span>): (mutable.<span class="type">Map</span>[<span class="type">Long</span>, <span class="type">ProducerAppendInfo</span>], <span class="type">List</span>[<span class="type">CompletedTxn</span>], <span class="type">Option</span>[<span class="type">BatchMetadata</span>]) = &#123;</div><div class="line">  <span class="keyword">val</span> updatedProducers = mutable.<span class="type">Map</span>.empty[<span class="type">Long</span>, <span class="type">ProducerAppendInfo</span>]</div><div class="line">  <span class="keyword">val</span> completedTxns = <span class="type">ListBuffer</span>.empty[<span class="type">CompletedTxn</span>]</div><div class="line">  <span class="keyword">for</span> (batch &lt;- records.batches.asScala <span class="keyword">if</span> batch.hasProducerId) &#123; <span class="comment">//note: 有 pid 时,才会做相应的判断</span></div><div class="line">    <span class="keyword">val</span> maybeLastEntry = producerStateManager.lastEntry(batch.producerId)</div><div class="line"></div><div class="line">    <span class="comment">// if this is a client produce request, there will be up to 5 batches which could have been duplicated.</span></div><div class="line">    <span class="comment">// If we find a duplicate, we return the metadata of the appended batch to the client.</span></div><div class="line">    <span class="keyword">if</span> (isFromClient) &#123;</div><div class="line">      maybeLastEntry.flatMap(_.findDuplicateBatch(batch)).foreach &#123; duplicate =&gt;</div><div class="line">        <span class="keyword">return</span> (updatedProducers, completedTxns.toList, <span class="type">Some</span>(duplicate)) <span class="comment">//note: 如果这个 batch 已经收到过，这里直接返回</span></div><div class="line">      &#125;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="keyword">val</span> maybeCompletedTxn = updateProducers(batch, updatedProducers, isFromClient = isFromClient) <span class="comment">//note: 这里</span></div><div class="line">    maybeCompletedTxn.foreach(completedTxns += _)</div><div class="line">  &#125;</div><div class="line">  (updatedProducers, completedTxns.toList, <span class="type">None</span>)</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>如果这个 batch 有 PID 信息，会首先检查这个 batch 是否为重复的 batch 数据，其实现如下，batchMetadata 会缓存最新 5个 batch 的数据（如果超过5个，添加时会进行删除，这个也是幂等性要求 MAX_IN_FLIGHT_REQUESTS_PER_CONNECTION 小于等于5 的原因，与这个值的设置有关），根据 batchMetadata 缓存的 batch 数据来判断这个 batch 是否为重复的数据。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">findDuplicateBatch</span></span>(batch: <span class="type">RecordBatch</span>): <span class="type">Option</span>[<span class="type">BatchMetadata</span>] = &#123;</div><div class="line">  <span class="keyword">if</span> (batch.producerEpoch != producerEpoch)</div><div class="line">     <span class="type">None</span></div><div class="line">  <span class="keyword">else</span></div><div class="line">    batchWithSequenceRange(batch.baseSequence, batch.lastSequence)</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="comment">// Return the batch metadata of the cached batch having the exact sequence range, if any.</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">batchWithSequenceRange</span></span>(firstSeq: <span class="type">Int</span>, lastSeq: <span class="type">Int</span>): <span class="type">Option</span>[<span class="type">BatchMetadata</span>] = &#123;</div><div class="line">  <span class="keyword">val</span> duplicate = batchMetadata.filter &#123; metadata =&gt;</div><div class="line">    firstSeq == metadata.firstSeq &amp;&amp; lastSeq == metadata.lastSeq</div><div class="line">  &#125;</div><div class="line">  duplicate.headOption</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">addBatchMetadata</span></span>(batch: <span class="type">BatchMetadata</span>): <span class="type">Unit</span> = &#123;</div><div class="line">  <span class="keyword">if</span> (batchMetadata.size == <span class="type">ProducerStateEntry</span>.<span class="type">NumBatchesToRetain</span>)</div><div class="line">    batchMetadata.dequeue() <span class="comment">//note: 只会保留最近 5 个 batch 的记录</span></div><div class="line">  batchMetadata.enqueue(batch) <span class="comment">//note: 添加到 batchMetadata 中记录，便于后续根据 seq id 判断是否重复</span></div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>如果 batch 不是重复的数据，<code>analyzeAndValidateProducerState()</code> 会通过 <code>updateProducers()</code> 更新 producer 的相应记录，在更新的过程中，会做一步校验，校验方法如下所示：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//note: 检查 seq number</span></div><div class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">checkSequence</span></span>(producerEpoch: <span class="type">Short</span>, appendFirstSeq: <span class="type">Int</span>): <span class="type">Unit</span> = &#123;</div><div class="line">  <span class="keyword">if</span> (producerEpoch != updatedEntry.producerEpoch) &#123; <span class="comment">//note: epoch 不同时</span></div><div class="line">    <span class="keyword">if</span> (appendFirstSeq != <span class="number">0</span>) &#123; <span class="comment">//note: 此时要求 seq number 必须从0开始（如果不是的话，pid 可能是新建的或者 PID 在 Server 端已经过期）</span></div><div class="line">      <span class="comment">//note: pid 已经过期（updatedEntry.producerEpoch 不是-1，证明时原来的 pid 过期了）</span></div><div class="line">      <span class="keyword">if</span> (updatedEntry.producerEpoch != <span class="type">RecordBatch</span>.<span class="type">NO_PRODUCER_EPOCH</span>) &#123;</div><div class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">OutOfOrderSequenceException</span>(<span class="string">s"Invalid sequence number for new epoch: <span class="subst">$producerEpoch</span> "</span> +</div><div class="line">          <span class="string">s"(request epoch), <span class="subst">$appendFirstSeq</span> (seq. number)"</span>)</div><div class="line">      &#125; <span class="keyword">else</span> &#123; <span class="comment">//note: pid 已经过期（updatedEntry.producerEpoch 为-1，证明 server 端 meta 新建的，PID 在 server 端已经过期，client 还在接着上次的 seq 发数据）</span></div><div class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">UnknownProducerIdException</span>(<span class="string">s"Found no record of producerId=<span class="subst">$producerId</span> on the broker. It is possible "</span> +</div><div class="line">          <span class="string">s"that the last message with t（）he producerId=<span class="subst">$producerId</span> has been removed due to hitting the retention limit."</span>)</div><div class="line">      &#125;</div><div class="line">    &#125;</div><div class="line">  &#125; <span class="keyword">else</span> &#123;</div><div class="line">    <span class="keyword">val</span> currentLastSeq = <span class="keyword">if</span> (!updatedEntry.isEmpty)</div><div class="line">      updatedEntry.lastSeq</div><div class="line">    <span class="keyword">else</span> <span class="keyword">if</span> (producerEpoch == currentEntry.producerEpoch)</div><div class="line">      currentEntry.lastSeq</div><div class="line">    <span class="keyword">else</span></div><div class="line">      <span class="type">RecordBatch</span>.<span class="type">NO_SEQUENCE</span></div><div class="line"></div><div class="line">    <span class="keyword">if</span> (currentLastSeq == <span class="type">RecordBatch</span>.<span class="type">NO_SEQUENCE</span> &amp;&amp; appendFirstSeq != <span class="number">0</span>) &#123;</div><div class="line">      <span class="comment">//note: 此时期望的 seq number 是从 0 开始,因为 currentLastSeq 是 -1,也就意味着这个 pid 还没有写入过数据</span></div><div class="line">      <span class="comment">// the epoch was bumped by a control record, so we expect the sequence number to be reset</span></div><div class="line">      <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">OutOfOrderSequenceException</span>(<span class="string">s"Out of order sequence number for producerId <span class="subst">$producerId</span>: found <span class="subst">$appendFirstSeq</span> "</span> +</div><div class="line">        <span class="string">s"(incoming seq. number), but expected 0"</span>)</div><div class="line">    &#125; <span class="keyword">else</span> <span class="keyword">if</span> (!inSequence(currentLastSeq, appendFirstSeq)) &#123;</div><div class="line">      <span class="comment">//note: 判断是否连续</span></div><div class="line">      <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">OutOfOrderSequenceException</span>(<span class="string">s"Out of order sequence number for producerId <span class="subst">$producerId</span>: <span class="subst">$appendFirstSeq</span> "</span> +</div><div class="line">        <span class="string">s"(incoming seq. number), <span class="subst">$currentLastSeq</span> (current end sequence number)"</span>)</div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>其校验逻辑如前面流程中所述。</p>
<h2 id="小思考"><a href="#小思考" class="headerlink" title="小思考"></a>小思考</h2><p>这里主要思考两个问题：</p>
<ol>
<li>Producer 在设置幂等性时，为什么要求 MAX_IN_FLIGHT_REQUESTS_PER_CONNECTION 小于等于 5，如果设置大于 5（不考虑 Producer 端参数校验的报错），会带来什么后果？</li>
<li>Producer 在设置幂等性时，如果我们设置 MAX_IN_FLIGHT_REQUESTS_PER_CONNECTION 大于 1，那么是否可以保证有序，如果可以，是怎么做到的？</li>
</ol>
<p>先说一下结论，问题 1 的这个设置要求其实上面分析的时候已经讲述过了，主要跟 server 端只会缓存最近 5 个 batch 的机制有关；问题 2，即使 MAX_IN_FLIGHT_REQUESTS_PER_CONNECTION 大于 1，幂等性时依然可以做到有序，下面来详细分析一下这两个问题。</p>
<h3 id="为什么要求-MAX-IN-FLIGHT-REQUESTS-PER-CONNECTION-小于等于5"><a href="#为什么要求-MAX-IN-FLIGHT-REQUESTS-PER-CONNECTION-小于等于5" class="headerlink" title="为什么要求 MAX_IN_FLIGHT_REQUESTS_PER_CONNECTION 小于等于5"></a>为什么要求 MAX_IN_FLIGHT_REQUESTS_PER_CONNECTION 小于等于5</h3><p>其实这里，要求 MAX_IN_FLIGHT_REQUESTS_PER_CONNECTION 小于等于 5 的主要原因是：Server 端的 ProducerStateManager 实例会缓存每个 PID 在每个 Topic-Partition 上发送的最近 5 个batch 数据（这个 5 是写死的，至于为什么是 5，可能跟经验有关，当不设置幂等性时，当这个设置为 5 时，性能相对来说较高，社区是有一个相关测试文档，忘记在哪了），如果超过 5，ProducerStateManager 就会将最旧的 batch 数据清除。</p>
<p>假设应用将 MAX_IN_FLIGHT_REQUESTS_PER_CONNECTION 设置为 6，假设发送的请求顺序是 1、2、3、4、5、6，这时候 server 端只能缓存 2、3、4、5、6 请求对应的 batch 数据，这时候假设请求 1 发送失败，需要重试，当重试的请求发送过来后，首先先检查是否为重复的 batch，这时候检查的结果是否，之后会开始 check 其 sequence number 值，这时候只会返回一个 OutOfOrderSequenceException 异常，client 在收到这个异常后，会再次进行重试，直到超过最大重试次数或者超时，这样不但会影响 Producer 性能，还可能给 Server 带来压力（相当于client 狂发错误请求）。</p>
<p>那有没有更好的方案呢？我认为是有的，那就是对于 OutOfOrderSequenceException 异常，再进行细分，区分这个 sequence number 是大于 nextSeq （期望的下次 sequence number  值）还是小于 nextSeq，如果是小于，那么肯定是重复的数据。</p>
<h3 id="当-MAX-IN-FLIGHT-REQUESTS-PER-CONNECTION-配置大于1时，是否保证有序"><a href="#当-MAX-IN-FLIGHT-REQUESTS-PER-CONNECTION-配置大于1时，是否保证有序" class="headerlink" title="当 MAX_IN_FLIGHT_REQUESTS_PER_CONNECTION 配置大于1时，是否保证有序"></a>当 MAX_IN_FLIGHT_REQUESTS_PER_CONNECTION 配置大于1时，是否保证有序</h3><p>先来分析一下，在什么情况下 Producer 会出现乱序的问题？没有幂等性时，乱序的问题是在重试时出现的，举个例子：client 依然发送了 6 个请求 1、2、3、4、5、6（它们分别对应了一个 batch），这 6 个请求只有 2-6 成功 ack 了，1 失败了，这时候需要重试，重试时就会把 batch 1 的数据添加到待发送的数据列队中），那么下次再发送时，batch 1 的数据将会被发送，这时候数据就已经出现了乱序，因为 batch 1 的数据已经晚于了 batch 2-6。</p>
<p>当 MAX_IN_FLIGHT_REQUESTS_PER_CONNECTION 设置为 1 时，是可以解决这个为题，因为同时只允许一个请求正在发送，只有当前的请求发送完成（成功 ack 后），才能继续下一条请求的发送，类似单线程处理这种模式，每次请求发送时都会等待上次的完成，效率非常差，但是可以解决乱序的问题（当然这里有序只是针对单 client 情况，多 client 并发写是无法做到的）。</p>
<p>系统能提供的方案，基本上就是有序性与性能之间二选一，无法做到兼容，实际上系统出现请求重试的几率是很小的（一般都是网络问题触发的），可能连 0.1% 的时间都不到，但是就是为了这 0.1% 时间都不到的情况，应用需要牺牲性能问题来解决，在大数据场景下，我们是希望有更友好的方式来解决这个问题。简单来说，就是当出现重试时，max-in-flight-request 可以动态减少到 1，在正常情况下还是按 5 （5是举例说明）来处理，这有点类似于分布式系统 CAP 理论中关于 P 的考虑，当出现问题时，可以容忍性能变差，但是其他的情况下，我们希望的是能拥有原来的性能，而不是一刀切。令人高兴的，在 Kafka 2.0.0 版本中，如果 Producer 开始了幂等性，Kafka 是可以做到这一点的，如果不开启幂等性，是无法做到的，因为它的实现是依赖了 sequence number。</p>
<p>当请求出现重试时，batch 会重新添加到队列中，这时候是根据 sequence number 添加到队列的合适位置（有些 batch 如果还没有 sequence number，那么就保持其相对位置不变），也就是队列中排在这个 batch 前面的 batch，其 sequence number 都比这个 batch 的 sequence number 小，其实现如下，这个方法保证了在重试时，其 batch 会被放到合适的位置：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/**</span></div><div class="line"> * Re-enqueue the given record batch in the accumulator to retry</div><div class="line"> */</div><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">reenqueue</span><span class="params">(ProducerBatch batch, <span class="keyword">long</span> now)</span> </span>&#123;</div><div class="line">    batch.reenqueued(now); <span class="comment">//note: 重试,更新相应的 meta</span></div><div class="line">    Deque&lt;ProducerBatch&gt; deque = getOrCreateDeque(batch.topicPartition);</div><div class="line">    <span class="keyword">synchronized</span> (deque) &#123;</div><div class="line">        <span class="keyword">if</span> (transactionManager != <span class="keyword">null</span>)</div><div class="line">            insertInSequenceOrder(deque, batch); <span class="comment">//note: 将 batch 添加到队列的合适位置（根据 seq num 信息）</span></div><div class="line">        <span class="keyword">else</span></div><div class="line">            deque.addFirst(batch);</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>另外 Sender 在发送请求时，会首先通过 RecordAccumulator 的 <code>drain()</code> 方法获取其发送的数据，在遍历 Topic-Partition 对应的 queue 中的 batch 时，如果发现 batch 已经有了 sequence number 的话，则证明这个 batch 是重试的 batch，因为没有重试的 batch 其 sequence number 还没有设置，这时候会做一个判断，会等待其 in-flight-requests 中请求发送完成，才允许再次发送这个 Topic-Partition 的数据，其判断实现如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//note: 获取 inFlightBatches 中第一个 batch 的 baseSequence, inFlightBatches 为 null 的话返回 RecordBatch.NO_SEQUENCE</span></div><div class="line"><span class="keyword">int</span> firstInFlightSequence = transactionManager.firstInFlightSequence(first.topicPartition);</div><div class="line"><span class="keyword">if</span> (firstInFlightSequence != RecordBatch.NO_SEQUENCE &amp;&amp; first.hasSequence()</div><div class="line">        &amp;&amp; first.baseSequence() != firstInFlightSequence)</div><div class="line">    <span class="comment">//note: 重试操作（seq number 不为0）,如果这个 batch 的 baseSequence 与 in-flight</span></div><div class="line">    <span class="comment">//note: queue 中第一个 request batch 的 baseSequence不同的话（证明它前面还有请求未成功）,</span></div><div class="line">    <span class="comment">//note: 会等待下次循环再判断, 最坏的情况下会导致 in-flight request 为1（只影响这个 partition）</span></div><div class="line">    <span class="comment">//note: 这种情况下,继续发送这个是没有意义的,因为幂等性时保证顺序的,只有前面的都成功,后面的再发送才有意义</span></div><div class="line">    <span class="comment">//note: 这里是 break,相当于在这次发送中直接跳过了这个 topic-partition 的发送</span></div><div class="line">    <span class="comment">// If the queued batch already has an assigned sequence, then it is being</span></div><div class="line">    <span class="comment">// retried. In this case, we wait until the next immediate batch is ready</span></div><div class="line">    <span class="comment">// and drain that. We only move on when the next in line batch is complete (either successfully</span></div><div class="line">    <span class="comment">// or due to a fatal broker error). This effectively reduces our</span></div><div class="line">    <span class="comment">// in flight request count to 1.</span></div><div class="line">    <span class="keyword">break</span>;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>仅有 client 端这两个机制还不够，Server 端在处理 ProduceRequest 请求时，还会检查 batch 的 sequence number 值，它会要求这个值必须是连续的，如果不连续都会返回异常，Client 会进行相应的重试，举个栗子：假设 Client 发送的请求顺序是 1、2、3、4、5（分别对应了一个 batch），如果中间的请求 2 出现了异常，那么会导致 3、4、5 都返回异常进行重试（因为 sequence number 不连续），也就是说此时 2、3、4、5 都会进行重试操作添加到对应的 queue 中。</p>
<p>Producer 的 TransactionManager 实例的 inflightBatchesBySequence 成员变量会维护这个 Topic-Partition 与目前正在发送的 batch 的对应关系（通过 <code>addInFlightBatch()</code> 方法添加 batch 记录），只有这个 batch 成功 ack 后，才会通过 <code>removeInFlightBatch()</code> 方法将这个 batch 从 inflightBatchesBySequence 中移除。接着前面的例子，此时 inflightBatchesBySequence 中还有 2、3、4、5 这几个 batch（有顺序的，2 在前面），根据前面的 RecordAccumulator 的 <code>drain()</code> 方法可以知道只有这个 Topic-Partition 下次要发送的 batch 是 batch 2（跟 transactionManager 的这个 <code>firstInFlightSequence()</code> 方法获取 inFlightBatches 中第一个 batch 的 baseSequence 来判断） 时，才可以发送，否则会直接 break，跳过这个 Topic-Partition 的数据发送。这里相当于有一个等待，等待 batch 2 重新加入到 queue 中，才可以发送，不能跳过 batch 2，直接重试 batch 3、4、5，这是不允许的。</p>
<p>简单来说，其实现机制概括为：</p>
<ol>
<li>Server 端验证 batch 的 sequence number 值，不连续时，直接返回异常；</li>
<li>Client 端请求重试时，batch 在 reenqueue 时会根据 sequence number 值放到合适的位置（有序保证之一）；</li>
<li>Sender 线程发送时，在遍历 queue 中的 batch 时，会检查这个 batch 是否是重试的 batch，如果是的话，只有这个 batch 是最旧的那个需要重试的 batch，才允许发送，否则本次发送跳过这个 Topic-Partition 数据的发送等待下次发送。</li>
</ol>
<hr>
<p>参考：</p>
<ol>
<li><a href="https://docs.google.com/document/d/11Jqy_GjUGtdXJK94XGsEIK7CP1SnQGdp2eF0wSw9ra8/edit" target="_blank" rel="external">Exactly Once Delivery and Transactional Messaging in Kafka</a>；</li>
<li><a href="https://cwiki.apache.org/confluence/display/KAFKA/Idempotent+Producer" target="_blank" rel="external">Idempotent Producer</a>；</li>
</ol>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[BookKeeper 集群搭建及使用]]></title>
      <url>http://matt33.com/2018/10/19/bk-cluster-install-and-use/</url>
      <content type="html"><![CDATA[<p>随着 Apache Pulsar 成为 Apache 的顶级开源项目，其存储层的解决方案 Apache BookKeeper 再次受到业界广泛关注。BookKeeper 在 Pulsar 之前也有很多成功的应用，比如使用 BookKeeper 实现了 HDFS NameNode 的 HA 机制（可能大部分公司使用的还是 Quorum Journal Manage 方案）、Twitter 开源的 DistributedLog 系统（可参考<a href="http://www.infoq.com/cn/news/2016/05/Twitter-Github-DistributedLog" target="_blank" rel="external">Twitter开源分布式高性能日志复制服务</a>），BookKeeper 作为一个高扩展、强容错、低延迟的存储服务（A scalable, fault-tolerant, and low-latency storage service optimized for real-time workloads），它相当于把底层的存储层系统服务化（BookKeeper 是更底层的存储服务，类似于 Kafka 的存储层）。这样可以使得依赖于 BookKeeper 实现的分布式存储系统（包括分布式消息队列）在设计时可以只关注其应用层和功能层的内容，存储层比较难解决的问题像一致性、容错等，BookKeeper 已经实现了，从这个层面看，BookKeeper 确实解决业内的一些问题，而且 BookKeeper （Ledger 化，Ledger 相当于 Kafka segment）天生适合云上部署，未来还是有很大潜力的。近段对 BookKeeper 做了一些相应的调研，做了一些总结，本文将会主要从集群部署和使用角度来介绍一下 Apache BookKeeper，后面准备再写一篇文章来深入讲述其架构设计及实现原理。</p>
<h2 id="BookKeeper-简介"><a href="#BookKeeper-简介" class="headerlink" title="BookKeeper 简介"></a>BookKeeper 简介</h2><p>这里先对 BookKeeper 的基本概念做一下介绍，下图是 BookKeeper 的架构图（图片来自 <a href="https://www.slideshare.net/streamlio/introduction-to-apache-bookkeeper-distributed-storage?qid=3cbd6bbf-9e04-4e38-9ab6-4619e4d8f61e&amp;v=&amp;b=&amp;from_search=1" target="_blank" rel="external">Introduction to Apache BookKeeper</a>）：</p>
<p><img src="/images/bookkeeper/bookkeeper.png" alt="Apache BookKeeper 架构图"></p>
<p>在 BookKeeper 中节点（Server）被称作 Bookie（类似于 Kafka 中 Broker，HDFS 中的 DN，但是 BookKeeper 没有 Master 节点，它是典型 Slave/Slave 架构），数据在 Bookie 上以 Ledger 的形式存储（类似 Kafka 中的 Segment，HDFS 中的 Block）， BookKeeper 相关的基本概念如下：</p>
<ol>
<li>Cluster: 所有的 Bookie 组成一个集群（连接到同一个 zk 地址的 Bookie 集合）；</li>
<li>Bookie：BookKeeper 的存储节点，也即 Server 节点；</li>
<li>Ledger：Ledger 是对一个 log 文件的抽象，它本质上是由一系列 Entry （类似与 Kafka 每条 msg）组成的，client 在向 BookKeeper 写数据时也是往 Ledger 中写的；</li>
<li>Entry：entry 本质上就是一条数据，它会有一个 id 做标识；</li>
<li>Journal: Write ahead log，数据是先写到 Journal 中，这个也是 BookKeeper 读写分离实现机制的一部分，后续会详细分析；</li>
<li>Ensemble: Set of Bookies across which a ledger is striped，一个 Ledger 所涉及的 Bookie 集合，初始化 Ledger 时，需要指定这个 Ledger 可以在几台 Bookie 上存储；</li>
<li>Write Quorum Size: Number of replicas，要写入的副本数；</li>
<li>Ack Quorum Size: Number of responses needed before client’s write is satisfied，当这么多副本写入成功后才会向 client 返回成功，比如副本数设置了 3，这个设置了2，client 会同时向三副本写入数据，当收到两个成功响应后，会认为数据已经写入成功；</li>
<li>LAC: Last Add Confirmed，Ledger 中已经确认的最近一条数据的 entry id。</li>
</ol>
<h2 id="BookKeeper-集群搭建"><a href="#BookKeeper-集群搭建" class="headerlink" title="BookKeeper 集群搭建"></a>BookKeeper 集群搭建</h2><p>关于 BookKeeper 集群的搭建可以参考 <a href="https://bookkeeper.apache.org/docs/4.8.0/deployment/manual/#starting-up-bookies" target="_blank" rel="external">Apache BookKeeper Manual deployment</a> 这篇文章。</p>
<h3 id="集群搭建前准备"><a href="#集群搭建前准备" class="headerlink" title="集群搭建前准备"></a>集群搭建前准备</h3><p>BookKeeper 集群搭建需要：</p>
<ol>
<li>ZooKeeper 集群；</li>
<li>一些 Bookie 节点（在集群的模式下最好是选取三台）；</li>
<li>JDK 版本要求是 JDK8；</li>
</ol>
<p>这里先看下 BookKeeper 的目录结构，跟其他分布式系统也类似，命令在 bin 目录下，配置文件在 conf 目录下，lib 是其依赖的相关 jar 包，如下所示：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">[matt@XXX2 bookkeeper]$ ll</div><div class="line">total 64</div><div class="line">drwxr-xr-x 2 matt matt  4096 Sep 20 18:35 bin</div><div class="line">drwxr-xr-x 2 matt matt  4096 Sep 20 18:35 conf</div><div class="line">drwxrwxr-x 9 matt matt  4096 Oct  9 21:41 deps</div><div class="line">drwxrwxr-x 2 matt matt 12288 Oct  9 21:41 lib</div><div class="line">-rw-r--r-- 1 matt matt 24184 Sep 20 18:35 LICENSE</div><div class="line">-rw-r--r-- 1 matt matt  5114 Sep 20 18:35 NOTICE</div><div class="line">-rw-r--r-- 1 matt matt  4267 Sep 20 18:35 README.md</div></pre></td></tr></table></figure>
<p>bin 目录下提供了 BookKeeper 相应的操作命令，这里用的命令主要是 <code>bin/bookkeeper*</code>（<code>bookkeeper-daemon.sh</code> 可以让 Bookie 进程在后台自动运行），可以在 <code>bin/common.sh</code> 配置一些通用的配置（比如 JAVA_HOME），关于 bookkeeper 命令的使用方法见 <a href="https://bookkeeper.apache.org/docs/4.8.0/reference/cli/#bookkeeper" target="_blank" rel="external">bookkeeper cli</a></p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">[matt@XXX2 bookkeeper]$ ll bin/</div><div class="line">total 56</div><div class="line">-rwxr-xr-x 1 matt matt 2319 Sep 20 18:35 bkctl</div><div class="line">-rwxr-xr-x 1 matt matt 5874 Sep 20 18:35 bookkeeper</div><div class="line">-rwxr-xr-x 1 matt matt 2869 Sep 20 18:35 bookkeeper-cluster.sh</div><div class="line">-rwxr-xr-x 1 matt matt 4590 Sep 20 18:35 bookkeeper-daemon.sh</div><div class="line">-rwxr-xr-x 1 matt matt 7785 Sep 20 18:35 common.sh</div><div class="line">-rwxr-xr-x 1 matt matt 4575 Sep 20 18:35 dlog</div><div class="line">-rwxr-xr-x 1 matt matt 1738 Sep 20 18:35 standalone</div><div class="line">-rwxr-xr-x 1 matt matt 5128 Sep 20 18:35 standalone.docker-compose</div><div class="line">-rwxr-xr-x 1 matt matt 1854 Sep 20 18:35 standalone.process</div></pre></td></tr></table></figure>
<p>在 bookkeper 命令中，又提供了 shell 的相关命令，这里提供的命令非常丰富，可以参考 <a href="https://bookkeeper.apache.org/docs/4.8.0/reference/cli/#the-bookkeeper-shell" target="_blank" rel="external">BookKeeper Shell</a>，如下所示：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div></pre></td><td class="code"><pre><div class="line">[matt@XXX2 bookkeeper]$ bin/bookkeeper shell</div><div class="line">Usage: bookkeeper shell [-localbookie [&lt;host:port&gt;]] [-ledgeridformat &lt;hex/long/uuid&gt;] [-entryformat &lt;hex/string&gt;] [-conf configuration] &lt;<span class="built_in">command</span>&gt;</div><div class="line"><span class="built_in">where</span> <span class="built_in">command</span> is one of:</div><div class="line">       autorecovery [-enable|-disable]</div><div class="line">       bookieformat [-nonInteractive] [-force] [-deleteCookie]</div><div class="line">       bookieinfo</div><div class="line">       bookiesanity [-entries N] [-timeout N]</div><div class="line">       convert-to-db-storage</div><div class="line">       convert-to-interleaved-storage</div><div class="line">       decommissionbookie [-bookieid &lt;bookieaddress&gt;]</div><div class="line">       deleteledger -ledgerid &lt;ledgerid&gt; [-force]</div><div class="line">       <span class="built_in">help</span>         [COMMAND]</div><div class="line">       initbookie</div><div class="line">       initnewcluster</div><div class="line">       lastmark</div><div class="line">       ledger       [-m] &lt;ledger_id&gt;</div><div class="line">       ledgermetadata -ledgerid &lt;ledgerid&gt;</div><div class="line">       listbookies  [-readwrite|-readonly] [-hostnames]</div><div class="line">       listfilesondisc  [-journal|-entrylog|-index]</div><div class="line">       listledgers  [-meta] [-bookieid &lt;bookieaddress&gt;]</div><div class="line">       listunderreplicated [[-missingreplica &lt;bookieaddress&gt;] [-excludingmissingreplica &lt;bookieaddress&gt;]] [-printmissingreplica] [-printreplicationworkerid]</div><div class="line">       lostbookierecoverydelay [-get|-set &lt;value&gt;]</div><div class="line">       metaformat   [-nonInteractive] [-force]</div><div class="line">       nukeexistingcluster -zkledgersrootpath &lt;zkledgersrootpath&gt; [-instanceid &lt;instanceid&gt; | -force]</div><div class="line">       readjournal [-dir] [-msg] &lt;journal_id | journal_file_name&gt;</div><div class="line">       readledger  [-bookie &lt;address:port&gt;]  [-msg] -ledgerid &lt;ledgerid&gt; [-firstentryid &lt;firstentryid&gt; [-lastentryid &lt;lastentryid&gt;]] [-force-recovery]</div><div class="line">       readlog      [-msg] &lt;entry_log_id | entry_log_file_name&gt; [-ledgerid &lt;ledgerid&gt; [-entryid &lt;entryid&gt;]] [-startpos &lt;startEntryLogBytePos&gt; [-endpos &lt;endEntryLogBytePos&gt;]]</div><div class="line">       readlogmetadata &lt;entry_log_id | entry_log_file_name&gt;</div><div class="line">       rebuild-db-ledger-locations-index</div><div class="line">       recover [-deleteCookie] &lt;bookieSrc[:bookieSrc]&gt;</div><div class="line">       simpletest   [-ensemble N] [-writeQuorum N] [-ackQuorum N] [-numEntries N]</div><div class="line">       triggeraudit</div><div class="line">       updatecookie [-bookieId &lt;hostname|ip&gt;] [-expandstorage] [-list] [-delete &lt;force&gt;]</div><div class="line">       updateledgers -bookieId &lt;hostname|ip&gt; [-updatespersec N] [-limit N] [-verbose <span class="literal">true</span>/<span class="literal">false</span>] [-printprogress N]</div><div class="line">       whatisinstanceid</div><div class="line">       whoisauditor</div></pre></td></tr></table></figure>
<p>conf 目录下是关于 BookKeeper 的相关配置，如下所示，主要配置在 <code>bk_server.conf</code> 中，这里可以提供的配置非常多，具体可配置的参数可以参考 <a href="https://bookkeeper.apache.org/docs/4.8.0/reference/config/" target="_blank" rel="external">BookKeeper Config</a>，</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line">[matt@XXX2 bookkeeper]$ ll conf/</div><div class="line">total 84</div><div class="line">-rw-r--r-- 1 matt matt  1804 Sep 20 18:35 bk_cli_env.sh</div><div class="line">-rw-r--r-- 1 matt matt  2448 Sep 20 18:35 bkenv.sh</div><div class="line">-rwxr-xr-x 1 matt matt 42269 Sep 20 18:35 bk_server.conf</div><div class="line">-rw-r--r-- 1 matt matt  1211 Sep 20 18:35 jaas_example.conf</div><div class="line">-rw-r--r-- 1 matt matt  2311 Sep 20 18:35 <span class="built_in">log</span>4j.cli.properties</div><div class="line">-rw-r--r-- 1 matt matt  2881 Sep 20 18:35 <span class="built_in">log</span>4j.properties</div><div class="line">-rw-r--r-- 1 matt matt  1810 Sep 20 18:35 <span class="built_in">log</span>4j.shell.properties</div><div class="line">-rw-r--r-- 1 matt matt  1117 Sep 20 18:35 nettyenv.sh</div><div class="line">-rwxr-xr-x 1 matt matt  1300 Sep 20 18:35 standalone.conf</div><div class="line">-rw-r--r-- 1 matt matt  3275 Sep 20 18:35 zookeeper.conf</div><div class="line">-rw-r--r-- 1 matt matt   843 Sep 20 18:35 zookeeper.conf.dynamic</div></pre></td></tr></table></figure>
<h3 id="集群搭建"><a href="#集群搭建" class="headerlink" title="集群搭建"></a>集群搭建</h3><p>在 <a href="https://bookkeeper.apache.org/releases/" target="_blank" rel="external">Apache BookKeeper Releases</a> 中下载 BookKeeper 最新的安装包（这里以 bookkeeper-server-4.8.0-bin.tar.gz 为例）。</p>
<p>将安装包在指定目录下解压后，启动的操作分为以下几步：</p>
<ol>
<li>修改相关配置（<code>zkServers</code>、<code>bookiePort</code>、<code>journalDir</code>、<code>ledgerDir</code> 等）；</li>
<li>在相应的机器上启动 Bookie 进程（使用 <code>./bin/bookkeeper-daemon.sh start bookie</code> 启动 Bookie）；</li>
<li>当所有的 Bookie 启动完成后，随便选择一台，初始化集群 meta 信息（使用 <code>bookkeeper-server/bin/bookkeeper shell metaformat</code> 命令初始化集群的 meta 信息，这里只需要初始化一次）。</li>
</ol>
<p>如果启动成功的话（如果有异常日志，即使 Bookie 进程存在，也可能没有启动成功），启动正常的情况下，在日志中，可以看到类似下面的信息：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">2018-10-15 11:24:49,549 - INFO  [main:ComponentStarter@81] - Started component bookie-server.</div></pre></td></tr></table></figure>
<h3 id="Admin-REST-API"><a href="#Admin-REST-API" class="headerlink" title="Admin REST API"></a>Admin REST API</h3><p>BookKeeper 服务提供了相应的 Rest API，可供管理员使用，具体可以参考 <a href="https://bookkeeper.apache.org/docs/4.8.0/admin/http/" target="_blank" rel="external">BookKeeper Admin REST API</a>，如果想要使用这个功能，首先需要 Bookie 服务将 bk_server.conf 中的 <code>httpServerEnabled</code> 配置设置为 true ，相关的配置参考 <a href="https://bookkeeper.apache.org/docs/4.8.0/reference/config/#http-server-settings" target="_blank" rel="external">Http server settings</a>。</p>
<h3 id="安装时踩的坑"><a href="#安装时踩的坑" class="headerlink" title="安装时踩的坑"></a>安装时踩的坑</h3><p>在搭建 BookKeeper 集群中，并没有想象中那么顺畅，遇到了一些小问题，记录如下：</p>
<h4 id="问题1：修改配置后重新启动失败"><a href="#问题1：修改配置后重新启动失败" class="headerlink" title="问题1：修改配置后重新启动失败"></a>问题1：修改配置后重新启动失败</h4><p>在使用  <code>./bin/bookkeeper-daemon.sh  stop bookie</code> 命令关闭 Bookie 进程，当关闭完 Bookie 进程后，再次启动时，发现无法启动，报出了下面的错误：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line">2018-10-13 21:05:40,674 - ERROR [main:Main@221] - Failed to build bookie server</div><div class="line">org.apache.bookkeeper.bookie.BookieException<span class="variable">$InvalidCookieException</span>: instanceId 406a08e5-911e-4ab6-b97b-40e4a56279a8 is not matching with null</div><div class="line">	at org.apache.bookkeeper.bookie.Cookie.verifyInternal(Cookie.java:142)</div><div class="line">	at org.apache.bookkeeper.bookie.Cookie.verify(Cookie.java:147)</div><div class="line">	at org.apache.bookkeeper.bookie.Bookie.verifyAndGetMissingDirs(Bookie.java:381)</div><div class="line">	at org.apache.bookkeeper.bookie.Bookie.checkEnvironmentWithStorageExpansion(Bookie.java:444)</div><div class="line">	at org.apache.bookkeeper.bookie.Bookie.checkEnvironment(Bookie.java:262)</div><div class="line">	at org.apache.bookkeeper.bookie.Bookie.&lt;init&gt;(Bookie.java:646)</div><div class="line">	at org.apache.bookkeeper.proto.BookieServer.newBookie(BookieServer.java:133)</div><div class="line">	at org.apache.bookkeeper.proto.BookieServer.&lt;init&gt;(BookieServer.java:102)</div><div class="line">	at org.apache.bookkeeper.server.service.BookieService.&lt;init&gt;(BookieService.java:43)</div><div class="line">	at org.apache.bookkeeper.server.Main.buildBookieServer(Main.java:299)</div><div class="line">	at org.apache.bookkeeper.server.Main.doMain(Main.java:219)</div><div class="line">	at org.apache.bookkeeper.server.Main.main(Main.java:201)</div></pre></td></tr></table></figure>
<p>大概的意思就是说现在 zk 上的 instanceId 是 <code>406a08e5-911e-4ab6-b97b-40e4a56279a8</code>，而期望的 instanceId 是 null，索引因为验证失败导致进程无法启动，instanceId 是搭建集群第三步（初始化集群 meta 信息的地方）中初始化的。此时如果我们启动测试的 client 程序，会抛出以下异常，这是因为目前集群只有2台 Bookie 处在可用状态，而 ensSize 默认是 3，writeQuorumSize 是 2，ackQuorumSize 是2。在 client 的测试程序中，新建一个 Ledger 时，由于集群当前可用的 Bookie 为2，不满足相应的条件，所以抛出了一下的异常：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line">org.apache.bookkeeper.client.BKException<span class="variable">$BKNotEnoughBookiesException</span>: Not enough non-faulty bookies available</div><div class="line">	at org.apache.bookkeeper.client.SyncCallbackUtils.finish(SyncCallbackUtils.java:83)</div><div class="line">	at org.apache.bookkeeper.client.SyncCallbackUtils<span class="variable">$SyncCreateCallback</span>.createComplete(SyncCallbackUtils.java:106)</div><div class="line">	at org.apache.bookkeeper.client.LedgerCreateOp.createComplete(LedgerCreateOp.java:238)</div><div class="line">	at org.apache.bookkeeper.client.LedgerCreateOp.initiate(LedgerCreateOp.java:142)</div><div class="line">	at org.apache.bookkeeper.client.BookKeeper.asyncCreateLedger(BookKeeper.java:891)</div><div class="line">	at org.apache.bookkeeper.client.BookKeeper.createLedger(BookKeeper.java:975)</div><div class="line">	at org.apache.bookkeeper.client.BookKeeper.createLedger(BookKeeper.java:930)</div><div class="line">	at org.apache.bookkeeper.client.BookKeeper.createLedger(BookKeeper.java:911)</div><div class="line">	at com.matt.test.bookkeeper.ledger.LedgerTest.createLedgerSync(LedgerTest.java:110)</div><div class="line">	at com.matt.test.bookkeeper.ledger.LedgerTest.main(LedgerTest.java:25)</div><div class="line">Exception <span class="keyword">in</span> thread <span class="string">"main"</span> java.lang.NullPointerException</div><div class="line">	at com.matt.test.bookkeeper.ledger.LedgerTest.main(LedgerTest.java:26)</div></pre></td></tr></table></figure>
<p>关于这个 BookieException$InvalidCookieException 异常，google 了一下并没有找到相应的解决办法，所以就直接看了相应的代码，抛出异常的代码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">verifyInternal</span><span class="params">(Cookie c, <span class="keyword">boolean</span> checkIfSuperSet)</span> <span class="keyword">throws</span> BookieException.InvalidCookieException </span>&#123;</div><div class="line">    String errMsg;</div><div class="line">    <span class="keyword">if</span> (c.layoutVersion &lt; <span class="number">3</span> &amp;&amp; c.layoutVersion != layoutVersion) &#123;</div><div class="line">        errMsg = <span class="string">"Cookie is of too old version "</span> + c.layoutVersion;</div><div class="line">        LOG.error(errMsg);</div><div class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> BookieException.InvalidCookieException(errMsg);</div><div class="line">    &#125; <span class="keyword">else</span> <span class="keyword">if</span> (!(c.layoutVersion &gt;= <span class="number">3</span> &amp;&amp; c.bookieHost.equals(bookieHost)</div><div class="line">        &amp;&amp; c.journalDirs.equals(journalDirs) &amp;&amp; verifyLedgerDirs(c, checkIfSuperSet))) &#123;</div><div class="line">        errMsg = <span class="string">"Cookie ["</span> + <span class="keyword">this</span> + <span class="string">"] is not matching with ["</span> + c + <span class="string">"]"</span>;</div><div class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> BookieException.InvalidCookieException(errMsg);</div><div class="line">    &#125; <span class="keyword">else</span> <span class="keyword">if</span> ((instanceId == <span class="keyword">null</span> &amp;&amp; c.instanceId != <span class="keyword">null</span>)</div><div class="line">            || (instanceId != <span class="keyword">null</span> &amp;&amp; !instanceId.equals(c.instanceId))) &#123;</div><div class="line">        <span class="comment">// instanceId should be same in both cookies</span></div><div class="line">        errMsg = <span class="string">"instanceId "</span> + instanceId</div><div class="line">                + <span class="string">" is not matching with "</span> + c.instanceId;</div><div class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> BookieException.InvalidCookieException(errMsg); <span class="comment">// 由于 instanceId 不匹配，抛出了相应的异常</span></div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>这里可以看到的是从 zk 上拿到的 instanceId 是 <code>406a08e5-911e-4ab6-b97b-40e4a56279a8</code>，而 Cookie 实例 c 中的 instanceId 为 null，那么 这个 Cookie 是如何初始化的呢？往上追一下代码，发现是在初始化 Bookie 时，会检查一下相应的运行环境，此时会从 journalDirectories 和 ledgerDirectories 中 <code>current/VERSION</code> 中初始化相应的 Cookie 对象，由于这个台机器之前启动过，所以这个文件已经创建了，文件的内容如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">[matt@XXX2 bookkeeper]$ cat /tmp/bk-data/current/VERSION</div><div class="line">4</div><div class="line">bookieHost: &quot;XXX:3181&quot;</div><div class="line">journalDir: &quot;/tmp/bk-txn&quot;</div><div class="line">ledgerDirs: &quot;1\t/tmp/bk-data&quot;</div><div class="line">[matt@XXX2 bookkeeper]$ cat /tmp/bk-txn/current/VERSION</div><div class="line">4</div><div class="line">bookieHost: &quot;XXX:3181&quot;</div><div class="line">journalDir: &quot;/tmp/bk-txn&quot;</div><div class="line">ledgerDirs: &quot;1\t/tmp/bk-data&quot;</div></pre></td></tr></table></figure>
<p>Cookie 从文件加载相应文件，并初始化对象的实现方法如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/**</span></div><div class="line"> * Read cookie from registration manager for a given bookie &lt;i&gt;address&lt;/i&gt;.</div><div class="line"> *</div><div class="line"> * <span class="doctag">@param</span> rm registration manager</div><div class="line"> * <span class="doctag">@param</span> address bookie address</div><div class="line"> * <span class="doctag">@return</span> versioned cookie object</div><div class="line"> * <span class="doctag">@throws</span> BookieException when fail to read cookie</div><div class="line"> */</div><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> Versioned&lt;Cookie&gt; <span class="title">readFromRegistrationManager</span><span class="params">(RegistrationManager rm,</span></span></div><div class="line">                                                     BookieSocketAddress address) <span class="keyword">throws</span> BookieException &#123;</div><div class="line">    Versioned&lt;<span class="keyword">byte</span>[]&gt; cookieData = rm.readCookie(address.toString());</div><div class="line">    <span class="keyword">try</span> &#123;</div><div class="line">        <span class="keyword">try</span> (BufferedReader reader = <span class="keyword">new</span> BufferedReader(</div><div class="line">                <span class="keyword">new</span> StringReader(<span class="keyword">new</span> String(cookieData.getValue(), UTF_8)))) &#123;</div><div class="line">            Builder builder = parse(reader);</div><div class="line">            Cookie cookie = builder.build();</div><div class="line">            <span class="keyword">return</span> <span class="keyword">new</span> Versioned&lt;Cookie&gt;(cookie, cookieData.getVersion());</div><div class="line">        &#125;</div><div class="line">    &#125; <span class="keyword">catch</span> (IOException ioe) &#123;</div><div class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> InvalidCookieException(ioe);</div><div class="line">    &#125;</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">static</span> Builder <span class="title">parse</span><span class="params">(BufferedReader reader)</span> <span class="keyword">throws</span> IOException </span>&#123;</div><div class="line">    Builder cBuilder = Cookie.newBuilder();</div><div class="line">    <span class="keyword">int</span> layoutVersion = <span class="number">0</span>;</div><div class="line">    String line = reader.readLine();</div><div class="line">    <span class="keyword">if</span> (<span class="keyword">null</span> == line) &#123;</div><div class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> EOFException(<span class="string">"Exception in parsing cookie"</span>);</div><div class="line">    &#125;</div><div class="line">    <span class="keyword">try</span> &#123;</div><div class="line">        layoutVersion = Integer.parseInt(line.trim());</div><div class="line">        cBuilder.setLayoutVersion(layoutVersion);</div><div class="line">    &#125; <span class="keyword">catch</span> (NumberFormatException e) &#123;</div><div class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> IOException(<span class="string">"Invalid string '"</span> + line.trim()</div><div class="line">                + <span class="string">"', cannot parse cookie."</span>);</div><div class="line">    &#125;</div><div class="line">    <span class="keyword">if</span> (layoutVersion == <span class="number">3</span>) &#123;</div><div class="line">        cBuilder.setBookieHost(reader.readLine());</div><div class="line">        cBuilder.setJournalDirs(reader.readLine());</div><div class="line">        cBuilder.setLedgerDirs(reader.readLine());</div><div class="line">    &#125; <span class="keyword">else</span> <span class="keyword">if</span> (layoutVersion &gt;= <span class="number">4</span>) &#123; <span class="comment">//这里的版本默认为 4</span></div><div class="line">        CookieFormat.Builder cfBuilder = CookieFormat.newBuilder();</div><div class="line">        TextFormat.merge(reader, cfBuilder);</div><div class="line">        CookieFormat data = cfBuilder.build();</div><div class="line">        cBuilder.setBookieHost(data.getBookieHost());</div><div class="line">        cBuilder.setJournalDirs(data.getJournalDir());</div><div class="line">        cBuilder.setLedgerDirs(data.getLedgerDirs());</div><div class="line">        <span class="comment">// Since InstanceId is optional</span></div><div class="line">        <span class="keyword">if</span> (<span class="keyword">null</span> != data.getInstanceId() &amp;&amp; !data.getInstanceId().isEmpty()) &#123; <span class="comment">//如果文件中没有 instanceId 字段，这里就不会初始化到 Cookie 中</span></div><div class="line">            cBuilder.setInstanceId(data.getInstanceId());</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line">    <span class="keyword">return</span> cBuilder;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>解决的方法很简单，在 <code>current/VERSION</code> 文件中添加相应的 instanceId 字段后，Bookie 便可启动成功。但是这里还需要考虑的问题是：</p>
<ul>
<li>instanceId 在这里的作用是什么？instanceId 是在集群初始化时设置的，关于这个值的含义，我推测它的目的是对节点的上线做一个简单的认证，也就是说如果打算在集群中新添加一台 Bookie，需要知道当前的 instanceId 值，这样才能加入到这个集群中；</li>
<li>Bookie 服务的启动流程是什么样的？这里就需要看下代码的具体实现，追一下 Bookie 的启动流程了。</li>
</ul>
<h2 id="BookKeeper-API-使用"><a href="#BookKeeper-API-使用" class="headerlink" title="BookKeeper API 使用"></a>BookKeeper API 使用</h2><p>关于 BookKeeper API，总共提供了以下三种 API：</p>
<ol>
<li>The ledger API is a lower-level API that enables you to interact with ledgers directly，第一种是一种较为底层的 API 接口，直接与 Ledger 交互，见 <a href="https://bookkeeper.apache.org/docs/4.8.0/api/ledger-api/" target="_blank" rel="external">The Ledger API</a>；</li>
<li>The Ledger Advanced API is an advanced extension to Ledger API to provide more flexibilities to applications，第二种较高级的 API，提供了一些较高级的功能，见 <a href="https://bookkeeper.apache.org/docs/4.8.0/api/ledger-adv-apiThe Advanced Ledger API/" target="_blank" rel="external">The Advanced Ledger API</a>；</li>
<li>The DistributedLog API is a higher-level API that provides convenient abstractions，这种是关于 DistributedLog 的一些操作 API，见 <a href="https://bookkeeper.apache.org/docs/4.8.0/api/distributedlog-api/" target="_blank" rel="external">DistributedLog</a>。</li>
</ol>
<p>在这节，我们主要看下第一种的实现，会简单讲述一下第二种，第三种这里不再介绍。</p>
<h3 id="The-Ledger-API"><a href="#The-Ledger-API" class="headerlink" title="The Ledger API"></a>The Ledger API</h3><p>关于 Ledger API 基本操作主要有以下几种：</p>
<ol>
<li>创建 Ledger；</li>
<li>向 Ledger 写入数据（Entry）；</li>
<li>关闭 Ledger，Ledger 关闭后数据就不能再写入，Ledger 一旦关闭它的数据就是不可变的；</li>
<li>从 Ledger 中读取数据；</li>
<li>删除 Ledger。</li>
</ol>
<p>当然实现上述操作的前提是，需要先初始化一个 BookKeeper Client，下面开始慢慢讲述。</p>
<h4 id="初始化-BookKeeper-Client"><a href="#初始化-BookKeeper-Client" class="headerlink" title="初始化 BookKeeper Client"></a>初始化 BookKeeper Client</h4><p>BK Client 的初始化需要指定 zk 地址，BK Client 通过 zk 来连接到 BK 集群，具体实现如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// 第一种初始化 BookKeeper Client 的方法</span></div><div class="line"><span class="keyword">try</span> &#123;</div><div class="line">    String connectionString = zkAddr; <span class="comment">// For a single-node, local ZooKeeper cluster</span></div><div class="line">    BookKeeper bkClient = <span class="keyword">new</span> BookKeeper(connectionString);</div><div class="line">    logger.info(<span class="string">"BookKeeper client init success."</span>);</div><div class="line">&#125; <span class="keyword">catch</span> (InterruptedException | IOException | BKException e) &#123;</div><div class="line">    e.printStackTrace();</div><div class="line">    <span class="keyword">throw</span> <span class="keyword">new</span> RuntimeException(</div><div class="line">            <span class="string">"There is an exception throw while creating the BookKeeper client."</span>);</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="comment">// 第二种初始化 BookKeeper Client 的方法</span></div><div class="line"><span class="keyword">try</span> &#123;</div><div class="line">    ClientConfiguration config = <span class="keyword">new</span> ClientConfiguration();</div><div class="line">    config.setZkServers(zkAddr);</div><div class="line">    config.setAddEntryTimeout(<span class="number">2000</span>);</div><div class="line">    BookKeeper bkClient = <span class="keyword">new</span> BookKeeper(config);</div><div class="line">    logger.info(<span class="string">"BookKeeper client init success."</span>);</div><div class="line">&#125; <span class="keyword">catch</span> (InterruptedException | IOException | BKException e) &#123;</div><div class="line">    e.printStackTrace();</div><div class="line">    <span class="keyword">throw</span> <span class="keyword">new</span> RuntimeException(</div><div class="line">            <span class="string">"There is an exception throw while creating the BookKeeper client."</span>);</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h4 id="新建一个-Ledger"><a href="#新建一个-Ledger" class="headerlink" title="新建一个 Ledger"></a>新建一个 Ledger</h4><p>Ledger 的创建有两种，一种是同步创建，一种是异步创建（创建时需要指定相应的 password），其实现分别如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/**</span></div><div class="line"> * create the ledger, default ensemble size is 3, write quorum size is 2, ack quorum size is 2</div><div class="line"> *</div><div class="line"> * <span class="doctag">@param</span> pw password</div><div class="line"> * <span class="doctag">@return</span> LedgerHandle</div><div class="line"> */</div><div class="line"><span class="function"><span class="keyword">public</span> LedgerHandle <span class="title">createLedgerSync</span><span class="params">(String pw)</span> </span>&#123;</div><div class="line">    <span class="keyword">byte</span>[] password = pw.getBytes();</div><div class="line">    <span class="keyword">try</span> &#123;</div><div class="line">        LedgerHandle handle = bkClient.createLedger(BookKeeper.DigestType.MAC, password);</div><div class="line">        <span class="keyword">return</span> handle;</div><div class="line">    &#125; <span class="keyword">catch</span> (BKException e) &#123;</div><div class="line">        e.printStackTrace();</div><div class="line">    &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</div><div class="line">        e.printStackTrace();</div><div class="line">    &#125;</div><div class="line">    <span class="keyword">return</span> <span class="keyword">null</span>;</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="comment">/**</span></div><div class="line"> * create the ledger</div><div class="line"> *</div><div class="line"> * <span class="doctag">@param</span> pw password</div><div class="line"> */</div><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">createLedgerAsync</span><span class="params">(String pw)</span> </span>&#123;</div><div class="line"></div><div class="line">    <span class="class"><span class="keyword">class</span> <span class="title">LedgerCreationCallback</span> <span class="keyword">implements</span> <span class="title">AsyncCallback</span>.<span class="title">CreateCallback</span> </span>&#123;</div><div class="line"></div><div class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">createComplete</span><span class="params">(<span class="keyword">int</span> returnCode, LedgerHandle handle, Object ctx)</span> </span>&#123;</div><div class="line">            System.out.println(<span class="string">"Ledger successfully created"</span>);</div><div class="line">            logger.info(<span class="string">"Ledger successfully created async."</span>);</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    bkClient.asyncCreateLedger(</div><div class="line">            <span class="number">3</span>, <span class="comment">// ensSize</span></div><div class="line">            <span class="number">2</span>, <span class="comment">// writeQuorumSize and ackQuorumSize</span></div><div class="line">            BookKeeper.DigestType.MAC,</div><div class="line">            pw.getBytes(),</div><div class="line">            <span class="keyword">new</span> LedgerCreationCallback(),</div><div class="line">            <span class="string">"some context"</span></div><div class="line">    );</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>新建好 Ledger 之后，会返回一个 LedgerHandle 实例，对于 Ledger 的操作都是通过这个实例对象完成的，也可以通过 <code>LedgerHandle.getId()</code> 方法获取 Ledger 的 id，有了这个 id 就可以映射到具体的 Ledger，当需要读取数据时，通过 ledger id 初始化相应的 LedgerHandle 实例即可。</p>
<h4 id="向-Ledger-写入数据"><a href="#向-Ledger-写入数据" class="headerlink" title="向 Ledger 写入数据"></a>向 Ledger 写入数据</h4><p>有了 Ledger 对应的 LedgerHandle 实例之后，可以通过 <code>addEntry()</code> 方法直接向 Ledger 写数据，如下所示：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">long</span> <span class="title">addEntry</span><span class="params">(LedgerHandle ledgerHandle, String msg)</span> </span>&#123;</div><div class="line">    <span class="keyword">try</span> &#123;</div><div class="line">        <span class="keyword">return</span> ledgerHandle.addEntry(msg.getBytes());</div><div class="line">    &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</div><div class="line">        e.printStackTrace();</div><div class="line">    &#125; <span class="keyword">catch</span> (BKException e) &#123;</div><div class="line">        e.printStackTrace();</div><div class="line">    &#125;</div><div class="line">    <span class="keyword">return</span> -<span class="number">1</span>;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h4 id="从-Ledger-读取数据"><a href="#从-Ledger-读取数据" class="headerlink" title="从 Ledger 读取数据"></a>从 Ledger 读取数据</h4><p>从 Ledger 读取数据时，也是通过 LedgerHandle 实例的方法实现，提供了以下三种方法：</p>
<ol>
<li>指定读取的 entry.id 范围消费；</li>
<li>从某一个 entry.id 一直读取到 LAC （LastAddConfirmed，该 Ledger 中最近的已经确认的数据）位置；</li>
<li>从某一个 entry.id 一直读取到 lastEntryIdExpectedToRead 位置，该位置可以比 LAC 大，前提是需要该值已经有对应的数据；</li>
</ol>
<p>方法实现如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/**</span></div><div class="line"> * read entry from startId to endId</div><div class="line"> *</div><div class="line"> * <span class="doctag">@param</span> ledgerHandle the ledger</div><div class="line"> * <span class="doctag">@param</span> startId      start entry id</div><div class="line"> * <span class="doctag">@param</span> endId        end entry id</div><div class="line"> * <span class="doctag">@return</span> the entries, if occur exception, return null</div><div class="line"> */</div><div class="line"><span class="function"><span class="keyword">public</span> Enumeration&lt;LedgerEntry&gt; <span class="title">readEntry</span><span class="params">(LedgerHandle ledgerHandle, <span class="keyword">int</span> startId, <span class="keyword">int</span> endId)</span> </span>&#123;</div><div class="line">    <span class="keyword">try</span> &#123;</div><div class="line">        <span class="keyword">return</span> ledgerHandle.readEntries(startId, endId);</div><div class="line">    &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</div><div class="line">        e.printStackTrace();</div><div class="line">    &#125; <span class="keyword">catch</span> (BKException e) &#123;</div><div class="line">        e.printStackTrace();</div><div class="line">    &#125;</div><div class="line">    <span class="keyword">return</span> <span class="keyword">null</span>;</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="comment">/**</span></div><div class="line"> * read entry from 0 to the LAC</div><div class="line"> *</div><div class="line"> * <span class="doctag">@param</span> ledgerHandle the ledger</div><div class="line"> * <span class="doctag">@return</span> the entries, if occur exception, return null</div><div class="line"> */</div><div class="line"><span class="function"><span class="keyword">public</span> Enumeration&lt;LedgerEntry&gt; <span class="title">readEntry</span><span class="params">(LedgerHandle ledgerHandle)</span> </span>&#123;</div><div class="line">    <span class="keyword">try</span> &#123;</div><div class="line">        <span class="keyword">return</span> ledgerHandle.readEntries(<span class="number">0</span>, ledgerHandle.getLastAddConfirmed());</div><div class="line">    &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</div><div class="line">        e.printStackTrace();</div><div class="line">    &#125; <span class="keyword">catch</span> (BKException e) &#123;</div><div class="line">        e.printStackTrace();</div><div class="line">    &#125;</div><div class="line">    <span class="keyword">return</span> <span class="keyword">null</span>;</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="comment">/**</span></div><div class="line"> * read entry form 0 to lastEntryIdExpectedToRead which can larger than the LastAddConfirmed range</div><div class="line"> *</div><div class="line"> * <span class="doctag">@param</span> ledgerHandle              the handle</div><div class="line"> * <span class="doctag">@param</span> lastEntryIdExpectedToRead the last entry id</div><div class="line"> * <span class="doctag">@return</span> the entries, if occur exception, return null</div><div class="line"> */</div><div class="line"><span class="function"><span class="keyword">public</span> Enumeration&lt;LedgerEntry&gt; <span class="title">readEntry</span><span class="params">(LedgerHandle ledgerHandle,</span></span></div><div class="line">                                          <span class="keyword">long</span> lastEntryIdExpectedToRead) &#123;</div><div class="line">    <span class="keyword">try</span> &#123;</div><div class="line">        <span class="keyword">return</span> ledgerHandle.readUnconfirmedEntries(<span class="number">0</span>, lastEntryIdExpectedToRead);</div><div class="line">    &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</div><div class="line">        e.printStackTrace();</div><div class="line">    &#125; <span class="keyword">catch</span> (BKException e) &#123;</div><div class="line">        e.printStackTrace();</div><div class="line">    &#125;</div><div class="line">    <span class="keyword">return</span> <span class="keyword">null</span>;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h4 id="删除-Ledger"><a href="#删除-Ledger" class="headerlink" title="删除 Ledger"></a>删除 Ledger</h4><p>Ledger 的删除实现也很简洁，如下所示：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/**</span></div><div class="line"> * delete the ledger</div><div class="line"> *</div><div class="line"> * <span class="doctag">@param</span> ledgerId the ledger id</div><div class="line"> * <span class="doctag">@return</span> if occur exception, return false</div><div class="line"> */</div><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">deleteLedger</span><span class="params">(<span class="keyword">long</span> ledgerId)</span> </span>&#123;</div><div class="line">    <span class="keyword">try</span> &#123;</div><div class="line">        bkClient.deleteLedger(ledgerId);</div><div class="line">        <span class="keyword">return</span> <span class="keyword">true</span>;</div><div class="line">    &#125; <span class="keyword">catch</span> (Exception e) &#123;</div><div class="line">        e.printStackTrace();</div><div class="line">    &#125;</div><div class="line">    <span class="keyword">return</span> <span class="keyword">false</span>;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h3 id="The-Ledger-Advanced-API"><a href="#The-Ledger-Advanced-API" class="headerlink" title="The Ledger Advanced API"></a>The Ledger Advanced API</h3><p>Ledger 的 Advanced API 在用法上与上面的实现差异不大，它向应用提供了更大的灵活性，比如：在创建 Ledger 时，应用可以指定 LedgerId，写入 Entry 时，应用也可以指定相应的 EntryID。</p>
<h4 id="新建-Ledger"><a href="#新建-Ledger" class="headerlink" title="新建 Ledger"></a>新建 Ledger</h4><p>在新建 Ledger 这部分，Advanced API 可以指定 LedgerId 创建相应的 Ledger，如下面示例的第三种实现。</p>
<p>假设当前 BK 集群的 LedgerId 已经到了5，这时候在新建 Ledger 时如果不指定 LedgerId，下一个被使用的 LedgerId 就是6，如果应用指定了 7，新建的 Leader 的 id 将会是设置的 7，id 6 会等待下次再被使用。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/**</span></div><div class="line"> * create the ledger</div><div class="line"> *</div><div class="line"> * <span class="doctag">@param</span> password pw</div><div class="line"> * <span class="doctag">@return</span> LedgerHandleAdv</div><div class="line"> */</div><div class="line"><span class="function"><span class="keyword">public</span> LedgerHandleAdv <span class="title">createLedger</span><span class="params">(String password)</span> </span>&#123;</div><div class="line">    <span class="keyword">byte</span>[] passwd = password.getBytes();</div><div class="line">    <span class="keyword">try</span> &#123;</div><div class="line">        LedgerHandleAdv handle = (LedgerHandleAdv) bkClient.createLedgerAdv(</div><div class="line">                <span class="number">3</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="comment">// replica settings</span></div><div class="line">                BookKeeper.DigestType.CRC32,</div><div class="line">                passwd);</div><div class="line">        <span class="keyword">return</span> handle;</div><div class="line">    &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</div><div class="line">        e.printStackTrace();</div><div class="line">    &#125; <span class="keyword">catch</span> (BKException e) &#123;</div><div class="line">        e.printStackTrace();</div><div class="line">    &#125; <span class="keyword">catch</span> (Exception e) &#123;</div><div class="line">        e.printStackTrace();</div><div class="line">    &#125;</div><div class="line">    <span class="keyword">return</span> <span class="keyword">null</span>;</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="comment">/**</span></div><div class="line"> * create the ledger async</div><div class="line"> *</div><div class="line"> * <span class="doctag">@param</span> password</div><div class="line"> */</div><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">createLedgerAsync</span><span class="params">(String password)</span> </span>&#123;</div><div class="line">    <span class="class"><span class="keyword">class</span> <span class="title">LedgerCreationCallback</span> <span class="keyword">implements</span> <span class="title">AsyncCallback</span>.<span class="title">CreateCallback</span> </span>&#123;</div><div class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">createComplete</span><span class="params">(<span class="keyword">int</span> returnCode, LedgerHandle handle, Object ctx)</span> </span>&#123;</div><div class="line">            System.out.println(<span class="string">"Ledger successfully created"</span>);</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line">    bkClient.asyncCreateLedgerAdv(</div><div class="line">            <span class="number">3</span>, <span class="comment">// ensemble size</span></div><div class="line">            <span class="number">3</span>, <span class="comment">// write quorum size</span></div><div class="line">            <span class="number">2</span>, <span class="comment">// ack quorum size</span></div><div class="line">            BookKeeper.DigestType.CRC32,</div><div class="line">            password.getBytes(),</div><div class="line">            <span class="keyword">new</span> LedgerCreationCallback(),</div><div class="line">            <span class="string">"some context"</span>,</div><div class="line">            <span class="keyword">null</span>);</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="comment">/**</span></div><div class="line"> * create the ledger on special ledgerId</div><div class="line"> *</div><div class="line"> * <span class="doctag">@param</span> password pw</div><div class="line"> * <span class="doctag">@param</span> ledgerId the ledger id, if the ledger id exist, it will return BKLedgerExistException</div><div class="line"> * <span class="doctag">@return</span> LedgerHandleAdv</div><div class="line"> */</div><div class="line"><span class="function"><span class="keyword">public</span> LedgerHandleAdv <span class="title">createLedger</span><span class="params">(String password, <span class="keyword">long</span> ledgerId)</span> </span>&#123;</div><div class="line">    <span class="keyword">byte</span>[] passwd = password.getBytes();</div><div class="line">    <span class="keyword">try</span> &#123;</div><div class="line">        LedgerHandleAdv handle = (LedgerHandleAdv) bkClient.createLedgerAdv(</div><div class="line">                ledgerId,</div><div class="line">                <span class="number">3</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="comment">// replica settings</span></div><div class="line">                BookKeeper.DigestType.CRC32,</div><div class="line">                passwd,</div><div class="line">                <span class="keyword">null</span>);</div><div class="line">        <span class="keyword">return</span> handle;</div><div class="line">    &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</div><div class="line">        e.printStackTrace();</div><div class="line">    &#125; <span class="keyword">catch</span> (BKException e) &#123;</div><div class="line">        e.printStackTrace();</div><div class="line">    &#125; <span class="keyword">catch</span> (Exception e) &#123;</div><div class="line">        e.printStackTrace();</div><div class="line">    &#125;</div><div class="line">    <span class="keyword">return</span> <span class="keyword">null</span>;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h4 id="向-Ledger-添加-Entry"><a href="#向-Ledger-添加-Entry" class="headerlink" title="向 Ledger 添加 Entry"></a>向 Ledger 添加 Entry</h4><p>向 Ledger 添加 Entry API 中，最吸引我的是可以指定 EntryId 写入（熟悉 Kafka 的同学知道，向 Kafka 写入数据是可以指定 Partition，但是不能指定 offset，如果可以指定 offset 写入，那么在做容灾时就可以实现 topic 的完全同步，下游可以根据 commit offset 随时切换数据源），其示例如下（注意，Advanced API 在写数据时是强制要指定 entryId 的）：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/**</span></div><div class="line"> * add the msg to the ledger on the special entryId</div><div class="line"> *</div><div class="line"> * <span class="doctag">@param</span> ledgerHandleAdv ledgerHandleAdv</div><div class="line"> * <span class="doctag">@param</span> entryId         the entry id</div><div class="line"> * <span class="doctag">@param</span> msg             msg</div><div class="line"> */</div><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">addEntry</span><span class="params">(LedgerHandleAdv ledgerHandleAdv, <span class="keyword">long</span> entryId, String msg)</span> </span>&#123;</div><div class="line">    <span class="keyword">try</span> &#123;</div><div class="line">        ledgerHandleAdv.addEntry(entryId, msg.getBytes());</div><div class="line">    &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</div><div class="line">        e.printStackTrace();</div><div class="line">    &#125; <span class="keyword">catch</span> (BKException e) &#123;</div><div class="line">        e.printStackTrace();</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>关于这个 API，社区官方文档有如下介绍：</p>
<ol>
<li>The entry id has to be non-negative.</li>
<li>Clients are okay to add entries out of order.</li>
<li>However, the entries are only acknowledged in a monotonic order starting from 0.</li>
</ol>
<p>首先，说下我对上面的理解：entry.id 要求是非负的，client 在添加 entry 时可以乱序，但是 entry 只有 0 开始单调顺序增加时才会被 ack。最开始，我以为是只要 entry.id 单调递增就可以，跑了一个测试用例，第一个 entry 的 id 设置为 0，第二个设置为 2，然后程序直接 hang 在那里了，相应日志信息为：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line">2018-10-19 16:58:34  [ BookKeeperClientWorker-OrderedExecutor-0-0:662 ] - [ DEBUG ]  Got Add response from bookie:XXX.230:3181 rc:EOK, ledger:8:entry:0</div><div class="line">2018-10-19 16:58:34  [ BookKeeperClientWorker-OrderedExecutor-0-0:663 ] - [ DEBUG ]  Got Add response from bookie:XXX.247:3181 rc:EOK, ledger:8:entry:0</div><div class="line">2018-10-19 16:58:34  [ BookKeeperClientWorker-OrderedExecutor-0-0:663 ] - [ DEBUG ]  Submit callback (lid:8, eid: 0). rc:0</div><div class="line">2018-10-19 16:58:34  [ main:663 ] - [ DEBUG ]  Adding entry [50, 32, 109, 97, 116, 116, 32, 116, 101, 115, 116]</div><div class="line">2018-10-19 16:58:34  [ BookKeeperClientWorker-OrderedExecutor-0-0:673 ] - [ DEBUG ]  Got Add response from bookie:XXX.247:3181 rc:EOK, ledger:8:entry:2</div><div class="line">2018-10-19 16:58:34  [ BookKeeperClientWorker-OrderedExecutor-0-0:673 ] - [ DEBUG ]  Got Add response from bookie:XXX.230:3181 rc:EOK, ledger:8:entry:2</div><div class="line">2018-10-19 16:58:34  [ BookKeeperClientWorker-OrderedExecutor-0-0:673 ] - [ DEBUG ]  Head of the queue entryId: 2 is not the expected value: 1</div><div class="line">2018-10-19 16:58:34  [ BookKeeperClientWorker-OrderedExecutor-0-0:673 ] - [ DEBUG ]  Got Add response from bookie:XXX.146:3181 rc:EOK, ledger:8:entry:0</div><div class="line">2018-10-19 16:58:34  [ BookKeeperClientWorker-OrderedExecutor-0-0:673 ] - [ DEBUG ]  Head of the queue entryId: 2 is not the expected value: 1</div><div class="line">2018-10-19 16:58:34  [ BookKeeperClientWorker-OrderedExecutor-0-0:681 ] - [ DEBUG ]  Got Add response from bookie:XXX.146:3181 rc:EOK, ledger:8:entry:2</div><div class="line">2018-10-19 16:58:34  [ BookKeeperClientWorker-OrderedExecutor-0-0:681 ] - [ DEBUG ]  Head of the queue entryId: 2 is not the expected value: 1</div><div class="line">2018-10-19 16:58:37  [ main-SendThread(zk01:2181):3702 ] - [ DEBUG ]  Got ping response <span class="keyword">for</span> sessionid: 0x3637dbff9e7486c after 0ms</div><div class="line">2018-10-19 16:58:40  [ main-SendThread(zk01:2181):7039 ] - [ DEBUG ]  Got ping response <span class="keyword">for</span> sessionid: 0x3637dbff9e7486c after 0ms</div><div class="line">2018-10-19 16:58:43  [ main-SendThread(zk01:2181):10374 ] - [ DEBUG ]  Got ping response <span class="keyword">for</span> sessionid: 0x3637dbff9e7486c after 0ms</div><div class="line">2018-10-19 16:58:47  [ main-SendThread(zk01:2181):13710 ] - [ DEBUG ]  Got ping response <span class="keyword">for</span> sessionid: 0x3637dbff9e7486c after 0ms</div><div class="line">2018-10-19 16:58:50  [ main-SendThread(zk01:2181):17043 ] - [ DEBUG ]  Got ping response <span class="keyword">for</span> sessionid: 0x3637dbff9e7486c after 0ms</div></pre></td></tr></table></figure>
<p>可以看到有这样的异常日志 <code>Head of the queue entryId: 2 is not the expected value: 1</code>，期望的 entry id 是 1，这里是 2，乱序了，导致程序直接 hang 住（hang 住的原因推测是这个 Entry 没有被 ack），该异常信息出现地方如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">void</span> <span class="title">sendAddSuccessCallbacks</span><span class="params">()</span> </span>&#123;</div><div class="line">    <span class="comment">// Start from the head of the queue and proceed while there are</span></div><div class="line">    <span class="comment">// entries that have had all their responses come back</span></div><div class="line">    PendingAddOp pendingAddOp;</div><div class="line"></div><div class="line">    <span class="keyword">while</span> ((pendingAddOp = pendingAddOps.peek()) != <span class="keyword">null</span></div><div class="line">           &amp;&amp; blockAddCompletions.get() == <span class="number">0</span>) &#123;</div><div class="line">        <span class="keyword">if</span> (!pendingAddOp.completed) &#123;</div><div class="line">            <span class="keyword">if</span> (LOG.isDebugEnabled()) &#123;</div><div class="line">                LOG.debug(<span class="string">"pending add not completed: &#123;&#125;"</span>, pendingAddOp);</div><div class="line">            &#125;</div><div class="line">            <span class="keyword">return</span>;</div><div class="line">        &#125;</div><div class="line">        <span class="comment">// Check if it is the next entry in the sequence.</span></div><div class="line">        <span class="keyword">if</span> (pendingAddOp.entryId != <span class="number">0</span> &amp;&amp; pendingAddOp.entryId != pendingAddsSequenceHead + <span class="number">1</span>) &#123;</div><div class="line">            <span class="keyword">if</span> (LOG.isDebugEnabled()) &#123;</div><div class="line">                LOG.debug(<span class="string">"Head of the queue entryId: &#123;&#125; is not the expected value: &#123;&#125;"</span>, pendingAddOp.entryId,</div><div class="line">                           pendingAddsSequenceHead + <span class="number">1</span>);</div><div class="line">            &#125;</div><div class="line">            <span class="keyword">return</span>;</div><div class="line">        &#125;</div><div class="line"></div><div class="line">        pendingAddOps.remove();</div><div class="line">        explicitLacFlushPolicy.updatePiggyBackedLac(lastAddConfirmed);</div><div class="line">        pendingAddsSequenceHead = pendingAddOp.entryId;</div><div class="line">        <span class="keyword">if</span> (!writeFlags.contains(WriteFlag.DEFERRED_SYNC)) &#123;</div><div class="line">            <span class="keyword">this</span>.lastAddConfirmed = pendingAddsSequenceHead;</div><div class="line">        &#125;</div><div class="line">        pendingAddOp.submitCallback(BKException.Code.OK);</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>如果 entry id 出现了乱序，会导致这个 add 操作没有正常处理。但是如果这里强制要求 entry.id 从 0，而还有序，那么这个 API 跟前面的 API 有什么区别？这点没有搞懂，也向社区发一封邮件咨询，还在等待社区的响应。</p>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[YARN 架构学习总结]]></title>
      <url>http://matt33.com/2018/09/01/yarn-architecture-learn/</url>
      <content type="html"><![CDATA[<p>关于 Hadoop 的介绍，这里就不再多说，可以简答来说 Hadoop 的出现真正让更多的互联网公司开始有能力解决大数据场景下的问题，其中的 HDFS 和 YARN 已经成为大数据场景下存储和资源调度的统一解决方案（MR 现在正在被 Spark 所取代，Spark 在计算这块的地位也开始受到其他框架的冲击，流计算上有 Flink，AI 上有 Tensorflow，两面夹击，但是 Spark 的生态建设得很好，其他框架想要在生产环境立马取代还有很长的路要走）。本片文章就是关于 YARN 框架学习的简单总结，目的是希望自己能对分布式调度这块有更深入的了解，当然也希望也这篇文章能够对初学者有所帮助，文章的主要内容来自 <a href="https://item.jd.com/15542271154.html" target="_blank" rel="external">《Hadoop 技术内幕：深入解析 YARN 架构设计与实现原理》</a> 和 <a href="https://item.jd.com/11540991.html" target="_blank" rel="external">《大数据日知录：架构与算法》</a>。</p>
<h1 id="Yarn-背景"><a href="#Yarn-背景" class="headerlink" title="Yarn 背景"></a>Yarn 背景</h1><p>关于 YARN 出现的背景，还是得从 Hadoop1.0 说起，在 Hadoop1.0 中，MR 作业的调度还是有两个重要的组件：JobTracker 和 TaskTracker，其基础的架构如下图所示，从下图中可以大概看出原 MR 作业启动流程：</p>
<ol>
<li>首先用户程序 (Client) 提交了一个 job，job 的信息会发送到 JobTracker 中，JobTracker 是 Map-Reduce 框架的中心，它需要与集群中的机器定时通信 (心跳：heartbeat), 需要管理哪些程序应该跑在哪些机器上，需要管理<strong>所有 job</strong> 失败、重启等操作；</li>
<li>TaskTracker 是 Map-Reduce 集群中每台机器都有的一个组件，它做的事情主要是监视自己所在机器的资源使用情况；</li>
<li>TaskTracker 同时监视当前机器的 tasks 运行状况。TaskTracker 需要把这些信息通过 heartbeat 发送给 JobTracker，JobTracker 会搜集这些信息以便处理新提交的 job，来决定其应该分配运行在哪些机器上。</li>
</ol>
<p><img src="/images/hadoop/yarn10.png" alt="Hadoop 1.0 调度的架构图"></p>
<p>可以看出原来的调度框架实现非常简答明了，在 Hadoop 推出的最初几年，也获得业界的认可，但是随着集群规模的增大，很多的弊端开始显露出来，主要有以下几点：</p>
<ol>
<li>JobTracker 是 Map-Reduce 的集中处理点，存在<strong>单点故障</strong>；</li>
<li>JobTracker 赋予的功能太多，导致负载过重，1.0 时未将资源管理与作业控制（包括：作业监控、容错等）分开，导致负载重而且无法支撑更多的计算框架，当集群的作业非常多时，会有很大的内存开销，潜在来说，也增加了 JobTracker fail 的风险，这也是业界普遍总结出 Hadoop1.0 的 Map-Reduce 只能支持 4000 节点主机上限的原因；</li>
<li>在 TaskTracker 端，以 map/reduce task 的数目作为资源的表示过于简单，没有考虑到 cpu/ 内存的占用情况，如果两个大内存消耗的 task 被调度到了一个节点上，很容易出现 OOM；</li>
<li>在 TaskTracker 端，把资源强制划分为 map task slot 和 reduce task slot, 如果当系统中只有 map task 或者只有 reduce task 的时候，会造成资源的浪费，也就是前面提过的集群资源利用的问题。</li>
</ol>
<p>Hadoop 2.0 中下一代 MR 框架的基本设计思想就是将 JobTracker 的两个主要功能，资源管理和作业控制（包括作业监控、容错等），分拆成两个独立的进程。资源管理与具体的应用程序无关，它负责整个集群的资源（内存、CPU、磁盘等）管理，而作业控制进程则是直接与应用程序相关的模块，且每个作业控制进程只负责管理一个作业，这样就是 YARN 诞生的背景，它是在 MapReduce 框架上衍生出的一个资源统一的管理平台。</p>
<h1 id="Yarn-架构"><a href="#Yarn-架构" class="headerlink" title="Yarn 架构"></a>Yarn 架构</h1><p>YARN 的全称是 Yet Another Resource Negotiator，YARN 整体上是 Master/Slave 结构，在整个框架中，ResourceManager 为 Master，NodeManager 为 Slave，如下图所示：</p>
<p><img src="/images/hadoop/yarn20.gif" alt="YARN 基本架构"></p>
<h2 id="ResourceManager（RM）"><a href="#ResourceManager（RM）" class="headerlink" title="ResourceManager（RM）"></a>ResourceManager（RM）</h2><p>RM 是一个全局的资源管理器，负责整个系统的资源管理和分配，它主要有两个组件构成：</p>
<ol>
<li>调度器：Scheduler；</li>
<li>应用程序管理器：Applications Manager，ASM。</li>
</ol>
<h3 id="调度器"><a href="#调度器" class="headerlink" title="调度器"></a>调度器</h3><p>调度器根据容量、􏳴队列等限制条件（如某个队列分配一定的资源，最多执行一定数量的作业等），将系统中的资源分配给各个正在运行的应用程序。􏰣要注意的是，该调度器是一个纯调度器，它不再从事任何与应用程序有关的工作，比如不负责重新启动（因应用程序失败或者硬件故障导致的失败），这些均交由应用程序相关的 ApplicationMaster 完成。调度器仅根据各个应用程序的资源需求进行资源分配，而资源分配单位用一个抽象概念 <strong>资源容器(Resource Container，也即 Container)</strong>，Container 是一个动态资源分配单位，它将内存、CPU、磁盘、网络等资源封装在一起，从而限定每个任务使用的资源量。此外，该调度器是一个可插拔的组件，用户可根据自己的需求设计新的调度器，YARN 提供了多种直接可用的调度器，比如 Fair Scheduler 和 Capacity Schedule 等。</p>
<h3 id="应用程序管理器"><a href="#应用程序管理器" class="headerlink" title="应用程序管理器"></a>应用程序管理器</h3><p>应用程序管理器负责管理整个系统中所有应用程序，包括应用程序提交、与调度器协商资源以 AM、监控 AM 运行状态并在失败时重新启动它等。</p>
<h2 id="NodeManager（NM）"><a href="#NodeManager（NM）" class="headerlink" title="NodeManager（NM）"></a>NodeManager（NM）</h2><p>NM 是每个节点上运行的资源和任务管理器，一方面，它会定时向 RM 汇报本节点上的资源使用情况和各个 Container 的运行状态；另一方面，它接收并处理来自 AM 的 Container 启动/停止等各种请求。</p>
<h2 id="ApplicationMaster（AM）"><a href="#ApplicationMaster（AM）" class="headerlink" title="ApplicationMaster（AM）"></a>ApplicationMaster（AM）</h2><p>提交的每个作业都会包含一个 AM，主要功能包括：</p>
<ol>
<li>与 RM 协商以获取资源（用 container 表示）；</li>
<li>将得到的任务进一步分配给内部的任务；</li>
<li>与 NM 通信以启动/停止任务；</li>
<li>监控所有任务的运行状态，当任务有失败时，重新为任务申请资源并重启任务。</li>
</ol>
<p>MapReduce 就是原生支持 ON YARN 的一种框架，可以在 YARN 上运行 MapReduce 作业。有很多分布式应用都开发了对应的应用程序框架，用于在 YARN 上运行任务，例如 Spark，Storm、Flink 等。</p>
<h2 id="Container"><a href="#Container" class="headerlink" title="Container"></a>Container</h2><p>Container 是 YARN 中的资源抽象，它封装了某个节点上的多维度资源，如内存、CPU、磁盘、网络等，当 AM 向 RM 申请资源时，RM 为 AM 返回的资源便是用 Container 表示的。 YARN 会为每个任务分配一个 Container 且该任务只能使用该 Container 中描述的资源。</p>
<h1 id="YARN-作业提交流程"><a href="#YARN-作业提交流程" class="headerlink" title="YARN 作业提交流程"></a>YARN 作业提交流程</h1><p>当用户向 YARN 中提交一个应用程序后，YARN 将分两个阶段运行该应用程序：第一个阶段是启动 ApplicationMaster；第二个阶段是由 ApplicationMaster 创建应用程序，为它申请资源，并监控它的整个运行过程，直到运行完成，如下图所示（此图来自<a href="https://item.jd.com/15542271154.html" target="_blank" rel="external">《Hadoop 技术内幕：深入解析 YARN 架构设计与实现原理》</a>）：</p>
<p><img src="/images/hadoop/yarn-flow.png" alt="YARN 工作流程"></p>
<p>上图所示的 YARN 工作流程分为以下几个步骤：</p>
<ol>
<li>用户向 YARN 提交应用程序，其中包括 ApplicationMaster 程序，启动 ApplicationMaster 命令、用户程序等；</li>
<li>RM 为该应用程序分配第一个 Container，并与对应的 NM 通信，要求它在这个 Container 中启动应用程序的 ApplicationMaster；</li>
<li>ApplicationMaster 首先向 RM 注册，这样用户可以直接通过 NM 查看应用程序的运行状态，然后它将为各个任务申请资源，并监控它的运行状态，直到运行结束，一直重复下面的 4-7 步；</li>
<li>ApplicationMaster 采用轮询的方式通过 RPC 协议向 RM 申请和领取资源；</li>
<li>一旦 ApplicationMaster 申请到资源后，便与对应的 NM 通信，要求它启动任务；</li>
<li>NM 为任务设置好运行环境（包括环境变量、jar 包等）后，将任务启动命令写到一个脚本中，并通过运行该脚本启动任务；</li>
<li>各个任务通过某个 RPC 协议向 ApplicationMaster 汇报自己的状态和进度，以让 ApplicationMaster 随时掌握各个任务的运行状态，从而可以在任务失败时重新启动任务；</li>
<li>应用程序运行完成后，ApplicationMaster 向 RM 注销并关闭自己（当然像 Storm、Flink 这种常驻应用程序列外）。</li>
</ol>
<h1 id="调度器-1"><a href="#调度器-1" class="headerlink" title="调度器"></a>调度器</h1><p>YARN 的调度器是一个可插拔的组件，目前社区已经提供了 FIFO Scheduler（先进先出调度器）、Capacity Scheduler（能力调度器）、Fair Scheduler（公平调度器），用户也可以继承 ResourceScheduler 的接口实现自定义的调度器，就像 app on yarn 流程一样，不同的应用可以自己去实现，这里只是简单讲述上述三种调度器的基本原理。</p>
<h2 id="FIFO-Scheduler"><a href="#FIFO-Scheduler" class="headerlink" title="FIFO Scheduler"></a>FIFO Scheduler</h2><p>FIFO 是最简单的资源调度策略，提交的作业按照提交时间先后顺序或者根据优先级次序将其放入线性队列相应的位置，在资源调度时，<strong>按照队列的先后顺序、先进先出地进行调度和资源分配</strong>。</p>
<p>很明显这种调度器过于简单，在实际的生产中，应用不是很多，毕竟需要调度的作业是有不同的优先级的。</p>
<h2 id="公平调度器（Fair-Scheduler）"><a href="#公平调度器（Fair-Scheduler）" class="headerlink" title="公平调度器（Fair Scheduler）"></a>公平调度器（Fair Scheduler）</h2><p>公平调度器先将用户的任务分配到多个资源池（Pool）中，每个资源池设定资源分配最低保障和最高上限，管理员也可以指定资源池的优先级，优先级高的资源池将会被分配更多的资源，当一个资源池有剩余时，可以临时将剩余资源共享给其他资源池。公平调度器的调度过程如下：</p>
<ol>
<li>根据每个资源池的最小资源保障，将系统中的部分资源分配给各个资源池；</li>
<li>根据资源池的指定优先级讲剩余资源按照比例分配给各个资源池；</li>
<li>在各个资源池中，按照作业的优先级或者根据公平策略将资源分配给各个作业；</li>
</ol>
<p>公平调度器有以下几个特点：</p>
<ol>
<li><strong>支持抢占式调度</strong>，即如果某个资源池长时间未能被分配到公平共享量的资源，则调度器可以杀死过多分配资源的资源池的任务，以空出资源供这个资源池使用；</li>
<li><strong>强调作业之间的公平性</strong>：在每个资源池中，公平调度器默认使用公平策略来实现资源分配，这种公平策略是最大最小公平算法的一种具体实现，可以尽可能保证作业间的资源分配公平性；</li>
<li><strong>负载均衡</strong>：公平调度器提供了一个基于任务数目的负载均衡机制，该机制尽可能将系统中的任务均匀分配到给各个节点上；</li>
<li><strong>调度策略配置灵活</strong>：允许管理员为每个队列单独设置调度策略；</li>
<li><strong>提高小应用程序响应时间</strong>：由于采用了最大最小公平算法，小作业可以快速获得资源并运行完成。</li>
</ol>
<h2 id="能力调度器（Capacity-Scheduler）"><a href="#能力调度器（Capacity-Scheduler）" class="headerlink" title="能力调度器（Capacity Scheduler）"></a>能力调度器（Capacity Scheduler）</h2><p>能力调度器是 Yahool 为 Hadoop 开发的多用户调度器，应用于用户量众多的应用场景，与公平调度器相比，其更强调资源在用户之间而非作业之间的公平性。</p>
<p>它将用户和任务组织成多个队列，每个队列可以设定资源最低保障和使用上限，当一个队列的资源有剩余时，可以将剩余资源暂时分享给其他队列。调度器在调度时，优先将资源分配给资源使用率最低的队列（即队列已使用资源量占分配给队列的资源量比例最小的队列）；在队列内部，则按照作业优先级的先后顺序遵循 FIFO 策略进行调度。</p>
<p>能力调度器有以下几点特点：</p>
<ol>
<li><strong>容量保证</strong>：管理员可为每个队列设置资源最低保证和资源使用上限，而所有提交到该队列的应用程序共享这些资源；</li>
<li><strong>灵活性</strong>：如果一个队列资源有剩余，可以暂时共享给那些需要资源的队列，而一旦该队列有新的应用程序提交，则其他队列释放的资源会归还给该队列；</li>
<li><strong>多重租赁</strong>：支持多用户共享集群和多应用程序同时运行，为防止单个应用程序、用户或者队列独占集群中的资源，管理员可为之增多多重约束；</li>
<li><strong>安全保证</strong>：每个队列有严格的 ACL 列表规定它访问用户，每个用户可指定哪些用户允许查看自己应用程序的运行状态或者控制应用程序；</li>
<li><strong>动态更新配置文件</strong>：管理可以根据需要动态修改各种配置参数。</li>
</ol>
<h1 id="Yarn-容错"><a href="#Yarn-容错" class="headerlink" title="Yarn 容错"></a>Yarn 容错</h1><p>对于分布式系统，不论是调度系统还是其他系统，容错机制都是非常必要的，这里我们简单看下 YARN 的容错机制，YARN 需要做容错的地方，有以下四个地方：</p>
<ol>
<li>ApplicationMaster 容错：ResourceManager 会和 ApplicationMaster 保持通信，一旦发现 ApplicationMaster 失败或者超时，会为其重新分配资源并重启。重启后 ApplicationMaster 的运行状态需要自己恢复，比如 MRAppMaster 会把相关的状态记录到 HDFS 上，重启后从 HDFS 读取运行状态恢复；</li>
<li>NodeManager 容错：NodeManager 如果超时，则 ResourceManager 会认为它失败，将其上的所有 container 标记为失败并通知相应的 ApplicationMaster，由 AM 决定如何处理（可以重新分配任务，可以整个作业失败，重新拉起）；</li>
<li>container 容错：如果 ApplicationMaster 在一定时间内未启动分配的 container，RM 会将其收回，如果 Container 运行失败，RM 会告诉对应的 AM 由其处理；</li>
<li>RM 容错：RM 采用 HA 机制，这里详细讲述一下。</li>
</ol>
<h2 id="ResourceManager-HA"><a href="#ResourceManager-HA" class="headerlink" title="ResourceManager HA"></a>ResourceManager HA</h2><p>因为 RM 是 YARN 架构中的一个单点，所以他的容错很难做，一般是采用 HA 的方式，有一个 active master 和一个 standby master（可参考：<a href="https://hadoop.apache.org/docs/r2.7.1/hadoop-yarn/hadoop-yarn-site/ResourceManagerHA.html" target="_blank" rel="external">ResourceManager High Availability</a>），HA 的架构方案如下图所示：</p>
<p><img src="/images/hadoop/rm-ha-overview.png" alt="YARN RM HA 机制"></p>
<p>关于 YARN 的 RM 的 HA 机制，其实现与 HDFS 的很像，可以参考前面关于 HDFS 文章的讲述 <a href="http://matt33.com/2018/07/15/hdfs-architecture-learn/#HDFS-2-0-%E7%9A%84-HA-%E5%AE%9E%E7%8E%B0">HDFS NN HA 实现</a>。</p>
<h1 id="分布式调度器总结"><a href="#分布式调度器总结" class="headerlink" title="分布式调度器总结"></a>分布式调度器总结</h1><p>上面基本已经把 YARN 的相关内容总结完了，这个小节主要讲述一下分布式调度系统的一些内容（调度框架只是具体的一种实现方案），主要讲述分布式调度系统要解决的一些问题和分布式调度系统的调度模型。</p>
<h2 id="调度系统设计遇到的基本问题"><a href="#调度系统设计遇到的基本问题" class="headerlink" title="调度系统设计遇到的基本问题"></a>调度系统设计遇到的基本问题</h2><p>对于分布式调度系统，在实际的生产环境中，遇到的问题很相似，这个小节就是看下调度系统主要面对的问题。</p>
<h3 id="资源异构性与工作负载异构性"><a href="#资源异构性与工作负载异构性" class="headerlink" title="资源异构性与工作负载异构性"></a>资源异构性与工作负载异构性</h3><p>在资源管理与调度场景下，有两类异质性需要考虑：</p>
<ol>
<li>资源异质性：这个是从系统拥有资源的角度来看，对于数据中心来说非常常见，数据中心的机器很难保证完全一样的配置，有的配置会高一些，有的会低一些；</li>
<li>工作负载异质性：在大型互联网公司中很常见，因为各种服务和功能特性各异，对资源的需求千差万别。</li>
</ol>
<h3 id="数据局部性（Data-Locality）"><a href="#数据局部性（Data-Locality）" class="headerlink" title="数据局部性（Data Locality）"></a>数据局部性（Data Locality）</h3><p>在大数据场景下，还有一个基本的共识：将计算任务推送到数据所在地进行而不是反过来。因为数据的移动会产生大量低效的数据网络传输开销，而计算代码相比而言数据小得多，所以将计算任务推动到数据所在地是非常常见的，这就是<strong>数据局部性</strong>，在资源调度中，有三种类型的数据局部性，分别是：</p>
<ol>
<li>节点局部性（Node Locality）：计算任务分配到数据所在机器节点，无需任务网络传输；</li>
<li>机架局部性（Rack Locality）：虽然计算任务与数据分布在不同的节点，但这两个节点在同一个机架中，这也是效率较高的一种数据性；</li>
<li>全局局部性（Global Locality）：需要跨机架的传输，会产生较大的网络传输开销。</li>
</ol>
<h3 id="抢占式调度与非抢占式调度"><a href="#抢占式调度与非抢占式调度" class="headerlink" title="抢占式调度与非抢占式调度"></a>抢占式调度与非抢占式调度</h3><p>在多用户场景下，面对已经分配的资源，资源管理调度系统可以有两种不同类型的调度方式：</p>
<ol>
<li>抢占式调度：对于某个计算任务来说，如果空闲资源不足或者出现不同任务共同竞争同一资源，调度系统可以从比当前计算任务优先级低的其他任务中获取已经分配资源，而被抢占资源的计算任务则需要出让资源停止计算；</li>
<li>非抢占式调度：只允许从空闲资源中进行分配，如果当前空闲资源不足，则须等待其他任务释放资源后才能进行。</li>
</ol>
<h3 id="资源分配粒度（Allocation-Granularity）"><a href="#资源分配粒度（Allocation-Granularity）" class="headerlink" title="资源分配粒度（Allocation Granularity）"></a>资源分配粒度（Allocation Granularity）</h3><p>大数据场景下的计算任务往往由两层结构构成：作业级（Job）和任务级（Task），一个作业由多个并发任务构成，任务之间的依赖关系往往形成有向无环图（DAG），比如：MR 作业，关于作业资源分配的粒度，常见的有两种模式：</p>
<ol>
<li>群体分配（全分或不分）：需要将作业的所有所需资源一次性分配完成；</li>
<li>增量满足式分配策略：对于某个作业，只要分配部分资源就能启动一些任务开始运行，随着空闲资源的不断出现，可以逐步增量式分配给作业的其他任务以维护作业不断向后进行。</li>
</ol>
<p>还有一种策略是 <strong>资源储备策略</strong>，它指的是只有分配到一定量的资源资源才能启动，但是在未获得足够资源的时候，作业可以先持有目前已经分配的资源，并等待其他作业释放资源，这样从调度系统不断获取新资源并进行储备和累积，直到分配到的资源量达到最低标准后开始运行。</p>
<h3 id="饿死（Starvation）与死锁（Dead-Lock）问题"><a href="#饿死（Starvation）与死锁（Dead-Lock）问题" class="headerlink" title="饿死（Starvation）与死锁（Dead Lock）问题"></a>饿死（Starvation）与死锁（Dead Lock）问题</h3><p>饿死和死锁是一个合理的资源调度系统需要避免的两个问题：</p>
<ol>
<li>饿死：指的是这个计算任务持续上时间无法获得开始执行所需的最少资源量，导致一直处于等待执行的状态，比如在资源紧张的情形下，有些低优先级的任务始终无法获得资源分配机会，如果不断出现新提交的高优先级任务，则这些低优先级任务就会出现饿死现象；</li>
<li>死锁：指的是由于资源调度不当导致整个调度无法继续正常执行，比如前面提高的资源储备策略就有可能导致调度系统进入死锁状态，多个作业占有一定作业的情况下，都在等待新的资源释放。</li>
</ol>
<h3 id="资源隔离方法"><a href="#资源隔离方法" class="headerlink" title="资源隔离方法"></a>资源隔离方法</h3><p>目前对于资源隔离最常用的手段是 Linux 容器（Linux Container，LXC，可以参考<a href="https://www.redhat.com/zh/topics/containers/whats-a-linux-container" target="_blank" rel="external">什么是 Linux 容器？</a>），YARN 和 Mesos 都是采用了这种方式来实现资源隔离。LXC 是一种轻量级的内核虚拟化技术，可以用来进行资源和进程运行的隔离，通过 LXC 可以在一台物理机上隔离出多个互相隔离的容器。LXC 在资源管理方面依赖于 Linux 内核的 cgroups 子系统，cgroups 子系统是 Linux 内核提供的一个基于进程组的资源管理的框架，可以为特定的进程组限定可以使用的资源。</p>
<h2 id="调度器模型"><a href="#调度器模型" class="headerlink" title="调度器模型"></a>调度器模型</h2><p>关于资源管理与调度功能的实际功能，分布式调度器根据运行机制的不同进行分类，可以归纳为三种资源管理与调度系统泛型：</p>
<ol>
<li>集中式调度器；</li>
<li>两级调度器；</li>
<li>状态共享调度器。</li>
</ol>
<p>它们的区别与联系如下图所示：</p>
<p><img src="/images/hadoop/scheduler.png" alt="三种调度模型"></p>
<h3 id="集中式调度器"><a href="#集中式调度器" class="headerlink" title="集中式调度器"></a>集中式调度器</h3><p>集中式调度器在整个系统中只运行一个全局的中央调度器实例，所有之上的框架或者计算任务的资源请求全部经由中央调度器来满足（也就是说：资源的使用及任务的执行状态都由中央调度器管理），因此，整个调度系统缺乏并发性且所有调度逻辑全部由中央调度器来完成。集中式调度器有以下这些特点：</p>
<ol>
<li>适合批处理任务和吞吐量较大、运行时间较长的任务；</li>
<li>调度逻辑全部融入到了中央调度器，实现逻辑复杂，灵活性和策略的可扩展性不高；</li>
<li>并发性能较差，比较适合小规模的集群系统；</li>
<li>状态同步比较容易且稳定，这是因为资源使用和任务执行的状态被统一管理，降低了状态同步和并发控制的难度。</li>
</ol>
<h3 id="两级调度器"><a href="#两级调度器" class="headerlink" title="两级调度器"></a>两级调度器</h3><p>对于集中式调度器的不足之处，两级调度器是一个很好的解决方案，它可以看做一种策略下放的机制，它将整个系统的调度工作分为两个级别：</p>
<ol>
<li>中央调度器：中央调度器可以看到集群中所有机器的可用资源并管理其状态，它可以按照一定策略将集群中的所有资源更配各个计算框架，中央调度器级别的资源调度是一种粗粒度的资源调度方式；</li>
<li>框架调度器：各个计算框架在接收到所需资源后，可以根据自身计算任务的特性，使用自身的调度策略来进一步细粒度地分配从中央调度器获得的各种资源。</li>
</ol>
<p>在这种两级调度器架构中，只有中央调度器能够观察到所有集群资源的状态，而每个框架并无全局资源概念（不知道整个集群资源使用情况），只能看到由中央调度器分配给自己的资源，Mesos、YARN 和 Hadoop on Demand 系统是3个典型的两级调度器。两级调度的缺点也非常明显：</p>
<ol>
<li><strong>各个框架无法知道整个集群的实时资源使用情况</strong>：很多框架不需要知道整个集群的实时资源使用情况就可以运行得很顺畅，但是对于其他一些应用，为之提供实时资源使用情况可以挖掘潜在的优化空间；</li>
<li><strong>采用悲观锁，并发粒度小</strong>：悲观锁通常采用锁机制控制并发，这会大大降低性能。</li>
</ol>
<h3 id="状态共享调度器"><a href="#状态共享调度器" class="headerlink" title="状态共享调度器"></a>状态共享调度器</h3><p>通过前面两种模型的介绍，可以发现集群中需要管理的状态主要包括以下两种：</p>
<ol>
<li>系统中资源分配和使用的状态；</li>
<li>系统中任务调度和执行的状态</li>
</ol>
<p>在集中式调度器中，这两个状态都由中心调度器管理，并且一并集成了调度等功能；而在双层调度器中，这两个状态分别由中央调度器和框架调度器管理。集中式调度器可以容易地保证全局状态的一致性，但是可扩展性不够；双层调度器对共享状态的管理较难达到好的一致性保证，也不容易检测资源竞争和死锁。</p>
<p>这也就催生出了另一种调度器 —— 状态共享调度器（Shared-State Scheduler），它是 Google 的 Omega 调度系统提出的一种调度器模型。在这种调度器中，每个计算框架可以看到整个集群中的所有资源，并采用互相竞争的方式去获取自己所需的资源，根据自身特性采取不同的具体资源调整策略，同时系统采用了乐观并发控制手段解决不同框架在资源竞争过程中出现的需求冲突。这样，状态共享调度器在一下两个方面对两级调度器做了相应的优化：</p>
<ol>
<li><strong>乐观并发控制增加了系统的并发性能</strong>；</li>
<li>每个计算框架都可以获得全局的资源使用状况；</li>
</ol>
<p>与两级调度器对比，两者的根本区别在于 <strong>中央调度器功能的强弱不同</strong>，两级调度器依赖中央调度器来进行第一次资源分配，而 Omega 则严重弱化中央调度器的功能，只是维护一份可恢复的集群资源状态信息的主副本，这份数据被称为 <strong>单元状态（Cell State）</strong></p>
<ol>
<li>每个框架在自身内部会维护 单元状态 的一份私有并不断更新的副本信息，而框架对资源的需求则直接在这份副本信息上进行；</li>
<li>只要框架具有特定的优先级，就可以在这份副本信息上申请相应的闲置资源，也可以抢夺已经分配给其他比自身优先级低的计算任务的资源；</li>
<li>一旦框架做出资源决策，则可以改变私有 单元状态 信息并将其同步到全局的 单元状态 信息中区，这样就完成了资源申请并使得这种变化让其他框架可见；</li>
<li>上述资源竞争过程通过 <strong>事务操作</strong> 来进行，保证了操作的原子性。</li>
</ol>
<p>如果两个框架竞争同一份资源，因其决策过程都是在各自私有数据上做出的，并通过原子事务进行提交，系统保证此种情形下只有一个竞争胜出者，而失败者可以后续继续重新申请资源，这是一种乐观并发控制手段，可以增加系统的整体并发性能。</p>
<p>从上面的过程，可以看出，这种架构是一种 <strong>以效率优先，不太考虑资源分配公平性</strong> 的策略，很明显高优先级的任务总是能够在资源竞争过程中获胜，而低优先级的任务存在由于长时间无法竞争到所需资源而被【饿死】的风险。</p>
<hr>
<p>参考：</p>
<ul>
<li><a href="https://item.jd.com/15542271154.html" target="_blank" rel="external">《Hadoop 技术内幕：深入解析 YARN 架构设计与实现原理》</a>;</li>
<li><a href="https://item.jd.com/11540991.html" target="_blank" rel="external">《大数据日知录：架构与算法》</a>；</li>
<li><a href="https://hadoop.apache.org/docs/r2.7.1/hadoop-yarn/hadoop-yarn-site/YARN.html" target="_blank" rel="external">Hadoop Yarn</a>；</li>
<li><a href="https://www.ibm.com/developerworks/cn/opensource/os-cn-hadoop-yarn/" target="_blank" rel="external">Hadoop 新 MapReduce 框架 Yarn 详解</a>；</li>
<li><a href="http://shiyanjun.cn/archives/1119.html" target="_blank" rel="external">Hadoop YARN架构设计要点</a>；</li>
<li><a href="https://www.ibm.com/developerworks/cn/data/library/bd-yarn-intro/index.html" target="_blank" rel="external">YARN 简介</a>；</li>
<li><a href="https://blog.csdn.net/bingduanlbd/article/details/51880019" target="_blank" rel="external">理解Hadoop YARN架构</a>；</li>
<li><a href="https://dbaplus.cn/news-141-2004-1.html" target="_blank" rel="external">这里有7种主流案例，告诉你调度器架构设计通用法则</a>；</li>
</ul>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[如何学习开源项目]]></title>
      <url>http://matt33.com/2018/08/01/system-learn-summary/</url>
      <content type="html"><![CDATA[<p>本篇文章的方法论内容基本来自订阅的极客时间-李运华老师的《从0开始学架构》中的一篇文章，会结合自己的学习经验、加上以 Flink 为例来做一个总结，也为了让自己再学习其他开源项目时能够按照这样的一个方法论高效的深入学习。先简单说一下开源项目，开源项目最早从上个世纪开始，我知道最早的是 linux 项目（其他的不是很了解），再到近几年大数据领域，发展非常迅速，开源给本公司带来的好处，首先是提高这家在技术界的影响力，然后如果这个项目比较受大家认可，那么这家公司的这个技术可能会成为业界的统一解决方案，就像 Hadoop、Kafka 等。对其他公司的好处是，节省成本、可以快速应用来解决业务中的问题。</p>
<p>但是对于公司技术员工不好的地方是，作为这些项目的维护者，以后真的可能变成运维工程师，社区这些项目发展一般都很快，小厂很难有足够的人力、能力在这上面做太多的研发，一般都是跟着社区升级，可能发展到最后的结果是: 项目的研发由社区（或者背后主导的公司）来负责，其他公司融入这一生态，做好运维工作或产品化的东西就可以了，稳定性、可靠性、新功能交给社区，随着项目逐渐庞大，到最后可能其他公司很少有人能对这些项目有较强的掌控力，研发完全依赖于社区。这些开源项目的接口变得越来越简单、内部越来越复杂时，虽然降低了开发者、维护者的门槛，但也降低对开发者、维护者的要求，这是一把双刃剑，对于在技术上对自己有一定要求的工程师，不应该仅限于使用、原理等。</p>
<p>上面是一些浅薄的想法，下面开始结合李运华老师的文章总结学习开源项目的方法论。首先在学习开源项目时，有几点需要明确的是：</p>
<ol>
<li>先树立正确观念，不管你是什么身份，都可以从开源项目中学到很多东西（比如：要学习 Redis 的网络模型，不需要我们成为 Redis 的开发者，也不需要一定要用到 Redis，只需要具备一定的网络编程基础，再通过阅读 Redis 源码，就可以学习 Redis 这种单进程的 Reactor 模型）；</li>
<li>不要只盯着数据结构和算法，这些在学习开源项目时并没有那么重要（Nginx 使用红黑树来管理定时器，对于大多数人只需要这一点就足够了，并不需要研究 Nginx 实现红黑树的源码是如何写的，除非需要修改这部分的逻辑代码）；</li>
<li>采取<strong>自顶向下</strong>的学习方法，源码不是第一步，而是最后一步（基本掌握了功能、原理、关键设计之后再去看源码，看源码的主要目的是为了学习其代码的写作方式以及关键技术的实现）。</li>
</ol>
<blockquote>
<p>例如，Redis 的 RDB 持久化模式「会将当前内存中的数据库快照保存到磁盘文件中」，那这里所谓的 “数据库快照” 到底是怎么做的呢？在 Linux 平台上其实就是 fork 一个子进程保存就可以了；那为何 fork 子进程就生成了数据库快照了呢？这又和 Linux 的父子进程机制以及 copy-on-write 技术相关了。通过这种学习方式，既能够快速掌握系统设计的关键点（Redis 和 RDB 模式），又能够掌握具体的变成技巧（内存快照）。</p>
</blockquote>
<p>下面来看下李运华老师的『自顶向下』的学习方法和步骤。</p>
<h3 id="1-安装"><a href="#1-安装" class="headerlink" title="1. 安装"></a>1. 安装</h3><p>这里的安装并不是对着手册执行一下命令，而是要通过安装过程，获取到如下一些关键的信息：</p>
<ul>
<li>这个系统的依赖组件，而依赖的组件又是系统设计和实现的基础;</li>
<li>安装目录也能够提供一些使用和运行的基本信息；</li>
<li>系统提供了哪些工具方便我们使用（<strong>带着问题去学习效率是最高的</strong>）。</li>
</ul>
<p>以 Nginx 为例，源码安装时依赖的库有 pcre、pcre-devel、openssl、openssl-devel、zlib，光从名字上看能够了解一些信息，例如 openssl 可能和 https 有关，zlib 可能与压缩有关。再以 Memcache 为例，它最大的依赖库就是 libevent，而根据 libevent 是一个高性能的网络库，大概能够推测 Memcache 的网络实现应该是 Reactor 模型。</p>
<p>例如，flink1.5.0安装完成后，目录如下：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">[XXX@matt@pro flink-1.5.0]$ ll</div><div class="line">total 52</div><div class="line">drwxr-xr-x 2 XXX XXX  4096 Jul  9 23:39 bin</div><div class="line">drwxr-xr-x 2 XXX XXX  4096 Jul  9 23:57 conf</div><div class="line">drwxr-xr-x 6 XXX XXX  4096 Jul  9 23:39 examples</div><div class="line">drwxr-xr-x 2 XXX XXX  4096 Jul  9 23:39 lib</div><div class="line">-rw-r--r-- 1 XXX XXX 18197 Jul  9 23:39 LICENSE</div><div class="line">drwxr-xr-x 2 XXX XXX  4096 Jul  9 23:57 <span class="built_in">log</span></div><div class="line">-rw-r--r-- 1 XXX XXX   779 Jul  9 23:39 NOTICE</div><div class="line">drwxr-xr-x 2 XXX XXX  4096 Jul  9 23:39 opt</div><div class="line">-rw-r--r-- 1 XXX XXX  1308 Jul  9 23:39 README.txt</div></pre></td></tr></table></figure>
<p>上面 bin 是运行程序，conf 是配置文件的目录，lib 和 opt 是依赖的相关 jar 包，但为什么分为两个目录去放，这个我还不是很明白。下面是目录的详细内容:</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div></pre></td><td class="code"><pre><div class="line">[XXX@matt@pro flink-1.5.0]$ ll bin/</div><div class="line">total 116</div><div class="line">-rwxr-xr-x 1 XXX XXX 23957 Jul  9 23:39 config.sh</div><div class="line">-rwxr-xr-x 1 XXX XXX  2224 Jul  9 23:39 flink</div><div class="line">-rwxr-xr-x 1 XXX XXX  1271 Jul  9 23:39 flink.bat</div><div class="line">-rwxr-xr-x 1 XXX XXX  2823 Jul  9 23:39 flink-console.sh</div><div class="line">-rwxr-xr-x 1 XXX XXX  6407 Jul  9 23:39 flink-daemon.sh</div><div class="line">-rwxr-xr-x 1 XXX XXX  1482 Jul  9 23:39 historyserver.sh</div><div class="line">-rwxr-xr-x 1 XXX XXX  2652 Jul  9 23:39 jobmanager.sh</div><div class="line">-rwxr-xr-x 1 XXX XXX  1802 Jul  9 23:39 mesos-appmaster-job.sh</div><div class="line">-rwxr-xr-x 1 XXX XXX  1971 Jul  9 23:39 mesos-appmaster.sh</div><div class="line">-rwxr-xr-x 1 XXX XXX  2013 Jul  9 23:39 mesos-taskmanager.sh</div><div class="line">-rwxr-xr-x 1 XXX XXX  1164 Jul  9 23:39 pyflink.bat</div><div class="line">-rwxr-xr-x 1 XXX XXX  1107 Jul  9 23:39 pyflink.sh</div><div class="line">-rwxr-xr-x 1 XXX XXX  1182 Jul  9 23:39 pyflink-stream.sh</div><div class="line">-rwxr-xr-x 1 XXX XXX  3434 Jul  9 23:39 sql-client.sh</div><div class="line">-rwxr-xr-x 1 XXX XXX  3364 Jul  9 23:39 start-cluster.bat</div><div class="line">-rwxr-xr-x 1 XXX XXX  1836 Jul  9 23:39 start-cluster.sh</div><div class="line">-rwxr-xr-x 1 XXX XXX  2960 Jul  9 23:39 start-scala-shell.sh</div><div class="line">-rwxr-xr-x 1 XXX XXX  1854 Jul  9 23:39 start-zookeeper-quorum.sh</div><div class="line">-rwxr-xr-x 1 XXX XXX  1616 Jul  9 23:39 stop-cluster.sh</div><div class="line">-rwxr-xr-x 1 XXX XXX  1845 Jul  9 23:39 stop-zookeeper-quorum.sh</div><div class="line">-rwxr-xr-x 1 XXX XXX  3543 Jul  9 23:39 taskmanager.sh</div><div class="line">-rwxr-xr-x 1 XXX XXX  1674 Jul  9 23:39 yarn-session.sh</div><div class="line">-rwxr-xr-x 1 XXX XXX  2281 Jul  9 23:39 zookeeper.sh</div><div class="line">[XXX@matt@pro flink-1.5.0]$ ll lib/</div><div class="line">total 88972</div><div class="line">-rw-r--r-- 1 XXX XXX 90458504 Jul  9 23:39 flink-dist_2.11-1.5.0.jar</div><div class="line">-rw-r--r-- 1 XXX XXX   142041 Jul  9 23:39 flink-python_2.11-1.5.0.jar</div><div class="line">-rw-r--r-- 1 XXX XXX   489884 Jul  9 23:39 <span class="built_in">log</span>4j-1.2.17.jar</div><div class="line">-rw-r--r-- 1 XXX XXX     8870 Jul  9 23:39 slf4j-log4j12-1.7.7.jar</div><div class="line">[XXX@matt@pro flink-1.5.0]$ ll opt/</div><div class="line">total 193956</div><div class="line">-rw-r--r-- 1 XXX XXX    48215 Jul  9 23:39 flink-avro-1.5.0.jar</div><div class="line">-rw-r--r-- 1 XXX XXX   124115 Jul  9 23:39 flink-cep_2.11-1.5.0.jar</div><div class="line">-rw-r--r-- 1 XXX XXX    49235 Jul  9 23:39 flink-cep-scala_2.11-1.5.0.jar</div><div class="line">-rw-r--r-- 1 XXX XXX   630006 Jul  9 23:39 flink-gelly_2.11-1.5.0.jar</div><div class="line">-rw-r--r-- 1 XXX XXX   759288 Jul  9 23:39 flink-gelly-scala_2.11-1.5.0.jar</div><div class="line">-rw-r--r-- 1 XXX XXX    21140 Jul  9 23:39 flink-json-1.5.0.jar</div><div class="line">-rw-r--r-- 1 XXX XXX    16835 Jul  9 23:39 flink-metrics-datadog-1.5.0.jar</div><div class="line">-rw-r--r-- 1 XXX XXX   136599 Jul  9 23:39 flink-metrics-dropwizard-1.5.0.jar</div><div class="line">-rw-r--r-- 1 XXX XXX   278137 Jul  9 23:39 flink-metrics-ganglia-1.5.0.jar</div><div class="line">-rw-r--r-- 1 XXX XXX   161637 Jul  9 23:39 flink-metrics-graphite-1.5.0.jar</div><div class="line">-rw-r--r-- 1 XXX XXX    89072 Jul  9 23:39 flink-metrics-prometheus-1.5.0.jar</div><div class="line">-rw-r--r-- 1 XXX XXX     6029 Jul  9 23:39 flink-metrics-slf4j-1.5.0.jar</div><div class="line">-rw-r--r-- 1 XXX XXX     7712 Jul  9 23:39 flink-metrics-statsd-1.5.0.jar</div><div class="line">-rw-r--r-- 1 XXX XXX 27197071 Jul  9 23:39 flink-ml_2.11-1.5.0.jar</div><div class="line">-rw-r--r-- 1 XXX XXX    17916 Jul  9 23:39 flink-queryable-state-runtime_2.11-1.5.0.jar</div><div class="line">-rw-r--r-- 1 XXX XXX 30676687 Jul  9 23:39 flink<span class="_">-s</span>3-fs-hadoop-1.5.0.jar</div><div class="line">-rw-r--r-- 1 XXX XXX 38244766 Jul  9 23:39 flink<span class="_">-s</span>3-fs-presto-1.5.0.jar</div><div class="line">-rw-r--r-- 1 XXX XXX 18517471 Jul  9 23:39 flink-sql-client-1.5.0.jar</div><div class="line">-rw-r--r-- 1 XXX XXX 37325999 Jul  9 23:39 flink-streaming-python_2.11-1.5.0.jar</div><div class="line">-rw-r--r-- 1 XXX XXX 26088550 Jul  9 23:39 flink-swift-fs-hadoop-1.5.0.jar</div><div class="line">-rw-r--r-- 1 XXX XXX 18172108 Jul  9 23:39 flink-table_2.11-1.5.0.jar</div><div class="line">[XXX@matt@pro flink-1.5.0]$ ll conf/</div><div class="line">total 56</div><div class="line">-rw-r--r-- 1 XXX XXX 9866 Jul  9 23:57 flink-conf.yaml</div><div class="line">-rw-r--r-- 1 XXX XXX 2138 Jul  9 23:39 <span class="built_in">log</span>4j-cli.properties</div><div class="line">-rw-r--r-- 1 XXX XXX 1884 Jul  9 23:39 <span class="built_in">log</span>4j-console.properties</div><div class="line">-rw-r--r-- 1 XXX XXX 1939 Jul  9 23:39 <span class="built_in">log</span>4j.properties</div><div class="line">-rw-r--r-- 1 XXX XXX 1709 Jul  9 23:39 <span class="built_in">log</span>4j-yarn-session.properties</div><div class="line">-rw-r--r-- 1 XXX XXX 2294 Jul  9 23:39 logback-console.xml</div><div class="line">-rw-r--r-- 1 XXX XXX 2331 Jul  9 23:39 logback.xml</div><div class="line">-rw-r--r-- 1 XXX XXX 1550 Jul  9 23:39 logback-yarn.xml</div><div class="line">-rw-r--r-- 1 XXX XXX   15 Jul  9 23:39 masters</div><div class="line">-rw-r--r-- 1 XXX XXX  120 Jul  9 23:39 slaves</div><div class="line">-rw-r--r-- 1 XXX XXX 2755 Jul  9 23:39 sql-client-defaults.yaml</div><div class="line">-rw-r--r-- 1 XXX XXX 1434 Jul  9 23:39 zoo.cfg</div></pre></td></tr></table></figure>
<p>比如这里我们想查一下 <code>sql-client.sh</code> 是做什么的？应该怎么使用？不同参数是什么意思，可以通过 help 信息查看。</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div></pre></td><td class="code"><pre><div class="line">./bin/sql-client.sh</div><div class="line">./sql-client [MODE] [OPTIONS]</div><div class="line"></div><div class="line">The following options are available:</div><div class="line"></div><div class="line">Mode <span class="string">"embedded"</span> submits Flink <span class="built_in">jobs</span> from the <span class="built_in">local</span> machine.</div><div class="line"></div><div class="line">  Syntax: embedded [OPTIONS]</div><div class="line">  <span class="string">"embedded"</span> mode options:</div><div class="line">     <span class="_">-d</span>,--defaults &lt;environment file&gt;      The environment properties with <span class="built_in">which</span></div><div class="line">                                           every new session is initialized.</div><div class="line">                                           Properties might be overwritten by</div><div class="line">                                           session properties.</div><div class="line">     <span class="_">-e</span>,--environment &lt;environment file&gt;   The environment properties to be</div><div class="line">                                           imported into the session. It might</div><div class="line">                                           overwrite default environment</div><div class="line">                                           properties.</div><div class="line">     -h,--help                             Show the <span class="built_in">help</span> message with</div><div class="line">                                           descriptions of all options.</div><div class="line">     -j,--jar &lt;JAR file&gt;                   A JAR file to be imported into the</div><div class="line">                                           session. The file might contain</div><div class="line">                                           user-defined classes needed <span class="keyword">for</span> the</div><div class="line">                                           execution of statements such as</div><div class="line">                                           <span class="built_in">functions</span>, table sources, or sinks.</div><div class="line">                                           Can be used multiple times.</div><div class="line">     <span class="_">-l</span>,--library &lt;JAR directory&gt;          A JAR file directory with <span class="built_in">which</span> every</div><div class="line">                                           new session is initialized. The files</div><div class="line">                                           might contain user-defined classes</div><div class="line">                                           needed <span class="keyword">for</span> the execution of</div><div class="line">                                           statements such as <span class="built_in">functions</span>, table</div><div class="line">                                           sources, or sinks. Can be used</div><div class="line">                                           multiple times.</div><div class="line">     <span class="_">-s</span>,--session &lt;session identifier&gt;     The identifier <span class="keyword">for</span> a session.</div><div class="line">                                           <span class="string">'default'</span> is the default identifier.</div></pre></td></tr></table></figure>
<h3 id="2-运行"><a href="#2-运行" class="headerlink" title="2. 运行"></a>2. 运行</h3><p>安装完成后，我们需要真正将系统运行起来，运行系统的时候有两个地方要特别关注：<strong>命令行和配置文件</strong>，它们主要提供了两个非常关键的信息：</p>
<ol>
<li>系统具备哪些能力（提供哪些可配置化的参数，这些参数是做什么的以及不同的配置带来的影响是什么）；</li>
<li>系统将会如何运行。</li>
</ol>
<p>这些信息是我们窥视系统内部运行机制和原理的一扇窗口。</p>
<p>例如，下面 Flink 配置中一些配置参数（Flink 集群模式的安装和运行可以参考 <a href="http://wuchong.me/blog/2016/02/26/flink-docs-setup-cluster/" target="_blank" rel="external">Flink官方文档翻译：安装部署（集群模式）</a>），通过这几个启动时的配置参数，我们可以获取下面这些信息：</p>
<ul>
<li><code>jobmanager.rpc.address</code>：The external address of the JobManager, which is the master/coordinator of the distributed system (DEFAULT: localhost)；</li>
<li><code>jobmanager.rpc.port</code>：The port number of the JobManager (DEFAULT: 6123)；</li>
<li><code>jobmanager.heap.mb</code>：JVM heap size (in megabytes) for the JobManager. You may have to increase the heap size for the JobManager if you are running very large applications (with many operators), or if you are keeping a long history of them.</li>
<li><code>taskmanager.numberOfTaskSlots</code>： JVM heap size (in megabytes) for the TaskManagers, which are the parallel workers of the system；</li>
<li><code>taskmanager.numberOfTaskSlots</code>: The number of parallel operator or user function instances that a single TaskManager can run (DEFAULT: 1).</li>
<li><code>parallelism.default</code>：The default parallelism to use for programs that have no parallelism specified. (DEFAULT: 1).；</li>
</ul>
<p>通过上面这些配置参数，我们基本上可以看到 Flink 的 Master/Salve 模型，是分为 JobManager 和 TaskManager，而 TaskManager 中又有对应的 TaskSlot，系统也提供了相应配置参数进行设置，Flink 1.5.0 的配置信息可以参考 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.5/ops/config.html" target="_blank" rel="external">Flink 1.5.0 配置</a>，社区的文档对这些参数描述得非常清楚，如果之前有大数据系统的基础，比如了解 HDFS、YARN、Spark、Storm、Kafka 的架构，那么在看到这些参数时，其实并不会感觉到太陌生，分布式系统很多东西都是相通的。</p>
<p>在通常情况下，如果我们将每个命令行参数和配置项的作用和原理都全部掌握清楚了的话，基本上对系统已经很熟悉了。这里李运华老师介绍了一个他的经验，那么就是：<strong>不管三七二十一，先把所有的配置项全部研究一遍，包括配置项的原理、作用、影响，并且尝试去修改配置项然后看看系统会有什么变化</strong>。</p>
<h3 id="3-原理研究"><a href="#3-原理研究" class="headerlink" title="3. 原理研究"></a>3. 原理研究</h3><p>在完成前两个步骤后，我们对系统已经有了初步的感觉和理解，此时可以更进一步去研究其原理。其实在研究命令行和配置项的时候已经涉及一部分原理了，但是并不是很系统，因此我们要专门针对原理进行系统性的研究。这里的关键就是<strong>系统性</strong>三个字，怎么才算系统性呢？主要体现在如下几个方面：</p>
<h4 id="3-1-关键特性的基本实现原理"><a href="#3-1-关键特性的基本实现原理" class="headerlink" title="3.1. 关键特性的基本实现原理"></a>3.1. 关键特性的基本实现原理</h4><p>每个应用广泛的开源项目之所以能够受到大众的欢迎，肯定是有一些卖点的，有一些它们的应用场景，常见的有高性能、高可用、可扩展等特性，那到底这些项目是如何做到其所宣称的那么牛的呢？这些牛的地方就是我们需要深入学习的地方：</p>
<ol>
<li>Memcache 的高性能具体是怎么做到的呢？首先是基于 libevent 实现了高性能的网络模型，其次是内存管理 Slab Allocator 机制。为了彻底理解 Memcache 的高性能网络模型，我们需要掌握很多知识：多路复用、Linux epoll、Reactor 模型、多线程等，通过研究 Memcache 的高性能网络模型，我们能够学习一个具体的项目中如何将这些东西全部串起来实现了高性能。</li>
<li>再以 React 为例，Virtual DOM 的实现原理是什么、为何要实现 Virtual DOM、React 是如何构建 Virtual DOM 树、Virtual DOM 与 DOM 什么关系等，通过研究学习 Virtual DOM，即使不使用 React，我们也能够学习如何写出高性能的前端的代码。</li>
<li>这里再以 Kafka 为例，Kafka 作为在大数据领域应用非常广泛的消息队列，它是如何实现它宣称的高性能的、高可靠？以及在 0.11.0 之后的版本它是如何实现幂等性、事务性的？在 2.0 之后是如何实现可以支撑千台机器、百万 partition 规模的？通过深入学习一些，能够让我们学学习到大数据存储系统的可靠性、高性能实现方案，以及分布式一致性（事务性）的实现；</li>
<li>最后以 Flink 为例，Flink 最开始的卖点是 Exactly once 和低延迟，现在的话再加上流式系统 SQL 的支持，那么它与 Storm、Spark streaming 相比，Flink 的 Exactly once 是怎么实现的？为什么 Storm 在现有机制上（不含 Trident）无法实现 Exactly once？Spark Streaming 微批处理模型延迟消耗主要在什么地方？为什么 Flink 可以做到低延迟？Flink  怎么实现窗口计算以及 Flink SQL 是怎么实现的，以及 Flink SQL 现在面对的问题是什么？</li>
</ol>
<h4 id="3-2-优缺点对比分析"><a href="#3-2-优缺点对比分析" class="headerlink" title="3.2. 优缺点对比分析"></a>3.2. 优缺点对比分析</h4><p>这是我想特别强调的一点，<strong>只有清楚掌握技术方案的优缺点后才算真正的掌握这门技术，也只有掌握了技术方案的优缺点后才能在架构设计的时候做出合理的选择。优缺点主要通过对比来分析，即：我们将两个类似的系统进行对比，看看它们的实现差异，以及不同的实现优缺点都是什么</strong>。</p>
<ol>
<li>典型的对比有 Memcache 和 Redis，例如（仅举例说明，实际上对比的点很多），Memcache 用多线程，Redis 用单进程，各有什么优缺点？Memcache 和 Redis 的集群方式，各有什么优缺点？</li>
<li>即使是 Redis 自身，我们也可以对比 RDB 和 AOF 两种模式的优缺点。</li>
</ol>
<h4 id="3-3-如何系统性学习一个开源项目"><a href="#3-3-如何系统性学习一个开源项目" class="headerlink" title="3.3. 如何系统性学习一个开源项目"></a>3.3. 如何系统性学习一个开源项目</h4><p>在你了解了什么是【系统性】后，我来介绍一下原理研究的手段，主要有三种：</p>
<ol>
<li>通读项目的设计文档：例如 Kafka 的设计文档，基本涵盖了消息队列设计的关键决策部分；Disruptor 的设计白皮书，详细的阐述了 Java 单机高性能的设计技巧（官方文档是学习一个项目的必须资料）。</li>
<li>阅读网上已有的分析文档：通常情况下比较热门的开源项目，都已经有非常多的分析文档了，我们可以站在前人的基础上，避免大量的重复投入。但需要注意的是，由于经验、水平、关注点等差异，不同的人分析的结论可能有差异，甚至有的是错误的，因此不能完全参照。一个比较好的方式就是多方对照，也就是说看很多篇分析文档，比较它们的内容共同点和差异点（网上分析文档很多，但是要知道如何区分这些分析文档，多对比一些，同一个东西，每个人的理解并不一定相同）。</li>
<li>Demo 验证：如果有些技术点难以查到资料，自己又不确定，则可以真正去写 Demo 进行验证，通过打印一些日志或者调试，能清晰的理解具体的细节。例如，写一个简单的分配内存程序，然后通过日志和命令行（jmap、jstat、jstack 等）来查看 Java 虚拟机垃圾回收时的具体表现（开源项目一般都会有一些实例供我们学习参考，这也是我们学习一个项目的重要资料，先去看如何使用，再去看不同使用方式背后的原理）。</li>
</ol>
<h3 id="4-测试"><a href="#4-测试" class="headerlink" title="4. 测试"></a>4. 测试</h3><p>通常情况下，如果你真的准备在实际项目中使用某个开源项目的话，必须进行测试。有的同学可能会说，网上的分析和测试文档很多，直接找一篇看就可以了？如果只是自己学习和研究，这样做是可以的，因为构建完整的测试用例既需要耗费较多时间，又需要较多机器资源，如果每个项目都这么做的话，投入成本有点大；但如果是要在实践项目中使用，必须自己进行测试，因为网上搜的测试结果，不一定与自己的业务场景很契合，如果简单参考别人的测试结果，很可能会得出错误的结论。例如，开源系统的版本不同，测试结果可能差异较大。同样是 K-V 存储，别人测试的 value 是 128 字节，而你的场景 value 都达到了 128k 字节，两者的测试结果也差异很大，不能简单照搬（在实际真正应用前，需要足够的性能测试，而且要能分析出测试结论背后的理论原因，如果找不到理论做为支撑，这样的测试并不是可信的，因为网络中环境有很大的随机性）。</p>
<p>测试阶段需要特别强调的一点就是：测试一定要在原理研究之后做，不能安装完成立马就测试！原因在于如果对系统不熟悉，很可能出现命令行、配置参数没用对，或者运行模式选择不对，导致没有根据业务的特点搭建正确的环境、没有设计合理的测试用例，从而使得最终的测试结果得出了错误结论，误导了设计决策。曾经有团队安装完成 MySQL 5.1 后就进行性能测试，测试结果出来让人大跌眼镜，经过定位才发现 <code>innodb_buffer_pool_size</code> 使用的是默认值 8M。</p>
<h3 id="5-源码研究"><a href="#5-源码研究" class="headerlink" title="5. 源码研究"></a>5. 源码研究</h3><p>源码研究的主要目的是<strong>学习原理背后的具体编码如何实现，通过学习这些技巧来提升我们自己的技术能力</strong>。例如 Redis 的 RDB 快照、Nginx 的多 Reactor 模型、Disruptor 如何使用 volatile 以及 CAS 来做无锁设计、Netty 的 Zero-Copy 等，这些技巧都很精巧，掌握后能够大大提升自己的编码能力。</p>
<p>通常情况下，不建议通读所有源码，因为想掌握每行代码的含义和作用还是非常耗费时间的，尤其是 MySQL、Nginx 这种规模的项目，即使是他们的开发人员，都不一定每个人都掌握了所有代码。带着明确目的去研究源码，做到有的放矢，才能事半功倍，这也是源码研究要放在最后的原因。</p>
<h3 id="时间分配"><a href="#时间分配" class="headerlink" title="时间分配"></a>时间分配</h3><p>前面介绍的【自顶向下】五个步骤，完整执行下来需要花费较长时间，而时间又是大部分技术人员比较稀缺的资源。很多人在学习技术的时候都会反馈说时间不够，版本进度很紧，很难有大量的时间进行学习，但如果不学习感觉自己又很难提升？面对这种两难问题，具体该如何做呢？</p>
<p>通常情况下，以上 5 个步骤的前 3 个步骤，不管是已经成为架构师的技术人员，还是立志成为架构师的技术人员，在研究开源项目的时候都必不可少；第四步可以在准备采用开源项目的时候才实施，第五步可以根据你的时间来进行灵活安排。这里的“灵活安排”不是说省略不去做，而是在自己有一定时间和精力的时候做，因为只有这样才能真正理解和学到具体的技术。</p>
<p>如果感觉自己时间和精力不够，与其蜻蜓点水每个开源项目都去简单了解一下，还不如集中精力将一个开源项目研究通透，就算是每个季度只学习一个开源项目，积累几年后这个数量也是很客观的；而且一旦你将一个项目研究透以后，再去研究其他类似项目，你会发现自己学习的非常快，因为共性的部分你已经都掌握了，只需要掌握新项目差异的部分即可。</p>
<p>这里个人的感想是，对于初中级工程师，最好还是要有2-3项目或者2-3个方向需要走到第五步，毕竟我们是靠这个吃饭的，对于其他的项目（目前业界统一的解决方案，比如 hdfs、hbase、spark 等），至少需要走到第四步，这样与这方面的专业人士沟通交流时，至少让自己不至于处在懵逼状态。当然对于这些项目的核心代码，也是可以深入学习，比如 spark 的 shuffle 在代码上是如何实现的等。在一个项目上深入之后，再去看同一个领域的其他项目时，当看到其他的架构时，其实我们基本上就可以清楚这架构设计的原因、要解决的问题以及这种设计带来的其他问题，每种设计都有其应用场景，比如对 Kafka 有了深入了解后，再看 RocketMQ、phxqueue 时，看到它们的架构方案基本上就明白要解决的问题以及其特定的应用场景，当然对一些独特的特性，还是需要深入到代码层面去学习的，比如 RocketMQ 的延迟队列实现。这是一些个人的感想，并不一定对，大家可以共同交流，总之，是感觉李运华老师这篇文章是值得总结分享的，希望自己在后面学习开源项目时，能够静下心、认真坚持学下去。</p>
<hr>
<p>最后，非常推荐极客时间李运华老师的《从0开始学架构》的专栏，里面涉猎的内容很多，讲得也都比较深入，如果能结合这个专栏去学习，是非常能开阔自己的技术视野，需要的同学可以通过下面的连接购买，会有一定的优惠。</p>
<p><img src="/images/share/learn-the-design-of-architecture.jpeg" alt="《从0开始学架构》专栏"></p>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[JVM 之 ParNew 和 CMS 日志分析]]></title>
      <url>http://matt33.com/2018/07/28/jvm-cms/</url>
      <content type="html"><![CDATA[<p>在两年前的文章 <a href="http://matt33.com/2016/09/18/jvm-basic2/">JVM 学习——垃圾收集器与内存分配策略</a> 中，已经对 GC 算法的原理以及常用的垃圾收集器做了相应的总结。今天这篇文章主要是对生产环境中（Java7）常用的两种垃圾收集器（ParNew：年轻代，CMS：老年代）从日志信息上进行分析，做一下总结，这样当我们在排查相应的问题时，看到 GC 的日志信息，不会再那么陌生，能清楚地知道这些日志是什么意思，GC 线程当前处在哪个阶段，正在做什么事情等。</p>
<h2 id="ParNew-收集器"><a href="#ParNew-收集器" class="headerlink" title="ParNew 收集器"></a>ParNew 收集器</h2><p><a href="http://matt33.com/2016/09/18/jvm-basic2/#ParNew-%E6%94%B6%E9%9B%86%E5%99%A8">ParNew 收集器</a>是年轻代常用的垃圾收集器，它采用的是复制算法，youngGC 时一个典型的日志信息如下所示：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">2018-04-12T13:48:26.134+0800: 15578.050: [GC2018-04-12T13:48:26.135+0800: 15578.050: [ParNew: 3412467K-&gt;59681K(3774912K), 0.0971990 secs] 9702786K-&gt;6354533K(24746432K), 0.0974940 secs] [Times: user=0.95 sys=0.00, real=0.09 secs]</div></pre></td></tr></table></figure>
<p>依次分析一下上面日志信息的含义：</p>
<ul>
<li><code>2018-04-12T13:48:26.134+0800</code>：Mirror GC 发生的时间；</li>
<li><code>15578.050</code>：GC 开始时，相对 JVM 启动的相对时间，单位时秒，这里是4h+；</li>
<li><code>ParNew</code>：收集器名称，这里是 ParNew 收集器，它使用的是并行的 mark-copy 算法，GC 过程也会 Stop the World；</li>
<li><code>3412467K-&gt;59681K</code>：收集前后年轻代的使用情况，这里是 3.25G-&gt;58.28M；</li>
<li><code>3774912K</code>：整个年轻代的容量，这里是 3.6G；</li>
<li><code>0.0971990 secs</code>：Duration for the collection w/o final cleanup.</li>
<li><code>9702786K-&gt;6354533K</code>：收集前后整个堆的使用情况，这里是 9.25G-&gt;6.06G;</li>
<li><code>24746432K</code>：整个堆的容量，这里是 23.6G；</li>
<li><code>0.0974940 secs</code>：ParNew 收集器标记和复制年轻代活着的对象所花费的时间（包括和老年代通信的开销、对象晋升到老年代开销、垃圾收集周期结束一些最后的清理对象等的花销）；</li>
</ul>
<p>对于 <code>[Times: user=0.95 sys=0.00, real=0.09 secs]</code>，这里面涉及到三种时间类型，含义如下：</p>
<ul>
<li>user：GC 线程在垃圾收集期间所使用的 CPU 总时间；</li>
<li>sys：系统调用或者等待系统事件花费的时间；</li>
<li>real：应用被暂停的时钟时间，由于 GC 线程是多线程的，导致了 real 小于 (user+real)，如果是 gc 线程是单线程的话，real 是接近于 (user+real) 时间。</li>
</ul>
<h2 id="CMS-收集器"><a href="#CMS-收集器" class="headerlink" title="CMS 收集器"></a>CMS 收集器</h2><p><a href="http://matt33.com/2016/09/18/jvm-basic2/#CMS-%E6%94%B6%E9%9B%86%E5%99%A8">CMS 收集器</a>是老年代经常使用的收集器，它采用的是标记-清楚算法，应用程序在发生一次 Full GC 时，典型的 GC 日志信息如下：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line">2018-04-12T13:48:26.233+0800: 15578.148: [GC [1 CMS-initial-mark: 6294851K(20971520K)] 6354687K(24746432K), 0.0466580 secs] [Times: user=0.04 sys=0.00, real=0.04 secs]</div><div class="line">2018-04-12T13:48:26.280+0800: 15578.195: [CMS-concurrent-mark-start]</div><div class="line">2018-04-12T13:48:26.418+0800: 15578.333: [CMS-concurrent-mark: 0.138/0.138 secs] [Times: user=1.01 sys=0.21, real=0.14 secs]</div><div class="line">2018-04-12T13:48:26.418+0800: 15578.334: [CMS-concurrent-preclean-start]</div><div class="line">2018-04-12T13:48:26.476+0800: 15578.391: [CMS-concurrent-preclean: 0.056/0.057 secs] [Times: user=0.20 sys=0.12, real=0.06 secs]</div><div class="line">2018-04-12T13:48:26.476+0800: 15578.391: [CMS-concurrent-abortable-preclean-start]</div><div class="line">2018-04-12T13:48:29.989+0800: 15581.905: [CMS-concurrent-abortable-preclean: 3.506/3.514 secs] [Times: user=11.93 sys=6.77, real=3.51 secs]</div><div class="line">2018-04-12T13:48:29.991+0800: 15581.906: [GC[YG occupancy: 1805641 K (3774912 K)]2018-04-12T13:48:29.991+0800: 15581.906: [GC2018-04-12T13:48:29.991+0800: 15581.906: [ParNew: 1805641K-&gt;48395K(3774912K), 0.0826620 secs] 8100493K-&gt;6348225K(24746432K), 0.0829480 secs] [Times: user=0.81 sys=0.00, real=0.09 secs]2018-04-12T13:48:30.074+0800: 15581.989: [Rescan (parallel) , 0.0429390 secs]2018-04-12T13:48:30.117+0800: 15582.032: [weak refs processing, 0.0027800 secs]2018-04-12T13:48:30.119+0800: 15582.035: [class unloading, 0.0033120 secs]2018-04-12T13:48:30.123+0800: 15582.038: [scrub symbol table, 0.0016780 secs]2018-04-12T13:48:30.124+0800: 15582.040: [scrub string table, 0.0004780 secs] [1 CMS-remark: 6299829K(20971520K)] 6348225K(24746432K), 0.1365130 secs] [Times: user=1.24 sys=0.00, real=0.14 secs]</div><div class="line">2018-04-12T13:48:30.128+0800: 15582.043: [CMS-concurrent-sweep-start]</div><div class="line">2018-04-12T13:48:36.638+0800: 15588.553: [GC2018-04-12T13:48:36.638+0800: 15588.554: [ParNew: 3403915K-&gt;52142K(3774912K), 0.0874610 secs] 4836483K-&gt;1489601K(24746432K), 0.0877490 secs] [Times: user=0.84 sys=0.00, real=0.09 secs]</div><div class="line">2018-04-12T13:48:38.412+0800: 15590.327: [CMS-concurrent-sweep: 8.193/8.284 secs] [Times: user=30.34 sys=16.44, real=8.28 secs]</div><div class="line">2018-04-12T13:48:38.419+0800: 15590.334: [CMS-concurrent-reset-start]</div><div class="line">2018-04-12T13:48:38.462+0800: 15590.377: [CMS-concurrent-reset: 0.044/0.044 secs] [Times: user=0.15 sys=0.10, real=0.04 secs]</div></pre></td></tr></table></figure>
<p>CMS Full GC 拆分开来，涉及的阶段比较多，下面分别来介绍各个阶段的情况。</p>
<h3 id="阶段1：Initial-Mark"><a href="#阶段1：Initial-Mark" class="headerlink" title="阶段1：Initial Mark"></a>阶段1：Initial Mark</h3><p>这个是 CMS 两次 stop-the-wolrd 事件的其中一次，这个阶段的目标是：标记那些直接被 GC root 引用或者被年轻代存活对象所引用的所有对象，标记后示例如下所示（插图来自：<a href="https://plumbr.io/handbook/garbage-collection-algorithms-implementations#concurrent-mark-and-sweep" target="_blank" rel="external">GC Algorithms：Implementations —— Concurrent Mark and Sweep —— Full GC</a>）：</p>
<p><img src="/images/java/cms-1.png" alt="CMS 初始标记阶段"></p>
<p>上述例子对应的日志信息为：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">2018-04-12T13:48:26.233+0800: 15578.148: [GC [1 CMS-initial-mark: 6294851K(20971520K)] 6354687K(24746432K), 0.0466580 secs] [Times: user=0.04 sys=0.00, real=0.04 secs]</div></pre></td></tr></table></figure>
<p>逐行介绍上面日志的含义：</p>
<ol>
<li><code>2018-04-12T13:48:26.233+0800: 15578.148</code>：GC 开始的时间，以及相对于 JVM 启动的相对时间（单位是秒，这里大概是4.33h），与前面 ParNew 类似，下面的分析中就直接跳过这个了；</li>
<li><code>CMS-initial-mark</code>：初始标记阶段，它会收集所有 GC Roots 以及其直接引用的对象；</li>
<li><code>6294851K</code>：当前老年代使用的容量，这里是 6G；</li>
<li><code>(20971520K)</code>：老年代可用的最大容量，这里是 20G；</li>
<li><code>6354687K</code>：整个堆目前使用的容量，这里是 6.06G；</li>
<li><code>(24746432K)</code>：堆可用的容量，这里是 23.6G；</li>
<li><code>0.0466580 secs</code>：这个阶段的持续时间；</li>
<li><code>[Times: user=0.04 sys=0.00, real=0.04 secs]</code>：与前面的类似，这里是相应 user、system and real 的时间统计。</li>
</ol>
<h3 id="阶段2：并发标记"><a href="#阶段2：并发标记" class="headerlink" title="阶段2：并发标记"></a>阶段2：并发标记</h3><p>在这个阶段 Garbage Collector 会遍历老年代，然后标记所有存活的对象，它会根据上个阶段找到的 GC Roots 遍历查找。并发标记阶段，它会与用户的应用程序并发运行。并不是老年代所有的存活对象都会被标记，因为在标记期间用户的程序可能会改变一些引用，如下图所示（插图来自：<a href="https://plumbr.io/handbook/garbage-collection-algorithms-implementations#concurrent-mark-and-sweep" target="_blank" rel="external">GC Algorithms：Implementations —— Concurrent Mark and Sweep —— Full GC</a>）：</p>
<p><img src="/images/java/cms-2.png" alt="CMS 并发标记阶段"></p>
<p>在上面的图中，与阶段1的图进行对比，就会发现有一个对象的引用已经发生了变化，这个阶段相应的日志信息如下：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">2018-04-12T13:48:26.280+0800: 15578.195: [CMS-concurrent-mark-start]</div><div class="line">2018-04-12T13:48:26.418+0800: 15578.333: [CMS-concurrent-mark: 0.138/0.138 secs] [Times: user=1.01 sys=0.21, real=0.14 secs]</div></pre></td></tr></table></figure>
<p>这里详细对上面的日志解释，如下所示：</p>
<ol>
<li><code>CMS-concurrent-mark</code>：并发收集阶段，这个阶段会遍历老年代，并标记所有存活的对象；</li>
<li><code>0.138/0.138 secs</code>：这个阶段的持续时间与时钟时间；</li>
<li><code>[Times: user=1.01 sys=0.21, real=0.14 secs]</code>：如前面所示，但是这部的时间，其实意义不大，因为它是从并发标记的开始时间开始计算，这期间因为是并发进行，不仅仅包含 GC 线程的工作。</li>
</ol>
<h3 id="阶段3：Concurrent-Preclean"><a href="#阶段3：Concurrent-Preclean" class="headerlink" title="阶段3：Concurrent Preclean"></a>阶段3：Concurrent Preclean</h3><p>Concurrent Preclean：这也是一个并发阶段，与应用的线程并发运行，并不会 stop 应用的线程。在并发运行的过程中，一些对象的引用可能会发生变化，但是这种情况发生时，JVM 会将包含这个对象的区域（Card）标记为 Dirty，这也就是 Card Marking。如下图所示（插图来自：<a href="https://plumbr.io/handbook/garbage-collection-algorithms-implementations#concurrent-mark-and-sweep" target="_blank" rel="external">GC Algorithms：Implementations —— Concurrent Mark and Sweep —— Full GC</a>：</p>
<p><img src="/images/java/cms-3.png" alt="Concurrent Preclean 1"></p>
<p>在pre-clean阶段，那些能够从 Dirty 对象到达的对象也会被标记，这个标记做完之后，dirty card 标记就会被清除了，如下（插图来自：<a href="https://plumbr.io/handbook/garbage-collection-algorithms-implementations#concurrent-mark-and-sweep" target="_blank" rel="external">GC Algorithms：Implementations —— Concurrent Mark and Sweep —— Full GC</a>：</p>
<p><img src="/images/java/cms-4.png" alt="Concurrent Preclean 2"></p>
<p>这个阶段相应的日志信息如下：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">2018-04-12T13:48:26.418+0800: 15578.334: [CMS-concurrent-preclean-start]</div><div class="line">2018-04-12T13:48:26.476+0800: 15578.391: [CMS-concurrent-preclean: 0.056/0.057 secs] [Times: user=0.20 sys=0.12, real=0.06 secs]</div></pre></td></tr></table></figure>
<p>其含义为：</p>
<ol>
<li><code>CMS-concurrent-preclean</code>：Concurrent Preclean 阶段，对在前面并发标记阶段中引用发生变化的对象进行标记；</li>
<li><code>0.056/0.057 secs</code>：这个阶段的持续时间与时钟时间；</li>
<li><code>[Times: user=0.20 sys=0.12, real=0.06 secs]</code>：同并发标记阶段中的含义。</li>
</ol>
<h3 id="阶段4：Concurrent-Abortable-Preclean"><a href="#阶段4：Concurrent-Abortable-Preclean" class="headerlink" title="阶段4：Concurrent Abortable Preclean"></a>阶段4：Concurrent Abortable Preclean</h3><p>这也是一个并发阶段，但是同样不会影响影响用户的应用线程，这个阶段是为了尽量承担 STW（stop-the-world）中最终标记阶段的工作。这个阶段持续时间依赖于很多的因素，由于这个阶段是在重复做很多相同的工作，直接满足一些条件（比如：重复迭代的次数、完成的工作量或者时钟时间等）。这个阶段的日志信息如下：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">2018-04-12T13:48:26.476+0800: 15578.391: [CMS-concurrent-abortable-preclean-start]</div><div class="line">2018-04-12T13:48:29.989+0800: 15581.905: [CMS-concurrent-abortable-preclean: 3.506/3.514 secs] [Times: user=11.93 sys=6.77, real=3.51 secs]</div></pre></td></tr></table></figure>
<ol>
<li><code>CMS-concurrent-abortable-preclean</code>：Concurrent Abortable Preclean 阶段；</li>
<li><code>3.506/3.514 secs</code>：这个阶段的持续时间与时钟时间，本质上，这里的 gc 线程会在 STW 之前做更多的工作，通常会持续 5s 左右；</li>
<li><code>[Times: user=11.93 sys=6.77, real=3.51 secs]</code>：同前面。</li>
</ol>
<h3 id="阶段5：Final-Remark"><a href="#阶段5：Final-Remark" class="headerlink" title="阶段5：Final Remark"></a>阶段5：Final Remark</h3><p>这是第二个 STW 阶段，也是 CMS 中的最后一个，这个阶段的目标是标记所有老年代所有的存活对象，由于之前的阶段是并发执行的，gc 线程可能跟不上应用程序的变化，为了完成标记老年代所有存活对象的目标，STW 就非常有必要了。</p>
<p>通常 CMS 的 Final Remark 阶段会在年轻代尽可能干净的时候运行，目的是为了减少连续 STW 发生的可能性（年轻代存活对象过多的话，也会导致老年代涉及的存活对象会很多）。这个阶段会比前面的几个阶段更复杂一些，相关日志如下：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">2018-04-12T13:48:29.991+0800: 15581.906: [GC[YG occupancy: 1805641 K (3774912 K)]2018-04-12T13:48:29.991+0800: 15581.906: [GC2018-04-12T13:48:29.991+0800: 15581.906: [ParNew: 1805641K-&gt;48395K(3774912K), 0.0826620 secs] 8100493K-&gt;6348225K(24746432K), 0.0829480 secs] [Times: user=0.81 sys=0.00, real=0.09 secs]2018-04-12T13:48:30.074+0800: 15581.989: [Rescan (parallel) , 0.0429390 secs]2018-04-12T13:48:30.117+0800: 15582.032: [weak refs processing, 0.0027800 secs]2018-04-12T13:48:30.119+0800: 15582.035: [class unloading, 0.0033120 secs]2018-04-12T13:48:30.123+0800: 15582.038: [scrub symbol table, 0.0016780 secs]2018-04-12T13:48:30.124+0800: 15582.040: [scrub string table, 0.0004780 secs] [1 CMS-remark: 6299829K(20971520K)] 6348225K(24746432K), 0.1365130 secs] [Times: user=1.24 sys=0.00, real=0.14 secs]</div></pre></td></tr></table></figure>
<p>对上面的日志进行分析：</p>
<ol>
<li><code>YG occupancy: 1805641 K (3774912 K)</code>：年轻代当前占用量及容量，这里分别是 1.71G 和 3.6G；</li>
<li><code>ParNew:...</code>：触发了一次 young GC，这里触发的原因是为了减少年轻代的存活对象，尽量使年轻代更干净一些；</li>
<li><code>[Rescan (parallel) , 0.0429390 secs]</code>：这个 Rescan 是当应用暂停的情况下完成对所有存活对象的标记，这个阶段是并行处理的，这里花费了  0.0429390s；</li>
<li><code>[weak refs processing, 0.0027800 secs]</code>：第一个子阶段，它的工作是处理弱引用；</li>
<li><code>[class unloading, 0.0033120 secs]</code>：第二个子阶段，它的工作是：unloading the unused classes；</li>
<li><code>[scrub symbol table, 0.0016780 secs] ... [scrub string table, 0.0004780 secs]</code>：最后一个子阶段，它的目的是：cleaning up symbol and string tables which hold class-level metadata and internalized string respectively，时钟的暂停也包含在这里；</li>
<li><code>6299829K(20971520K)</code>：这个阶段之后，老年代的使用量与总量，这里分别是 6G 和 20G；</li>
<li><code>6348225K(24746432K)</code>：这个阶段之后，堆的使用量与总量（包括年轻代，年轻代在前面发生过 GC），这里分别是 6.05G 和 23.6G；</li>
<li><code>0.1365130 secs</code>：这个阶段的持续时间；</li>
<li><code>[Times: user=1.24 sys=0.00, real=0.14 secs]</code>：对应的时间信息。</li>
</ol>
<p>经历过这五个阶段之后，老年代所有存活的对象都被标记过了，现在可以通过清除算法去清理那些老年代不再使用的对象。</p>
<h3 id="阶段6：Concurrent-Sweep"><a href="#阶段6：Concurrent-Sweep" class="headerlink" title="阶段6：Concurrent Sweep"></a>阶段6：Concurrent Sweep</h3><p>这里不需要 STW，它是与用户的应用程序并发运行，这个阶段是：清除那些不再使用的对象，回收它们的占用空间为将来使用。如下图所示（插图来自：<a href="https://plumbr.io/handbook/garbage-collection-algorithms-implementations#concurrent-mark-and-sweep" target="_blank" rel="external">GC Algorithms：Implementations —— Concurrent Mark and Sweep —— Full GC</a>：<br>）：</p>
<p><img src="/images/java/cms-5.png" alt="CMS Concurrent Sweep 阶段"></p>
<p>这个阶段对应的日志信息如下（这中间又发生了一次 Young GC）：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">2018-04-12T13:48:30.128+0800: 15582.043: [CMS-concurrent-sweep-start]</div><div class="line">2018-04-12T13:48:36.638+0800: 15588.553: [GC2018-04-12T13:48:36.638+0800: 15588.554: [ParNew: 3403915K-&gt;52142K(3774912K), 0.0874610 secs] 4836483K-&gt;1489601K(24746432K), 0.0877490 secs] [Times: user=0.84 sys=0.00, real=0.09 secs]</div><div class="line">2018-04-12T13:48:38.412+0800: 15590.327: [CMS-concurrent-sweep: 8.193/8.284 secs] [Times: user=30.34 sys=16.44, real=8.28 secs]</div></pre></td></tr></table></figure>
<p>分别介绍一下：</p>
<ol>
<li><code>CMS-concurrent-sweep</code>：这个阶段主要是清除那些没有被标记的对象，回收它们的占用空间；</li>
<li><code>8.193/8.284 secs</code>：这个阶段的持续时间与时钟时间；</li>
<li><code>[Times: user=30.34 sys=16.44, real=8.28 secs]</code>：同前面；</li>
</ol>
<h3 id="阶段7：Concurrent-Reset"><a href="#阶段7：Concurrent-Reset" class="headerlink" title="阶段7：Concurrent Reset."></a>阶段7：Concurrent Reset.</h3><p>这个阶段也是并发执行的，它会重设 CMS 内部的数据结构，为下次的 GC 做准备，对应的日志信息如下：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">2018-04-12T13:48:38.419+0800: 15590.334: [CMS-concurrent-reset-start]</div><div class="line">2018-04-12T13:48:38.462+0800: 15590.377: [CMS-concurrent-reset: 0.044/0.044 secs] [Times: user=0.15 sys=0.10, real=0.04 secs]</div></pre></td></tr></table></figure>
<p>日志详情分别如下：</p>
<ol>
<li><code>CMS-concurrent-reset</code>：这个阶段的开始，目的如前面所述；</li>
<li><code>0.044/0.044 secs</code>：这个阶段的持续时间与时钟时间；</li>
<li><code>[Times: user=0.15 sys=0.10, real=0.04 secs]</code>：同前面。</li>
</ol>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>CMS 通过将大量工作分散到并发处理阶段来在减少 STW 时间，在这块做得非常优秀，但是 CMS 也有一些其他的问题：</p>
<ol>
<li>CMS 收集器无法处理浮动垃圾（ Floating Garbage），可能出现 “Concurrnet Mode Failure” 失败而导致另一次 Full GC 的产生，可能引发串行 Full GC；</li>
<li>空间碎片，导致无法分配大对象，CMS 收集器提供了一个 <code>-XX:+UseCMSCompactAtFullCollection</code> 开关参数（默认就是开启的），用于在 CMS 收集器顶不住要进行 Full GC 时开启内存碎片的合并整理过程，内存整理的过程是无法并发的，空间碎片问题没有了，但停顿时间不得不变长；</li>
<li>对于堆比较大的应用上，GC 的时间难以预估。</li>
</ol>
<p>CMS 的一些缺陷也是 G1 收集器兴起的原因。</p>
<p>参考：</p>
<ul>
<li><a href="https://t.hao0.me/jvm/2016/03/15/jvm-gc-log.html" target="_blank" rel="external">JVM各类GC日志剖析</a>；</li>
<li><a href="http://www.cnblogs.com/zhangxiaoguang/p/5792468.html" target="_blank" rel="external">GC之详解CMS收集过程和日志分析</a>；</li>
<li><a href="http://www.oracle.com/technetwork/tutorials/tutorials-1876574.html" target="_blank" rel="external">Getting Started with the G1 Garbage Collector</a>；</li>
<li><a href="http://ifeve.com/useful-jvm-flags-part-7-cms-collector/" target="_blank" rel="external">JVM实用参数（七）CMS收集器</a>；</li>
<li><a href="https://plumbr.io/handbook/garbage-collection-algorithms-implementations#concurrent-mark-and-sweep" target="_blank" rel="external">GC Algorithms：Implementations —— Concurrent Mark and Sweep —— Full GC</a>；</li>
</ul>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[HDFS 架构学习总结]]></title>
      <url>http://matt33.com/2018/07/15/hdfs-architecture-learn/</url>
      <content type="html"><![CDATA[<p>HDFS（Hadoop Distributed File System）是一个分布式文件存储系统，几乎是离线存储领域的标准解决方案（有能力自研的大厂列外），业内应用非常广泛。近段抽时间，看一下 HDFS 的架构设计，虽然研究生也学习过相关内容，但是现在基本忘得差不多了，今天抽空对这块做了一个简单的总结，也算是再温习了一下这块的内容，这样后续再看 HDFS 方面的文章时，不至于处于懵逼状态。</p>
<h2 id="HDFS-1-0-架构"><a href="#HDFS-1-0-架构" class="headerlink" title="HDFS 1.0 架构"></a>HDFS 1.0 架构</h2><p>HDFS 采用的是 Master/Slave 架构，一个 HDFS 集群包含一个单独的 NameNode 和多个 DataNode 节点，如下图所示（这个图是 HDFS1.0的架构图，经典的架构图）：</p>
<p><img src="/images/hadoop/hdfs.jpg" alt="HDFS 1.0 架构图"></p>
<h3 id="NameNode"><a href="#NameNode" class="headerlink" title="NameNode"></a>NameNode</h3><p>NameNode 负责管理整个分布式系统的元数据，主要包括：</p>
<ul>
<li>目录树结构；</li>
<li>文件到数据库 Block 的映射关系；</li>
<li>Block 副本及其存储位置等管理数据；</li>
<li>DataNode 的状态监控，两者通过段时间间隔的心跳来传递管理信息和数据信息，通过这种方式的信息传递，NameNode 可以获知每个 DataNode 保存的 Block 信息、DataNode 的健康状况、命令 DataNode 启动停止等（如果发现某个 DataNode 节点故障，NameNode 会将其负责的 block 在其他 DataNode 上进行备份）。</li>
</ul>
<p>这些数据保存在内存中，同时在磁盘保存两个元数据管理文件：fsimage 和 editlog。</p>
<ul>
<li>fsimage：是内存命名空间元数据在外存的镜像文件；</li>
<li>editlog：则是各种元数据操作的 write-ahead-log 文件，在体现到内存数据变化前首先会将操作记入 editlog 中，以防止数据丢失。</li>
</ul>
<p>这两个文件相结合可以构造完整的内存数据。</p>
<h3 id="Secondary-NameNode"><a href="#Secondary-NameNode" class="headerlink" title="Secondary NameNode"></a>Secondary NameNode</h3><p>Secondary NameNode 并不是 NameNode 的热备机，而是定期从 NameNode 拉取 fsimage 和 editlog 文件，并对两个文件进行合并，形成新的 fsimage 文件并传回 NameNode，这样做的目的是减轻 NameNod 的工作压力，本质上 SNN 是一个提供检查点功能服务的服务点。</p>
<h3 id="DataNode"><a href="#DataNode" class="headerlink" title="DataNode"></a>DataNode</h3><p>负责数据块的实际存储和读写工作，Block 默认是64MB（HDFS2.0改成了128MB），当客户端上传一个大文件时，HDFS 会自动将其切割成固定大小的 Block，为了保证数据可用性，每个 Block 会以多备份的形式存储，默认是3份。</p>
<h3 id="文件写入过程"><a href="#文件写入过程" class="headerlink" title="文件写入过程"></a>文件写入过程</h3><p>Client 向 HDFS 文件写入的过程可以参考<a href="http://shiyanjun.cn/archives/942.html" target="_blank" rel="external">HDFS写文件过程分析</a>，整体过程如下图（这个图比较经典，最开始来自<a href="https://book.douban.com/subject/3220004/" target="_blank" rel="external">《Hadoop：The Definitive Guide》</a>）所示：</p>
<p><img src="/images/hadoop/hdfs-write-flow.png" alt="HDFS 文件写入过程"></p>
<p>具体过程如下：</p>
<ol>
<li>Client 调用 DistributedFileSystem 对象的 <code>create</code> 方法，创建一个文件输出流（FSDataOutputStream）对象；</li>
<li>通过 DistributedFileSystem 对象与集群的 NameNode 进行一次 RPC 远程调用，在 HDFS 的 Namespace 中创建一个文件条目（Entry），此时该条目没有任何的 Block，NameNode 会返回该数据每个块需要拷贝的 DataNode 地址信息；</li>
<li>通过 FSDataOutputStream 对象，开始向 DataNode 写入数据，数据首先被写入 FSDataOutputStream 对象内部的数据队列中，数据队列由 DataStreamer 使用，它通过选择合适的 DataNode 列表来存储副本，从而要求 NameNode 分配新的 block；</li>
<li>DataStreamer 将数据包以流式传输的方式传输到分配的第一个 DataNode 中，该数据流将数据包存储到第一个 DataNode 中并将其转发到第二个 DataNode 中，接着第二个 DataNode 节点会将数据包转发到第三个 DataNode 节点；</li>
<li>DataNode 确认数据传输完成，最后由第一个 DataNode 通知 client 数据写入成功；</li>
<li>完成向文件写入数据，Client 在文件输出流（FSDataOutputStream）对象上调用 <code>close</code> 方法，完成文件写入；</li>
<li>调用 DistributedFileSystem 对象的 complete 方法，通知 NameNode 文件写入成功，NameNode 会将相关结果记录到 editlog 中。</li>
</ol>
<h3 id="文件读取过程"><a href="#文件读取过程" class="headerlink" title="文件读取过程"></a>文件读取过程</h3><p>相对于文件写入，文件的读取就简单一些，流程如下图所示：</p>
<p><img src="/images/hadoop/hdfs-read-flow.png" alt="HDFS 文件读取过程"></p>
<p>其具体过程总结如下（简单总结一下）：</p>
<ol>
<li>Client 通过 DistributedFileSystem 对象与集群的 NameNode 进行一次 RPC 远程调用，获取文件 block 位置信息；</li>
<li>NameNode 返回存储的每个块的 DataNode 列表；</li>
<li>Client 将连接到列表中最近的 DataNode；</li>
<li>Client 开始从 DataNode 并行读取数据；</li>
<li>一旦 Client 获得了所有必须的 block，它就会将这些 block 组合起来形成一个文件。</li>
</ol>
<p>在处理 Client 的读取请求时，HDFS 会利用机架感知选举最接近 Client 位置的副本，这将会减少读取延迟和带宽消耗。</p>
<h2 id="HDFS-1-0-的问题"><a href="#HDFS-1-0-的问题" class="headerlink" title="HDFS 1.0 的问题"></a>HDFS 1.0 的问题</h2><p>在前面的介绍中，关于 HDFS1.0 的架构，首先都会看到 NameNode 的单点问题，这个在生产环境中是非常要命的问题，早期的 HDFS 由于规模较小，有些问题就被隐藏了，但自从进入了移动互联网时代，很多公司都开始进入了 PB 级的大数据时代，HDFS 1.0的设计缺陷已经无法满足生产的需求，最致命的问题有以下两点：</p>
<ul>
<li>NameNode 的单点问题，如果 NameNode 挂掉了，数据读写都会受到影响，HDFS 整体将变得不可用，这在生产环境中是不可接受的；</li>
<li>水平扩展问题，随着集群规模的扩大，1.0 时集群规模达到3000时，会导致整个集群管理的文件数目达到上限（因为 NameNode 要管理整个集群 block 元信息、数据目录信息等）。</li>
</ul>
<p>为了解决上面的两个问题，Hadoop2.0 提供一套统一的解决方案：</p>
<ol>
<li>HA（High Availability 高可用方案）：这个是为了解决 NameNode 单点问题；</li>
<li>NameNode Federation：是用来解决 HDFS 集群的线性扩展能力。</li>
</ol>
<h2 id="HDFS-2-0-的-HA-实现"><a href="#HDFS-2-0-的-HA-实现" class="headerlink" title="HDFS 2.0 的 HA 实现"></a>HDFS 2.0 的 HA 实现</h2><p>关于 HDFS 高可用方案，非常推荐这篇文章：<a href="https://www.ibm.com/developerworks/cn/opensource/os-cn-hadoop-name-node/" target="_blank" rel="external">Hadoop NameNode 高可用 (High Availability) 实现解析</a>，IBM 博客的质量确实很高，这部分我这里也是主要根据这篇文章做一个总结，这里会从问题的原因、如何解决的角度去总结，并不会深入源码的实现细节，想有更深入了解还是推荐上面文章。</p>
<p>这里先看下 HDFS 高可用解决方案的架构设计，如下图（下图来自上面的文章）所示：</p>
<p><img src="/images/hadoop/hdfs-ha.png" alt="HDFS HA 架构实现"></p>
<p>这里与前面 1.0 的架构已经有很大变化，简单介绍一下上面的组件：</p>
<ol>
<li>Active NameNode 和 Standby NameNode：两台 NameNode 形成互备，一台处于 Active 状态，为主 NameNode，另外一台处于 Standby 状态，为备 NameNode，只有主 NameNode 才能对外提供读写服务；</li>
<li>ZKFailoverController（主备切换控制器，FC）：ZKFailoverController 作为独立的进程运行，对 NameNode 的主备切换进行总体控制。ZKFailoverController 能及时检测到 NameNode 的健康状况，在主 NameNode 故障时借助 Zookeeper 实现自动的主备选举和切换（当然 NameNode 目前也支持不依赖于 Zookeeper 的手动主备切换）；</li>
<li>Zookeeper 集群：为主备切换控制器提供主备选举支持；</li>
<li>共享存储系统：共享存储系统是实现 NameNode 的高可用最为关键的部分，共享存储系统保存了 NameNode 在运行过程中所产生的 HDFS 的元数据。主 NameNode 和备 NameNode 通过共享存储系统实现元数据同步。在进行主备切换的时候，新的主 NameNode 在<strong>确认元数据完全同步之后才能继续对外提供服务</strong>。</li>
<li>DataNode 节点：因为主 NameNode 和备 NameNode 需要共享 HDFS 的数据块和 DataNode 之间的映射关系，为了使故障切换能够快速进行，DataNode 会同时向主 NameNode 和备 NameNode 上报数据块的位置信息。</li>
</ol>
<h3 id="FailoverController"><a href="#FailoverController" class="headerlink" title="FailoverController"></a>FailoverController</h3><p>FC 最初的目的是为了实现 SNN 和 ANN 之间故障自动切换，FC 是独立与 NN 之外的故障切换控制器，ZKFC 作为 NameNode 机器上一个独立的进程启动 ，它启动的时候会创建 HealthMonitor 和 ActiveStandbyElector 这两个主要的内部组件，其中：</p>
<ol>
<li>HealthMonitor：主要负责检测 NameNode 的健康状态，如果检测到 NameNode 的状态发生变化，会回调 ZKFailoverController 的相应方法进行自动的主备选举；</li>
<li>ActiveStandbyElector：主要负责完成自动的主备选举，内部封装了 Zookeeper 的处理逻辑，一旦 Zookeeper 主备选举完成，会回调 ZKFailoverController 的相应方法来进行 NameNode 的主备状态切换。</li>
</ol>
<h3 id="自动触发主备选举"><a href="#自动触发主备选举" class="headerlink" title="自动触发主备选举"></a>自动触发主备选举</h3><p>NameNode 在选举成功后，会在 zk 上创建了一个 <code>/hadoop-ha/${dfs.nameservices}/ActiveStandbyElectorLock</code> 节点，而没有选举成功的备 NameNode 会监控这个节点，通过 Watcher 来监听这个节点的状态变化事件，ZKFC 的 ActiveStandbyElector 主要关注这个节点的 NodeDeleted 事件（这部分实现跟 Kafka 中 Controller 的选举一样）。</p>
<p>如果 Active NameNode 对应的 HealthMonitor 检测到 NameNode 的状态异常时， ZKFailoverController 会主动删除当前在 Zookeeper 上建立的临时节点 /hadoop-ha/${dfs.nameservices}/ActiveStandbyElectorLock，这样处于 Standby 状态的 NameNode 的 ActiveStandbyElector 注册的监听器就会收到这个节点的 NodeDeleted 事件。收到这个事件之后，会马上再次进入到创建 /hadoop-ha/${dfs.nameservices}/ActiveStandbyElectorLock  节点的流程，如果创建成功，这个本来处于 Standby 状态的 NameNode 就选举为主 NameNode 并随后开始切换为 Active 状态。</p>
<p>当然，如果是 Active 状态的 NameNode 所在的机器整个宕掉的话，那么根据 Zookeeper 的临时节点特性，/hadoop-ha/${dfs.nameservices}/ActiveStandbyElectorLock 节点会自动被删除，从而也会自动进行一次主备切换。</p>
<h3 id="HDFS-脑裂问题"><a href="#HDFS-脑裂问题" class="headerlink" title="HDFS 脑裂问题"></a>HDFS 脑裂问题</h3><p>在实际中，NameNode 可能会出现这种情况，NameNode 在垃圾回收（GC）时，可能会在长时间内整个系统无响应，因此，也就无法向 zk 写入心跳信息，这样的话可能会导致临时节点掉线，备 NameNode 会切换到 Active 状态，这种情况，可能会导致整个集群会有同时有两个 NameNode，这就是脑裂问题。</p>
<p>脑裂问题的解决方案是隔离（Fencing），主要是在以下三处采用隔离措施：</p>
<ol>
<li>第三方共享存储：任一时刻，只有一个 NN 可以写入；</li>
<li>DataNode：需要保证只有一个 NN 发出与管理数据副本有关的删除命令；</li>
<li>Client：需要保证同一时刻只有一个 NN 能够对 Client 的请求发出正确的响应。</li>
</ol>
<p>关于这个问题目前解决方案的实现如下：</p>
<ol>
<li>ActiveStandbyElector 为了实现 fencing，会在成功创建 Zookeeper 节点 hadoop-ha/${dfs.nameservices}/ActiveStandbyElectorLock 从而成为 Active NameNode 之后，创建另外一个路径为 <strong>/hadoop-ha/${dfs.nameservices}/ActiveBreadCrumb</strong> 的持久节点，这个节点里面保存了这个 Active NameNode 的地址信息；</li>
<li>Active NameNode 的 ActiveStandbyElector 在正常的状态下关闭 Zookeeper Session 的时候，会一起删除这个持久节点；</li>
<li>但如果 ActiveStandbyElector 在异常的状态下 Zookeeper Session 关闭 (比如前述的 Zookeeper 假死)，那么由于 /hadoop-ha/${dfs.nameservices}/ActiveBreadCrumb 是持久节点，会一直保留下来，后面当另一个 NameNode 选主成功之后，会注意到上一个 Active NameNode 遗留下来的这个节点，从而会回调 ZKFailoverController 的方法对旧的 Active NameNode 进行 fencing。</li>
</ol>
<p>在进行 fencing 的时候，会执行以下的操作：</p>
<ol>
<li>首先尝试调用这个旧 Active NameNode 的 HAServiceProtocol RPC 接口的 <code>transitionToStandby</code> 方法，看能不能把它转换为 Standby 状态；</li>
<li>如果 <code>transitionToStandby</code> 方法调用失败，那么就执行 Hadoop 配置文件之中预定义的隔离措施。</li>
</ol>
<p>Hadoop 目前主要提供两种隔离措施，通常会选择第一种：</p>
<ol>
<li>sshfence：通过 SSH 登录到目标机器上，执行命令 fuser 将对应的进程杀死；</li>
<li>shellfence：执行一个用户自定义的 shell 脚本来将对应的进程隔离。</li>
</ol>
<p>只有在成功地执行完成 fencing 之后，选主成功的 ActiveStandbyElector 才会回调 ZKFailoverController 的 <code>becomeActive</code> 方法将对应的 NameNode 转换为 Active 状态，开始对外提供服务。</p>
<p>NameNode 选举的实现机制与 Kafka 的 Controller 类似，那么 Kafka 是如何避免脑裂问题的呢？</p>
<ol>
<li>Controller 给 Broker 发送的请求中，都会携带 controller epoch 信息，如果 broker 发现当前请求的 epoch 小于缓存中的值，那么就证明这是来自旧 Controller 的请求，就会决绝这个请求，正常情况下是没什么问题的；</li>
<li>但是异常情况下呢？如果 Broker 先收到异常 Controller 的请求进行处理呢？现在看 Kafka 在这一部分并没有适合的方案；</li>
<li>正常情况下，Kafka 新的 Controller 选举出来之后，Controller 会向全局所有 broker 发送一个 metadata 请求，这样全局所有 Broker 都可以知道当前最新的 controller epoch，但是并不能保证可以完全避免上面这个问题，还是有出现这个问题的几率的，只不过非常小，而且即使出现了由于 Kafka 的高可靠架构，影响也非常有限，至少从目前看，这个问题并不是严重的问题。</li>
</ol>
<h3 id="第三方存储（共享存储）"><a href="#第三方存储（共享存储）" class="headerlink" title="第三方存储（共享存储）"></a>第三方存储（共享存储）</h3><p>上述 HA 方案还有一个明显缺点，那就是第三方存储节点有可能失效，之前有很多共享存储的实现方案，目前社区已经把由 Clouderea 公司实现的基于 QJM 的方案合并到 HDFS 的 trunk 之中并且作为默认的共享存储实现，本部分只针对基于 QJM 的共享存储方案的内部实现原理进行分析。</p>
<p>QJM（Quorum Journal Manager）本质上是利用 Paxos 协议来实现的，QJM 在 <code>2F+1</code>  个 JournalNode 上存储 NN 的 editlog，每次写入操作都通过 Paxos 保证写入的一致性，它最多可以允许有 F 个 JournalNode 节点同时故障，其实现如下（图片来自：<a href="https://www.ibm.com/developerworks/cn/opensource/os-cn-hadoop-name-node/" target="_blank" rel="external">Hadoop NameNode 高可用 (High Availability) 实现解析</a> ）：</p>
<p><img src="/images/hadoop/hdfs-ha-qjm.png" alt="基于 QJM 的共享存储的数据同步机制"></p>
<p>Active NameNode 首先把 EditLog 提交到 JournalNode 集群，然后 Standby NameNode 再从 JournalNode 集群定时同步 EditLog。</p>
<p>还有一点需要注意的是，在 2.0 中不再有 SNN 这个角色了，NameNode 在启动后，会先加载 FSImage 文件和共享目录上的 EditLog Segment 文件，之后 NameNode 会启动 EditLogTailer 线程和 StandbyCheckpointer 线程，正式进入 Standby 模式，其中：</p>
<ol>
<li>EditLogTailer 线程的作用是定时从 JournalNode 集群上同步 EditLog；</li>
<li>StandbyCheckpointer 线程的作用其实是为了替代 Hadoop 1.x 版本之中的 Secondary NameNode 的功能，StandbyCheckpointer 线程会在 Standby NameNode 节点上定期进行 Checkpoint，将 Checkpoint 之后的 FSImage 文件上传到 Active NameNode 节点。</li>
</ol>
<h2 id="HDFS-2-0-Federation-实现"><a href="#HDFS-2-0-Federation-实现" class="headerlink" title="HDFS 2.0 Federation 实现"></a>HDFS 2.0 Federation 实现</h2><p>在 1.0 中，HDFS 的架构设计有以下缺点：</p>
<ol>
<li>namespace 扩展性差：在单一的 NN 情况下，因为所有 namespace 数据都需要加载到内存，所以物理机内存的大小限制了整个 HDFS 能够容纳文件的最大个数（namespace 指的是 HDFS 中树形目录和文件结构以及文件对应的 block 信息）；</li>
<li>性能可扩展性差：由于所有请求都需要经过 NN，单一 NN 导致所有请求都由一台机器进行处理，很容易达到单台机器的吞吐；</li>
<li>隔离性差：多租户的情况下，单一 NN 的架构无法在租户间进行隔离，会造成不可避免的相互影响。</li>
</ol>
<p>而 Federation 的设计就是为了解决这些问题，采用 Federation 的最主要原因是设计实现简单，而且还能解决问题。</p>
<h3 id="Federation-架构"><a href="#Federation-架构" class="headerlink" title="Federation 架构"></a>Federation 架构</h3><p>Federation 的架构设计如下图所示（图片来自 <a href="http://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-hdfs/Federation.html" target="_blank" rel="external">HDFS Federation</a>）：</p>
<p><img src="/images/hadoop/hdfs-federation.gif" alt="HDFS Federation 架构实现"></p>
<h3 id="Federation-的核心设计思想"><a href="#Federation-的核心设计思想" class="headerlink" title="Federation 的核心设计思想"></a>Federation 的核心设计思想</h3><p>Federation 的核心思想是将一个大的 namespace 划分多个子 namespace，并且每个 namespace 分别由单独的 NameNode 负责，这些 NameNode 之间互相独立，不会影响，不需要做任何协调工作（其实跟拆集群有一些相似），集群的所有 DataNode 会被多个 NameNode 共享。</p>
<p>其中，每个子 namespace 和 DataNode 之间会由数据块管理层作为中介建立映射关系，数据块管理层由若干数据块池（Pool）构成，每个数据块只会唯一属于某个固定的数据块池，而一个子 namespace 可以对应多个数据块池。每个 DataNode 需要向集群中所有的 NameNode 注册，且周期性地向所有 NameNode 发送心跳和块报告，并执行来自所有 NameNode 的命令。</p>
<ul>
<li>一个 block pool 由属于同一个 namespace 的数据块组成，每个 DataNode 可能会存储集群中所有 block pool 的数据块；</li>
<li>每个 block pool 内部自治，也就是说各自管理各自的 block，不会与其他 block pool 交流，如果一个 NameNode 挂掉了，不会影响其他 NameNode;</li>
<li>某个 NameNode 上的 namespace 和它对应的 block pool 一起被称为 namespace volume，它是管理的基本单位。当一个 NameNode/namespace 被删除后，其所有 DataNode 上对应的 block pool 也会被删除，当集群升级时，每个 namespace volume 可以作为一个基本单元进行升级。</li>
</ul>
<p>到这里，基本对 HDFS 这部分总结完了，虽然文章的内容基本都来自下面的参考资料，但是自己在总结的过程中，也对 HDFS 的基本架构有一定的了解，后续结合公司 HDFS 团队的 CaseStudy 深入学习这部分的内容，工作中，也慢慢感觉到分布式系统，很多的设计实现与问题解决方案都很类似，只不过因为面对业务场景的不同而采用了不同的实现。</p>
<hr>
<p>参考：</p>
<ul>
<li><a href="https://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-hdfs/HdfsDesign.html" target="_blank" rel="external">HDFS Architecture</a>;</li>
<li><a href="http://shiyanjun.cn/archives/942.html" target="_blank" rel="external">HDFS 写文件过程分析</a>;</li>
<li><a href="https://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-hdfs/HDFSRouterFederation.html" target="_blank" rel="external">HDFS Router-based Federation</a>；</li>
<li><a href="https://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-hdfs/HDFSHighAvailabilityWithQJM.html" target="_blank" rel="external">HDFS High Availability Using the Quorum Journal Manager</a>；</li>
<li><a href="https://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-hdfs/HDFSCommands.html" target="_blank" rel="external">HDFS Commands Guide</a>；</li>
<li><a href="https://www.ibm.com/developerworks/cn/opensource/os-cn-hadoop-name-node/" target="_blank" rel="external">Hadoop NameNode 高可用 (High Availability) 实现解析</a></li>
<li><a href="http://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-hdfs/Federation.html" target="_blank" rel="external">HDFS Federation</a>；</li>
<li><a href="http://dongxicheng.org/mapreduce/hdfs-federation-introduction/" target="_blank" rel="external">HDFS Federation设计动机与基本原理</a>；</li>
<li><a href="https://item.jd.com/11540991.html" target="_blank" rel="external">《大数据日知录：架构与算法》</a>；</li>
<li><a href="https://tech.meituan.com/namenode-restart-optimization.html" target="_blank" rel="external">HDFS NameNode重启优化</a>；</li>
<li><a href="https://tech.meituan.com/hdfs-federation.html" target="_blank" rel="external">HDFS Federation在美团点评的应用与改进</a>。</li>
</ul>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[Kafka Controller Redesign 方案]]></title>
      <url>http://matt33.com/2018/07/14/kafka-controller-redesign/</url>
      <content type="html"><![CDATA[<p>Kafka Controller 是 Kafka 的核心组件，在前面的文章中，已经详细讲述过 Controller 部分的内容。在过去的几年根据大家在生产环境中应用的反馈，Controller 也积累了一些比较大的问题，而针对这些问题的修复，代码的改动量都是非常大的，无疑是一次重构，因此，社区准备在新版的系统里对 Controller 做一些相应的优化（0.11.0及以后的版本），相应的设计方案见：<a href="https://docs.google.com/document/d/1rLDmzDOGQQeSiMANP0rC2RYp_L7nUGHzFD9MQISgXYM/edit#heading=h.pxfjarumuhko" target="_blank" rel="external">Kafka Controller Redesign</a>，本文的内容就是结合这篇文章做一个简单的总结。</p>
<h2 id="Controller-功能"><a href="#Controller-功能" class="headerlink" title="Controller 功能"></a>Controller 功能</h2><p>在一个 Kafka 中，Controller 要处理的事情总结如下表所示：</p>
<table>
<thead>
<tr>
<th>功能</th>
<th>详情</th>
</tr>
</thead>
<tbody>
<tr>
<td>cluster metadata updates</td>
<td>producer 或 consumer 可以通过 MetadataRequest 请求从集群任何一台 broker 上查询到某个 Partition 的 metadata 信息，如果一个 Partition 的 leader 或 isr 等信息变化，Controller 会广播到集群的所有 broker 上，这样每台 Broker 都会有该 Partition 的最新 Metadata 信息</td>
</tr>
<tr>
<td>topic creation</td>
<td>用户可以通过多种方式创建一个 topic，最终的结果都是在 zk 的 <code>/brokers/topics</code> 目录下新建一个 topic 节点信息，controller 通过监控这个目录来判断是否有新的 topic 需要创建</td>
</tr>
<tr>
<td>topic deletion</td>
<td>Controller 通过监控 zk 的 <code>/admin/delete_topics</code> 节点来触发 topic 删除操作</td>
</tr>
<tr>
<td>partition reassignment</td>
<td>Controller 通过监控 zk 的 <code>/admin/reassign_partitions</code> 节点来触发 Partition 的副本迁移操作</td>
</tr>
<tr>
<td>preferred replica leader election</td>
<td>Controller 通过监控 zk 的 <code>/admin/preferred_replica_election</code> 节点来触发最优 leader 选举操作，该操作的目的选举 Partition 的第一个 replica 作为 leader</td>
</tr>
<tr>
<td>topic partition expansion</td>
<td>Controller 通过监控 zk 的 <code>/brokers/topics/&lt;topic&gt;</code> 数据内容的变化，来触发 Topic 的 Partition 扩容操作</td>
</tr>
<tr>
<td>broker join</td>
<td>Controller 通过监控 zk 的 <code>/brokers/ids</code> 目录变化，就会知道哪些 broker 是最新加入的，进而触发 broker 的上线操作</td>
</tr>
<tr>
<td>broker failure</td>
<td>同样，Controller 通过监控 zk 的 <code>/brokers/ids</code> 目录变化，就会知道哪些 broker 掉线了，进而触发 broker 的下线操作</td>
<td></td>
</tr>
<tr>
<td>controlled shutdown</td>
<td>Controller 通过处理 ControlledShudownRequest 请求来优雅地关闭一个 broker 节点，主动关闭与直接 kill 的区别，它可以减少 Partition 的不可用时间，因为一个 broker 的 zk 临时节点消失是需要一定时间的</td>
</tr>
<tr>
<td>controller leader election</td>
<td>集群中所有 broker 会监听 zk 的 <code>/controller</code> 节点，如果该节点消失，所有的 broker 都回去抢占 controller 节点，抢占成功的，就成了最新的 controller</td>
</tr>
</tbody>
</table>
<h2 id="Controller-目前存在的问题"><a href="#Controller-目前存在的问题" class="headerlink" title="Controller 目前存在的问题"></a>Controller 目前存在的问题</h2><p>之所以要重新设计 Controller，是因为现在的 Controller 积累了一些比较难解决的问题，这些问题解决起来，代码改动量都是巨大的，甚至需要改变 controller 部门的设计，基本就跟重构差不多了，下面我们先来了看一下 controller 之前（主要是 0.11.0 之前的版本）存在的一些问题。</p>
<p>目前遇到的比较大的问题有以下几个：</p>
<ol>
<li>Partition 级别同步 zk 写；</li>
<li>sequential per-partition controller-to-broker requests；</li>
<li>Controller 复杂的并发语义；</li>
<li>代码组织混乱；</li>
<li>控制类请求与数据类请求未分离；</li>
<li>Controller 给 broker 的请求中没有 broker 的 generation信息；</li>
<li>ZkClient 阻碍 Client 的状态管理。</li>
</ol>
<h3 id="Partition-级别同步-zk-写"><a href="#Partition-级别同步-zk-写" class="headerlink" title="Partition 级别同步 zk 写"></a>Partition 级别同步 zk 写</h3><p>zookeeper 的同步写意味着在下次写之前需要等待前面整个过程的结束，而且由于它们都是 partition 粒度的（一个 Partition 一个 Partition 的去执行写操作），对于 Partition 非常多的集群来说，需要等待的时间会更长，Controller 通常会在下面这两个地方做 Partition 级别 zookeeper 同步写操作：</p>
<ol>
<li>PartitionStateMachine 在进行触发 leader 选举（partition 目的状态是 OnlinePartition），将会触发上面的操作；</li>
<li>ReplicaStateMachine 更新 LeaderAndIsr 信息到 zk（replica 状态转变为 OfflineReplica），这种情况也触发这种情况，它既阻碍了 Controller 进程，也有可能会 zk 造成压力。</li>
</ol>
<h3 id="sequential-per-partition-controller-to-broker-requests"><a href="#sequential-per-partition-controller-to-broker-requests" class="headerlink" title="sequential per-partition controller-to-broker requests"></a>sequential per-partition controller-to-broker requests</h3><p>Controller 在向 Broker 发送请求，有些情况下也是 Partition 粒度去发送的，效率非常低，比如在 Controller 处理 broker shutdown 请求时，这里是按 Partition 级别处理，每处理一个 Partition 都会执行 Partition、Replica 状态变化以及 Metadata 更新，并且调用 <code>sendRequestsToBrokers()</code> 向 broker 发送请求，这样的话，效率将变得非常低。</p>
<h3 id="Controller-复杂的并发语义"><a href="#Controller-复杂的并发语义" class="headerlink" title="Controller 复杂的并发语义"></a>Controller 复杂的并发语义</h3><p>Controller 需要在多个线程之间共享状态信息，这些线程有：</p>
<ol>
<li>IO threads handling controlled shutdown requests</li>
<li>The ZkClient org.I0Itec.zkclient.ZkEventThread processing zookeeper callbacks sequentially；</li>
<li>The TopicDeletionManager kafka.controller.DeleteTopicsThread；</li>
<li>Per-broker RequestSendThread within ControllerChannelManager.</li>
</ol>
<p>所有这些线程都需要访问或修改状态信息（ControllerContext），现在它们是通过 ControllerContext 的 controllerLock（排它锁）实现的，Controller 的并发变得虚弱无力。</p>
<h3 id="代码组织混乱"><a href="#代码组织混乱" class="headerlink" title="代码组织混乱"></a>代码组织混乱</h3><p>KafkaController 部分的代码组织（KafkaController、PartitionStateMachine 和 ReplicaStateMachine）不是很清晰，比如，下面的问题就很难回答：</p>
<ol>
<li>where and when does zookeeper get updated?</li>
<li>where and when does a controller-to-broker request get formed?</li>
<li>what impact does a failing zookeeper update or controller-to-broker request have on the cluster state?</li>
</ol>
<p>这也导致了这部分很多开发者不敢轻易去改动。</p>
<h3 id="控制类请求与数据类请求未分离"><a href="#控制类请求与数据类请求未分离" class="headerlink" title="控制类请求与数据类请求未分离"></a>控制类请求与数据类请求未分离</h3><p>现在 broker 收到的请求，有来自 client、broker 和 controller 的请求，这些请求都会被放到同一个 requestQueue 中，它们有着同样的优先级，所以来自 client 的请求很可能会影响来自 controller 请求的处理（如果是 leader 变动的请求，ack 设置的不是 all，这种情况有可能会导致数据丢失）。</p>
<h3 id="Controller-给-broker-的请求中没有-broker-的-generation信息"><a href="#Controller-给-broker-的请求中没有-broker-的-generation信息" class="headerlink" title="Controller 给 broker 的请求中没有 broker 的 generation信息"></a>Controller 给 broker 的请求中没有 broker 的 generation信息</h3><p>这里的 Broker generation 代表着一个标识，每当它重新加入集群时，这个标识都会变化。如果 Controller 的请求没有这个信息的话，可能会导致一个重启的 Broker 收到之前的请求，让 Broker 进入到一个错误的状态。</p>
<p>比如，Broker 收到之前的 StopReplica 请求，可能会导致副本同步线程退出。</p>
<h3 id="ZkClient-阻碍-Client-的状态管理"><a href="#ZkClient-阻碍-Client-的状态管理" class="headerlink" title="ZkClient 阻碍 Client 的状态管理"></a>ZkClient 阻碍 Client 的状态管理</h3><p>这里的状态管理指的是当 Client 发生重连或会话过期时，Client 可以监控这种状态变化，并做出一些处理，因为开源版的 ZKClient 在处理 notification 时，是线性处理的，一些 notification 会被先放到 ZkEventThread’s queue 中，这样会导致一些最新的 notification 不能及时被处理，特别是与 zk 连接断开重连的情况。</p>
<h2 id="Controller-改进方案"><a href="#Controller-改进方案" class="headerlink" title="Controller 改进方案"></a>Controller 改进方案</h2><p>关于上述问题，Kafka 提出了一些改进方案，有些已经在最新版的系统中实现，有的还在规划中。</p>
<h3 id="使用异步的-zk-api"><a href="#使用异步的-zk-api" class="headerlink" title="使用异步的 zk api"></a>使用异步的 zk api</h3><p>Zookeeper 的 client 提供三种执行请求的方式：</p>
<ol>
<li>同步调用，意味着下次请求需要等待当前当前请求的完成；</li>
<li>异步调用，意味着不需要等待当前请求的完成就可以开始下次请求的执行，并且我们可以通过回调机制去处理请求返回的结果；</li>
<li>单请求的 batch 调用，意味着 batch 内的所有请求都会在一次事务处理中完成，这里需要关注的是 zookeeper 的 server 对单请求的大小是有限制的（jute.maxbuffer）。</li>
</ol>
<p>文章中给出了三种请求的测试结果，Kafka 最后选取的是异步处理机制，因为对于单请求处理，异步处理更加简洁，并且相比于同步处理还可以保持一个更好的写性能。</p>
<h3 id="improve-controller-to-broker-request-batching"><a href="#improve-controller-to-broker-request-batching" class="headerlink" title="improve controller-to-broker request batching"></a>improve controller-to-broker request batching</h3><p>这个在设计文档还是 TODO 状态，具体的方案还没确定，不过基本可以猜测一下，因为目的是提高 batch 发送能力，那么只能是在调用对每个 broker 的 RequestSenderThread 线程发送请求之前，做一下检测，而不是来一个请求立马就发送，这是一个性能与时间的权衡，如果不是立马发送请求，那么可能会带来 broker 短时 metadata 信息的不一致，这个不一致时间不同的应用场景要求是不一样的。</p>
<h3 id="单线程的事件处理模型"><a href="#单线程的事件处理模型" class="headerlink" title="单线程的事件处理模型"></a>单线程的事件处理模型</h3><p>采用单线程的时间处理模型将极大简化 Controller 的并发实现，只允许这个线程访问和修改 Controller 的本地状态信息，因此在 Controller 部分也就不需要到处加锁来保证线程安全了。</p>
<p>目前 1.1.0 的实现中，Controller 使用了一个 ControllerEventThread 线程来处理所有的 event，目前可以支持13种不同类型事件：</p>
<ol>
<li>Idle：代表当前 ControllerEventThread 处理空闲状态；</li>
<li>ControllerChange：Controller 切换处理；</li>
<li>BrokerChange：Broker 变动处理，broker 可能有上线或掉线；</li>
<li>TopicChange：Topic 新增处理；</li>
<li>TopicDeletion：Topic 删除处理；</li>
<li>PartitionReassignment：Partition 副本迁移处理；</li>
<li>AutoLeaderBalance：自动 rebalance 处理；</li>
<li>ManualLeaderBalance：最优 leader 选举处理，这里叫做手动 rebalance，手动去切流量；</li>
<li>ControlledShutdown：优雅关闭 broker；</li>
<li>IsrChange：Isr 变动处理；</li>
<li>LeaderAndIsrResponseReceived；</li>
<li>LogDirChange：Broker 某个目录失败后的处理（比如磁盘坏掉等）；</li>
<li>ControllerShutdown：ControllerEventThread 处理这个事件时，会关闭当前线程。</li>
</ol>
<h3 id="重构集群状态管理"><a href="#重构集群状态管理" class="headerlink" title="重构集群状态管理"></a>重构集群状态管理</h3><p>这部分的改动，目前社区也没有一个很好的解决思路，重构这部分的目的是希望 Partition、Replica 的状态管理变得更清晰一些，让我们从代码中可以清楚地明白状态是在什么时间、什么地方、什么条件下被触发的。这个优化其实是跟上面那个有很大关联，采用单线程的事件处理模型，可以让状态管理也变得更清晰。</p>
<h4 id="prioritize-controller-requests"><a href="#prioritize-controller-requests" class="headerlink" title="prioritize controller requests"></a>prioritize controller requests</h4><p>我们想要把控制类请求与数据类请求分开，提高 controller 请求的优先级，这样的话即使 Broker 中请求有堆积，Broker 也会优先处理控制类的请求。</p>
<p>这部分的优化可以在网络层的 RequestChannel 中做，RequestChannel 可以根据请求的 id 信息把请求分为正常的和优先的，如果请求是 UpdateMetadataRequest、LeaderAndIsrRequest 或者 StopReplicaRequest，那么这个请求的优先级应该提高。实现方案有以下两种：</p>
<ol>
<li>在请求队列中增加一个优先级队列，优先级高的请求放到 the prioritized request queue 中，优先级低的放到普通请求队列中，但是无论使用一个定时拉取（poll）还是2个定时拉取，都会带来其他的问题，要么是增大普通请求的处理延迟，要么是增大了优先级高请求的延迟；</li>
<li>直接使用优先级队列代替现在的普通队列，设计上更倾向与这一种。</li>
</ol>
<p>目前这部分在1.1.0中还未实现。</p>
<h3 id="Controller-发送请求中添加-broker-的-generation-信息"><a href="#Controller-发送请求中添加-broker-的-generation-信息" class="headerlink" title="Controller 发送请求中添加 broker 的 generation 信息"></a>Controller 发送请求中添加 broker 的 generation 信息</h3><p>generation 信息是用来标识当前 broker 加入集群 epoch 信息，每当 broker 重新加入集群中，该 broker.id 对应的 generation 都应该变化（要求递增），目前有两种实现方案：</p>
<ol>
<li>为 broker 分配的一个全局唯一的 id，由 controller 广播给其他 broker；</li>
<li>直接使用 zookeeper 的 zxid 信息（broker.id 注册时的 zxid）。</li>
</ol>
<h3 id="直接使用原生的-Zookeeper-client"><a href="#直接使用原生的-Zookeeper-client" class="headerlink" title="直接使用原生的 Zookeeper client"></a>直接使用原生的 Zookeeper client</h3><p>Client 端的状态管理意味着当 Client 端发生状态变化（像连接中断或回话超时）时，我们有能力做一些操作。其中，zookeeper client 有效的状态（目前的 client 比下面又多了几种状态，这里先不深入）是:</p>
<ul>
<li>NOT_CONNECTED： the initial state of the client；</li>
<li>CONNECTING： the client is establishing a connection to zookeeper；</li>
<li>CONNECTED： the client has established a connection and session to zookeeper；</li>
<li>CLOSED： the session has closed or expired。</li>
</ul>
<p>有效的状态转移是：</p>
<ul>
<li>NOT_CONNECTED &gt; CONNECTING</li>
<li>CONNECTING &gt; CONNECTED</li>
<li>CONNECTING &gt; CLOSED</li>
<li>CONNECTED &gt; CONNECTING</li>
<li>CONNECTED &gt; CLOSED</li>
</ul>
<p>最开始的设想是直接使用原生 Client 的异步调用方式，这样的话依然可以通过回调方法监控到状态的变化（像连接中断或回话超时），同样，在每次事件处理时，可以通过检查状态信息来监控到 Client 状态的变化，及时做一些处理。</p>
<p>当一个 Client 接收到连接中断的 notification（Client 状态变成了 CONNECTING 状态），它意味着 Client 不能再从 zookeeper 接收到任何 notification 了。如果断开连接，对于 Controller 而言，无论它现在正在做什么它都应该先暂停，因为可能集群的 Controller 已经切换到其他机器上了，只是它还没接收到通知，它如果还在工作，可能会导致集群状态不一致。当连接断开后，Client 可以重新建立连接（re-establish，状态变为 CONNECTED）或者会话过期（状态变为 CLOSED，会话过期是由 zookeeper Server 来决定的）。如果变成了 CONNECTED 状态，Controller 应该重新开始这些暂停的操作，而如果状态变成了 CLOSED 状态，旧的 Controller 就会知道它不再是 controller，应该丢弃掉这些任务。</p>
<p>参考：</p>
<ul>
<li><a href="https://docs.google.com/document/d/1rLDmzDOGQQeSiMANP0rC2RYp_L7nUGHzFD9MQISgXYM/edit#heading=h.pxfjarumuhko" target="_blank" rel="external">Kafka Controller Redesign</a>；</li>
<li><a href="https://www.cnblogs.com/huxi2b/p/6980045.html" target="_blank" rel="external">Kafka controller重设计</a>。</li>
</ul>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[分布式系统的一致性协议之 2PC 和 3PC]]></title>
      <url>http://matt33.com/2018/07/08/distribute-system-consistency-protocol/</url>
      <content type="html"><![CDATA[<p>在分布式系统领域，有一个理论，对于分布式系统的设计影响非常大，那就是 CAP 理论，即对于一个分布式系统而言，它是无法同时满足 Consistency(强一致性)、Availability(可用性) 和  Partition tolerance(分区容忍性) 这三个条件的，最多只能满足其中两个。但在实际中，由于网络环境是不可信的，所以分区容忍性几乎是必不可选的，设计者基本就是在一致性和可用性之间做选择，当然大部分情况下，大家都会选择牺牲一部分的一致性来保证可用性（可用性较差的系统非常影响用户体验的，但是对另一些场景，比如支付场景，强一致性是必须要满足）。但是分布式系统又无法彻底放弃一致性（Consistency），如果真的放弃一致性，那么就说明这个系统中的数据根本不可信，数据也就没有意义，那么这个系统也就没有任何价值可言。</p>
<h2 id="CAP-理论"><a href="#CAP-理论" class="headerlink" title="CAP 理论"></a>CAP 理论</h2><p>CAP 理论三个特性的详细含义如下：</p>
<ol>
<li>一致性（Consistency）：每次读取要么是最新的数据，要么是一个错误；</li>
<li>可用性（Availability）：client 在任何时刻的读写操作都能在限定的延迟内完成的，即每次请求都能获得一个响应（非错误），但不保证是最新的数据；</li>
<li>分区容忍性（Partition tolerance）：在大规模分布式系统中，网络分区现象，即分区间的机器无法进行网络通信的情况是必然会发生的，系统应该能保证在这种情况下可以正常工作。</li>
</ol>
<h3 id="分区容忍性"><a href="#分区容忍性" class="headerlink" title="分区容忍性"></a>分区容忍性</h3><p>很多人可能对分区容忍性不太理解，知乎有一个回答对这个解释的比较清楚（<a href="https://www.zhihu.com/question/54105974" target="_blank" rel="external">CAP理论中的P到底是个什么意思？</a>），这里引用一下：</p>
<ul>
<li>一个分布式系统里面，节点组成的网络本来应该是连通的。然而可能因为一些故障，使得有些节点之间不连通了，整个网络就分成了几块区域。数据就散布在了这些不连通的区域中。这就叫分区。</li>
<li>当你一个数据项只在一个节点中保存，那么分区出现后，和这个节点不连通的部分就访问不到这个数据了。这时分区就是无法容忍的。</li>
<li>提高分区容忍性的办法就是一个数据项复制到多个节点上，那么出现分区之后，这一数据项就可能分布到各个区里，容忍性就提高了。</li>
<li>然而，要把数据复制到多个节点，就会带来一致性的问题，就是多个节点上面的数据可能是不一致的。</li>
<li>要保证一致，每次写操作就都要等待全部节点写成功，而这等待又会带来可用性的问题。</li>
<li>总的来说就是，数据存在的节点越多，分区容忍性越高，但要复制更新的数据就越多，一致性就越难保证。为了保证一致性，更新所有节点数据所需要的时间就越长，可用性就会降低。</li>
</ul>
<h3 id="CAP-如何选择"><a href="#CAP-如何选择" class="headerlink" title="CAP 如何选择"></a>CAP 如何选择</h3><p>CAP 理论一个经典原理如下所示：</p>
<p><img src="/images/distribute/CAP.png" alt="CAP 理论原理"></p>
<p>CAP 定理表明，在存在网络分区的情况下，一致性和可用性必须二选一。而在没有发生网络故障时，即分布式系统正常运行时，一致性和可用性是可以同时被满足的。但是，对于大多数互联网应用来说，因为规模比较大，部署节点分散，网络故障是常态，可用性是必须要保证的，所以只有舍弃一致性来保证服务的 AP。但是对于一些金融相关行业，它有很多场景需要确保一致性，这种情况通常会权衡 CA 和 CP 模型，CA 模型网络故障时完全不可用，CP 模型具备部分可用性。</p>
<p>在一个分布式系统中，对于这三个特性，我们只能三选二，无法同时满足这三个特性，三选二的组合以及这样系统的特点总结如下（来自<a href="http://www.infoq.com/cn/news/2018/05/distributed-system-architecture" target="_blank" rel="external">左耳朵耗子推荐：分布式系统架构经典资料</a>）：</p>
<ul>
<li>CA (Consistency + Availability)：关注一致性和可用性，它需要非常严格的全体一致的协议，比如“两阶段提交”（2PC）。CA 系统不能容忍网络错误或节点错误，一旦出现这样的问题，整个系统就会拒绝写请求，因为它并不知道对面的那个结点是否挂掉了，还是只是网络问题。唯一安全的做法就是把自己变成只读的。</li>
<li>CP (consistency + partition tolerance)：关注一致性和分区容忍性。它关注的是系统里大多数人的一致性协议，比如：Paxos 算法 (Quorum 类的算法)。这样的系统只需要保证大多数结点数据一致，而少数的结点会在没有同步到最新版本的数据时变成不可用的状态。这样能够提供一部分的可用性。</li>
<li>AP (availability + partition tolerance)：这样的系统关心可用性和分区容忍性。因此，这样的系统不能达成一致性，需要给出数据冲突，给出数据冲突就需要维护数据版本。Dynamo 就是这样的系统。</li>
</ul>
<p>对于分布式系统分区容忍性是天然具备的要求，否则一旦出现网络分区，系统就拒绝所有写入只允许可读，这对大部分的场景是不可接收的，因此，在设计分布式系统时，更多的情况下是选举 CP 还是 AP，要么选择强一致性弱可用性，要么选择高可用性容忍弱一致性。</p>
<h3 id="一致性模型"><a href="#一致性模型" class="headerlink" title="一致性模型"></a>一致性模型</h3><p>关于分布式系统的一致性模型有以下几种：</p>
<h4 id="强一致性"><a href="#强一致性" class="headerlink" title="强一致性"></a>强一致性</h4><p>当更新操作完成之后，任何多个后续进程或者线程的访问都会返回最新的更新过的值，直到这个数据被其他数据更新为止。</p>
<p>但是这种实现对性能影响较大，因为这意味着，只要上次的操作没有处理完，就不能让用户读取数据。</p>
<h4 id="弱一致性"><a href="#弱一致性" class="headerlink" title="弱一致性"></a>弱一致性</h4><p>系统并不保证进程或者线程的访问都会返回最新更新过的值。系统在数据写入成功之后，不承诺立即可以读到最新写入的值，也不会具体的承诺多久之后可以读到。但会尽可能保证在某个时间级别（比如秒级别）之后，可以让数据达到一致性状态。</p>
<h4 id="最终一致性"><a href="#最终一致性" class="headerlink" title="最终一致性"></a>最终一致性</h4><p>最终一致性也是弱一致性的一种，它无法保证数据更新后，所有后续的访问都能看到最新数值，而是需要一个时间，在这个时间之后可以保证这一点，而在这个时间内，数据也许是不一致的，这个系统无法保证强一致性的时间片段被称为「不一致窗口」。不一致窗口的时间长短取决于很多因素，比如备份数据的个数、网络传输延迟速度、系统负载等。</p>
<p>最终一致性在实际应用中又有多种变种：</p>
<table>
<thead>
<tr>
<th>类型</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>因果一致性</td>
<td>如果 A 进程在更新之后向 B 进程通知更新的完成，那么 B 的访问操作将会返回更新的值。而没有因果关系的 C 进程将会遵循最终一致性的规则（C 在不一致窗口内还是看到是旧值）。</td>
</tr>
<tr>
<td>读你所写一致性</td>
<td>因果一致性的特定形式。一个进程进行数据更新后，会给自己发送一条通知，该进程后续的操作都会以最新值作为基础，而其他的进程还是只能在不一致窗口之后才能看到最新值。</td>
</tr>
<tr>
<td>会话一致性</td>
<td>读你所写一致性的特定形式。进程在访问存储系统同一个会话内，系统保证该进程可以读取到最新之，但如果会话终止，重新连接后，如果此时还在不一致窗口内，还是可嫩读取到旧值。</td>
</tr>
<tr>
<td>单调读一致性</td>
<td>如果一个进程已经读取到一个特定值，那么该进程不会读取到该值以前的任何值。</td>
</tr>
<tr>
<td>单调写一致性</td>
<td>系统保证对同一个进程的写操作串行化。</td>
</tr>
</tbody>
</table>
<p>它们的关系又如下图所示（图来自 <a href="https://item.jd.com/11540991.html" target="_blank" rel="external">《大数据日知录：架构与算法》</a>）：</p>
<p><img src="/images/distribute/consistency.png" alt="一致性模型之间关系"></p>
<h2 id="分布式一致性协议"><a href="#分布式一致性协议" class="headerlink" title="分布式一致性协议"></a>分布式一致性协议</h2><p>为了解决分布式系统的一致性问题，在长期的研究探索过程中，业内涌现出了一大批经典的一致性协议和算法，其中比较著名的有二阶段提交协议（2PC），三阶段提交协议（3PC）和 Paxos 算法（本文暂时先不介绍）。</p>
<p>Google 2009年 在<a href="https://snarfed.org/transactions_across_datacenters_io.html" target="_blank" rel="external">Transaction Across DataCenter</a> 的分享中，对一致性协议在业内的实践做了一简单的总结，如下图所示，这是 CAP 理论在工业界应用的实践经验。</p>
<p><img src="/images/distribute/cap-sumarry.png" alt="CAP 理论在工业界的实践"></p>
<p>其中，第一行表头代表了分布式系统中通用的一致性方案，包括冷备、Master/Slave、Master/Master、两阶段提交以及基于 Paxos 算法的解决方案，第一列表头代表了分布式系统大家所关心的各项指标，包括一致性、事务支持程度、数据延迟、系统吞吐量、数据丢失可能性、故障自动恢复方式。</p>
<h2 id="两阶段提交协议（2PC）"><a href="#两阶段提交协议（2PC）" class="headerlink" title="两阶段提交协议（2PC）"></a>两阶段提交协议（2PC）</h2><p>二阶段提交协议（Two-phase Commit，即2PC）是常用的分布式事务解决方案，它可以保证在分布式事务中，要么所有参与进程都提交事务，要么都取消事务，即实现 ACID 的原子性（A）。在数据一致性中，它的含义是：要么所有副本（备份数据）同时修改某个数值，要么都不更改，以此来保证数据的强一致性。</p>
<p>2PC 要解决的问题可以简单总结为：在分布式系统中，每个节点虽然可以知道自己的操作是成功还是失败，却是无法知道其他节点的操作状态。当一个事务需要跨越多个节点时，为了保持事务的 ACID 特性，需要引入一个作为<strong>协调者</strong>的组件来统一掌控所有节点（参与者）的操作结果并最终指示这些节点是否要把操作结果进行真正的提交（比如将更新后的数据写入磁盘等等）。因此，二阶段提交的算法思路可以概括为： 参与者将操作结果通知协调者，再由协调者根据所有参与者的反馈情报决定各参与者是否要提交操作还是中止操作。</p>
<h3 id="2PC-过程"><a href="#2PC-过程" class="headerlink" title="2PC 过程"></a>2PC 过程</h3><p>关于两阶段提交的过程如下图所示：</p>
<p><img src="/images/distribute/2pc_process.png" alt="两阶段提交过程"></p>
<p>顾名思义，2PC 分为两个过程：</p>
<ol>
<li>表决阶段：此时 Coordinator （协调者）向所有的参与者发送一个 vote request，参与者在收到这请求后，如果准备好了就会向 Coordinator 发送一个 <code>VOTE_COMMIT</code> 消息作为回应，告知 Coordinator 自己已经做好了准备，否则会返回一个 <code>VOTE_ABORT</code> 消息；</li>
<li>提交阶段：Coordinator 收到所有参与者的表决信息，如果所有参与者一致认为可以提交事务，那么 Coordinator 就会发送 <code>GLOBAL_COMMIT</code> 消息，否则发送 <code>GLOBAL_ABORT</code> 消息；对于参与者而言，如果收到 <code>GLOBAL_COMMIT</code> 消息，就会提交本地事务，否则就会取消本地事务。</li>
</ol>
<h3 id="2PC-一致性问题"><a href="#2PC-一致性问题" class="headerlink" title="2PC 一致性问题"></a>2PC 一致性问题</h3><p>这里先讨论一下，2PC 是否可以在任何情况下都可以解决一致性问题，在实际的网络生产中，各种情况都有可能发生，这里，我们先从理论上分析各种意外情况。</p>
<p>2PC 在执行过程中可能发生 Coordinator 或者参与者突然宕机的情况，在不同时期宕机可能有不同的现象。</p>
<table>
<thead>
<tr>
<th>情况</th>
<th>分析及解决方案</th>
</tr>
</thead>
<tbody>
<tr>
<td>Coordinator 挂了，参与者没挂</td>
<td>这种情况其实比较好解决，只要找一个 Coordinator 的替代者。当他成为新的 Coordinator 的时候，询问所有参与者的最后那条事务的执行情况，他就可以知道是应该做什么样的操作了。所以，这种情况不会导致数据不一致。</td>
</tr>
<tr>
<td>参与者挂了（无法恢复），Coordinator 没挂</td>
<td>如果挂了之后没有恢复，那么是不会导致数据一致性问题。</td>
</tr>
<tr>
<td>参与者挂了（后来恢复），Coordinator 没挂</td>
<td>恢复后参与者如果发现有未执行完的事务操作，直接取消，然后再询问 Coordinator 目前我应该怎么做，协调者就会比对自己的事务执行记录和该参与者的事务执行记录，告诉他应该怎么做来保持数据的一致性。</td>
</tr>
</tbody>
</table>
<p>还有一种情况是：参与者挂了，Coordinator 也挂了，需要再细分为几种类型来讨论：</p>
<table>
<thead>
<tr>
<th>情况</th>
<th>分析及解决方案</th>
</tr>
</thead>
<tbody>
<tr>
<td>Coordinator 和参与者在第一阶段挂了</td>
<td>由于这时还没有执行 commit 操作，新选出来的 Coordinator 可以询问各个参与者的情况，再决定是进行 commit 还是 roolback。因为还没有 commit，所以不会导致数据一致性问题。</td>
</tr>
<tr>
<td>Coordinator 和参与者在第二阶段挂了，但是挂的这个参与者在挂之前还没有做相关操作</td>
<td>这种情况下，当新的 Coordinator 被选出来之后，他同样是询问所有参与者的情况。只要有机器执行了 abort（roolback）操作或者第一阶段返回的信息是 No 的话，那就直接执行 roolback 操作。如果没有人执行 abort 操作，但是有机器执行了 commit 操作，那么就直接执行 commit 操作。这样，当挂掉的参与者恢复之后，只要按照 Coordinator 的指示进行事务的 commit 还是 roolback 操作就可以了。因为挂掉的机器并没有做 commit 或者 roolback 操作，而没有挂掉的机器们和新的 Coordinator 又执行了同样的操作，那么这种情况不会导致数据不一致现象。</td>
</tr>
<tr>
<td>Coordinator 和参与者在第二阶段挂了，挂的这个参与者在挂之前已经执行了操作。但是由于他挂了，没有人知道他执行了什么操作。</td>
<td>这种情况下，新的 Coordinator 被选出来之后，如果他想负起 Coordinator 的责任的话他就只能按照之前那种情况来执行 commit 或者 roolback 操作。这样新的 Coordinator 和所有没挂掉的参与者就保持了数据的一致性，我们假定他们执行了 commit。但是，这个时候，那个挂掉的参与者恢复了怎么办，因为他已经执行完了之前的事务，如果他执行的是 commit 那还好，和其他的机器保持一致了，万一他执行的是 roolback 操作呢？这不就导致数据的不一致性了么？虽然这个时候可以再通过手段让他和 Coordinator 通信，再想办法把数据搞成一致的，但是，这段时间内他的数据状态已经是不一致的了！</td>
</tr>
</tbody>
</table>
<p>所以，2PC协议中，如果出现协调者和参与者都挂了的情况，有可能导致数据不一致。为了解决这个问题，衍生除了3PC。</p>
<h3 id="2PC-优缺点"><a href="#2PC-优缺点" class="headerlink" title="2PC 优缺点"></a>2PC 优缺点</h3><p>简单总结一下 2PC 的优缺点：</p>
<ul>
<li>优点：原理简洁清晰、实现方便；</li>
<li>缺点：同步阻塞、单点问题、某些情况可能导致数据不一致。</li>
</ul>
<p>关于这几个缺点，在实际应用中，都是对2PC 做了相应的改造：</p>
<ol>
<li>同步阻塞：2PC 有几个过程（比如 Coordinator 等待所有参与者表决的过程中）都是同步阻塞的，在实际的应用中，这可能会导致长阻塞问题，这个问题是通过超时判断机制来解决的，但并不能完全解决同步阻塞问题；</li>
<li>Coordinator 单点问题：实际生产应用中，Coordinator 都会有相应的备选节点；</li>
<li>数据不一致：这个在前面已经讲述过了，如果在第二阶段，Coordinator 和参与者都出现挂掉的情况下，是有可能导致数据不一致的。</li>
</ol>
<h2 id="三阶段提交协议（3PC）"><a href="#三阶段提交协议（3PC）" class="headerlink" title="三阶段提交协议（3PC）"></a>三阶段提交协议（3PC）</h2><p>三阶段提交协议（Three-Phase Commit， 3PC）最关键要解决的就是 Coordinator 和参与者同时挂掉导致数据不一致的问题，所以 3PC 把在 2PC 中又添加一个阶段，这样三阶段提交就有：CanCommit、PreCommit 和 DoCommit 三个阶段。</p>
<h3 id="3PC-过程"><a href="#3PC-过程" class="headerlink" title="3PC 过程"></a>3PC 过程</h3><p>三阶段提交协议的过程如下图（图来自 <a href="https://en.wikipedia.org/wiki/Three-phase_commit_protocol" target="_blank" rel="external">维基百科：三阶段提交</a>）所示：</p>
<p><img src="/images/distribute/Three-phase_commit_diagram.png" alt="三节点提交过程"></p>
<p>3PC 的详细过程如下（这个过程步骤内容来自 <a href="https://segmentfault.com/a/1190000004474543" target="_blank" rel="external">2PC到3PC到Paxos到Raft到ISR</a>）：</p>
<h4 id="阶段一-CanCommit"><a href="#阶段一-CanCommit" class="headerlink" title="阶段一 CanCommit"></a>阶段一 CanCommit</h4><ol>
<li>事务询问：Coordinator 向各参与者发送 CanCommit 的请求，询问是否可以执行事务提交操作，并开始等待各参与者的响应；</li>
<li>参与者向 Coordinator 反馈询问的响应：参与者收到 CanCommit 请求后，正常情况下，如果自身认为可以顺利执行事务，那么会反馈 Yes 响应，并进入预备状态，否则反馈 No。</li>
</ol>
<h4 id="阶段二-PreCommit"><a href="#阶段二-PreCommit" class="headerlink" title="阶段二 PreCommit"></a>阶段二 PreCommit</h4><p><strong>执行事务预提交</strong>：如果 Coordinator 接收到各参与者反馈都是Yes，那么执行事务预提交：</p>
<ol>
<li>发送预提交请求：Coordinator 向各参与者发送 preCommit 请求，并进入 prepared 阶段；</li>
<li>事务预提交：参与者接收到 preCommit 请求后，会执行事务操作，并将 Undo 和 Redo 信息记录到事务日记中；</li>
<li>各参与者向 Coordinator 反馈事务执行的响应：如果各参与者都成功执行了事务操作，那么反馈给协调者 ACK 响应，同时等待最终指令，提交 commit 或者终止 abort，结束流程；</li>
</ol>
<p><strong>中断事务</strong>：如果任何一个参与者向 Coordinator 反馈了 No 响应，或者在等待超时后，Coordinator 无法接收到所有参与者的反馈，那么就会中断事务。</p>
<ol>
<li>发送中断请求：Coordinator 向所有参与者发送 abort 请求；</li>
<li>中断事务：无论是收到来自 Coordinator 的 abort 请求，还是等待超时，参与者都中断事务。</li>
</ol>
<h4 id="阶段三-doCommit"><a href="#阶段三-doCommit" class="headerlink" title="阶段三 doCommit"></a>阶段三 doCommit</h4><p><strong>执行提交</strong></p>
<ol>
<li>发送提交请求：假设 Coordinator 正常工作，接收到了所有参与者的 ack 响应，那么它将从预提交阶段进入提交状态，并向所有参与者发送 doCommit 请求；</li>
<li>事务提交：参与者收到 doCommit 请求后，正式提交事务，并在完成事务提交后释放占用的资源；</li>
<li>反馈事务提交结果：参与者完成事务提交后，向 Coordinator 发送 ACK 信息；</li>
<li>完成事务：Coordinator 接收到所有参与者 ack 信息，完成事务。</li>
</ol>
<p><strong>中断事务</strong>：假设 Coordinator 正常工作，并且有任一参与者反馈 No，或者在等待超时后无法接收所有参与者的反馈，都会中断事务</p>
<ol>
<li>发送中断请求：Coordinator 向所有参与者节点发送 abort 请求；</li>
<li>事务回滚：参与者接收到 abort 请求后，利用 undo 日志执行事务回滚，并在完成事务回滚后释放占用的资源；</li>
<li>反馈事务回滚结果：参与者在完成事务回滚之后，向 Coordinator 发送 ack 信息；</li>
<li>中断事务：Coordinator 接收到所有参与者反馈的 ack 信息后，中断事务。</li>
</ol>
<h3 id="3PC-分析"><a href="#3PC-分析" class="headerlink" title="3PC 分析"></a>3PC 分析</h3><p>3PC 虽然解决了 Coordinator 与参与者都异常情况下导致数据不一致的问题，3PC 依然带来其他问题：比如，网络分区问题，在 preCommit 消息发送后突然两个机房断开，这时候 Coordinator 所在机房会 abort, 另外剩余参与者的机房则会 commit。</p>
<p>而且由于3PC 的设计过于复杂，在解决2PC 问题的同时也引入了新的问题，所以在实际上应用不是很广泛。</p>
<p>参考：</p>
<ul>
<li><a href="https://en.wikipedia.org/wiki/Two-phase_commit_protocol" target="_blank" rel="external">维基百科：二阶段提交</a>；</li>
<li><a href="https://en.wikipedia.org/wiki/Three-phase_commit_protocol" target="_blank" rel="external">维基百科：三阶段提交</a>；</li>
<li><a href="http://www.infoq.com/cn/news/2018/05/distributed-system-architecture" target="_blank" rel="external">左耳朵耗子推荐：分布式系统架构经典资料</a>；</li>
<li><a href="http://www.hollischuang.com/archives/663" target="_blank" rel="external">关于分布式一致性的探究</a>；</li>
<li><a href="http://www.hollischuang.com/archives/681" target="_blank" rel="external">关于分布式事务、两阶段提交协议、三阶提交协议</a>；</li>
<li><a href="http://www.hollischuang.com/archives/1580" target="_blank" rel="external">深入理解分布式系统的2PC和3PC</a>；</li>
<li><a href="https://segmentfault.com/a/1190000004474543" target="_blank" rel="external">2PC到3PC到Paxos到Raft到ISR</a>；</li>
<li><a href="https://item.jd.com/11540991.html" target="_blank" rel="external">《大数据日知录：架构与算法》</a>；</li>
<li><a href="https://coolshell.cn/articles/10910.html" target="_blank" rel="external">分布式系统的事务处理</a>。</li>
</ul>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[Java 守护线程]]></title>
      <url>http://matt33.com/2018/07/07/java-daemon-thread/</url>
      <content type="html"><![CDATA[<p>在 Java 并发编程实践或看涉及到 Java 并发相关的代码时，经常会遇到一些线程（比如做 metrics 统计的线程等）会通过 <code>setDaemon()</code> 方法设置将该线程的 daemon 变量设置为 True，也就是将这个线程设置为了<strong>守护线程(daemon thread)</strong>，那么什么是守护线程呢？或者说守护线程与非守护线程（普通线程）的区别在什么地方呢？这个就是本文主要讲述的内容。</p>
<h2 id="守护线程"><a href="#守护线程" class="headerlink" title="守护线程"></a>守护线程</h2><p>一般来说，Java 中的线程可以分为两种：守护线程和普通线程。在 JVM 刚启动时，它创建的所有线程，除了主线程（main thread）外，其他的线程都是守护线程（比如：垃圾收集器、以及其他执行辅助操作的线程）。</p>
<p>当创建一个新线程时，新线程将会继承它线程的守护状态，默认情况下，主线程创建的所有线程都是普通线程。</p>
<p>什么情况下会需要守护线程呢？一般情况下是，当我们希望创建一个线程来执行一些辅助的工作，但是又不希望这个线程阻碍 JVM 的关闭，在这种情况下，我们就需要使用守护线程了。</p>
<h2 id="守护线程的作用"><a href="#守护线程的作用" class="headerlink" title="守护线程的作用"></a>守护线程的作用</h2><p>守护线程与普通线程唯一的区别是：当线程退出时，JVM 会检查其他正在运行的线程，如果这些线程都是守护线程，那么 JVM 会正常退出操作，但是如果有普通线程还在运行，JVM 是不会执行退出操作的。当 JVM 退出时，所有仍然存在的守护线程都将被抛弃，既不会执行 finally 部分的代码，也不会执行 stack unwound 操作，JVM 会直接退出。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">When the JVM halts any remaining daemon threads are abandoned:</div><div class="line"></div><div class="line"> 1. finally blocks are not executed,</div><div class="line"> 2. stacks are not unwound - the JVM just exits.</div></pre></td></tr></table></figure>
<p>下面有个小示例，来自 <a href="https://stackoverflow.com/questions/2213340/what-is-a-daemon-thread-in-java" target="_blank" rel="external">What is a daemon thread in Java?</a>，代码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">DaemonTest</span> </span>&#123;</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</div><div class="line">        <span class="keyword">new</span> WorkerThread().start();</div><div class="line"></div><div class="line">        <span class="keyword">try</span> &#123;</div><div class="line">            Thread.sleep(<span class="number">7500</span>);</div><div class="line">        &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</div><div class="line">            <span class="comment">// handle here exception</span></div><div class="line">        &#125;</div><div class="line"></div><div class="line">        System.out.println(<span class="string">"Main Thread ending"</span>);</div><div class="line">    &#125;</div><div class="line"></div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">WorkerThread</span> <span class="keyword">extends</span> <span class="title">Thread</span> </span>&#123;</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="title">WorkerThread</span><span class="params">()</span> </span>&#123;</div><div class="line">        <span class="comment">// When false, (i.e. when it's a user thread), the Worker thread continues to run.</span></div><div class="line">        <span class="comment">// When true, (i.e. when it's a daemon thread), the Worker thread terminates when the main thread terminates.</span></div><div class="line">        setDaemon(<span class="keyword">false</span>);</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</div><div class="line">        <span class="keyword">int</span> count = <span class="number">0</span>;</div><div class="line"></div><div class="line">        <span class="keyword">while</span> (<span class="keyword">true</span>) &#123;</div><div class="line">            System.out.println(<span class="string">"Hello from Worker "</span> + count++);</div><div class="line"></div><div class="line">            <span class="keyword">try</span> &#123;</div><div class="line">                sleep(<span class="number">5000</span>);</div><div class="line">            &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</div><div class="line">                <span class="comment">// handle exception here</span></div><div class="line">            &#125;</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>当为普通线程时，输出如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">Hello from Worker 0</div><div class="line">Hello from Worker 1</div><div class="line">Main Thread ending</div><div class="line">Hello from Worker 2</div><div class="line">Hello from Worker 3</div><div class="line">Hello from Worker 4</div><div class="line">Hello from Worker 5</div><div class="line">....</div></pre></td></tr></table></figure>
<p>也就是说，此时即使主线程执行完了，JVM 也会等待 WorkerThread 执行完毕才会退出，而如果将该线程设置守护线程的话，输出如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">Hello from Worker 0</div><div class="line">Hello from Worker 1</div><div class="line">Main Thread ending</div></pre></td></tr></table></figure>
<p>在 main 线程执行完毕后，JVM 进程就退出了，不会 care WorkerThread 线程是否执行完毕。</p>
<p>参考：</p>
<ul>
<li><a href="https://stackoverflow.com/questions/2213340/what-is-a-daemon-thread-in-java" target="_blank" rel="external">What is a daemon thread in Java?</a>;</li>
<li><a href="http://www.javaconcurrencyinpractice.com/" target="_blank" rel="external">《Java 并发编程实战》</a>。</li>
</ul>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[Kafka 源码解析之 Server 1+N+M 网络处理模型（二十三）]]></title>
      <url>http://matt33.com/2018/06/27/kafka-server-process-model/</url>
      <content type="html"><![CDATA[<p>前面7篇对 Kafka Controller 的内容做了相应的总结，Controller 这部分的总结算是暂时告一段落，本节会讲述 Kafka 源码分析系列中最后一节的内容，是关于 Server 端对不同类型请求处理的网络模型。在前面的文章中也讲述过几种不同类型的请求处理实现，如果还有印象，就会知道它们都是通过 KafkaApis 对象处理的，但是前面并没有详细讲述 Server 端是如何监听到相应的请求、请求是如何交给 KafkaApis 对象进行处理，以及处理后是如何返回给请求者（请求者可以是 client 也可以是 server），这些都属于 Server 的网络处理模型，也是本文讲述的主要内容。</p>
<h2 id="Server-网络模型整体流程"><a href="#Server-网络模型整体流程" class="headerlink" title="Server 网络模型整体流程"></a>Server 网络模型整体流程</h2><p>Kafka Server 启动后，会通过 KafkaServer 的 <code>startup()</code> 方法初始化涉及到网络模型的相关对象，如下所示：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">startup</span></span>()&#123;</div><div class="line">  <span class="comment">//note: socketServer</span></div><div class="line">  socketServer = <span class="keyword">new</span> <span class="type">SocketServer</span>(config, metrics, time, credentialProvider)</div><div class="line">  socketServer.startup()</div><div class="line">  <span class="comment">//<span class="doctag">NOTE:</span> 初始化 KafkaApis 实例,每个 Server 只会启动一个线程</span></div><div class="line">  apis = <span class="keyword">new</span> <span class="type">KafkaApis</span>(socketServer.requestChannel, replicaManager, adminManager, groupCoordinator,</div><div class="line">    kafkaController, zkUtils, config.brokerId, config, metadataCache, metrics, authorizer, quotaManagers,</div><div class="line">    clusterId, time)</div><div class="line"></div><div class="line">  requestHandlerPool = <span class="keyword">new</span> <span class="type">KafkaRequestHandlerPool</span>(config.brokerId, socketServer.requestChannel, apis, time,</div><div class="line">    config.numIoThreads)</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>Kafka Server 在启动时会初始化 SocketServer、KafkaApis 和 KafkaRequestHandlerPool 对象，这也是 Server 网络处理模型的主要组成部分。Kafka Server 的网络处理模型也是基于 Java NIO 机制实现的，实现模式与 Reactor 模式类似，其完整的处理流程图如下所示：</p>
<p><img src="/images/kafka/server-nio.png" alt="Kafka Server 1+N+M 网络处理模型"></p>
<p>上图如果现在不理解，并不要紧，这里先简单介绍一些，讲述一下整体的流程，本节下面会结合 Kafka 的代码详细来讲述图中的过程。上图的网络模型可以简要总结为以下三个重要组成部分：</p>
<ol>
<li>1 个 Acceptor 线程，负责监听 Socket 新的连接请求，注册了 <code>OP_ACCEPT</code> 事件，将新的连接按照 round robin 方式交给对应的 Processor 线程处理；</li>
<li>N 个 Processor 线程，其中每个 Processor 都有自己的 selector，它会向 Acceptor 分配的 SocketChannel 注册相应的 <code>OP_READ</code> 事件，N 的大小由 <code>num.networker.threads</code> 决定；</li>
<li>M 个 KafkaRequestHandler  线程处理请求，并将处理的结果返回给 Processor 线程对应的 response queue 中，由 Processor 将处理的结果返回给相应的请求发送者，M 的大小由 <code>num.io.threads</code> 来决定。</li>
</ol>
<p>上图展示的整体的处理流程如下所示：</p>
<ol>
<li>Acceptor 监听到来自请求者（请求者可以是来自 client，也可以来自 server）的新的连接，Acceptor 将这个请求者按照 round robin 的方式交给对对应的 Processor 进行处理；</li>
<li>Processor 注册这个 SocketChannel 的 <code>OP_READ</code> 的事件，如果有请求发送过来就可以被 Processor 的 Selector 选中；</li>
<li>Processor 将请求者发送的请求放入到一个 Request Queue 中，这是所有 Processor 共有的一个队列；</li>
<li>KafkaRequestHandler 从 Request Queue 中取出请求；</li>
<li>调用 KafkaApis 进行相应的处理；</li>
<li>处理的结果放入到该 Processor 对应的 Response Queue 中（每个 request 都标识它们来自哪个 Processor），Request Queue 的数量与 Processor 的数量保持一致；</li>
<li>Processor 从对应的 Response Queue 中取出 response；</li>
<li>Processor 将处理的结果返回给对应的请求者。</li>
</ol>
<p>上面是 Server 端网络处理的整体流程，下面我们开始详细讲述上面内容在 Kafka 中实现。</p>
<h2 id="SocketServer"><a href="#SocketServer" class="headerlink" title="SocketServer"></a>SocketServer</h2><p>SocketServer 是接收 Socket 连接、处理请求并返回处理结果的地方，Acceptor 及 Processor 的初始化、处理逻辑都是在这里实现的。在SocketServer 内有几个比较重要的变量，这里先来看下：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div></pre></td><td class="code"><pre><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">SocketServer</span>(<span class="params">val config: <span class="type">KafkaConfig</span>, val metrics: <span class="type">Metrics</span>, val time: <span class="type">Time</span>, val credentialProvider: <span class="type">CredentialProvider</span></span>) <span class="keyword">extends</span> <span class="title">Logging</span> <span class="keyword">with</span> <span class="title">KafkaMetricsGroup</span> </span>&#123;</div><div class="line"></div><div class="line">  <span class="keyword">private</span> <span class="keyword">val</span> endpoints = config.listeners.map(l =&gt; l.listenerName -&gt; l).toMap <span class="comment">//note: broker 开放的端口数</span></div><div class="line">  <span class="keyword">private</span> <span class="keyword">val</span> numProcessorThreads = config.numNetworkThreads <span class="comment">//note: num.network.threads 默认为 3个，即 processor</span></div><div class="line">  <span class="keyword">private</span> <span class="keyword">val</span> maxQueuedRequests = config.queuedMaxRequests <span class="comment">//note:  queued.max.requests，request 队列中允许的最多请求数，默认是500</span></div><div class="line">  <span class="keyword">private</span> <span class="keyword">val</span> totalProcessorThreads = numProcessorThreads * endpoints.size <span class="comment">//note: 每个端口会对应 N 个 processor</span></div><div class="line"></div><div class="line">  <span class="keyword">private</span> <span class="keyword">val</span> maxConnectionsPerIp = config.maxConnectionsPerIp <span class="comment">//note: 默认 2147483647</span></div><div class="line">  <span class="keyword">private</span> <span class="keyword">val</span> maxConnectionsPerIpOverrides = config.maxConnectionsPerIpOverrides</div><div class="line"></div><div class="line">  <span class="keyword">this</span>.logIdent = <span class="string">"[Socket Server on Broker "</span> + config.brokerId + <span class="string">"], "</span></div><div class="line"></div><div class="line">  <span class="comment">//note: 请求队列</span></div><div class="line">  <span class="keyword">val</span> requestChannel = <span class="keyword">new</span> <span class="type">RequestChannel</span>(totalProcessorThreads, maxQueuedRequests)</div><div class="line">  <span class="keyword">private</span> <span class="keyword">val</span> processors = <span class="keyword">new</span> <span class="type">Array</span>[<span class="type">Processor</span>](totalProcessorThreads)</div><div class="line"></div><div class="line">  <span class="keyword">private</span>[network] <span class="keyword">val</span> acceptors = mutable.<span class="type">Map</span>[<span class="type">EndPoint</span>, <span class="type">Acceptor</span>]()</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">RequestChannel</span>(<span class="params">val numProcessors: <span class="type">Int</span>, val queueSize: <span class="type">Int</span></span>) <span class="keyword">extends</span> <span class="title">KafkaMetricsGroup</span> </span>&#123;</div><div class="line">  <span class="keyword">private</span> <span class="keyword">var</span> responseListeners: <span class="type">List</span>[(<span class="type">Int</span>) =&gt; <span class="type">Unit</span>] = <span class="type">Nil</span></div><div class="line">  <span class="comment">//note: 一个 requestQueue 队列,N 个 responseQueues 队列</span></div><div class="line">  <span class="keyword">private</span> <span class="keyword">val</span> requestQueue = <span class="keyword">new</span> <span class="type">ArrayBlockingQueue</span>[<span class="type">RequestChannel</span>.<span class="type">Request</span>](queueSize)</div><div class="line">  <span class="keyword">private</span> <span class="keyword">val</span> responseQueues = <span class="keyword">new</span> <span class="type">Array</span>[<span class="type">BlockingQueue</span>[<span class="type">RequestChannel</span>.<span class="type">Response</span>]](numProcessors)</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>其中</p>
<ol>
<li><code>numProcessorThreads</code>：决定了 Processor 的个数，默认是3个，也就是 1+N+M 的 N 的数值；</li>
<li><code>maxQueuedRequests</code>：决定了 request queue 中最多允许放入多少个请求（等待处理的请求），默认是 500；</li>
<li>在 <code>RequestChannel</code> 中初始化了一个 requestQueue 和 N 个 responseQueue。</li>
</ol>
<h3 id="SocketServer-初始化"><a href="#SocketServer-初始化" class="headerlink" title="SocketServer 初始化"></a>SocketServer 初始化</h3><p>在 SocketServer 初始化方法 <code>startup()</code> 中，会初始化 1 个 Acceptor 和 N 个 Processor 线程（每个 EndPoint 都会初始化这么多，一般来说一个 Server 只会设置一个端口），其实现如下：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">startup</span></span>() &#123;</div><div class="line">  <span class="keyword">this</span>.synchronized &#123;</div><div class="line">    <span class="comment">//note: 一台 broker 一般只设置一个端口，当然这里也可以设置两个</span></div><div class="line">    config.listeners.foreach &#123; endpoint =&gt;</div><div class="line">      <span class="keyword">val</span> listenerName = endpoint.listenerName</div><div class="line">      <span class="keyword">val</span> securityProtocol = endpoint.securityProtocol</div><div class="line">      <span class="keyword">val</span> processorEndIndex = processorBeginIndex + numProcessorThreads</div><div class="line"></div><div class="line">      <span class="comment">//note: N 个 processor</span></div><div class="line">      <span class="keyword">for</span> (i &lt;- processorBeginIndex until processorEndIndex)</div><div class="line">        processors(i) = newProcessor(i, connectionQuotas, listenerName, securityProtocol)</div><div class="line"></div><div class="line">      <span class="comment">//note: 1个 Acceptor</span></div><div class="line">      <span class="keyword">val</span> acceptor = <span class="keyword">new</span> <span class="type">Acceptor</span>(endpoint, sendBufferSize, recvBufferSize, brokerId,</div><div class="line">        processors.slice(processorBeginIndex, processorEndIndex), connectionQuotas)</div><div class="line">      acceptors.put(endpoint, acceptor)</div><div class="line">      <span class="type">Utils</span>.newThread(<span class="string">s"kafka-socket-acceptor-<span class="subst">$listenerName</span>-<span class="subst">$securityProtocol</span>-<span class="subst">$&#123;endpoint.port&#125;</span>"</span>, acceptor, <span class="literal">false</span>).start()</div><div class="line">      acceptor.awaitStartup()</div><div class="line"></div><div class="line">      processorBeginIndex = processorEndIndex</div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h3 id="Acceptor-处理"><a href="#Acceptor-处理" class="headerlink" title="Acceptor 处理"></a>Acceptor 处理</h3><p>SocketServer 在初始化后 Acceptor 线程后，Acceptor 启动，会首先注册 <code>OP_ACCEPT</code> 事件，监听是否有新的连接，如果来了新的连接就将该 SocketChannel 交给对应的 Processor 进行处理，Processor 是通过 round robin 方法选择的，这样可以保证 Processor 的负载相差无几（至少可以保证监听的 SocketChannel 差不多），实现如下：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">run</span></span>() &#123;</div><div class="line">  serverChannel.register(nioSelector, <span class="type">SelectionKey</span>.<span class="type">OP_ACCEPT</span>)<span class="comment">//note: 注册 accept 事件</span></div><div class="line">  startupComplete()</div><div class="line">  <span class="keyword">try</span> &#123;</div><div class="line">    <span class="keyword">var</span> currentProcessor = <span class="number">0</span></div><div class="line">    <span class="keyword">while</span> (isRunning) &#123;</div><div class="line">      <span class="keyword">try</span> &#123;</div><div class="line">        <span class="keyword">val</span> ready = nioSelector.select(<span class="number">500</span>)</div><div class="line">        <span class="keyword">if</span> (ready &gt; <span class="number">0</span>) &#123;</div><div class="line">          <span class="keyword">val</span> keys = nioSelector.selectedKeys()</div><div class="line">          <span class="keyword">val</span> iter = keys.iterator()</div><div class="line">          <span class="keyword">while</span> (iter.hasNext &amp;&amp; isRunning) &#123;</div><div class="line">            <span class="keyword">try</span> &#123;</div><div class="line">              <span class="keyword">val</span> key = iter.next</div><div class="line">              iter.remove()</div><div class="line">              <span class="keyword">if</span> (key.isAcceptable)</div><div class="line">                accept(key, processors(currentProcessor))<span class="comment">//note: 拿到一个socket 连接，轮询选择一个processor进行处理</span></div><div class="line">              <span class="keyword">else</span></div><div class="line">                <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">IllegalStateException</span>(<span class="string">"Unrecognized key state for acceptor thread."</span>)</div><div class="line"></div><div class="line">              <span class="comment">//note: 轮询算法,使用 round robin</span></div><div class="line">              <span class="comment">// round robin to the next processor thread</span></div><div class="line">              currentProcessor = (currentProcessor + <span class="number">1</span>) % processors.length</div><div class="line">            &#125; <span class="keyword">catch</span> &#123;</div><div class="line">              <span class="keyword">case</span> e: <span class="type">Throwable</span> =&gt; error(<span class="string">"Error while accepting connection"</span>, e)</div><div class="line">            &#125;</div><div class="line">          &#125;</div><div class="line">        &#125;</div><div class="line">      &#125;</div><div class="line">      <span class="keyword">catch</span> &#123;</div><div class="line">        <span class="comment">// We catch all the throwables to prevent the acceptor thread from exiting on exceptions due</span></div><div class="line">        <span class="comment">// to a select operation on a specific channel or a bad request. We don't want</span></div><div class="line">        <span class="comment">// the broker to stop responding to requests from other clients in these scenarios.</span></div><div class="line">        <span class="keyword">case</span> e: <span class="type">ControlThrowable</span> =&gt; <span class="keyword">throw</span> e</div><div class="line">        <span class="keyword">case</span> e: <span class="type">Throwable</span> =&gt; error(<span class="string">"Error occurred"</span>, e)</div><div class="line">      &#125;</div><div class="line">    &#125;</div><div class="line">  &#125; <span class="keyword">finally</span> &#123;</div><div class="line">    debug(<span class="string">"Closing server socket and selector."</span>)</div><div class="line">    swallowError(serverChannel.close())</div><div class="line">    swallowError(nioSelector.close())</div><div class="line">    shutdownComplete()</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>Acceptor 通过 <code>accept()</code> 将该新连接交给对应的 Processor，其实现如下：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//note: 处理一个新的连接</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">accept</span></span>(key: <span class="type">SelectionKey</span>, processor: <span class="type">Processor</span>) &#123;</div><div class="line">  <span class="comment">//note: accept 事件发生时，获取注册到 selector 上的 ServerSocketChannel</span></div><div class="line">  <span class="keyword">val</span> serverSocketChannel = key.channel().asInstanceOf[<span class="type">ServerSocketChannel</span>]</div><div class="line">  <span class="keyword">val</span> socketChannel = serverSocketChannel.accept()</div><div class="line">  <span class="keyword">try</span> &#123;</div><div class="line">    connectionQuotas.inc(socketChannel.socket().getInetAddress)</div><div class="line">    socketChannel.configureBlocking(<span class="literal">false</span>)</div><div class="line">    socketChannel.socket().setTcpNoDelay(<span class="literal">true</span>)</div><div class="line">    socketChannel.socket().setKeepAlive(<span class="literal">true</span>)</div><div class="line">    <span class="keyword">if</span> (sendBufferSize != <span class="type">Selectable</span>.<span class="type">USE_DEFAULT_BUFFER_SIZE</span>)</div><div class="line">      socketChannel.socket().setSendBufferSize(sendBufferSize)</div><div class="line"></div><div class="line">    debug(<span class="string">"Accepted connection from %s on %s and assigned it to processor %d, sendBufferSize [actual|requested]: [%d|%d] recvBufferSize [actual|requested]: [%d|%d]"</span></div><div class="line">          .format(socketChannel.socket.getRemoteSocketAddress, socketChannel.socket.getLocalSocketAddress, processor.id,</div><div class="line">                socketChannel.socket.getSendBufferSize, sendBufferSize,</div><div class="line">                socketChannel.socket.getReceiveBufferSize, recvBufferSize))</div><div class="line"></div><div class="line">    <span class="comment">//note: 轮询选择不同的 processor 进行处理</span></div><div class="line">    processor.accept(socketChannel)</div><div class="line">  &#125; <span class="keyword">catch</span> &#123;</div><div class="line">    <span class="keyword">case</span> e: <span class="type">TooManyConnectionsException</span> =&gt;</div><div class="line">      info(<span class="string">"Rejected connection from %s, address already has the configured maximum of %d connections."</span>.format(e.ip, e.count))</div><div class="line">      close(socketChannel)</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h3 id="Processor-处理"><a href="#Processor-处理" class="headerlink" title="Processor 处理"></a>Processor 处理</h3><p>在前面，Acceptor 通过 <code>accept()</code> 将新的连接交给 Processor，Processor 实际上是将该 SocketChannel 添加到该 Processor 的 <code>newConnections</code> 队列中，实现如下：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">accept</span></span>(socketChannel: <span class="type">SocketChannel</span>) &#123;</div><div class="line">  newConnections.add(socketChannel)<span class="comment">//note: 添加到队列中</span></div><div class="line">  wakeup()<span class="comment">//note: 唤醒 Processor 的 selector（如果此时在阻塞的话）</span></div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>这里详细看下 Processor 线程做了什么事情，其 <code>run()</code> 方法的实现如下：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">run</span></span>() &#123;</div><div class="line">  startupComplete()</div><div class="line">  <span class="keyword">while</span> (isRunning) &#123;</div><div class="line">    <span class="keyword">try</span> &#123;</div><div class="line">      <span class="comment">// setup any new connections that have been queued up</span></div><div class="line">      configureNewConnections()<span class="comment">//note: 对新的 socket 连接,并注册 READ 事件</span></div><div class="line">      <span class="comment">// register any new responses for writing</span></div><div class="line">      processNewResponses()<span class="comment">//note: 处理 response 队列中 response</span></div><div class="line">      poll() <span class="comment">//note: 监听所有的 socket channel，是否有新的请求发送过来</span></div><div class="line">      processCompletedReceives() <span class="comment">//note: 处理接收到请求，将其放入到 request queue 中</span></div><div class="line">      processCompletedSends() <span class="comment">//note: 处理已经完成的发送</span></div><div class="line">      processDisconnected() <span class="comment">//note: 处理断开的连接</span></div><div class="line">    &#125; <span class="keyword">catch</span> &#123;</div><div class="line">      <span class="comment">// We catch all the throwables here to prevent the processor thread from exiting. We do this because</span></div><div class="line">      <span class="comment">// letting a processor exit might cause a bigger impact on the broker. Usually the exceptions thrown would</span></div><div class="line">      <span class="comment">// be either associated with a specific socket channel or a bad request. We just ignore the bad socket channel</span></div><div class="line">      <span class="comment">// or request. This behavior might need to be reviewed if we see an exception that need the entire broker to stop.</span></div><div class="line">      <span class="keyword">case</span> e: <span class="type">ControlThrowable</span> =&gt; <span class="keyword">throw</span> e</div><div class="line">      <span class="keyword">case</span> e: <span class="type">Throwable</span> =&gt;</div><div class="line">        error(<span class="string">"Processor got uncaught exception."</span>, e)</div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  debug(<span class="string">"Closing selector - processor "</span> + id)</div><div class="line">  swallowError(closeAll())</div><div class="line">  shutdownComplete()</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>Processor 在一次循环中，主要做的事情如下：</p>
<ol>
<li><code>configureNewConnections()</code>：对新添加到 <code>newConnections</code> 队列中的 SocketChannel 进行处理，这里主要是 Processor 的 selector 注册该连接的 <code>OP_READ</code> 事件；</li>
<li><code>processNewResponses()</code>：从该 Processor 对应的 response queue 中取出一个 response，进行发送；</li>
<li><code>poll()</code>：调用 selector 的 <code>poll()</code> 方法，遍历注册的 SocketChannel，查看是否有事件准备就绪；</li>
<li><code>processCompletedReceives()</code>：将接收到请求添加到的 request queue 中；</li>
<li><code>processCompletedSends()</code>：处理已经完成的响应发送；</li>
<li><code>processDisconnected()</code>：处理断开的 SocketChannel。</li>
</ol>
<p>上面就是 Processor 线程处理的主要逻辑，先是向新的 SocketChannel 注册相应的事件，监控是否有请求发送过来，接着从 response queue 中取出处理完成的请求发送给对应的请求者，然后调用一下 selector 的 <code>poll()</code>，遍历一下注册的所有 SocketChannel，判断是否有事件就绪，然后做相应的处理。这里需要注意的是，request queue 是所有 Processor 公用的一个队列，而 response queue 则是与 Processor 一一对应的，因为每个 Processor 监听的 SocketChannel 并不是同一批的，如果公有一个 response queue，那么这个 N 个 Processor 的 selector 要去监听所有的 SocketChannel，而不是现在这种，只需要去关注分配给自己的 SocketChannel。</p>
<p>下面分别看下上面的这些方法的具体实现。</p>
<h4 id="configureNewConnections"><a href="#configureNewConnections" class="headerlink" title="configureNewConnections"></a>configureNewConnections</h4><p><code>configureNewConnections()</code> 对新添加到 <code>newConnections</code> 队列中的 SocketChannel 进行处理，主要是 selector 注册相应的 <code>OP_READ</code> 事件，其实现如下：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//note: 如果有新的连接过来，将该 Channel 的 OP_READ 事件注册到 selector 上</span></div><div class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">configureNewConnections</span></span>() &#123;</div><div class="line">  <span class="keyword">while</span> (!newConnections.isEmpty) &#123;</div><div class="line">    <span class="keyword">val</span> channel = newConnections.poll()</div><div class="line">    <span class="keyword">try</span> &#123;</div><div class="line">      debug(<span class="string">s"Processor <span class="subst">$id</span> listening to new connection from <span class="subst">$&#123;channel.socket.getRemoteSocketAddress&#125;</span>"</span>)</div><div class="line">      <span class="keyword">val</span> localHost = channel.socket().getLocalAddress.getHostAddress</div><div class="line">      <span class="keyword">val</span> localPort = channel.socket().getLocalPort</div><div class="line">      <span class="keyword">val</span> remoteHost = channel.socket().getInetAddress.getHostAddress</div><div class="line">      <span class="keyword">val</span> remotePort = channel.socket().getPort</div><div class="line">      <span class="keyword">val</span> connectionId = <span class="type">ConnectionId</span>(localHost, localPort, remoteHost, remotePort).toString</div><div class="line">      selector.register(connectionId, channel)</div><div class="line">    &#125; <span class="keyword">catch</span> &#123;</div><div class="line">      <span class="comment">// We explicitly catch all non fatal exceptions and close the socket to avoid a socket leak. The other</span></div><div class="line">      <span class="comment">// throwables will be caught in processor and logged as uncaught exceptions.</span></div><div class="line">      <span class="keyword">case</span> <span class="type">NonFatal</span>(e) =&gt;</div><div class="line">        <span class="keyword">val</span> remoteAddress = channel.getRemoteAddress</div><div class="line">        <span class="comment">// need to close the channel here to avoid a socket leak.</span></div><div class="line">        close(channel)</div><div class="line">        error(<span class="string">s"Processor <span class="subst">$id</span> closed connection from <span class="subst">$remoteAddress</span>"</span>, e)</div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h4 id="processNewResponses"><a href="#processNewResponses" class="headerlink" title="processNewResponses"></a>processNewResponses</h4><p><code>processNewResponses()</code> 方法是从该 Processor 对应的 response queue 中取出一个 response，Processor 是通过 RequestChannel 的 <code>receiveResponse()</code> 从该 Processor 对应的 response queue 中取出 response，如下所示：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//note: 获取 response</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">receiveResponse</span></span>(processor: <span class="type">Int</span>): <span class="type">RequestChannel</span>.<span class="type">Response</span> = &#123;</div><div class="line">  <span class="keyword">val</span> response = responseQueues(processor).poll()</div><div class="line">  <span class="keyword">if</span> (response != <span class="literal">null</span>)</div><div class="line">    response.request.responseDequeueTimeMs = <span class="type">Time</span>.<span class="type">SYSTEM</span>.milliseconds</div><div class="line">  response</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>取到相应的 response 之后，会判断该 response 的类型，进行相应的操作，如果需要返回，那么会调用 <code>sendResponse()</code> 发送该 response，如下所示：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//note: 处理一个新的 response 响应</span></div><div class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">processNewResponses</span></span>() &#123;</div><div class="line">  <span class="keyword">var</span> curr = requestChannel.receiveResponse(id)</div><div class="line">  <span class="keyword">while</span> (curr != <span class="literal">null</span>) &#123;</div><div class="line">    <span class="keyword">try</span> &#123;</div><div class="line">      curr.responseAction <span class="keyword">match</span> &#123;</div><div class="line">        <span class="keyword">case</span> <span class="type">RequestChannel</span>.<span class="type">NoOpAction</span> =&gt; <span class="comment">//note: 如果这个请求不需要返回 response，再次注册该监听事件</span></div><div class="line">          <span class="comment">// There is no response to send to the client, we need to read more pipelined requests</span></div><div class="line">          <span class="comment">// that are sitting in the server's socket buffer</span></div><div class="line">          curr.request.updateRequestMetrics</div><div class="line">          trace(<span class="string">"Socket server received empty response to send, registering for read: "</span> + curr)</div><div class="line">          <span class="keyword">val</span> channelId = curr.request.connectionId</div><div class="line">          <span class="keyword">if</span> (selector.channel(channelId) != <span class="literal">null</span> || selector.closingChannel(channelId) != <span class="literal">null</span>)</div><div class="line">              selector.unmute(channelId)</div><div class="line">        <span class="keyword">case</span> <span class="type">RequestChannel</span>.<span class="type">SendAction</span> =&gt; <span class="comment">//note: 需要发送的 response，那么进行发送</span></div><div class="line">          sendResponse(curr)</div><div class="line">        <span class="keyword">case</span> <span class="type">RequestChannel</span>.<span class="type">CloseConnectionAction</span> =&gt; <span class="comment">//note: 要关闭的 response</span></div><div class="line">          curr.request.updateRequestMetrics</div><div class="line">          trace(<span class="string">"Closing socket connection actively according to the response code."</span>)</div><div class="line">          close(selector, curr.request.connectionId)</div><div class="line">      &#125;</div><div class="line">    &#125; <span class="keyword">finally</span> &#123;</div><div class="line">      curr = requestChannel.receiveResponse(id)</div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="comment">/* `protected` for test usage */</span></div><div class="line"><span class="comment">//note: 发送的对应的 response</span></div><div class="line"><span class="keyword">protected</span>[network] <span class="function"><span class="keyword">def</span> <span class="title">sendResponse</span></span>(response: <span class="type">RequestChannel</span>.<span class="type">Response</span>) &#123;</div><div class="line">  trace(<span class="string">s"Socket server received response to send, registering for write and sending data: <span class="subst">$response</span>"</span>)</div><div class="line">  <span class="keyword">val</span> channel = selector.channel(response.responseSend.destination)</div><div class="line">  <span class="comment">// `channel` can be null if the selector closed the connection because it was idle for too long</span></div><div class="line">  <span class="keyword">if</span> (channel == <span class="literal">null</span>) &#123;</div><div class="line">    warn(<span class="string">s"Attempting to send response via channel for which there is no open connection, connection id <span class="subst">$id</span>"</span>)</div><div class="line">    response.request.updateRequestMetrics()</div><div class="line">  &#125;</div><div class="line">  <span class="keyword">else</span> &#123;</div><div class="line">    selector.send(response.responseSend) <span class="comment">//note: 发送该 response</span></div><div class="line">    inflightResponses += (response.request.connectionId -&gt; response) <span class="comment">//note: 添加到 inflinght 中</span></div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h4 id="processCompletedReceives"><a href="#processCompletedReceives" class="headerlink" title="processCompletedReceives"></a>processCompletedReceives</h4><p><code>processCompletedReceives()</code> 方法的主要作用是处理接收到请求，并将其放入到 request queue 中，其实现如下：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//note: 处理接收到的所有请求</span></div><div class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">processCompletedReceives</span></span>() &#123;</div><div class="line">  selector.completedReceives.asScala.foreach &#123; receive =&gt;</div><div class="line">    <span class="keyword">try</span> &#123;</div><div class="line">      <span class="keyword">val</span> openChannel = selector.channel(receive.source)</div><div class="line">      <span class="keyword">val</span> session = &#123;</div><div class="line">        <span class="comment">// Only methods that are safe to call on a disconnected channel should be invoked on 'channel'.</span></div><div class="line">        <span class="keyword">val</span> channel = <span class="keyword">if</span> (openChannel != <span class="literal">null</span>) openChannel <span class="keyword">else</span> selector.closingChannel(receive.source)</div><div class="line">        <span class="type">RequestChannel</span>.<span class="type">Session</span>(<span class="keyword">new</span> <span class="type">KafkaPrincipal</span>(<span class="type">KafkaPrincipal</span>.<span class="type">USER_TYPE</span>, channel.principal.getName), channel.socketAddress)</div><div class="line">      &#125;</div><div class="line">      <span class="keyword">val</span> req = <span class="type">RequestChannel</span>.<span class="type">Request</span>(processor = id, connectionId = receive.source, session = session,</div><div class="line">        buffer = receive.payload, startTimeMs = time.milliseconds, listenerName = listenerName,</div><div class="line">        securityProtocol = securityProtocol)</div><div class="line">      requestChannel.sendRequest(req) <span class="comment">//note: 添加到请求队列，如果队列满了，将会阻塞</span></div><div class="line">      selector.mute(receive.source) <span class="comment">//note: 移除该连接的 OP_READ 监听</span></div><div class="line">    &#125; <span class="keyword">catch</span> &#123;</div><div class="line">      <span class="keyword">case</span> e @ (_: <span class="type">InvalidRequestException</span> | _: <span class="type">SchemaException</span>) =&gt;</div><div class="line">        <span class="comment">// note that even though we got an exception, we can assume that receive.source is valid. Issues with constructing a valid receive object were handled earlier</span></div><div class="line">        error(<span class="string">s"Closing socket for <span class="subst">$&#123;receive.source&#125;</span> because of error"</span>, e)</div><div class="line">        close(selector, receive.source)</div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h4 id="processCompletedSends"><a href="#processCompletedSends" class="headerlink" title="processCompletedSends"></a>processCompletedSends</h4><p><code>processCompletedSends()</code> 方法是处理已经完成的发送，其实现如下：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">processCompletedSends</span></span>() &#123;</div><div class="line">  selector.completedSends.asScala.foreach &#123; send =&gt;</div><div class="line">    <span class="comment">//note: response 发送完成，从正在发送的集合中移除</span></div><div class="line">    <span class="keyword">val</span> resp = inflightResponses.remove(send.destination).getOrElse &#123;</div><div class="line">      <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">IllegalStateException</span>(<span class="string">s"Send for <span class="subst">$&#123;send.destination&#125;</span> completed, but not in `inflightResponses`"</span>)</div><div class="line">    &#125;</div><div class="line">    resp.request.updateRequestMetrics()</div><div class="line">    selector.unmute(send.destination) <span class="comment">//note: 完成这个请求之后再次监听 OP_READ 事件</span></div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h2 id="KafkaRequestHandlerPool"><a href="#KafkaRequestHandlerPool" class="headerlink" title="KafkaRequestHandlerPool"></a>KafkaRequestHandlerPool</h2><p>上面主要是讲述 SocketServer 中 Acceptor 与 Processor 的处理内容，也就是 1+N+M 模型中 1+N 部分，下面开始讲述 M 部分，也就是 KafkaRequestHandler 的内容，其初始化实现如下：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div></pre></td><td class="code"><pre><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">KafkaRequestHandlerPool</span>(<span class="params">val brokerId: <span class="type">Int</span>,</span></span></div><div class="line">                              val requestChannel: <span class="type">RequestChannel</span>,</div><div class="line">                              val apis: <span class="type">KafkaApis</span>,</div><div class="line">                              time: <span class="type">Time</span>,</div><div class="line">                              numThreads: <span class="type">Int</span>) <span class="keyword">extends</span> <span class="title">Logging</span> <span class="keyword">with</span> <span class="title">KafkaMetricsGroup</span> &#123;</div><div class="line"></div><div class="line">  <span class="comment">/* a meter to track the average free capacity of the request handlers */</span></div><div class="line">  <span class="keyword">private</span> <span class="keyword">val</span> aggregateIdleMeter = newMeter(<span class="string">"RequestHandlerAvgIdlePercent"</span>, <span class="string">"percent"</span>, <span class="type">TimeUnit</span>.<span class="type">NANOSECONDS</span>)</div><div class="line"></div><div class="line">  <span class="keyword">this</span>.logIdent = <span class="string">"[Kafka Request Handler on Broker "</span> + brokerId + <span class="string">"], "</span></div><div class="line">  <span class="keyword">val</span> threads = <span class="keyword">new</span> <span class="type">Array</span>[<span class="type">Thread</span>](numThreads)</div><div class="line">  <span class="keyword">val</span> runnables = <span class="keyword">new</span> <span class="type">Array</span>[<span class="type">KafkaRequestHandler</span>](numThreads)</div><div class="line">  <span class="comment">//note: 建立 M 个（numThreads）KafkaRequestHandler</span></div><div class="line">  <span class="keyword">for</span>(i &lt;- <span class="number">0</span> until numThreads) &#123;</div><div class="line">    <span class="comment">//note: requestChannel 是 Processor 存放 request 请求的地方,也是 Handler 处理完请求存放 response 的地方</span></div><div class="line">    runnables(i) = <span class="keyword">new</span> <span class="type">KafkaRequestHandler</span>(i, brokerId, aggregateIdleMeter, numThreads, requestChannel, apis, time)</div><div class="line">    threads(i) = <span class="type">Utils</span>.daemonThread(<span class="string">"kafka-request-handler-"</span> + i, runnables(i))</div><div class="line">    threads(i).start()</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">shutdown</span></span>() &#123;</div><div class="line">    info(<span class="string">"shutting down"</span>)</div><div class="line">    <span class="keyword">for</span>(handler &lt;- runnables)</div><div class="line">      handler.shutdown</div><div class="line">    <span class="keyword">for</span>(thread &lt;- threads)</div><div class="line">      thread.join</div><div class="line">    info(<span class="string">"shut down completely"</span>)</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>如上面实现所示：</p>
<ol>
<li>KafkaRequestHandlerPool 会初始化 M 个 KafkaRequestHandler 线程，并启动该线程；</li>
<li>在初始化 KafkaRequestHandler 时，传入一个 requestChannel 变量，这个是 Processor 存放 request 的地方，KafkaRequestHandler 在处理请求时，会从这个 queue 中取出相应的 request。</li>
</ol>
<h3 id="KafkaRequestHandler"><a href="#KafkaRequestHandler" class="headerlink" title="KafkaRequestHandler"></a>KafkaRequestHandler</h3><p>KafkaRequestHandler 线程的处理实现如下：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">run</span></span>() &#123;</div><div class="line">  <span class="keyword">while</span>(<span class="literal">true</span>) &#123;</div><div class="line">    <span class="keyword">try</span> &#123;</div><div class="line">      <span class="keyword">var</span> req : <span class="type">RequestChannel</span>.<span class="type">Request</span> = <span class="literal">null</span></div><div class="line">      <span class="keyword">while</span> (req == <span class="literal">null</span>) &#123;</div><div class="line">        <span class="comment">// We use a single meter for aggregate idle percentage for the thread pool.</span></div><div class="line">        <span class="comment">// Since meter is calculated as total_recorded_value / time_window and</span></div><div class="line">        <span class="comment">// time_window is independent of the number of threads, each recorded idle</span></div><div class="line">        <span class="comment">// time should be discounted by # threads.</span></div><div class="line">        <span class="keyword">val</span> startSelectTime = time.nanoseconds</div><div class="line">        req = requestChannel.receiveRequest(<span class="number">300</span>) <span class="comment">//note: 从 request queue 中拿去 request</span></div><div class="line">        <span class="keyword">val</span> idleTime = time.nanoseconds - startSelectTime</div><div class="line">        aggregateIdleMeter.mark(idleTime / totalHandlerThreads)</div><div class="line">      &#125;</div><div class="line"></div><div class="line">      <span class="keyword">if</span>(req eq <span class="type">RequestChannel</span>.<span class="type">AllDone</span>) &#123;</div><div class="line">        debug(<span class="string">"Kafka request handler %d on broker %d received shut down command"</span>.format(</div><div class="line">          id, brokerId))</div><div class="line">        <span class="keyword">return</span></div><div class="line">      &#125;</div><div class="line">      req.requestDequeueTimeMs = time.milliseconds</div><div class="line">      trace(<span class="string">"Kafka request handler %d on broker %d handling request %s"</span>.format(id, brokerId, req))</div><div class="line">      apis.handle(req) <span class="comment">//note: 处理请求,并将处理的结果通过 sendResponse 放入 response queue 中</span></div><div class="line">    &#125; <span class="keyword">catch</span> &#123;</div><div class="line">      <span class="keyword">case</span> e: <span class="type">Throwable</span> =&gt; error(<span class="string">"Exception when handling request"</span>, e)</div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>上述方法的实现逻辑：</p>
<ol>
<li>从 RequestChannel 取出相应的 request；</li>
<li>KafkaApis 处理这个 request，并通过 <code>requestChannel.sendResponse()</code> 将处理的结果放入 requestChannel 的 response queue 中，如下所示：</li>
</ol>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//note: 将 response 添加到对应的队列中</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">sendResponse</span></span>(response: <span class="type">RequestChannel</span>.<span class="type">Response</span>) &#123;</div><div class="line">  responseQueues(response.processor).put(response)</div><div class="line">  <span class="keyword">for</span>(onResponse &lt;- responseListeners)</div><div class="line">    onResponse(response.processor) <span class="comment">//note: 调用对应 processor 的 wakeup 方法</span></div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>到这里为止，一个请求从 Processor 接收，到 KafkaRequestHandler 通过 KafkaApis 处理并放回该 Processor 对应的 response queue 这整个过程就完成了（建议阅读本文的时候结合最前面的流程图一起看）。</p>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[Kafka 源码解析之 LeaderAndIsr 请求的处理（二十二）]]></title>
      <url>http://matt33.com/2018/06/25/leaderAndIsr-process/</url>
      <content type="html"><![CDATA[<p>本篇算是 Controller 部分的最后一篇，在前面讲述 ReplicaManager 时，留一个地方没有讲解，是关于 Broker 对 Controller 发送的 LeaderAndIsr 请求的处理，这个请求的处理实现会稍微复杂一些，本篇文章主要就是讲述 Kafka Server 是如何处理 LeaderAndIsr 请求的。</p>
<h2 id="LeaderAndIsr-请求"><a href="#LeaderAndIsr-请求" class="headerlink" title="LeaderAndIsr 请求"></a>LeaderAndIsr 请求</h2><p>LeaderAndIsr 请求是在一个 Topic Partition 的 leader、isr、assignment replicas 变动时，Controller 向 Broker 发送的一种请求，有时候是向这个 Topic Partition 的所有副本发送，有时候是其中的某个副本，跟具体的触发情况有关系。在一个 LeaderAndIsr 请求中，会封装多个 Topic Partition 的信息，每个 Topic Partition 会对应一个 PartitionState 对象，这个对象主要成员变量如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">PartitionState</span> </span>&#123;</div><div class="line">    <span class="keyword">public</span> <span class="keyword">final</span> <span class="keyword">int</span> controllerEpoch;</div><div class="line">    <span class="keyword">public</span> <span class="keyword">final</span> <span class="keyword">int</span> leader;</div><div class="line">    <span class="keyword">public</span> <span class="keyword">final</span> <span class="keyword">int</span> leaderEpoch;</div><div class="line">    <span class="keyword">public</span> <span class="keyword">final</span> List&lt;Integer&gt; isr;</div><div class="line">    <span class="keyword">public</span> <span class="keyword">final</span> <span class="keyword">int</span> zkVersion;</div><div class="line">    <span class="keyword">public</span> <span class="keyword">final</span> Set&lt;Integer&gt; replicas;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>由此可见，在 LeaderAndIsr 请求中，会包含一个 Partition 的以下信息：</p>
<ol>
<li>当前 Controller 的 epoch（Broker 收到这个请求后，如果发现是过期的 Controller 请求，就会拒绝这个请求）；</li>
<li>leader，Partition 的 leader 信息；</li>
<li>leader epoch，Partition leader epoch 信息（leader、isr、AR 变动时，这个 epoch 都会加1）；</li>
<li>isr 列表；</li>
<li>zkVersion，；</li>
<li>AR，所有的 replica 列表。</li>
</ol>
<h3 id="LeaderAndIsr-请求处理"><a href="#LeaderAndIsr-请求处理" class="headerlink" title="LeaderAndIsr 请求处理"></a>LeaderAndIsr 请求处理</h3><h3 id="处理整体流程"><a href="#处理整体流程" class="headerlink" title="处理整体流程"></a>处理整体流程</h3><p>LeaderAndIsr 请求可谓是包含了一个 Partition 的所有 metadata 信息，Server 在接收到 Controller 发送的这个请求后，其处理的逻辑如下：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//KafkaApis</span></div><div class="line"><span class="comment">//note: LeaderAndIsr 请求的处理</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">handleLeaderAndIsrRequest</span></span>(request: <span class="type">RequestChannel</span>.<span class="type">Request</span>) &#123;</div><div class="line">  <span class="comment">// ensureTopicExists is only for client facing requests</span></div><div class="line">  <span class="comment">// We can't have the ensureTopicExists check here since the controller sends it as an advisory to all brokers so they</span></div><div class="line">  <span class="comment">// stop serving data to clients for the topic being deleted</span></div><div class="line">  <span class="keyword">val</span> correlationId = request.header.correlationId</div><div class="line">  <span class="keyword">val</span> leaderAndIsrRequest = request.body.asInstanceOf[<span class="type">LeaderAndIsrRequest</span>]</div><div class="line"></div><div class="line">  <span class="keyword">try</span> &#123;</div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">onLeadershipChange</span></span>(updatedLeaders: <span class="type">Iterable</span>[<span class="type">Partition</span>], updatedFollowers: <span class="type">Iterable</span>[<span class="type">Partition</span>]) &#123;</div><div class="line">      <span class="comment">// for each new leader or follower, call coordinator to handle consumer group migration.</span></div><div class="line">      <span class="comment">// this callback is invoked under the replica state change lock to ensure proper order of</span></div><div class="line">      <span class="comment">// leadership changes</span></div><div class="line">      <span class="comment">//note: __consumer_offset 是 leader 的情况，读取相应 group 的 offset 信息</span></div><div class="line">      updatedLeaders.foreach &#123; partition =&gt;</div><div class="line">        <span class="keyword">if</span> (partition.topic == <span class="type">Topic</span>.<span class="type">GroupMetadataTopicName</span>)</div><div class="line">          coordinator.handleGroupImmigration(partition.partitionId)</div><div class="line">      &#125;</div><div class="line">      <span class="comment">//note: __consumer_offset 是 follower 的情况，如果之前是 leader，那么移除这个 partition 对应的信息</span></div><div class="line">      updatedFollowers.foreach &#123; partition =&gt;</div><div class="line">        <span class="keyword">if</span> (partition.topic == <span class="type">Topic</span>.<span class="type">GroupMetadataTopicName</span>)</div><div class="line">          coordinator.handleGroupEmigration(partition.partitionId)</div><div class="line">      &#125;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="keyword">val</span> leaderAndIsrResponse =</div><div class="line">      <span class="keyword">if</span> (authorize(request.session, <span class="type">ClusterAction</span>, <span class="type">Resource</span>.<span class="type">ClusterResource</span>)) &#123;<span class="comment">//note: 有权限的情况下</span></div><div class="line">        <span class="comment">//note: replicaManager 进行相应的处理</span></div><div class="line">        <span class="keyword">val</span> result = replicaManager.becomeLeaderOrFollower(correlationId, leaderAndIsrRequest, metadataCache, onLeadershipChange)</div><div class="line">        <span class="keyword">new</span> <span class="type">LeaderAndIsrResponse</span>(result.errorCode, result.responseMap.mapValues(<span class="keyword">new</span> <span class="type">JShort</span>(_)).asJava)</div><div class="line">      &#125; <span class="keyword">else</span> &#123;</div><div class="line">        <span class="keyword">val</span> result = leaderAndIsrRequest.partitionStates.asScala.keys.map((_, <span class="keyword">new</span> <span class="type">JShort</span>(<span class="type">Errors</span>.<span class="type">CLUSTER_AUTHORIZATION_FAILED</span>.code))).toMap</div><div class="line">        <span class="keyword">new</span> <span class="type">LeaderAndIsrResponse</span>(<span class="type">Errors</span>.<span class="type">CLUSTER_AUTHORIZATION_FAILED</span>.code, result.asJava)</div><div class="line">      &#125;</div><div class="line"></div><div class="line">    requestChannel.sendResponse(<span class="keyword">new</span> <span class="type">Response</span>(request, leaderAndIsrResponse))</div><div class="line">  &#125; <span class="keyword">catch</span> &#123;</div><div class="line">    <span class="keyword">case</span> e: <span class="type">KafkaStorageException</span> =&gt;</div><div class="line">      fatal(<span class="string">"Disk error during leadership change."</span>, e)</div><div class="line">      <span class="type">Runtime</span>.getRuntime.halt(<span class="number">1</span>)</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>上述处理逻辑分为以下两步：</p>
<ol>
<li>ReplicaManager 调用 <code>becomeLeaderOrFollower()</code> 方法对这个请求进行相应的处理；</li>
<li>如果请求中包含 <code>__consumer_offset</code> 的 Partition（对应两种情况：之前是 fllower 现在变成了 leader、之前是 leader 现在变成了 follower），那么还需要调用这个方法中定义的 <code>onLeadershipChange()</code> 方法进行相应的处理。</li>
</ol>
<p><code>becomeLeaderOrFollower()</code>  的整体处理流程如下：</p>
<p><img src="/images/kafka/leader-and-isr.png" alt="LeaderAndIsr 请求的处理"></p>
<h3 id="becomeLeaderOrFollower"><a href="#becomeLeaderOrFollower" class="headerlink" title="becomeLeaderOrFollower"></a>becomeLeaderOrFollower</h3><p>这里先看下 ReplicaManager 的 <code>becomeLeaderOrFollower()</code> 方法，它是 LeaderAndIsr 请求处理的实现，如下所示：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//note: 处理 LeaderAndIsr 请求</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">becomeLeaderOrFollower</span></span>(correlationId: <span class="type">Int</span>,leaderAndISRRequest: <span class="type">LeaderAndIsrRequest</span>,</div><div class="line">                           metadataCache: <span class="type">MetadataCache</span>,</div><div class="line">                           onLeadershipChange: (<span class="type">Iterable</span>[<span class="type">Partition</span>], <span class="type">Iterable</span>[<span class="type">Partition</span>]) =&gt; <span class="type">Unit</span>): <span class="type">BecomeLeaderOrFollowerResult</span> = &#123;</div><div class="line">  leaderAndISRRequest.partitionStates.asScala.foreach &#123; <span class="keyword">case</span> (topicPartition, stateInfo) =&gt;</div><div class="line">    stateChangeLogger.trace(<span class="string">"Broker %d received LeaderAndIsr request %s correlation id %d from controller %d epoch %d for partition [%s,%d]"</span></div><div class="line">                              .format(localBrokerId, stateInfo, correlationId,</div><div class="line">                                      leaderAndISRRequest.controllerId, leaderAndISRRequest.controllerEpoch, topicPartition.topic, topicPartition.partition))</div><div class="line">  &#125;</div><div class="line">  replicaStateChangeLock synchronized &#123;</div><div class="line">    <span class="keyword">val</span> responseMap = <span class="keyword">new</span> mutable.<span class="type">HashMap</span>[<span class="type">TopicPartition</span>, <span class="type">Short</span>]</div><div class="line">    <span class="comment">//note: 1. 验证 controller 的 epoch，如果是来自旧的 controller，就拒绝这个请求</span></div><div class="line">    <span class="keyword">if</span> (leaderAndISRRequest.controllerEpoch &lt; controllerEpoch) &#123;</div><div class="line">      stateChangeLogger.warn((<span class="string">"Broker %d ignoring LeaderAndIsr request from controller %d with correlation id %d since "</span> +</div><div class="line">        <span class="string">"its controller epoch %d is old. Latest known controller epoch is %d"</span>).format(localBrokerId, leaderAndISRRequest.controllerId,</div><div class="line">        correlationId, leaderAndISRRequest.controllerEpoch, controllerEpoch))</div><div class="line">      <span class="type">BecomeLeaderOrFollowerResult</span>(responseMap, <span class="type">Errors</span>.<span class="type">STALE_CONTROLLER_EPOCH</span>.code)</div><div class="line">    &#125; <span class="keyword">else</span> &#123; <span class="comment">//note: 当前 controller 的请求</span></div><div class="line">      <span class="keyword">val</span> controllerId = leaderAndISRRequest.controllerId</div><div class="line">      controllerEpoch = leaderAndISRRequest.controllerEpoch</div><div class="line"></div><div class="line">      <span class="comment">// First check partition's leader epoch</span></div><div class="line">      <span class="comment">//note: 2. 检查 leader epoch，得到一个 partitionState map，epoch 满足条件并且有副本在本地的集合</span></div><div class="line">      <span class="keyword">val</span> partitionState = <span class="keyword">new</span> mutable.<span class="type">HashMap</span>[<span class="type">Partition</span>, <span class="type">PartitionState</span>]()</div><div class="line">      leaderAndISRRequest.partitionStates.asScala.foreach &#123; <span class="keyword">case</span> (topicPartition, stateInfo) =&gt;</div><div class="line">        <span class="keyword">val</span> partition = getOrCreatePartition(topicPartition) <span class="comment">//note: 对应的 tp 如果没有 Partition 实例的话,就新建一个</span></div><div class="line">        <span class="keyword">val</span> partitionLeaderEpoch = partition.getLeaderEpoch <span class="comment">//note: 更新 leader epoch</span></div><div class="line">        <span class="comment">// If the leader epoch is valid record the epoch of the controller that made the leadership decision.</span></div><div class="line">        <span class="comment">// This is useful while updating the isr to maintain the decision maker controller's epoch in the zookeeper path</span></div><div class="line">        <span class="keyword">if</span> (partitionLeaderEpoch &lt; stateInfo.leaderEpoch) &#123;</div><div class="line">          <span class="keyword">if</span>(stateInfo.replicas.contains(localBrokerId))</div><div class="line">            partitionState.put(partition, stateInfo)  <span class="comment">//note: 更新 replica 的 stateInfo</span></div><div class="line">          <span class="keyword">else</span> &#123;</div><div class="line">            stateChangeLogger.warn((<span class="string">"Broker %d ignoring LeaderAndIsr request from controller %d with correlation id %d "</span> +</div><div class="line">              <span class="string">"epoch %d for partition [%s,%d] as itself is not in assigned replica list %s"</span>)</div><div class="line">              .format(localBrokerId, controllerId, correlationId, leaderAndISRRequest.controllerEpoch,</div><div class="line">                topicPartition.topic, topicPartition.partition, stateInfo.replicas.asScala.mkString(<span class="string">","</span>)))</div><div class="line">            responseMap.put(topicPartition, <span class="type">Errors</span>.<span class="type">UNKNOWN_TOPIC_OR_PARTITION</span>.code)</div><div class="line">          &#125;</div><div class="line">        &#125; <span class="keyword">else</span> &#123;  <span class="comment">//note: 忽略这个请求，因为请求的 leader epoch 小于缓存的 epoch</span></div><div class="line">          <span class="comment">// Otherwise record the error code in response</span></div><div class="line">          stateChangeLogger.warn((<span class="string">"Broker %d ignoring LeaderAndIsr request from controller %d with correlation id %d "</span> +</div><div class="line">            <span class="string">"epoch %d for partition [%s,%d] since its associated leader epoch %d is not higher than the current leader epoch %d"</span>)</div><div class="line">            .format(localBrokerId, controllerId, correlationId, leaderAndISRRequest.controllerEpoch,</div><div class="line">              topicPartition.topic, topicPartition.partition, stateInfo.leaderEpoch, partitionLeaderEpoch))</div><div class="line">          responseMap.put(topicPartition, <span class="type">Errors</span>.<span class="type">STALE_CONTROLLER_EPOCH</span>.code)</div><div class="line">        &#125;</div><div class="line">      &#125;</div><div class="line"></div><div class="line">      <span class="comment">//note: 3. 过滤出本地副本设置为 leader 的 Partition 列表</span></div><div class="line">      <span class="keyword">val</span> partitionsTobeLeader = partitionState.filter &#123; <span class="keyword">case</span> (_, stateInfo) =&gt;</div><div class="line">        stateInfo.leader == localBrokerId</div><div class="line">      &#125;</div><div class="line">      <span class="comment">//note: 4. 过滤出本地副本设置为 follower 的 Partition 列表</span></div><div class="line">      <span class="keyword">val</span> partitionsToBeFollower = partitionState -- partitionsTobeLeader.keys <span class="comment">//note: 这些 tp 设置为了 follower</span></div><div class="line"></div><div class="line">      <span class="comment">//note: 5. 将为 leader 的副本设置为 leader</span></div><div class="line">      <span class="keyword">val</span> partitionsBecomeLeader = <span class="keyword">if</span> (partitionsTobeLeader.nonEmpty)</div><div class="line">        makeLeaders(controllerId, controllerEpoch, partitionsTobeLeader, correlationId, responseMap)</div><div class="line">      <span class="keyword">else</span></div><div class="line">        <span class="type">Set</span>.empty[<span class="type">Partition</span>]</div><div class="line"></div><div class="line">      <span class="comment">//note: 6. 将为 follower 的副本设置为 follower</span></div><div class="line">      <span class="keyword">val</span> partitionsBecomeFollower = <span class="keyword">if</span> (partitionsToBeFollower.nonEmpty)</div><div class="line">        makeFollowers(controllerId, controllerEpoch, partitionsToBeFollower, correlationId, responseMap, metadataCache)</div><div class="line">      <span class="keyword">else</span></div><div class="line">        <span class="type">Set</span>.empty[<span class="type">Partition</span>]</div><div class="line"></div><div class="line">      <span class="comment">//note: 7. 如果 hw checkpoint 的线程没有初始化，这里需要进行一次初始化</span></div><div class="line">      <span class="comment">// we initialize highwatermark thread after the first leaderisrrequest. This ensures that all the partitions</span></div><div class="line">      <span class="comment">// have been completely populated before starting the checkpointing there by avoiding weird race conditions</span></div><div class="line">      <span class="keyword">if</span> (!hwThreadInitialized) &#123;</div><div class="line">        startHighWaterMarksCheckPointThread()</div><div class="line">        hwThreadInitialized = <span class="literal">true</span></div><div class="line">      &#125;</div><div class="line">      <span class="comment">//note: 8. 检查 replica fetcher 是否需要关闭（有些副本需要关闭因为可能从 follower 变为 leader）</span></div><div class="line">      replicaFetcherManager.shutdownIdleFetcherThreads()</div><div class="line"></div><div class="line">      <span class="comment">//note: 9. 检查是否 __consumer_offset 的 Partition 的 leaderAndIsr 信息，有的话进行相应的操作</span></div><div class="line">      onLeadershipChange(partitionsBecomeLeader, partitionsBecomeFollower)</div><div class="line">      <span class="type">BecomeLeaderOrFollowerResult</span>(responseMap, <span class="type">Errors</span>.<span class="type">NONE</span>.code)</div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>上述实现，其处理逻辑总结如下：</p>
<ol>
<li>检查 Controller 的 epoch，如果是来自旧的 Controller，那么就拒绝这个请求；</li>
<li>获取请求的 Partition 列表的 PartitionState 信息，在遍历的过程中，会进行一个检查，如果 leader epoch 小于缓存中的 epoch 值，那么就过滤掉这个 Partition 信息，如果这个 Partition 在本地不存在，那么会初始化这个 Partition 的对象（这时候并不会初始化本地副本）；</li>
<li>获取出本地副本为 leader 的 Partition 列表（partitionsTobeLeader）；</li>
<li>获取出本地副本为 follower 的 Partition 列表（partitionsToBeFollower）；</li>
<li>调用 <code>makeLeaders()</code> 方法将 leader 的副本设置为 leader；</li>
<li>调用 <code>makeFollowers()</code> 方法将 leader 的副本设置为 follower；</li>
<li>检查 HW checkpoint 的线程是否初始化，如果没有，这里需要进行一次初始化；</li>
<li>检查 ReplicaFetcherManager 是否有线程需要关闭（如果这个线程上没有分配要拉取的 Topic Partition，那么在这里这个线程就会被关闭，下次需要时会再次启动）；</li>
<li>检查是否有 <code>__consumer_offset</code> Partition 的 leaderAndIsr 信息，有的话进行相应的操作。</li>
</ol>
<p>这其中，比较复杂的部分是第 5、6、9步，也前面图中标出的 1、2、4步，文章下面接着分析这三部分。</p>
<h3 id="makeLeaders"><a href="#makeLeaders" class="headerlink" title="makeLeaders"></a>makeLeaders</h3><p>ReplicaManager 的 <code>makeLeaders()</code> 的作用是将指定的这批 Partition 列表设置为 Leader，并返回是新 leader 对应的 Partition 列表（之前不是 leader，现在选举为了 leader），其实实现如下：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//note: 选举当前副本作为 partition 的 leader，处理过程：</span></div><div class="line"><span class="comment">//note: 1. 停止这些 partition 的 副本同步请求；</span></div><div class="line"><span class="comment">//note: 2. 更新缓存中的 partition metadata；</span></div><div class="line"><span class="comment">//note: 3. 将这些 partition 添加到 leader partition 集合中。</span></div><div class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">makeLeaders</span></span>(controllerId: <span class="type">Int</span>,</div><div class="line">                        epoch: <span class="type">Int</span>,</div><div class="line">                        partitionState: <span class="type">Map</span>[<span class="type">Partition</span>, <span class="type">PartitionState</span>],</div><div class="line">                        correlationId: <span class="type">Int</span>,</div><div class="line">                        responseMap: mutable.<span class="type">Map</span>[<span class="type">TopicPartition</span>, <span class="type">Short</span>]): <span class="type">Set</span>[<span class="type">Partition</span>] = &#123;</div><div class="line">  partitionState.keys.foreach &#123; partition =&gt;</div><div class="line">    stateChangeLogger.trace((<span class="string">"Broker %d handling LeaderAndIsr request correlationId %d from controller %d epoch %d "</span> +</div><div class="line">      <span class="string">"starting the become-leader transition for partition %s"</span>)</div><div class="line">      .format(localBrokerId, correlationId, controllerId, epoch, partition.topicPartition))</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  <span class="keyword">for</span> (partition &lt;- partitionState.keys)</div><div class="line">    responseMap.put(partition.topicPartition, <span class="type">Errors</span>.<span class="type">NONE</span>.code)</div><div class="line"></div><div class="line">  <span class="keyword">val</span> partitionsToMakeLeaders: mutable.<span class="type">Set</span>[<span class="type">Partition</span>] = mutable.<span class="type">Set</span>()</div><div class="line"></div><div class="line">  <span class="keyword">try</span> &#123;</div><div class="line">    <span class="comment">// First stop fetchers for all the partitions</span></div><div class="line">    <span class="comment">//note: 1. 停止这些副本同步请求</span></div><div class="line">    replicaFetcherManager.removeFetcherForPartitions(partitionState.keySet.map(_.topicPartition))</div><div class="line">    <span class="comment">// Update the partition information to be the leader</span></div><div class="line">    <span class="comment">//note: 2. 更新这些 partition 的信息（这些 partition 成为 leader 了）</span></div><div class="line">    partitionState.foreach&#123; <span class="keyword">case</span> (partition, partitionStateInfo) =&gt;</div><div class="line">      <span class="comment">//note: 在 partition 对象将本地副本设置为 leader</span></div><div class="line">      <span class="keyword">if</span> (partition.makeLeader(controllerId, partitionStateInfo, correlationId))</div><div class="line">        partitionsToMakeLeaders += partition <span class="comment">//note: 成功选为 leader 的 partition 集合</span></div><div class="line">      <span class="keyword">else</span></div><div class="line">        <span class="comment">//note: 本地 replica 已经是 leader replica，可能是接收了重试的请求</span></div><div class="line">        stateChangeLogger.info((<span class="string">"Broker %d skipped the become-leader state change after marking its partition as leader with correlation id %d from "</span> +</div><div class="line">          <span class="string">"controller %d epoch %d for partition %s since it is already the leader for the partition."</span>)</div><div class="line">          .format(localBrokerId, correlationId, controllerId, epoch, partition.topicPartition))</div><div class="line">    &#125;</div><div class="line">    partitionsToMakeLeaders.foreach &#123; partition =&gt;</div><div class="line">      stateChangeLogger.trace((<span class="string">"Broker %d stopped fetchers as part of become-leader request from controller "</span> +</div><div class="line">        <span class="string">"%d epoch %d with correlation id %d for partition %s"</span>)</div><div class="line">        .format(localBrokerId, controllerId, epoch, correlationId, partition.topicPartition))</div><div class="line">    &#125;</div><div class="line">  &#125; <span class="keyword">catch</span> &#123;</div><div class="line">    <span class="keyword">case</span> e: <span class="type">Throwable</span> =&gt;</div><div class="line">      partitionState.keys.foreach &#123; partition =&gt;</div><div class="line">        <span class="keyword">val</span> errorMsg = (<span class="string">"Error on broker %d while processing LeaderAndIsr request correlationId %d received from controller %d"</span> +</div><div class="line">          <span class="string">" epoch %d for partition %s"</span>).format(localBrokerId, correlationId, controllerId, epoch, partition.topicPartition)</div><div class="line">        stateChangeLogger.error(errorMsg, e)</div><div class="line">      &#125;</div><div class="line">      <span class="comment">// Re-throw the exception for it to be caught in KafkaApis</span></div><div class="line">      <span class="keyword">throw</span> e</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  <span class="comment">//note: LeaderAndIsr 请求处理完成</span></div><div class="line">  partitionState.keys.foreach &#123; partition =&gt;</div><div class="line">    stateChangeLogger.trace((<span class="string">"Broker %d completed LeaderAndIsr request correlationId %d from controller %d epoch %d "</span> +</div><div class="line">      <span class="string">"for the become-leader transition for partition %s"</span>)</div><div class="line">      .format(localBrokerId, correlationId, controllerId, epoch, partition.topicPartition))</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  partitionsToMakeLeaders</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>实现逻辑如下：</p>
<ol>
<li>调用 ReplicaFetcherManager 的 <code>removeFetcherForPartitions()</code> 方法移除这些 Partition 的副本同步线程；</li>
<li>遍历这些 Partition，通过 Partition 的 <code>makeLeader()</code> 方法将这个 Partition 设置为 Leader，如果设置成功（如果 leader 没有变化，证明这个 Partition 之前就是 leader，这个方法返回的是 false，这种情况下不会更新到缓存中），那么将 leader 信息更新到缓存中。</li>
</ol>
<p>下面来看下在 Partition 中是如何真正初始化一个 Partition 的 leader？其实现如下：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//note: 将本地副本设置为 leader, 如果 leader 不变,向 ReplicaManager 返回 false</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">makeLeader</span></span>(controllerId: <span class="type">Int</span>, partitionStateInfo: <span class="type">PartitionState</span>, correlationId: <span class="type">Int</span>): <span class="type">Boolean</span> = &#123;</div><div class="line">  <span class="keyword">val</span> (leaderHWIncremented, isNewLeader) = inWriteLock(leaderIsrUpdateLock) &#123;</div><div class="line">    <span class="keyword">val</span> allReplicas = partitionStateInfo.replicas.asScala.map(_.toInt)</div><div class="line">    <span class="comment">// record the epoch of the controller that made the leadership decision. This is useful while updating the isr</span></div><div class="line">    <span class="comment">// to maintain the decision maker controller's epoch in the zookeeper path</span></div><div class="line">    controllerEpoch = partitionStateInfo.controllerEpoch</div><div class="line">    <span class="comment">// add replicas that are new</span></div><div class="line">    <span class="comment">//note: 为了新的 replica 创建副本实例</span></div><div class="line">    allReplicas.foreach(replica =&gt; getOrCreateReplica(replica))</div><div class="line">    <span class="comment">//note: 获取新的 isr 列表</span></div><div class="line">    <span class="keyword">val</span> newInSyncReplicas = partitionStateInfo.isr.asScala.map(r =&gt; getOrCreateReplica(r)).toSet</div><div class="line">    <span class="comment">// remove assigned replicas that have been removed by the controller</span></div><div class="line">    <span class="comment">//note: 将已经在不在 AR 中的副本移除</span></div><div class="line">    (assignedReplicas.map(_.brokerId) -- allReplicas).foreach(removeReplica)</div><div class="line">    inSyncReplicas = newInSyncReplicas</div><div class="line">    leaderEpoch = partitionStateInfo.leaderEpoch</div><div class="line">    zkVersion = partitionStateInfo.zkVersion</div><div class="line">    <span class="comment">//note: 判断是否是新的 leader</span></div><div class="line">    <span class="keyword">val</span> isNewLeader =</div><div class="line">      <span class="keyword">if</span> (leaderReplicaIdOpt.isDefined &amp;&amp; leaderReplicaIdOpt.get == localBrokerId) &#123;<span class="comment">//note: leader 没有更新</span></div><div class="line">        <span class="literal">false</span></div><div class="line">      &#125; <span class="keyword">else</span> &#123;</div><div class="line">        leaderReplicaIdOpt = <span class="type">Some</span>(localBrokerId)</div><div class="line">        <span class="literal">true</span></div><div class="line">      &#125;</div><div class="line">    <span class="keyword">val</span> leaderReplica = getReplica().get <span class="comment">//note: 获取在当前上的副本,也就是 leader replica</span></div><div class="line">    <span class="keyword">val</span> curLeaderLogEndOffset = leaderReplica.logEndOffset.messageOffset <span class="comment">//note: 获取 leader replica 的 the end offset</span></div><div class="line">    <span class="keyword">val</span> curTimeMs = time.milliseconds</div><div class="line">    <span class="comment">// initialize lastCaughtUpTime of replicas as well as their lastFetchTimeMs and lastFetchLeaderLogEndOffset.</span></div><div class="line">    (assignedReplicas - leaderReplica).foreach &#123; replica =&gt; <span class="comment">//note: 对于 isr 中的 replica,更新 LastCaughtUpTime</span></div><div class="line">      <span class="keyword">val</span> lastCaughtUpTimeMs = <span class="keyword">if</span> (inSyncReplicas.contains(replica)) curTimeMs <span class="keyword">else</span> <span class="number">0</span>L</div><div class="line">      replica.resetLastCaughtUpTime(curLeaderLogEndOffset, curTimeMs, lastCaughtUpTimeMs)</div><div class="line">    &#125;</div><div class="line">    <span class="comment">// we may need to increment high watermark since ISR could be down to 1</span></div><div class="line">    <span class="keyword">if</span> (isNewLeader) &#123;  <span class="comment">//note: 如果是新的 leader,那么需要</span></div><div class="line">      <span class="comment">// construct the high watermark metadata for the new leader replica</span></div><div class="line">      <span class="comment">//note: 为新的 leader 构造 replica 的 HW metadata</span></div><div class="line">      leaderReplica.convertHWToLocalOffsetMetadata()</div><div class="line">      <span class="comment">// reset log end offset for remote replicas</span></div><div class="line">      <span class="comment">//note: 更新远程副本的副本同步信息（设置为 unKnown）</span></div><div class="line">      assignedReplicas.filter(_.brokerId != localBrokerId).foreach(_.updateLogReadResult(<span class="type">LogReadResult</span>.<span class="type">UnknownLogReadResult</span>))</div><div class="line">    &#125;</div><div class="line">    <span class="comment">//note: 如果满足更新 isr 的条件,就更新 HW 信息</span></div><div class="line">    (maybeIncrementLeaderHW(leaderReplica), isNewLeader)</div><div class="line">  &#125;</div><div class="line">  <span class="comment">// some delayed operations may be unblocked after HW changed</span></div><div class="line">  <span class="keyword">if</span> (leaderHWIncremented) <span class="comment">//note: HW 更新的情况下</span></div><div class="line">    tryCompleteDelayedRequests()</div><div class="line">  isNewLeader</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>简单总结一下上述的实现：</p>
<ol>
<li>首先更新这个 Partition 的相应信息，包括：isr、AR、leader epoch、zkVersion 等，并为每个副本创建一个 Replica 对象（如果不存在该对象的情况下才会创建，只有本地副本才会初始化相应的日志对象）；</li>
<li>如果这个 Partition 的 leader 本来就是本地副本，那么返回的结果设置为 false，证明这个 leader 并不是新的 leader；</li>
<li>对于 isr 中的所有 Replica，更新 LastCaughtUpTime 值，即最近一次赶得上 leader 的时间；</li>
<li>如果是新的 leader，那么为 leader 初始化相应的 HighWatermarkMetadata 对象，并将所有副本的副本同步信息更新为 UnknownLogReadResult；</li>
<li>检查一下是否需要更新 HW 值。</li>
</ol>
<p>如果这个本地副本是新选举的 leader，那么它所做的事情就是初始化 Leader 应该记录的相关信息。</p>
<h3 id="makeFollowers"><a href="#makeFollowers" class="headerlink" title="makeFollowers"></a>makeFollowers</h3><p>ReplicaManager 的 <code>makeFollowers()</code> 方法，是将哪些 Partition 设置为 Follower，返回的结果是那些新的 follower 对应的 Partition 列表（之前是 leader，现在变成了 follower），其实现如下：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div><div class="line">113</div><div class="line">114</div><div class="line">115</div><div class="line">116</div><div class="line">117</div><div class="line">118</div><div class="line">119</div><div class="line">120</div><div class="line">121</div><div class="line">122</div><div class="line">123</div><div class="line">124</div><div class="line">125</div><div class="line">126</div><div class="line">127</div><div class="line">128</div><div class="line">129</div><div class="line">130</div><div class="line">131</div><div class="line">132</div><div class="line">133</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">makeFollowers</span></span>(controllerId: <span class="type">Int</span>,</div><div class="line">                          epoch: <span class="type">Int</span>,</div><div class="line">                          partitionState: <span class="type">Map</span>[<span class="type">Partition</span>, <span class="type">PartitionState</span>],</div><div class="line">                          correlationId: <span class="type">Int</span>,</div><div class="line">                          responseMap: mutable.<span class="type">Map</span>[<span class="type">TopicPartition</span>, <span class="type">Short</span>],</div><div class="line">                          metadataCache: <span class="type">MetadataCache</span>) : <span class="type">Set</span>[<span class="type">Partition</span>] = &#123;</div><div class="line">  partitionState.keys.foreach &#123; partition =&gt;</div><div class="line">    stateChangeLogger.trace((<span class="string">"Broker %d handling LeaderAndIsr request correlationId %d from controller %d epoch %d "</span> +</div><div class="line">      <span class="string">"starting the become-follower transition for partition %s"</span>)</div><div class="line">      .format(localBrokerId, correlationId, controllerId, epoch, partition.topicPartition))</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  <span class="keyword">for</span> (partition &lt;- partitionState.keys)</div><div class="line">    responseMap.put(partition.topicPartition, <span class="type">Errors</span>.<span class="type">NONE</span>.code)</div><div class="line"></div><div class="line">  <span class="comment">//note: 1. 统计 follower 的集合</span></div><div class="line">  <span class="keyword">val</span> partitionsToMakeFollower: mutable.<span class="type">Set</span>[<span class="type">Partition</span>] = mutable.<span class="type">Set</span>()</div><div class="line"></div><div class="line">  <span class="keyword">try</span> &#123;</div><div class="line"></div><div class="line">    <span class="comment">// <span class="doctag">TODO:</span> Delete leaders from LeaderAndIsrRequest</span></div><div class="line">    partitionState.foreach&#123; <span class="keyword">case</span> (partition, partitionStateInfo) =&gt;</div><div class="line">      <span class="keyword">val</span> newLeaderBrokerId = partitionStateInfo.leader</div><div class="line">      metadataCache.getAliveBrokers.find(_.id == newLeaderBrokerId) <span class="keyword">match</span> &#123; <span class="comment">//note: leader 是可用的 Partition</span></div><div class="line">        <span class="comment">// Only change partition state when the leader is available</span></div><div class="line">        <span class="keyword">case</span> <span class="type">Some</span>(_) =&gt; <span class="comment">//note: 2. 将 Partition 的本地副本设置为 follower</span></div><div class="line">          <span class="keyword">if</span> (partition.makeFollower(controllerId, partitionStateInfo, correlationId))</div><div class="line">            partitionsToMakeFollower += partition</div><div class="line">          <span class="keyword">else</span> <span class="comment">//note: 这个 partition 的本地副本已经是 follower 了</span></div><div class="line">            stateChangeLogger.info((<span class="string">"Broker %d skipped the become-follower state change after marking its partition as follower with correlation id %d from "</span> +</div><div class="line">              <span class="string">"controller %d epoch %d for partition %s since the new leader %d is the same as the old leader"</span>)</div><div class="line">              .format(localBrokerId, correlationId, controllerId, partitionStateInfo.controllerEpoch,</div><div class="line">              partition.topicPartition, newLeaderBrokerId))</div><div class="line">        <span class="keyword">case</span> <span class="type">None</span> =&gt;</div><div class="line">          <span class="comment">// The leader broker should always be present in the metadata cache.</span></div><div class="line">          <span class="comment">// If not, we should record the error message and abort the transition process for this partition</span></div><div class="line">          stateChangeLogger.error((<span class="string">"Broker %d received LeaderAndIsrRequest with correlation id %d from controller"</span> +</div><div class="line">            <span class="string">" %d epoch %d for partition %s but cannot become follower since the new leader %d is unavailable."</span>)</div><div class="line">            .format(localBrokerId, correlationId, controllerId, partitionStateInfo.controllerEpoch,</div><div class="line">            partition.topicPartition, newLeaderBrokerId))</div><div class="line">          <span class="comment">// Create the local replica even if the leader is unavailable. This is required to ensure that we include</span></div><div class="line">          <span class="comment">// the partition's high watermark in the checkpoint file (see KAFKA-1647)</span></div><div class="line">          partition.getOrCreateReplica()</div><div class="line">      &#125;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="comment">//note: 3. 移除这些 Partition 的副本同步线程,这样在 MakeFollower 期间,这些 Partition 就不会进行副本同步了</span></div><div class="line">    replicaFetcherManager.removeFetcherForPartitions(partitionsToMakeFollower.map(_.topicPartition))</div><div class="line">    partitionsToMakeFollower.foreach &#123; partition =&gt;</div><div class="line">      stateChangeLogger.trace((<span class="string">"Broker %d stopped fetchers as part of become-follower request from controller "</span> +</div><div class="line">        <span class="string">"%d epoch %d with correlation id %d for partition %s"</span>)</div><div class="line">        .format(localBrokerId, controllerId, epoch, correlationId, partition.topicPartition))</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="comment">//note: 4. Truncate the partition logs to the specified offsets and checkpoint the recovery point to this offset</span></div><div class="line">    logManager.truncateTo(partitionsToMakeFollower.map &#123; partition =&gt;</div><div class="line">      (partition.topicPartition, partition.getOrCreateReplica().highWatermark.messageOffset)</div><div class="line">    &#125;.toMap)</div><div class="line">    <span class="comment">//note: 5. 完成那些延迟请求的处理（Produce 和 FetchConsumer 请求）</span></div><div class="line">    partitionsToMakeFollower.foreach &#123; partition =&gt;</div><div class="line">      <span class="keyword">val</span> topicPartitionOperationKey = <span class="keyword">new</span> <span class="type">TopicPartitionOperationKey</span>(partition.topicPartition)</div><div class="line">      tryCompleteDelayedProduce(topicPartitionOperationKey)</div><div class="line">      tryCompleteDelayedFetch(topicPartitionOperationKey)</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    partitionsToMakeFollower.foreach &#123; partition =&gt;</div><div class="line">      stateChangeLogger.trace((<span class="string">"Broker %d truncated logs and checkpointed recovery boundaries for partition %s as part of "</span> +</div><div class="line">        <span class="string">"become-follower request with correlation id %d from controller %d epoch %d"</span>).format(localBrokerId,</div><div class="line">        partition.topicPartition, correlationId, controllerId, epoch))</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="keyword">if</span> (isShuttingDown.get()) &#123;</div><div class="line">      partitionsToMakeFollower.foreach &#123; partition =&gt;</div><div class="line">        stateChangeLogger.trace((<span class="string">"Broker %d skipped the adding-fetcher step of the become-follower state change with correlation id %d from "</span> +</div><div class="line">          <span class="string">"controller %d epoch %d for partition %s since it is shutting down"</span>).format(localBrokerId, correlationId,</div><div class="line">          controllerId, epoch, partition.topicPartition))</div><div class="line">      &#125;</div><div class="line">    &#125;</div><div class="line">    <span class="keyword">else</span> &#123;</div><div class="line">      <span class="comment">// we do not need to check if the leader exists again since this has been done at the beginning of this process</span></div><div class="line">      <span class="comment">//note: 6. 启动副本同步线程</span></div><div class="line">      <span class="keyword">val</span> partitionsToMakeFollowerWithLeaderAndOffset = partitionsToMakeFollower.map(partition =&gt;</div><div class="line">        partition.topicPartition -&gt; <span class="type">BrokerAndInitialOffset</span>(</div><div class="line">          metadataCache.getAliveBrokers.find(_.id == partition.leaderReplicaIdOpt.get).get.getBrokerEndPoint(config.interBrokerListenerName),</div><div class="line">          partition.getReplica().get.logEndOffset.messageOffset)).toMap <span class="comment">//note: leader 信息+本地 replica 的 offset</span></div><div class="line">      replicaFetcherManager.addFetcherForPartitions(partitionsToMakeFollowerWithLeaderAndOffset)</div><div class="line"></div><div class="line">      partitionsToMakeFollower.foreach &#123; partition =&gt;</div><div class="line">        stateChangeLogger.trace((<span class="string">"Broker %d started fetcher to new leader as part of become-follower request from controller "</span> +</div><div class="line">          <span class="string">"%d epoch %d with correlation id %d for partition %s"</span>)</div><div class="line">          .format(localBrokerId, controllerId, epoch, correlationId, partition.topicPartition))</div><div class="line">      &#125;</div><div class="line">    &#125;</div><div class="line">  &#125; <span class="keyword">catch</span> &#123;</div><div class="line">    <span class="keyword">case</span> e: <span class="type">Throwable</span> =&gt;</div><div class="line">      <span class="keyword">val</span> errorMsg = (<span class="string">"Error on broker %d while processing LeaderAndIsr request with correlationId %d received from controller %d "</span> +</div><div class="line">        <span class="string">"epoch %d"</span>).format(localBrokerId, correlationId, controllerId, epoch)</div><div class="line">      stateChangeLogger.error(errorMsg, e)</div><div class="line">      <span class="comment">// Re-throw the exception for it to be caught in KafkaApis</span></div><div class="line">      <span class="keyword">throw</span> e</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  partitionState.keys.foreach &#123; partition =&gt;</div><div class="line">    stateChangeLogger.trace((<span class="string">"Broker %d completed LeaderAndIsr request correlationId %d from controller %d epoch %d "</span> +</div><div class="line">      <span class="string">"for the become-follower transition for partition %s"</span>)</div><div class="line">      .format(localBrokerId, correlationId, controllerId, epoch, partition.topicPartition))</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  partitionsToMakeFollower</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="comment">//note: 遍历所有的 partition 对象,检查其 isr 是否需要抖动</span></div><div class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">maybeShrinkIsr</span></span>(): <span class="type">Unit</span> = &#123;</div><div class="line">  trace(<span class="string">"Evaluating ISR list of partitions to see which replicas can be removed from the ISR"</span>)</div><div class="line">  allPartitions.values.foreach(partition =&gt; partition.maybeShrinkIsr(config.replicaLagTimeMaxMs))</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">updateFollowerLogReadResults</span></span>(replicaId: <span class="type">Int</span>, readResults: <span class="type">Seq</span>[(<span class="type">TopicPartition</span>, <span class="type">LogReadResult</span>)]) &#123;</div><div class="line">  debug(<span class="string">"Recording follower broker %d log read results: %s "</span>.format(replicaId, readResults))</div><div class="line">  readResults.foreach &#123; <span class="keyword">case</span> (topicPartition, readResult) =&gt;</div><div class="line">    getPartition(topicPartition) <span class="keyword">match</span> &#123;</div><div class="line">      <span class="keyword">case</span> <span class="type">Some</span>(partition) =&gt;</div><div class="line">        <span class="comment">//note: 更新副本的相关信息</span></div><div class="line">        partition.updateReplicaLogReadResult(replicaId, readResult)</div><div class="line"></div><div class="line">        <span class="comment">// for producer requests with ack &gt; 1, we need to check</span></div><div class="line">        <span class="comment">// if they can be unblocked after some follower's log end offsets have moved</span></div><div class="line">        tryCompleteDelayedProduce(<span class="keyword">new</span> <span class="type">TopicPartitionOperationKey</span>(topicPartition))</div><div class="line">      <span class="keyword">case</span> <span class="type">None</span> =&gt;</div><div class="line">        warn(<span class="string">"While recording the replica LEO, the partition %s hasn't been created."</span>.format(topicPartition))</div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>简单总结一下上述的逻辑过程：</p>
<ol>
<li>首先遍历所有的 Partition，获到那些 leader 可用、并且 Partition 可以成功设置为 Follower 的 Partition 列表（partitionsToMakeFollower）；</li>
<li>在上面遍历的过程中，会调用 Partition 的 <code>makeFollower()</code> 方法将 Partition 设置为 Follower（在这里，如果该 Partition 的本地副本不存在，会初始化相应的日志对象，如果该 Partition 的 leader 已经存在，并且没有变化，那么就返回 false，只有 leader 变化的 Partition，才会返回 true，才会加入到 partitionsToMakeFollower 集合中，这是因为 leader 没有变化的 Partition 是不需要变更副本同步线程的）；</li>
<li>移除这些 Partition 的副本同步线程，这样在 MakeFollower 期间，这些 Partition 就不会进行副本同步了；</li>
<li>Truncate the partition logs to the specified offsets and checkpoint the recovery point to this offset，因为前面已经移除了这个 Partition 的副本同步线程，所以这里在 checkpoint 后可以保证所有缓存的数据都可以刷新到磁盘；</li>
<li>完成那些延迟请求的处理（Produce 和 FetchConsumer 请求）；</li>
<li>启动相应的副本同步线程。</li>
</ol>
<p>到这里 LeaderAndIsr 请求的大部分处理已经完成，但是有一个比较特殊的 topic（<code>__consumer_offset</code>），如果这 Partition 的 leader 发生变化，是需要一些额外的处理。</p>
<h2 id="consumer-offset-leader-切换处理"><a href="#consumer-offset-leader-切换处理" class="headerlink" title="__consumer_offset leader 切换处理"></a><code>__consumer_offset</code> leader 切换处理</h2><p><code>__consumer_offset</code> 这个 Topic 如果发生了 leader 切换，GroupCoordinator 需要进行相应的处理，其处理过程如下：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">onLeadershipChange</span></span>(updatedLeaders: <span class="type">Iterable</span>[<span class="type">Partition</span>], updatedFollowers: <span class="type">Iterable</span>[<span class="type">Partition</span>]) &#123;</div><div class="line">  <span class="comment">// for each new leader or follower, call coordinator to handle consumer group migration.</span></div><div class="line">  <span class="comment">// this callback is invoked under the replica state change lock to ensure proper order of</span></div><div class="line">  <span class="comment">// leadership changes</span></div><div class="line">  <span class="comment">//note: __consumer_offset 是 leader 的情况，读取相应 group 的 offset 信息</span></div><div class="line">  updatedLeaders.foreach &#123; partition =&gt;</div><div class="line">    <span class="keyword">if</span> (partition.topic == <span class="type">Topic</span>.<span class="type">GroupMetadataTopicName</span>)</div><div class="line">      coordinator.handleGroupImmigration(partition.partitionId)</div><div class="line">  &#125;</div><div class="line">  <span class="comment">//note: __consumer_offset 是 follower 的情况，如果之前是 leader，那么移除这个 partition 对应的信息</span></div><div class="line">  updatedFollowers.foreach &#123; partition =&gt;</div><div class="line">    <span class="keyword">if</span> (partition.topic == <span class="type">Topic</span>.<span class="type">GroupMetadataTopicName</span>)</div><div class="line">      coordinator.handleGroupEmigration(partition.partitionId)</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h3 id="成为-leader"><a href="#成为-leader" class="headerlink" title="成为 leader"></a>成为 leader</h3><p>如果当前节点这个 <code>__consumer_offset</code> 有 Partition 成为 leader，GroupCoordinator 通过 <code>handleGroupImmigration()</code> 方法进行相应的处理。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//note: 加载这个 Partition 对应的 group offset 信息</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">handleGroupImmigration</span></span>(offsetTopicPartitionId: <span class="type">Int</span>) &#123;</div><div class="line">  groupManager.loadGroupsForPartition(offsetTopicPartitionId, onGroupLoaded)</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="comment">//note: 异步地加载这个 offset Partition 的信息</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">loadGroupsForPartition</span></span>(offsetsPartition: <span class="type">Int</span>, onGroupLoaded: <span class="type">GroupMetadata</span> =&gt; <span class="type">Unit</span>) &#123;</div><div class="line">  <span class="keyword">val</span> topicPartition = <span class="keyword">new</span> <span class="type">TopicPartition</span>(<span class="type">Topic</span>.<span class="type">GroupMetadataTopicName</span>, offsetsPartition)</div><div class="line"></div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">doLoadGroupsAndOffsets</span></span>() &#123;</div><div class="line">    info(<span class="string">s"Loading offsets and group metadata from <span class="subst">$topicPartition</span>"</span>)</div><div class="line"></div><div class="line">    <span class="comment">//note: 添加到  loadingPartitions 集合中</span></div><div class="line">    inLock(partitionLock) &#123;</div><div class="line">      <span class="keyword">if</span> (loadingPartitions.contains(offsetsPartition)) &#123;</div><div class="line">        info(<span class="string">s"Offset load from <span class="subst">$topicPartition</span> already in progress."</span>)</div><div class="line">        <span class="keyword">return</span></div><div class="line">      &#125; <span class="keyword">else</span> &#123;</div><div class="line">        loadingPartitions.add(offsetsPartition)</div><div class="line">      &#125;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="comment">//note: 开始加载，加载成功的话，将该 Partition 从 loadingPartitions 集合中移除，添加到 ownedPartition 集合中</span></div><div class="line">    <span class="keyword">try</span> &#123;</div><div class="line">      loadGroupsAndOffsets(topicPartition, onGroupLoaded)</div><div class="line">    &#125; <span class="keyword">catch</span> &#123;</div><div class="line">      <span class="keyword">case</span> t: <span class="type">Throwable</span> =&gt; error(<span class="string">s"Error loading offsets from <span class="subst">$topicPartition</span>"</span>, t)</div><div class="line">    &#125; <span class="keyword">finally</span> &#123;</div><div class="line">      inLock(partitionLock) &#123;</div><div class="line">        ownedPartitions.add(offsetsPartition)</div><div class="line">        loadingPartitions.remove(offsetsPartition)</div><div class="line">      &#125;</div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  scheduler.schedule(topicPartition.toString, doLoadGroupsAndOffsets)</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>这个方法的做的事情是：</p>
<ol>
<li>将正在处理的 Partition 添加到 loadingPartitions 集合中，这个集合内都是当前正在加载的 Partition（特指 <code>__consumer_offset</code> Topic）；</li>
<li>通过 <code>loadGroupsAndOffsets()</code> 加载这个 Partition 的数据，处理完成后，该 Partition 从 loadingPartitions 中清除，并添加到 ownedPartitions 集合中。</li>
</ol>
<p><code>loadGroupsAndOffsets()</code> 的实现如下：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//note: 读取该 group offset Partition 数据</span></div><div class="line"><span class="keyword">private</span>[coordinator] <span class="function"><span class="keyword">def</span> <span class="title">loadGroupsAndOffsets</span></span>(topicPartition: <span class="type">TopicPartition</span>, onGroupLoaded: <span class="type">GroupMetadata</span> =&gt; <span class="type">Unit</span>) &#123;</div><div class="line">  <span class="comment">//note: 这个必然有本地副本，现获取 hw（如果本地是 leader 的情况，否则返回-1）</span></div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">highWaterMark</span> </span>= replicaManager.getHighWatermark(topicPartition).getOrElse(<span class="number">-1</span>L)</div><div class="line"></div><div class="line">  <span class="keyword">val</span> startMs = time.milliseconds()</div><div class="line">  replicaManager.getLog(topicPartition) <span class="keyword">match</span> &#123;</div><div class="line">    <span class="keyword">case</span> <span class="type">None</span> =&gt;</div><div class="line">      warn(<span class="string">s"Attempted to load offsets and group metadata from <span class="subst">$topicPartition</span>, but found no log"</span>)</div><div class="line"></div><div class="line">    <span class="keyword">case</span> <span class="type">Some</span>(log) =&gt;</div><div class="line">      <span class="keyword">var</span> currOffset = log.logStartOffset <span class="comment">//note: 这副本最起始的 offset</span></div><div class="line">      <span class="keyword">val</span> buffer = <span class="type">ByteBuffer</span>.allocate(config.loadBufferSize) <span class="comment">//note: 默认5MB</span></div><div class="line">      <span class="comment">// loop breaks if leader changes at any time during the load, since getHighWatermark is -1</span></div><div class="line">      <span class="comment">//note: group 与 offset 的对应关系</span></div><div class="line">      <span class="keyword">val</span> loadedOffsets = mutable.<span class="type">Map</span>[<span class="type">GroupTopicPartition</span>, <span class="type">OffsetAndMetadata</span>]()</div><div class="line">      <span class="keyword">val</span> removedOffsets = mutable.<span class="type">Set</span>[<span class="type">GroupTopicPartition</span>]()</div><div class="line">      <span class="comment">//note: Group 对应的 meta 信息</span></div><div class="line">      <span class="keyword">val</span> loadedGroups = mutable.<span class="type">Map</span>[<span class="type">String</span>, <span class="type">GroupMetadata</span>]()</div><div class="line">      <span class="keyword">val</span> removedGroups = mutable.<span class="type">Set</span>[<span class="type">String</span>]()</div><div class="line"></div><div class="line">      <span class="keyword">while</span> (currOffset &lt; highWaterMark &amp;&amp; !shuttingDown.get()) &#123; <span class="comment">//note: 直到读取到 hw 位置，或服务关闭</span></div><div class="line">        buffer.clear()</div><div class="line">        <span class="keyword">val</span> fileRecords = log.read(currOffset, config.loadBufferSize, maxOffset = <span class="type">None</span>, minOneMessage = <span class="literal">true</span>)</div><div class="line">          .records.asInstanceOf[<span class="type">FileRecords</span>]</div><div class="line">        <span class="keyword">val</span> bufferRead = fileRecords.readInto(buffer, <span class="number">0</span>)</div><div class="line"></div><div class="line">        <span class="type">MemoryRecords</span>.readableRecords(bufferRead).deepEntries.asScala.foreach &#123; entry =&gt;</div><div class="line">          <span class="keyword">val</span> record = entry.record</div><div class="line">          require(record.hasKey, <span class="string">"Group metadata/offset entry key should not be null"</span>)</div><div class="line"></div><div class="line">          <span class="type">GroupMetadataManager</span>.readMessageKey(record.key) <span class="keyword">match</span> &#123;</div><div class="line">            <span class="keyword">case</span> offsetKey: <span class="type">OffsetKey</span> =&gt; <span class="comment">//note: GroupTopicPartition，有 group 和 topic-partition</span></div><div class="line">              <span class="comment">// load offset</span></div><div class="line">              <span class="comment">//note: 加载 offset 信息</span></div><div class="line">              <span class="keyword">val</span> key = offsetKey.key</div><div class="line">              <span class="keyword">if</span> (record.hasNullValue) &#123; <span class="comment">//note: value 为空</span></div><div class="line">                loadedOffsets.remove(key)</div><div class="line">                removedOffsets.add(key)</div><div class="line">              &#125; <span class="keyword">else</span> &#123; <span class="comment">//note: 有 commit offset 信息</span></div><div class="line">                <span class="keyword">val</span> value = <span class="type">GroupMetadataManager</span>.readOffsetMessageValue(record.value)</div><div class="line">                loadedOffsets.put(key, value)</div><div class="line">                removedOffsets.remove(key)</div><div class="line">              &#125;</div><div class="line"></div><div class="line">            <span class="keyword">case</span> groupMetadataKey: <span class="type">GroupMetadataKey</span> =&gt;</div><div class="line">              <span class="comment">// load group metadata</span></div><div class="line">              <span class="comment">//note: 加载 group metadata 信息</span></div><div class="line">              <span class="keyword">val</span> groupId = groupMetadataKey.key</div><div class="line">              <span class="keyword">val</span> groupMetadata = <span class="type">GroupMetadataManager</span>.readGroupMessageValue(groupId, record.value)</div><div class="line">              <span class="keyword">if</span> (groupMetadata != <span class="literal">null</span>) &#123;</div><div class="line">                trace(<span class="string">s"Loaded group metadata for group <span class="subst">$groupId</span> with generation <span class="subst">$&#123;groupMetadata.generationId&#125;</span>"</span>)</div><div class="line">                removedGroups.remove(groupId)</div><div class="line">                loadedGroups.put(groupId, groupMetadata)</div><div class="line">              &#125; <span class="keyword">else</span> &#123; <span class="comment">//note: 更新最新的信息</span></div><div class="line">                loadedGroups.remove(groupId)</div><div class="line">                removedGroups.add(groupId)</div><div class="line">              &#125;</div><div class="line"></div><div class="line">            <span class="keyword">case</span> unknownKey =&gt;</div><div class="line">              <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">IllegalStateException</span>(<span class="string">s"Unexpected message key <span class="subst">$unknownKey</span> while loading offsets and group metadata"</span>)</div><div class="line">          &#125;</div><div class="line"></div><div class="line">          currOffset = entry.nextOffset</div><div class="line">        &#125;</div><div class="line">      &#125;</div><div class="line"></div><div class="line">      <span class="keyword">val</span> (groupOffsets, emptyGroupOffsets) = loadedOffsets</div><div class="line">        .groupBy(_._1.group)</div><div class="line">        .mapValues(_.map &#123; <span class="keyword">case</span> (groupTopicPartition, offset) =&gt; (groupTopicPartition.topicPartition, offset)&#125; )</div><div class="line">        .partition &#123; <span class="keyword">case</span> (group, _) =&gt; loadedGroups.contains(group) &#125; <span class="comment">//note: 把集合根据条件分两个部分</span></div><div class="line"></div><div class="line">      loadedGroups.values.foreach &#123; group =&gt;</div><div class="line">        <span class="keyword">val</span> offsets = groupOffsets.getOrElse(group.groupId, <span class="type">Map</span>.empty[<span class="type">TopicPartition</span>, <span class="type">OffsetAndMetadata</span>])</div><div class="line">        loadGroup(group, offsets) <span class="comment">//note: 在缓存中添加 group 和初始化 offset 信息</span></div><div class="line">        onGroupLoaded(group) <span class="comment">//note: 设置 group 下一次心跳超时时间</span></div><div class="line">      &#125;</div><div class="line"></div><div class="line">      <span class="comment">// load groups which store offsets in kafka, but which have no active members and thus no group</span></div><div class="line">      <span class="comment">// metadata stored in the log</span></div><div class="line">      <span class="comment">//note: 加载哪些有 offset 信息但是当前没有活跃的 member 信息的 group</span></div><div class="line">      emptyGroupOffsets.foreach &#123; <span class="keyword">case</span> (groupId, offsets) =&gt;</div><div class="line">        <span class="keyword">val</span> group = <span class="keyword">new</span> <span class="type">GroupMetadata</span>(groupId)</div><div class="line">        loadGroup(group, offsets)</div><div class="line">        onGroupLoaded(group)</div><div class="line">      &#125;</div><div class="line"></div><div class="line">      removedGroups.foreach &#123; groupId =&gt;</div><div class="line">        <span class="comment">// if the cache already contains a group which should be removed, raise an error. Note that it</span></div><div class="line">        <span class="comment">// is possible (however unlikely) for a consumer group to be removed, and then to be used only for</span></div><div class="line">        <span class="comment">// offset storage (i.e. by "simple" consumers)</span></div><div class="line">        <span class="keyword">if</span> (groupMetadataCache.contains(groupId) &amp;&amp; !emptyGroupOffsets.contains(groupId))</div><div class="line">          <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">IllegalStateException</span>(<span class="string">s"Unexpected unload of active group <span class="subst">$groupId</span> while "</span> +</div><div class="line">            <span class="string">s"loading partition <span class="subst">$topicPartition</span>"</span>)</div><div class="line">      &#125;</div><div class="line"></div><div class="line">      <span class="keyword">if</span> (!shuttingDown.get())</div><div class="line">        info(<span class="string">"Finished loading offsets from %s in %d milliseconds."</span></div><div class="line">          .format(topicPartition, time.milliseconds() - startMs))</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>上面方法的实现虽然比较长，但是处理逻辑还是比较简单的，实现结果如下：</p>
<ol>
<li>获取这个 Partition 的 HW 值（如果 leader 不在本地，那么返回-1）；</li>
<li>初始化 loadedOffsets 和 removedOffsets、loadedGroups 和 removedGroups 集合，它们就是 group offset 信息以及 consumer member 信息；</li>
<li>从这个 Partition 第一条数据开始读取，直到读取到 HW 位置，加载相应的 commit offset、consumer member 信息，因为是顺序读取的，所以会新的值会覆盖前面的值；</li>
<li>通过 <code>loadGroup()</code> 加载到 GroupCoordinator 的缓存中。</li>
</ol>
<p>经过上面这些步骤，这个 Partition 的数据就被完整加载缓存中了。</p>
<h3 id="变成-follower"><a href="#变成-follower" class="headerlink" title="变成 follower"></a>变成 follower</h3><p>如果 <code>__consumer_offset</code> 有 Partition 变成了 follower（之前是 leader，如果之前不是 leader，不会走到这一步的），GroupCoordinator 通过 <code>handleGroupEmigration()</code> 移除这个 Partition 相应的缓存信息。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//note: 移除这个 Partition 对应的 group offset 信息</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">handleGroupEmigration</span></span>(offsetTopicPartitionId: <span class="type">Int</span>) &#123;</div><div class="line">  groupManager.removeGroupsForPartition(offsetTopicPartitionId, onGroupUnloaded)</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p><code>removeGroupsForPartition()</code> 的实现如下：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//note: 当一个 broker 变成一个 follower 时，清空这个 partition 的相关缓存信息</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">removeGroupsForPartition</span></span>(offsetsPartition: <span class="type">Int</span>,</div><div class="line">                             onGroupUnloaded: <span class="type">GroupMetadata</span> =&gt; <span class="type">Unit</span>) &#123;</div><div class="line">  <span class="keyword">val</span> topicPartition = <span class="keyword">new</span> <span class="type">TopicPartition</span>(<span class="type">Topic</span>.<span class="type">GroupMetadataTopicName</span>, offsetsPartition)</div><div class="line">  scheduler.schedule(topicPartition.toString, removeGroupsAndOffsets)</div><div class="line"></div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">removeGroupsAndOffsets</span></span>() &#123;</div><div class="line">    <span class="keyword">var</span> numOffsetsRemoved = <span class="number">0</span></div><div class="line">    <span class="keyword">var</span> numGroupsRemoved = <span class="number">0</span></div><div class="line"></div><div class="line">    inLock(partitionLock) &#123;</div><div class="line">      <span class="comment">// we need to guard the group removal in cache in the loading partition lock</span></div><div class="line">      <span class="comment">// to prevent coordinator's check-and-get-group race condition</span></div><div class="line">      ownedPartitions.remove(offsetsPartition)</div><div class="line"></div><div class="line">      <span class="keyword">for</span> (group &lt;- groupMetadataCache.values) &#123;</div><div class="line">        <span class="keyword">if</span> (partitionFor(group.groupId) == offsetsPartition) &#123;</div><div class="line">          onGroupUnloaded(group) <span class="comment">//note: 将 group 状态转移成 dead</span></div><div class="line">          groupMetadataCache.remove(group.groupId, group) <span class="comment">//note: 清空 group 的信息</span></div><div class="line">          numGroupsRemoved += <span class="number">1</span></div><div class="line">          numOffsetsRemoved += group.numOffsets</div><div class="line">        &#125;</div><div class="line">      &#125;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="keyword">if</span> (numOffsetsRemoved &gt; <span class="number">0</span>)</div><div class="line">      info(<span class="string">s"Removed <span class="subst">$numOffsetsRemoved</span> cached offsets for <span class="subst">$topicPartition</span> on follower transition."</span>)</div><div class="line"></div><div class="line">    <span class="keyword">if</span> (numGroupsRemoved &gt; <span class="number">0</span>)</div><div class="line">      info(<span class="string">s"Removed <span class="subst">$numGroupsRemoved</span> cached groups for <span class="subst">$topicPartition</span> on follower transition."</span>)</div><div class="line">  &#125;</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">onGroupUnloaded</span></span>(group: <span class="type">GroupMetadata</span>) &#123;</div><div class="line">  group synchronized &#123;</div><div class="line">    info(<span class="string">s"Unloading group metadata for <span class="subst">$&#123;group.groupId&#125;</span> with generation <span class="subst">$&#123;group.generationId&#125;</span>"</span>)</div><div class="line">    <span class="keyword">val</span> previousState = group.currentState</div><div class="line">    group.transitionTo(<span class="type">Dead</span>) <span class="comment">//note: 状态转移成 dead</span></div><div class="line"></div><div class="line">    previousState <span class="keyword">match</span> &#123;</div><div class="line">      <span class="keyword">case</span> <span class="type">Empty</span> | <span class="type">Dead</span> =&gt;</div><div class="line">      <span class="keyword">case</span> <span class="type">PreparingRebalance</span> =&gt;</div><div class="line">        <span class="keyword">for</span> (member &lt;- group.allMemberMetadata) &#123; <span class="comment">//note: 如果有 member 信息返回异常</span></div><div class="line">          <span class="keyword">if</span> (member.awaitingJoinCallback != <span class="literal">null</span>) &#123;</div><div class="line">            member.awaitingJoinCallback(joinError(member.memberId, <span class="type">Errors</span>.<span class="type">NOT_COORDINATOR_FOR_GROUP</span>.code))</div><div class="line">            member.awaitingJoinCallback = <span class="literal">null</span></div><div class="line">          &#125;</div><div class="line">        &#125;</div><div class="line">        joinPurgatory.checkAndComplete(<span class="type">GroupKey</span>(group.groupId))</div><div class="line"></div><div class="line">      <span class="keyword">case</span> <span class="type">Stable</span> | <span class="type">AwaitingSync</span> =&gt;</div><div class="line">        <span class="keyword">for</span> (member &lt;- group.allMemberMetadata) &#123; <span class="comment">//note: 如果有 member 信息，返回异常</span></div><div class="line">          <span class="keyword">if</span> (member.awaitingSyncCallback != <span class="literal">null</span>) &#123;</div><div class="line">            member.awaitingSyncCallback(<span class="type">Array</span>.empty[<span class="type">Byte</span>], <span class="type">Errors</span>.<span class="type">NOT_COORDINATOR_FOR_GROUP</span>.code)</div><div class="line">            member.awaitingSyncCallback = <span class="literal">null</span></div><div class="line">          &#125;</div><div class="line">          heartbeatPurgatory.checkAndComplete(<span class="type">MemberKey</span>(member.groupId, member.memberId))</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>对于在这个 Partition 上的所有 Group，会按下面的步骤执行：</p>
<ol>
<li>通过 <code>onGroupUnloaded()</code> 方法先将这个 Group 的状态转换为 dead，如果 Group 处在 PreparingRebalance/Stable/AwaitingSync 状态，并且设置了相应的回调函数，那么就在回调函数中返回带有 NOT_COORDINATOR_FOR_GROUP 异常信息的响应，consumer 在收到这个异常信息会重新加入 group；</li>
<li>从缓存中移除这个 Group 的信息。</li>
</ol>
<p>这个遍历执行完成之后，这个 Topic Partition 就从 Leader 变成了 follower 状态。</p>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[Kafka 源码解析之 Controller 发送模型（二十一）]]></title>
      <url>http://matt33.com/2018/06/23/controller-request-model/</url>
      <content type="html"><![CDATA[<p>本篇主要讲述 Controller 向各个 Broker 发送请求的模型，算是对 <a href="http://matt33.com/2018/06/15/kafka-controller-start/#Controller-Channel-Manager">Controller Channel Manager</a> 部分的一个补充，在这篇文章中，将会看到 Controller 在处理 leader 切换、ShutDown 请求时如何向 Broker 发送相应的请求。</p>
<p>Kafka Controller 向 Broker 发送的请求类型主要分为三种：LeaderAndIsr、UpdateMetadata、StopReplica 请求，正如  <a href="http://matt33.com/2018/06/15/kafka-controller-start/#Controller-Channel-Manager">Controller Channel Manager</a> 这里介绍的，Controller 会为每台 Broker 初始化为一个 ControllerBrokerStateInfo 对象，该对象主要包含以下四个内容：</p>
<ol>
<li>NetworkClient：与 Broker 的网络连接对象；</li>
<li>Node：Broker 的节点信息；</li>
<li>MessageQueue：每个 Broker 对应的请求队列，Controller 向 Broker 发送的请求会想放在这个队列里；</li>
<li>RequestSendThread：每台 Broker 对应的请求发送线程。</li>
</ol>
<h2 id="Controller-的请求发送模型"><a href="#Controller-的请求发送模型" class="headerlink" title="Controller 的请求发送模型"></a>Controller 的请求发送模型</h2><p>在讲述 Controller 发送模型之前，先看下 Controller 是如何向 Broker 发送请求的，这里以发送 metadata 更新请求为例，简略的代码如下：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//note: 创建新的批量请求</span></div><div class="line">brokerRequestBatch.newBatch()</div><div class="line"><span class="comment">//note: 为目标 Broker 添加相应的请求</span></div><div class="line">brokerRequestBatch.addUpdateMetadataRequestForBrokers(brokers, partitions)</div><div class="line"><span class="comment">//note: 发送请求，实际上只是把请求添加发送线程的 request queue 中</span></div><div class="line">brokerRequestBatch.sendRequestsToBrokers(epoch)</div></pre></td></tr></table></figure>
<p>这里有一个比较重要的对象，就是 ControllerBrokerRequestBatch 对象，可以认为它是一个专门用于批量请求发送的对象，在这个对象中有几个重要成员变量：</p>
<ol>
<li>leaderAndIsrRequestMap：记录每个 broker 与要发送的 LeaderAndIsr 请求集合的 map；</li>
<li>stopReplicaRequestMap：记录每个 broker 与要发送的 StopReplica 集合的 map；</li>
<li>updateMetadataRequestBrokerSet：记录要发送的 update-metadata 请求的 broker 集合；</li>
<li>updateMetadataRequestPartitionInfoMap：记录 update-metadata 请求要更新的 Topic Partition 集合。</li>
</ol>
<p>Controller 可以通过下面这三方法向这些集合添加相应的请求：</p>
<ol>
<li><code>addLeaderAndIsrRequestForBrokers()</code>：向给定的 Broker 发送某个 Topic Partition 的 LeaderAndIsr 请求；</li>
<li><code>addStopReplicaRequestForBrokers()</code>：向给定的 Broker 发送某个 Topic Partition 的 StopReplica 请求；</li>
<li><code>addUpdateMetadataRequestForBrokers()</code>：向给定的 Broker 发送某一批 Partitions 的 UpdateMetadata 请求。</li>
</ol>
<p>Controller 整体的请求模型概况如下图所示：</p>
<p><img src="/images/kafka/controller-request-model.png" alt="Controller 的请求发送模型"></p>
<p>上述三个方法将相应的请求添加到对应的集合中后，然后通过 <code>sendRequestsToBrokers()</code> 方法将该请求添加到该 Broker 对应的请求队列中，接着再由该 Broker 对应的 RequestSendThread 去发送相应的请求。</p>
<h2 id="ControllerBrokerRequestBatch"><a href="#ControllerBrokerRequestBatch" class="headerlink" title="ControllerBrokerRequestBatch"></a>ControllerBrokerRequestBatch</h2><p>这节详细讲述一下关于 ControllerBrokerRequestBatch 的一些方法实现。</p>
<h3 id="newBatch-方法"><a href="#newBatch-方法" class="headerlink" title="newBatch 方法"></a>newBatch 方法</h3><p>Controller 在添加请求前，都会先调用 <code>newBatch()</code> 方法，该方法的实现如下：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//note: 创建新的请求前,确保前一批请求全部发送完毕</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">newBatch</span></span>() &#123;</div><div class="line">  <span class="comment">// raise error if the previous batch is not empty</span></div><div class="line">  <span class="keyword">if</span> (leaderAndIsrRequestMap.nonEmpty)</div><div class="line">    <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">IllegalStateException</span>(<span class="string">"Controller to broker state change requests batch is not empty while creating "</span> +</div><div class="line">      <span class="string">"a new one. Some LeaderAndIsr state changes %s might be lost "</span>.format(leaderAndIsrRequestMap.toString()))</div><div class="line">  <span class="keyword">if</span> (stopReplicaRequestMap.nonEmpty)</div><div class="line">    <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">IllegalStateException</span>(<span class="string">"Controller to broker state change requests batch is not empty while creating a "</span> +</div><div class="line">      <span class="string">"new one. Some StopReplica state changes %s might be lost "</span>.format(stopReplicaRequestMap.toString()))</div><div class="line">  <span class="keyword">if</span> (updateMetadataRequestBrokerSet.nonEmpty)</div><div class="line">    <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">IllegalStateException</span>(<span class="string">"Controller to broker state change requests batch is not empty while creating a "</span> +</div><div class="line">      <span class="string">"new one. Some UpdateMetadata state changes to brokers %s with partition info %s might be lost "</span>.format(</div><div class="line">        updateMetadataRequestBrokerSet.toString(), updateMetadataRequestPartitionInfoMap.toString()))</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>这个方法的主要作用是检查上一波的 LeaderAndIsr、UpdateMetadata、StopReplica 请求是否已经发送，正常情况下，Controller 在调用 <code>sendRequestsToBrokers()</code> 方法之后，这些集合中的请求都会被发送，发送之后，会将相应的请求集合清空，当然在异常情况可能会导致部分集合没有被清空，导致无法 <code>newBatch()</code>，这种情况下，通常策略是重启 controller，因为现在 Controller 的设计还是有些复杂，在某些情况下还是可能会导致异常发生，并且有些异常还是无法恢复的。</p>
<h3 id="添加-LeaderAndIsr-请求"><a href="#添加-LeaderAndIsr-请求" class="headerlink" title="添加 LeaderAndIsr 请求"></a>添加 LeaderAndIsr 请求</h3><p>Controller 可以通过 <code>addLeaderAndIsrRequestForBrokers()</code> 向指定 Broker 列表添加某个 Topic Partition 的 LeaderAndIsr 请求，其具体实现如下：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//note: 将 LeaderAndIsr 添加到对应的 broker 中,还未开始发送数据</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">addLeaderAndIsrRequestForBrokers</span></span>(brokerIds: <span class="type">Seq</span>[<span class="type">Int</span>], topic: <span class="type">String</span>, partition: <span class="type">Int</span>,</div><div class="line">                                     leaderIsrAndControllerEpoch: <span class="type">LeaderIsrAndControllerEpoch</span>,</div><div class="line">                                     replicas: <span class="type">Seq</span>[<span class="type">Int</span>], callback: <span class="type">AbstractResponse</span> =&gt; <span class="type">Unit</span> = <span class="literal">null</span>) &#123;</div><div class="line">  <span class="keyword">val</span> topicPartition = <span class="keyword">new</span> <span class="type">TopicPartition</span>(topic, partition)</div><div class="line"></div><div class="line">  <span class="comment">//note: 将请求添加到对应的 broker 上</span></div><div class="line">  brokerIds.filter(_ &gt;= <span class="number">0</span>).foreach &#123; brokerId =&gt;</div><div class="line">    <span class="keyword">val</span> result = leaderAndIsrRequestMap.getOrElseUpdate(brokerId, mutable.<span class="type">Map</span>.empty)</div><div class="line">    result.put(topicPartition, <span class="type">PartitionStateInfo</span>(leaderIsrAndControllerEpoch, replicas.toSet))</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  <span class="comment">//note: 在更新 LeaderAndIsr 信息时,主题的 metadata 相当于也进行了更新,需要发送这个 topic 的 metadata 给所有存活的 broker</span></div><div class="line">  addUpdateMetadataRequestForBrokers(controllerContext.liveOrShuttingDownBrokerIds.toSeq,</div><div class="line">                                     <span class="type">Set</span>(<span class="type">TopicAndPartition</span>(topic, partition)))</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>这个方法的处理流程如下：</p>
<ol>
<li>向对应的 Broker 添加 LeaderAndIsr 请求，请求会被添加到 leaderAndIsrRequestMap 集合中；</li>
<li>并通过 <code>addUpdateMetadataRequestForBrokers()</code> 方法向所有的 Broker 添加这个 Topic-Partition 的 UpdateMatedata 请求，leader 或 isr 变动时，会向所有 broker 同步这个 Partition 的 metadata 信息，这样可以保证每台 Broker 上都有最新的 metadata 信息。</li>
</ol>
<h3 id="添加-UpdateMetadata-请求"><a href="#添加-UpdateMetadata-请求" class="headerlink" title="添加 UpdateMetadata 请求"></a>添加 UpdateMetadata 请求</h3><p>Controller 可以通过 <code>addUpdateMetadataRequestForBrokers()</code> 向指定 Broker 列表添加某批 Partitions 的 UpdateMetadata 请求，其具体实现如下：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//note: 向给行的 Broker 发送 UpdateMetadataRequest 请求</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">addUpdateMetadataRequestForBrokers</span></span>(brokerIds: <span class="type">Seq</span>[<span class="type">Int</span>],</div><div class="line">                                       partitions: collection.<span class="type">Set</span>[<span class="type">TopicAndPartition</span>] = <span class="type">Set</span>.empty[<span class="type">TopicAndPartition</span>],</div><div class="line">                                       callback: <span class="type">AbstractResponse</span> =&gt; <span class="type">Unit</span> = <span class="literal">null</span>) &#123;</div><div class="line">  <span class="comment">//note: 将 Topic-Partition 添加到对应的 map 中</span></div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">updateMetadataRequestPartitionInfo</span></span>(partition: <span class="type">TopicAndPartition</span>, beingDeleted: <span class="type">Boolean</span>) &#123;</div><div class="line">    <span class="keyword">val</span> leaderIsrAndControllerEpochOpt = controllerContext.partitionLeadershipInfo.get(partition)</div><div class="line">    leaderIsrAndControllerEpochOpt <span class="keyword">match</span> &#123;</div><div class="line">      <span class="keyword">case</span> <span class="type">Some</span>(leaderIsrAndControllerEpoch) =&gt;</div><div class="line">        <span class="keyword">val</span> replicas = controllerContext.partitionReplicaAssignment(partition).toSet</div><div class="line">        <span class="keyword">val</span> partitionStateInfo = <span class="keyword">if</span> (beingDeleted) &#123; <span class="comment">//note: 正在删除的 Partition,设置 leader 为-2</span></div><div class="line">          <span class="keyword">val</span> leaderAndIsr = <span class="keyword">new</span> <span class="type">LeaderAndIsr</span>(<span class="type">LeaderAndIsr</span>.<span class="type">LeaderDuringDelete</span>, leaderIsrAndControllerEpoch.leaderAndIsr.isr)</div><div class="line">          <span class="type">PartitionStateInfo</span>(<span class="type">LeaderIsrAndControllerEpoch</span>(leaderAndIsr, leaderIsrAndControllerEpoch.controllerEpoch), replicas)</div><div class="line">        &#125; <span class="keyword">else</span> &#123;</div><div class="line">          <span class="type">PartitionStateInfo</span>(leaderIsrAndControllerEpoch, replicas)</div><div class="line">        &#125;</div><div class="line">        <span class="comment">//note: 添加到对应的 request map 中</span></div><div class="line">        updateMetadataRequestPartitionInfoMap.put(<span class="keyword">new</span> <span class="type">TopicPartition</span>(partition.topic, partition.partition), partitionStateInfo)</div><div class="line">      <span class="keyword">case</span> <span class="type">None</span> =&gt;</div><div class="line">        info(<span class="string">"Leader not yet assigned for partition %s. Skip sending UpdateMetadataRequest."</span>.format(partition))</div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  <span class="comment">//note:过滤出要发送的 partition</span></div><div class="line">  <span class="keyword">val</span> filteredPartitions = &#123;</div><div class="line">    <span class="keyword">val</span> givenPartitions = <span class="keyword">if</span> (partitions.isEmpty)</div><div class="line">      controllerContext.partitionLeadershipInfo.keySet <span class="comment">//note: Partitions 为空时，就过滤出所有的 topic</span></div><div class="line">    <span class="keyword">else</span></div><div class="line">      partitions</div><div class="line">    <span class="keyword">if</span> (controller.deleteTopicManager.partitionsToBeDeleted.isEmpty)</div><div class="line">      givenPartitions</div><div class="line">    <span class="keyword">else</span></div><div class="line">      givenPartitions -- controller.deleteTopicManager.partitionsToBeDeleted <span class="comment">//note: 将要删除的 topic 过滤掉</span></div><div class="line">  &#125;</div><div class="line"></div><div class="line">  updateMetadataRequestBrokerSet ++= brokerIds.filter(_ &gt;= <span class="number">0</span>) <span class="comment">//note: 将 broker 列表更新到要发送的集合中</span></div><div class="line">  <span class="comment">//note: 对于要更新 metadata 的 Partition,设置 beingDeleted 为 False</span></div><div class="line">  filteredPartitions.foreach(partition =&gt; updateMetadataRequestPartitionInfo(partition, beingDeleted = <span class="literal">false</span>))</div><div class="line">  <span class="comment">//note: 要删除的 Partition 设置 BeingDeleted 为 True</span></div><div class="line">  controller.deleteTopicManager.partitionsToBeDeleted.foreach(partition =&gt; updateMetadataRequestPartitionInfo(partition, beingDeleted = <span class="literal">true</span>))</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>这个方法的实现逻辑如下：</p>
<ol>
<li>首先过滤出要发送的 Partition 列表，如果没有指定要发送 partitions 列表，那么默认就是发送全局的 metadata 信息；</li>
<li>接着将已经标记为删除的 Partition 从上面的列表中移除；</li>
<li>将要发送的 Broker 列表添加到 updateMetadataRequestBrokerSet 集合中；</li>
<li>将前面过滤的 Partition 列表对应的 metadata 信息添加到对应的 updateMetadataRequestPartitionInfoMap 集合中;</li>
<li>将当前设置为删除的所有 Partition 的 metadata 信息也添加到 updateMetadataRequestPartitionInfoMap 集合中，添加前会把其 leader 设置为-2，这样 Broker 收到这个 Partition 的 metadata 信息之后就会知道这个 Partition 是设置删除标志。</li>
</ol>
<h3 id="添加-StopReplica-请求"><a href="#添加-StopReplica-请求" class="headerlink" title="添加 StopReplica 请求"></a>添加 StopReplica 请求</h3><p>Controller 可以通过 <code>addStopReplicaRequestForBrokers()</code> 向指定 Broker 列表添加某个 Topic Partition 的 StopReplica 请求，其具体实现如下：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//note: 将 StopReplica 添加到对应的 Broker 中,还未开始发送数据</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">addStopReplicaRequestForBrokers</span></span>(brokerIds: <span class="type">Seq</span>[<span class="type">Int</span>], topic: <span class="type">String</span>, partition: <span class="type">Int</span>, deletePartition: <span class="type">Boolean</span>,</div><div class="line">                                    callback: (<span class="type">AbstractResponse</span>, <span class="type">Int</span>) =&gt; <span class="type">Unit</span> = <span class="literal">null</span>) &#123;</div><div class="line">  brokerIds.filter(b =&gt; b &gt;= <span class="number">0</span>).foreach &#123; brokerId =&gt;</div><div class="line">    stopReplicaRequestMap.getOrElseUpdate(brokerId, <span class="type">Seq</span>.empty[<span class="type">StopReplicaRequestInfo</span>])</div><div class="line">    <span class="keyword">val</span> v = stopReplicaRequestMap(brokerId)</div><div class="line">    <span class="keyword">if</span>(callback != <span class="literal">null</span>)</div><div class="line">      stopReplicaRequestMap(brokerId) = v :+ <span class="type">StopReplicaRequestInfo</span>(<span class="type">PartitionAndReplica</span>(topic, partition, brokerId),</div><div class="line">        deletePartition, (r: <span class="type">AbstractResponse</span>) =&gt; callback(r, brokerId))</div><div class="line">    <span class="keyword">else</span></div><div class="line">      stopReplicaRequestMap(brokerId) = v :+ <span class="type">StopReplicaRequestInfo</span>(<span class="type">PartitionAndReplica</span>(topic, partition, brokerId),</div><div class="line">        deletePartition)</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>这个方法的实现逻辑比较简单，直接将 StopReplica 添加到 stopReplicaRequestMap 中。</p>
<h3 id="向-Broker-发送请求"><a href="#向-Broker-发送请求" class="headerlink" title="向 Broker 发送请求"></a>向 Broker 发送请求</h3><p>Controller 在添加完相应的请求后，最后一步都会去调用 <code>sendRequestsToBrokers()</code> 方法构造相应的请求，并把请求添加到 Broker 对应的 RequestQueue 中。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div><div class="line">113</div><div class="line">114</div><div class="line">115</div><div class="line">116</div><div class="line">117</div><div class="line">118</div><div class="line">119</div><div class="line">120</div><div class="line">121</div><div class="line">122</div><div class="line">123</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//note: 发送请求给 broker（只是将对应处理后放入到对应的 queue 中）</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">sendRequestsToBrokers</span></span>(controllerEpoch: <span class="type">Int</span>) &#123;</div><div class="line">  <span class="keyword">try</span> &#123;</div><div class="line">    <span class="comment">//note: LeaderAndIsr 请求</span></div><div class="line">    leaderAndIsrRequestMap.foreach &#123; <span class="keyword">case</span> (broker, partitionStateInfos) =&gt;</div><div class="line">      partitionStateInfos.foreach &#123; <span class="keyword">case</span> (topicPartition, state) =&gt;</div><div class="line">        <span class="keyword">val</span> typeOfRequest = <span class="keyword">if</span> (broker == state.leaderIsrAndControllerEpoch.leaderAndIsr.leader) <span class="string">"become-leader"</span> <span class="keyword">else</span> <span class="string">"become-follower"</span></div><div class="line">        stateChangeLogger.trace((<span class="string">"Controller %d epoch %d sending %s LeaderAndIsr request %s to broker %d "</span> +</div><div class="line">                                 <span class="string">"for partition [%s,%d]"</span>).format(controllerId, controllerEpoch, typeOfRequest,</div><div class="line">                                                                 state.leaderIsrAndControllerEpoch, broker,</div><div class="line">                                                                 topicPartition.topic, topicPartition.partition))</div><div class="line">      &#125;</div><div class="line">      <span class="comment">//note: leader id 集合</span></div><div class="line">      <span class="keyword">val</span> leaderIds = partitionStateInfos.map(_._2.leaderIsrAndControllerEpoch.leaderAndIsr.leader).toSet</div><div class="line">      <span class="keyword">val</span> leaders = controllerContext.liveOrShuttingDownBrokers.filter(b =&gt; leaderIds.contains(b.id)).map &#123;</div><div class="line">        _.getNode(controller.config.interBrokerListenerName)</div><div class="line">      &#125;</div><div class="line">      <span class="comment">//note: requests.PartitionState</span></div><div class="line">      <span class="keyword">val</span> partitionStates = partitionStateInfos.map &#123; <span class="keyword">case</span> (topicPartition, partitionStateInfo) =&gt;</div><div class="line">        <span class="keyword">val</span> <span class="type">LeaderIsrAndControllerEpoch</span>(leaderIsr, controllerEpoch) = partitionStateInfo.leaderIsrAndControllerEpoch</div><div class="line">        <span class="keyword">val</span> partitionState = <span class="keyword">new</span> requests.<span class="type">PartitionState</span>(controllerEpoch, leaderIsr.leader,</div><div class="line">          leaderIsr.leaderEpoch, leaderIsr.isr.map(<span class="type">Integer</span>.valueOf).asJava, leaderIsr.zkVersion,</div><div class="line">          partitionStateInfo.allReplicas.map(<span class="type">Integer</span>.valueOf).asJava)</div><div class="line">        topicPartition -&gt; partitionState</div><div class="line">      &#125;</div><div class="line">      <span class="comment">//note: 构造 LeaderAndIsr 请求,并添加到对应的 queue 中</span></div><div class="line">      <span class="keyword">val</span> leaderAndIsrRequest = <span class="keyword">new</span> <span class="type">LeaderAndIsrRequest</span>.</div><div class="line">          <span class="type">Builder</span>(controllerId, controllerEpoch, partitionStates.asJava, leaders.asJava)</div><div class="line">      controller.sendRequest(broker, <span class="type">ApiKeys</span>.<span class="type">LEADER_AND_ISR</span>, leaderAndIsrRequest, <span class="literal">null</span>)</div><div class="line">    &#125;</div><div class="line">    leaderAndIsrRequestMap.clear() <span class="comment">//note: 清空 leaderAndIsr 集合</span></div><div class="line"></div><div class="line">    <span class="comment">//note: update-metadata 请求</span></div><div class="line">    updateMetadataRequestPartitionInfoMap.foreach(p =&gt; stateChangeLogger.trace((<span class="string">"Controller %d epoch %d sending UpdateMetadata request %s "</span> +</div><div class="line">      <span class="string">"to brokers %s for partition %s"</span>).format(controllerId, controllerEpoch, p._2.leaderIsrAndControllerEpoch,</div><div class="line">      updateMetadataRequestBrokerSet.toString(), p._1)))</div><div class="line">    <span class="keyword">val</span> partitionStates = updateMetadataRequestPartitionInfoMap.map &#123; <span class="keyword">case</span> (topicPartition, partitionStateInfo) =&gt;</div><div class="line">      <span class="keyword">val</span> <span class="type">LeaderIsrAndControllerEpoch</span>(leaderIsr, controllerEpoch) = partitionStateInfo.leaderIsrAndControllerEpoch</div><div class="line">      <span class="keyword">val</span> partitionState = <span class="keyword">new</span> requests.<span class="type">PartitionState</span>(controllerEpoch, leaderIsr.leader,</div><div class="line">        leaderIsr.leaderEpoch, leaderIsr.isr.map(<span class="type">Integer</span>.valueOf).asJava, leaderIsr.zkVersion,</div><div class="line">        partitionStateInfo.allReplicas.map(<span class="type">Integer</span>.valueOf).asJava)</div><div class="line">      topicPartition -&gt; partitionState</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="keyword">val</span> version: <span class="type">Short</span> =</div><div class="line">      <span class="keyword">if</span> (controller.config.interBrokerProtocolVersion &gt;= <span class="type">KAFKA_0_10_2_IV0</span>) <span class="number">3</span></div><div class="line">      <span class="keyword">else</span> <span class="keyword">if</span> (controller.config.interBrokerProtocolVersion &gt;= <span class="type">KAFKA_0_10_0_IV1</span>) <span class="number">2</span></div><div class="line">      <span class="keyword">else</span> <span class="keyword">if</span> (controller.config.interBrokerProtocolVersion &gt;= <span class="type">KAFKA_0_9_0</span>) <span class="number">1</span></div><div class="line">      <span class="keyword">else</span> <span class="number">0</span></div><div class="line"></div><div class="line">    <span class="comment">//note: 构造 update-metadata 请求</span></div><div class="line">    <span class="keyword">val</span> updateMetadataRequest = &#123;</div><div class="line">      <span class="keyword">val</span> liveBrokers = <span class="keyword">if</span> (version == <span class="number">0</span>) &#123;</div><div class="line">        <span class="comment">// Version 0 of UpdateMetadataRequest only supports PLAINTEXT.</span></div><div class="line">        controllerContext.liveOrShuttingDownBrokers.map &#123; broker =&gt;</div><div class="line">          <span class="keyword">val</span> securityProtocol = <span class="type">SecurityProtocol</span>.<span class="type">PLAINTEXT</span></div><div class="line">          <span class="keyword">val</span> listenerName = <span class="type">ListenerName</span>.forSecurityProtocol(securityProtocol)</div><div class="line">          <span class="keyword">val</span> node = broker.getNode(listenerName)</div><div class="line">          <span class="keyword">val</span> endPoints = <span class="type">Seq</span>(<span class="keyword">new</span> <span class="type">EndPoint</span>(node.host, node.port, securityProtocol, listenerName))</div><div class="line">          <span class="keyword">new</span> <span class="type">UpdateMetadataRequest</span>.<span class="type">Broker</span>(broker.id, endPoints.asJava, broker.rack.orNull)</div><div class="line">        &#125;</div><div class="line">      &#125; <span class="keyword">else</span> &#123;</div><div class="line">        controllerContext.liveOrShuttingDownBrokers.map &#123; broker =&gt;</div><div class="line">          <span class="keyword">val</span> endPoints = broker.endPoints.map &#123; endPoint =&gt;</div><div class="line">            <span class="keyword">new</span> <span class="type">UpdateMetadataRequest</span>.<span class="type">EndPoint</span>(endPoint.host, endPoint.port, endPoint.securityProtocol, endPoint.listenerName)</div><div class="line">          &#125;</div><div class="line">          <span class="keyword">new</span> <span class="type">UpdateMetadataRequest</span>.<span class="type">Broker</span>(broker.id, endPoints.asJava, broker.rack.orNull)</div><div class="line">        &#125;</div><div class="line">      &#125;</div><div class="line">      <span class="keyword">new</span> <span class="type">UpdateMetadataRequest</span>.<span class="type">Builder</span>(</div><div class="line">        controllerId, controllerEpoch, partitionStates.asJava, liveBrokers.asJava).</div><div class="line">        setVersion(version)</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="comment">//note: 将请求添加到对应的 queue</span></div><div class="line">    updateMetadataRequestBrokerSet.foreach &#123; broker =&gt;</div><div class="line">      controller.sendRequest(broker, <span class="type">ApiKeys</span>.<span class="type">UPDATE_METADATA_KEY</span>, updateMetadataRequest, <span class="literal">null</span>)</div><div class="line">    &#125;</div><div class="line">    updateMetadataRequestBrokerSet.clear() <span class="comment">//note: 清空对应的请求记录</span></div><div class="line">    updateMetadataRequestPartitionInfoMap.clear()</div><div class="line"></div><div class="line">    <span class="comment">//note: StopReplica 请求的处理</span></div><div class="line">    stopReplicaRequestMap.foreach &#123; <span class="keyword">case</span> (broker, replicaInfoList) =&gt;</div><div class="line">      <span class="keyword">val</span> stopReplicaWithDelete = replicaInfoList.filter(_.deletePartition).map(_.replica).toSet</div><div class="line">      <span class="keyword">val</span> stopReplicaWithoutDelete = replicaInfoList.filterNot(_.deletePartition).map(_.replica).toSet</div><div class="line">      debug(<span class="string">"The stop replica request (delete = true) sent to broker %d is %s"</span></div><div class="line">        .format(broker, stopReplicaWithDelete.mkString(<span class="string">","</span>)))</div><div class="line">      debug(<span class="string">"The stop replica request (delete = false) sent to broker %d is %s"</span></div><div class="line">        .format(broker, stopReplicaWithoutDelete.mkString(<span class="string">","</span>)))</div><div class="line"></div><div class="line">      <span class="keyword">val</span> (replicasToGroup, replicasToNotGroup) = replicaInfoList.partition(r =&gt; !r.deletePartition &amp;&amp; r.callback == <span class="literal">null</span>)</div><div class="line"></div><div class="line">      <span class="comment">// Send one StopReplicaRequest for all partitions that require neither delete nor callback. This potentially</span></div><div class="line">      <span class="comment">// changes the order in which the requests are sent for the same partitions, but that's OK.</span></div><div class="line">      <span class="keyword">val</span> stopReplicaRequest = <span class="keyword">new</span> <span class="type">StopReplicaRequest</span>.<span class="type">Builder</span>(controllerId, controllerEpoch, <span class="literal">false</span>,</div><div class="line">        replicasToGroup.map(r =&gt; <span class="keyword">new</span> <span class="type">TopicPartition</span>(r.replica.topic, r.replica.partition)).toSet.asJava)</div><div class="line">      controller.sendRequest(broker, <span class="type">ApiKeys</span>.<span class="type">STOP_REPLICA</span>, stopReplicaRequest)</div><div class="line"></div><div class="line">      replicasToNotGroup.foreach &#123; r =&gt;</div><div class="line">        <span class="keyword">val</span> stopReplicaRequest = <span class="keyword">new</span> <span class="type">StopReplicaRequest</span>.<span class="type">Builder</span>(</div><div class="line">            controllerId, controllerEpoch, r.deletePartition,</div><div class="line">            <span class="type">Set</span>(<span class="keyword">new</span> <span class="type">TopicPartition</span>(r.replica.topic, r.replica.partition)).asJava)</div><div class="line">        controller.sendRequest(broker, <span class="type">ApiKeys</span>.<span class="type">STOP_REPLICA</span>, stopReplicaRequest, r.callback)</div><div class="line">      &#125;</div><div class="line">    &#125;</div><div class="line">    stopReplicaRequestMap.clear()</div><div class="line">  &#125; <span class="keyword">catch</span> &#123;</div><div class="line">    <span class="keyword">case</span> e: <span class="type">Throwable</span> =&gt;</div><div class="line">      <span class="keyword">if</span> (leaderAndIsrRequestMap.nonEmpty) &#123;</div><div class="line">        error(<span class="string">"Haven't been able to send leader and isr requests, current state of "</span> +</div><div class="line">            <span class="string">s"the map is <span class="subst">$leaderAndIsrRequestMap</span>. Exception message: <span class="subst">$e</span>"</span>)</div><div class="line">      &#125;</div><div class="line">      <span class="keyword">if</span> (updateMetadataRequestBrokerSet.nonEmpty) &#123;</div><div class="line">        error(<span class="string">s"Haven't been able to send metadata update requests to brokers <span class="subst">$updateMetadataRequestBrokerSet</span>, "</span> +</div><div class="line">              <span class="string">s"current state of the partition info is <span class="subst">$updateMetadataRequestPartitionInfoMap</span>. Exception message: <span class="subst">$e</span>"</span>)</div><div class="line">      &#125;</div><div class="line">      <span class="keyword">if</span> (stopReplicaRequestMap.nonEmpty) &#123;</div><div class="line">        error(<span class="string">"Haven't been able to send stop replica requests, current state of "</span> +</div><div class="line">            <span class="string">s"the map is <span class="subst">$stopReplicaRequestMap</span>. Exception message: <span class="subst">$e</span>"</span>)</div><div class="line">      &#125;</div><div class="line">      <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">IllegalStateException</span>(e)</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>上面这个方法看着很复杂，其实做的事情很明确，就是将三个集合中的请求发送对应 Broker 的请求队列中，这里简单作一个总结：</p>
<ol>
<li>从 leaderAndIsrRequestMap 集合中构造相应的 LeaderAndIsr 请求，通过 Controller 的 <code>sendRequest()</code> 方法将请求添加到 Broker 对应的 MessageQueue 中，最后清空 leaderAndIsrRequestMap 集合；</li>
<li>从 updateMetadataRequestPartitionInfoMap 集合中构造相应的 UpdateMetadata 请求，，通过 Controller 的 <code>sendRequest()</code> 方法将请求添加到 Broker 对应的 MessageQueue 中，最后清空 updateMetadataRequestBrokerSet 和 updateMetadataRequestPartitionInfoMap 集合；</li>
<li>从 stopReplicaRequestMap 集合中构造相应的 StopReplica 请求，在构造时会根据是否设置删除标志将要涉及的 Partition 分成两类，构造对应的请求，对于要删除数据的 StopReplica 会设置相应的回调函数，然后通过 Controller 的 <code>sendRequest()</code> 方法将请求添加到 Broker 对应的 MessageQueue 中，最后清空 stopReplicaRequestMap 集合。</li>
</ol>
<p>走到这一步，Controller 要发送的请求算是都添加到对应 Broker 的 MessageQueue 中，后台的 RequestSendThread 线程会从这个请求队列中遍历相应的请求，发送给对应的 Broker。</p>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[Kafka 源码解析之 Topic 的新建/扩容/删除（二十）]]></title>
      <url>http://matt33.com/2018/06/18/topic-create-alter-delete/</url>
      <content type="html"><![CDATA[<p>本篇接着讲述 Controller 的功能方面的内容，在 Kafka 中，一个 Topic 的新建、扩容或者删除都是由 Controller 来操作的，本篇文章也是主要聚焦在 Topic 的操作处理上（新建、扩容、删除），实际上 Topic 的创建在 <a href="http://matt33.com/2017/07/21/kafka-topic-create/">Kafka 源码解析之 topic 创建过程（三）</a> 中已经讲述过了，本篇与前面不同的是，本篇主要是从 Controller 角度来讲述，而且是把新建、扩容、删除这三个 Topic 级别的操作放在一起做一个总结。</p>
<h2 id="Topic-新建与扩容"><a href="#Topic-新建与扩容" class="headerlink" title="Topic 新建与扩容"></a>Topic 新建与扩容</h2><p>这里把 Topic 新建与扩容放在一起讲解，主要是因为无论 Topic 是新建还是扩容，在 Kafka 内部其实都是 Partition 的新建，底层的实现机制是一样的，Topic 的新建与扩容的整体流程如下图所示：</p>
<p><img src="/images/kafka/topic-create-alter.png" alt="Topic 新建与扩容流程"></p>
<p>Topic 新建与扩容触发条件的不同如下所示：</p>
<ol>
<li>对于 Topic 扩容，监控的节点是 <code>/brokers/topics/TOPIC_NAME</code>，监控的是具体的 Topic 节点，通过 PartitionStateMachine 的 <code>registerPartitionChangeListener(topic)</code> 方法注册的相应 listener；</li>
<li>对于 Topic 新建，监控的节点是 <code>/brokers/topics</code>，监控的是 Topic 列表，通过 PartitionStateMachine 的 <code>registerTopicChangeListener()</code> 方法注册的相应 listener。</li>
</ol>
<p>下面开始详细讲述这两种情况。</p>
<h3 id="Topic-扩容"><a href="#Topic-扩容" class="headerlink" title="Topic 扩容"></a>Topic 扩容</h3><p>Kafka 提供了 Topic 扩容工具，假设一个 Topic（topic_test）只有一个 partition，这时候我们想把它扩容到两个 Partition，可以通过下面两个命令来实现：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">./bin/kafka-topics.sh --zookeeper zk01:2181/kafka --topic topic_test --alter --partitions 2</div><div class="line">./bin/kafka-topics.sh --zookeeper zk01:2181/kafka --topic topic_test --alter --replica-assignment 1:2,2:1 --partitions 2</div></pre></td></tr></table></figure>
<p>这两种方法的区别是：第二种方法直接指定了要扩容的 Partition 2 的副本需要分配到哪台机器上，这样的话我们可以精确控制到哪些 Topic 放下哪些机器上。</p>
<p>无论是使用哪种方案，上面两条命令产生的结果只有一个，将 Topic 各个 Partition 的副本写入到 ZK 对应的节点上，这样的话 <code>/brokers/topics/topic_test</code> 节点的内容就会发生变化，PartitionModificationsListener 监听器就会被触发，该监听器的处理流程如下：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//note: Partition change 监听器,主要是用于 Partition 扩容的监听</span></div><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">PartitionModificationsListener</span>(<span class="params">protected val controller: <span class="type">KafkaController</span>, topic: <span class="type">String</span></span>) <span class="keyword">extends</span> <span class="title">ControllerZkDataListener</span> </span>&#123;</div><div class="line"></div><div class="line">  <span class="keyword">protected</span> <span class="function"><span class="keyword">def</span> <span class="title">logName</span> </span>= <span class="string">"AddPartitionsListener"</span></div><div class="line"></div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">doHandleDataChange</span></span>(dataPath: <span class="type">String</span>, data: <span class="type">AnyRef</span>) &#123;</div><div class="line">    inLock(controllerContext.controllerLock) &#123;</div><div class="line">      <span class="keyword">try</span> &#123;</div><div class="line">        info(<span class="string">s"Partition modification triggered <span class="subst">$data</span> for path <span class="subst">$dataPath</span>"</span>)</div><div class="line">        <span class="keyword">val</span> partitionReplicaAssignment = zkUtils.getReplicaAssignmentForTopics(<span class="type">List</span>(topic))</div><div class="line">        <span class="comment">//note: 获取新增的 partition 列表及其对应的分配副本列表</span></div><div class="line">        <span class="keyword">val</span> partitionsToBeAdded = partitionReplicaAssignment.filter(p =&gt;</div><div class="line">          !controllerContext.partitionReplicaAssignment.contains(p._1))</div><div class="line">        <span class="comment">//note: 如果该 topic 被标记为删除,那么直接跳过,不再处理,否则创建该 Partition</span></div><div class="line">        <span class="keyword">if</span>(controller.deleteTopicManager.isTopicQueuedUpForDeletion(topic))</div><div class="line">          error(<span class="string">"Skipping adding partitions %s for topic %s since it is currently being deleted"</span></div><div class="line">                .format(partitionsToBeAdded.map(_._1.partition).mkString(<span class="string">","</span>), topic))</div><div class="line">        <span class="keyword">else</span> &#123;</div><div class="line">          <span class="keyword">if</span> (partitionsToBeAdded.nonEmpty) &#123;</div><div class="line">            info(<span class="string">"New partitions to be added %s"</span>.format(partitionsToBeAdded))</div><div class="line">            controllerContext.partitionReplicaAssignment.++=(partitionsToBeAdded)</div><div class="line">            controller.onNewPartitionCreation(partitionsToBeAdded.keySet)<span class="comment">//note: 创建新的 partition</span></div><div class="line">          &#125;</div><div class="line">        &#125;</div><div class="line">      &#125; <span class="keyword">catch</span> &#123;</div><div class="line">        <span class="keyword">case</span> e: <span class="type">Throwable</span> =&gt; error(<span class="string">"Error while handling add partitions for data path "</span> + dataPath, e)</div><div class="line">      &#125;</div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  <span class="comment">// this is not implemented for partition change</span></div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">doHandleDataDeleted</span></span>(parentPath: <span class="type">String</span>): <span class="type">Unit</span> = &#123;&#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>其 <code>doHandleDataChange()</code> 方法的处理流程如下：</p>
<ol>
<li>首先获取该 Topic 在 ZK 的 Partition 副本列表，跟本地的缓存做对比，获取新增的 Partition 列表；</li>
<li>检查这个 Topic 是否被标记为删除，如果被标记了，那么直接跳过，不再处理这个 Partition 扩容的请求；</li>
<li>调用 KafkaController 的 <code>onNewPartitionCreation()</code> 新建该 Partition。</li>
</ol>
<p>下面我们看下 <code>onNewPartitionCreation()</code> 方法，其实现如下：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//note: 用于 Topic Partition 的新建</span></div><div class="line"><span class="comment">//note: 1. 将新创建的 partition 状态置为 NewPartition 状态;</span></div><div class="line"><span class="comment">//note: 2. 将新创建的 Replica 状态置为 NewReplica 状态;</span></div><div class="line"><span class="comment">//note: 3. 将该 Partition 从 NewPartition 改为 OnlinePartition 状态,这期间会 为该 Partition 选举 leader 和 isr，更新到 zk 和 controller的缓存中</span></div><div class="line"><span class="comment">//note: 4. 将副本状态从 NewReplica 改为 OnlineReplica 状态。</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">onNewPartitionCreation</span></span>(newPartitions: <span class="type">Set</span>[<span class="type">TopicAndPartition</span>]) &#123;</div><div class="line">  info(<span class="string">"New partition creation callback for %s"</span>.format(newPartitions.mkString(<span class="string">","</span>)))</div><div class="line">  partitionStateMachine.handleStateChanges(newPartitions, <span class="type">NewPartition</span>)</div><div class="line">  replicaStateMachine.handleStateChanges(controllerContext.replicasForPartition(newPartitions), <span class="type">NewReplica</span>)</div><div class="line">  partitionStateMachine.handleStateChanges(newPartitions, <span class="type">OnlinePartition</span>, offlinePartitionSelector)</div><div class="line">  replicaStateMachine.handleStateChanges(controllerContext.replicasForPartition(newPartitions), <span class="type">OnlineReplica</span>)</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>关于 Partition 的新建，总共分了以下四步：</p>
<ol>
<li>将新创建的 Partition 状态置为 NewPartition 状态，此时 Partition 刚刚创建，只是分配了相应的 Replica 但是还没有 leader 和 isr，不能正常工作;</li>
<li>将该 Partition 对应的 Replica 列表状态设置为 NewReplica 状态，这部分只是将 Replica 的状态设置为了 NewReplica，并没有做其他的处理;</li>
<li>将该 Partition 的状态从 NewPartition 改为 OnlinePartition 状态，这期间会为该 Partition 选举 leader 和 isr，并将结果更新到 ZK 和 Controller 的缓存中，并向该 Partition 的所有副本发送对应的 LeaderAndIsr 信息（发送 LeaderAndIsr 请求的同时也会向所有 Broker 发送该 Topic 的 leader、isr metadata 信息）；</li>
<li>将副本状态从 NewReplica 转移为 OnlineReplica 状态。</li>
</ol>
<p>经过上面几个阶段，一个 Partition 算是真正创建出来，可以正常进行读写工作了，当然上面只是讲述了 Controller 端做的内容，Partition 副本所在节点对 LeaderAndIsr 请求会做更多的工作，这部分会在后面关于 LeaderAndIsr 请求的处理中只能够详细讲述。</p>
<h3 id="Topic-新建"><a href="#Topic-新建" class="headerlink" title="Topic 新建"></a>Topic 新建</h3><p>Kafka 也提供了 Topic 创建的工具，假设我们要创建一个名叫 topic_test，Partition 数为2的 Topic，创建的命令如下：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">./bin/kafka-topics.sh --zookeeper zk01:2181/kafka --topic topic_test --create --partitions 2 --replication-factor 2</div><div class="line">./bin/kafka-topics.sh --zookeeper zk01:2181/kafka --topic topic_test --create --replica-assignment 1:2,2:1 --partitions 2</div></pre></td></tr></table></figure>
<p>跟前面的类似，方法二是可以精确控制新建 Topic 每个 Partition 副本所在位置，Topic 创建的本质上是在 <code>/brokers/topics</code> 下新建一个节点信息，并将 Topic 的分区详情写入进去，当 <code>/brokers/topics</code> 有了新增的 Topic 节点后，会触发 TopicChangeListener 监听器，其实现如下：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//note: 监控 zk 上 Topic 子节点的变化 ,KafkaController 会进行相应的处理</span></div><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">TopicChangeListener</span>(<span class="params">protected val controller: <span class="type">KafkaController</span></span>) <span class="keyword">extends</span> <span class="title">ControllerZkChildListener</span> </span>&#123;</div><div class="line"></div><div class="line">  <span class="keyword">protected</span> <span class="function"><span class="keyword">def</span> <span class="title">logName</span> </span>= <span class="string">"TopicChangeListener"</span></div><div class="line"></div><div class="line">  <span class="comment">//note: 当 zk 上 topic 节点上有变更时,这个方法就会调用</span></div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">doHandleChildChange</span></span>(parentPath: <span class="type">String</span>, children: <span class="type">Seq</span>[<span class="type">String</span>]) &#123;</div><div class="line">    inLock(controllerContext.controllerLock) &#123;</div><div class="line">      <span class="keyword">if</span> (hasStarted.get) &#123;</div><div class="line">        <span class="keyword">try</span> &#123;</div><div class="line">          <span class="keyword">val</span> currentChildren = &#123;</div><div class="line">            debug(<span class="string">"Topic change listener fired for path %s with children %s"</span>.format(parentPath, children.mkString(<span class="string">","</span>)))</div><div class="line">            children.toSet</div><div class="line">          &#125;</div><div class="line">          <span class="comment">//note: 新创建的 topic 列表</span></div><div class="line">          <span class="keyword">val</span> newTopics = currentChildren -- controllerContext.allTopics</div><div class="line">          <span class="comment">//note: 已经删除的 topic 列表</span></div><div class="line">          <span class="keyword">val</span> deletedTopics = controllerContext.allTopics -- currentChildren</div><div class="line">          controllerContext.allTopics = currentChildren</div><div class="line"></div><div class="line">          <span class="comment">//note: 新创建 topic 对应的 partition 列表及副本列表添加到 Controller 的缓存中</span></div><div class="line">          <span class="keyword">val</span> addedPartitionReplicaAssignment = zkUtils.getReplicaAssignmentForTopics(newTopics.toSeq)</div><div class="line">          <span class="comment">//note: Controller 从缓存中把已经删除 partition 过滤掉</span></div><div class="line">          controllerContext.partitionReplicaAssignment = controllerContext.partitionReplicaAssignment.filter(p =&gt;</div><div class="line">            !deletedTopics.contains(p._1.topic))</div><div class="line">          controllerContext.partitionReplicaAssignment.++=(addedPartitionReplicaAssignment)<span class="comment">//note: 将新增的 tp-replicas 更新到缓存中</span></div><div class="line">          info(<span class="string">"New topics: [%s], deleted topics: [%s], new partition replica assignment [%s]"</span>.format(newTopics,</div><div class="line">            deletedTopics, addedPartitionReplicaAssignment))</div><div class="line">          <span class="keyword">if</span> (newTopics.nonEmpty)<span class="comment">//note: 处理新建的 topic</span></div><div class="line">            controller.onNewTopicCreation(newTopics, addedPartitionReplicaAssignment.keySet)</div><div class="line">        &#125; <span class="keyword">catch</span> &#123;</div><div class="line">          <span class="keyword">case</span> e: <span class="type">Throwable</span> =&gt; error(<span class="string">"Error while handling new topic"</span>, e)</div><div class="line">        &#125;</div><div class="line">      &#125;</div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>只要 <code>/brokers/topics</code> 下子节点信息有变化（topic 新增或者删除），TopicChangeListener 都会被触发，其 <code>doHandleChildChange()</code> 方法的处理流程如下：</p>
<ol>
<li>获取 ZK 当前的所有 Topic 列表，根据本地缓存的 Topic 列表记录，可以得到新增的 Topic 记录与已经删除的 Topic 列表；</li>
<li>将新增 Topic 的相信信息更新到 Controller 的缓存中，将已经删除的 Topic 从 Controller 的副本缓存中移除；</li>
<li>调用 KafkaController 的 <code>onNewTopicCreation()</code> 方法创建该 topic。</li>
</ol>
<p>接着看下 <code>onNewTopicCreation()</code> 方法实现</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//note: 当 partition state machine 监控到有新 topic 或 partition 时,这个方法将会被调用</span></div><div class="line"><span class="comment">//note: 1. 注册 partition change listener, 监听 Parition 变化;</span></div><div class="line"><span class="comment">//note: 2. 触发 the new partition, 也即是 onNewPartitionCreation()</span></div><div class="line"><span class="comment">//note: 3. 发送 metadata 请求给所有的 Broker</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">onNewTopicCreation</span></span>(topics: <span class="type">Set</span>[<span class="type">String</span>], newPartitions: <span class="type">Set</span>[<span class="type">TopicAndPartition</span>]) &#123;</div><div class="line">  info(<span class="string">"New topic creation callback for %s"</span>.format(newPartitions.mkString(<span class="string">","</span>)))</div><div class="line">  <span class="comment">// subscribe to partition changes</span></div><div class="line">  topics.foreach(topic =&gt; partitionStateMachine.registerPartitionChangeListener(topic))</div><div class="line">  onNewPartitionCreation(newPartitions)</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>上述方法主要做了两件事：</p>
<ol>
<li>注册这个 topic 的 PartitionModificationsListener 监听器；</li>
<li>通过 <code>onNewPartitionCreation()</code> 创建该 Topic 的所有 Partition。</li>
</ol>
<p><code>onNewPartitionCreation()</code> 的实现在前面 Topic 扩容部分已经讲述过，这里不再重复，最好参考前面流程图来梳理 Topic 扩容和新建的整个过程。</p>
<h2 id="Topic-删除"><a href="#Topic-删除" class="headerlink" title="Topic 删除"></a>Topic 删除</h2><p>Kafka Topic 删除这部分的逻辑是一个单独线程去做的，这个线程是在 Controller 启动时初始化和启动的。</p>
<h3 id="TopicDeletionManager-初始化"><a href="#TopicDeletionManager-初始化" class="headerlink" title="TopicDeletionManager 初始化"></a>TopicDeletionManager 初始化</h3><p>TopicDeletionManager 启动实现如下所示：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/**</span></div><div class="line"> * Invoked at the end of new controller initiation</div><div class="line"> */</div><div class="line"><span class="comment">//note: Controller 初始化完成,触发这个操作,删除 topic 线程启动</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">start</span></span>() &#123;</div><div class="line">  <span class="keyword">if</span> (isDeleteTopicEnabled) &#123;</div><div class="line">    deleteTopicsThread = <span class="keyword">new</span> <span class="type">DeleteTopicsThread</span>()</div><div class="line">    <span class="keyword">if</span> (topicsToBeDeleted.nonEmpty)</div><div class="line">      deleteTopicStateChanged.set(<span class="literal">true</span>)</div><div class="line">    deleteTopicsThread.start() <span class="comment">//note: 启动 DeleteTopicsThread</span></div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>TopicDeletionManager 启动时只是初始化了一个 DeleteTopicsThread 线程，并启动该线程。TopicDeletionManager 这个类从名字上去看，它是 Topic 删除的管理器，它是如何实现 Topic 删除管理呢，这里先看下该类的几个重要的成员变量：</p>
<ol>
<li>topicsToBeDeleted：需要删除的 Topic 列表，每当有新的 topic 需要删除时，Controller 就通过 <code>enqueueTopicsForDeletion()</code> 方法将 Topic 添加到这个列表中，而 DeleteTopicsThread 线程则会从列表拿到需要进行删除的 Topic 信息；</li>
<li>partitionsToBeDeleted：需要删除的 Partition 列表，跟上面的 Topic 列表保持一致，只不过纬度不同；</li>
<li>topicsIneligibleForDeletion：非法删除的 Topic 列表，当一个 Topic 正在进行副本迁移、leader 选举或者有副本 dead 的情况下，该 Topic 都会设置被非法删除状态，只有恢复正常后，这个状态才会解除，处在这个状态的 Topic 是无法删除的。</li>
</ol>
<h3 id="Topic-删除整体流程"><a href="#Topic-删除整体流程" class="headerlink" title="Topic 删除整体流程"></a>Topic 删除整体流程</h3><p>前面一小节，简单介绍了 TopicDeletionManager、DeleteTopicsThread 的启动以及它们之间的关系，这里我们看下一个 Topic 被设置删除后，其处理的整理流程，简单做了一个小图，如下所示：</p>
<p><img src="/images/kafka/topic-delete.png" alt="Topic 删除整理流程"></p>
<p>这里先简单讲述上面的流程，当一个 Topic 设置为删除后：</p>
<ol>
<li>首先 DeleteTopicsListener 会被触发，然后通过 <code>enqueueTopicsForDeletion()</code> 方法将 Topic 添加到要删除的 Topic 列表中；</li>
<li>DeleteTopicsThread 这个线程会不断调用 <code>doWork()</code> 方法，这个方法被调用时，它会遍历 <code>topicsToBeDeleted</code> 中的所有 Topic 列表；</li>
<li>对于之前没有处理过的 Topic（之前还没有开始删除），会通过 TopicDeletionManager 的 <code>onTopicDeletion()</code> 方法执行删除操作；</li>
<li>如果 Topic 删除完成（所有 Replica 的状态都变为 ReplicaDeletionSuccessful 状态），那么就执行 TopicDeletionManager 的 <code>completeDeleteTopic()</code> 完成删除流程，即更新状态信息，并将 Topic 的 meta 信息从缓存和 ZK 中清除。</li>
</ol>
<h3 id="Topic-删除详细实现"><a href="#Topic-删除详细实现" class="headerlink" title="Topic 删除详细实现"></a>Topic 删除详细实现</h3><p>先看下 DeleteTopicsListener 的实现，如下：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//note: 删除 Topic 包括以下操作:</span></div><div class="line"><span class="comment">//note: 1. 如果要删除的 topic 存在,将 Topic 添加到 Topic 将要删除的缓存中;</span></div><div class="line"><span class="comment">//note: 2. 如果有 Topic 将要被删除,那么将触发 Topic 删除线程</span></div><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">DeleteTopicsListener</span>(<span class="params">protected val controller: <span class="type">KafkaController</span></span>) <span class="keyword">extends</span> <span class="title">ControllerZkChildListener</span> </span>&#123;</div><div class="line">  <span class="keyword">private</span> <span class="keyword">val</span> zkUtils = controllerContext.zkUtils</div><div class="line"></div><div class="line">  <span class="keyword">protected</span> <span class="function"><span class="keyword">def</span> <span class="title">logName</span> </span>= <span class="string">"DeleteTopicsListener"</span></div><div class="line"></div><div class="line">  <span class="comment">/**</span></div><div class="line">   * Invoked when a topic is being deleted</div><div class="line">   * @throws Exception On any error.</div><div class="line">   */</div><div class="line">  <span class="comment">//note: 当 topic 需要被删除时,才会触发</span></div><div class="line">  <span class="meta">@throws</span>[<span class="type">Exception</span>]</div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">doHandleChildChange</span></span>(parentPath: <span class="type">String</span>, children: <span class="type">Seq</span>[<span class="type">String</span>]) &#123;</div><div class="line">    inLock(controllerContext.controllerLock) &#123;</div><div class="line">      <span class="keyword">var</span> topicsToBeDeleted = children.toSet</div><div class="line">      debug(<span class="string">"Delete topics listener fired for topics %s to be deleted"</span>.format(topicsToBeDeleted.mkString(<span class="string">","</span>)))</div><div class="line">      <span class="comment">//note: 不存在的、需要删除的 topic, 直接清除 zk 上的记录</span></div><div class="line">      <span class="keyword">val</span> nonExistentTopics = topicsToBeDeleted -- controllerContext.allTopics</div><div class="line">      <span class="keyword">if</span> (nonExistentTopics.nonEmpty) &#123;</div><div class="line">        warn(<span class="string">"Ignoring request to delete non-existing topics "</span> + nonExistentTopics.mkString(<span class="string">","</span>))</div><div class="line">        nonExistentTopics.foreach(topic =&gt; zkUtils.deletePathRecursive(getDeleteTopicPath(topic)))</div><div class="line">      &#125;</div><div class="line">      topicsToBeDeleted --= nonExistentTopics</div><div class="line">      <span class="keyword">if</span> (controller.config.deleteTopicEnable) &#123; <span class="comment">//note: 如果允许 topic 删除</span></div><div class="line">        <span class="keyword">if</span> (topicsToBeDeleted.nonEmpty) &#123; <span class="comment">//note: 有 Topic 需要删除</span></div><div class="line">          info(<span class="string">"Starting topic deletion for topics "</span> + topicsToBeDeleted.mkString(<span class="string">","</span>))</div><div class="line">          <span class="comment">// mark topic ineligible for deletion if other state changes are in progress</span></div><div class="line">          topicsToBeDeleted.foreach &#123; topic =&gt; <span class="comment">//note: 如果 topic 正在最优 leader 选举或正在迁移,那么将 topic 标记为非法删除状态</span></div><div class="line">            <span class="keyword">val</span> preferredReplicaElectionInProgress =</div><div class="line">              controllerContext.partitionsUndergoingPreferredReplicaElection.map(_.topic).contains(topic)</div><div class="line">            <span class="keyword">val</span> partitionReassignmentInProgress =</div><div class="line">              controllerContext.partitionsBeingReassigned.keySet.map(_.topic).contains(topic)</div><div class="line">            <span class="keyword">if</span> (preferredReplicaElectionInProgress || partitionReassignmentInProgress)</div><div class="line">              controller.deleteTopicManager.markTopicIneligibleForDeletion(<span class="type">Set</span>(topic))</div><div class="line">          &#125;</div><div class="line">          <span class="comment">// add topic to deletion list</span></div><div class="line">          <span class="comment">//note: 将要删除的 topic 添加到待删除的 topic</span></div><div class="line">          controller.deleteTopicManager.enqueueTopicsForDeletion(topicsToBeDeleted)</div><div class="line">        &#125;</div><div class="line">      &#125; <span class="keyword">else</span> &#123;</div><div class="line">        <span class="comment">// If delete topic is disabled remove entries under zookeeper path : /admin/delete_topics</span></div><div class="line">        <span class="keyword">for</span> (topic &lt;- topicsToBeDeleted) &#123;</div><div class="line">          info(<span class="string">"Removing "</span> + getDeleteTopicPath(topic) + <span class="string">" since delete topic is disabled"</span>)</div><div class="line">          zkUtils.zkClient.delete(getDeleteTopicPath(topic))</div><div class="line">        &#125;</div><div class="line">      &#125;</div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">doHandleDataDeleted</span></span>(dataPath: <span class="type">String</span>) &#123;&#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>其 <code>doHandleChildChange()</code> 的实现逻辑如下：</p>
<ol>
<li>根据要删除的 Topic 列表，过滤出那些不存在的 Topic 列表，直接从 ZK 中清除（只是从 <code>/admin/delete_topics</code> 中移除）；</li>
<li>如果集群不允许 Topic 删除，直接从 ZK 中清除（只是从 <code>/admin/delete_topics</code> 中移除）这些 Topic 列表，结束流程；</li>
<li>如果这个列表中有正在进行副本迁移或 leader 选举的 Topic，那么先将这些 Topic 加入到 <code>topicsIneligibleForDeletion</code> 中，即标记为非法删除；</li>
<li>通过 <code>enqueueTopicsForDeletion()</code> 方法将 Topic 添加到要删除的 Topic 列表（<code>topicsToBeDeleted</code>）、将 Partition 添加到要删除的 Partition 列表中（<code>partitionsToBeDeleted</code>）。</li>
</ol>
<p>接下来，看下 Topic 删除线程 DeleteTopicsThread 的实现，如下所示：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div></pre></td><td class="code"><pre><div class="line">/note: topic 删除线程</div><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">DeleteTopicsThread</span>(<span class="params"></span>) <span class="keyword">extends</span> <span class="title">ShutdownableThread</span>(<span class="params">name = "delete-topics-thread-" + controller.config.brokerId, isInterruptible = false</span>) </span>&#123;</div><div class="line">  <span class="keyword">val</span> zkUtils = controllerContext.zkUtils</div><div class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">doWork</span></span>() &#123;</div><div class="line">    awaitTopicDeletionNotification()</div><div class="line"></div><div class="line">    <span class="keyword">if</span> (!isRunning.get)</div><div class="line">      <span class="keyword">return</span></div><div class="line"></div><div class="line">    inLock(controllerContext.controllerLock) &#123;</div><div class="line">      <span class="comment">//note: 要删除的 topic 列表</span></div><div class="line">      <span class="keyword">val</span> topicsQueuedForDeletion = <span class="type">Set</span>.empty[<span class="type">String</span>] ++ topicsToBeDeleted</div><div class="line"></div><div class="line">      <span class="keyword">if</span>(topicsQueuedForDeletion.nonEmpty)</div><div class="line">        info(<span class="string">"Handling deletion for topics "</span> + topicsQueuedForDeletion.mkString(<span class="string">","</span>))</div><div class="line"></div><div class="line">      topicsQueuedForDeletion.foreach &#123; topic =&gt;</div><div class="line">      <span class="comment">// if all replicas are marked as deleted successfully, then topic deletion is done</span></div><div class="line">        <span class="keyword">if</span>(controller.replicaStateMachine.areAllReplicasForTopicDeleted(topic)) &#123;<span class="comment">//note: 如果 Topic 所有副本都删除成功的情况下</span></div><div class="line">          <span class="comment">// clear up all state for this topic from controller cache and zookeeper</span></div><div class="line">          <span class="comment">//note: 从 controller 的缓存和 zk 中清除这个 topic 的所有记录,这个 topic 彻底删除成功了</span></div><div class="line">          completeDeleteTopic(topic)</div><div class="line">          info(<span class="string">"Deletion of topic %s successfully completed"</span>.format(topic))</div><div class="line">        &#125; <span class="keyword">else</span> &#123;</div><div class="line">          <span class="keyword">if</span>(controller.replicaStateMachine.isAtLeastOneReplicaInDeletionStartedState(topic)) &#123;</div><div class="line">            <span class="comment">//note: Topic 的副本至少有一个状态为 ReplicaDeletionStarted 时</span></div><div class="line">            <span class="comment">// ignore since topic deletion is in progress</span></div><div class="line">            <span class="comment">//note: 过滤出 Topic 中副本状态为 ReplicaDeletionStarted 的 Partition 列表</span></div><div class="line">            <span class="keyword">val</span> replicasInDeletionStartedState = controller.replicaStateMachine.replicasInState(topic, <span class="type">ReplicaDeletionStarted</span>)</div><div class="line">            <span class="comment">//note: 表明了上面这些副本正在删除中</span></div><div class="line">            <span class="keyword">val</span> replicaIds = replicasInDeletionStartedState.map(_.replica)</div><div class="line">            <span class="keyword">val</span> partitions = replicasInDeletionStartedState.map(r =&gt; <span class="type">TopicAndPartition</span>(r.topic, r.partition))</div><div class="line">            info(<span class="string">"Deletion for replicas %s for partition %s of topic %s in progress"</span>.format(replicaIds.mkString(<span class="string">","</span>),</div><div class="line">              partitions.mkString(<span class="string">","</span>), topic))</div><div class="line">          &#125; <span class="keyword">else</span> &#123; <span class="comment">//note:副本既没有全部删除完成、也没有一个副本是在删除过程中，证明这个 topic 还没有开始删除或者删除完成但是至少一个副本删除失败</span></div><div class="line">            <span class="comment">// if you come here, then no replica is in TopicDeletionStarted and all replicas are not in</span></div><div class="line">            <span class="comment">// TopicDeletionSuccessful. That means, that either given topic haven't initiated deletion</span></div><div class="line">            <span class="comment">// or there is at least one failed replica (which means topic deletion should be retried).</span></div><div class="line">            <span class="keyword">if</span>(controller.replicaStateMachine.isAnyReplicaInState(topic, <span class="type">ReplicaDeletionIneligible</span>)) &#123;</div><div class="line">              <span class="comment">//note: 如果有副本删除失败,那么进行重试操作</span></div><div class="line">              <span class="comment">// mark topic for deletion retry</span></div><div class="line">              markTopicForDeletionRetry(topic)</div><div class="line">            &#125;</div><div class="line">          &#125;</div><div class="line">        &#125;</div><div class="line">        <span class="comment">// Try delete topic if it is eligible for deletion.</span></div><div class="line">        <span class="keyword">if</span>(isTopicEligibleForDeletion(topic)) &#123; <span class="comment">//note: 如果 topic 可以被删除</span></div><div class="line">          info(<span class="string">"Deletion of topic %s (re)started"</span>.format(topic))</div><div class="line">          <span class="comment">// topic deletion will be kicked off</span></div><div class="line">          <span class="comment">//note: 开始删除 topic</span></div><div class="line">          onTopicDeletion(<span class="type">Set</span>(topic))</div><div class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span>(isTopicIneligibleForDeletion(topic)) &#123;</div><div class="line">          info(<span class="string">"Not retrying deletion of topic %s at this time since it is marked ineligible for deletion"</span>.format(topic))</div><div class="line">        &#125;</div><div class="line">      &#125;</div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p><code>doWork()</code> 方法处理逻辑如下：</p>
<ol>
<li>遍历所有要删除的 Topic，进行如下处理；</li>
<li>如果该 Topic 的所有副本都下线成功（状态为 ReplicaDeletionSuccessful）时，那么执行 <code>completeDeleteTopic()</code> 方法完成 Topic 的删除；</li>
<li>否则，如果 Topic 在删除过程有失败的副本（状态为 ReplicaDeletionIneligible），那么执行 <code>markTopicForDeletionRetry()</code> 将失败的 Replica 状态设置为 OfflineReplica；</li>
<li>判断 Topic 是否允许删除（不在非法删除的集合中就代表运允许），调用 <code>onTopicDeletion()</code> 执行 Topic 删除。</li>
</ol>
<p>先看下 <code>onTopicDeletion()</code> 方法，这是 Topic 最开始删除时的实现，如下所示：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//note: Topic 删除</span></div><div class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">onTopicDeletion</span></span>(topics: <span class="type">Set</span>[<span class="type">String</span>]) &#123;</div><div class="line">  info(<span class="string">"Topic deletion callback for %s"</span>.format(topics.mkString(<span class="string">","</span>)))</div><div class="line">  <span class="comment">// send update metadata so that brokers stop serving data for topics to be deleted</span></div><div class="line">  <span class="keyword">val</span> partitions = topics.flatMap(controllerContext.partitionsForTopic) <span class="comment">//note: topic 的所有 Partition</span></div><div class="line">  controller.sendUpdateMetadataRequest(controllerContext.liveOrShuttingDownBrokerIds.toSeq, partitions) <span class="comment">//note: 更新meta</span></div><div class="line">  <span class="keyword">val</span> partitionReplicaAssignmentByTopic = controllerContext.partitionReplicaAssignment.groupBy(p =&gt; p._1.topic)</div><div class="line">  topics.foreach &#123; topic =&gt; <span class="comment">//note:  删除 topic 的每一个 Partition</span></div><div class="line">    onPartitionDeletion(partitionReplicaAssignmentByTopic(topic).keySet)</div><div class="line">  &#125;</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="comment">//note: 这个方法是用于 delete-topic, 用于删除 topic 的所有 partition</span></div><div class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">onPartitionDeletion</span></span>(partitionsToBeDeleted: <span class="type">Set</span>[<span class="type">TopicAndPartition</span>]) &#123;</div><div class="line">  info(<span class="string">"Partition deletion callback for %s"</span>.format(partitionsToBeDeleted.mkString(<span class="string">","</span>)))</div><div class="line">  <span class="keyword">val</span> replicasPerPartition = controllerContext.replicasForPartition(partitionsToBeDeleted)</div><div class="line">  startReplicaDeletion(replicasPerPartition)</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>Topic 的删除的真正实现方法还是在 <code>startReplicaDeletion()</code> 方法中，Topic 删除时，会先调用 <code>onPartitionDeletion()</code> 方法删除所有的 Partition，然后在 Partition 删除时，执行 <code>startReplicaDeletion()</code> 方法删除该 Partition 的副本，该方法的实现如下：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//note: 被 onPartitionDeletion 方法触发,删除副本具体的实现的地方</span></div><div class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">startReplicaDeletion</span></span>(replicasForTopicsToBeDeleted: <span class="type">Set</span>[<span class="type">PartitionAndReplica</span>]) &#123;</div><div class="line">  replicasForTopicsToBeDeleted.groupBy(_.topic).keys.foreach &#123; topic =&gt;</div><div class="line">    <span class="comment">//note: topic 所有存活的 replica</span></div><div class="line">    <span class="keyword">val</span> aliveReplicasForTopic = controllerContext.allLiveReplicas().filter(p =&gt; p.topic == topic)</div><div class="line">    <span class="comment">//note: topic 的 dead replica</span></div><div class="line">    <span class="keyword">val</span> deadReplicasForTopic = replicasForTopicsToBeDeleted -- aliveReplicasForTopic</div><div class="line">    <span class="comment">//note: topic 中已经处于 ReplicaDeletionSuccessful 状态的副本</span></div><div class="line">    <span class="keyword">val</span> successfullyDeletedReplicas = controller.replicaStateMachine.replicasInState(topic, <span class="type">ReplicaDeletionSuccessful</span>)</div><div class="line">    <span class="comment">//note: 还没有成功删除的、存活的副本</span></div><div class="line">    <span class="keyword">val</span> replicasForDeletionRetry = aliveReplicasForTopic -- successfullyDeletedReplicas</div><div class="line">    <span class="comment">// move dead replicas directly to failed state</span></div><div class="line">    <span class="comment">//note: 将 dead replica 设置为 ReplicaDeletionIneligible（删除无效的状态）</span></div><div class="line">    replicaStateMachine.handleStateChanges(deadReplicasForTopic, <span class="type">ReplicaDeletionIneligible</span>)</div><div class="line">    <span class="comment">// send stop replica to all followers that are not in the OfflineReplica state so they stop sending fetch requests to the leader</span></div><div class="line">    <span class="comment">//note: 将 replicasForDeletionRetry 设置为 OfflineReplica（发送 StopReplica 请求）</span></div><div class="line">    replicaStateMachine.handleStateChanges(replicasForDeletionRetry, <span class="type">OfflineReplica</span>)</div><div class="line">    debug(<span class="string">"Deletion started for replicas %s"</span>.format(replicasForDeletionRetry.mkString(<span class="string">","</span>)))</div><div class="line">    <span class="comment">//note: 将 replicasForDeletionRetry 设置为 ReplicaDeletionStarted 状态</span></div><div class="line">    controller.replicaStateMachine.handleStateChanges(replicasForDeletionRetry, <span class="type">ReplicaDeletionStarted</span>,</div><div class="line">      <span class="keyword">new</span> <span class="type">Callbacks</span>.<span class="type">CallbackBuilder</span>().stopReplicaCallback(deleteTopicStopReplicaCallback).build)</div><div class="line">    <span class="keyword">if</span>(deadReplicasForTopic.nonEmpty) &#123; <span class="comment">//note: 将 topic 标记为不能删除</span></div><div class="line">      debug(<span class="string">"Dead Replicas (%s) found for topic %s"</span>.format(deadReplicasForTopic.mkString(<span class="string">","</span>), topic))</div><div class="line">      markTopicIneligibleForDeletion(<span class="type">Set</span>(topic))</div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>该方法的执行逻辑如下：</p>
<ol>
<li>首先获取当前集群所有存活的 broker 信息，根据这个信息可以知道 Topic 哪些副本所在节点是处于 dead 状态；</li>
<li>找到那些已经成功删除的 Replica 列表（状态为 ReplicaDeletionSuccessful），进而可以得到那些还没有成功删除、并且存活的 Replica 列表（<code>replicasForDeletionRetry</code>）；</li>
<li>将处于 dead 节点上的 Replica 的状态设置为 ReplicaDeletionIneligible 状态；</li>
<li>然后重新删除 replicasForDeletionRetry 列表中的副本，先将其状态转移为 OfflineReplica，再转移为 ReplicaDeletionStarted 状态（真正从发送 StopReplica +从物理上删除数据）；</li>
<li>如果有 Replica 所在的机器处于 dead 状态，那么将 Topic 设置为非法删除状态。</li>
</ol>
<p>在将副本状态从 OfflineReplica 转移成 ReplicaDeletionStarted 时，会设置一个回调方法 <code>deleteTopicStopReplicaCallback()</code>，该方法会将删除成功的 Replica 设置为 ReplicaDeletionSuccessful 状态，删除失败的 Replica 设置为 ReplicaDeletionIneligible 状态（需要根据 StopReplica 请求处理的过程，看下哪些情况下 Replica 会删除失败，这个会在后面讲解）。</p>
<p>下面看下这个方法 <code>completeDeleteTopic()</code>，当一个 Topic 的所有 Replica 都删除成功时，即其状态都在 ReplicaDeletionSuccessful 时，会调用这个方法，如下所示：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//note: topic 删除后,从 controller 缓存、状态机以及 zk 移除这个 topic 相关记录</span></div><div class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">completeDeleteTopic</span></span>(topic: <span class="type">String</span>) &#123;</div><div class="line">  <span class="comment">// deregister partition change listener on the deleted topic. This is to prevent the partition change listener</span></div><div class="line">  <span class="comment">// firing before the new topic listener when a deleted topic gets auto created</span></div><div class="line">  <span class="comment">//note: 1. 取消 zk 对这个 topic 的 partition-modify-listener</span></div><div class="line">  partitionStateMachine.deregisterPartitionChangeListener(topic)</div><div class="line">  <span class="comment">//note: 2. 过滤出副本状态为 ReplicaDeletionSuccessful 的副本列表</span></div><div class="line">  <span class="keyword">val</span> replicasForDeletedTopic = controller.replicaStateMachine.replicasInState(topic, <span class="type">ReplicaDeletionSuccessful</span>)</div><div class="line">  <span class="comment">// controller will remove this replica from the state machine as well as its partition assignment cache</span></div><div class="line">  <span class="comment">//note: controller 将会从副本状态机移除这些副本</span></div><div class="line">  replicaStateMachine.handleStateChanges(replicasForDeletedTopic, <span class="type">NonExistentReplica</span>)</div><div class="line">  <span class="keyword">val</span> partitionsForDeletedTopic = controllerContext.partitionsForTopic(topic)</div><div class="line">  <span class="comment">// move respective partition to OfflinePartition and NonExistentPartition state</span></div><div class="line">  <span class="comment">//note: 3. 从分区状态机中下线并移除这个 topic 的分区</span></div><div class="line">  partitionStateMachine.handleStateChanges(partitionsForDeletedTopic, <span class="type">OfflinePartition</span>)</div><div class="line">  partitionStateMachine.handleStateChanges(partitionsForDeletedTopic, <span class="type">NonExistentPartition</span>)</div><div class="line">  topicsToBeDeleted -= topic <span class="comment">//note: 删除成功,从删除 topic 列表中移除</span></div><div class="line">  partitionsToBeDeleted.retain(_.topic != topic) <span class="comment">//note: 从 partitionsToBeDeleted 移除这个 topic</span></div><div class="line">  <span class="keyword">val</span> zkUtils = controllerContext.zkUtils</div><div class="line">  <span class="comment">//note: 4. 删除 zk 上关于这个 topic 的相关记录</span></div><div class="line">  zkUtils.zkClient.deleteRecursive(getTopicPath(topic))</div><div class="line">  zkUtils.zkClient.deleteRecursive(getEntityConfigPath(<span class="type">ConfigType</span>.<span class="type">Topic</span>, topic))</div><div class="line">  zkUtils.zkClient.delete(getDeleteTopicPath(topic))</div><div class="line">  <span class="comment">//note: 5. 从 controller 的所有缓存中再次移除关于这个 topic 的信息</span></div><div class="line">  controllerContext.removeTopic(topic)</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>当一个 Topic 所有副本都删除后，会进行如下处理：</p>
<ol>
<li>取消对该 Topic 的 partition-modify-listener 监听器；</li>
<li>将状态为 ReplicaDeletionSuccessful 的副本状态都转移成 NonExistentReplica；</li>
<li>将该 Topic Partition 状态先后转移成 OfflinePartition、NonExistentPartition 状态，正式下线了该 Partition；</li>
<li>从分区状态机和副本状态机中移除这个 Topic 记录；</li>
<li>从 Controller 缓存和 ZK 中清除这个 Topic 的相关记录。</li>
</ol>
<p>至此，一个 Topic 算是真正删除完成。</p>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[Kafka 源码解析之 Broker 上线下线（十九）]]></title>
      <url>http://matt33.com/2018/06/17/broker-online-offline/</url>
      <content type="html"><![CDATA[<p>本篇接着讲述 Controller 对于监听器的处理内容 —— Broker 节点上下线的处理流程。每台 Broker 在上线时，都会与 ZK 建立一个建立一个 session，并在 <code>/brokers/ids</code> 下注册一个节点，节点名字就是 broker id，这个节点是临时节点，该节点内部会有这个 Broker 的详细节点信息。Controller 会监听 <code>/brokers/ids</code> 这个路径下的所有子节点，如果有新的节点出现，那么就代表有新的 Broker 上线，如果有节点消失，就代表有 broker 下线，Controller 会进行相应的处理，Kafka 就是利用 ZK 的这种 watch 机制及临时节点的特性来完成集群 Broker 的上下线，本文将会深入讲解这一过程。</p>
<h2 id="BrokerChangeListener"><a href="#BrokerChangeListener" class="headerlink" title="BrokerChangeListener"></a>BrokerChangeListener</h2><p>KafkaController 在启动时，会通过副本状态机注册一个监控 broker 上下线的监听器，通过 ReplicaStateMachine 的 <code>registerListeners()</code> 方法实现的，该方法的实现如下：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"> <span class="comment">// register ZK listeners of the replica state machine</span></div><div class="line"> <span class="function"><span class="keyword">def</span> <span class="title">registerListeners</span></span>() &#123;</div><div class="line">   <span class="comment">// register broker change listener</span></div><div class="line">   registerBrokerChangeListener() <span class="comment">//note: 监听【/brokers/ids】，broker 的上线下线</span></div><div class="line"> &#125;</div><div class="line"></div><div class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">registerBrokerChangeListener</span></span>() = &#123;</div><div class="line">  zkUtils.zkClient.subscribeChildChanges(<span class="type">ZkUtils</span>.<span class="type">BrokerIdsPath</span>, brokerChangeListener)</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>BrokerChangeListener 是监听 <code>/brokers/ids</code> 节点的监听器，当该节点有变化时会触发 <code>doHandleChildChange()</code> 方法，具体实现如下：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//note: 如果 【/brokers/ids】 目录下子节点有变化将会触发这个操作</span></div><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">BrokerChangeListener</span>(<span class="params">protected val controller: <span class="type">KafkaController</span></span>) <span class="keyword">extends</span> <span class="title">ControllerZkChildListener</span> </span>&#123;</div><div class="line"></div><div class="line">  <span class="keyword">protected</span> <span class="function"><span class="keyword">def</span> <span class="title">logName</span> </span>= <span class="string">"BrokerChangeListener"</span></div><div class="line"></div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">doHandleChildChange</span></span>(parentPath: <span class="type">String</span>, currentBrokerList: <span class="type">Seq</span>[<span class="type">String</span>]) &#123;</div><div class="line">    info(<span class="string">"Broker change listener fired for path %s with children %s"</span>.format(parentPath, currentBrokerList.sorted.mkString(<span class="string">","</span>)))</div><div class="line">    inLock(controllerContext.controllerLock) &#123;</div><div class="line">      <span class="keyword">if</span> (hasStarted.get) &#123;</div><div class="line">        <span class="type">ControllerStats</span>.leaderElectionTimer.time &#123;</div><div class="line">          <span class="keyword">try</span> &#123;</div><div class="line">            <span class="comment">//note: 当前 zk 的 broker 列表</span></div><div class="line">            <span class="keyword">val</span> curBrokers = currentBrokerList.map(_.toInt).toSet.flatMap(zkUtils.getBrokerInfo)</div><div class="line">            <span class="comment">//note: ZK 中的 broker id 列表</span></div><div class="line">            <span class="keyword">val</span> curBrokerIds = curBrokers.map(_.id)</div><div class="line">            <span class="comment">//note: Controller 缓存中的 broker 列表</span></div><div class="line">            <span class="keyword">val</span> liveOrShuttingDownBrokerIds = controllerContext.liveOrShuttingDownBrokerIds</div><div class="line">            <span class="comment">//note: 新上线的 broker id 列表</span></div><div class="line">            <span class="keyword">val</span> newBrokerIds = curBrokerIds -- liveOrShuttingDownBrokerIds</div><div class="line">            <span class="comment">//note: 掉线的 broker id 列表</span></div><div class="line">            <span class="keyword">val</span> deadBrokerIds = liveOrShuttingDownBrokerIds -- curBrokerIds</div><div class="line">            <span class="comment">//note: 新上线的 Broker 列表</span></div><div class="line">            <span class="keyword">val</span> newBrokers = curBrokers.filter(broker =&gt; newBrokerIds(broker.id))</div><div class="line">            controllerContext.liveBrokers = curBrokers <span class="comment">//note: 更新缓存中当前 broker 列表</span></div><div class="line">            <span class="keyword">val</span> newBrokerIdsSorted = newBrokerIds.toSeq.sorted</div><div class="line">            <span class="keyword">val</span> deadBrokerIdsSorted = deadBrokerIds.toSeq.sorted</div><div class="line">            <span class="keyword">val</span> liveBrokerIdsSorted = curBrokerIds.toSeq.sorted</div><div class="line">            info(<span class="string">"Newly added brokers: %s, deleted brokers: %s, all live brokers: %s"</span></div><div class="line">              .format(newBrokerIdsSorted.mkString(<span class="string">","</span>), deadBrokerIdsSorted.mkString(<span class="string">","</span>), liveBrokerIdsSorted.mkString(<span class="string">","</span>)))</div><div class="line">            <span class="comment">//note: Broker 上线, 在 Controller Channel Manager 中添加该 broker</span></div><div class="line">            newBrokers.foreach(controllerContext.controllerChannelManager.addBroker)</div><div class="line">            <span class="comment">//note: Broker 下线处理, 在 Controller Channel Manager 移除该 broker</span></div><div class="line">            deadBrokerIds.foreach(controllerContext.controllerChannelManager.removeBroker)</div><div class="line">            <span class="keyword">if</span>(newBrokerIds.nonEmpty) <span class="comment">//note: 启动该 Broker</span></div><div class="line">              controller.onBrokerStartup(newBrokerIdsSorted)</div><div class="line">            <span class="keyword">if</span>(deadBrokerIds.nonEmpty) <span class="comment">//note: broker 掉线后开始 leader 选举</span></div><div class="line">              controller.onBrokerFailure(deadBrokerIdsSorted)</div><div class="line">          &#125; <span class="keyword">catch</span> &#123;</div><div class="line">            <span class="keyword">case</span> e: <span class="type">Throwable</span> =&gt; error(<span class="string">"Error while handling broker changes"</span>, e)</div><div class="line">          &#125;</div><div class="line">        &#125;</div><div class="line">      &#125;</div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>这里需要重点关注 <code>doHandleChildChange()</code> 方法的实现，该方法处理逻辑如下：</p>
<ol>
<li>从 ZK 获取当前的 Broker 列表（<code>curBrokers</code>）及 broker id 的列表（<code>curBrokerIds</code>）；</li>
<li>获取当前 Controller 中缓存的 broker id 列表（<code>liveOrShuttingDownBrokerIds</code>）；</li>
<li>获取新上线 broker id 列表：<code>newBrokerIds</code> = <code>curBrokerIds</code> – <code>liveOrShuttingDownBrokerIds</code>；</li>
<li>获取掉线的 broker id 列表：<code>deadBrokerIds</code> = <code>liveOrShuttingDownBrokerIds</code> – <code>curBrokerIds</code>；</li>
<li>对于新上线的 broker，先在 ControllerChannelManager 中添加该 broker（即建立与该 Broker 的连接、初始化相应的发送线程和请求队列），最后 Controller 调用 <code>onBrokerStartup()</code> 上线该 Broker；</li>
<li>对于掉线的 broker，先在 ControllerChannelManager 中移除该 broker（即关闭与 Broker 的连接、关闭相应的发送线程和清空请求队列），最后 Controller 调用 <code>onBrokerFailure()</code> 下线该 Broker。</li>
</ol>
<p>整体的处理流程如下图所示：</p>
<p><img src="/images/kafka/broker_online_offline.png" alt="Broker 上线下线处理过程"></p>
<h2 id="Broker-上线"><a href="#Broker-上线" class="headerlink" title="Broker 上线"></a>Broker 上线</h2><p>本节主要讲述一台 Broker 上线的过程，如前面图中所示，一台 Broker 上线主要有以下两步：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">controllerContext.controllerChannelManager.addBroker</div><div class="line">controller.onBrokerStartup(newBrokerIdsSorted)</div></pre></td></tr></table></figure>
<ol>
<li>在 Controller Channel Manager 中添加该 Broker 节点，主要的内容是：Controller 建立与该 Broker 的连接、初始化相应的请求发送线程与请求队列；</li>
<li>调用 Controller 的 <code>onBrokerStartup()</code> 方法上线该节点。</li>
</ol>
<p>Controller Channel Manager 添加 Broker 的实现如下，这里就不重复讲述了，前面讲述 Controller 服务初始化的文章（ <a href="http://matt33.com/2018/06/15/kafka-controller-start/#Controller-Channel-Manager">Controller Channel Manager </a>）已经讲述过这部分的内容。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">addBroker</span></span>(broker: <span class="type">Broker</span>) &#123;</div><div class="line">  <span class="comment">// be careful here. Maybe the startup() API has already started the request send thread</span></div><div class="line">  brokerLock synchronized &#123;</div><div class="line">    <span class="keyword">if</span>(!brokerStateInfo.contains(broker.id)) &#123;</div><div class="line">      addNewBroker(broker)</div><div class="line">      startRequestSendThread(broker.id)</div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>下面再看下 Controller 如何在 <code>onBrokerStartup()</code> 方法中实现 Broker 上线操作的，具体实现如下所示：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//note: 这个是被 副本状态机触发的</span></div><div class="line"><span class="comment">//note: 1. 发送 update-metadata 请求给所有存活的 broker;</span></div><div class="line"><span class="comment">//note: 2. 对于所有 new/offline partition 触发选主操作, 选举成功的, Partition 状态设置为 Online</span></div><div class="line"><span class="comment">//note: 3. 检查是否有分区的重新副本分配分配到了这个台机器上, 如果有, 就进行相应的操作</span></div><div class="line"><span class="comment">//note: 4. 检查这台机器上是否有 Topic 被设置为了删除标志, 如果是, 那么机器启动完成后, 重新尝试删除操作</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">onBrokerStartup</span></span>(newBrokers: <span class="type">Seq</span>[<span class="type">Int</span>]) &#123;</div><div class="line">  info(<span class="string">"New broker startup callback for %s"</span>.format(newBrokers.mkString(<span class="string">","</span>)))</div><div class="line">  <span class="keyword">val</span> newBrokersSet = newBrokers.toSet <span class="comment">//note: 新启动的 broker</span></div><div class="line">  <span class="comment">// send update metadata request to all live and shutting down brokers. Old brokers will get to know of the new</span></div><div class="line">  <span class="comment">// broker via this update.</span></div><div class="line">  <span class="comment">// In cases of controlled shutdown leaders will not be elected when a new broker comes up. So at least in the</span></div><div class="line">  <span class="comment">// common controlled shutdown case, the metadata will reach the new brokers faster</span></div><div class="line">  <span class="comment">//note: 发送 metadata 更新给所有的 broker, 这样的话旧的 broker 将会知道有机器新上线了</span></div><div class="line">  sendUpdateMetadataRequest(controllerContext.liveOrShuttingDownBrokerIds.toSeq)</div><div class="line">  <span class="comment">// the very first thing to do when a new broker comes up is send it the entire list of partitions that it is</span></div><div class="line">  <span class="comment">// supposed to host. Based on that the broker starts the high watermark threads for the input list of partitions</span></div><div class="line">  <span class="comment">//note:  获取这个机器上的所有 replica 请求</span></div><div class="line">  <span class="keyword">val</span> allReplicasOnNewBrokers = controllerContext.replicasOnBrokers(newBrokersSet)</div><div class="line">  <span class="comment">//note: 将这些副本的状态设置为 OnlineReplica</span></div><div class="line">  replicaStateMachine.handleStateChanges(allReplicasOnNewBrokers, <span class="type">OnlineReplica</span>)</div><div class="line">  <span class="comment">// when a new broker comes up, the controller needs to trigger leader election for all new and offline partitions</span></div><div class="line">  <span class="comment">// to see if these brokers can become leaders for some/all of those</span></div><div class="line">  <span class="comment">//note: 新的 broker 上线也会触发所有处于 new/offline 的 partition 进行 leader 选举</span></div><div class="line">  partitionStateMachine.triggerOnlinePartitionStateChange()</div><div class="line">  <span class="comment">// check if reassignment of some partitions need to be restarted</span></div><div class="line">  <span class="comment">//note: 检查是否副本的重新分配分配到了这台机器上</span></div><div class="line">  <span class="keyword">val</span> partitionsWithReplicasOnNewBrokers = controllerContext.partitionsBeingReassigned.filter &#123;</div><div class="line">    <span class="keyword">case</span> (_, reassignmentContext) =&gt; reassignmentContext.newReplicas.exists(newBrokersSet.contains(_))</div><div class="line">  &#125;</div><div class="line">  <span class="comment">//note: 如果需要副本进行迁移的话,就执行副本迁移操作</span></div><div class="line">  partitionsWithReplicasOnNewBrokers.foreach(p =&gt; onPartitionReassignment(p._1, p._2))</div><div class="line">  <span class="comment">// check if topic deletion needs to be resumed. If at least one replica that belongs to the topic being deleted exists</span></div><div class="line">  <span class="comment">// on the newly restarted brokers, there is a chance that topic deletion can resume</span></div><div class="line">  <span class="comment">//note: 检查 topic 删除操作是否需要重新启动</span></div><div class="line">  <span class="keyword">val</span> replicasForTopicsToBeDeleted = allReplicasOnNewBrokers.filter(p =&gt; deleteTopicManager.isTopicQueuedUpForDeletion(p.topic))</div><div class="line">  <span class="keyword">if</span>(replicasForTopicsToBeDeleted.nonEmpty) &#123;</div><div class="line">    info((<span class="string">"Some replicas %s for topics scheduled for deletion %s are on the newly restarted brokers %s. "</span> +</div><div class="line">      <span class="string">"Signaling restart of topic deletion for these topics"</span>).format(replicasForTopicsToBeDeleted.mkString(<span class="string">","</span>),</div><div class="line">      deleteTopicManager.topicsToBeDeleted.mkString(<span class="string">","</span>), newBrokers.mkString(<span class="string">","</span>)))</div><div class="line">    deleteTopicManager.resumeDeletionForTopics(replicasForTopicsToBeDeleted.map(_.topic))</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p><code>onBrokerStartup()</code> 方法在实现的逻辑上分为以下几步：</p>
<ol>
<li>调用 <code>sendUpdateMetadataRequest()</code> 方法向当前集群所有存活的 Broker 发送 Update Metadata 请求，这样的话其他的节点就会知道当前的 Broker 已经上线了；</li>
<li>获取当前节点分配的所有的 Replica 列表，并将其状态转移为 OnlineReplica 状态；</li>
<li>触发 PartitionStateMachine 的 <code>triggerOnlinePartitionStateChange()</code> 方法，为所有处于 NewPartition/OfflinePartition 状态的 Partition 进行 leader 选举，如果 leader 选举成功，那么该 Partition 的状态就会转移到 OnlinePartition 状态，否则状态转移失败；</li>
<li>如果副本迁移中有新的 Replica 落在这台新上线的节点上，那么开始执行副本迁移操作（见<a href="http://matt33.com/2018/06/16/partition-reassignment/">Kafka 源码解析之 Partition 副本迁移实现</a>）;</li>
<li>如果之前由于这个 Topic 设置为删除标志，但是由于其中有 Replica 掉线而导致无法删除，这里在节点启动后，尝试重新执行删除操作。</li>
</ol>
<p>到此为止，一台 Broker 算是真正加入到了 Kafka 的集群中，在上述过程中，涉及到 leader 选举的操作，都会触发 LeaderAndIsr 请求及 Metadata 请求的发送。</p>
<h2 id="Broker-掉线"><a href="#Broker-掉线" class="headerlink" title="Broker 掉线"></a>Broker 掉线</h2><p>本节主要讲述一台 Broker 掉线后的处理过程，正如前面图中所示，一台 Broker 掉线后主要有以下两步：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">controllerContext.controllerChannelManager.removeBroker</div><div class="line">controller.onBrokerFailure(deadBrokerIdsSorted)</div></pre></td></tr></table></figure>
<ol>
<li>首先在 Controller Channel Manager 中移除该 Broker 节点，主要的内容是：关闭 Controller  与 Broker 的连接和相应的请求发送线程，并清空请求队列；</li>
<li>调用 Controller 的 <code>onBrokerFailure()</code> 方法下线该节点。</li>
</ol>
<p>Controller Channel Manager 下线 Broker 的处理如下所示：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">removeBroker</span></span>(brokerId: <span class="type">Int</span>) &#123;</div><div class="line">  brokerLock synchronized &#123;</div><div class="line">    removeExistingBroker(brokerStateInfo(brokerId))</div><div class="line">  &#125;</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="comment">//note: 移除旧的 broker（关闭网络连接、关闭请求发送线程）</span></div><div class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">removeExistingBroker</span></span>(brokerState: <span class="type">ControllerBrokerStateInfo</span>) &#123;</div><div class="line">  <span class="keyword">try</span> &#123;</div><div class="line">    brokerState.networkClient.close()</div><div class="line">    brokerState.messageQueue.clear()</div><div class="line">    brokerState.requestSendThread.shutdown()</div><div class="line">    brokerStateInfo.remove(brokerState.brokerNode.id)</div><div class="line">  &#125; <span class="keyword">catch</span> &#123;</div><div class="line">    <span class="keyword">case</span> e: <span class="type">Throwable</span> =&gt; error(<span class="string">"Error while removing broker by the controller"</span>, e)</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>在 Controller Channel Manager 处理完掉线的 Broker 节点后，下面 KafkaController 将会调用 <code>onBrokerFailure()</code> 进行相应的处理，其实现如下：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//note: 这个方法会被副本状态机调用（进行 broker 节点下线操作）</span></div><div class="line"><span class="comment">//note: 1. 将 leader 在这台机器上的分区设置为 Offline</span></div><div class="line"><span class="comment">//note: 2. 通过 OfflinePartitionLeaderSelector 为 new/offline partition 选举新的 leader</span></div><div class="line"><span class="comment">//note: 3. leader 选举后,发送 LeaderAndIsr 请求给该分区所有存活的副本;</span></div><div class="line"><span class="comment">//note: 4. 分区选举 leader 后,状态更新为 Online</span></div><div class="line"><span class="comment">//note: 5. 要下线的 broker 上的所有 replica 改为 Offline 状态</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">onBrokerFailure</span></span>(deadBrokers: <span class="type">Seq</span>[<span class="type">Int</span>]) &#123;</div><div class="line">  info(<span class="string">"Broker failure callback for %s"</span>.format(deadBrokers.mkString(<span class="string">","</span>)))</div><div class="line">  <span class="comment">//note: 从正在下线的 broker 集合中移除已经下线的机器</span></div><div class="line">  <span class="keyword">val</span> deadBrokersThatWereShuttingDown =</div><div class="line">    deadBrokers.filter(id =&gt; controllerContext.shuttingDownBrokerIds.remove(id))</div><div class="line">  info(<span class="string">"Removed %s from list of shutting down brokers."</span>.format(deadBrokersThatWereShuttingDown))</div><div class="line">  <span class="keyword">val</span> deadBrokersSet = deadBrokers.toSet</div><div class="line">  <span class="comment">// trigger OfflinePartition state for all partitions whose current leader is one amongst the dead brokers</span></div><div class="line">  <span class="comment">//note: 1. 将 leader 在这台机器上的、并且未设置删除的分区状态设置为 Offline</span></div><div class="line">  <span class="keyword">val</span> partitionsWithoutLeader = controllerContext.partitionLeadershipInfo.filter(partitionAndLeader =&gt;</div><div class="line">    deadBrokersSet.contains(partitionAndLeader._2.leaderAndIsr.leader) &amp;&amp;</div><div class="line">      !deleteTopicManager.isTopicQueuedUpForDeletion(partitionAndLeader._1.topic)).keySet</div><div class="line">  partitionStateMachine.handleStateChanges(partitionsWithoutLeader, <span class="type">OfflinePartition</span>)</div><div class="line">  <span class="comment">// trigger OnlinePartition state changes for offline or new partitions</span></div><div class="line">  <span class="comment">//note: 2. 选举 leader, 选举成功后设置为 Online 状态</span></div><div class="line">  partitionStateMachine.triggerOnlinePartitionStateChange()</div><div class="line">  <span class="comment">// filter out the replicas that belong to topics that are being deleted</span></div><div class="line">  <span class="comment">//note: 过滤出 replica 在这个机器上、并且没有被设置为删除的 topic 列表</span></div><div class="line">  <span class="keyword">var</span> allReplicasOnDeadBrokers = controllerContext.replicasOnBrokers(deadBrokersSet)</div><div class="line">  <span class="keyword">val</span> activeReplicasOnDeadBrokers = allReplicasOnDeadBrokers.filterNot(p =&gt; deleteTopicManager.isTopicQueuedUpForDeletion(p.topic))</div><div class="line">  <span class="comment">// handle dead replicas</span></div><div class="line">  <span class="comment">//note: 将这些 replica 状态转为 Offline</span></div><div class="line">  replicaStateMachine.handleStateChanges(activeReplicasOnDeadBrokers, <span class="type">OfflineReplica</span>)</div><div class="line">  <span class="comment">// check if topic deletion state for the dead replicas needs to be updated</span></div><div class="line">  <span class="comment">//note: 过滤设置为删除的 replica</span></div><div class="line">  <span class="keyword">val</span> replicasForTopicsToBeDeleted = allReplicasOnDeadBrokers.filter(p =&gt; deleteTopicManager.isTopicQueuedUpForDeletion(p.topic))</div><div class="line">  <span class="keyword">if</span>(replicasForTopicsToBeDeleted.nonEmpty) &#123; <span class="comment">//note: 将上面这个 topic 列表的 topic 标记为删除失败</span></div><div class="line">    <span class="comment">// it is required to mark the respective replicas in TopicDeletionFailed state since the replica cannot be</span></div><div class="line">    <span class="comment">// deleted when the broker is down. This will prevent the replica from being in TopicDeletionStarted state indefinitely</span></div><div class="line">    <span class="comment">// since topic deletion cannot be retried until at least one replica is in TopicDeletionStarted state</span></div><div class="line">    deleteTopicManager.failReplicaDeletion(replicasForTopicsToBeDeleted)</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  <span class="comment">// If broker failure did not require leader re-election, inform brokers of failed broker</span></div><div class="line">  <span class="comment">// Note that during leader re-election, brokers update their metadata</span></div><div class="line">  <span class="keyword">if</span> (partitionsWithoutLeader.isEmpty) &#123;</div><div class="line">    sendUpdateMetadataRequest(controllerContext.liveOrShuttingDownBrokerIds.toSeq)</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>Controller 对于掉线 Broker 的处理过程主要有以下几步：</p>
<ol>
<li>首先找到 Leader 在该 Broker 上所有 Partition 列表，然后将这些 Partition 的状态全部转移为 OfflinePartition 状态；</li>
<li>触发 PartitionStateMachine 的 <code>triggerOnlinePartitionStateChange()</code> 方法，为所有处于 NewPartition/OfflinePartition 状态的 Partition 进行 Leader 选举，如果 Leader 选举成功，那么该 Partition 的状态就会迁移到 OnlinePartition 状态，否则状态转移失败（Broker 上线/掉线、Controller 初始化时都会触发这个方法）；</li>
<li>获取在该 Broker 上的所有 Replica 列表，将其状态转移成 OfflineReplica 状态；</li>
<li>过滤出设置为删除、并且有副本在该节点上的 Topic 列表，先将该 Replica 的转移成 ReplicaDeletionIneligible 状态，然后再将该 Topic 标记为非法删除，即因为有 Replica 掉线导致该 Topic 无法删除；</li>
<li>如果 leader 在该 Broker 上所有 Partition 列表不为空，证明有 Partition 的 leader 需要选举，在最后一步会触发全局 metadata 信息的更新。</li>
</ol>
<p>到这里，一台掉线的 Broker 算是真正下线完成了。</p>
<h2 id="Broker-优雅下线"><a href="#Broker-优雅下线" class="headerlink" title="Broker 优雅下线"></a>Broker 优雅下线</h2><p>前面部分是关于通过监听节点变化来实现对 Broker 的上下线，这也是 Kafka 上下线 Broker 的主要流程，但是还有一种情况是：主动关闭 Kafka 服务，这种情况又被称为 Broker 的优雅关闭。</p>
<p>优雅关闭的节点会向 Controller 发送 ControlledShutdownRequest 请求，Controller 在收到这个情况会进行相应的处理，如下所示：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">handleControlledShutdownRequest</span></span>(request: <span class="type">RequestChannel</span>.<span class="type">Request</span>) &#123;</div><div class="line">  <span class="comment">// ensureTopicExists is only for client facing requests</span></div><div class="line">  <span class="comment">// We can't have the ensureTopicExists check here since the controller sends it as an advisory to all brokers so they</span></div><div class="line">  <span class="comment">// stop serving data to clients for the topic being deleted</span></div><div class="line">  <span class="keyword">val</span> controlledShutdownRequest = request.requestObj.asInstanceOf[<span class="type">ControlledShutdownRequest</span>]</div><div class="line"></div><div class="line">  <span class="comment">//note: 判断该连接是否经过认证</span></div><div class="line">  authorizeClusterAction(request)</div><div class="line"></div><div class="line">  <span class="comment">//note: 处理该请求</span></div><div class="line">  <span class="keyword">val</span> partitionsRemaining = controller.shutdownBroker(controlledShutdownRequest.brokerId)</div><div class="line">  <span class="comment">//note: 返回的 response</span></div><div class="line">  <span class="keyword">val</span> controlledShutdownResponse = <span class="keyword">new</span> <span class="type">ControlledShutdownResponse</span>(controlledShutdownRequest.correlationId,</div><div class="line">    <span class="type">Errors</span>.<span class="type">NONE</span>.code, partitionsRemaining)</div><div class="line">  requestChannel.sendResponse(<span class="keyword">new</span> <span class="type">Response</span>(request, <span class="keyword">new</span> <span class="type">RequestOrResponseSend</span>(request.connectionId, controlledShutdownResponse)))</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>Controller 在接收这个关闭服务的请求，通过 <code>shutdownBroker()</code> 方法进行处理，实现如下所示：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//note: 优雅地关闭 Broker</span></div><div class="line"><span class="comment">//note: controller 首先决定将这个 broker 上的 leader 迁移到其他可用的机器上</span></div><div class="line"><span class="comment">//note: 返回还没有 leader 的迁移的 TopicPartition 集合</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">shutdownBroker</span></span>(id: <span class="type">Int</span>): <span class="type">Set</span>[<span class="type">TopicAndPartition</span>] = &#123;</div><div class="line"></div><div class="line">  <span class="keyword">if</span> (!isActive) &#123;</div><div class="line">    <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">ControllerMovedException</span>(<span class="string">"Controller moved to another broker. Aborting controlled shutdown"</span>)</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  controllerContext.brokerShutdownLock synchronized &#123; <span class="comment">//note: 拿到 broker shutdown 的唯一锁</span></div><div class="line">    info(<span class="string">"Shutting down broker "</span> + id)</div><div class="line"></div><div class="line">    inLock(controllerContext.controllerLock) &#123; <span class="comment">//note: 拿到 controllerLock 的排它锁</span></div><div class="line">      <span class="keyword">if</span> (!controllerContext.liveOrShuttingDownBrokerIds.contains(id))</div><div class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">BrokerNotAvailableException</span>(<span class="string">"Broker id %d does not exist."</span>.format(id))</div><div class="line"></div><div class="line">      controllerContext.shuttingDownBrokerIds.add(id) <span class="comment">//note: 将 broker id 添加到正在关闭的 broker 列表中</span></div><div class="line">      debug(<span class="string">"All shutting down brokers: "</span> + controllerContext.shuttingDownBrokerIds.mkString(<span class="string">","</span>))</div><div class="line">      debug(<span class="string">"Live brokers: "</span> + controllerContext.liveBrokerIds.mkString(<span class="string">","</span>))</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="comment">//note: 获取这个 broker 上所有 Partition 与副本数的 map</span></div><div class="line">    <span class="keyword">val</span> allPartitionsAndReplicationFactorOnBroker: <span class="type">Set</span>[(<span class="type">TopicAndPartition</span>, <span class="type">Int</span>)] =</div><div class="line">      inLock(controllerContext.controllerLock) &#123;</div><div class="line">        controllerContext.partitionsOnBroker(id)</div><div class="line">          .map(topicAndPartition =&gt; (topicAndPartition, controllerContext.partitionReplicaAssignment(topicAndPartition).size))</div><div class="line">      &#125;</div><div class="line"></div><div class="line">    <span class="comment">//note: 处理这些 TopicPartition，更新 Partition 或 Replica 的状态，必要时进行 leader 选举</span></div><div class="line">    allPartitionsAndReplicationFactorOnBroker.foreach &#123;</div><div class="line">      <span class="keyword">case</span>(topicAndPartition, replicationFactor) =&gt;</div><div class="line">        <span class="comment">// Move leadership serially to relinquish lock.</span></div><div class="line">        inLock(controllerContext.controllerLock) &#123;</div><div class="line">          controllerContext.partitionLeadershipInfo.get(topicAndPartition).foreach &#123; currLeaderIsrAndControllerEpoch =&gt;</div><div class="line">            <span class="keyword">if</span> (replicationFactor &gt; <span class="number">1</span>) &#123; <span class="comment">//note: 副本数大于1</span></div><div class="line">              <span class="keyword">if</span> (currLeaderIsrAndControllerEpoch.leaderAndIsr.leader == id) &#123; <span class="comment">//note: leader 正好是下线的节点</span></div><div class="line">                <span class="comment">// If the broker leads the topic partition, transition the leader and update isr. Updates zk and</span></div><div class="line">                <span class="comment">// notifies all affected brokers</span></div><div class="line">                <span class="comment">//todo: 这种情况下 Replica 的状态不需要修改么？（Replica 的处理还是通过监听器还实现的,这里只是在服务关闭前进行 leader 切换和停止副本同步）</span></div><div class="line">                <span class="comment">//note: 状态变化（变为 OnlinePartition，并且进行 leader 选举，使用 controlledShutdownPartitionLeaderSelector 算法）</span></div><div class="line">                partitionStateMachine.handleStateChanges(<span class="type">Set</span>(topicAndPartition), <span class="type">OnlinePartition</span>,</div><div class="line">                  controlledShutdownPartitionLeaderSelector)</div><div class="line">              &#125; <span class="keyword">else</span> &#123;</div><div class="line">                <span class="comment">// Stop the replica first. The state change below initiates ZK changes which should take some time</span></div><div class="line">                <span class="comment">// before which the stop replica request should be completed (in most cases)</span></div><div class="line">                <span class="keyword">try</span> &#123; <span class="comment">//note: 要下线的机器停止副本迁移，发送 StopReplica 请求</span></div><div class="line">                  brokerRequestBatch.newBatch()</div><div class="line">                  brokerRequestBatch.addStopReplicaRequestForBrokers(<span class="type">Seq</span>(id), topicAndPartition.topic,</div><div class="line">                    topicAndPartition.partition, deletePartition = <span class="literal">false</span>)</div><div class="line">                  brokerRequestBatch.sendRequestsToBrokers(epoch)</div><div class="line">                &#125; <span class="keyword">catch</span> &#123;</div><div class="line">                  <span class="keyword">case</span> e : <span class="type">IllegalStateException</span> =&gt; &#123;</div><div class="line">                    <span class="comment">// Resign if the controller is in an illegal state</span></div><div class="line">                    error(<span class="string">"Forcing the controller to resign"</span>)</div><div class="line">                    brokerRequestBatch.clear()</div><div class="line">                    controllerElector.resign()</div><div class="line"></div><div class="line">                    <span class="keyword">throw</span> e</div><div class="line">                  &#125;</div><div class="line">                &#125;</div><div class="line">                <span class="comment">// If the broker is a follower, updates the isr in ZK and notifies the current leader</span></div><div class="line">                <span class="comment">//note: 更新这个副本的状态，变为 OfflineReplica</span></div><div class="line">                replicaStateMachine.handleStateChanges(<span class="type">Set</span>(<span class="type">PartitionAndReplica</span>(topicAndPartition.topic,</div><div class="line">                  topicAndPartition.partition, id)), <span class="type">OfflineReplica</span>)</div><div class="line">              &#125;</div><div class="line">            &#125;</div><div class="line">          &#125;</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line">    <span class="comment">//note: 返回 leader 在这个要下线节点上并且副本数大于 1 的 TopicPartition 集合</span></div><div class="line">    <span class="comment">//note: 在已经进行前面 leader 迁移后</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">replicatedPartitionsBrokerLeads</span></span>() = inLock(controllerContext.controllerLock) &#123;</div><div class="line">      trace(<span class="string">"All leaders = "</span> + controllerContext.partitionLeadershipInfo.mkString(<span class="string">","</span>))</div><div class="line">      controllerContext.partitionLeadershipInfo.filter &#123;</div><div class="line">        <span class="keyword">case</span> (topicAndPartition, leaderIsrAndControllerEpoch) =&gt;</div><div class="line">          leaderIsrAndControllerEpoch.leaderAndIsr.leader == id &amp;&amp; controllerContext.partitionReplicaAssignment(topicAndPartition).size &gt; <span class="number">1</span></div><div class="line">      &#125;.keys</div><div class="line">    &#125;</div><div class="line">    replicatedPartitionsBrokerLeads().toSet</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>上述方法的处理逻辑如下：</p>
<ol>
<li>先将要下线的 Broker 添加到 shuttingDownBrokerIds 集合中，该集合记录了当前正在进行关闭的 broker 列表；</li>
<li>获取副本在该节点上的所有 Partition 的列表集合；</li>
<li>遍历上述 Partition 列表进行处理：如果该 Partition 的 leader 是要下线的节点，那么通过 PartitionStateMachine 进行状态转移（OnlinePartition –&gt; OnlinePartition）触发 leader 选举，使用的 leader 选举方法是 <a href="http://matt33.com/2018/06/15/kafka-controller-start/#ControlledShutdownLeaderSelector">ControlledShutdownLeaderSelector</a>，它会选举 isr 中第一个没有正在关闭的 Replica 作为 leader，否则抛出 StateChangeFailedException 异常；</li>
<li>否则的话，即要下线的节点不是 leader，那么就向要下线的节点发送 StopReplica 请求停止副本同步，并将该副本设置为 OfflineReplica 状态，这里对 Replica 进行处理的原因是为了让要下线的机器关闭副本同步流程，这样 Kafka 服务才能正常关闭。</li>
</ol>
<p>我在看这部分的代码是有一个疑问的，那就是如果要下线的节点是 Partition leader 的情况下，并没有对 Replica 进行相应的处理，这里的原因是，这部分 Replica 的处理可以放在 <code>onBrokerFailure()</code> 方法中处理，即使通过优雅下线的方法下线了 Broker，但是监听 ZK 的 BrokerChangeListener 监听器还是会被触发的。</p>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[Kafka 源码解析之 Partition 副本迁移实现（十八）]]></title>
      <url>http://matt33.com/2018/06/16/partition-reassignment/</url>
      <content type="html"><![CDATA[<p>前面两篇关于 Controller 的内容分别讲述了 Controller 选举和启动，以及副本状态机和分区状态机的内容，从本文开始会详细讲述 Controller 的一些其他功能，主要是 Controller 的对不同类型监听器的处理，这部分预计分三篇左右的文章讲述。Controller 在初始化时，会利用 ZK 的 watch 机制注册很多不同类型的监听器，当监听的事件被触发时，Controller 就会触发相应的操作。</p>
<p>Controller 在初始化时，会注册多种类型的监听器，主要有以下6种：</p>
<ol>
<li>监听 <code>/admin/reassign_partitions</code> 节点，用于分区副本迁移的监听；</li>
<li>监听 <code>/isr_change_notification</code> 节点，用于 Partition Isr 变动的监听，；</li>
<li>监听 <code>/admin/preferred_replica_election</code> 节点，用于需要进行 Partition 最优 leader 选举的监听；</li>
<li>监听 <code>/brokers/topics</code> 节点，用于 Topic 新建的监听；</li>
<li>监听 <code>/brokers/topics/TOPIC_NAME</code> 节点，用于 Topic Partition 扩容的监听；</li>
<li>监听 <code>/admin/delete_topics</code> 节点，用于 Topic 删除的监听；</li>
<li>监听 <code>/brokers/ids</code> 节点，用于 Broker 上下线的监听。</li>
</ol>
<p>本文主要讲解第一部分，也就是 Controller 对 Partition 副本迁移的处理，后续会单独一篇文章讲述 Topic 的新建、扩容和删除，再单独一篇文章讲述 Broker 的上下线，另外两部分将会在对 LeaderAndIsr 请求处理的文章中讲述。</p>
<h2 id="Partition-副本迁移整体流程"><a href="#Partition-副本迁移整体流程" class="headerlink" title="Partition 副本迁移整体流程"></a>Partition 副本迁移整体流程</h2><p>Partition 的副本迁移实际上就是将分区的副本重新分配到不同的代理节点上，如果 zk 中新副本的集合与 Partition 原来的副本集合相同，那么这个副本就不需要重新分配了。</p>
<p>Partition 的副本迁移是通过监听 zk 的 <code>/admin/reassign_partitions</code> 节点触发的，Kafka 也向用户提供相应的脚本工具进行副本迁移，副本迁移的脚本使用方法如下所示：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">./bin/kafka-reassign-partitions.sh --zookeeper XXX --reassignment-json-file XXX.json --execute</div></pre></td></tr></table></figure>
<p>其中 XXX.json 为要进行 Partition 副本迁移的 json 文件，json 文件的格式如下所示：</p>
<figure class="highlight json"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div></pre></td><td class="code"><pre><div class="line">&#123;</div><div class="line">    <span class="attr">"version"</span>:<span class="number">1</span>,</div><div class="line">    <span class="attr">"partitions"</span>:[</div><div class="line">        &#123;</div><div class="line">            <span class="attr">"topic"</span>:<span class="string">"__consumer_offsets"</span>,</div><div class="line">            <span class="attr">"partition"</span>:<span class="number">19</span>,</div><div class="line">            <span class="attr">"replicas"</span>:[</div><div class="line">                <span class="number">3</span>,</div><div class="line">                <span class="number">9</span>,</div><div class="line">                <span class="number">2</span></div><div class="line">            ]</div><div class="line">        &#125;,</div><div class="line">        &#123;</div><div class="line">            <span class="attr">"topic"</span>:<span class="string">"__consumer_offsets"</span>,</div><div class="line">            <span class="attr">"partition"</span>:<span class="number">26</span>,</div><div class="line">            <span class="attr">"replicas"</span>:[</div><div class="line">                <span class="number">2</span>,</div><div class="line">                <span class="number">6</span>,</div><div class="line">                <span class="number">4</span></div><div class="line">            ]</div><div class="line">        &#125;,</div><div class="line">        &#123;</div><div class="line">            <span class="attr">"topic"</span>:<span class="string">"__consumer_offsets"</span>,</div><div class="line">            <span class="attr">"partition"</span>:<span class="number">27</span>,</div><div class="line">            <span class="attr">"replicas"</span>:[</div><div class="line">                <span class="number">5</span>,</div><div class="line">                <span class="number">3</span>,</div><div class="line">                <span class="number">8</span></div><div class="line">            ]</div><div class="line">        &#125;</div><div class="line">    ]</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>这个 json 文件的意思是将 Topic <code>__consumer_offsets</code> Partition 19 的副本迁移到 {3, 2, 9} 上，Partition 26 的副本迁移到 {6, 2, 4} 上，Partition 27 的副本迁移到 {5, 3, 8} 上。</p>
<p>在调用脚本向 zk 提交 Partition 的迁移计划时，迁移计划更新到 zk 前需要进行一步判断，如果该节点（写入迁移计划的节点）已经存在，即副本迁移还在进行，那么本次副本迁移计划是无法提交的，实现的逻辑如下所示：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">executeAssignment</span></span>(zkUtils: <span class="type">ZkUtils</span>, reassignmentJsonString: <span class="type">String</span>, throttle: <span class="type">Long</span> = <span class="number">-1</span>) &#123;</div><div class="line">  <span class="keyword">val</span> partitionsToBeReassigned = parseAndValidate(zkUtils, reassignmentJsonString)</div><div class="line">  <span class="keyword">val</span> reassignPartitionsCommand = <span class="keyword">new</span> <span class="type">ReassignPartitionsCommand</span>(zkUtils, partitionsToBeReassigned.toMap)</div><div class="line"></div><div class="line">  <span class="comment">// If there is an existing rebalance running, attempt to change its throttle</span></div><div class="line">  <span class="comment">//note: 如果副本迁移正在进行,那么这次的副本迁移计划是无法提交的</span></div><div class="line">  <span class="keyword">if</span> (zkUtils.pathExists(<span class="type">ZkUtils</span>.<span class="type">ReassignPartitionsPath</span>)) &#123;</div><div class="line">    println(<span class="string">"There is an existing assignment running."</span>)</div><div class="line">    reassignPartitionsCommand.maybeLimit(throttle)</div><div class="line">  &#125;</div><div class="line">  <span class="keyword">else</span> &#123;</div><div class="line">    printCurrentAssignment(zkUtils, partitionsToBeReassigned)</div><div class="line">    <span class="keyword">if</span> (throttle &gt;= <span class="number">0</span>)</div><div class="line">      println(<span class="type">String</span>.format(<span class="string">"Warning: You must run Verify periodically, until the reassignment completes, to ensure the throttle is removed. You can also alter the throttle by rerunning the Execute command passing a new value."</span>))</div><div class="line">    <span class="comment">//note: 将迁移计划更新到 zk 上</span></div><div class="line">    <span class="keyword">if</span> (reassignPartitionsCommand.reassignPartitions(throttle)) &#123;</div><div class="line">      println(<span class="string">"Successfully started reassignment of partitions."</span>)</div><div class="line">    &#125; <span class="keyword">else</span></div><div class="line">      println(<span class="string">"Failed to reassign partitions %s"</span>.format(partitionsToBeReassigned))</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>在迁移计划提交到 zk 之后，Controller 的 PartitionsReassignedListener 就会被触发，Controller 开始 Partition 的副本迁移，触发之后 Controller 的处理流程大体如下图所示：</p>
<p><img src="/images/kafka/partition_reassignment.png" alt="Partition 迁移过程"></p>
<h2 id="PartitionsReassignedListener-副本迁移处理"><a href="#PartitionsReassignedListener-副本迁移处理" class="headerlink" title="PartitionsReassignedListener 副本迁移处理"></a>PartitionsReassignedListener 副本迁移处理</h2><p>在 zk 的 <code>/admin/reassign_partitions</code> 节点数据有变化时，就会触发 PartitionsReassignedListener 的 <code>doHandleDataChange()</code> 方法，实现如下：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//note: 开始进行 partition reassignment 除非这三种情况发生:</span></div><div class="line"><span class="comment">//note: 1. 这个 partition 的 reassignment 之前已经存在, 即正在迁移中;</span></div><div class="line"><span class="comment">//note: 2. new replica 与已经存在的 replicas 相同;</span></div><div class="line"><span class="comment">//note: 3. Partition 所有新分配 replica 都已经 dead;</span></div><div class="line"><span class="comment">//note: 这种情况发生时,会输出一条日志,并从 zk 移除该 Partition 的迁移计划。</span></div><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">PartitionsReassignedListener</span>(<span class="params">protected val controller: <span class="type">KafkaController</span></span>) <span class="keyword">extends</span> <span class="title">ControllerZkDataListener</span> </span>&#123;</div><div class="line">  <span class="keyword">private</span> <span class="keyword">val</span> controllerContext = controller.controllerContext</div><div class="line"></div><div class="line">  <span class="keyword">protected</span> <span class="function"><span class="keyword">def</span> <span class="title">logName</span> </span>= <span class="string">"PartitionsReassignedListener"</span></div><div class="line"></div><div class="line">  <span class="comment">/**</span></div><div class="line">   * Invoked when some partitions are reassigned by the admin command</div><div class="line">   *</div><div class="line">   * @throws Exception On any error.</div><div class="line">   */</div><div class="line">  <span class="comment">//note: 当一些分区需要进行迁移时</span></div><div class="line">  <span class="meta">@throws</span>[<span class="type">Exception</span>]</div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">doHandleDataChange</span></span>(dataPath: <span class="type">String</span>, data: <span class="type">AnyRef</span>) &#123;</div><div class="line">    debug(<span class="string">"Partitions reassigned listener fired for path %s. Record partitions to be reassigned %s"</span></div><div class="line">      .format(dataPath, data))</div><div class="line">    <span class="keyword">val</span> partitionsReassignmentData = <span class="type">ZkUtils</span>.parsePartitionReassignmentData(data.toString)</div><div class="line">    <span class="keyword">val</span> partitionsToBeReassigned = inLock(controllerContext.controllerLock) &#123; <span class="comment">//note: 需要迁移的新副本</span></div><div class="line">      <span class="comment">//note: 过滤掉正在迁移的副本,如果 Partition 正在迁移,这一波迁移完之前不允许再次迁移</span></div><div class="line">      partitionsReassignmentData.filterNot(p =&gt; controllerContext.partitionsBeingReassigned.contains(p._1))</div><div class="line">    &#125;</div><div class="line">    partitionsToBeReassigned.foreach &#123; partitionToBeReassigned =&gt;</div><div class="line">      inLock(controllerContext.controllerLock) &#123;</div><div class="line">        <span class="keyword">if</span>(controller.deleteTopicManager.isTopicQueuedUpForDeletion(partitionToBeReassigned._1.topic)) &#123;</div><div class="line">          <span class="comment">//note: 如果这个 topic 已经设置了删除，那么就不会进行迁移了（从需要副本迁移的集合中移除）</span></div><div class="line">          error(<span class="string">"Skipping reassignment of partition %s for topic %s since it is currently being deleted"</span></div><div class="line">            .format(partitionToBeReassigned._1, partitionToBeReassigned._1.topic))</div><div class="line">          controller.removePartitionFromReassignedPartitions(partitionToBeReassigned._1)</div><div class="line">        &#125; <span class="keyword">else</span> &#123; <span class="comment">//note: 添加到需要迁移的副本集合中</span></div><div class="line">          <span class="keyword">val</span> context = <span class="keyword">new</span> <span class="type">ReassignedPartitionsContext</span>(partitionToBeReassigned._2)</div><div class="line">          controller.initiateReassignReplicasForTopicPartition(partitionToBeReassigned._1, context)</div><div class="line">        &#125;</div><div class="line">      &#125;</div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">doHandleDataDeleted</span></span>(dataPath: <span class="type">String</span>) &#123;&#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>如果 Partition 出现下面的情况，将不会进行副本迁移，直接将 Partition 的迁移计划从 ZK 移除：</p>
<ol>
<li>这个 Partition 的 reassignment 之前已经存在, 即正在迁移中;</li>
<li>这个 Partition 新分配的 replica 与之前的 replicas 相同;</li>
<li>这个 Partition 所有新分配 replica 都已经 dead;</li>
<li>这个 Partition 已经被设置了删除标志。</li>
</ol>
<p>对于可以进行副本迁移的 Partition 集合，这里将会调用 Kafka Controller 的 <code>initiateReassignReplicasForTopicPartition()</code> 方法对每个 Partition 进行处理。</p>
<h2 id="副本迁移初始化"><a href="#副本迁移初始化" class="headerlink" title="副本迁移初始化"></a>副本迁移初始化</h2><p>进行了前面的判断后，这个 Partition 满足了可以迁移的条件，Controller 会首先初始化副本迁移的流程，实现如下所示：</p>
<blockquote>
<p>如果 Partition 新分配的 replica 与之前的 replicas 相同，那么不会进行副本迁移，这部分的判断实际上是在这里实现的，前面只是为了更好地讲述。</p>
</blockquote>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//note: 初始化 Topic-Partition 的副本迁移</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">initiateReassignReplicasForTopicPartition</span></span>(topicAndPartition: <span class="type">TopicAndPartition</span>,</div><div class="line">                                      reassignedPartitionContext: <span class="type">ReassignedPartitionsContext</span>) &#123;</div><div class="line">  <span class="comment">//note: 要迁移的 topic-partition，及新的副本</span></div><div class="line">  <span class="keyword">val</span> newReplicas = reassignedPartitionContext.newReplicas</div><div class="line">  <span class="keyword">val</span> topic = topicAndPartition.topic</div><div class="line">  <span class="keyword">val</span> partition = topicAndPartition.partition</div><div class="line">  <span class="keyword">try</span> &#123;</div><div class="line">    <span class="keyword">val</span> assignedReplicasOpt = controllerContext.partitionReplicaAssignment.get(topicAndPartition) <span class="comment">//note: partition 的 AR</span></div><div class="line">    assignedReplicasOpt <span class="keyword">match</span> &#123;</div><div class="line">      <span class="keyword">case</span> <span class="type">Some</span>(assignedReplicas) =&gt;</div><div class="line">        <span class="keyword">if</span> (assignedReplicas == newReplicas) &#123; <span class="comment">//note: 不需要迁移</span></div><div class="line">          <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">KafkaException</span>(<span class="string">"Partition %s to be reassigned is already assigned to replicas"</span>.format(topicAndPartition) +</div><div class="line">            <span class="string">" %s. Ignoring request for partition reassignment"</span>.format(newReplicas.mkString(<span class="string">","</span>)))</div><div class="line">        &#125; <span class="keyword">else</span> &#123;</div><div class="line">          info(<span class="string">"Handling reassignment of partition %s to new replicas %s"</span>.format(topicAndPartition, newReplicas.mkString(<span class="string">","</span>)))</div><div class="line">          <span class="comment">// first register ISR change listener</span></div><div class="line">          <span class="comment">//note: 首先注册 ISR 监听的变化</span></div><div class="line">          watchIsrChangesForReassignedPartition(topic, partition, reassignedPartitionContext)</div><div class="line">          <span class="comment">//note: 正在迁移 Partition 添加到缓存中</span></div><div class="line">          controllerContext.partitionsBeingReassigned.put(topicAndPartition, reassignedPartitionContext)</div><div class="line">          <span class="comment">// mark topic ineligible for deletion for the partitions being reassigned</span></div><div class="line">          <span class="comment">//note: 设置正在迁移的副本为不能删除</span></div><div class="line">          deleteTopicManager.markTopicIneligibleForDeletion(<span class="type">Set</span>(topic))</div><div class="line">          <span class="comment">//note: 进行副本迁移</span></div><div class="line">          onPartitionReassignment(topicAndPartition, reassignedPartitionContext)</div><div class="line">        &#125;</div><div class="line">      <span class="keyword">case</span> <span class="type">None</span> =&gt; <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">KafkaException</span>(<span class="string">"Attempt to reassign partition %s that doesn't exist"</span></div><div class="line">        .format(topicAndPartition))</div><div class="line">    &#125;</div><div class="line">  &#125; <span class="keyword">catch</span> &#123;</div><div class="line">    <span class="keyword">case</span> e: <span class="type">Throwable</span> =&gt; error(<span class="string">"Error completing reassignment of partition %s"</span>.format(topicAndPartition), e)</div><div class="line">    <span class="comment">// remove the partition from the admin path to unblock the admin client</span></div><div class="line">    removePartitionFromReassignedPartitions(topicAndPartition)</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>对于副本迁移流程初始化如下：</p>
<ol>
<li>通过 <code>watchIsrChangesForReassignedPartition()</code> 方法监控这个 Partition 的 LeaderAndIsr 变化，如果有新的副本数据同步完成，那么 leader 会将其加到 isr 中更新到 zk 中，这时候 Controller 是可以接收到相关的信息通知的；</li>
<li>将正在迁移的 Partition 添加到 partitionsBeingReassigned 中，它会记录当前正在迁移的 Partition 列表；</li>
<li>将要迁移的 Topic 设置为非法删除删除状态，在这个状态的 Topic 是无法进行删除的；</li>
<li>调用 <code>onPartitionReassignment()</code>，进行副本迁移。</li>
</ol>
<p>在第一步中，会向这个 Partition 注册一个额外的监听器，监听其 LeaderAndIsr 信息变化，如下所示：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//note: ISR 变动的监听器（这个不是由 leader 主动触发的，而是 controller 自己触发的，主要用于 partition 迁移时，isr 变动的监听处理）</span></div><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">ReassignedPartitionsIsrChangeListener</span>(<span class="params">protected val controller: <span class="type">KafkaController</span>, topic: <span class="type">String</span>, partition: <span class="type">Int</span>,</span></span></div><div class="line">                                            reassignedReplicas: <span class="type">Set</span>[<span class="type">Int</span>]) <span class="keyword">extends</span> <span class="title">ControllerZkDataListener</span> &#123;</div><div class="line">  <span class="keyword">private</span> <span class="keyword">val</span> zkUtils = controller.controllerContext.zkUtils</div><div class="line">  <span class="keyword">private</span> <span class="keyword">val</span> controllerContext = controller.controllerContext</div><div class="line"></div><div class="line">  <span class="keyword">protected</span> <span class="function"><span class="keyword">def</span> <span class="title">logName</span> </span>= <span class="string">"ReassignedPartitionsIsrChangeListener"</span></div><div class="line"></div><div class="line">  <span class="comment">/**</span></div><div class="line">   * Invoked when some partitions need to move leader to preferred replica</div><div class="line">   */</div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">doHandleDataChange</span></span>(dataPath: <span class="type">String</span>, data: <span class="type">AnyRef</span>) &#123;</div><div class="line">    inLock(controllerContext.controllerLock) &#123;</div><div class="line">      debug(<span class="string">"Reassigned partitions isr change listener fired for path %s with children %s"</span>.format(dataPath, data))</div><div class="line">      <span class="keyword">val</span> topicAndPartition = <span class="type">TopicAndPartition</span>(topic, partition)</div><div class="line">      <span class="keyword">try</span> &#123;</div><div class="line">        <span class="comment">// check if this partition is still being reassigned or not</span></div><div class="line">        <span class="comment">//note: 检查这个副本是不是还在迁移中（这个方法只用于副本迁移中）</span></div><div class="line">        controllerContext.partitionsBeingReassigned.get(topicAndPartition) <span class="keyword">match</span> &#123;</div><div class="line">          <span class="keyword">case</span> <span class="type">Some</span>(reassignedPartitionContext) =&gt;</div><div class="line">            <span class="comment">// need to re-read leader and isr from zookeeper since the zkclient callback doesn't return the Stat object</span></div><div class="line">            <span class="comment">//note: 从 zk 获取最新的 leader 和 isr 信息</span></div><div class="line">            <span class="keyword">val</span> newLeaderAndIsrOpt = zkUtils.getLeaderAndIsrForPartition(topic, partition)</div><div class="line">            newLeaderAndIsrOpt <span class="keyword">match</span> &#123;</div><div class="line">              <span class="keyword">case</span> <span class="type">Some</span>(leaderAndIsr) =&gt; <span class="comment">// check if new replicas have joined ISR</span></div><div class="line">                <span class="keyword">val</span> caughtUpReplicas = reassignedReplicas &amp; leaderAndIsr.isr.toSet</div><div class="line">                <span class="keyword">if</span>(caughtUpReplicas == reassignedReplicas) &#123; <span class="comment">//note: 新分配的副本已经全部在 isr 中了</span></div><div class="line">                  <span class="comment">// resume the partition reassignment process</span></div><div class="line">                  info(<span class="string">"%d/%d replicas have caught up with the leader for partition %s being reassigned."</span></div><div class="line">                    .format(caughtUpReplicas.size, reassignedReplicas.size, topicAndPartition) +</div><div class="line">                    <span class="string">"Resuming partition reassignment"</span>)</div><div class="line">                  <span class="comment">//note: 再次触发 onPartitionReassignment 方法,副本已经迁移完成</span></div><div class="line">                  controller.onPartitionReassignment(topicAndPartition, reassignedPartitionContext)</div><div class="line">                &#125;</div><div class="line">                <span class="keyword">else</span> &#123;  <span class="comment">//note: 否则不进行任何处理</span></div><div class="line">                  info(<span class="string">"%d/%d replicas have caught up with the leader for partition %s being reassigned."</span></div><div class="line">                    .format(caughtUpReplicas.size, reassignedReplicas.size, topicAndPartition) +</div><div class="line">                    <span class="string">"Replica(s) %s still need to catch up"</span>.format((reassignedReplicas -- leaderAndIsr.isr.toSet).mkString(<span class="string">","</span>)))</div><div class="line">                &#125;</div><div class="line">              <span class="keyword">case</span> <span class="type">None</span> =&gt; error(<span class="string">"Error handling reassignment of partition %s to replicas %s as it was never created"</span></div><div class="line">                .format(topicAndPartition, reassignedReplicas.mkString(<span class="string">","</span>)))</div><div class="line">            &#125;</div><div class="line">          <span class="keyword">case</span> <span class="type">None</span> =&gt;</div><div class="line">        &#125;</div><div class="line">      &#125; <span class="keyword">catch</span> &#123;</div><div class="line">        <span class="keyword">case</span> e: <span class="type">Throwable</span> =&gt; error(<span class="string">"Error while handling partition reassignment"</span>, e)</div><div class="line">      &#125;</div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">doHandleDataDeleted</span></span>(dataPath: <span class="type">String</span>) &#123;&#125;</div><div class="line"></div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>如果该 Partition 的 LeaderAndIsr 信息有变动，那么就会触发这个 listener 的 <code>doHandleDataChange()</code> 方法：</p>
<ol>
<li>首先检查这个 Partition 是否在还在迁移中，不在的话直接结束流程，因为这个监听器本来就是为了 Partition 副本迁移而服务的；</li>
<li>从 zk 获取最新的 leader 和 isr 信息，如果新分配的副本全部都在 isr 中，那么就再次触发 controller 的 <code>onPartitionReassignment()</code> 方法，再次调用时实际上已经证明了这个 Partition 的副本迁移已经完成，否则的话就会不进行任何处理，等待新分配的所有副本迁移完成。</li>
</ol>
<h2 id="副本迁移"><a href="#副本迁移" class="headerlink" title="副本迁移"></a>副本迁移</h2><p>Partition 副本迁移真正实际处理是在 Controller 的 <code>onPartitionReassignment()</code> 方法完成的，在看这个方法之前，先介绍几个基本的概念（假设一个 Partition 原来的 replica 是 {1、2、3}，新分配的副本列表是：{2、3、4}）：</p>
<ul>
<li>RAR = Reassigned replicas，即新分配的副本列表，也就是 {2、3、4}；</li>
<li>OAR = Original list of replicas for partition，即这个 Partition 原来的副本列表，也就是 {1、2、3}；</li>
<li>AR = current assigned replicas，该 Partition 当前的副本列表，这个会随着阶段的不同而变化；</li>
<li>RAR-OAR：需要创建、数据同步的新副本，也就是 {4}；</li>
<li>OAR-RAR：不需要创建、数据同步的副本，也就是{2、3}</li>
</ul>
<p>这个方法的实现如下所示：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//note: 这个回调方法被 reassigned partitions listener 触发,当需要进行分区副本迁移时,会在【/admin/reassign_partitions】下创建一个节点来触发操作</span></div><div class="line"><span class="comment">//note: RAR: 重新分配的副本, OAR: 这个分区原来的副本列表, AR: 当前的分配的副本</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">onPartitionReassignment</span></span>(topicAndPartition: <span class="type">TopicAndPartition</span>, reassignedPartitionContext: <span class="type">ReassignedPartitionsContext</span>) &#123;</div><div class="line">  <span class="keyword">val</span> reassignedReplicas = reassignedPartitionContext.newReplicas</div><div class="line">  <span class="keyword">if</span> (!areReplicasInIsr(topicAndPartition.topic, topicAndPartition.partition, reassignedReplicas)) &#123;</div><div class="line">    <span class="comment">//note: 新分配的并没有权限在 isr 中</span></div><div class="line">    info(<span class="string">"New replicas %s for partition %s being "</span>.format(reassignedReplicas.mkString(<span class="string">","</span>), topicAndPartition) +</div><div class="line">      <span class="string">"reassigned not yet caught up with the leader"</span>)</div><div class="line">    <span class="comment">//note: RAR-OAR</span></div><div class="line">    <span class="keyword">val</span> newReplicasNotInOldReplicaList = reassignedReplicas.toSet -- controllerContext.partitionReplicaAssignment(topicAndPartition).toSet</div><div class="line">    <span class="comment">//note: RAR+OAR</span></div><div class="line">    <span class="keyword">val</span> newAndOldReplicas = (reassignedPartitionContext.newReplicas ++ controllerContext.partitionReplicaAssignment(topicAndPartition)).toSet</div><div class="line">    <span class="comment">//1. Update AR in ZK with OAR + RAR.</span></div><div class="line">    updateAssignedReplicasForPartition(topicAndPartition, newAndOldReplicas.toSeq)</div><div class="line">    <span class="comment">//2. Send LeaderAndIsr request to every replica in OAR + RAR (with AR as OAR + RAR).</span></div><div class="line">    updateLeaderEpochAndSendRequest(topicAndPartition, controllerContext.partitionReplicaAssignment(topicAndPartition),</div><div class="line">      newAndOldReplicas.toSeq)</div><div class="line">    <span class="comment">//3. replicas in RAR - OAR -&gt; NewReplica</span></div><div class="line">    <span class="comment">//note: 新分配的副本状态更新为 NewReplica（在第二步中发送 LeaderAndIsr 请求时,新的副本会开始创建并且同步数据）</span></div><div class="line">    startNewReplicasForReassignedPartition(topicAndPartition, reassignedPartitionContext, newReplicasNotInOldReplicaList)</div><div class="line">    info(<span class="string">"Waiting for new replicas %s for partition %s being "</span>.format(reassignedReplicas.mkString(<span class="string">","</span>), topicAndPartition) +</div><div class="line">      <span class="string">"reassigned to catch up with the leader"</span>)</div><div class="line">  &#125; <span class="keyword">else</span> &#123; <span class="comment">//note: 新副本全在 isr 中了</span></div><div class="line">    <span class="comment">//4. Wait until all replicas in RAR are in sync with the leader.</span></div><div class="line">   <span class="comment">//note: 【OAR-RAR】</span></div><div class="line">    <span class="keyword">val</span> oldReplicas = controllerContext.partitionReplicaAssignment(topicAndPartition).toSet -- reassignedReplicas.toSet</div><div class="line">    <span class="comment">//5. replicas in RAR -&gt; OnlineReplica</span></div><div class="line">    <span class="comment">//note: RAR 中的副本都在 isr 中了,将副本状态设置为 OnlineReplica</span></div><div class="line">    reassignedReplicas.foreach &#123; replica =&gt;</div><div class="line">      replicaStateMachine.handleStateChanges(<span class="type">Set</span>(<span class="keyword">new</span> <span class="type">PartitionAndReplica</span>(topicAndPartition.topic, topicAndPartition.partition,</div><div class="line">        replica)), <span class="type">OnlineReplica</span>)</div><div class="line">    &#125;</div><div class="line">    <span class="comment">//6. Set AR to RAR in memory.</span></div><div class="line">    <span class="comment">//7. Send LeaderAndIsr request with a potential new leader (if current leader not in RAR) and</span></div><div class="line">    <span class="comment">//   a new AR (using RAR) and same isr to every broker in RAR</span></div><div class="line">    <span class="comment">//note: 到这一步,新加入的 replica 已经同步完成,leader和isr都更新到最新的结果</span></div><div class="line">    moveReassignedPartitionLeaderIfRequired(topicAndPartition, reassignedPartitionContext)</div><div class="line">    <span class="comment">//8. replicas in OAR - RAR -&gt; Offline (force those replicas out of isr)</span></div><div class="line">    <span class="comment">//9. replicas in OAR - RAR -&gt; NonExistentReplica (force those replicas to be deleted)</span></div><div class="line">    <span class="comment">//note: 下线旧的副本</span></div><div class="line">    stopOldReplicasOfReassignedPartition(topicAndPartition, reassignedPartitionContext, oldReplicas)</div><div class="line">    <span class="comment">//10. Update AR in ZK with RAR.</span></div><div class="line">    updateAssignedReplicasForPartition(topicAndPartition, reassignedReplicas)</div><div class="line">    <span class="comment">//11. Update the /admin/reassign_partitions path in ZK to remove this partition.</span></div><div class="line">    <span class="comment">//note: partition 迁移完成,从待迁移的集合中移除该 Partition</span></div><div class="line">    removePartitionFromReassignedPartitions(topicAndPartition)</div><div class="line">    info(<span class="string">"Removed partition %s from the list of reassigned partitions in zookeeper"</span>.format(topicAndPartition))</div><div class="line">    controllerContext.partitionsBeingReassigned.remove(topicAndPartition)</div><div class="line">    <span class="comment">//12. After electing leader, the replicas and isr information changes, so resend the update metadata request to every broker</span></div><div class="line">    <span class="comment">//note: 发送 metadata 更新请求给所有存活的 broker</span></div><div class="line">    sendUpdateMetadataRequest(controllerContext.liveOrShuttingDownBrokerIds.toSeq, <span class="type">Set</span>(topicAndPartition))</div><div class="line">    <span class="comment">// signal delete topic thread if reassignment for some partitions belonging to topics being deleted just completed</span></div><div class="line">    <span class="comment">//note: topic 删除恢复（如果当前 topic 设置了删除,之前由于无法删除）</span></div><div class="line">    deleteTopicManager.resumeDeletionForTopics(<span class="type">Set</span>(topicAndPartition.topic))</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>这个方法整体分为以下12个步骤：</p>
<ol>
<li>把 AR = OAR+RAR （{1、2、3、4}）更新到 zk 及本地 Controller 缓存中;</li>
<li>发送 LeaderAndIsr 给 AR 中每一个副本,并且会强制更新 zk 中 leader 的 epoch;</li>
<li>创建需要新建的副本（【RAR-OAR】，即 {4}）,将其状态设置为 NewReplica；</li>
<li>等待直到 RAR（{2、3、4}） 中的所有副本都在 ISR 中;</li>
<li>把 RAR（{2、3、4}） 中的所有副本设置为 OnReplica 状态;</li>
<li>将缓存中 AR 更新为 RAR（重新分配的副本列表，即 {2、3、4}）;</li>
<li>如果 leader 不在 RAR 中, 就从 RAR 选择对应的 leader, 然后发送 LeaderAndIsr 请求；如果不需要，那么只会更新 leader epoch，然后发送 LeaderAndIsr 请求; 在发送 LeaderAndIsr 请求前设置了 AR=RAR, 这将确保了 leader 在 isr 中不会添加任何 【RAR-OAR】中的副本（old replica，即 {1}）；</li>
<li>将【OAR-RAR】（{1}）中的副本设置为 OfflineReplica 状态，OfflineReplica 状态的变化，将会从 ISR 中删除【OAR-RAR】的副本，更新到 zk 中并发送 LeaderAndIsr 请求给 leader，通知 leader isr 变动。之后再发送 StopReplica 请求（delete=false）给【OAR-RAR】中的副本；</li>
<li>将【OAR-RAR】中的副本设置为 NonExistentReplica 状态。这将发送 StopReplica 请求（delete=true）给【OAR-RAR】中的副本，这些副本将会从本地上删除数据；</li>
<li>在 zk 中更新 AR 为 RAR；</li>
<li>更新 zk 中路径 【/admin/reassign_partitions】信息，移除已经成功迁移的 Partition；</li>
<li>leader 选举之后，这个 replica 和 isr 信息将会变动，发送 metadata 更新给所有的 broker。</li>
</ol>
<p>上面的流程简单来说，就是先创建新的 replica，开始同步数据，等待所有新的分配都加入到了 isr 中后，开始进行 leader 选举（需要的情况下），下线不需要的副本（OAR-RAR），下线完成后将 Partition 的最新 AR （即 RAR）信息更新到 zk 中，最后发送相应的请求给 broker，到这里一个 Partition 的副本迁移算是完成了。</p>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[Kafka 源码解析之副本状态机与分区状态机（十七）]]></title>
      <url>http://matt33.com/2018/06/16/controller-state-machine/</url>
      <content type="html"><![CDATA[<p>上篇讲述了 KafkaController 的启动流程，但是关于分区状态机和副本状态机的初始化并没有触及，分区状态机和副本状态机的内容将在本篇文章深入讲述。分区状态机记录着当前集群所有 Partition 的状态信息以及如何对 Partition 状态转移进行相应的处理；副本状态机则是记录着当前集群所有 Replica 的状态信息以及如何对 Replica 状态转变进行相应的处理。</p>
<h2 id="ReplicaStateMachine"><a href="#ReplicaStateMachine" class="headerlink" title="ReplicaStateMachine"></a>ReplicaStateMachine</h2><p>ReplicaStateMachine 记录着集群所有 Replica 的状态信息，它决定着一个 replica 处在什么状态以及它在什么状态下可以转变为什么状态，Kafka 中副本的状态总共有以下七种类型：</p>
<ol>
<li>NewReplica：这种状态下 Controller 可以创建这个 Replica，这种状态下该 Replica 只能作为 follower，它可以是 Replica 删除后的一个临时状态，它有效的前置状态是 NonExistentReplica；</li>
<li>OnlineReplica：一旦这个 Replica 被分配到指定的 Partition 上，并且 Replica 创建完成，那么它将会被置为这个状态，在这个状态下，这个 Replica 既可以作为 leader 也可以作为 follower，它有效的前置状态是  NewReplica、OnlineReplica 或 OfflineReplica；</li>
<li>OfflineReplica：如果一个 Replica 挂掉（所在的节点宕机或者其他情况），该 Replica 将会被转换到这个状态，它有的效前置状态是 NewReplica、OfflineReplica 或者 OnlineReplica；</li>
<li>ReplicaDeletionStarted：Replica 开始删除时被置为的状态，它有效的前置状态是 OfflineReplica；</li>
<li>ReplicaDeletionSuccessful：如果 Replica 在删除时没有遇到任何错误信息，它将被置为这个状态，这个状态代表该 Replica 的数据已经从节点上清除了，它有效的前置状态是 ReplicaDeletionStarted；</li>
<li>ReplicaDeletionIneligible：如果 Replica 删除失败，它将会转移到这个状态，这个状态意思是非法删除，也就是删除是无法成功的，它有效的前置状态是 ReplicaDeletionStarted；</li>
<li>NonExistentReplica：如果 Replica 删除成功，它将被转移到这个状态，它有效的前置状态是：ReplicaDeletionSuccessful。</li>
</ol>
<p>上面的状态中其中后面4是专门为 Replica 删除而服务的，副本状态机转移图如下所示：</p>
<p><img src="/images/kafka/replica_state.png" alt="副本状态机"></p>
<p>这张图是副本状态机的核心，在下面会详细讲述，接下来先看下 KafkaController 在启动时，调用 ReplicaStateMachine 的 <code>startup()</code> 方法初始化的处理过程。</p>
<h3 id="ReplicaStateMachine-初始化"><a href="#ReplicaStateMachine-初始化" class="headerlink" title="ReplicaStateMachine 初始化"></a>ReplicaStateMachine 初始化</h3><p>副本状态机初始化的过程如下：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//note: Controller 重新选举后触发的操作</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">startup</span></span>() &#123;</div><div class="line">  <span class="comment">// initialize replica state</span></div><div class="line">  <span class="comment">//note: 初始化 zk 上所有的 Replica 状态信息（replica 存活的话设置为 Online,不存活的设置为 ReplicaDeletionIneligible）</span></div><div class="line">  initializeReplicaState()</div><div class="line">  <span class="comment">// set started flag</span></div><div class="line">  hasStarted.set(<span class="literal">true</span>)</div><div class="line">  <span class="comment">// move all Online replicas to Online</span></div><div class="line">  <span class="comment">//note: 将存活的副本状态转变为 OnlineReplica</span></div><div class="line">  handleStateChanges(controllerContext.allLiveReplicas(), <span class="type">OnlineReplica</span>)</div><div class="line"></div><div class="line">  info(<span class="string">"Started replica state machine with initial state -&gt; "</span> + replicaState.toString())</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>在这个方法中，ReplicaStateMachine 先调用 <code>initializeReplicaState()</code> 方法初始化集群中所有 Replica 的状态信息，如果 Replica 所在机器是 alive 的，那么将其状态设置为 OnlineReplica，否则设置为 ReplicaDeletionIneligible 状态，这里只是将 Replica 的状态信息更新副本状态机的缓存 <code>replicaState</code> 中，并没有真正进行状态转移的操作。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//note: 初始化所有副本的状态信息</span></div><div class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">initializeReplicaState</span></span>() &#123;</div><div class="line">  <span class="keyword">for</span>((topicPartition, assignedReplicas) &lt;- controllerContext.partitionReplicaAssignment) &#123;</div><div class="line">    <span class="keyword">val</span> topic = topicPartition.topic</div><div class="line">    <span class="keyword">val</span> partition = topicPartition.partition</div><div class="line">    assignedReplicas.foreach &#123; replicaId =&gt;</div><div class="line">      <span class="keyword">val</span> partitionAndReplica = <span class="type">PartitionAndReplica</span>(topic, partition, replicaId)</div><div class="line">      <span class="keyword">if</span> (controllerContext.liveBrokerIds.contains(replicaId)) <span class="comment">//note: 如果副本是存活,那么将状态都设置为 OnlineReplica</span></div><div class="line">        replicaState.put(partitionAndReplica, <span class="type">OnlineReplica</span>)</div><div class="line">      <span class="keyword">else</span></div><div class="line">        <span class="comment">// mark replicas on dead brokers as failed for topic deletion, if they belong to a topic to be deleted.</span></div><div class="line">        <span class="comment">// This is required during controller failover since during controller failover a broker can go down,</span></div><div class="line">        <span class="comment">// so the replicas on that broker should be moved to ReplicaDeletionIneligible to be on the safer side.</span></div><div class="line">        <span class="comment">//note: 将不存活的副本状态设置为 ReplicaDeletionIneligible</span></div><div class="line">        replicaState.put(partitionAndReplica, <span class="type">ReplicaDeletionIneligible</span>)</div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>接着第二步调用 <code>handleStateChanges()</code> 将所有存活的副本状态转移为 OnlineReplica 状态，这里才是真正进行状态转移的地方，其具体实现如下：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//note: 用于处理 Replica 状态的变化</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">handleStateChanges</span></span>(replicas: <span class="type">Set</span>[<span class="type">PartitionAndReplica</span>], targetState: <span class="type">ReplicaState</span>,</div><div class="line">                       callbacks: <span class="type">Callbacks</span> = (<span class="keyword">new</span> <span class="type">CallbackBuilder</span>).build) &#123;</div><div class="line">  <span class="keyword">if</span>(replicas.nonEmpty) &#123;</div><div class="line">    info(<span class="string">"Invoking state change to %s for replicas %s"</span>.format(targetState, replicas.mkString(<span class="string">","</span>)))</div><div class="line">    <span class="keyword">try</span> &#123;</div><div class="line">      brokerRequestBatch.newBatch()</div><div class="line">      <span class="comment">//note: 状态转变</span></div><div class="line">      replicas.foreach(r =&gt; handleStateChange(r, targetState, callbacks))</div><div class="line">      <span class="comment">//note: 向 broker 发送相应请求</span></div><div class="line">      brokerRequestBatch.sendRequestsToBrokers(controller.epoch)</div><div class="line">    &#125;<span class="keyword">catch</span> &#123;</div><div class="line">      <span class="keyword">case</span> e: <span class="type">Throwable</span> =&gt; error(<span class="string">"Error while moving some replicas to %s state"</span>.format(targetState), e)</div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>这里是副本状态机 <code>startup()</code> 方法的最后一步，它的目的是将所有 alive 的 Replica 状态转移到 OnlineReplica 状态，由于前面已经这些 alive replica 的状态设置成了 OnlineReplica，所以这里 Replica 的状态转移情况是：<strong>OnlineReplica –&gt; OnlineReplica</strong>，这个方法主要是做了两件事：</p>
<ol>
<li>状态转移（这个在下面详细讲述）；</li>
<li>发送相应的请求。</li>
</ol>
<h3 id="副本的状态转移"><a href="#副本的状态转移" class="headerlink" title="副本的状态转移"></a>副本的状态转移</h3><p>这里以要转移的 TargetState 区分做详细详细讲解，当 TargetState 分别是 NewReplica、ReplicaDeletionStarted、ReplicaDeletionIneligible、ReplicaDeletionSuccessful、NonExistentReplica、OnlineReplica 或者 OfflineReplica 时，副本状态机所做的事情。</p>
<h4 id="TargetState-NewReplica"><a href="#TargetState-NewReplica" class="headerlink" title="TargetState: NewReplica"></a>TargetState: NewReplica</h4><p>NewReplica 这个状态是 Replica 准备开始创建是的一个状态，其实现逻辑如下：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">val</span> currState = replicaState.getOrElseUpdate(partitionAndReplica, <span class="type">NonExistentReplica</span>)<span class="comment">//note: Replica 不存在的话,状态初始化为 NonExistentReplica</span></div><div class="line">assertValidPreviousStates(partitionAndReplica, <span class="type">List</span>(<span class="type">NonExistentReplica</span>), targetState)<span class="comment">//note: 验证</span></div><div class="line"><span class="comment">// start replica as a follower to the current leader for its partition</span></div><div class="line"><span class="comment">//note: 从 zk 获取 Partition 的 leaderAndIsr 信息</span></div><div class="line"><span class="keyword">val</span> leaderIsrAndControllerEpochOpt = <span class="type">ReplicationUtils</span>.getLeaderIsrAndEpochForPartition(zkUtils, topic, partition)</div><div class="line">leaderIsrAndControllerEpochOpt <span class="keyword">match</span> &#123;</div><div class="line">  <span class="keyword">case</span> <span class="type">Some</span>(leaderIsrAndControllerEpoch) =&gt;</div><div class="line">    <span class="keyword">if</span>(leaderIsrAndControllerEpoch.leaderAndIsr.leader == replicaId)<span class="comment">//note: 这个状态的 Replica 不能作为 leader</span></div><div class="line">      <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">StateChangeFailedException</span>(<span class="string">"Replica %d for partition %s cannot be moved to NewReplica"</span></div><div class="line">        .format(replicaId, topicAndPartition) + <span class="string">"state as it is being requested to become leader"</span>)</div><div class="line">    <span class="comment">//note: 向该 replicaId 发送 LeaderAndIsr 请求,这个方法同时也会向所有的 broker 发送 updateMeta 请求</span></div><div class="line">    brokerRequestBatch.addLeaderAndIsrRequestForBrokers(<span class="type">List</span>(replicaId),</div><div class="line">                                                        topic, partition, leaderIsrAndControllerEpoch,</div><div class="line">                                                        replicaAssignment)</div><div class="line">  <span class="keyword">case</span> <span class="type">None</span> =&gt; <span class="comment">// new leader request will be sent to this replica when one gets elected</span></div><div class="line">&#125;</div><div class="line">replicaState.put(partitionAndReplica, <span class="type">NewReplica</span>)<span class="comment">//note: 缓存这个 replica 对象的状态</span></div><div class="line">stateChangeLogger.trace(<span class="string">"Controller %d epoch %d changed state of replica %d for partition %s from %s to %s"</span></div><div class="line">                          .format(controllerId, controller.epoch, replicaId, topicAndPartition, currState,</div><div class="line">                                  targetState))</div></pre></td></tr></table></figure>
<p>当想要把 Replica 的状态转移为 NewReplica 时，副本状态机的处理逻辑如下：</p>
<ol>
<li>校验 Replica 的前置状态，只有处于 NonExistentReplica 状态的副本才能转移到 NewReplica 状态；</li>
<li>从 zk 中获取该 Topic-Partition 的 LeaderIsrAndControllerEpoch 信息；</li>
<li>如果获取不到上述信息，直接将该 Replica 的状态转移成 NewReplica，然后结束流程（对与新建的 Partition，处于这个状态时，该 Partition 是没有相应的 LeaderAndIsr 信息的）；</li>
<li>获取到 Partition 的 LeaderIsrAndControllerEpoch 信息，如果发现该 Partition 的 leader 是当前副本，那么就抛出 StateChangeFailedException 异常，因为处在这个状态的 Replica 是不能被选举为 leader 的；</li>
<li>获取到了 Partition 的 LeaderIsrAndControllerEpoch 信息，并且该 Partition 的 leader 不是当前 replica，那么向该 Partition 的所有 Replica 添加一个 LeaderAndIsr 请求（添加 LeaderAndIsr 请求时，实际上也会向所有的 Broker 都添加一个 Update-Metadata 请求）；</li>
<li>最后将该 Replica 的状态转移成 NewReplica，然后结束流程。</li>
</ol>
<h4 id="TargetState-ReplicaDeletionStarted"><a href="#TargetState-ReplicaDeletionStarted" class="headerlink" title="TargetState: ReplicaDeletionStarted"></a>TargetState: ReplicaDeletionStarted</h4><p>这是 Replica 开始删除时的状态，Replica 转移到这种状态的处理实现如下：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">assertValidPreviousStates(partitionAndReplica, <span class="type">List</span>(<span class="type">OfflineReplica</span>), targetState)</div><div class="line">replicaState.put(partitionAndReplica, <span class="type">ReplicaDeletionStarted</span>)</div><div class="line"><span class="comment">// send stop replica command</span></div><div class="line"><span class="comment">//note: 发送 StopReplica 请求给该副本,并设置 deletePartition=true</span></div><div class="line">brokerRequestBatch.addStopReplicaRequestForBrokers(<span class="type">List</span>(replicaId), topic, partition, deletePartition = <span class="literal">true</span>,</div><div class="line">  callbacks.stopReplicaResponseCallback)</div><div class="line">stateChangeLogger.trace(<span class="string">"Controller %d epoch %d changed state of replica %d for partition %s from %s to %s"</span></div><div class="line">  .format(controllerId, controller.epoch, replicaId, topicAndPartition, currState, targetState))</div></pre></td></tr></table></figure>
<p>这部分的实现逻辑：</p>
<ol>
<li>校验其前置状态，Replica 只能是在 OfflineReplica 的情况下才能转移到这种状态；</li>
<li>更新向该 Replica 的状态为 ReplicaDeletionStarted；</li>
<li>向该 replica 发送 StopReplica 请求（deletePartition = true），收到这请求后，broker 会从物理存储上删除这个 Replica 的数据内容；</li>
<li>如果请求返回的话会触发其回调函数（这部分会在 topic 删除部分讲解）。</li>
</ol>
<h4 id="TargetState-ReplicaDeletionIneligible"><a href="#TargetState-ReplicaDeletionIneligible" class="headerlink" title="TargetState: ReplicaDeletionIneligible"></a>TargetState: ReplicaDeletionIneligible</h4><p>ReplicaDeletionIneligible 是副本删除失败时的状态，Replica 转移到这种状态的处理实现如下：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">assertValidPreviousStates(partitionAndReplica, <span class="type">List</span>(<span class="type">ReplicaDeletionStarted</span>), targetState)</div><div class="line">replicaState.put(partitionAndReplica, <span class="type">ReplicaDeletionIneligible</span>)</div><div class="line">stateChangeLogger.trace(<span class="string">"Controller %d epoch %d changed state of replica %d for partition %s from %s to %s"</span></div><div class="line">  .format(controllerId, controller.epoch, replicaId, topicAndPartition, currState, targetState))</div></pre></td></tr></table></figure>
<p>实现逻辑：</p>
<ol>
<li>校验其前置状态，Replica 只能是在 ReplicaDeletionStarted 下才能转移这种状态；</li>
<li>更新该 Replica 的状态为 ReplicaDeletionIneligible。</li>
</ol>
<h4 id="TargetState-ReplicaDeletionSuccessful"><a href="#TargetState-ReplicaDeletionSuccessful" class="headerlink" title="TargetState: ReplicaDeletionSuccessful"></a>TargetState: ReplicaDeletionSuccessful</h4><p>ReplicaDeletionSuccessful 是副本删除成功时的状态，Replica 转移到这种状态的处理实现如下：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">assertValidPreviousStates(partitionAndReplica, <span class="type">List</span>(<span class="type">ReplicaDeletionStarted</span>), targetState)</div><div class="line">replicaState.put(partitionAndReplica, <span class="type">ReplicaDeletionSuccessful</span>)</div><div class="line">stateChangeLogger.trace(<span class="string">"Controller %d epoch %d changed state of replica %d for partition %s from %s to %s"</span></div><div class="line">  .format(controllerId, controller.epoch, replicaId, topicAndPartition, currState, targetState))</div></pre></td></tr></table></figure>
<p>实现逻辑：</p>
<ol>
<li>检验其前置状态，Replica 只能是在 ReplicaDeletionStarted 下才能转移这种状态；</li>
<li>更新该 Replica 的状态为 ReplicaDeletionSuccessful。</li>
</ol>
<h4 id="TargetState-NonExistentReplica"><a href="#TargetState-NonExistentReplica" class="headerlink" title="TargetState: NonExistentReplica"></a>TargetState: NonExistentReplica</h4><p>NonExistentReplica 是副本完全删除、不存在这个副本的状态，Replica 转移到这种状态的处理实现如下：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">assertValidPreviousStates(partitionAndReplica, <span class="type">List</span>(<span class="type">ReplicaDeletionSuccessful</span>), targetState)</div><div class="line"><span class="comment">// remove this replica from the assigned replicas list for its partition</span></div><div class="line"><span class="keyword">val</span> currentAssignedReplicas = controllerContext.partitionReplicaAssignment(topicAndPartition)</div><div class="line"><span class="comment">//note: 从 controller 和副本状态机的缓存中清除这个 Replica 的记录西溪</span></div><div class="line">controllerContext.partitionReplicaAssignment.put(topicAndPartition, currentAssignedReplicas.filterNot(_ == replicaId))</div><div class="line">replicaState.remove(partitionAndReplica)</div><div class="line">stateChangeLogger.trace(<span class="string">"Controller %d epoch %d changed state of replica %d for partition %s from %s to %s"</span></div><div class="line">  .format(controllerId, controller.epoch, replicaId, topicAndPartition, currState, targetState))</div></pre></td></tr></table></figure>
<p>实现逻辑：</p>
<ol>
<li>检验其前置状态，Replica 只能是在 ReplicaDeletionSuccessful 下才能转移这种状态；</li>
<li>在 controller 的 partitionReplicaAssignment 删除这个 Partition 对应的 replica 信息；</li>
<li>从 Controller 和副本状态机中将这个 Topic 从缓存中删除。</li>
</ol>
<h4 id="TargetState-OnlineReplica"><a href="#TargetState-OnlineReplica" class="headerlink" title="TargetState: OnlineReplica"></a>TargetState: OnlineReplica</h4><p>OnlineReplica 是副本正常工作时的状态，此时的 Replica 既可以作为 leader 也可以作为 follower，Replica 转移到这种状态的处理实现如下：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div></pre></td><td class="code"><pre><div class="line">assertValidPreviousStates(partitionAndReplica,</div><div class="line">  <span class="type">List</span>(<span class="type">NewReplica</span>, <span class="type">OnlineReplica</span>, <span class="type">OfflineReplica</span>, <span class="type">ReplicaDeletionIneligible</span>), targetState)</div><div class="line">replicaState(partitionAndReplica) <span class="keyword">match</span> &#123;</div><div class="line">  <span class="keyword">case</span> <span class="type">NewReplica</span> =&gt; <span class="comment">//note: NewReplica --&gt; OnlineReplica</span></div><div class="line">    <span class="comment">// add this replica to the assigned replicas list for its partition</span></div><div class="line">    <span class="comment">//note: 向 the assigned replicas list 添加这个 replica（正常情况下这些 replicas 已经更新到 list 中了）</span></div><div class="line">    <span class="keyword">val</span> currentAssignedReplicas = controllerContext.partitionReplicaAssignment(topicAndPartition)</div><div class="line">    <span class="keyword">if</span>(!currentAssignedReplicas.contains(replicaId))</div><div class="line">      controllerContext.partitionReplicaAssignment.put(topicAndPartition, currentAssignedReplicas :+ replicaId)</div><div class="line">    stateChangeLogger.trace(<span class="string">"Controller %d epoch %d changed state of replica %d for partition %s from %s to %s"</span></div><div class="line">                              .format(controllerId, controller.epoch, replicaId, topicAndPartition, currState,</div><div class="line">                                      targetState))</div><div class="line">  <span class="keyword">case</span> _ =&gt; <span class="comment">//note: OnlineReplica/OfflineReplica/ReplicaDeletionIneligible --&gt; OnlineReplica</span></div><div class="line">    <span class="comment">// check if the leader for this partition ever existed</span></div><div class="line">    <span class="comment">//note: 如果该 Partition 的 LeaderIsrAndControllerEpoch 信息存在,那么就更新副本的状态,并发送相应的请求</span></div><div class="line">    controllerContext.partitionLeadershipInfo.get(topicAndPartition) <span class="keyword">match</span> &#123;</div><div class="line">      <span class="keyword">case</span> <span class="type">Some</span>(leaderIsrAndControllerEpoch) =&gt;</div><div class="line">        brokerRequestBatch.addLeaderAndIsrRequestForBrokers(<span class="type">List</span>(replicaId), topic, partition, leaderIsrAndControllerEpoch,</div><div class="line">          replicaAssignment)</div><div class="line">        replicaState.put(partitionAndReplica, <span class="type">OnlineReplica</span>)</div><div class="line">        stateChangeLogger.trace(<span class="string">"Controller %d epoch %d changed state of replica %d for partition %s from %s to %s"</span></div><div class="line">          .format(controllerId, controller.epoch, replicaId, topicAndPartition, currState, targetState))</div><div class="line">      <span class="keyword">case</span> <span class="type">None</span> =&gt; <span class="comment">// that means the partition was never in OnlinePartition state, this means the broker never</span></div><div class="line">        <span class="comment">// started a log for that partition and does not have a high watermark value for this partition</span></div><div class="line">    &#125;</div><div class="line">&#125;</div><div class="line">replicaState.put(partitionAndReplica, <span class="type">OnlineReplica</span>)</div></pre></td></tr></table></figure>
<p>从前面的状态转移图中可以看出，当 Replica 处在 NewReplica、OnlineReplica、OfflineReplica 或者 ReplicaDeletionIneligible 状态时，Replica 是可以转移到 OnlineReplica 状态的，下面分两种情况讲述：</p>
<p><strong>NewReplica –&gt; OnlineReplica</strong> 的处理逻辑如下：</p>
<ol>
<li>从 Controller 的 partitionReplicaAssignment 中获取这个 Partition 的 AR；</li>
<li>如果 Replica 不在 AR 中的话，那么就将其添加到 Partition 的 AR 中；</li>
<li>最后将 Replica 的状态设置为 OnlineReplica 状态。</li>
</ol>
<p><strong>OnlineReplica/OfflineReplica/ReplicaDeletionIneligible –&gt; OnlineReplica</strong> 的处理逻辑如下：</p>
<ol>
<li>从 Controller 的 partitionLeadershipInfo 中获取 Partition 的 LeaderAndIsr 信息；</li>
<li>如果该信息存在，那么就向这个 Replica 所在 broker 添加这个 Partition 的 LeaderAndIsr 请求，并将 Replica 的状态设置为 OnlineReplica 状态；</li>
<li>否则不做任务处理；</li>
<li>最后更新R Replica 的状态为 OnlineReplica。</li>
</ol>
<h4 id="TargetState-OfflineReplica"><a href="#TargetState-OfflineReplica" class="headerlink" title="TargetState: OfflineReplica"></a>TargetState: OfflineReplica</h4><p>OfflineReplica 是 Replica 所在 Broker 掉线时 Replica 的状态，转移到这种状态的处理逻辑如下：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div></pre></td><td class="code"><pre><div class="line">assertValidPreviousStates(partitionAndReplica,</div><div class="line">  <span class="type">List</span>(<span class="type">NewReplica</span>, <span class="type">OnlineReplica</span>, <span class="type">OfflineReplica</span>, <span class="type">ReplicaDeletionIneligible</span>), targetState)</div><div class="line"><span class="comment">// send stop replica command to the replica so that it stops fetching from the leader</span></div><div class="line"><span class="comment">//note: 发送 StopReplica 请求给该副本,先停止副本同步</span></div><div class="line">brokerRequestBatch.addStopReplicaRequestForBrokers(<span class="type">List</span>(replicaId), topic, partition, deletePartition = <span class="literal">false</span>)</div><div class="line"><span class="comment">// As an optimization, the controller removes dead replicas from the ISR</span></div><div class="line"><span class="keyword">val</span> leaderAndIsrIsEmpty: <span class="type">Boolean</span> =</div><div class="line">  controllerContext.partitionLeadershipInfo.get(topicAndPartition) <span class="keyword">match</span> &#123;</div><div class="line">    <span class="keyword">case</span> <span class="type">Some</span>(_) =&gt;</div><div class="line">      controller.removeReplicaFromIsr(topic, partition, replicaId) <span class="keyword">match</span> &#123; <span class="comment">//note: 从 isr 中移除这个副本（前提是 ISR 有其他有效副本）</span></div><div class="line">        <span class="keyword">case</span> <span class="type">Some</span>(updatedLeaderIsrAndControllerEpoch) =&gt;</div><div class="line">          <span class="comment">// send the shrunk ISR state change request to all the remaining alive replicas of the partition.</span></div><div class="line">          <span class="comment">//note: 发送 LeaderAndIsr 请求给剩余的其他副本,因为 ISR 变动了</span></div><div class="line">          <span class="keyword">val</span> currentAssignedReplicas = controllerContext.partitionReplicaAssignment(topicAndPartition)</div><div class="line">          <span class="keyword">if</span> (!controller.deleteTopicManager.isPartitionToBeDeleted(topicAndPartition)) &#123;</div><div class="line">            brokerRequestBatch.addLeaderAndIsrRequestForBrokers(currentAssignedReplicas.filterNot(_ == replicaId),</div><div class="line">              topic, partition, updatedLeaderIsrAndControllerEpoch, replicaAssignment)</div><div class="line">          &#125;</div><div class="line">          replicaState.put(partitionAndReplica, <span class="type">OfflineReplica</span>)</div><div class="line">          stateChangeLogger.trace(<span class="string">"Controller %d epoch %d changed state of replica %d for partition %s from %s to %s"</span></div><div class="line">            .format(controllerId, controller.epoch, replicaId, topicAndPartition, currState, targetState))</div><div class="line">          <span class="literal">false</span></div><div class="line">        <span class="keyword">case</span> <span class="type">None</span> =&gt;</div><div class="line">          <span class="literal">true</span></div><div class="line">      &#125;</div><div class="line">    <span class="keyword">case</span> <span class="type">None</span> =&gt;</div><div class="line">      <span class="literal">true</span></div><div class="line">  &#125;</div><div class="line"><span class="keyword">if</span> (leaderAndIsrIsEmpty &amp;&amp; !controller.deleteTopicManager.isPartitionToBeDeleted(topicAndPartition))</div><div class="line">  <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">StateChangeFailedException</span>(</div><div class="line">    <span class="string">"Failed to change state of replica %d for partition %s since the leader and isr path in zookeeper is empty"</span></div><div class="line">    .format(replicaId, topicAndPartition))</div></pre></td></tr></table></figure>
<p>处理逻辑如下：</p>
<ol>
<li>校验其前置状态，只有 Replica 在 NewReplica、OnlineReplica、OfflineReplica 或者 ReplicaDeletionIneligible 状态时，才能转移到这种状态；</li>
<li>向该 Replica 所在节点发送 StopReplica 请求（deletePartition = false）；</li>
<li>调用 Controller 的 <code>removeReplicaFromIsr()</code> 方法将该 replica 从 Partition 的 isr 移除这个 replica（前提 isr 中还有其他有效副本），然后向该 Partition 的其他副本发送 LeaderAndIsr 请求；</li>
<li>更新这个 Replica 的状态为 OfflineReplica。</li>
</ol>
<h3 id="状态转移触发的条件"><a href="#状态转移触发的条件" class="headerlink" title="状态转移触发的条件"></a>状态转移触发的条件</h3><p>这里主要是看一下上面 Replica 各种转移的触发的条件，整理的结果如下表所示，部分内容会在后续文章讲解。</p>
<table>
<thead>
<tr>
<th>TargetState</th>
<th>触发方法</th>
<th>作用</th>
</tr>
</thead>
<tbody>
<tr>
<td>OnlineReplica</td>
<td>KafkaController 的 onBrokerStartup()</td>
<td>Broker 启动时，目的是将在该节点的 Replica 状态设置为 OnlineReplica</td>
</tr>
<tr>
<td>OnlineReplica</td>
<td>KafkaController 的 onNewPartitionCreation()</td>
<td>新建 Partition 时，Replica 初始化及 Partition 状态变成 OnlinePartition 后，新创建的 Replica 状态也变为 OnlineReplica；</td>
</tr>
<tr>
<td>OnlineReplica</td>
<td>KafkaController 的 onPartitionReassignment()</td>
<td>副本迁移完成后，RAR 中的副本设置为 OnlineReplica 状态</td>
</tr>
<tr>
<td>OnlineReplica</td>
<td>ReplicaStateMachine 的 startup()</td>
<td>副本状态机刚初始化启动时，将存活的副本状态设置为 OnlineReplica</td>
</tr>
<tr>
<td>OfflineReplica</td>
<td>TopicDeletionManager 的  markTopicForDeletionRetry()</td>
<td>将删除失败的 Replica 设置为 OfflineReplica，重新进行删除</td>
</tr>
<tr>
<td>OfflineReplica</td>
<td>TopicDeletionManager 的 startReplicaDeletion()</td>
<td>开始副本删除时，先将副本设置为 OfflineReplica</td>
</tr>
<tr>
<td>OfflineReplica</td>
<td>KafkaController 的 shutdownBroker() 方法</td>
<td>优雅关闭 broker 时，目的是把下线节点上的副本状态设置为 OfflineReplica</td>
</tr>
<tr>
<td>OfflineReplica</td>
<td>KafkaController 的 onBrokerFailure()</td>
<td>broker 掉线时，目的是把下线节点上的副本状态设置为 OfflineReplica</td>
</tr>
<tr>
<td>NewReplica</td>
<td>KafkaController 的 onNewPartitionCreation()</td>
<td>Partition 新建时，当 Partition 状态变为 NewPartition 后，副本的状态变为 NewReplica</td>
</tr>
<tr>
<td>NewReplica</td>
<td>KafkaController 的 startNewReplicasForReassignedPartition()</td>
<td>Partition 副本迁移时，将新分配的副本状态设置为 NewReplica；</td>
</tr>
<tr>
<td>ReplicaDeletionStarted</td>
<td>TopicDeletionManager 的  startReplicaDeletion()</td>
<td>下线副本时，将成功设置为 OfflineReplica 的 Replica 设置为 ReplicaDeletionStarted 状态，开始物理上删除副本数据（也是发送 StopReplica）</td>
</tr>
<tr>
<td>ReplicaDeletionStarted</td>
<td>KafkaController 的 stopOldReplicasOfReassignedPartition()</td>
<td>Partition 的副本迁移时，目的是下线那些 old replica，新的 replica 已经迁移到新分配的副本上了</td>
</tr>
<tr>
<td>ReplicaDeletionSuccessful</td>
<td>TopicDeletionManager 的  completeReplicaDeletion()</td>
<td>物理将数据成功删除的 Replica 状态会变为这个</td>
</tr>
<tr>
<td>ReplicaDeletionSuccessful</td>
<td>KafkaController 的 stopOldReplicasOfReassignedPartition()</td>
<td>Partition 的副本迁移时，在下线那些旧 Replica 时的一个状态，删除成功</td>
</tr>
<tr>
<td>ReplicaDeletionIneligible</td>
<td>TopicDeletionManager 的  startReplicaDeletion()</td>
<td>开始副本删除时，删除失败的副本会设置成这个状态</td>
</tr>
<tr>
<td>ReplicaDeletionIneligible</td>
<td>KafkaController 的 stopOldReplicasOfReassignedPartition()</td>
<td>Partition 副本迁移时，在下线那些旧的 Replica 时的一个状态，删除失败</td>
</tr>
<tr>
<td>NonExistentReplica</td>
<td>TopicDeletionManager 的  completeReplicaDeletion()</td>
<td>副本删除成功后（状态为 ReplicaDeletionSuccessful），从状态机和 Controller 的缓存中清除该副本的记录；</td>
</tr>
<tr>
<td>NonExistentReplica</td>
<td>KafkaController 的 stopOldReplicasOfReassignedPartition()</td>
<td>Partition 的副本成功迁移、旧副本成功删除后，从状态机和 Controller 的缓存中清除旧副本的记录</td>
</tr>
</tbody>
</table>
<h2 id="PartitionStateMachine"><a href="#PartitionStateMachine" class="headerlink" title="PartitionStateMachine"></a>PartitionStateMachine</h2><p>PartitionStateMachine 记录着集群所有 Partition 的状态信息，它决定着一个 Partition 处在什么状态以及它在什么状态下可以转变为什么状态，Kafka 中 Partition 的状态总共有以下四种类型：</p>
<ol>
<li>NonExistentPartition：这个代表着这个 Partition 之前没有被创建过或者之前创建了现在又被删除了，它有效的前置状态是 OfflinePartition；</li>
<li>NewPartition：Partition 创建后，它将处于这个状态，这个状态的 Partition 还没有 leader 和 isr，它有效的前置状态是 NonExistentPartition；</li>
<li>OnlinePartition：一旦这个 Partition 的 leader 被选举出来了，它将处于这个状态，它有效的前置状态是 NewPartition、OnlinePartition、OfflinePartition；</li>
<li>OfflinePartition：如果这个 Partition 的 leader 掉线，这个 Partition 将被转移到这个状态，它有效的前置状态是 NewPartition、OnlinePartition、OfflinePartition。</li>
</ol>
<p>分区状态机转移图如下所示：</p>
<p><img src="/images/kafka/partition_state.png" alt="分区状态机"></p>
<p>这张图是分区状态机的核心，在下面会详细讲述，接下来先看下 KafkaController 在启动时，调用 PartitionStateMachine 的 <code>startup()</code> 方法初始化的处理过程。</p>
<h3 id="PartitionStateMachine-初始化"><a href="#PartitionStateMachine-初始化" class="headerlink" title="PartitionStateMachine 初始化"></a>PartitionStateMachine 初始化</h3><p>PartitionStateMachine 的初始化方法如下所示：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//note: Controller 启动时触发</span></div><div class="line"><span class="comment">//note: 初始化所有 Partition 的状态（从 zk 获取）, 然后对于 new/offline Partition 触发选主（选主成功的话,变为 OnlinePartition）</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">startup</span></span>() &#123;</div><div class="line">  <span class="comment">// initialize partition state</span></div><div class="line">  <span class="comment">//note: 初始化 partition 的状态,如果 leader 所在 broker 是 alive 的,那么状态为 OnlinePartition,否则为 OfflinePartition</span></div><div class="line">  initializePartitionState()</div><div class="line">  <span class="comment">// set started flag</span></div><div class="line">  hasStarted.set(<span class="literal">true</span>)</div><div class="line">  <span class="comment">// try to move partitions to online state</span></div><div class="line">  <span class="comment">//note: 为所有处理 NewPartition 或 OnlinePartition 状态 Partition 选举 leader</span></div><div class="line">  triggerOnlinePartitionStateChange()</div><div class="line"></div><div class="line">  info(<span class="string">"Started partition state machine with initial state -&gt; "</span> + partitionState.toString())</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>在这个方法中，PartitionStateMachine 先调用 <code>initializePartitionState()</code> 方法初始化集群中所有 Partition 的状态信息：</p>
<ol>
<li>如果该 Partition 有 LeaderAndIsr 信息，那么如果 Partition leader 所在的机器是 alive 的，那么将其状态设置为 OnlinePartition，否则设置为 OfflinePartition 状态；</li>
<li>如果该 Partition 没有 LeaderAndIsr 信息，那么将其状态设置为 NewPartition。</li>
</ol>
<p>这里只是将 Partition 的状态信息更新分区状态机的缓存 <code>partitionState</code> 中，并没有真正进行状态的转移。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//note: 根据从 zk 获取的所有 Partition,进行状态初始化</span></div><div class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">initializePartitionState</span></span>() &#123;</div><div class="line">  <span class="keyword">for</span> (topicPartition &lt;- controllerContext.partitionReplicaAssignment.keys) &#123;</div><div class="line">    <span class="comment">// check if leader and isr path exists for partition. If not, then it is in NEW state</span></div><div class="line">    controllerContext.partitionLeadershipInfo.get(topicPartition) <span class="keyword">match</span> &#123;</div><div class="line">      <span class="keyword">case</span> <span class="type">Some</span>(currentLeaderIsrAndEpoch) =&gt;</div><div class="line">        <span class="comment">// else, check if the leader for partition is alive. If yes, it is in Online state, else it is in Offline state</span></div><div class="line">        <span class="keyword">if</span> (controllerContext.liveBrokerIds.contains(currentLeaderIsrAndEpoch.leaderAndIsr.leader))</div><div class="line">          <span class="comment">// leader is alive</span></div><div class="line">          <span class="comment">//note: 有 LeaderAndIsr 信息,并且 leader 存活,设置为 OnlinePartition 状态</span></div><div class="line">          partitionState.put(topicPartition, <span class="type">OnlinePartition</span>)</div><div class="line">        <span class="keyword">else</span></div><div class="line">          <span class="comment">//note: 有 LeaderAndIsr 信息,但是 leader 不存活,设置为 OfflinePartition 状态</span></div><div class="line">          partitionState.put(topicPartition, <span class="type">OfflinePartition</span>)</div><div class="line">      <span class="keyword">case</span> <span class="type">None</span> =&gt;</div><div class="line">        <span class="comment">//note: 没有 LeaderAndIsr 信息,设置为 NewPartition 状态（这个 Partition 还没有）</span></div><div class="line">        partitionState.put(topicPartition, <span class="type">NewPartition</span>)</div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>在初始化的第二步，将会调用 <code>triggerOnlinePartitionStateChange()</code> 方法，为所有的状态为 NewPartition/OnlinePartition 的 Partition 进行 leader 选举，选举成功后的话，其状态将会设置为 OnlinePartition，调用的 Leader 选举方法是 <a href="http://matt33.com/2018/06/15/kafka-controller-start/#OfflinePartitionLeaderSelector">OfflinePartitionLeaderSelector</a>（具体实现参考链接）。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//note: 这个方法是在 controller 选举后或 broker 上线或下线时时触发的</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">triggerOnlinePartitionStateChange</span></span>() &#123;</div><div class="line">  <span class="keyword">try</span> &#123;</div><div class="line">    brokerRequestBatch.newBatch()</div><div class="line">    <span class="comment">// try to move all partitions in NewPartition or OfflinePartition state to OnlinePartition state except partitions</span></div><div class="line">    <span class="comment">// that belong to topics to be deleted</span></div><div class="line">    <span class="comment">//note: 开始为所有状态在 NewPartition or OfflinePartition 状态的 partition 更新状态（除去将要被删除的 topic）</span></div><div class="line">    <span class="keyword">for</span>((topicAndPartition, partitionState) &lt;- partitionState</div><div class="line">        <span class="keyword">if</span> !controller.deleteTopicManager.isTopicQueuedUpForDeletion(topicAndPartition.topic)) &#123;</div><div class="line">      <span class="keyword">if</span>(partitionState.equals(<span class="type">OfflinePartition</span>) || partitionState.equals(<span class="type">NewPartition</span>))</div><div class="line">        <span class="comment">//note: 尝试为处在 OfflinePartition 或 NewPartition 状态的 Partition 选主,成功后转换为 OnlinePartition</span></div><div class="line">        handleStateChange(topicAndPartition.topic, topicAndPartition.partition, <span class="type">OnlinePartition</span>, controller.offlinePartitionSelector,</div><div class="line">                          (<span class="keyword">new</span> <span class="type">CallbackBuilder</span>).build)</div><div class="line">    &#125;</div><div class="line">    <span class="comment">//note: 发送请求给所有的 broker,包括 LeaderAndIsr 请求和 UpdateMetadata 请求（这里只是添加到 Broker 对应的 RequestQueue 中,后台有线程去发送）</span></div><div class="line">    brokerRequestBatch.sendRequestsToBrokers(controller.epoch)</div><div class="line">  &#125; <span class="keyword">catch</span> &#123;</div><div class="line">    <span class="keyword">case</span> e: <span class="type">Throwable</span> =&gt; error(<span class="string">"Error while moving some partitions to the online state"</span>, e)</div><div class="line">    <span class="comment">// <span class="doctag">TODO:</span> It is not enough to bail out and log an error, it is important to trigger leader election for those partitions</span></div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>上面方法的目的是为尝试将所有的状态为 NewPartition/OnlinePartition 的 Partition 状态转移到 OnlinePartition，这个方法主要是做了两件事：</p>
<ol>
<li>状态转移（这个在下面详细讲述）；</li>
<li>发送相应的请求。</li>
</ol>
<h3 id="分区的状态转移"><a href="#分区的状态转移" class="headerlink" title="分区的状态转移"></a>分区的状态转移</h3><p>这里以要转移的 TargetState 区分做详细详细讲解，当 TargetState 分别是 NewPartition、OfflinePartition、NonExistentPartition 或者 OnlinePartition 时，副本状态机所做的事情。</p>
<h4 id="TargetState-NewPartition"><a href="#TargetState-NewPartition" class="headerlink" title="TargetState: NewPartition"></a>TargetState: NewPartition</h4><p>NewPartition 是 Partition 刚创建时的一个状态，其处理逻辑如下：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//note: 如果该 Partition 的状态不存在,默认为 NonExistentPartition</span></div><div class="line"><span class="keyword">val</span> currState = partitionState.getOrElseUpdate(topicAndPartition, <span class="type">NonExistentPartition</span>)</div><div class="line"><span class="comment">// pre: partition did not exist before this</span></div><div class="line">assertValidPreviousStates(topicAndPartition, <span class="type">List</span>(<span class="type">NonExistentPartition</span>), <span class="type">NewPartition</span>)</div><div class="line">partitionState.put(topicAndPartition, <span class="type">NewPartition</span>) <span class="comment">//note: 缓存 partition 的状态</span></div><div class="line"><span class="keyword">val</span> assignedReplicas = controllerContext.partitionReplicaAssignment(topicAndPartition).mkString(<span class="string">","</span>)</div><div class="line">stateChangeLogger.trace(<span class="string">"Controller %d epoch %d changed partition %s state from %s to %s with assigned replicas %s"</span></div><div class="line">                          .format(controllerId, controller.epoch, topicAndPartition, currState, targetState,</div><div class="line">                                  assignedReplicas))</div></pre></td></tr></table></figure>
<p>实现逻辑：</p>
<ol>
<li>校验其前置状态，它有效的前置状态为 NonExistentPartition；</li>
<li>将该 Partition 的状态转移为 NewPartition 状态，并且更新到缓存中。</li>
</ol>
<h4 id="TargetState-OnlinePartition"><a href="#TargetState-OnlinePartition" class="headerlink" title="TargetState: OnlinePartition"></a>TargetState: OnlinePartition</h4><p>OnlinePartition 是一个 Partition 正常工作时的状态，这个状态下的 Partition 已经成功选举出了 leader 和 isr 信息，其实现逻辑如下：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//note: 判断 Partition 之前的状态是否可以转换为目的状态</span></div><div class="line">assertValidPreviousStates(topicAndPartition, <span class="type">List</span>(<span class="type">NewPartition</span>, <span class="type">OnlinePartition</span>, <span class="type">OfflinePartition</span>), <span class="type">OnlinePartition</span>)</div><div class="line">partitionState(topicAndPartition) <span class="keyword">match</span> &#123;</div><div class="line">  <span class="keyword">case</span> <span class="type">NewPartition</span> =&gt; <span class="comment">//note: 新建的 Partition</span></div><div class="line">    <span class="comment">//note: 选举 leader 和 isr,更新到 zk 和 controller 中,如果没有存活的 replica,抛出异常</span></div><div class="line">    <span class="comment">// initialize leader and isr path for new partition</span></div><div class="line">    initializeLeaderAndIsrForPartition(topicAndPartition)</div><div class="line">  <span class="keyword">case</span> <span class="type">OfflinePartition</span> =&gt; <span class="comment">//note: leader 挂掉的 Partition</span></div><div class="line">    <span class="comment">//note: 进行 leader 选举,更新到 zk 及 controller 缓存中,失败的抛出异常</span></div><div class="line">    electLeaderForPartition(topic, partition, leaderSelector)</div><div class="line">  <span class="keyword">case</span> <span class="type">OnlinePartition</span> =&gt; <span class="comment">// invoked when the leader needs to be re-elected</span></div><div class="line">    <span class="comment">//note:这种只有在 leader 需要重新选举时才会触发</span></div><div class="line">    electLeaderForPartition(topic, partition, leaderSelector)</div><div class="line">  <span class="keyword">case</span> _ =&gt; <span class="comment">// should never come here since illegal previous states are checked above</span></div><div class="line">&#125;</div><div class="line">partitionState.put(topicAndPartition, <span class="type">OnlinePartition</span>)</div><div class="line"><span class="keyword">val</span> leader = controllerContext.partitionLeadershipInfo(topicAndPartition).leaderAndIsr.leader</div><div class="line">stateChangeLogger.trace(<span class="string">"Controller %d epoch %d changed partition %s from %s to %s with leader %d"</span></div><div class="line">                          .format(controllerId, controller.epoch, topicAndPartition, currState, targetState, leader))</div></pre></td></tr></table></figure>
<p>实现逻辑：</p>
<ol>
<li>校验这个 Partition 的前置状态，有效的前置状态是：NewPartition、OnlinePartition 或者 OfflinePartition；</li>
<li>如果前置状态是 NewPartition，那么为该 Partition 选举 leader 和 isr，更新到 zk 和 controller 的缓存中，如果副本没有处于 alive 状态的话，就抛出异常；</li>
<li>如果前置状态是 OnlinePartition，那么只是触发 leader 选举，在 OnlinePartition –&gt; OnlinePartition 这种状态转移时，需要传入 leader 选举的方法，触发该 Partition 的 leader 选举；</li>
<li>如果前置状态是 OfflinePartition，同上，也是触发 leader 选举。</li>
<li>更新 Partition 的状态为 OnlinePartition。</li>
</ol>
<p>对于以上这几种情况，无论前置状态是什么，最后都会触发这个 Partition 的 leader 选举，leader 成功后，都会触发向这个 Partition 的所有 replica 发送 LeaderAndIsr 请求。</p>
<h4 id="TargetState-OfflinePartition"><a href="#TargetState-OfflinePartition" class="headerlink" title="TargetState: OfflinePartition"></a>TargetState: OfflinePartition</h4><p>OfflinePartition 是这个 Partition 的 leader 挂掉时转移的一个状态，如果 Partition 转移到这个状态，那么就意味着这个 Partition 没有了可用 leader。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// pre: partition should be in New or Online state</span></div><div class="line">assertValidPreviousStates(topicAndPartition, <span class="type">List</span>(<span class="type">NewPartition</span>, <span class="type">OnlinePartition</span>, <span class="type">OfflinePartition</span>), <span class="type">OfflinePartition</span>)</div><div class="line"><span class="comment">// should be called when the leader for a partition is no longer alive</span></div><div class="line">stateChangeLogger.trace(<span class="string">"Controller %d epoch %d changed partition %s state from %s to %s"</span></div><div class="line">                          .format(controllerId, controller.epoch, topicAndPartition, currState, targetState))</div><div class="line">partitionState.put(topicAndPartition, <span class="type">OfflinePartition</span>)</div><div class="line"><span class="comment">// post: partition has no alive leader</span></div></pre></td></tr></table></figure>
<p>实现逻辑：</p>
<ol>
<li>校验其前置状态，它有效的前置状态为 NewPartition、OnlinePartition 或者 OfflinePartition；</li>
<li>将该 Partition 的状态转移为 OfflinePartition 状态，并且更新到缓存中。</li>
</ol>
<h4 id="TargetState-NonExistentPartition"><a href="#TargetState-NonExistentPartition" class="headerlink" title="TargetState: NonExistentPartition"></a>TargetState: NonExistentPartition</h4><p>NonExistentPartition 代表了已经处于 OfflinePartition 状态的 Partition 已经从 metadata 和 zk 中删除后进入的状态。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"> <span class="comment">// pre: partition should be in Offline state</span></div><div class="line">assertValidPreviousStates(topicAndPartition, <span class="type">List</span>(<span class="type">OfflinePartition</span>), <span class="type">NonExistentPartition</span>)</div><div class="line">stateChangeLogger.trace(<span class="string">"Controller %d epoch %d changed partition %s state from %s to %s"</span></div><div class="line">                          .format(controllerId, controller.epoch, topicAndPartition, currState, targetState))</div><div class="line">partitionState.put(topicAndPartition, <span class="type">NonExistentPartition</span>)</div><div class="line"><span class="comment">// post: partition state is deleted from all brokers and zookeeper</span></div></pre></td></tr></table></figure>
<p>实现逻辑：</p>
<ol>
<li>校验其前置状态，它有效的前置状态为 OfflinePartition；</li>
<li>将该 Partition 的状态转移为 NonExistentPartition 状态，并且更新到缓存中。</li>
</ol>
<h3 id="状态转移触发的条件-1"><a href="#状态转移触发的条件-1" class="headerlink" title="状态转移触发的条件"></a>状态转移触发的条件</h3><p>这里主要是看一下上面 Partition   各种转移的触发的条件，整理的结果如下表所示，部分内容会在后续文章讲解。</p>
<table>
<thead>
<tr>
<th>TargetState</th>
<th>触发方法</th>
<th>作用</th>
</tr>
</thead>
<tbody>
<tr>
<td>OnlinePartition</td>
<td>Controller 的 shutdownBroker()</td>
<td>优雅关闭 Broker 时调用，因为要下线的节点是 leader，所以需要触发 leader 选举</td>
</tr>
<tr>
<td>OnlinePartition</td>
<td>Controller 的 onNewPartitionCreation()</td>
<td>Partition 新建时，这个是在 Replica 已经变为 NewPartition 状态后进行的，为新建的 Partition 初始化 leader 和 isr</td>
</tr>
<tr>
<td>OnlinePartition</td>
<td>controller 的 onPreferredReplicaElection()</td>
<td>对 Partition 进行最优 leader 选举，目的是触发 leader 选举</td>
</tr>
<tr>
<td>OnlinePartition</td>
<td>controller 的 moveReassignedPartitionLeaderIfRequired()</td>
<td>分区副本迁移完成后，1. 当前的 leader 不在 RAR 中，需要触发 leader 选举；2. 当前 leader 在 RAR 但是掉线了，也需要触发 leader 选举</td>
</tr>
<tr>
<td>OnlinePartition</td>
<td>PartitionStateMachine 的 triggerOnlinePartitionStateChange()</td>
<td>当 Controller 重新选举出来或 broker 有变化时，目的为了那些状态为 NewPartition/OfflinePartition 的 Partition 重新选举 leader，选举成功后状态变为 OnlinePartition</td>
</tr>
<tr>
<td>OnlinePartition</td>
<td>PartitionStateMachine 的 initializePartitionState()</td>
<td>Controller 初始化时，遍历 zk 的所有的分区，如果有 LeaderAndIsr 信息并且 leader 在 alive broker 上，那么就将状态转为 OnlinePartition。</td>
</tr>
<tr>
<td>OfflinePartition</td>
<td>controller 的 onBrokerFailure()</td>
<td>当有 broker 掉线时，将 leader 在这个机器上的 Partition 设置为 OfflinePartition</td>
</tr>
<tr>
<td>OfflinePartition</td>
<td>TopicDeletionManager 的 completeDeleteTopic()</td>
<td>Topic 删除成功后，中间会将该 Partition 的状态先转变为 OfflinePartition</td>
</tr>
<tr>
<td>NonExistentPartition</td>
<td>TopicDeletionManager 的 completeDeleteTopic()</td>
<td>Topic 删除成功后，最后会将该 Partition 的状态转移为 NonExistentPartition</td>
</tr>
<tr>
<td>NewPartition</td>
<td>Controller 的 onNewPartitionCreation()</td>
<td>Partition 刚创建时的一个中间状态 ，此时还没选举 leader 和设置 isr 信息</td>
</tr>
</tbody>
</table>
<p>上面就是副本状态机与分区状态机的所有内容，这里只是单纯地讲述了一下这两种状态机，后续文章会开始介绍 Controller 一些其他内容，包括 Partition 迁移、Topic 新建、Topic 下线等，这些内容都会用到这篇文章讲述的内容。</p>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[Kafka 源码解析之 Controller 选举及服务启动流程（十六）]]></title>
      <url>http://matt33.com/2018/06/15/kafka-controller-start/</url>
      <content type="html"><![CDATA[<p>从本篇文章开始，Kafka 源码解析就正式进入了 Controller 部分，Controller 作为 Kafka Server 端一个重要的组件，它的角色类似于其他分布式系统 Master 的角色，跟其他系统不一样的是，Kafka 集群的任何一台 Broker 都可以作为 Controller，但是在一个集群中同时只会有一个 Controller 是 alive 状态。Controller 在集群中负责的事务很多，比如：集群 meta 信息的一致性保证、Partition leader 的选举、broker 上下线等都是由 Controller 来具体负责。Controller 部分的内容还是比较多的，计划分5篇左右的文章讲述，本文先来看下 Controller 的简介、Controller 的选举、Controller 选举后服务的启动流程以及 Controller 的四种不同 leader 选举机制。分区状态机、副本副本状态机以及对各种 listener 的处理将在后续的文章中展开。</p>
<h2 id="Controller-简介"><a href="#Controller-简介" class="headerlink" title="Controller 简介"></a>Controller 简介</h2><p>在于分布式系统中，总会有一个地方需要对全局 meta 做一个统一的维护，Kafka 的 Controller 就是充当这个角色的。Kafka 简单的框架图如下所示</p>
<p><img src="/images/kafka/kafka-framwoker.png" alt="Kafka架构简图"></p>
<p>Controller 是运行在 Broker 上的，任何一台 Broker 都可以作为 Controller，但是一个集群同时只能存在一个 Controller，也就意味着 Controller 与数据节点是在一起的，Controller 做的主要事情如下：</p>
<ol>
<li>Broker 的上线、下线处理；</li>
<li>新创建的 topic 或已有 topic 的分区扩容，处理分区副本的分配、leader 选举；</li>
<li>管理所有副本的状态机和分区的状态机，处理状态机的变化事件；</li>
<li>topic 删除、副本迁移、leader 切换等处理。</li>
</ol>
<h2 id="Controller-选举过程"><a href="#Controller-选举过程" class="headerlink" title="Controller 选举过程"></a>Controller 选举过程</h2><p>Kafka 的每台 Broker 在启动过程中，都会启动 Controller 服务，相关代码如下：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">startup</span></span>() &#123;</div><div class="line">  info(<span class="string">"starting"</span>)</div><div class="line">  <span class="keyword">val</span> canStartup = isStartingUp.compareAndSet(<span class="literal">false</span>, <span class="literal">true</span>)</div><div class="line">  <span class="keyword">if</span> (canStartup) &#123;</div><div class="line">    <span class="comment">/* start kafka controller */</span></div><div class="line">    <span class="comment">//note: 启动 controller</span></div><div class="line">    kafkaController = <span class="keyword">new</span> <span class="type">KafkaController</span>(config, zkUtils, brokerState, time, metrics, threadNamePrefix)</div><div class="line">    kafkaController.startup()</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h3 id="Controller-启动"><a href="#Controller-启动" class="headerlink" title="Controller 启动"></a>Controller 启动</h3><p>Kafka Server 在启动的过程中，都会去启动 Controller 服务，Controller 启动方法如下：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//<span class="doctag">NOTE:</span> 当 broker 的 controller 模块启动时触发,它比并不保证当前 broker 是 controller,它仅仅是注册 registerSessionExpirationListener 和启动 controllerElector</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">startup</span></span>() = &#123;</div><div class="line">  inLock(controllerContext.controllerLock) &#123;</div><div class="line">    info(<span class="string">"Controller starting up"</span>)</div><div class="line">    registerSessionExpirationListener() <span class="comment">// note: 注册回话失效的监听器</span></div><div class="line">    isRunning = <span class="literal">true</span></div><div class="line">    controllerElector.startup <span class="comment">//note: 启动选举过程</span></div><div class="line">    info(<span class="string">"Controller startup complete"</span>)</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>Controller 在 <code>startup()</code> 方法中主要实现以下两部分功能：</p>
<ol>
<li><code>registerSessionExpirationListener()</code> 方法注册连接 zk 的超时监听器；</li>
<li><code>controllerElector.startup()</code> 方法，监听 zk 上 controller 节点的变化，并触发 controller 选举方法。</li>
</ol>
<h3 id="Controller-选举"><a href="#Controller-选举" class="headerlink" title="Controller 选举"></a>Controller 选举</h3><p>Controller 在启动时，会初始化 ZookeeperLeaderElector 对象，并调用其 <code>startup()</code> 启动相应的流程，具体过程如下：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">startup</span> </span>&#123;</div><div class="line">  inLock(controllerContext.controllerLock) &#123;</div><div class="line">    controllerContext.zkUtils.zkClient.subscribeDataChanges(electionPath, leaderChangeListener)</div><div class="line">    elect</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>在 <code>startup()</code> 方法中，主要做了下面两件事情：</p>
<ol>
<li>监听 zk 的 <code>/controller</code> 节点的数据变化，一旦节点有变化，立刻通过 LeaderChangeListener 的方法进行相应的处理；</li>
<li><code>elect</code> 在 controller 不存在的情况下选举 controller，存在的话，就是从 zk 获取当前的 controller 节点信息。</li>
</ol>
<h4 id="Controller-选举方法-elect"><a href="#Controller-选举方法-elect" class="headerlink" title="Controller 选举方法 elect"></a>Controller 选举方法 elect</h4><p>ZookeeperLeaderElector 的 <code>elect</code> 方法实现如下：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//note: 从 zk 获取当前的 controller 信息</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">getControllerID</span></span>(): <span class="type">Int</span> = &#123;</div><div class="line">  controllerContext.zkUtils.readDataMaybeNull(electionPath)._1 <span class="keyword">match</span> &#123;</div><div class="line">     <span class="keyword">case</span> <span class="type">Some</span>(controller) =&gt; <span class="type">KafkaController</span>.parseControllerId(controller)</div><div class="line">     <span class="keyword">case</span> <span class="type">None</span> =&gt; <span class="number">-1</span></div><div class="line">  &#125;</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="comment">//note: 进行 controller 选举</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">elect</span></span>: <span class="type">Boolean</span> = &#123;</div><div class="line">  <span class="keyword">val</span> timestamp = time.milliseconds.toString</div><div class="line">  <span class="keyword">val</span> electString = <span class="type">Json</span>.encode(<span class="type">Map</span>(<span class="string">"version"</span> -&gt; <span class="number">1</span>, <span class="string">"brokerid"</span> -&gt; brokerId, <span class="string">"timestamp"</span> -&gt; timestamp))</div><div class="line"></div><div class="line"> leaderId = getControllerID</div><div class="line">  <span class="comment">/*</span></div><div class="line">   * We can get here during the initial startup and the handleDeleted ZK callback. Because of the potential race condition,</div><div class="line">   * it's possible that the controller has already been elected when we get here. This check will prevent the following</div><div class="line">   * createEphemeralPath method from getting into an infinite loop if this broker is already the controller.</div><div class="line">   */</div><div class="line">  <span class="keyword">if</span>(leaderId != <span class="number">-1</span>) &#123;</div><div class="line">     debug(<span class="string">"Broker %d has been elected as leader, so stopping the election process."</span>.format(leaderId))</div><div class="line">     <span class="keyword">return</span> amILeader</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  <span class="keyword">try</span> &#123;</div><div class="line">    <span class="keyword">val</span> zkCheckedEphemeral = <span class="keyword">new</span> <span class="type">ZKCheckedEphemeral</span>(electionPath,</div><div class="line">                                                    electString,</div><div class="line">                                                    controllerContext.zkUtils.zkConnection.getZookeeper,</div><div class="line">                                                    <span class="type">JaasUtils</span>.isZkSecurityEnabled())</div><div class="line">    zkCheckedEphemeral.create() <span class="comment">//note: 没有异常的话就是创建成功了</span></div><div class="line">    info(brokerId + <span class="string">" successfully elected as leader"</span>)</div><div class="line">    leaderId = brokerId</div><div class="line">    onBecomingLeader() <span class="comment">//note: 成为了 controller</span></div><div class="line">  &#125; <span class="keyword">catch</span> &#123;</div><div class="line">    <span class="keyword">case</span> _: <span class="type">ZkNodeExistsException</span> =&gt; <span class="comment">//note: 在创建时,发现已经有 broker 提前注册成功</span></div><div class="line">      <span class="comment">// If someone else has written the path, then</span></div><div class="line">      leaderId = getControllerID</div><div class="line"></div><div class="line">      <span class="keyword">if</span> (leaderId != <span class="number">-1</span>)</div><div class="line">        debug(<span class="string">"Broker %d was elected as leader instead of broker %d"</span>.format(leaderId, brokerId))</div><div class="line">      <span class="keyword">else</span></div><div class="line">        warn(<span class="string">"A leader has been elected but just resigned, this will result in another round of election"</span>)</div><div class="line"></div><div class="line">    <span class="keyword">case</span> e2: <span class="type">Throwable</span> =&gt; <span class="comment">//note: 抛出了其他异常，那么重新选举 controller</span></div><div class="line">      error(<span class="string">"Error while electing or becoming leader on broker %d"</span>.format(brokerId), e2)</div><div class="line">      resign()</div><div class="line">  &#125;</div><div class="line">  amILeader</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">amILeader</span> </span>: <span class="type">Boolean</span> = leaderId == brokerId</div></pre></td></tr></table></figure>
<p>其实现逻辑如下：</p>
<ol>
<li>先获取 zk 的 <code>/cotroller</code> 节点的信息，获取 controller 的 broker id，如果该节点不存在（比如集群刚创建时），那么获取的 controller id 为-1；</li>
<li>如果 controller id 不为-1，即 controller 已经存在，直接结束流程；</li>
<li>如果 controller id 为-1，证明 controller 还不存在，这时候当前 broker 开始在 zk 注册 controller；</li>
<li>如果注册成功，那么当前 broker 就成为了 controller，这时候开始调用 <code>onBecomingLeader()</code> 方法，正式初始化 controller（注意：<strong>controller 节点是临时节点</strong>，如果当前 controller 与 zk 的 session 断开，那么 controller 的临时节点会消失，会触发 controller 的重新选举）；</li>
<li>如果注册失败（刚好 controller 被其他 broker 创建了、抛出异常等），那么直接返回。</li>
</ol>
<p>在这里 controller 算是成功被选举出来了，controller 选举过程实际上就是各个 Broker 抢占式注册该节点，注册成功的便为 Controller。</p>
<h4 id="controller-节点监听-LeaderChangeListener"><a href="#controller-节点监听-LeaderChangeListener" class="headerlink" title="controller 节点监听 LeaderChangeListener"></a>controller 节点监听 LeaderChangeListener</h4><p>LeaderChangeListener 主要是监听 zk 上的 Controller 节点变化，如果该节点内容变化或者节点被删除，那么会触发 <code>handleDataChange()</code> 和 <code>handleDataDeleted()</code> 方法，具体实现如下：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//note: 监控 controller 内容的变化</span></div><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">LeaderChangeListener</span> <span class="keyword">extends</span> <span class="title">IZkDataListener</span> <span class="keyword">with</span> <span class="title">Logging</span> </span>&#123;</div><div class="line">  <span class="comment">/**</span></div><div class="line">   * Called when the leader information stored in zookeeper has changed. Record the new leader in memory</div><div class="line">   * @throws Exception On any error.</div><div class="line">   */</div><div class="line">  <span class="meta">@throws</span>[<span class="type">Exception</span>]</div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">handleDataChange</span></span>(dataPath: <span class="type">String</span>, data: <span class="type">Object</span>) &#123;</div><div class="line">    <span class="keyword">val</span> shouldResign = inLock(controllerContext.controllerLock) &#123;</div><div class="line">      <span class="keyword">val</span> amILeaderBeforeDataChange = amILeader</div><div class="line">      leaderId = <span class="type">KafkaController</span>.parseControllerId(data.toString)</div><div class="line">      info(<span class="string">"New leader is %d"</span>.format(leaderId))</div><div class="line">      <span class="comment">// The old leader needs to resign leadership if it is no longer the leader</span></div><div class="line">      amILeaderBeforeDataChange &amp;&amp; !amILeader</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="comment">//note: 之前是 controller,现在不是了</span></div><div class="line">    <span class="keyword">if</span> (shouldResign)</div><div class="line">      onResigningAsLeader() <span class="comment">//note: 关闭 controller 服务</span></div><div class="line">  &#125;</div><div class="line"></div><div class="line">  <span class="comment">/**</span></div><div class="line">   * Called when the leader information stored in zookeeper has been delete. Try to elect as the leader</div><div class="line">   * @throws Exception</div><div class="line">   *             On any error.</div><div class="line">   */</div><div class="line">  <span class="comment">//note: 如果之前是 controller,现在这个节点被删除了,那么首先退出 controller 进程,然后开始重新选举 controller</span></div><div class="line">  <span class="meta">@throws</span>[<span class="type">Exception</span>]</div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">handleDataDeleted</span></span>(dataPath: <span class="type">String</span>) &#123;</div><div class="line">    <span class="keyword">val</span> shouldResign = inLock(controllerContext.controllerLock) &#123;</div><div class="line">      debug(<span class="string">"%s leader change listener fired for path %s to handle data deleted: trying to elect as a leader"</span></div><div class="line">        .format(brokerId, dataPath))</div><div class="line">      amILeader</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="keyword">if</span> (shouldResign)</div><div class="line">      onResigningAsLeader()</div><div class="line"></div><div class="line">    inLock(controllerContext.controllerLock) &#123;</div><div class="line">      elect</div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>处理过程如下：</p>
<ol>
<li>如果 <code>/controller</code> 节点内容变化，那么更新一下 controller 最新的节点信息，如果该节点刚好之前是 controller，现在不是了，那么需要执行 controller 关闭操作，即 <code>onResigningAsLeader()</code> 方法；</li>
<li>如果 <code>/controller</code> 节点被删除，如果该节点刚好之前是 controller，那么需要执行 controller 关闭操作，即 <code>onResigningAsLeader()</code> 方法，然后再执行 <code>elect</code> 方法重新去选举 controller；</li>
</ol>
<h2 id="Controller-服务启动流程"><a href="#Controller-服务启动流程" class="headerlink" title="Controller 服务启动流程"></a>Controller 服务启动流程</h2><p>Controller 节点选举出来之后，ZookeeperLeaderElector 就会调用 <code>onBecomingLeader()</code> 方法初始化 KafkaController 的相关内容，在 KafkaController 对 ZookeeperLeaderElector 的初始化中可以看到 <code>onBecomingLeader()</code> 这个方法实际上是 KafkaController 的 <code>onControllerFailover()</code> 方法。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">KafkaController</span></span>&#123;</div><div class="line">    <span class="keyword">private</span> <span class="keyword">val</span> controllerElector = <span class="keyword">new</span> <span class="type">ZookeeperLeaderElector</span>(controllerContext, <span class="type">ZkUtils</span>.<span class="type">ControllerPath</span>, onControllerFailover,</div><div class="line">                                                               onControllerResignation, config.brokerId, time) <span class="comment">//note: controller 通过 zk 选举</span></div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="comment">//note: controller 临时节点监控及 controller 选举</span></div><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">ZookeeperLeaderElector</span>(<span class="params">controllerContext: <span class="type">ControllerContext</span>,</span></span></div><div class="line">                             electionPath: <span class="type">String</span>, //note: 路径是 /controller</div><div class="line">                             onBecomingLeader: () <span class="title">=&gt;</span> <span class="title">Unit</span>, <span class="title">//note</span>: onControllerFailover() 方法</div><div class="line">                             onResigningAsLeader: () =&gt; <span class="type">Unit</span>, <span class="comment">//note: onControllerResignation() 方法</span></div><div class="line">                             brokerId: <span class="type">Int</span>,</div><div class="line">                             time: <span class="type">Time</span>)</div></pre></td></tr></table></figure>
<h3 id="onControllerFailover-启动及初始化"><a href="#onControllerFailover-启动及初始化" class="headerlink" title="onControllerFailover 启动及初始化"></a>onControllerFailover 启动及初始化</h3><p>下面开始进入 KafkaController 正式初始化的讲解过程中，<code>onControllerFailover()</code> 方法实现如下：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//note: 如果当前 Broker 被选为 controller 时, 当被选为 controller,它将会做以下操作</span></div><div class="line"><span class="comment">//note: 1. 注册 controller epoch changed listener;</span></div><div class="line"><span class="comment">//note: 2. controller epoch 自增加1;</span></div><div class="line"><span class="comment">//note: 3. 初始化 KafkaController 的上下文信息 ControllerContext,它包含了当前的 topic、存活的 broker 以及已经存在的 partition 的 leader;</span></div><div class="line"><span class="comment">//note: 4. 启动 controller 的 channel 管理: 建立与其他 broker 的连接的,负责与其他 broker 之间的通信;</span></div><div class="line"><span class="comment">//note: 5. 启动 ReplicaStateMachine（副本状态机,管理副本的状态）;</span></div><div class="line"><span class="comment">//note: 6. 启动 PartitionStateMachine（分区状态机,管理分区的状态）;</span></div><div class="line"><span class="comment">//note: 如果在 Controller 服务初始化的过程中，出现了任何不可预期的 异常/错误，它将会退出当前的进程，这确保了可以再次触发 controller 的选举</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">onControllerFailover</span></span>() &#123;</div><div class="line">  <span class="keyword">if</span>(isRunning) &#123;</div><div class="line">    info(<span class="string">"Broker %d starting become controller state transition"</span>.format(config.brokerId))</div><div class="line">    readControllerEpochFromZookeeper() <span class="comment">//note: 从 zk 获取 controllrt 的 epoch 和 zkVersion 值</span></div><div class="line">    incrementControllerEpoch(zkUtils.zkClient) <span class="comment">//note: 更新 Controller 的 epoch 和 zkVersion 值，可能会抛出异常</span></div><div class="line"></div><div class="line">    <span class="comment">// before reading source of truth from zookeeper, register the listeners to get broker/topic callbacks</span></div><div class="line">    <span class="comment">//note: 再从 zk 获取数据初始化前，注册一些关于 broker/topic 的回调监听器</span></div><div class="line">    registerReassignedPartitionsListener() <span class="comment">//note: 监控路径【/admin/reassign_partitions】，分区迁移监听</span></div><div class="line">    registerIsrChangeNotificationListener() <span class="comment">//note: 监控路径【/isr_change_notification】，isr 变动监听</span></div><div class="line">    registerPreferredReplicaElectionListener() <span class="comment">//note: 监听路径【/admin/preferred_replica_election】，最优 leader 选举</span></div><div class="line">    partitionStateMachine.registerListeners()<span class="comment">//note: 监听 Topic 的创建与删除</span></div><div class="line">    replicaStateMachine.registerListeners() <span class="comment">//note: 监听 broker 的上下线</span></div><div class="line"></div><div class="line">    <span class="comment">//note: 初始化 controller 相关的变量信息:包括 alive broker 列表、partition 的详细信息等</span></div><div class="line">    initializeControllerContext() <span class="comment">//note: 初始化 controller 相关的变量信息</span></div><div class="line"></div><div class="line">    <span class="comment">// We need to send UpdateMetadataRequest after the controller context is initialized and before the state machines</span></div><div class="line">    <span class="comment">// are started. The is because brokers need to receive the list of live brokers from UpdateMetadataRequest before</span></div><div class="line">    <span class="comment">// they can process the LeaderAndIsrRequests that are generated by replicaStateMachine.startup() and</span></div><div class="line">    <span class="comment">// partitionStateMachine.startup().</span></div><div class="line">    <span class="comment">//note: 在 controller contest 初始化之后,我们需要发送 UpdateMetadata 请求在状态机启动之前,这是因为 broker 需要从 UpdateMetadata 请求</span></div><div class="line">    <span class="comment">//note: 获取当前存活的 broker list, 因为它们需要处理来自副本状态机或分区状态机启动发送的 LeaderAndIsr 请求</span></div><div class="line">    sendUpdateMetadataRequest(controllerContext.liveOrShuttingDownBrokerIds.toSeq)</div><div class="line"></div><div class="line">    <span class="comment">//note: 初始化 replica 的状态信息: replica 是存活状态时是 OnlineReplica, 否则是 ReplicaDeletionIneligible</span></div><div class="line">    replicaStateMachine.startup() <span class="comment">//note: 初始化 replica 的状态信息</span></div><div class="line">    <span class="comment">//note: 初始化 partition 的状态信息:如果 leader 所在 broker 是 alive 的,那么状态为 OnlinePartition,否则为 OfflinePartition</span></div><div class="line">    <span class="comment">//note: 并状态为 OfflinePartition 的 topic 选举 leader</span></div><div class="line">    partitionStateMachine.startup() <span class="comment">//note: 初始化 partition 的状态信息</span></div><div class="line"></div><div class="line">    <span class="comment">// register the partition change listeners for all existing topics on failover</span></div><div class="line">    <span class="comment">//note: 为所有的 topic 注册 partition change 监听器</span></div><div class="line">    controllerContext.allTopics.foreach(topic =&gt; partitionStateMachine.registerPartitionChangeListener(topic))</div><div class="line">    info(<span class="string">"Broker %d is ready to serve as the new controller with epoch %d"</span>.format(config.brokerId, epoch))</div><div class="line">    maybeTriggerPartitionReassignment() <span class="comment">//note: 触发一次分区副本迁移的操作</span></div><div class="line">    maybeTriggerPreferredReplicaElection() <span class="comment">//note: 触发一次分区的最优 leader 选举操作</span></div><div class="line">    <span class="keyword">if</span> (config.autoLeaderRebalanceEnable) &#123; <span class="comment">//note: 如果开启自动均衡</span></div><div class="line">      info(<span class="string">"starting the partition rebalance scheduler"</span>)</div><div class="line">      autoRebalanceScheduler.startup()</div><div class="line">      autoRebalanceScheduler.schedule(<span class="string">"partition-rebalance-thread"</span>, checkAndTriggerPartitionRebalance,</div><div class="line">        <span class="number">5</span>, config.leaderImbalanceCheckIntervalSeconds.toLong, <span class="type">TimeUnit</span>.<span class="type">SECONDS</span>) <span class="comment">//note: 发送最新的 meta 信息</span></div><div class="line">    &#125;</div><div class="line">    deleteTopicManager.start() <span class="comment">//note: topic 删除线程启动</span></div><div class="line">  &#125;</div><div class="line">  <span class="keyword">else</span></div><div class="line">    info(<span class="string">"Controller has been shut down, aborting startup/failover"</span>)</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>简单来说，<code>onControllerFailover()</code> 所做的事情如下：</p>
<ol>
<li><code>readControllerEpochFromZookeeper()</code> 方法更新 controller 的 epoch 及 zkVersion 信息，<code>incrementControllerEpoch()</code> 方法将 controller 的 epoch 字增加1，并更新到 zk 中；</li>
<li>在控制器中注册相关的监听器，主要有6类类型，如下面表格中所列；</li>
<li>通过 <code>initializeControllerContext()</code> 方法初始化 Controller 的上下文信息，更新 Controller 的相关缓存信息、并启动 ControllerChannelManager 等；</li>
<li>向所有 alive 的 broker 发送 Update-Metadata 请求，broker 通过这个请求获取当前集群中 alive 的 broker 列表；</li>
<li>启动副本状态机，初始化所有 Replica 的状态信息，如果 Replica 所在节点是 alive 的，那么状态更新为 OnlineReplica, 否则更新为 ReplicaDeletionIneligible；</li>
<li>启动分区状态机，初始化所有 Partition 的状态信息，如果 leader 所在 broker 是 alive 的，那么状态更新为 OnlinePartition，否则更新为 OfflinePartition；</li>
<li>为当前所有 topic 注册一个 PartitionModificationsListener 监听器，监听所有 Topic 分区数的变化；</li>
<li>KafkaController 初始化完成，正式启动；</li>
<li>KafkaController 启动后，触发一次副本迁移，如果需要的情况下；</li>
<li>KafkaController 启动后，触发一次最优 leader 选举操作，如果需要的情况下；</li>
<li>KafkaController 启动后，如果开启了自动 leader 均衡，启动自动 leader 均衡线程，它会根据配置的信息定期运行。</li>
</ol>
<p>KafkaController 需要监听的 zk 节点、触发的监听方法及作用如下：</p>
<table>
<thead>
<tr>
<th>监听方法</th>
<th>监听路径</th>
<th>作用</th>
</tr>
</thead>
<tbody>
<tr>
<td>registerReassignedPartitionsListener</td>
<td>/admin/reassign_partitions</td>
<td>用于分区副本迁移</td>
</tr>
<tr>
<td>registerIsrChangeNotificationListener</td>
<td>/isr_change_notification</td>
<td>用于 Partition ISR 变动</td>
</tr>
<tr>
<td>registerPreferredReplicaElectionListener</td>
<td>/admin/preferred_replica_election</td>
<td>用于 Partition 最优 leader 选举</td>
</tr>
<tr>
<td>partitionStateMachine.registerTopicChangeListener()</td>
<td>/brokers/topics</td>
<td>用于 Topic 新建的监听</td>
</tr>
<tr>
<td>partitionStateMachine.registerDeleteTopicListener()</td>
<td>/admin/delete_topics</td>
<td>用于 Topic 删除的监听</td>
</tr>
<tr>
<td>replicaStateMachine.registerBrokerChangeListener()</td>
<td>/brokers/ids</td>
<td>用于 broker 上下线的监听</td>
</tr>
<tr>
<td>partitionStateMachine.registerPartitionChangeListener(topic)</td>
<td>/brokers/topics/TOPIC_NAME</td>
<td>用于 Topic Partition 扩容的监听</td>
</tr>
</tbody>
</table>
<p>在 KafkaController 中</p>
<ul>
<li>有两个状态机：分区状态机和副本状态机；</li>
<li>一个管理器：Channel 管理器，负责管理所有的 Broker 通信；</li>
<li>相关缓存：Partition 信息、Topic 信息、broker id 信息等；</li>
<li>四种 leader 选举机制：分别是用 leader offline、broker 掉线、partition reassign、最优 leader 选举时触发；</li>
</ul>
<p>如下图所示：</p>
<p><img src="/images/kafka/controller-cache.png" alt="Kafka Controller 的重要内容"></p>
<h3 id="initializeControllerContext-初始化-Controller-上下文信息"><a href="#initializeControllerContext-初始化-Controller-上下文信息" class="headerlink" title="initializeControllerContext 初始化 Controller 上下文信息"></a>initializeControllerContext 初始化 Controller 上下文信息</h3><p>在 <code>initializeControllerContext()</code> 初始化 KafkaController 上下文信息的方法中，主要做了以下事情：</p>
<ol>
<li>从 zk 获取所有 alive broker 列表，记录到 <code>liveBrokers</code>；</li>
<li>从 zk 获取所有的 topic 列表，记录到 <code>allTopic</code> 中；</li>
<li>从 zk 获取所有 Partition 的 replica 信息，更新到 <code>partitionReplicaAssignment</code> 中；</li>
<li>从 zk 获取所有 Partition 的 LeaderAndIsr 信息，更新到 <code>partitionLeadershipInfo</code> 中；</li>
<li>调用 <code>startChannelManager()</code> 启动 Controller 的 Channel Manager；</li>
<li>通过 <code>initializePreferredReplicaElection()</code> 初始化需要最优 leader 选举的 Partition 列表，记录到 <code>partitionsUndergoingPreferredReplicaElection</code> 中；</li>
<li>通过 <code>initializePartitionReassignment()</code> 方法初始化需要进行副本迁移的 Partition 列表，记录到 <code>partitionsBeingReassigned</code> 中；</li>
<li>通过 <code>initializeTopicDeletion()</code> 方法初始化需要删除的 topic 列表及 TopicDeletionManager 对象；</li>
</ol>
<p>综上，这个方法最主要的作用就是相关的 meta 信息及启动 Channel 管理器，其具体实现如下所示：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//note: 初始化 KafkaController 的上下文数据</span></div><div class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">initializeControllerContext</span></span>() &#123;</div><div class="line">  <span class="comment">// update controller cache with delete topic information</span></div><div class="line">  controllerContext.liveBrokers = zkUtils.getAllBrokersInCluster().toSet <span class="comment">//note: 初始化 zk 的 broker_list 信息</span></div><div class="line">  controllerContext.allTopics = zkUtils.getAllTopics().toSet <span class="comment">//note: 初始化所有的 topic 信息</span></div><div class="line">  <span class="comment">//note: 初始化所有 topic 的所有 partition 的 replica 分配</span></div><div class="line">  controllerContext.partitionReplicaAssignment = zkUtils.getReplicaAssignmentForTopics(controllerContext.allTopics.toSeq)</div><div class="line">  <span class="comment">//note: 下面两个都是新创建的空集合</span></div><div class="line">  controllerContext.partitionLeadershipInfo = <span class="keyword">new</span> mutable.<span class="type">HashMap</span>[<span class="type">TopicAndPartition</span>, <span class="type">LeaderIsrAndControllerEpoch</span>]</div><div class="line">  controllerContext.shuttingDownBrokerIds = mutable.<span class="type">Set</span>.empty[<span class="type">Int</span>]</div><div class="line">  <span class="comment">// update the leader and isr cache for all existing partitions from Zookeeper</span></div><div class="line">  updateLeaderAndIsrCache() <span class="comment">//note: 获取 topic-partition 的详细信息,更新到 partitionLeadershipInfo 中</span></div><div class="line">  <span class="comment">// start the channel manager</span></div><div class="line">  startChannelManager() <span class="comment">//note: 启动连接所有的 broker 的线程, 根据 broker/ids 的临时去判断要连接哪些 broker</span></div><div class="line">  initializePreferredReplicaElection() <span class="comment">//note: 初始化需要进行最优 leader 选举的 partition</span></div><div class="line">  initializePartitionReassignment() <span class="comment">//note: 初始化需要进行分区副本迁移的 partition</span></div><div class="line">  initializeTopicDeletion() <span class="comment">//note: 初始化要删除的 topic 及后台的 topic 删除线程,还有不能删除的 topic 集合</span></div><div class="line">  info(<span class="string">"Currently active brokers in the cluster: %s"</span>.format(controllerContext.liveBrokerIds))</div><div class="line">  info(<span class="string">"Currently shutting brokers in the cluster: %s"</span>.format(controllerContext.shuttingDownBrokerIds))</div><div class="line">  info(<span class="string">"Current list of topics in the cluster: %s"</span>.format(controllerContext.allTopics))</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<blockquote>
<p>最优 leader 选举：就是默认选择 Replica 分配中第一个 replica 作为 leader，为什么叫做最优 leader 选举呢？因为 Kafka 在给每个 Partition 分配副本时，它会保证分区的主副本会均匀分布在所有的 broker 上，这样的话只要保证第一个 replica 被选举为 leader，读写流量就会均匀分布在所有的 Broker 上，当然这是有一个前提的，那就是每个 Partition 的读写流量相差不多，但是在实际的生产环境，这是不太可能的，所以一般情况下，大集群是不建议开自动 leader 均衡的，可以通过额外的算法计算、手动去触发最优 leader 选举。</p>
</blockquote>
<h3 id="Controller-Channel-Manager"><a href="#Controller-Channel-Manager" class="headerlink" title="Controller Channel Manager"></a>Controller Channel Manager</h3><p><code>initializeControllerContext()</code> 方法会通过 <code>startChannelManager()</code> 方法初始化 ControllerChannelManager 对象，如下所示：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//note: 启动 ChannelManager 线程</span></div><div class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">startChannelManager</span></span>() &#123;</div><div class="line">  controllerContext.controllerChannelManager = <span class="keyword">new</span> <span class="type">ControllerChannelManager</span>(controllerContext, config, time, metrics, threadNamePrefix)</div><div class="line">  controllerContext.controllerChannelManager.startup()</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>ControllerChannelManager 在初始化时，会为集群中的每个节点初始化一个 ControllerBrokerStateInfo 对象，该对象包含四个部分：</p>
<ol>
<li>NetworkClient：网络连接对象；</li>
<li>Node：节点信息；</li>
<li>BlockingQueue：请求队列；</li>
<li>RequestSendThread：请求的发送线程。</li>
</ol>
<p>其具体实现如下所示：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//note: 控制所有已经存活 broker 的网络连接</span></div><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">ControllerChannelManager</span>(<span class="params">controllerContext: <span class="type">ControllerContext</span>, config: <span class="type">KafkaConfig</span>, time: <span class="type">Time</span>, metrics: <span class="type">Metrics</span>, threadNamePrefix: <span class="type">Option</span>[<span class="type">String</span>] = <span class="type">None</span></span>) <span class="keyword">extends</span> <span class="title">Logging</span> </span>&#123;</div><div class="line">  <span class="keyword">protected</span> <span class="keyword">val</span> brokerStateInfo = <span class="keyword">new</span> <span class="type">HashMap</span>[<span class="type">Int</span>, <span class="type">ControllerBrokerStateInfo</span>]</div><div class="line">  controllerContext.liveBrokers.foreach(addNewBroker) <span class="comment">//note: 获取目前已经存活的所有 broker</span></div><div class="line">  <span class="comment">//note: 添加一个新的 broker（初始化时,这个方法相当于连接当前存活的所有 broker）</span></div><div class="line">  <span class="comment">//note: 建立网络连接、启动请求发送线程</span></div><div class="line">  <span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">addNewBroker</span></span>(broker: <span class="type">Broker</span>) &#123;</div><div class="line">    <span class="keyword">val</span> messageQueue = <span class="keyword">new</span> <span class="type">LinkedBlockingQueue</span>[<span class="type">QueueItem</span>]</div><div class="line">    debug(<span class="string">"Controller %d trying to connect to broker %d"</span>.format(config.brokerId, broker.id))</div><div class="line">    <span class="keyword">val</span> brokerEndPoint = broker.getBrokerEndPoint(config.interBrokerListenerName)</div><div class="line">    <span class="keyword">val</span> brokerNode = <span class="keyword">new</span> <span class="type">Node</span>(broker.id, brokerEndPoint.host, brokerEndPoint.port)</div><div class="line">    <span class="keyword">val</span> networkClient = &#123; <span class="comment">//note: 初始化 NetworkClient</span></div><div class="line">      <span class="keyword">val</span> channelBuilder = <span class="type">ChannelBuilders</span>.clientChannelBuilder(</div><div class="line">        config.interBrokerSecurityProtocol,</div><div class="line">        <span class="type">LoginType</span>.<span class="type">SERVER</span>,</div><div class="line">        config.values,</div><div class="line">        config.saslMechanismInterBrokerProtocol,</div><div class="line">        config.saslInterBrokerHandshakeRequestEnable</div><div class="line">      )</div><div class="line">      <span class="keyword">val</span> selector = <span class="keyword">new</span> <span class="type">Selector</span>(</div><div class="line">        <span class="type">NetworkReceive</span>.<span class="type">UNLIMITED</span>,</div><div class="line">        <span class="type">Selector</span>.<span class="type">NO_IDLE_TIMEOUT_MS</span>,</div><div class="line">        metrics,</div><div class="line">        time,</div><div class="line">        <span class="string">"controller-channel"</span>,</div><div class="line">        <span class="type">Map</span>(<span class="string">"broker-id"</span> -&gt; broker.id.toString).asJava,</div><div class="line">        <span class="literal">false</span>,</div><div class="line">        channelBuilder</div><div class="line">      )</div><div class="line">      <span class="keyword">new</span> <span class="type">NetworkClient</span>(</div><div class="line">        selector,</div><div class="line">        <span class="keyword">new</span> <span class="type">ManualMetadataUpdater</span>(<span class="type">Seq</span>(brokerNode).asJava),</div><div class="line">        config.brokerId.toString,</div><div class="line">        <span class="number">1</span>,</div><div class="line">        <span class="number">0</span>,</div><div class="line">        <span class="type">Selectable</span>.<span class="type">USE_DEFAULT_BUFFER_SIZE</span>,</div><div class="line">        <span class="type">Selectable</span>.<span class="type">USE_DEFAULT_BUFFER_SIZE</span>,</div><div class="line">        config.requestTimeoutMs,</div><div class="line">        time,</div><div class="line">        <span class="literal">false</span></div><div class="line">      )</div><div class="line">    &#125;</div><div class="line">    <span class="keyword">val</span> threadName = threadNamePrefix <span class="keyword">match</span> &#123;</div><div class="line">      <span class="keyword">case</span> <span class="type">None</span> =&gt; <span class="string">"Controller-%d-to-broker-%d-send-thread"</span>.format(config.brokerId, broker.id)</div><div class="line">      <span class="keyword">case</span> <span class="type">Some</span>(name) =&gt; <span class="string">"%s:Controller-%d-to-broker-%d-send-thread"</span>.format(name, config.brokerId, broker.id)</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="keyword">val</span> requestThread = <span class="keyword">new</span> <span class="type">RequestSendThread</span>(config.brokerId, controllerContext, messageQueue, networkClient,</div><div class="line">      brokerNode, config, time, threadName) <span class="comment">//note: 初始化 requestThread</span></div><div class="line">    requestThread.setDaemon(<span class="literal">false</span>) <span class="comment">//note: 非守护进程</span></div><div class="line">    brokerStateInfo.put(broker.id, <span class="keyword">new</span> <span class="type">ControllerBrokerStateInfo</span>(networkClient, brokerNode, messageQueue, requestThread))</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>清楚了上面的逻辑，再来看 KafkaController 部分是如何向 Broker 发送请求的？</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">sendRequest(brokerId: <span class="type">Int</span>, apiKey: <span class="type">ApiKeys</span>, request: <span class="type">AbstractRequest</span>.<span class="type">Builder</span>[_ &lt;: <span class="type">AbstractRequest</span>],</div><div class="line">                callback: <span class="type">AbstractResponse</span> =&gt; <span class="type">Unit</span> = <span class="literal">null</span>) = &#123;</div><div class="line">  controllerContext.controllerChannelManager.sendRequest(brokerId, apiKey, request, callback)</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>KafkaController 实际上是调用的 ControllerChannelManager 的 <code>sendRequest()</code> 方法向 Broker 发送请求信息，其实现如下所示：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//note: 向 broker 发送请求（并没有真正发送,只是添加到对应的 queue 中）</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">sendRequest</span></span>(brokerId: <span class="type">Int</span>, apiKey: <span class="type">ApiKeys</span>, request: <span class="type">AbstractRequest</span>.<span class="type">Builder</span>[_ &lt;: <span class="type">AbstractRequest</span>],</div><div class="line">                callback: <span class="type">AbstractResponse</span> =&gt; <span class="type">Unit</span> = <span class="literal">null</span>) &#123;</div><div class="line">  brokerLock synchronized &#123;</div><div class="line">    <span class="keyword">val</span> stateInfoOpt = brokerStateInfo.get(brokerId)</div><div class="line">    stateInfoOpt <span class="keyword">match</span> &#123;</div><div class="line">      <span class="keyword">case</span> <span class="type">Some</span>(stateInfo) =&gt;</div><div class="line">        stateInfo.messageQueue.put(<span class="type">QueueItem</span>(apiKey, request, callback))</div><div class="line">      <span class="keyword">case</span> <span class="type">None</span> =&gt;</div><div class="line">        warn(<span class="string">"Not sending request %s to broker %d, since it is offline."</span>.format(request, brokerId))</div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>它实际上只是把对应的请求添加到该 Broker 对应的 MessageQueue 中，并没有真正的去发送请求，请求的的发送是在 每台 Broker 对应的 RequestSendThread 中处理的。</p>
<h2 id="Controller-原生的四种-leader-选举机制"><a href="#Controller-原生的四种-leader-选举机制" class="headerlink" title="Controller 原生的四种 leader 选举机制"></a>Controller 原生的四种 leader 选举机制</h2><p>KafkaController 在初始化时，也会初始化四种不同的 leader 选举机制，如下所示：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//note: partition leader 挂掉时，选举 leader</span></div><div class="line"><span class="keyword">val</span> offlinePartitionSelector = <span class="keyword">new</span> <span class="type">OfflinePartitionLeaderSelector</span>(controllerContext, config)</div><div class="line"><span class="comment">//note: 重新分配分区时，leader 选举</span></div><div class="line"><span class="keyword">private</span> <span class="keyword">val</span> reassignedPartitionLeaderSelector = <span class="keyword">new</span> <span class="type">ReassignedPartitionLeaderSelector</span>(controllerContext)</div><div class="line"><span class="comment">//note: 使用最优的副本作为 leader</span></div><div class="line"><span class="keyword">private</span> <span class="keyword">val</span> preferredReplicaPartitionLeaderSelector = <span class="keyword">new</span> <span class="type">PreferredReplicaPartitionLeaderSelector</span>(controllerContext)</div><div class="line"><span class="comment">//note: broker 掉线时，重新选举 leader</span></div><div class="line"><span class="keyword">private</span> <span class="keyword">val</span> controlledShutdownPartitionLeaderSelector = <span class="keyword">new</span> <span class="type">ControlledShutdownLeaderSelector</span>(controllerContext)</div></pre></td></tr></table></figure>
<p>四种 leader 选举实现类及对应触发条件如下所示：</p>
<table>
<thead>
<tr>
<th>实现</th>
<th>触发条件</th>
</tr>
</thead>
<tbody>
<tr>
<td>OfflinePartitionLeaderSelector</td>
<td>leader 掉线时触发</td>
</tr>
<tr>
<td>ReassignedPartitionLeaderSelector</td>
<td>分区的副本重新分配数据同步完成后触发的</td>
</tr>
<tr>
<td>PreferredReplicaPartitionLeaderSelector</td>
<td>最优 leader 选举，手动触发或自动 leader 均衡调度时触发</td>
</tr>
<tr>
<td>ControlledShutdownLeaderSelector</td>
<td>broker 发送 ShutDown 请求主动关闭服务时触发</td>
</tr>
</tbody>
</table>
<h3 id="OfflinePartitionLeaderSelector"><a href="#OfflinePartitionLeaderSelector" class="headerlink" title="OfflinePartitionLeaderSelector"></a>OfflinePartitionLeaderSelector</h3><p>OfflinePartitionLeaderSelector Partition leader 选举的逻辑是：</p>
<ol>
<li>如果 isr 中至少有一个副本是存活的，那么从该 Partition 存活的 isr 中选举第一个副本作为新的 leader，存活的 isr 作为新的 isr；</li>
<li>否则，如果脏选举（unclear elect）是禁止的，那么就抛出 NoReplicaOnlineException 异常；</li>
<li>否则，即允许脏选举的情况下，从存活的、所分配的副本（不在 isr 中的副本）中选出一个副本作为新的 leader 和新的 isr 集合；</li>
<li>否则，即是 Partition 分配的副本没有存活的，抛出 NoReplicaOnlineException 异常；</li>
</ol>
<p>一旦 leader 被成功注册到 zk 中，它将会更新到 KafkaController 缓存中的 allLeaders 中。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//note: 对于 LeaderAndIsrRequest， 选举一个新的 leader、isr 和 receiving replicas</span></div><div class="line"><span class="comment">//note: 1.如果 isr 中至少有一个副本是存活的，那么存活的 isr 中选举一个副本作为新的 leader，存活的 isr 作为新的 isr；</span></div><div class="line"><span class="comment">//note: 2.否则，如果脏选举（unclear elect）是禁止的，那么就抛出 NoReplicaOnlineException 异常；</span></div><div class="line"><span class="comment">//note: 3.否则，从存活的、所分配的副本中选出一个副本作为新的 leader 和新的 isr 集合；</span></div><div class="line"><span class="comment">//note: 4.否则，partition 分配的副本没有存活的，抛出 NoReplicaOnlineException 异常；</span></div><div class="line"><span class="comment">//note: 一旦 leader 被成功注册到 zk 中，它将更新缓存中的 allLeaders。</span></div><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">OfflinePartitionLeaderSelector</span>(<span class="params">controllerContext: <span class="type">ControllerContext</span>, config: <span class="type">KafkaConfig</span></span>)</span></div><div class="line">  <span class="keyword">extends</span> <span class="type">PartitionLeaderSelector</span> <span class="keyword">with</span> <span class="type">Logging</span> &#123;</div><div class="line">  <span class="keyword">this</span>.logIdent = <span class="string">"[OfflinePartitionLeaderSelector]: "</span></div><div class="line"></div><div class="line">  <span class="comment">//note: leader 选举，过程如上面所述</span></div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">selectLeader</span></span>(topicAndPartition: <span class="type">TopicAndPartition</span>, currentLeaderAndIsr: <span class="type">LeaderAndIsr</span>): (<span class="type">LeaderAndIsr</span>, <span class="type">Seq</span>[<span class="type">Int</span>]) = &#123;</div><div class="line">    controllerContext.partitionReplicaAssignment.get(topicAndPartition) <span class="keyword">match</span> &#123;</div><div class="line">      <span class="keyword">case</span> <span class="type">Some</span>(assignedReplicas) =&gt;</div><div class="line">        <span class="comment">//note: AR 中还存活的副本</span></div><div class="line">        <span class="keyword">val</span> liveAssignedReplicas = assignedReplicas.filter(r =&gt; controllerContext.liveBrokerIds.contains(r))</div><div class="line">        <span class="comment">//note: 当前 isr 中还存活的副本</span></div><div class="line">        <span class="keyword">val</span> liveBrokersInIsr = currentLeaderAndIsr.isr.filter(r =&gt; controllerContext.liveBrokerIds.contains(r))</div><div class="line">        <span class="keyword">val</span> currentLeaderEpoch = currentLeaderAndIsr.leaderEpoch <span class="comment">//note: epoch</span></div><div class="line">        <span class="keyword">val</span> currentLeaderIsrZkPathVersion = currentLeaderAndIsr.zkVersion <span class="comment">//note: zkVersion</span></div><div class="line">        <span class="comment">//note: 选取新的 leader 和 isr</span></div><div class="line">        <span class="keyword">val</span> newLeaderAndIsr =</div><div class="line">          <span class="keyword">if</span> (liveBrokersInIsr.isEmpty) &#123; <span class="comment">//note: 当前 isr 中副本都挂了</span></div><div class="line">            <span class="comment">// Prior to electing an unclean (i.e. non-ISR) leader, ensure that doing so is not disallowed by the configuration</span></div><div class="line">            <span class="comment">// for unclean leader election.</span></div><div class="line">            <span class="keyword">if</span> (!<span class="type">LogConfig</span>.fromProps(config.originals, <span class="type">AdminUtils</span>.fetchEntityConfig(controllerContext.zkUtils,</div><div class="line">              <span class="type">ConfigType</span>.<span class="type">Topic</span>, topicAndPartition.topic)).uncleanLeaderElectionEnable) &#123; <span class="comment">//note: 不允许脏选举的话，抛异常</span></div><div class="line">              <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">NoReplicaOnlineException</span>((<span class="string">"No broker in ISR for partition "</span> +</div><div class="line">                <span class="string">"%s is alive. Live brokers are: [%s],"</span>.format(topicAndPartition, controllerContext.liveBrokerIds)) +</div><div class="line">                <span class="string">" ISR brokers are: [%s]"</span>.format(currentLeaderAndIsr.isr.mkString(<span class="string">","</span>)))</div><div class="line">            &#125;</div><div class="line">            debug(<span class="string">"No broker in ISR is alive for %s. Pick the leader from the alive assigned replicas: %s"</span></div><div class="line">              .format(topicAndPartition, liveAssignedReplicas.mkString(<span class="string">","</span>)))</div><div class="line">            <span class="keyword">if</span> (liveAssignedReplicas.isEmpty) &#123; <span class="comment">//note: 副本全挂了，抛异常</span></div><div class="line">              <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">NoReplicaOnlineException</span>((<span class="string">"No replica for partition "</span> +</div><div class="line">                <span class="string">"%s is alive. Live brokers are: [%s],"</span>.format(topicAndPartition, controllerContext.liveBrokerIds)) +</div><div class="line">                <span class="string">" Assigned replicas are: [%s]"</span>.format(assignedReplicas))</div><div class="line">            &#125; <span class="keyword">else</span> &#123; <span class="comment">//note: 从存活的副本中选举 leader（不能保证选举的是 LEO 最大的副本），并将该副本作为 isr</span></div><div class="line">              <span class="type">ControllerStats</span>.uncleanLeaderElectionRate.mark()</div><div class="line">              <span class="keyword">val</span> newLeader = liveAssignedReplicas.head <span class="comment">//note: 选择第一个作为 leader</span></div><div class="line">              warn(<span class="string">"No broker in ISR is alive for %s. Elect leader %d from live brokers %s. There's potential data loss."</span></div><div class="line">                .format(topicAndPartition, newLeader, liveAssignedReplicas.mkString(<span class="string">","</span>)))</div><div class="line">              <span class="keyword">new</span> <span class="type">LeaderAndIsr</span>(newLeader, currentLeaderEpoch + <span class="number">1</span>, <span class="type">List</span>(newLeader), currentLeaderIsrZkPathVersion + <span class="number">1</span>)</div><div class="line">            &#125;</div><div class="line">          &#125; <span class="keyword">else</span> &#123; <span class="comment">//note: 当前 isr 中还有副本存活</span></div><div class="line">            <span class="keyword">val</span> liveReplicasInIsr = liveAssignedReplicas.filter(r =&gt; liveBrokersInIsr.contains(r))</div><div class="line">            <span class="keyword">val</span> newLeader = liveReplicasInIsr.head <span class="comment">//note: 第一个作为 leader</span></div><div class="line">            debug(<span class="string">"Some broker in ISR is alive for %s. Select %d from ISR %s to be the leader."</span></div><div class="line">              .format(topicAndPartition, newLeader, liveBrokersInIsr.mkString(<span class="string">","</span>)))</div><div class="line">            <span class="keyword">new</span> <span class="type">LeaderAndIsr</span>(newLeader, currentLeaderEpoch + <span class="number">1</span>, liveBrokersInIsr.toList, currentLeaderIsrZkPathVersion + <span class="number">1</span>)</div><div class="line">          &#125;</div><div class="line">        info(<span class="string">"Selected new leader and ISR %s for offline partition %s"</span>.format(newLeaderAndIsr.toString(), topicAndPartition))</div><div class="line">        (newLeaderAndIsr, liveAssignedReplicas)</div><div class="line">      <span class="keyword">case</span> <span class="type">None</span> =&gt;</div><div class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">NoReplicaOnlineException</span>(<span class="string">"Partition %s doesn't have replicas assigned to it"</span>.format(topicAndPartition))</div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line">&#125;</div><div class="line">`</div></pre></td></tr></table></figure>
<h3 id="ReassignedPartitionLeaderSelector"><a href="#ReassignedPartitionLeaderSelector" class="headerlink" title="ReassignedPartitionLeaderSelector"></a>ReassignedPartitionLeaderSelector</h3><p>ReassignedPartitionLeaderSelector 是在 Partition 副本迁移后，副本同步完成（RAR 都处在 isr 中，RAR 指的是该 Partition 新分配的副本）后触发的，其 leader 选举逻辑如下：</p>
<ol>
<li>leader 选择存活的 RAR 中的第一个副本，此时 RAR 都在 isr 中了；</li>
<li>new isr 是所有存活的 RAR 副本列表；</li>
</ol>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//note: 重新分配分区时，partition 的 leader 选举策略</span></div><div class="line"><span class="comment">//note: new leader = 新分配并且在 isr 中的一个副本</span></div><div class="line"><span class="comment">//note: new isr = 当前的 isr</span></div><div class="line"><span class="comment">//note: 接收 LeaderAndIsr request 的副本 = reassigned replicas</span></div><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">ReassignedPartitionLeaderSelector</span>(<span class="params">controllerContext: <span class="type">ControllerContext</span></span>) <span class="keyword">extends</span> <span class="title">PartitionLeaderSelector</span> <span class="keyword">with</span> <span class="title">Logging</span> </span>&#123;</div><div class="line">  <span class="keyword">this</span>.logIdent = <span class="string">"[ReassignedPartitionLeaderSelector]: "</span></div><div class="line"></div><div class="line">  <span class="comment">/**</span></div><div class="line">   * The reassigned replicas are already in the ISR when selectLeader is called.</div><div class="line">   */</div><div class="line">  <span class="comment">//note: 当这个方法被调用时，要求新分配的副本已经在 isr 中了</span></div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">selectLeader</span></span>(topicAndPartition: <span class="type">TopicAndPartition</span>, currentLeaderAndIsr: <span class="type">LeaderAndIsr</span>): (<span class="type">LeaderAndIsr</span>, <span class="type">Seq</span>[<span class="type">Int</span>]) = &#123;</div><div class="line">    <span class="comment">//note: 新分配的 replica 列表</span></div><div class="line">    <span class="keyword">val</span> reassignedInSyncReplicas = controllerContext.partitionsBeingReassigned(topicAndPartition).newReplicas</div><div class="line">    <span class="keyword">val</span> currentLeaderEpoch = currentLeaderAndIsr.leaderEpoch</div><div class="line">    <span class="comment">//note: 当前的 zk version</span></div><div class="line">    <span class="keyword">val</span> currentLeaderIsrZkPathVersion = currentLeaderAndIsr.zkVersion</div><div class="line">    <span class="comment">//note: 新分配的 replica 列表，并且其 broker 存活、且在 isr 中</span></div><div class="line">    <span class="keyword">val</span> aliveReassignedInSyncReplicas = reassignedInSyncReplicas.filter(r =&gt; controllerContext.liveBrokerIds.contains(r) &amp;&amp;</div><div class="line">                                                                             currentLeaderAndIsr.isr.contains(r))</div><div class="line">    <span class="comment">//note: 选择第一个作为新的 leader</span></div><div class="line">    <span class="keyword">val</span> newLeaderOpt = aliveReassignedInSyncReplicas.headOption</div><div class="line">    newLeaderOpt <span class="keyword">match</span> &#123;</div><div class="line">      <span class="keyword">case</span> <span class="type">Some</span>(newLeader) =&gt; (<span class="keyword">new</span> <span class="type">LeaderAndIsr</span>(newLeader, currentLeaderEpoch + <span class="number">1</span>, currentLeaderAndIsr.isr,</div><div class="line">        currentLeaderIsrZkPathVersion + <span class="number">1</span>), reassignedInSyncReplicas)</div><div class="line">      <span class="keyword">case</span> <span class="type">None</span> =&gt;</div><div class="line">        reassignedInSyncReplicas.size <span class="keyword">match</span> &#123;</div><div class="line">          <span class="keyword">case</span> <span class="number">0</span> =&gt;</div><div class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">NoReplicaOnlineException</span>(<span class="string">"List of reassigned replicas for partition "</span> +</div><div class="line">              <span class="string">" %s is empty. Current leader and ISR: [%s]"</span>.format(topicAndPartition, currentLeaderAndIsr))</div><div class="line">          <span class="keyword">case</span> _ =&gt;</div><div class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">NoReplicaOnlineException</span>(<span class="string">"None of the reassigned replicas for partition "</span> +</div><div class="line">              <span class="string">"%s are in-sync with the leader. Current leader and ISR: [%s]"</span>.format(topicAndPartition, currentLeaderAndIsr))</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h3 id="PreferredReplicaPartitionLeaderSelector"><a href="#PreferredReplicaPartitionLeaderSelector" class="headerlink" title="PreferredReplicaPartitionLeaderSelector"></a>PreferredReplicaPartitionLeaderSelector</h3><p>PreferredReplicaPartitionLeaderSelector 是最优 leader 选举，选择 AR（assign replica）中的第一个副本作为 leader，前提是该 replica 在是存活的、并且在 isr 中，否则会抛出 StateChangeFailedException 的异常。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//note: 最优的 leader 选举策略（主要用于自动 leader 均衡，选择 AR 中第一个为 leader，前提是它在 isr 中，这样整个集群的 leader 是均衡的,否则抛出异常）</span></div><div class="line"><span class="comment">//note: new leader = 第一个 replica（alive and in isr）</span></div><div class="line"><span class="comment">//note: new isr = 当前 isr</span></div><div class="line"><span class="comment">//note: 接收 LeaderAndIsr request 的 replica = AR</span></div><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">PreferredReplicaPartitionLeaderSelector</span>(<span class="params">controllerContext: <span class="type">ControllerContext</span></span>) <span class="keyword">extends</span> <span class="title">PartitionLeaderSelector</span></span></div><div class="line"><span class="keyword">with</span> <span class="type">Logging</span> &#123;</div><div class="line">  <span class="keyword">this</span>.logIdent = <span class="string">"[PreferredReplicaPartitionLeaderSelector]: "</span></div><div class="line"></div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">selectLeader</span></span>(topicAndPartition: <span class="type">TopicAndPartition</span>, currentLeaderAndIsr: <span class="type">LeaderAndIsr</span>): (<span class="type">LeaderAndIsr</span>, <span class="type">Seq</span>[<span class="type">Int</span>]) = &#123;</div><div class="line">    <span class="comment">//note: Partition 的 AR</span></div><div class="line">    <span class="keyword">val</span> assignedReplicas = controllerContext.partitionReplicaAssignment(topicAndPartition)</div><div class="line">    <span class="comment">//note: preferredReplica，第一个 replica</span></div><div class="line">    <span class="keyword">val</span> preferredReplica = assignedReplicas.head</div><div class="line">    <span class="comment">// check if preferred replica is the current leader</span></div><div class="line">    <span class="comment">//note: 当前的 leader</span></div><div class="line">    <span class="keyword">val</span> currentLeader = controllerContext.partitionLeadershipInfo(topicAndPartition).leaderAndIsr.leader</div><div class="line">    <span class="keyword">if</span> (currentLeader == preferredReplica) &#123;</div><div class="line">      <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">LeaderElectionNotNeededException</span>(<span class="string">"Preferred replica %d is already the current leader for partition %s"</span></div><div class="line">                                                   .format(preferredReplica, topicAndPartition))</div><div class="line">    &#125; <span class="keyword">else</span> &#123; <span class="comment">//note: 当前 leader 不是 preferredReplica 的情况</span></div><div class="line">      info(<span class="string">"Current leader %d for partition %s is not the preferred replica."</span>.format(currentLeader, topicAndPartition) +</div><div class="line">        <span class="string">" Triggering preferred replica leader election"</span>)</div><div class="line">      <span class="comment">// check if preferred replica is not the current leader and is alive and in the isr</span></div><div class="line">      <span class="comment">//note: preferredReplica 是 alive 并且在 isr 中</span></div><div class="line">      <span class="keyword">if</span> (controllerContext.liveBrokerIds.contains(preferredReplica) &amp;&amp; currentLeaderAndIsr.isr.contains(preferredReplica)) &#123;</div><div class="line">        (<span class="keyword">new</span> <span class="type">LeaderAndIsr</span>(preferredReplica, currentLeaderAndIsr.leaderEpoch + <span class="number">1</span>, currentLeaderAndIsr.isr,</div><div class="line">          currentLeaderAndIsr.zkVersion + <span class="number">1</span>), assignedReplicas)</div><div class="line">      &#125; <span class="keyword">else</span> &#123;</div><div class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">StateChangeFailedException</span>(<span class="string">"Preferred replica %d for partition "</span>.format(preferredReplica) +</div><div class="line">          <span class="string">"%s is either not alive or not in the isr. Current leader and ISR: [%s]"</span>.format(topicAndPartition, currentLeaderAndIsr))</div><div class="line">      &#125;</div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h3 id="ControlledShutdownLeaderSelector"><a href="#ControlledShutdownLeaderSelector" class="headerlink" title="ControlledShutdownLeaderSelector"></a>ControlledShutdownLeaderSelector</h3><p>ControlledShutdownLeaderSelector 是在处理 broker 下线时调用的 leader 选举方法，它会选举 isr 中第一个没有正在关闭的 replica 作为 leader，否则抛出 StateChangeFailedException 异常。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//note: Broker 掉线时，重新选举 leader 调用的 leader 选举方法</span></div><div class="line"><span class="comment">//note: new leader = 在 isr 中，并且没有正在 shutdown 的 replica</span></div><div class="line"><span class="comment">//note: new isr = 当前 isr 除去关闭的 replica</span></div><div class="line"><span class="comment">//note: 接收 LeaderAndIsr request 的 replica = 存活的 AR</span></div><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">ControlledShutdownLeaderSelector</span>(<span class="params">controllerContext: <span class="type">ControllerContext</span></span>)</span></div><div class="line">        <span class="keyword">extends</span> <span class="type">PartitionLeaderSelector</span></div><div class="line">        <span class="keyword">with</span> <span class="type">Logging</span> &#123;</div><div class="line"></div><div class="line">  <span class="keyword">this</span>.logIdent = <span class="string">"[ControlledShutdownLeaderSelector]: "</span></div><div class="line"></div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">selectLeader</span></span>(topicAndPartition: <span class="type">TopicAndPartition</span>, currentLeaderAndIsr: <span class="type">LeaderAndIsr</span>): (<span class="type">LeaderAndIsr</span>, <span class="type">Seq</span>[<span class="type">Int</span>]) = &#123;</div><div class="line">    <span class="keyword">val</span> currentLeaderEpoch = currentLeaderAndIsr.leaderEpoch</div><div class="line">    <span class="keyword">val</span> currentLeaderIsrZkPathVersion = currentLeaderAndIsr.zkVersion</div><div class="line"></div><div class="line">    <span class="keyword">val</span> currentLeader = currentLeaderAndIsr.leader</div><div class="line"></div><div class="line">    <span class="keyword">val</span> assignedReplicas = controllerContext.partitionReplicaAssignment(topicAndPartition)</div><div class="line">    <span class="keyword">val</span> liveOrShuttingDownBrokerIds = controllerContext.liveOrShuttingDownBrokerIds</div><div class="line">    <span class="comment">//note: 存活的 AR</span></div><div class="line">    <span class="keyword">val</span> liveAssignedReplicas = assignedReplicas.filter(r =&gt; liveOrShuttingDownBrokerIds.contains(r))</div><div class="line"></div><div class="line">    <span class="comment">//note: 从当前 isr 中过滤掉正在 shutdown 的 broker</span></div><div class="line">    <span class="keyword">val</span> newIsr = currentLeaderAndIsr.isr.filter(brokerId =&gt; !controllerContext.shuttingDownBrokerIds.contains(brokerId))</div><div class="line">    liveAssignedReplicas.find(newIsr.contains) <span class="keyword">match</span> &#123; <span class="comment">//note: find 方法返回的是第一满足条件的元素，AR 中第一个在 newIsr 集合中的元素被选为 leader</span></div><div class="line">      <span class="keyword">case</span> <span class="type">Some</span>(newLeader) =&gt;</div><div class="line">        debug(<span class="string">"Partition %s : current leader = %d, new leader = %d"</span>.format(topicAndPartition, currentLeader, newLeader))</div><div class="line">        (<span class="type">LeaderAndIsr</span>(newLeader, currentLeaderEpoch + <span class="number">1</span>, newIsr, currentLeaderIsrZkPathVersion + <span class="number">1</span>), liveAssignedReplicas)</div><div class="line">      <span class="keyword">case</span> <span class="type">None</span> =&gt;</div><div class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">StateChangeFailedException</span>((<span class="string">"No other replicas in ISR %s for %s besides"</span> +</div><div class="line">          <span class="string">" shutting down brokers %s"</span>).format(currentLeaderAndIsr.isr.mkString(<span class="string">","</span>), topicAndPartition, controllerContext.shuttingDownBrokerIds.mkString(<span class="string">","</span>)))</div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[Kafka 源码解析之 ReplicaManager 详解（十五）]]></title>
      <url>http://matt33.com/2018/05/01/kafka-replica-manager/</url>
      <content type="html"><![CDATA[<p>前面几篇文章讲述了 LogManager 的实现、Produce 请求、Fetch 请求的处理以及副本同步机制的实现，Kafka 存储层的主要内容基本上算是讲完了（还有几个小块的内容后面会结合 Controller 再详细介绍）。本篇文章以 ReplicaManager 类为入口，通过对 ReplicaManager 的详解，顺便再把 Kafka 存储层的内容做一个简单的总结。</p>
<h2 id="ReplicaManager-简介"><a href="#ReplicaManager-简介" class="headerlink" title="ReplicaManager 简介"></a>ReplicaManager 简介</h2><p>前面三篇文章，关于 Produce 请求、Fetch 请求以及副本同步流程的启动都是由 ReplicaManager 来控制的，ReplicaManager 可以说是 Server 端重要的组成部分，回头再仔细看下 KafkaApi 这个类，就会发现 Server 端要处理的多种类型的请求都是 ReplicaManager 来处理的，ReplicaManager 需要处理的请求的有以下六种：</p>
<ol>
<li>LeaderAndIsr 请求；</li>
<li>StopReplica 请求；</li>
<li>UpdateMetadata 请求；</li>
<li>Produce 请求；</li>
<li>Fetch 请求；</li>
<li>ListOffset 请求；</li>
</ol>
<p>其中后面三个已经在前面的文章中介绍过，前面三个都是 Controller 发送的请求，虽然是由 ReplicaManager 中处理的，也会在 Controller 部分展开详细的介绍。</p>
<p>这里先看下面这张图，这张图把 ReplicaManager、Partition、Replica、LogManager、Log、logSegment 这几个抽象的类之间的调用关系简单地串了起来，也算是对存储层这几个重要的部分简单总结了一下：</p>
<p><img src="/images/kafka/replica-manager.png" alt="存储层各个类之间关系"></p>
<p>对着上面的图，简单总结一下：</p>
<ol>
<li>ReplicaManager 是最外层暴露的一个实例，前面说的那几种类型的请求都是由这个实例来处理的；</li>
<li>LogManager 负责管理本节点上所有的日志（Log）实例，它作为 ReplicaManager 的变量传入到了 ReplicaManager 中，ReplicaManager 通过 LogManager 可以对相应的日志实例进行操作；</li>
<li>在 ReplicaManager 中有一个变量：allPartitions，它负责管理本节点所有的 Partition 实例（只要本节点有这个 partition 的日志实例，就会有一个对应的 Partition 对对象实例）；</li>
<li>在创建 Partition 实例时，ReplicaManager 也会作为成员变量传入到 Partition 实例中，Partition 通过 ReplicaManager 可以获得 LogManager 实例、brokerId 等；</li>
<li>Partition 会为它的每一个副本创建一个 Replica 对象实例，但只会为那个在本地副本创建 Log 对象实例（LogManager 不存在这个 Log 对象的情况下，有的话直接引用），这样的话，本地的 Replica 也就与 Log 实例建立了一个联系。</li>
</ol>
<p>关于 ReplicaManager 的 allPartitions 变量可以看下面这张图（假设 Partition 设置的是3副本）：</p>
<p><img src="/images/kafka/all-partition.png" alt="ReplicaManager 的 allPartitions 变量"></p>
<p>allPartitions 管理的 Partition 实例，因为是 3 副本，所以每个 Partition 实例又会管理着三个 Replica，其中只有本地副本（对于上图，就是值 replica.id = 1 的副本）才有对应的 Log 实例对象（HW 和 LEO 的介绍参考 <a href="http://matt33.com/2017/01/16/kafka-group/#offset-%E9%82%A3%E4%BA%9B%E4%BA%8B">Offset 那些事</a>）。</p>
<h2 id="ReplicaManager-启动"><a href="#ReplicaManager-启动" class="headerlink" title="ReplicaManager 启动"></a>ReplicaManager 启动</h2><p>KafkaServer 在启动时，就初始化了 ReplicaManager 实例，如下所示，KafkaServer 在初始化 logManager 后，将 logManager 作为参数传递给了 ReplicaManager。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">startup</span></span>() &#123;</div><div class="line">  <span class="keyword">try</span> &#123;</div><div class="line">    info(<span class="string">"starting"</span>)</div><div class="line"></div><div class="line">    <span class="keyword">if</span>(isShuttingDown.get)</div><div class="line">      <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">IllegalStateException</span>(<span class="string">"Kafka server is still shutting down, cannot re-start!"</span>)</div><div class="line"></div><div class="line">    <span class="keyword">if</span>(startupComplete.get)</div><div class="line">      <span class="keyword">return</span></div><div class="line"></div><div class="line">    <span class="keyword">val</span> canStartup = isStartingUp.compareAndSet(<span class="literal">false</span>, <span class="literal">true</span>)</div><div class="line">    <span class="keyword">if</span> (canStartup) &#123;</div><div class="line">      brokerState.newState(<span class="type">Starting</span>)</div><div class="line"></div><div class="line">      <span class="comment">/* start scheduler */</span></div><div class="line">      kafkaScheduler.startup()</div><div class="line"></div><div class="line">      <span class="comment">/* setup zookeeper */</span></div><div class="line">      zkUtils = initZk()</div><div class="line"></div><div class="line">      <span class="comment">/* Get or create cluster_id */</span></div><div class="line">      _clusterId = getOrGenerateClusterId(zkUtils)</div><div class="line">      info(<span class="string">s"Cluster ID = <span class="subst">$clusterId</span>"</span>)</div><div class="line"></div><div class="line">      <span class="comment">/* generate brokerId */</span></div><div class="line">      config.brokerId =  getBrokerId</div><div class="line">      <span class="keyword">this</span>.logIdent = <span class="string">"[Kafka Server "</span> + config.brokerId + <span class="string">"], "</span></div><div class="line"></div><div class="line">      <span class="comment">/* start log manager */</span></div><div class="line">      <span class="comment">//note: 启动日志管理线程</span></div><div class="line">      logManager = createLogManager(zkUtils.zkClient, brokerState)</div><div class="line">      logManager.startup()</div><div class="line"></div><div class="line">      <span class="comment">/* start replica manager */</span></div><div class="line">      <span class="comment">//note: 启动 replica manager</span></div><div class="line">      replicaManager = <span class="keyword">new</span> <span class="type">ReplicaManager</span>(config, metrics, time, zkUtils, kafkaScheduler, logManager,</div><div class="line">        isShuttingDown, quotaManagers.follower)</div><div class="line">      replicaManager.startup()</div><div class="line">  &#125; <span class="keyword">catch</span> &#123;</div><div class="line">    <span class="keyword">case</span> e: <span class="type">Throwable</span> =&gt;</div><div class="line">      fatal(<span class="string">"Fatal error during KafkaServer startup. Prepare to shutdown"</span>, e)</div><div class="line">      isStartingUp.set(<span class="literal">false</span>)</div><div class="line">      shutdown()</div><div class="line">      <span class="keyword">throw</span> e</div><div class="line">    &#125;</div><div class="line"> &#125;</div></pre></td></tr></table></figure>
<h3 id="startup"><a href="#startup" class="headerlink" title="startup"></a>startup</h3><p>ReplicaManager <code>startup()</code> 方法的实现如下：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">startup</span></span>() &#123;</div><div class="line">  <span class="comment">// start ISR expiration thread</span></div><div class="line">  <span class="comment">// A follower can lag behind leader for up to config.replicaLagTimeMaxMs x 1.5 before it is removed from ISR</span></div><div class="line">  <span class="comment">//note: 周期性检查 isr 是否有 replica 过期需要从 isr 中移除</span></div><div class="line">  scheduler.schedule(<span class="string">"isr-expiration"</span>, maybeShrinkIsr, period = config.replicaLagTimeMaxMs / <span class="number">2</span>, unit = <span class="type">TimeUnit</span>.<span class="type">MILLISECONDS</span>)</div><div class="line">  <span class="comment">//note: 周期性检查是不是有 topic-partition 的 isr 需要变动,如果需要,就更新到 zk 上,来触发 controller</span></div><div class="line">  scheduler.schedule(<span class="string">"isr-change-propagation"</span>, maybePropagateIsrChanges, period = <span class="number">2500</span>L, unit = <span class="type">TimeUnit</span>.<span class="type">MILLISECONDS</span>)</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>这个方法与 LogManager 的 <code>startup()</code> 方法类似，也是启动了相应的定时任务，这里，ReplicaManger 启动了两个周期性的任务：</p>
<ol>
<li>maybeShrinkIsr: 判断 topic-partition 的 isr 是否有 replica 因为延迟或 hang 住需要从 isr 中移除；</li>
<li>maybePropagateIsrChanges：判断是不是需要对 isr 进行更新，如果有 topic-partition 的 isr 发生了变动需要进行更新，那么这个方法就会被调用，它会触发 zk 的相应节点，进而触发 controller 进行相应的操作。</li>
</ol>
<p>关于 ReplicaManager 这两个方法的处理过程及 topic-partition isr 变动情况的触发，下面这张流程图做了简单的说明，如下所示：</p>
<p><img src="/images/kafka/replica-manager-startup.png" alt="ReplicaManager 的 Startup 方法启动两个周期性任务及 isr 扩充的情况"></p>
<h3 id="maybeShrinkIsr"><a href="#maybeShrinkIsr" class="headerlink" title="maybeShrinkIsr"></a>maybeShrinkIsr</h3><p>如前面流程图所示， ReplicaManager 的 <code>maybeShrinkIsr()</code> 实现如下：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//note: 遍历所有的 partition 对象,检查其 isr 是否需要抖动</span></div><div class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">maybeShrinkIsr</span></span>(): <span class="type">Unit</span> = &#123;</div><div class="line">  trace(<span class="string">"Evaluating ISR list of partitions to see which replicas can be removed from the ISR"</span>)</div><div class="line">  allPartitions.values.foreach(partition =&gt; partition.maybeShrinkIsr(config.replicaLagTimeMaxMs))</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p><code>maybeShrinkIsr()</code>  会遍历本节点所有的 Partition 实例，来检查它们 isr 中的 replica 是否需要从 isr 中移除，Partition 中这个方法的实现如下：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//note: 检查这个 isr 中的每个 replcia</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">maybeShrinkIsr</span></span>(replicaMaxLagTimeMs: <span class="type">Long</span>) &#123;</div><div class="line">  <span class="keyword">val</span> leaderHWIncremented = inWriteLock(leaderIsrUpdateLock) &#123;</div><div class="line">    leaderReplicaIfLocal <span class="keyword">match</span> &#123; <span class="comment">//note: 只有本地副本是 leader, 才会做这个操作</span></div><div class="line">      <span class="keyword">case</span> <span class="type">Some</span>(leaderReplica) =&gt;</div><div class="line">        <span class="comment">//note: 检查当前 isr 的副本是否需要从 isr 中移除</span></div><div class="line">        <span class="keyword">val</span> outOfSyncReplicas = getOutOfSyncReplicas(leaderReplica, replicaMaxLagTimeMs)</div><div class="line">        <span class="keyword">if</span>(outOfSyncReplicas.nonEmpty) &#123;</div><div class="line">          <span class="keyword">val</span> newInSyncReplicas = inSyncReplicas -- outOfSyncReplicas <span class="comment">//note: new isr</span></div><div class="line">          assert(newInSyncReplicas.nonEmpty)</div><div class="line">          info(<span class="string">"Shrinking ISR for partition [%s,%d] from %s to %s"</span>.format(topic, partitionId,</div><div class="line">            inSyncReplicas.map(_.brokerId).mkString(<span class="string">","</span>), newInSyncReplicas.map(_.brokerId).mkString(<span class="string">","</span>)))</div><div class="line">          <span class="comment">// update ISR in zk and in cache</span></div><div class="line">          updateIsr(newInSyncReplicas) <span class="comment">//note: 更新 isr 到 zk</span></div><div class="line">          <span class="comment">// we may need to increment high watermark since ISR could be down to 1</span></div><div class="line"></div><div class="line">          replicaManager.isrShrinkRate.mark() <span class="comment">//note: 更新 metrics</span></div><div class="line">          maybeIncrementLeaderHW(leaderReplica) <span class="comment">//note: isr 变动了,判断是否需要更新 partition 的 hw</span></div><div class="line">        &#125; <span class="keyword">else</span> &#123;</div><div class="line">          <span class="literal">false</span></div><div class="line">        &#125;</div><div class="line"></div><div class="line">      <span class="keyword">case</span> <span class="type">None</span> =&gt; <span class="literal">false</span> <span class="comment">// do nothing if no longer leader</span></div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  <span class="comment">// some delayed operations may be unblocked after HW changed</span></div><div class="line">  <span class="keyword">if</span> (leaderHWIncremented)</div><div class="line">    tryCompleteDelayedRequests()</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="comment">//note: 检查 isr 中的副本是否需要从 isr 中移除</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">getOutOfSyncReplicas</span></span>(leaderReplica: <span class="type">Replica</span>, maxLagMs: <span class="type">Long</span>): <span class="type">Set</span>[<span class="type">Replica</span>] = &#123;</div><div class="line">  <span class="comment">//note: 获取那些不应该咋 isr 中副本的列表</span></div><div class="line">  <span class="comment">//note: 1. hang 住的 replica: replica 的 LEO 超过 maxLagMs 没有更新, 那么这个 replica 将会被从 isr 中移除;</span></div><div class="line">  <span class="comment">//note: 2. 数据同步慢的 replica: 副本在 maxLagMs 内没有追上 leader 当前的 LEO, 那么这个 replica 讲会从 ist 中移除;</span></div><div class="line">  <span class="comment">//note: 都是通过 lastCaughtUpTimeMs 来判断的</span></div><div class="line">  <span class="keyword">val</span> candidateReplicas = inSyncReplicas - leaderReplica</div><div class="line"></div><div class="line">  <span class="keyword">val</span> laggingReplicas = candidateReplicas.filter(r =&gt; (time.milliseconds - r.lastCaughtUpTimeMs) &gt; maxLagMs)</div><div class="line">  <span class="keyword">if</span> (laggingReplicas.nonEmpty)</div><div class="line">    debug(<span class="string">"Lagging replicas for partition %s are %s"</span>.format(topicPartition, laggingReplicas.map(_.brokerId).mkString(<span class="string">","</span>)))</div><div class="line"></div><div class="line">  laggingReplicas</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p><code>maybeShrinkIsr()</code> 这个方法的实现可以简单总结为以下几步：</p>
<ol>
<li>先判断本地副本是不是这个 partition 的 leader，<strong>这个操作只会在 leader 上进行</strong>，如果不是 leader 直接跳过；</li>
<li>通过 <code>getOutOfSyncReplicas()</code> 方法遍历除 leader 外 isr 的所有 replica，找到那些满足条件（<strong>落后超过 maxLagMs 时间的副本</strong>）需要从 isr 中移除的 replica；</li>
<li>得到了新的 isr 列表，调用 <code>updateIsr()</code> 将新的 isr 更新到 zk 上，并且这个方法内部又调用了 ReplicaManager 的 <code>recordIsrChange()</code> 方法来告诉 ReplicaManager 当前这个 topic-partition 的 isr 发生了变化（<strong>可以看出，zk 上这个 topic-partition 的 isr 信息虽然变化了，但是实际上 controller 还是无法感知的</strong>）；</li>
<li>因为 isr 发生了变动，所以这里会通过 <code>maybeIncrementLeaderHW()</code> 方法来检查一下这个 partition 的 HW 是否需要更新。</li>
</ol>
<p><code>updateIsr()</code> 和 <code>maybeIncrementLeaderHW()</code> 的实现如下：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//note: 检查是否需要更新 partition 的 HW,这个方法将在两种情况下触发:</span></div><div class="line"><span class="comment">//note: 1.Partition ISR 变动; 2. 任何副本的 LEO 改变;</span></div><div class="line"><span class="comment">//note: 在获取 HW 时,是从 isr 和认为能追得上的副本中选择最小的 LEO,之所以也要从能追得上的副本中选择,是为了等待 follower 追上 HW,否则可能没机会追上了</span></div><div class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">maybeIncrementLeaderHW</span></span>(leaderReplica: <span class="type">Replica</span>, curTime: <span class="type">Long</span> = time.milliseconds): <span class="type">Boolean</span> = &#123;</div><div class="line">  <span class="comment">//note: 获取 isr 以及能够追上 isr （认为最近一次 fetch 的时间在 replica.lag.time.max.time 之内） 副本的 LEO 信息。</span></div><div class="line">  <span class="keyword">val</span> allLogEndOffsets = assignedReplicas.filter &#123; replica =&gt;</div><div class="line">    curTime - replica.lastCaughtUpTimeMs &lt;= replicaManager.config.replicaLagTimeMaxMs || inSyncReplicas.contains(replica)</div><div class="line">  &#125;.map(_.logEndOffset)</div><div class="line">  <span class="keyword">val</span> newHighWatermark = allLogEndOffsets.min(<span class="keyword">new</span> <span class="type">LogOffsetMetadata</span>.<span class="type">OffsetOrdering</span>) <span class="comment">//note: 新的 HW</span></div><div class="line">  <span class="keyword">val</span> oldHighWatermark = leaderReplica.highWatermark</div><div class="line">  <span class="keyword">if</span> (oldHighWatermark.messageOffset &lt; newHighWatermark.messageOffset || oldHighWatermark.onOlderSegment(newHighWatermark)) &#123;</div><div class="line">    leaderReplica.highWatermark = newHighWatermark</div><div class="line">    debug(<span class="string">"High watermark for partition [%s,%d] updated to %s"</span>.format(topic, partitionId, newHighWatermark))</div><div class="line">    <span class="literal">true</span></div><div class="line">  &#125; <span class="keyword">else</span> &#123;</div><div class="line">    debug(<span class="string">"Skipping update high watermark since Old hw %s is larger than new hw %s for partition [%s,%d]. All leo's are %s"</span></div><div class="line">      .format(oldHighWatermark, newHighWatermark, topic, partitionId, allLogEndOffsets.mkString(<span class="string">","</span>)))</div><div class="line">    <span class="literal">false</span></div><div class="line">  &#125;</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">updateIsr</span></span>(newIsr: <span class="type">Set</span>[<span class="type">Replica</span>]) &#123;</div><div class="line">  <span class="keyword">val</span> newLeaderAndIsr = <span class="keyword">new</span> <span class="type">LeaderAndIsr</span>(localBrokerId, leaderEpoch, newIsr.map(r =&gt; r.brokerId).toList, zkVersion)</div><div class="line">  <span class="keyword">val</span> (updateSucceeded,newVersion) = <span class="type">ReplicationUtils</span>.updateLeaderAndIsr(zkUtils, topic, partitionId,</div><div class="line">    newLeaderAndIsr, controllerEpoch, zkVersion) <span class="comment">//note: 执行更新操作</span></div><div class="line"></div><div class="line">  <span class="keyword">if</span>(updateSucceeded) &#123; <span class="comment">//note: 成功更新到 zk 上</span></div><div class="line">    replicaManager.recordIsrChange(topicPartition) <span class="comment">//note: 告诉 replicaManager 这个 partition 的 isr 需要更新</span></div><div class="line">    inSyncReplicas = newIsr</div><div class="line">    zkVersion = newVersion</div><div class="line">    trace(<span class="string">"ISR updated to [%s] and zkVersion updated to [%d]"</span>.format(newIsr.mkString(<span class="string">","</span>), zkVersion))</div><div class="line">  &#125; <span class="keyword">else</span> &#123;</div><div class="line">    info(<span class="string">"Cached zkVersion [%d] not equal to that in zookeeper, skip updating ISR"</span>.format(zkVersion))</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h3 id="maybePropagateIsrChanges"><a href="#maybePropagateIsrChanges" class="headerlink" title="maybePropagateIsrChanges"></a>maybePropagateIsrChanges</h3><p>ReplicaManager <code>maybePropagateIsrChanges()</code> 方法的作用是将那些 isr 变动的 topic-partition 列表（<code>isrChangeSet</code>）通过 ReplicationUtils 的 <code>propagateIsrChanges()</code> 方法更新 zk 上，这时候 Controller 才能知道哪些 topic-partition 的 isr 发生了变动。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//note: 这个方法是周期性的运行,来判断 partition 的 isr 是否需要更新,</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">maybePropagateIsrChanges</span></span>() &#123;</div><div class="line">  <span class="keyword">val</span> now = <span class="type">System</span>.currentTimeMillis()</div><div class="line">  isrChangeSet synchronized &#123;</div><div class="line">    <span class="keyword">if</span> (isrChangeSet.nonEmpty &amp;&amp; <span class="comment">//note:  有 topic-partition 的 isr 需要更新</span></div><div class="line">      (lastIsrChangeMs.get() + <span class="type">ReplicaManager</span>.<span class="type">IsrChangePropagationBlackOut</span> &lt; now || <span class="comment">//note: 5s 内没有触发过</span></div><div class="line">        lastIsrPropagationMs.get() + <span class="type">ReplicaManager</span>.<span class="type">IsrChangePropagationInterval</span> &lt; now)) &#123; <span class="comment">//note: 距离上次触发有60s</span></div><div class="line">      <span class="type">ReplicationUtils</span>.propagateIsrChanges(zkUtils, isrChangeSet) <span class="comment">//note: 在 zk 创建 isr 变动的提醒</span></div><div class="line">      isrChangeSet.clear() <span class="comment">//note: 清空 isrChangeSet,它记录着 isr 变动的 topic-partition 信息</span></div><div class="line">      lastIsrPropagationMs.set(now) <span class="comment">//note: 最近一次触发这个方法的时间</span></div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h2 id="Partition-ISR-变化"><a href="#Partition-ISR-变化" class="headerlink" title="Partition ISR 变化"></a>Partition ISR 变化</h2><p>前面讲述了 ReplicaManager 周期性调度的两个方法：<code>maybeShrinkIsr()</code> 和 <code>maybePropagateIsrChanges()</code> ，其中 <code>maybeShrinkIsr()</code> 是来检查 isr 中是否有 replica 需要从 isr 中移除，也就是说这个方法只会减少 isr 中的副本数，那么 isr 中副本数的增加是在哪里触发的呢？</p>
<p>观察上面流程图的第三部分，ReplicaManager 在处理来自 replica 的 Fetch 请求时，会将 Fetch 的相关信息到更新 Partition 中，Partition 调用 <code>maybeExpandIsr()</code> 方法来判断 isr 是否需要更新。</p>
<p>举一个例子，一个 topic 的 partition 1有三个副本，其中 replica 1 为 leader replica，那么这个副本之间关系图如下所示：</p>
<p><img src="/images/kafka/partition_replica.png" alt="Leader replica 与 follower replica"></p>
<p>简单分析一下上面的图：</p>
<ol>
<li>对于 replica 1 而言，它是 leader，首先 replica 1 有对应的 Log 实例对象，而且它会记录其他远程副本的 LEO，以便更新这个 Partition 的 HW；</li>
<li>对于 replica 2 而言，它是 follower，replica 2 有对应的 Log 实例对象，它只会有本地的 LEO 和 HW 记录，没有其他副本的 LEO 记录。</li>
<li>replica 2 和 replica 3 从 replica 1 上拉取数据，进行数据同步。</li>
</ol>
<p>再来看前面的流程图，ReplicaManager 在 <code>FetchMessages()</code> 方法对来自副本的 Fetch 请求进行处理的，实际上是会更新相应 replica 的 LEO 信息的，这时候 leader 可以根据副本 LEO 信息的变动来判断 这个副本是否满足加入 isr 的条件，下面详细来看下这个过程。</p>
<h3 id="updateFollowerLogReadResults"><a href="#updateFollowerLogReadResults" class="headerlink" title="updateFollowerLogReadResults"></a>updateFollowerLogReadResults</h3><p>在 ReplicaManager 的 <code>FetchMessages()</code> 方法中，如果 Fetch 请求是来自副本，那么会调用 <code>updateFollowerLogReadResults()</code> 更新远程副本的信息，其实现如下：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">updateFollowerLogReadResults</span></span>(replicaId: <span class="type">Int</span>, readResults: <span class="type">Seq</span>[(<span class="type">TopicPartition</span>, <span class="type">LogReadResult</span>)]) &#123;</div><div class="line">  debug(<span class="string">"Recording follower broker %d log read results: %s "</span>.format(replicaId, readResults))</div><div class="line">  readResults.foreach &#123; <span class="keyword">case</span> (topicPartition, readResult) =&gt;</div><div class="line">    getPartition(topicPartition) <span class="keyword">match</span> &#123;</div><div class="line">      <span class="keyword">case</span> <span class="type">Some</span>(partition) =&gt;</div><div class="line">        <span class="comment">//note: 更新副本的相关信息</span></div><div class="line">        partition.updateReplicaLogReadResult(replicaId, readResult)</div><div class="line"></div><div class="line">        <span class="comment">// for producer requests with ack &gt; 1, we need to check</span></div><div class="line">        <span class="comment">// if they can be unblocked after some follower's log end offsets have moved</span></div><div class="line">        tryCompleteDelayedProduce(<span class="keyword">new</span> <span class="type">TopicPartitionOperationKey</span>(topicPartition))</div><div class="line">      <span class="keyword">case</span> <span class="type">None</span> =&gt;</div><div class="line">        warn(<span class="string">"While recording the replica LEO, the partition %s hasn't been created."</span>.format(topicPartition))</div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>这个方法的作用就是找到本节点这个 Partition 对象，然后调用其 <code>updateReplicaLogReadResult()</code> 方法更新副本的 LEO 信息和拉取时间信息。</p>
<h3 id="updateReplicaLogReadResult"><a href="#updateReplicaLogReadResult" class="headerlink" title="updateReplicaLogReadResult"></a>updateReplicaLogReadResult</h3><p>这个方法的实现如下：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//note: 更新这个 partition replica 的 the end offset</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">updateReplicaLogReadResult</span></span>(replicaId: <span class="type">Int</span>, logReadResult: <span class="type">LogReadResult</span>) &#123;</div><div class="line">  getReplica(replicaId) <span class="keyword">match</span> &#123;</div><div class="line">    <span class="keyword">case</span> <span class="type">Some</span>(replica) =&gt;</div><div class="line">      <span class="comment">//note: 更新副本的信息</span></div><div class="line">      replica.updateLogReadResult(logReadResult)</div><div class="line">      <span class="comment">// check if we need to expand ISR to include this replica</span></div><div class="line">      <span class="comment">// if it is not in the ISR yet</span></div><div class="line">      <span class="comment">//note: 如果该副本不在 isr 中,检查是否需要进行更新</span></div><div class="line">      maybeExpandIsr(replicaId, logReadResult)</div><div class="line"></div><div class="line">      debug(<span class="string">"Recorded replica %d log end offset (LEO) position %d for partition %s."</span></div><div class="line">        .format(replicaId, logReadResult.info.fetchOffsetMetadata.messageOffset, topicPartition))</div><div class="line">    <span class="keyword">case</span> <span class="type">None</span> =&gt;</div><div class="line">      <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">NotAssignedReplicaException</span>((<span class="string">"Leader %d failed to record follower %d's position %d since the replica"</span> +</div><div class="line">        <span class="string">" is not recognized to be one of the assigned replicas %s for partition %s."</span>)</div><div class="line">        .format(localBrokerId,</div><div class="line">                replicaId,</div><div class="line">                logReadResult.info.fetchOffsetMetadata.messageOffset,</div><div class="line">                assignedReplicas.map(_.brokerId).mkString(<span class="string">","</span>),</div><div class="line">                topicPartition))</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>这个方法分为以下两步：</p>
<ol>
<li><code>updateLogReadResult()</code>：更新副本的相关信息，这里是更新该副本的 LEO、lastFetchLeaderLogEndOffset 和 lastFetchTimeMs；</li>
<li><code>maybeExpandIsr()</code>：判断 isr 是否需要扩充，即是否有不在 isr 内的副本满足进入 isr 的条件。</li>
</ol>
<h3 id="maybeExpandIsr"><a href="#maybeExpandIsr" class="headerlink" title="maybeExpandIsr"></a>maybeExpandIsr</h3><p><code>maybeExpandIsr()</code> 的实现如下：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//note: 检查当前 Partition 是否需要扩充 ISR, 副本的 LEO 大于等于 hw 的副本将会被添加到 isr 中</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">maybeExpandIsr</span></span>(replicaId: <span class="type">Int</span>, logReadResult: <span class="type">LogReadResult</span>) &#123;</div><div class="line">  <span class="keyword">val</span> leaderHWIncremented = inWriteLock(leaderIsrUpdateLock) &#123;</div><div class="line">    <span class="comment">// check if this replica needs to be added to the ISR</span></div><div class="line">    leaderReplicaIfLocal <span class="keyword">match</span> &#123;</div><div class="line">      <span class="keyword">case</span> <span class="type">Some</span>(leaderReplica) =&gt;</div><div class="line">        <span class="keyword">val</span> replica = getReplica(replicaId).get</div><div class="line">        <span class="keyword">val</span> leaderHW = leaderReplica.highWatermark</div><div class="line">        <span class="keyword">if</span>(!inSyncReplicas.contains(replica) &amp;&amp;</div><div class="line">           assignedReplicas.map(_.brokerId).contains(replicaId) &amp;&amp;</div><div class="line">           replica.logEndOffset.offsetDiff(leaderHW) &gt;= <span class="number">0</span>) &#123; <span class="comment">//note: replica LEO 大于 HW 的情况下,加入 isr 列表</span></div><div class="line">          <span class="keyword">val</span> newInSyncReplicas = inSyncReplicas + replica</div><div class="line">          info(<span class="string">s"Expanding ISR for partition <span class="subst">$topicPartition</span> from <span class="subst">$&#123;inSyncReplicas.map(_.brokerId).mkString(",")&#125;</span> "</span> +</div><div class="line">            <span class="string">s"to <span class="subst">$&#123;newInSyncReplicas.map(_.brokerId).mkString(",")&#125;</span>"</span>)</div><div class="line">          <span class="comment">// update ISR in ZK and cache</span></div><div class="line">          updateIsr(newInSyncReplicas) <span class="comment">//note: 更新到 zk</span></div><div class="line">          replicaManager.isrExpandRate.mark()</div><div class="line">        &#125;</div><div class="line"></div><div class="line">        <span class="comment">// check if the HW of the partition can now be incremented</span></div><div class="line">        <span class="comment">// since the replica may already be in the ISR and its LEO has just incremented</span></div><div class="line">        <span class="comment">//note: 检查 HW 是否需要更新</span></div><div class="line">        maybeIncrementLeaderHW(leaderReplica, logReadResult.fetchTimeMs)</div><div class="line"></div><div class="line">      <span class="keyword">case</span> <span class="type">None</span> =&gt; <span class="literal">false</span> <span class="comment">// nothing to do if no longer leader</span></div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  <span class="comment">// some delayed operations may be unblocked after HW changed</span></div><div class="line">  <span class="keyword">if</span> (leaderHWIncremented)</div><div class="line">    tryCompleteDelayedRequests()</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>这个方法会根据这个 replica 的 LEO 来判断它是否满足进入 ISR 的条件，如果满足的话，就添加到 ISR 中（前提是这个 replica 在 AR：assign replica 中，并且不在 ISR 中），之后再调用 <code>updateIsr()</code> 更新这个 topic-partition 的 isr 信息和更新 HW 信息。</p>
<h2 id="Updata-Metadata-请求的处理"><a href="#Updata-Metadata-请求的处理" class="headerlink" title="Updata-Metadata 请求的处理"></a>Updata-Metadata 请求的处理</h2><p>这里顺便讲述一下 Update-Metadata 请求的处理流程，先看下在 KafkaApis 中对 Update-Metadata 请求的处理流程：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//note: 处理 update-metadata 请求</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">handleUpdateMetadataRequest</span></span>(request: <span class="type">RequestChannel</span>.<span class="type">Request</span>) &#123;</div><div class="line">  <span class="keyword">val</span> correlationId = request.header.correlationId</div><div class="line">  <span class="keyword">val</span> updateMetadataRequest = request.body.asInstanceOf[<span class="type">UpdateMetadataRequest</span>]</div><div class="line"></div><div class="line">  <span class="keyword">val</span> updateMetadataResponse =</div><div class="line">    <span class="keyword">if</span> (authorize(request.session, <span class="type">ClusterAction</span>, <span class="type">Resource</span>.<span class="type">ClusterResource</span>)) &#123;</div><div class="line">      <span class="comment">//note: 更新 metadata, 并返回需要删除的 Partition</span></div><div class="line">      <span class="keyword">val</span> deletedPartitions = replicaManager.maybeUpdateMetadataCache(correlationId, updateMetadataRequest, metadataCache)</div><div class="line">      <span class="keyword">if</span> (deletedPartitions.nonEmpty)</div><div class="line">        coordinator.handleDeletedPartitions(deletedPartitions) <span class="comment">//note: GroupCoordinator 会清除相关 partition 的信息</span></div><div class="line"></div><div class="line">      <span class="keyword">if</span> (adminManager.hasDelayedTopicOperations) &#123;</div><div class="line">        updateMetadataRequest.partitionStates.keySet.asScala.map(_.topic).foreach &#123; topic =&gt;</div><div class="line">          adminManager.tryCompleteDelayedTopicOperations(topic)</div><div class="line">        &#125;</div><div class="line">      &#125;</div><div class="line">      <span class="keyword">new</span> <span class="type">UpdateMetadataResponse</span>(<span class="type">Errors</span>.<span class="type">NONE</span>.code)</div><div class="line">    &#125; <span class="keyword">else</span> &#123;</div><div class="line">      <span class="keyword">new</span> <span class="type">UpdateMetadataResponse</span>(<span class="type">Errors</span>.<span class="type">CLUSTER_AUTHORIZATION_FAILED</span>.code)</div><div class="line">    &#125;</div><div class="line"></div><div class="line">  requestChannel.sendResponse(<span class="keyword">new</span> <span class="type">Response</span>(request, updateMetadataResponse))</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>这个请求的处理还是调用 ReplicaManager 的 <code>maybeUpdateMetadataCache()</code> 方法进行处理的，这个方法会先更新相关的 meta 信息，然后返回需要删除的 topic-partition 信息，GroupCoordinator 再从它的 meta 删除这个 topic-partition 的相关信息。</p>
<h3 id="maybeUpdateMetadataCache"><a href="#maybeUpdateMetadataCache" class="headerlink" title="maybeUpdateMetadataCache"></a>maybeUpdateMetadataCache</h3><p>先看下 ReplicaManager 的 <code>maybeUpdateMetadataCache()</code> 方法实现：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//note: Controller 向所有的 Broker 发送请求,让它们去更新各自的 meta 信息</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">maybeUpdateMetadataCache</span></span>(correlationId: <span class="type">Int</span>, updateMetadataRequest: <span class="type">UpdateMetadataRequest</span>, metadataCache: <span class="type">MetadataCache</span>) : <span class="type">Seq</span>[<span class="type">TopicPartition</span>] =  &#123;</div><div class="line">  replicaStateChangeLock synchronized &#123;</div><div class="line">    <span class="keyword">if</span>(updateMetadataRequest.controllerEpoch &lt; controllerEpoch) &#123; <span class="comment">//note: 来自过期的 controller</span></div><div class="line">      <span class="keyword">val</span> stateControllerEpochErrorMessage = (<span class="string">"Broker %d received update metadata request with correlation id %d from an "</span> +</div><div class="line">        <span class="string">"old controller %d with epoch %d. Latest known controller epoch is %d"</span>).format(localBrokerId,</div><div class="line">        correlationId, updateMetadataRequest.controllerId, updateMetadataRequest.controllerEpoch,</div><div class="line">        controllerEpoch)</div><div class="line">      stateChangeLogger.warn(stateControllerEpochErrorMessage)</div><div class="line">      <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">ControllerMovedException</span>(stateControllerEpochErrorMessage)</div><div class="line">    &#125; <span class="keyword">else</span> &#123;</div><div class="line">      <span class="comment">//note: 更新 metadata 信息,并返回需要删除的 Partition 信息</span></div><div class="line">      <span class="keyword">val</span> deletedPartitions = metadataCache.updateCache(correlationId, updateMetadataRequest)</div><div class="line">      controllerEpoch = updateMetadataRequest.controllerEpoch</div><div class="line">      deletedPartitions</div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>这个方法就是：调用 <code>metadataCache.updateCache()</code> 方法更新 meta 缓存，然后返回需要删除的 topic-partition 列表。</p>
<h3 id="updateCache"><a href="#updateCache" class="headerlink" title="updateCache"></a>updateCache</h3><p>MetadataCache 的 <code>updateCache()</code> 的实现如下：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//note: 更新本地的 meta,并返回要删除的 topic-partition</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">updateCache</span></span>(correlationId: <span class="type">Int</span>, updateMetadataRequest: <span class="type">UpdateMetadataRequest</span>): <span class="type">Seq</span>[<span class="type">TopicPartition</span>] = &#123;</div><div class="line">  inWriteLock(partitionMetadataLock) &#123;</div><div class="line">    controllerId = updateMetadataRequest.controllerId <span class="keyword">match</span> &#123;</div><div class="line">        <span class="keyword">case</span> id <span class="keyword">if</span> id &lt; <span class="number">0</span> =&gt; <span class="type">None</span></div><div class="line">        <span class="keyword">case</span> id =&gt; <span class="type">Some</span>(id)</div><div class="line">      &#125;</div><div class="line">    <span class="comment">//note: 清空 aliveNodes 和 aliveBrokers 记录,并更新成最新的记录</span></div><div class="line">    aliveNodes.clear()</div><div class="line">    aliveBrokers.clear()</div><div class="line">    updateMetadataRequest.liveBrokers.asScala.foreach &#123; broker =&gt;</div><div class="line">      <span class="comment">// `aliveNodes` is a hot path for metadata requests for large clusters, so we use java.util.HashMap which</span></div><div class="line">      <span class="comment">// is a bit faster than scala.collection.mutable.HashMap. When we drop support for Scala 2.10, we could</span></div><div class="line">      <span class="comment">// move to `AnyRefMap`, which has comparable performance.</span></div><div class="line">      <span class="keyword">val</span> nodes = <span class="keyword">new</span> java.util.<span class="type">HashMap</span>[<span class="type">ListenerName</span>, <span class="type">Node</span>]</div><div class="line">      <span class="keyword">val</span> endPoints = <span class="keyword">new</span> mutable.<span class="type">ArrayBuffer</span>[<span class="type">EndPoint</span>]</div><div class="line">      broker.endPoints.asScala.foreach &#123; ep =&gt;</div><div class="line">        endPoints += <span class="type">EndPoint</span>(ep.host, ep.port, ep.listenerName, ep.securityProtocol)</div><div class="line">        nodes.put(ep.listenerName, <span class="keyword">new</span> <span class="type">Node</span>(broker.id, ep.host, ep.port))</div><div class="line">      &#125;</div><div class="line">      aliveBrokers(broker.id) = <span class="type">Broker</span>(broker.id, endPoints, <span class="type">Option</span>(broker.rack))</div><div class="line">      aliveNodes(broker.id) = nodes.asScala</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="keyword">val</span> deletedPartitions = <span class="keyword">new</span> mutable.<span class="type">ArrayBuffer</span>[<span class="type">TopicPartition</span>] <span class="comment">//note:</span></div><div class="line">    updateMetadataRequest.partitionStates.asScala.foreach &#123; <span class="keyword">case</span> (tp, info) =&gt;</div><div class="line">      <span class="keyword">val</span> controllerId = updateMetadataRequest.controllerId</div><div class="line">      <span class="keyword">val</span> controllerEpoch = updateMetadataRequest.controllerEpoch</div><div class="line">      <span class="keyword">if</span> (info.leader == <span class="type">LeaderAndIsr</span>.<span class="type">LeaderDuringDelete</span>) &#123; <span class="comment">//note: partition 被标记为了删除</span></div><div class="line">        removePartitionInfo(tp.topic, tp.partition) <span class="comment">//note: 从 cache 中删除</span></div><div class="line">        stateChangeLogger.trace(<span class="string">s"Broker <span class="subst">$brokerId</span> deleted partition <span class="subst">$tp</span> from metadata cache in response to UpdateMetadata "</span> +</div><div class="line">          <span class="string">s"request sent by controller <span class="subst">$controllerId</span> epoch <span class="subst">$controllerEpoch</span> with correlation id <span class="subst">$correlationId</span>"</span>)</div><div class="line">        deletedPartitions += tp</div><div class="line">      &#125; <span class="keyword">else</span> &#123;<span class="comment">//note: 更新</span></div><div class="line">        <span class="keyword">val</span> partitionInfo = partitionStateToPartitionStateInfo(info)</div><div class="line">        addOrUpdatePartitionInfo(tp.topic, tp.partition, partitionInfo) <span class="comment">//note: 更新 topic-partition meta</span></div><div class="line">        stateChangeLogger.trace(<span class="string">s"Broker <span class="subst">$brokerId</span> cached leader info <span class="subst">$partitionInfo</span> for partition <span class="subst">$tp</span> in response to "</span> +</div><div class="line">          <span class="string">s"UpdateMetadata request sent by controller <span class="subst">$controllerId</span> epoch <span class="subst">$controllerEpoch</span> with correlation id <span class="subst">$correlationId</span>"</span>)</div><div class="line">      &#125;</div><div class="line">    &#125;</div><div class="line">    deletedPartitions</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>它的处理流程如下：</p>
<ol>
<li>清空本节点的 aliveNodes 和 aliveBrokers 记录，并更新为最新的记录；</li>
<li>对于要删除的 topic-partition，从缓存中删除，并记录下来作为这个方法的返回；</li>
<li>对于其他的 topic-partition，执行 updateOrCreate 操作。</li>
</ol>
<p>到这里 ReplicaManager 算是讲述完了，Kafka 存储层的内容基本也介绍完了，后面会开始讲述 Kafka Controller 部分的内容，争取这部分能够在一个半月内总结完。</p>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[Kafka 源码解析之副本同步机制实现（十四）]]></title>
      <url>http://matt33.com/2018/04/29/kafka-replica-fetcher-thread/</url>
      <content type="html"><![CDATA[<p>在上篇文章中讲述了 Fetch 请求是如何处理的，其中包括来自副本同步的 Fetch 请求和 Consumer 的 Fetch 请求，副本同步是 Kafka 多副本机制（可靠性）实现的基础，它也是通过向 leader replica 发送 Fetch 请求来实现数据同步的。本篇文章我们就来看一下 Kafka 副本同步这块的内容，对于每个 broker 来说，它上面的 replica 对象，除了 leader 就是 follower，只要这台 broker 有 follower replica，broker 就会启动副本同步流程从 leader 同步数据，副本同步机制的实现是 Kafka Server 端非常重要的内容，在这篇文章中，主要会从以下几块来讲解：</p>
<ol>
<li>Kafka 在什么情况下会启动副本同步线程？</li>
<li>Kafka 副本同步线程启动流程及付副本同步流程的处理逻辑；</li>
<li>Kafka 副本同步需要解决的问题以及 Kafka 是如何解决这些问题的？</li>
<li>Kafka 在什么情况下会关闭一个副本同步线程。</li>
</ol>
<blockquote>
<p>小插曲：本来想先介绍一下与 LeaderAndIsr 请求相关的，因为副本同步线程的启动与这部分是息息相关的，但是发现涉及到了很多 controller 端的内容，而 controller 这部分还没开始涉及，所以本篇文章涉及到 LeaderAndIsr 请求的部分先简单讲述一下其处理逻辑，在 controller 这块再详细介绍。</p>
</blockquote>
<h2 id="整体流程"><a href="#整体流程" class="headerlink" title="整体流程"></a>整体流程</h2><p>Kafka Server 端的副本同步，是由 replica fetcher 线程来负责的，而它又是由 ReplicaManager 来控制的。关于 ReplicaManger，不知道大家还记不记得在 <a href="http://matt33.com/2018/03/18/kafka-server-handle-produce-request/">Kafka 源码解析之 Server 端如何处理 Produce 请求（十二）</a> 有一个简单的表格，如下所示。ReplicaManager 通过对 Partition 对象的管理，来控制着 Partition 对应的 Replica 实例，而 Replica 实例又是通过 Log 对象实例来管理着其底层的存储内容。</p>
<table>
<thead>
<tr>
<th></th>
<th>管理对象</th>
<th>组成部分</th>
</tr>
</thead>
<tbody>
<tr>
<td>日志管理器（LogManager）</td>
<td>日志（Log）</td>
<td>日志分段（LogSegment）</td>
</tr>
<tr>
<td>副本管理器（ReplicaManager）</td>
<td>分区（Partition）</td>
<td>副本（Replica）</td>
</tr>
</tbody>
</table>
<p>关于 ReplicaManager 的内容准备专门写一篇文章来介绍，刚好也作为对 Kafka 存储层内容的一个总结。</p>
<p>下面回到这篇文章的主题 —— 副本同步机制，在 ReplicaManager 中有一个实例变量 <code>replicaFetcherManager</code>，它负责管理所有副本同步线程，副本同步线程的启动和关闭都是由这个实例来操作的，关于副本同步相关处理逻辑，下面这张图可以作为一个整体流程，包括了 replica fetcher 线程的启动、工作流程、关闭三个部分，如下图所示：</p>
<p><img src="/images/kafka/fetcher_thread.png" alt="副本同步机制"></p>
<p>后面的讲述会围绕着这张图开始，这里看不懂或不理解也没有关系，后面会一一讲解。</p>
<h2 id="replica-fetcher-线程何时启动"><a href="#replica-fetcher-线程何时启动" class="headerlink" title="replica fetcher 线程何时启动"></a>replica fetcher 线程何时启动</h2><p>Broker 会在什么情况下启动副本同步线程呢？简单想一下这部分的逻辑：首先 broker 分配的任何一个 partition 都是以 Replica 对象实例的形式存在，而 Replica 在 Kafka 上是有两个角色： leader 和 follower，只要这个 Replica 是 follower，它便会向 leader 进行数据同步。</p>
<p>反应在 ReplicaManager 上就是如果 Broker 的本地副本被选举为 follower，那么它将会启动副本同步线程，其具体实现如下所示：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div><div class="line">113</div><div class="line">114</div><div class="line">115</div><div class="line">116</div><div class="line">117</div><div class="line">118</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//note: 对于给定的这些副本，将本地副本设置为 follower</span></div><div class="line"><span class="comment">//note: 1. 从 leader partition 集合移除这些 partition；</span></div><div class="line"><span class="comment">//note: 2. 将这些 partition 标记为 follower，之后这些 partition 就不会再接收 produce 的请求了；</span></div><div class="line"><span class="comment">//note: 3. 停止对这些 partition 的副本同步，这样这些副本就不会再有（来自副本请求线程）的数据进行追加了；</span></div><div class="line"><span class="comment">//note: 4. 对这些 partition 的 offset 进行 checkpoint，如果日志需要截断就进行截断操作；</span></div><div class="line"><span class="comment">//note: 5. 清空 purgatory 中的 produce 和 fetch 请求；</span></div><div class="line"><span class="comment">//note: 6. 如果 broker 没有掉线，向这些 partition 的新 leader 启动副本同步线程；</span></div><div class="line"><span class="comment">//note: 上面这些操作的顺序性，保证了这些副本在 offset checkpoint 之前将不会接收新的数据，这样的话，在 checkpoint 之前这些数据都可以保证刷到磁盘</span></div><div class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">makeFollowers</span></span>(controllerId: <span class="type">Int</span>,</div><div class="line">                          epoch: <span class="type">Int</span>,</div><div class="line">                          partitionState: <span class="type">Map</span>[<span class="type">Partition</span>, <span class="type">PartitionState</span>],</div><div class="line">                          correlationId: <span class="type">Int</span>,</div><div class="line">                          responseMap: mutable.<span class="type">Map</span>[<span class="type">TopicPartition</span>, <span class="type">Short</span>],</div><div class="line">                          metadataCache: <span class="type">MetadataCache</span>) : <span class="type">Set</span>[<span class="type">Partition</span>] = &#123;</div><div class="line">  partitionState.keys.foreach &#123; partition =&gt;</div><div class="line">    stateChangeLogger.trace((<span class="string">"Broker %d handling LeaderAndIsr request correlationId %d from controller %d epoch %d "</span> +</div><div class="line">      <span class="string">"starting the become-follower transition for partition %s"</span>)</div><div class="line">      .format(localBrokerId, correlationId, controllerId, epoch, partition.topicPartition))</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  <span class="keyword">for</span> (partition &lt;- partitionState.keys)</div><div class="line">    responseMap.put(partition.topicPartition, <span class="type">Errors</span>.<span class="type">NONE</span>.code)</div><div class="line"></div><div class="line">  <span class="comment">//note: 统计 follower 的集合</span></div><div class="line">  <span class="keyword">val</span> partitionsToMakeFollower: mutable.<span class="type">Set</span>[<span class="type">Partition</span>] = mutable.<span class="type">Set</span>()</div><div class="line"></div><div class="line">  <span class="keyword">try</span> &#123;</div><div class="line"></div><div class="line">    <span class="comment">// <span class="doctag">TODO:</span> Delete leaders from LeaderAndIsrRequest</span></div><div class="line">    partitionState.foreach&#123; <span class="keyword">case</span> (partition, partitionStateInfo) =&gt;</div><div class="line">      <span class="keyword">val</span> newLeaderBrokerId = partitionStateInfo.leader</div><div class="line">      metadataCache.getAliveBrokers.find(_.id == newLeaderBrokerId) <span class="keyword">match</span> &#123; <span class="comment">//note: leader 是可用的</span></div><div class="line">        <span class="comment">// Only change partition state when the leader is available</span></div><div class="line">        <span class="keyword">case</span> <span class="type">Some</span>(_) =&gt; <span class="comment">//note: partition 的本地副本设置为 follower</span></div><div class="line">          <span class="keyword">if</span> (partition.makeFollower(controllerId, partitionStateInfo, correlationId))</div><div class="line">            partitionsToMakeFollower += partition</div><div class="line">          <span class="keyword">else</span> <span class="comment">//note: 这个 partition 的本地副本已经是 follower 了</span></div><div class="line">            stateChangeLogger.info((<span class="string">"Broker %d skipped the become-follower state change after marking its partition as follower with correlation id %d from "</span> +</div><div class="line">              <span class="string">"controller %d epoch %d for partition %s since the new leader %d is the same as the old leader"</span>)</div><div class="line">              .format(localBrokerId, correlationId, controllerId, partitionStateInfo.controllerEpoch,</div><div class="line">              partition.topicPartition, newLeaderBrokerId))</div><div class="line">        <span class="keyword">case</span> <span class="type">None</span> =&gt;</div><div class="line">          <span class="comment">// The leader broker should always be present in the metadata cache.</span></div><div class="line">          <span class="comment">// If not, we should record the error message and abort the transition process for this partition</span></div><div class="line">          stateChangeLogger.error((<span class="string">"Broker %d received LeaderAndIsrRequest with correlation id %d from controller"</span> +</div><div class="line">            <span class="string">" %d epoch %d for partition %s but cannot become follower since the new leader %d is unavailable."</span>)</div><div class="line">            .format(localBrokerId, correlationId, controllerId, partitionStateInfo.controllerEpoch,</div><div class="line">            partition.topicPartition, newLeaderBrokerId))</div><div class="line">          <span class="comment">// Create the local replica even if the leader is unavailable. This is required to ensure that we include</span></div><div class="line">          <span class="comment">// the partition's high watermark in the checkpoint file (see KAFKA-1647)</span></div><div class="line">          partition.getOrCreateReplica()</div><div class="line">      &#125;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="comment">//note: 删除对这些 partition 的副本同步线程</span></div><div class="line">    replicaFetcherManager.removeFetcherForPartitions(partitionsToMakeFollower.map(_.topicPartition))</div><div class="line">    partitionsToMakeFollower.foreach &#123; partition =&gt;</div><div class="line">      stateChangeLogger.trace((<span class="string">"Broker %d stopped fetchers as part of become-follower request from controller "</span> +</div><div class="line">        <span class="string">"%d epoch %d with correlation id %d for partition %s"</span>)</div><div class="line">        .format(localBrokerId, controllerId, epoch, correlationId, partition.topicPartition))</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="comment">//note: Truncate the partition logs to the specified offsets and checkpoint the recovery point to this offset</span></div><div class="line">    logManager.truncateTo(partitionsToMakeFollower.map &#123; partition =&gt;</div><div class="line">      (partition.topicPartition, partition.getOrCreateReplica().highWatermark.messageOffset)</div><div class="line">    &#125;.toMap)</div><div class="line">    <span class="comment">//note: 完成那些延迟请求的处理</span></div><div class="line">    partitionsToMakeFollower.foreach &#123; partition =&gt;</div><div class="line">      <span class="keyword">val</span> topicPartitionOperationKey = <span class="keyword">new</span> <span class="type">TopicPartitionOperationKey</span>(partition.topicPartition)</div><div class="line">      tryCompleteDelayedProduce(topicPartitionOperationKey)</div><div class="line">      tryCompleteDelayedFetch(topicPartitionOperationKey)</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    partitionsToMakeFollower.foreach &#123; partition =&gt;</div><div class="line">      stateChangeLogger.trace((<span class="string">"Broker %d truncated logs and checkpointed recovery boundaries for partition %s as part of "</span> +</div><div class="line">        <span class="string">"become-follower request with correlation id %d from controller %d epoch %d"</span>).format(localBrokerId,</div><div class="line">        partition.topicPartition, correlationId, controllerId, epoch))</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="keyword">if</span> (isShuttingDown.get()) &#123;</div><div class="line">      partitionsToMakeFollower.foreach &#123; partition =&gt;</div><div class="line">        stateChangeLogger.trace((<span class="string">"Broker %d skipped the adding-fetcher step of the become-follower state change with correlation id %d from "</span> +</div><div class="line">          <span class="string">"controller %d epoch %d for partition %s since it is shutting down"</span>).format(localBrokerId, correlationId,</div><div class="line">          controllerId, epoch, partition.topicPartition))</div><div class="line">      &#125;</div><div class="line">    &#125;</div><div class="line">    <span class="keyword">else</span> &#123;</div><div class="line">      <span class="comment">// we do not need to check if the leader exists again since this has been done at the beginning of this process</span></div><div class="line">      <span class="comment">//note: 启动副本同步线程</span></div><div class="line">      <span class="keyword">val</span> partitionsToMakeFollowerWithLeaderAndOffset = partitionsToMakeFollower.map(partition =&gt;</div><div class="line">        partition.topicPartition -&gt; <span class="type">BrokerAndInitialOffset</span>(</div><div class="line">          metadataCache.getAliveBrokers.find(_.id == partition.leaderReplicaIdOpt.get).get.getBrokerEndPoint(config.interBrokerListenerName),</div><div class="line">          partition.getReplica().get.logEndOffset.messageOffset)).toMap <span class="comment">//note: leader 信息+本地 replica 的 offset</span></div><div class="line">      replicaFetcherManager.addFetcherForPartitions(partitionsToMakeFollowerWithLeaderAndOffset)</div><div class="line"></div><div class="line">      partitionsToMakeFollower.foreach &#123; partition =&gt;</div><div class="line">        stateChangeLogger.trace((<span class="string">"Broker %d started fetcher to new leader as part of become-follower request from controller "</span> +</div><div class="line">          <span class="string">"%d epoch %d with correlation id %d for partition %s"</span>)</div><div class="line">          .format(localBrokerId, controllerId, epoch, correlationId, partition.topicPartition))</div><div class="line">      &#125;</div><div class="line">    &#125;</div><div class="line">  &#125; <span class="keyword">catch</span> &#123;</div><div class="line">    <span class="keyword">case</span> e: <span class="type">Throwable</span> =&gt;</div><div class="line">      <span class="keyword">val</span> errorMsg = (<span class="string">"Error on broker %d while processing LeaderAndIsr request with correlationId %d received from controller %d "</span> +</div><div class="line">        <span class="string">"epoch %d"</span>).format(localBrokerId, correlationId, controllerId, epoch)</div><div class="line">      stateChangeLogger.error(errorMsg, e)</div><div class="line">      <span class="comment">// Re-throw the exception for it to be caught in KafkaApis</span></div><div class="line">      <span class="keyword">throw</span> e</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  partitionState.keys.foreach &#123; partition =&gt;</div><div class="line">    stateChangeLogger.trace((<span class="string">"Broker %d completed LeaderAndIsr request correlationId %d from controller %d epoch %d "</span> +</div><div class="line">      <span class="string">"for the become-follower transition for partition %s"</span>)</div><div class="line">      .format(localBrokerId, correlationId, controllerId, epoch, partition.topicPartition))</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  partitionsToMakeFollower</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>简单来说，<code>makeFollowers()</code> 的处理过程如下：</p>
<ol>
<li>先从本地记录 leader partition 的集合中将这些 partition 移除，因为这些 partition 已经被选举为了 follower；</li>
<li>将这些 partition 的本地副本设置为 follower，后面就不会接收关于这个 partition 的 Produce 请求了，如果依然有 client 在向这台 broker 发送数据，那么它将会返回相应的错误；</li>
<li>先停止关于这些 partition 的副本同步线程（如果本地副本之前是 follower 现在还是 follower，先关闭的原因是：这个 partition 的 leader 发生了变化，如果 leader 没有发生变化，那么 <code>makeFollower</code> 方法返回的是 False，这个 Partition 就不会被添加到 partitionsToMakeFollower 集合中），这样的话可以保证这些 partition 的本地副本将不会再有新的数据追加；</li>
<li>对这些 partition 本地副本日志文件进行截断操作并进行 checkpoint 操作；</li>
<li>完成那些延迟处理的 Produce 和 Fetch 请求；</li>
<li>如果本地的 broker 没有掉线，那么向这些 partition 新选举出来的 leader 启动副本同步线程。</li>
</ol>
<p>关于第6步，并不一定会为每一个 partition 都启动一个 fetcher 线程，对于一个目的 broker，只会启动 <code>num.replica.fetchers</code> 个线程，具体这个 topic-partition 会分配到哪个 fetcher 线程上，是根据 topic 名和 partition id 进行计算得到，实现所示：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//note: 获取分配到这个 topic-partition 的 fetcher 线程 id</span></div><div class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">getFetcherId</span></span>(topic: <span class="type">String</span>, partitionId: <span class="type">Int</span>) : <span class="type">Int</span> = &#123;</div><div class="line">  <span class="type">Utils</span>.abs(<span class="number">31</span> * topic.hashCode() + partitionId) % numFetchers</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h3 id="replica-fetcher-线程参数设置"><a href="#replica-fetcher-线程参数设置" class="headerlink" title="replica fetcher 线程参数设置"></a>replica fetcher 线程参数设置</h3><p>关于副本同步线程有一些参数配置，具体如下表所示：</p>
<table>
<thead>
<tr>
<th>参数</th>
<th>说明</th>
<th>默认值</th>
</tr>
</thead>
<tbody>
<tr>
<td>num.replica.fetchers</td>
<td>从一个 broker 同步数据的 fetcher 线程数，增加这个值时也会增加该 broker 的 Io 并行度（也就是说：从一台 broker 同步数据，最多能开这么大的线程数）</td>
<td>1</td>
</tr>
<tr>
<td>replica.fetch.wait.max.ms</td>
<td>对于 follower replica 而言，每个 Fetch 请求的最大等待时间，这个值应该比 <code>replica.lag.time.max.ms</code> 要小，否则对于那些吞吐量特别低的 topic 可能会导致 isr 频繁抖动</td>
<td>500</td>
</tr>
<tr>
<td>replica.high.watermark.checkpoint.interval.ms</td>
<td>hw 刷到磁盘频率</td>
<td>500</td>
</tr>
<tr>
<td>replica.lag.time.max.ms</td>
<td>如果一个 follower 在这个时间内没有发送任何 fetch 请求或者在这个时间内没有追上 leader 当前的 log end offset，那么将会从 isr 中移除</td>
<td>10000</td>
</tr>
<tr>
<td>replica.fetch.min.bytes</td>
<td>每次 fetch 请求最少拉取的数据量，如果不满足这个条件，那么要等待 replicaMaxWaitTimeMs</td>
<td>1</td>
</tr>
<tr>
<td>replica.fetch.backoff.ms</td>
<td>拉取时，如果遇到错误，下次拉取等待的时间</td>
<td>1000</td>
</tr>
<tr>
<td>replica.fetch.max.bytes</td>
<td>在对每个 partition 拉取时，最大的拉取数量，这并不是一个绝对值，如果拉取的第一条 msg 的大小超过了这个值，只要不超过这个 topic 设置（defined via message.max.bytes (broker config) or max.message.bytes (topic config)）的单条大小限制，依然会返回。</td>
<td>1048576</td>
</tr>
<tr>
<td>replica.fetch.response.max.bytes</td>
<td>对于一个 fetch 请求，返回的最大数据量（可能会涉及多个 partition），这并不是一个绝对值，如果拉取的第一条 msg 的大小超过了这个值，只要不超过这个 topic 设置（defined via message.max.bytes (broker config) or max.message.bytes (topic config)）的单条大小限制，依然会返回。</td>
<td>10MB</td>
</tr>
</tbody>
</table>
<h2 id="replica-fetcher-线程启动"><a href="#replica-fetcher-线程启动" class="headerlink" title="replica fetcher 线程启动"></a>replica fetcher 线程启动</h2><p>如上面的图所示，在 ReplicaManager 调用 <code>makeFollowers()</code> 启动 replica fetcher 线程后，它实际上是通过 ReplicaFetcherManager 实例进行相关 topic-partition 同步线程的启动和关闭，其启动过程分为下面两步：</p>
<ol>
<li>ReplicaFetcherManager 调用 <code>addFetcherForPartitions()</code> 添加对这些 topic-partition 的数据同步流程；</li>
<li>ReplicaFetcherManager 调用 <code>createFetcherThread()</code> 初始化相应的 ReplicaFetcherThread 线程。</li>
</ol>
<h3 id="addFetcherForPartitions"><a href="#addFetcherForPartitions" class="headerlink" title="addFetcherForPartitions"></a>addFetcherForPartitions</h3><p><code>addFetcherForPartitions()</code> 的具体实现如下所示：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//note: 为一个 topic-partition 添加 replica-fetch 线程</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">addFetcherForPartitions</span></span>(partitionAndOffsets: <span class="type">Map</span>[<span class="type">TopicPartition</span>, <span class="type">BrokerAndInitialOffset</span>]) &#123;</div><div class="line">  mapLock synchronized &#123;</div><div class="line">    <span class="comment">//note: 为这些 topic-partition 分配相应的 fetch 线程 id</span></div><div class="line">    <span class="keyword">val</span> partitionsPerFetcher = partitionAndOffsets.groupBy &#123; <span class="keyword">case</span>(topicPartition, brokerAndInitialOffset) =&gt;</div><div class="line">      <span class="type">BrokerAndFetcherId</span>(brokerAndInitialOffset.broker, getFetcherId(topicPartition.topic, topicPartition.partition))&#125;</div><div class="line">    <span class="keyword">for</span> ((brokerAndFetcherId, partitionAndOffsets) &lt;- partitionsPerFetcher) &#123;</div><div class="line">      <span class="comment">//note: 为 BrokerAndFetcherId 构造 fetcherThread 线程</span></div><div class="line">      <span class="keyword">var</span> fetcherThread: <span class="type">AbstractFetcherThread</span> = <span class="literal">null</span></div><div class="line">      fetcherThreadMap.get(brokerAndFetcherId) <span class="keyword">match</span> &#123;</div><div class="line">        <span class="keyword">case</span> <span class="type">Some</span>(f) =&gt; fetcherThread = f</div><div class="line">        <span class="keyword">case</span> <span class="type">None</span> =&gt;</div><div class="line">          <span class="comment">//note: 创建 fetcher 线程</span></div><div class="line">          fetcherThread = createFetcherThread(brokerAndFetcherId.fetcherId, brokerAndFetcherId.broker)</div><div class="line">          fetcherThreadMap.put(brokerAndFetcherId, fetcherThread)</div><div class="line">          fetcherThread.start</div><div class="line">      &#125;</div><div class="line"></div><div class="line">      <span class="comment">//note: 添加 topic-partition 列表</span></div><div class="line">      fetcherThreadMap(brokerAndFetcherId).addPartitions(partitionAndOffsets.map &#123; <span class="keyword">case</span> (tp, brokerAndInitOffset) =&gt;</div><div class="line">        tp -&gt; brokerAndInitOffset.initOffset</div><div class="line">      &#125;)</div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  info(<span class="string">"Added fetcher for partitions %s"</span>.format(partitionAndOffsets.map &#123; <span class="keyword">case</span> (topicPartition, brokerAndInitialOffset) =&gt;</div><div class="line">    <span class="string">"["</span> + topicPartition + <span class="string">", initOffset "</span> + brokerAndInitialOffset.initOffset + <span class="string">" to broker "</span> + brokerAndInitialOffset.broker + <span class="string">"] "</span>&#125;))</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>这个方法其实是做了下面这几件事：</p>
<ol>
<li>先计算这个 topic-partition 对应的 fetcher id；</li>
<li>根据 leader 和 fetcher id 获取对应的 replica fetcher 线程，如果没有找到，就调用 <code>createFetcherThread()</code> 创建一个新的 fetcher 线程；</li>
<li>如果是新启动的 replica fetcher 线程，那么就启动这个线程；</li>
<li>将 topic-partition 记录到 <code>fetcherThreadMap</code> 中，这个变量记录每个 replica fetcher 线程要同步的 topic-partition 列表。</li>
</ol>
<h3 id="createFetcherThread"><a href="#createFetcherThread" class="headerlink" title="createFetcherThread"></a>createFetcherThread</h3><p>ReplicaFetcherManager 创建 replica Fetcher 线程的实现如下：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//note: 创建 replica-fetch 线程</span></div><div class="line"><span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">createFetcherThread</span></span>(fetcherId: <span class="type">Int</span>, sourceBroker: <span class="type">BrokerEndPoint</span>): <span class="type">AbstractFetcherThread</span> = &#123;</div><div class="line">  <span class="keyword">val</span> threadName = threadNamePrefix <span class="keyword">match</span> &#123;</div><div class="line">    <span class="keyword">case</span> <span class="type">None</span> =&gt;</div><div class="line">      <span class="string">"ReplicaFetcherThread-%d-%d"</span>.format(fetcherId, sourceBroker.id)</div><div class="line">    <span class="keyword">case</span> <span class="type">Some</span>(p) =&gt;</div><div class="line">      <span class="string">"%s:ReplicaFetcherThread-%d-%d"</span>.format(p, fetcherId, sourceBroker.id)</div><div class="line">  &#125;</div><div class="line">  <span class="keyword">new</span> <span class="type">ReplicaFetcherThread</span>(threadName, fetcherId, sourceBroker, brokerConfig,</div><div class="line">    replicaMgr, metrics, time, quotaManager) <span class="comment">//note: replica-fetch 线程</span></div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h2 id="replica-fetcher-线程处理过程"><a href="#replica-fetcher-线程处理过程" class="headerlink" title="replica fetcher 线程处理过程"></a>replica fetcher 线程处理过程</h2><p>replica fetcher 线程在启动之后就开始进行正常数据同步流程了，在文章最开始流程图中的第二部分（线程处理过程）已经给出了大概的处理过程，这节会详细介绍一下，这个过程都是在 ReplicaFetcherThread 线程中实现的。</p>
<h3 id="doWoker"><a href="#doWoker" class="headerlink" title="doWoker"></a>doWoker</h3><p>ReplicaFetcherThread 的 <code>doWork()</code> 方法是一直在这个线程中的 <code>run()</code> 中调用的，实现方法如下：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">run</span></span>(): <span class="type">Unit</span> = &#123;</div><div class="line">  info(<span class="string">"Starting "</span>)</div><div class="line">  <span class="keyword">try</span>&#123;</div><div class="line">    <span class="keyword">while</span>(isRunning.get())&#123;</div><div class="line">      doWork()</div><div class="line">    &#125;</div><div class="line">  &#125; <span class="keyword">catch</span>&#123;</div><div class="line">    <span class="keyword">case</span> e: <span class="type">Throwable</span> =&gt;</div><div class="line">      <span class="keyword">if</span>(isRunning.get())</div><div class="line">        error(<span class="string">"Error due to "</span>, e)</div><div class="line">  &#125;</div><div class="line">  shutdownLatch.countDown()</div><div class="line">  info(<span class="string">"Stopped "</span>)</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">doWork</span></span>() &#123;</div><div class="line">  <span class="comment">//note: 构造 fetch request</span></div><div class="line">  <span class="keyword">val</span> fetchRequest = inLock(partitionMapLock) &#123;</div><div class="line">    <span class="keyword">val</span> fetchRequest = buildFetchRequest(partitionStates.partitionStates.asScala.map &#123; state =&gt;</div><div class="line">      state.topicPartition -&gt; state.value</div><div class="line">    &#125;)</div><div class="line">    <span class="keyword">if</span> (fetchRequest.isEmpty) &#123; <span class="comment">//note: 如果没有活跃的 partition，在下次调用之前，sleep fetchBackOffMs 时间</span></div><div class="line">      trace(<span class="string">"There are no active partitions. Back off for %d ms before sending a fetch request"</span>.format(fetchBackOffMs))</div><div class="line">      partitionMapCond.await(fetchBackOffMs, <span class="type">TimeUnit</span>.<span class="type">MILLISECONDS</span>)</div><div class="line">    &#125;</div><div class="line">    fetchRequest</div><div class="line">  &#125;</div><div class="line">  <span class="keyword">if</span> (!fetchRequest.isEmpty)</div><div class="line">    processFetchRequest(fetchRequest) <span class="comment">//note: 发送 fetch 请求，处理 fetch 的结果</span></div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>在 <code>doWork()</code> 方法中主要做了两件事：</p>
<ol>
<li>构造相应的 Fetch 请求（<code>buildFetchRequest()</code>）；</li>
<li>通过 <code>processFetchRequest()</code> 方法发送 Fetch 请求，并对其结果进行相应的处理。</li>
</ol>
<h3 id="buildFetchRequest"><a href="#buildFetchRequest" class="headerlink" title="buildFetchRequest"></a>buildFetchRequest</h3><p>通过 <code>buildFetchRequest()</code> 方法构造相应的 Fetcher 请求时，会设置 replicaId，该值会代表了这个 Fetch 请求是来自副本同步，而不是来自 consumer。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//note: 构造 Fetch 请求</span></div><div class="line"><span class="keyword">protected</span> <span class="function"><span class="keyword">def</span> <span class="title">buildFetchRequest</span></span>(partitionMap: <span class="type">Seq</span>[(<span class="type">TopicPartition</span>, <span class="type">PartitionFetchState</span>)]): <span class="type">FetchRequest</span> = &#123;</div><div class="line">  <span class="keyword">val</span> requestMap = <span class="keyword">new</span> util.<span class="type">LinkedHashMap</span>[<span class="type">TopicPartition</span>, <span class="type">JFetchRequest</span>.<span class="type">PartitionData</span>]</div><div class="line"></div><div class="line">  partitionMap.foreach &#123; <span class="keyword">case</span> (topicPartition, partitionFetchState) =&gt;</div><div class="line">    <span class="comment">// We will not include a replica in the fetch request if it should be throttled.</span></div><div class="line">    <span class="keyword">if</span> (partitionFetchState.isActive &amp;&amp; !shouldFollowerThrottle(quota, topicPartition))</div><div class="line">      requestMap.put(topicPartition, <span class="keyword">new</span> <span class="type">JFetchRequest</span>.<span class="type">PartitionData</span>(partitionFetchState.offset, fetchSize))</div><div class="line">  &#125;</div><div class="line">  <span class="comment">//note: 关键在于 setReplicaId 方法,设置了 replicaId, 对于 consumer, 该值为 CONSUMER_REPLICA_ID（-1）</span></div><div class="line">  <span class="keyword">val</span> requestBuilder = <span class="keyword">new</span> <span class="type">JFetchRequest</span>.<span class="type">Builder</span>(maxWait, minBytes, requestMap).</div><div class="line">      setReplicaId(replicaId).setMaxBytes(maxBytes)</div><div class="line">  requestBuilder.setVersion(fetchRequestVersion)</div><div class="line">  <span class="keyword">new</span> <span class="type">FetchRequest</span>(requestBuilder)</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h3 id="processFetchRequest"><a href="#processFetchRequest" class="headerlink" title="processFetchRequest"></a>processFetchRequest</h3><p><code>processFetchRequest()</code> 这个方法的作用是发送 Fetch 请求，并对返回的结果进行处理，最终写入到本地副本的 Log 实例中，其具体实现：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">processFetchRequest</span></span>(fetchRequest: <span class="type">REQ</span>) &#123;</div><div class="line">  <span class="keyword">val</span> partitionsWithError = mutable.<span class="type">Set</span>[<span class="type">TopicPartition</span>]()</div><div class="line"></div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">updatePartitionsWithError</span></span>(partition: <span class="type">TopicPartition</span>): <span class="type">Unit</span> = &#123;</div><div class="line">    partitionsWithError += partition</div><div class="line">    partitionStates.moveToEnd(partition)</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  <span class="keyword">var</span> responseData: <span class="type">Seq</span>[(<span class="type">TopicPartition</span>, <span class="type">PD</span>)] = <span class="type">Seq</span>.empty</div><div class="line"></div><div class="line">  <span class="keyword">try</span> &#123;</div><div class="line">    trace(<span class="string">"Issuing to broker %d of fetch request %s"</span>.format(sourceBroker.id, fetchRequest))</div><div class="line">    responseData = fetch(fetchRequest) <span class="comment">//note: 发送 fetch 请求，获取 fetch 结果</span></div><div class="line">  &#125; <span class="keyword">catch</span> &#123;</div><div class="line">    <span class="keyword">case</span> t: <span class="type">Throwable</span> =&gt;</div><div class="line">      <span class="keyword">if</span> (isRunning.get) &#123;</div><div class="line">        warn(<span class="string">s"Error in fetch <span class="subst">$fetchRequest</span>"</span>, t)</div><div class="line">        inLock(partitionMapLock) &#123; <span class="comment">//note: fetch 时发生错误，sleep 一会</span></div><div class="line">          partitionStates.partitionSet.asScala.foreach(updatePartitionsWithError)</div><div class="line">          <span class="comment">// there is an error occurred while fetching partitions, sleep a while</span></div><div class="line">          <span class="comment">// note that `ReplicaFetcherThread.handlePartitionsWithError` will also introduce the same delay for every</span></div><div class="line">          <span class="comment">// partition with error effectively doubling the delay. It would be good to improve this.</span></div><div class="line">          partitionMapCond.await(fetchBackOffMs, <span class="type">TimeUnit</span>.<span class="type">MILLISECONDS</span>)</div><div class="line">        &#125;</div><div class="line">      &#125;</div><div class="line">  &#125;</div><div class="line">  fetcherStats.requestRate.mark()</div><div class="line"></div><div class="line">  <span class="keyword">if</span> (responseData.nonEmpty) &#123; <span class="comment">//note: fetch 结果不为空</span></div><div class="line">    <span class="comment">// process fetched data</span></div><div class="line">    inLock(partitionMapLock) &#123;</div><div class="line"></div><div class="line">      responseData.foreach &#123; <span class="keyword">case</span> (topicPartition, partitionData) =&gt;</div><div class="line">        <span class="keyword">val</span> topic = topicPartition.topic</div><div class="line">        <span class="keyword">val</span> partitionId = topicPartition.partition</div><div class="line">        <span class="type">Option</span>(partitionStates.stateValue(topicPartition)).foreach(currentPartitionFetchState =&gt;</div><div class="line">          <span class="comment">// we append to the log if the current offset is defined and it is the same as the offset requested during fetch</span></div><div class="line">          <span class="comment">//note: 如果 fetch 的 offset 与返回结果的 offset 相同，并且返回没有异常，那么就将拉取的数据追加到对应的 partition 上</span></div><div class="line">          <span class="keyword">if</span> (fetchRequest.offset(topicPartition) == currentPartitionFetchState.offset) &#123;</div><div class="line">            <span class="type">Errors</span>.forCode(partitionData.errorCode) <span class="keyword">match</span> &#123;</div><div class="line">              <span class="keyword">case</span> <span class="type">Errors</span>.<span class="type">NONE</span> =&gt;</div><div class="line">                <span class="keyword">try</span> &#123;</div><div class="line">                  <span class="keyword">val</span> records = partitionData.toRecords</div><div class="line">                  <span class="keyword">val</span> newOffset = records.shallowEntries.asScala.lastOption.map(_.nextOffset).getOrElse(</div><div class="line">                    currentPartitionFetchState.offset)</div><div class="line"></div><div class="line">                  fetcherLagStats.getAndMaybePut(topic, partitionId).lag = <span class="type">Math</span>.max(<span class="number">0</span>L, partitionData.highWatermark - newOffset)</div><div class="line">                  <span class="comment">// Once we hand off the partition data to the subclass, we can't mess with it any more in this thread</span></div><div class="line">                  <span class="comment">//note: 将 fetch 的数据追加到日志文件中</span></div><div class="line">                  processPartitionData(topicPartition, currentPartitionFetchState.offset, partitionData)</div><div class="line"></div><div class="line">                  <span class="keyword">val</span> validBytes = records.validBytes</div><div class="line">                  <span class="keyword">if</span> (validBytes &gt; <span class="number">0</span>) &#123;</div><div class="line">                    <span class="comment">// Update partitionStates only if there is no exception during processPartitionData</span></div><div class="line">                    <span class="comment">//note: 更新 fetch 的 offset 位置</span></div><div class="line">                    partitionStates.updateAndMoveToEnd(topicPartition, <span class="keyword">new</span> <span class="type">PartitionFetchState</span>(newOffset))</div><div class="line">                    fetcherStats.byteRate.mark(validBytes) <span class="comment">//note: 更新 metrics</span></div><div class="line">                  &#125;</div><div class="line">                &#125; <span class="keyword">catch</span> &#123;</div><div class="line">                  <span class="keyword">case</span> ime: <span class="type">CorruptRecordException</span> =&gt;</div><div class="line">                    <span class="comment">// we log the error and continue. This ensures two things</span></div><div class="line">                    <span class="comment">// 1. If there is a corrupt message in a topic partition, it does not bring the fetcher thread down and cause other topic partition to also lag</span></div><div class="line">                    <span class="comment">// 2. If the message is corrupt due to a transient state in the log (truncation, partial writes can cause this), we simply continue and</span></div><div class="line">                    <span class="comment">// should get fixed in the subsequent fetches</span></div><div class="line">                    <span class="comment">//note: CRC 验证失败时，打印日志，并继续进行（这个线程还会有其他的 tp 拉取，防止影响其他副本同步）</span></div><div class="line">                    logger.error(<span class="string">"Found invalid messages during fetch for partition ["</span> + topic + <span class="string">","</span> + partitionId + <span class="string">"] offset "</span> + currentPartitionFetchState.offset  + <span class="string">" error "</span> + ime.getMessage)</div><div class="line">                    updatePartitionsWithError(topicPartition);</div><div class="line">                  <span class="keyword">case</span> e: <span class="type">Throwable</span> =&gt;</div><div class="line">                    <span class="comment">//note: 这里还会抛出异常，是 RUNTimeException</span></div><div class="line">                    <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">KafkaException</span>(<span class="string">"error processing data for partition [%s,%d] offset %d"</span></div><div class="line">                      .format(topic, partitionId, currentPartitionFetchState.offset), e)</div><div class="line">                &#125;</div><div class="line">              <span class="keyword">case</span> <span class="type">Errors</span>.<span class="type">OFFSET_OUT_OF_RANGE</span> =&gt; <span class="comment">//note: Out-of-range 的情况处理</span></div><div class="line">                <span class="keyword">try</span> &#123;</div><div class="line">                  <span class="keyword">val</span> newOffset = handleOffsetOutOfRange(topicPartition)</div><div class="line">                  partitionStates.updateAndMoveToEnd(topicPartition, <span class="keyword">new</span> <span class="type">PartitionFetchState</span>(newOffset))</div><div class="line">                  error(<span class="string">"Current offset %d for partition [%s,%d] out of range; reset offset to %d"</span></div><div class="line">                    .format(currentPartitionFetchState.offset, topic, partitionId, newOffset))</div><div class="line">                &#125; <span class="keyword">catch</span> &#123; <span class="comment">//note: 处理 out-of-range 是抛出的异常</span></div><div class="line">                  <span class="keyword">case</span> e: <span class="type">Throwable</span> =&gt;</div><div class="line">                    error(<span class="string">"Error getting offset for partition [%s,%d] to broker %d"</span>.format(topic, partitionId, sourceBroker.id), e)</div><div class="line">                    updatePartitionsWithError(topicPartition)</div><div class="line">                &#125;</div><div class="line">              <span class="keyword">case</span> _ =&gt; <span class="comment">//note: 其他的异常情况</span></div><div class="line">                <span class="keyword">if</span> (isRunning.get) &#123;</div><div class="line">                  error(<span class="string">"Error for partition [%s,%d] to broker %d:%s"</span>.format(topic, partitionId, sourceBroker.id,</div><div class="line">                    partitionData.exception.get))</div><div class="line">                  updatePartitionsWithError(topicPartition)</div><div class="line">                &#125;</div><div class="line">            &#125;</div><div class="line">          &#125;)</div><div class="line">      &#125;</div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  <span class="comment">//note: 处理拉取遇到的错误读的 tp</span></div><div class="line">  <span class="keyword">if</span> (partitionsWithError.nonEmpty) &#123;</div><div class="line">    debug(<span class="string">"handling partitions with error for %s"</span>.format(partitionsWithError))</div><div class="line">    handlePartitionsWithErrors(partitionsWithError)</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>其处理过程简单总结一下：</p>
<ol>
<li>通过 <code>fetch()</code> 方法，发送 Fetch 请求，获取相应的 response（如果遇到异常，那么在下次发送 Fetch 请求之前，会 sleep 一段时间再发）；</li>
<li>如果返回的结果 不为空，并且 Fetch 请求的 offset 信息与返回结果的 offset 信息对得上，那么就会调用 <code>processPartitionData()</code> 方法将拉取到的数据追加本地副本的日志文件中，如果返回结果有错误信息，那么就对相应错误进行相应的处理；</li>
<li>对在 Fetch 过程中遇到异常或返回错误的 topic-partition，会进行 delay 操作，下次 Fetch 请求的发生至少要间隔 <code>replica.fetch.backoff.ms</code> 时间。</li>
</ol>
<h4 id="fetch"><a href="#fetch" class="headerlink" title="fetch"></a>fetch</h4><p><code>fetch()</code> 方法作用是发送 Fetch 请求，并返回相应的结果，其具体的实现，如下：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//note: 发送 fetch 请求，获取拉取结果</span></div><div class="line"><span class="keyword">protected</span> <span class="function"><span class="keyword">def</span> <span class="title">fetch</span></span>(fetchRequest: <span class="type">FetchRequest</span>): <span class="type">Seq</span>[(<span class="type">TopicPartition</span>, <span class="type">PartitionData</span>)] = &#123;</div><div class="line">  <span class="keyword">val</span> clientResponse = sendRequest(fetchRequest.underlying)</div><div class="line">  <span class="keyword">val</span> fetchResponse = clientResponse.responseBody.asInstanceOf[<span class="type">FetchResponse</span>]</div><div class="line">  fetchResponse.responseData.asScala.toSeq.map &#123; <span class="keyword">case</span> (key, value) =&gt;</div><div class="line">    key -&gt; <span class="keyword">new</span> <span class="type">PartitionData</span>(value)</div><div class="line">  &#125;</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="comment">//note: 发送请求</span></div><div class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">sendRequest</span></span>(requestBuilder: <span class="type">AbstractRequest</span>.<span class="type">Builder</span>[_ &lt;: <span class="type">AbstractRequest</span>]): <span class="type">ClientResponse</span> = &#123;</div><div class="line">  <span class="keyword">import</span> kafka.utils.<span class="type">NetworkClientBlockingOps</span>._</div><div class="line">  <span class="keyword">try</span> &#123;</div><div class="line">    <span class="keyword">if</span> (!networkClient.blockingReady(sourceNode, socketTimeout)(time))</div><div class="line">      <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">SocketTimeoutException</span>(<span class="string">s"Failed to connect within <span class="subst">$socketTimeout</span> ms"</span>)</div><div class="line">    <span class="keyword">else</span> &#123;</div><div class="line">      <span class="keyword">val</span> clientRequest = networkClient.newClientRequest(sourceBroker.id.toString, requestBuilder,</div><div class="line">        time.milliseconds(), <span class="literal">true</span>)</div><div class="line">      networkClient.blockingSendAndReceive(clientRequest)(time) <span class="comment">//note: 阻塞直到获取返回结果</span></div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line">  <span class="keyword">catch</span> &#123;</div><div class="line">    <span class="keyword">case</span> e: <span class="type">Throwable</span> =&gt;</div><div class="line">      networkClient.close(sourceBroker.id.toString)</div><div class="line">      <span class="keyword">throw</span> e</div><div class="line">  &#125;</div><div class="line"></div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h4 id="processPartitionData"><a href="#processPartitionData" class="headerlink" title="processPartitionData"></a>processPartitionData</h4><p>这个方法的作用是，处理 Fetch 请求的具体数据内容，简单来说就是：检查一下数据大小是否超过限制、将数据追加到本地副本的日志文件中、更新本地副本的 hw 值。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// process fetched data</span></div><div class="line"><span class="comment">//note: 处理 fetch 的数据，将 fetch 的数据追加的日志文件中</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">processPartitionData</span></span>(topicPartition: <span class="type">TopicPartition</span>, fetchOffset: <span class="type">Long</span>, partitionData: <span class="type">PartitionData</span>) &#123;</div><div class="line">  <span class="keyword">try</span> &#123;</div><div class="line">    <span class="keyword">val</span> replica = replicaMgr.getReplica(topicPartition).get</div><div class="line">    <span class="keyword">val</span> records = partitionData.toRecords</div><div class="line"></div><div class="line">    <span class="comment">//note: 检查 records</span></div><div class="line">    maybeWarnIfOversizedRecords(records, topicPartition)</div><div class="line"></div><div class="line">    <span class="keyword">if</span> (fetchOffset != replica.logEndOffset.messageOffset)</div><div class="line">      <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">RuntimeException</span>(<span class="string">"Offset mismatch for partition %s: fetched offset = %d, log end offset = %d."</span>.format(topicPartition, fetchOffset, replica.logEndOffset.messageOffset))</div><div class="line">    <span class="keyword">if</span> (logger.isTraceEnabled)</div><div class="line">      trace(<span class="string">"Follower %d has replica log end offset %d for partition %s. Received %d messages and leader hw %d"</span></div><div class="line">        .format(replica.brokerId, replica.logEndOffset.messageOffset, topicPartition, records.sizeInBytes, partitionData.highWatermark))</div><div class="line">    replica.log.get.append(records, assignOffsets = <span class="literal">false</span>) <span class="comment">//note: 将 fetch 的数据追加到 log 中</span></div><div class="line">    <span class="keyword">if</span> (logger.isTraceEnabled)</div><div class="line">      trace(<span class="string">"Follower %d has replica log end offset %d after appending %d bytes of messages for partition %s"</span></div><div class="line">        .format(replica.brokerId, replica.logEndOffset.messageOffset, records.sizeInBytes, topicPartition))</div><div class="line">    <span class="comment">//note: 更新 replica 的 hw（logEndOffset 在追加数据后也会立马进行修改)</span></div><div class="line">    <span class="keyword">val</span> followerHighWatermark = replica.logEndOffset.messageOffset.min(partitionData.highWatermark)</div><div class="line">    <span class="comment">// for the follower replica, we do not need to keep</span></div><div class="line">    <span class="comment">// its segment base offset the physical position,</span></div><div class="line">    <span class="comment">// these values will be computed upon making the leader</span></div><div class="line">    <span class="comment">//note: 这个值主要是用在 leader replica 上的</span></div><div class="line">    replica.highWatermark = <span class="keyword">new</span> <span class="type">LogOffsetMetadata</span>(followerHighWatermark)</div><div class="line">    <span class="keyword">if</span> (logger.isTraceEnabled)</div><div class="line">      trace(<span class="string">s"Follower <span class="subst">$&#123;replica.brokerId&#125;</span> set replica high watermark for partition <span class="subst">$topicPartition</span> to <span class="subst">$followerHighWatermark</span>"</span>)</div><div class="line">    <span class="keyword">if</span> (quota.isThrottled(topicPartition))</div><div class="line">      quota.record(records.sizeInBytes)</div><div class="line">  &#125; <span class="keyword">catch</span> &#123;</div><div class="line">    <span class="keyword">case</span> e: <span class="type">KafkaStorageException</span> =&gt;</div><div class="line">      fatal(<span class="string">s"Disk error while replicating data for <span class="subst">$topicPartition</span>"</span>, e)</div><div class="line">      <span class="type">Runtime</span>.getRuntime.halt(<span class="number">1</span>)</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h2 id="副本同步异常情况的处理"><a href="#副本同步异常情况的处理" class="headerlink" title="副本同步异常情况的处理"></a>副本同步异常情况的处理</h2><p>在副本同步的过程中，会遇到哪些异常情况呢？</p>
<p>大家一定会想到关于 offset 的问题，在 Kafka 中，关于 offset 的处理，无论是 producer 端、consumer 端还是其他地方，offset 似乎都是一个形影不离的问题。在副本同步时，关于 offset，会遇到什么问题呢？下面举两个异常的场景：</p>
<ol>
<li>假如当前本地（id：1）的副本现在是 leader，其 LEO 假设为1000，而另一个在 isr 中的副本（id：2）其 LEO 为800，此时出现网络抖动，id 为1 的机器掉线后又上线了，但是此时副本的 leader 实际上已经变成了 2，而2的 LEO 为800，这时候1启动副本同步线程去2上拉取数据，希望从 offset=1000 的地方开始拉取，但是2上最大的 offset 才是800，这种情况该如何处理呢？</li>
<li>假设一个 replica （id：1）其 LEO 是10，它已经掉线好几天，这个 partition leader 的 offset 范围是 [100, 800]，那么 1 重启启动时，它希望从 offset=10 的地方开始拉取数据时，这时候发生了 OutOfRange，不过跟上面不同的是这里是小于了 leader offset 的范围，这种情况又该怎么处理？</li>
</ol>
<p>以上两种情况都是 offset OutOfRange 的情况，只不过：一是 Fetch Offset 超过了 leader 的 LEO，二是 Fetch Offset 小于 leader 最小的 offset，在介绍 Kafka 解决方案之前，我们先来自己思考一下这两种情况应该怎么处理？</p>
<ol>
<li>如果 fetch offset 超过 leader 的 offset，这时候副本应该是回溯到 leader 的 LEO 位置（超过这个值的数据删除），然后再去进行副本同步，当然这种解决方案其实是无法保证 leader 与 follower 数据的完全一致，再次发生 leader 切换时，可能会导致数据的可见性不一致，但既然用户允许了脏选举的发生，其实我们是可以认为用户是可以接收这种情况发生的；</li>
<li>这种就比较容易处理，首先清空本地的数据，因为本地的数据都已经过期了，然后从 leader 的最小 offset 位置开始拉取数据。</li>
</ol>
<p>上面是我们比较容易想出的解决方案，而在 Kafka 中，其解决方案也很类似，不过遇到情况比上面我们列出的两种情况多了一些复杂，其解决方案如下：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div></pre></td><td class="code"><pre><div class="line">  <span class="comment">/**</span></div><div class="line">   * Unclean leader election: A follower goes down, in the meanwhile the leader keeps appending messages. The follower comes back up</div><div class="line">   * and before it has completely caught up with the leader's logs, all replicas in the ISR go down. The follower is now uncleanly</div><div class="line">   * elected as the new leader, and it starts appending messages from the client. The old leader comes back up, becomes a follower</div><div class="line">   * and it may discover that the current leader's end offset is behind its own end offset.</div><div class="line">   *</div><div class="line">   * In such a case, truncate the current follower's log to the current leader's end offset and continue fetching.</div><div class="line">   *</div><div class="line">   * There is a potential for a mismatch between the logs of the two replicas here. We don't fix this mismatch as of now.</div><div class="line">   */</div><div class="line">  <span class="comment">//note: 脏选举的发生</span></div><div class="line">  <span class="comment">//note: 获取最新的 offset</span></div><div class="line">  <span class="keyword">val</span> leaderEndOffset: <span class="type">Long</span> = earliestOrLatestOffset(topicPartition, <span class="type">ListOffsetRequest</span>.<span class="type">LATEST_TIMESTAMP</span>,</div><div class="line">    brokerConfig.brokerId)</div><div class="line"></div><div class="line">  <span class="keyword">if</span> (leaderEndOffset &lt; replica.logEndOffset.messageOffset) &#123; <span class="comment">//note: leaderEndOffset 小于 副本 LEO 的情况</span></div><div class="line">    <span class="comment">// Prior to truncating the follower's log, ensure that doing so is not disallowed by the configuration for unclean leader election.</span></div><div class="line">    <span class="comment">// This situation could only happen if the unclean election configuration for a topic changes while a replica is down. Otherwise,</span></div><div class="line">    <span class="comment">// we should never encounter this situation since a non-ISR leader cannot be elected if disallowed by the broker configuration.</span></div><div class="line">    <span class="comment">//note: 这种情况只是发生在 unclear election 的情况下</span></div><div class="line">    <span class="keyword">if</span> (!<span class="type">LogConfig</span>.fromProps(brokerConfig.originals, <span class="type">AdminUtils</span>.fetchEntityConfig(replicaMgr.zkUtils,</div><div class="line">      <span class="type">ConfigType</span>.<span class="type">Topic</span>, topicPartition.topic)).uncleanLeaderElectionEnable) &#123; <span class="comment">//note: 不允许 unclear elect 时,直接退出进程</span></div><div class="line">      <span class="comment">// Log a fatal error and shutdown the broker to ensure that data loss does not unexpectedly occur.</span></div><div class="line">      fatal(<span class="string">"Exiting because log truncation is not allowed for partition %s,"</span>.format(topicPartition) +</div><div class="line">        <span class="string">" Current leader %d's latest offset %d is less than replica %d's latest offset %d"</span></div><div class="line">        .format(sourceBroker.id, leaderEndOffset, brokerConfig.brokerId, replica.logEndOffset.messageOffset))</div><div class="line">      <span class="type">System</span>.exit(<span class="number">1</span>)</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="comment">//note: warn 日志信息</span></div><div class="line">    warn(<span class="string">"Replica %d for partition %s reset its fetch offset from %d to current leader %d's latest offset %d"</span></div><div class="line">      .format(brokerConfig.brokerId, topicPartition, replica.logEndOffset.messageOffset, sourceBroker.id, leaderEndOffset))</div><div class="line">    <span class="comment">//note: 进行截断操作,将offset 大于等于targetOffset 的数据和索引删除</span></div><div class="line">    replicaMgr.logManager.truncateTo(<span class="type">Map</span>(topicPartition -&gt; leaderEndOffset))</div><div class="line">    leaderEndOffset</div><div class="line">  &#125; <span class="keyword">else</span> &#123; <span class="comment">//note: leader 的 LEO 大于 follower 的 LEO 的情况下,还发生了 OutOfRange</span></div><div class="line">    <span class="comment">//note: 1. follower 下线了很久,其 LEO 已经小于了 leader 的 StartOffset;</span></div><div class="line">    <span class="comment">//note: 2. 脏选举发生时, 如果 old leader 的 HW 大于 new leader 的 LEO,此时 old leader 回溯到 HW,并且这个位置开始拉取数据发生了 Out of range</span></div><div class="line">    <span class="comment">//note:    当这个方法调用时,随着 produce 持续产生数据,可能出现 leader LEO 大于 Follower LEO 的情况（不做任何处理,重试即可解决,但</span></div><div class="line">    <span class="comment">//note:    无法保证数据的一致性）。</span></div><div class="line">    <span class="comment">/**</span></div><div class="line">     * If the leader's log end offset is greater than the follower's log end offset, there are two possibilities:</div><div class="line">     * 1. The follower could have been down for a long time and when it starts up, its end offset could be smaller than the leader's</div><div class="line">     * start offset because the leader has deleted old logs (log.logEndOffset &lt; leaderStartOffset).</div><div class="line">     * 2. When unclean leader election occurs, it is possible that the old leader's high watermark is greater than</div><div class="line">     * the new leader's log end offset. So when the old leader truncates its offset to its high watermark and starts</div><div class="line">     * to fetch from the new leader, an OffsetOutOfRangeException will be thrown. After that some more messages are</div><div class="line">     * produced to the new leader. While the old leader is trying to handle the OffsetOutOfRangeException and query</div><div class="line">     * the log end offset of the new leader, the new leader's log end offset becomes higher than the follower's log end offset.</div><div class="line">     *</div><div class="line">     * In the first case, the follower's current log end offset is smaller than the leader's log start offset. So the</div><div class="line">     * follower should truncate all its logs, roll out a new segment and start to fetch from the current leader's log</div><div class="line">     * start offset.</div><div class="line">     * In the second case, the follower should just keep the current log segments and retry the fetch. In the second</div><div class="line">     * case, there will be some inconsistency of data between old and new leader. We are not solving it here.</div><div class="line">     * If users want to have strong consistency guarantees, appropriate configurations needs to be set for both</div><div class="line">     * brokers and producers.</div><div class="line">     *</div><div class="line">     * Putting the two cases together, the follower should fetch from the higher one of its replica log end offset</div><div class="line">     * and the current leader's log start offset.</div><div class="line">     *</div><div class="line">     */</div><div class="line">    <span class="keyword">val</span> leaderStartOffset: <span class="type">Long</span> = earliestOrLatestOffset(topicPartition, <span class="type">ListOffsetRequest</span>.<span class="type">EARLIEST_TIMESTAMP</span>,</div><div class="line">      brokerConfig.brokerId)</div><div class="line">    warn(<span class="string">"Replica %d for partition %s reset its fetch offset from %d to current leader %d's start offset %d"</span></div><div class="line">      .format(brokerConfig.brokerId, topicPartition, replica.logEndOffset.messageOffset, sourceBroker.id, leaderStartOffset))</div><div class="line">    <span class="keyword">val</span> offsetToFetch = <span class="type">Math</span>.max(leaderStartOffset, replica.logEndOffset.messageOffset)</div><div class="line">    <span class="comment">// Only truncate log when current leader's log start offset is greater than follower's log end offset.</span></div><div class="line">    <span class="keyword">if</span> (leaderStartOffset &gt; replica.logEndOffset.messageOffset) <span class="comment">//note: 如果 leader 的 startOffset 大于副本的最大 offset</span></div><div class="line">      <span class="comment">//note: 将这个 log 的数据全部清空,并且从 leaderStartOffset 开始拉取数据</span></div><div class="line">      replicaMgr.logManager.truncateFullyAndStartAt(topicPartition, leaderStartOffset)</div><div class="line">    offsetToFetch</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>针对第一种情况，在 Kafka 中，实际上还会发生这样一种情况，1 在收到 OutOfRange 错误时，这时去 leader 上获取的 LEO 值与最小的 offset 值，这时候却发现 leader 的 LEO 已经从 800 变成了 1100（这个 topic-partition 的数据量增长得比较快），再按照上面的解决方案就不太合理，Kafka 这边的解决方案是：遇到这种情况，进行重试就可以了，下次同步时就会正常了，但是依然会有上面说的那个问题。</p>
<h2 id="replica-fetcher-线程的关闭"><a href="#replica-fetcher-线程的关闭" class="headerlink" title="replica fetcher 线程的关闭"></a>replica fetcher 线程的关闭</h2><p>最后我们再来介绍一下 replica fetcher 线程在什么情况下会关闭，同样，看一下最开始那张图的第三部分，图中已经比较清晰地列出了 replica fetcher 线程关闭的条件，在三种情况下会关闭对这个 topic-partition 的拉取操作（<code>becomeLeaderOrFollower()</code> 这个方法会在对 LeaderAndIsr 请求处理的文章中讲解，这里先忽略）：</p>
<ol>
<li><code>stopReplica()</code>：broker 收到了 controller 发来的 StopReplica 请求，这时会开始关闭对指定 topic-partition 的同步线程；</li>
<li><code>makeLeaders</code>：这些 partition 的本地副本被选举成了 leader，这时候就会先停止对这些 topic-partition 副本同步线程；</li>
<li><code>makeFollowers()</code>：前面已经介绍过，这里实际上停止副本同步，然后再开启副本同步线程，因为这些 topic-partition 的 leader 可能发生了切换。</li>
</ol>
<blockquote>
<p>这里直接说线程关闭，其实不是很准确，因为每个 replica fetcher 线程操作的是多个 topic-partition，而在关闭的粒度是 partition 级别，只有这个线程分配的 partition 全部关闭后，这个线程才会真正被关闭。</p>
</blockquote>
<h3 id="关闭副本同步"><a href="#关闭副本同步" class="headerlink" title="关闭副本同步"></a>关闭副本同步</h3><p>看下 ReplicaManager 中触发 replica fetcher 线程关闭的三个方法。</p>
<h4 id="stopReplica"><a href="#stopReplica" class="headerlink" title="stopReplica"></a>stopReplica</h4><p>StopReplica 的请求实际上是 Controller 发送过来的，这个在 controller 部分会讲述，它触发的条件有多种，比如：broker 下线、partition replica 迁移等等，ReplicaManager 这里的实现如下：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//note: 获取 tp 的 leader replica</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">getLeaderReplicaIfLocal</span></span>(topicPartition: <span class="type">TopicPartition</span>): <span class="type">Replica</span> =  &#123;</div><div class="line">  <span class="keyword">val</span> partitionOpt = getPartition(topicPartition) <span class="comment">//note: 获取对应的 Partiion 对象</span></div><div class="line">  partitionOpt <span class="keyword">match</span> &#123;</div><div class="line">    <span class="keyword">case</span> <span class="type">None</span> =&gt;</div><div class="line">      <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">UnknownTopicOrPartitionException</span>(<span class="string">s"Partition <span class="subst">$topicPartition</span> doesn't exist on <span class="subst">$localBrokerId</span>"</span>)</div><div class="line">    <span class="keyword">case</span> <span class="type">Some</span>(partition) =&gt;</div><div class="line">      partition.leaderReplicaIfLocal <span class="keyword">match</span> &#123;</div><div class="line">        <span class="keyword">case</span> <span class="type">Some</span>(leaderReplica) =&gt; leaderReplica <span class="comment">//note: 返回 leader 对应的副本</span></div><div class="line">        <span class="keyword">case</span> <span class="type">None</span> =&gt;</div><div class="line">          <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">NotLeaderForPartitionException</span>(<span class="string">s"Leader not local for partition <span class="subst">$topicPartition</span> on broker <span class="subst">$localBrokerId</span>"</span>)</div><div class="line">      &#125;</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h4 id="makeLeaders"><a href="#makeLeaders" class="headerlink" title="makeLeaders"></a>makeLeaders</h4><p><code>makeLeaders()</code> 方法的调用是在 broker 上这个 partition 的副本被设置为 leader 时触发的，其实现如下：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/*</span></div><div class="line"> * Make the current broker to become leader for a given set of partitions by:</div><div class="line"> *</div><div class="line"> * 1. Stop fetchers for these partitions</div><div class="line"> * 2. Update the partition metadata in cache</div><div class="line"> * 3. Add these partitions to the leader partitions set</div><div class="line"> *</div><div class="line"> * If an unexpected error is thrown in this function, it will be propagated to KafkaApis where</div><div class="line"> * the error message will be set on each partition since we do not know which partition caused it. Otherwise,</div><div class="line"> * return the set of partitions that are made leader due to this method</div><div class="line"> *</div><div class="line"> *  <span class="doctag">TODO:</span> the above may need to be fixed later</div><div class="line"> */</div><div class="line"><span class="comment">//note: 选举当前副本作为 partition 的 leader，处理过程：</span></div><div class="line"><span class="comment">//note: 1. 停止这些 partition 的 副本同步请求；</span></div><div class="line"><span class="comment">//note: 2. 更新缓存中的 partition metadata；</span></div><div class="line"><span class="comment">//note: 3. 将这些 partition 添加到 leader partition 集合中。</span></div><div class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">makeLeaders</span></span>(controllerId: <span class="type">Int</span>,</div><div class="line">                        epoch: <span class="type">Int</span>,</div><div class="line">                        partitionState: <span class="type">Map</span>[<span class="type">Partition</span>, <span class="type">PartitionState</span>],</div><div class="line">                        correlationId: <span class="type">Int</span>,</div><div class="line">                        responseMap: mutable.<span class="type">Map</span>[<span class="type">TopicPartition</span>, <span class="type">Short</span>]): <span class="type">Set</span>[<span class="type">Partition</span>] = &#123;</div><div class="line">  partitionState.keys.foreach &#123; partition =&gt;</div><div class="line">    stateChangeLogger.trace((<span class="string">"Broker %d handling LeaderAndIsr request correlationId %d from controller %d epoch %d "</span> +</div><div class="line">      <span class="string">"starting the become-leader transition for partition %s"</span>)</div><div class="line">      .format(localBrokerId, correlationId, controllerId, epoch, partition.topicPartition))</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  <span class="keyword">for</span> (partition &lt;- partitionState.keys)</div><div class="line">    responseMap.put(partition.topicPartition, <span class="type">Errors</span>.<span class="type">NONE</span>.code)</div><div class="line"></div><div class="line">  <span class="keyword">val</span> partitionsToMakeLeaders: mutable.<span class="type">Set</span>[<span class="type">Partition</span>] = mutable.<span class="type">Set</span>()</div><div class="line"></div><div class="line">  <span class="keyword">try</span> &#123;</div><div class="line">    <span class="comment">// First stop fetchers for all the partitions</span></div><div class="line">    <span class="comment">//note: 停止这些副本同步请求</span></div><div class="line">    replicaFetcherManager.removeFetcherForPartitions(partitionState.keySet.map(_.topicPartition))</div><div class="line">    <span class="comment">// Update the partition information to be the leader</span></div><div class="line">    <span class="comment">//note: 更新这些 partition 的信息（这些 partition 成为 leader 了）</span></div><div class="line">    partitionState.foreach&#123; <span class="keyword">case</span> (partition, partitionStateInfo) =&gt;</div><div class="line">      <span class="comment">//note: 在 partition 对象将本地副本设置为 leader</span></div><div class="line">      <span class="keyword">if</span> (partition.makeLeader(controllerId, partitionStateInfo, correlationId))</div><div class="line">        partitionsToMakeLeaders += partition <span class="comment">//note: 成功选为 leader 的 partition 集合</span></div><div class="line">      <span class="keyword">else</span></div><div class="line">        <span class="comment">//note: 本地 replica 已经是 leader replica，可能是接收了重试的请求</span></div><div class="line">        stateChangeLogger.info((<span class="string">"Broker %d skipped the become-leader state change after marking its partition as leader with correlation id %d from "</span> +</div><div class="line">          <span class="string">"controller %d epoch %d for partition %s since it is already the leader for the partition."</span>)</div><div class="line">          .format(localBrokerId, correlationId, controllerId, epoch, partition.topicPartition))</div><div class="line">    &#125;</div><div class="line">    partitionsToMakeLeaders.foreach &#123; partition =&gt;</div><div class="line">      stateChangeLogger.trace((<span class="string">"Broker %d stopped fetchers as part of become-leader request from controller "</span> +</div><div class="line">        <span class="string">"%d epoch %d with correlation id %d for partition %s"</span>)</div><div class="line">        .format(localBrokerId, controllerId, epoch, correlationId, partition.topicPartition))</div><div class="line">    &#125;</div><div class="line">  &#125; <span class="keyword">catch</span> &#123;</div><div class="line">    <span class="keyword">case</span> e: <span class="type">Throwable</span> =&gt;</div><div class="line">      partitionState.keys.foreach &#123; partition =&gt;</div><div class="line">        <span class="keyword">val</span> errorMsg = (<span class="string">"Error on broker %d while processing LeaderAndIsr request correlationId %d received from controller %d"</span> +</div><div class="line">          <span class="string">" epoch %d for partition %s"</span>).format(localBrokerId, correlationId, controllerId, epoch, partition.topicPartition)</div><div class="line">        stateChangeLogger.error(errorMsg, e)</div><div class="line">      &#125;</div><div class="line">      <span class="comment">// Re-throw the exception for it to be caught in KafkaApis</span></div><div class="line">      <span class="keyword">throw</span> e</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  <span class="comment">//note: LeaderAndIsr 请求处理完成</span></div><div class="line">  partitionState.keys.foreach &#123; partition =&gt;</div><div class="line">    stateChangeLogger.trace((<span class="string">"Broker %d completed LeaderAndIsr request correlationId %d from controller %d epoch %d "</span> +</div><div class="line">      <span class="string">"for the become-leader transition for partition %s"</span>)</div><div class="line">      .format(localBrokerId, correlationId, controllerId, epoch, partition.topicPartition))</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  partitionsToMakeLeaders</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>简单来说，这个方法的过程逻辑如下：</p>
<ol>
<li>先停止对这些 partition 的副本同步流程，因为这些 partition 的本地副本已经被选举成为了 leader；</li>
<li>将这些 partition 的本地副本设置为 leader，并且开始更新相应 meta 信息（主要是记录其他 follower 副本的相关信息）；</li>
<li>将这些 partition 添加到本地记录的 leader partition 集合中。</li>
</ol>
<h4 id="makeFollowers"><a href="#makeFollowers" class="headerlink" title="makeFollowers"></a>makeFollowers</h4><p>这个在前面已经讲述过了，参考前面的讲述。</p>
<h3 id="removeFetcherForPartitions"><a href="#removeFetcherForPartitions" class="headerlink" title="removeFetcherForPartitions"></a>removeFetcherForPartitions</h3><p>调用 ReplicaFetcherManager 的 <code>removeFetcherForPartitions()</code> 删除对这些 topic-partition 的副本同步设置，这里在实现时，会遍历所有的 replica fetcher 线程，都执行 <code>removePartitions()</code> 方法来移除对应的 topic-partition 集合。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//note: 删除一个 partition 的 replica-fetch 线程</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">removeFetcherForPartitions</span></span>(partitions: <span class="type">Set</span>[<span class="type">TopicPartition</span>]) &#123;</div><div class="line">  mapLock synchronized &#123;</div><div class="line">    <span class="keyword">for</span> (fetcher &lt;- fetcherThreadMap.values) <span class="comment">//note: 遍历所有的 fetchThread 去移除这个 topic-partition 集合</span></div><div class="line">      fetcher.removePartitions(partitions)</div><div class="line">  &#125;</div><div class="line">  info(<span class="string">"Removed fetcher for partitions %s"</span>.format(partitions.mkString(<span class="string">","</span>)))</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h3 id="removePartitions"><a href="#removePartitions" class="headerlink" title="removePartitions"></a>removePartitions</h3><p>这个方法的作用是：ReplicaFetcherThread 将这些 topic-partition 从自己要拉取的 partition 列表中移除。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">removePartitions</span></span>(topicPartitions: <span class="type">Set</span>[<span class="type">TopicPartition</span>]) &#123;</div><div class="line">  partitionMapLock.lockInterruptibly()</div><div class="line">  <span class="keyword">try</span> &#123;</div><div class="line">    topicPartitions.foreach &#123; topicPartition =&gt;</div><div class="line">      partitionStates.remove(topicPartition)</div><div class="line">      fetcherLagStats.unregister(topicPartition.topic, topicPartition.partition)</div><div class="line">    &#125;</div><div class="line">  &#125; <span class="keyword">finally</span> partitionMapLock.unlock()</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h3 id="ReplicaFetcherThread-的关闭"><a href="#ReplicaFetcherThread-的关闭" class="headerlink" title="ReplicaFetcherThread 的关闭"></a>ReplicaFetcherThread 的关闭</h3><p>前面介绍那么多，似乎还是没有真正去关闭，那么 ReplicaFetcherThread 真正关闭是哪里操作的呢？</p>
<p>实际上 ReplicaManager 每次处理完 LeaderAndIsr 请求后，都会调用 ReplicaFetcherManager 的 <code>shutdownIdleFetcherThreads()</code> 方法，如果 fetcher 线程要拉取的 topic-partition 集合为空，那么就会关闭掉对应的 fetcher 线程。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//note: 关闭没有拉取 topic-partition 任务的拉取线程</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">shutdownIdleFetcherThreads</span></span>() &#123;</div><div class="line">  mapLock synchronized &#123;</div><div class="line">    <span class="keyword">val</span> keysToBeRemoved = <span class="keyword">new</span> mutable.<span class="type">HashSet</span>[<span class="type">BrokerAndFetcherId</span>]</div><div class="line">    <span class="keyword">for</span> ((key, fetcher) &lt;- fetcherThreadMap) &#123;</div><div class="line">      <span class="keyword">if</span> (fetcher.partitionCount &lt;= <span class="number">0</span>) &#123; <span class="comment">//note: 如果该线程拉取的 partition 数小于 0</span></div><div class="line">        fetcher.shutdown()</div><div class="line">        keysToBeRemoved += key</div><div class="line">      &#125;</div><div class="line">    &#125;</div><div class="line">    fetcherThreadMap --= keysToBeRemoved</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>关于 Replica Fetcher 线程这部分的内容终于讲解完了，希望能对大家有所帮助，有问题欢迎通过留言、微博或邮件进行交流。</p>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[Kafka 源码解析之 Server 端如何处理 Fetch 请求（十三）]]></title>
      <url>http://matt33.com/2018/04/15/kafka-server-handle-fetch-request/</url>
      <content type="html"><![CDATA[<p>上一篇讲述完 Kafka 如何处理 Produce 请求以及日志写操作之后，这篇文章开始讲述 Kafka 如何处理 Fetch 请求以及日志读操作。日志的读写操作是 Kafka 存储层最重要的内容，本文会以 Server 端处理 Fetch 请求的过程为入口，一步步深入到底层的 Log 实例部分。与 Produce 请求不一样的地方是，对于 Fetch 请求，是有两种不同的来源：consumer 和 follower，consumer 读取数据与副本同步数据都是通过向 leader 发送 Fetch 请求来实现的，在对这两种不同情况处理过程中，其底层的实现是统一的，只是实现方法的参数不同而已，在本文中会详细讲述对这两种不同情况的处理。</p>
<h2 id="Fetch-请求处理的整体流程"><a href="#Fetch-请求处理的整体流程" class="headerlink" title="Fetch 请求处理的整体流程"></a>Fetch 请求处理的整体流程</h2><p>Fetch 请求（读请求）的处理与 Produce 请求（写请求）的整体流程非常类似，读和写由最上面的抽象层做入口，最终还是在存储层的 Log 对象实例进行真正的读写操作，在这一点上，Kafka 封装的非常清晰，这样的系统设计是非常值得学习的，甚至可以作为分布式系统的模范系统来学习。</p>
<p>Fetch 请求处理的整体流程如下图所示，与 Produce 请求的处理流程非常相似。</p>
<p><img src="/images/kafka/kafka_fetch_request.png" alt="Server 端处理 Fetch 请求的总体过程"></p>
<h3 id="Fetch-请求的来源"><a href="#Fetch-请求的来源" class="headerlink" title="Fetch 请求的来源"></a>Fetch 请求的来源</h3><p>那 Server 要处理的 Fetch 请求有几种类型呢？来自于哪里呢？第一个来源肯定是 Consumer，Consumer 在消费数据时会向 Server 端发送 Fetch 请求，那么是不是还没有其他的类型，对 Kafka 比较熟悉的同学大概会猜到，还有一种就是：副本同步，follower 在从 leader 同步数据时，也是发送的 Fetch 请求，下面看下这两种情况的具体实现（代码会进行简化，并不完全与源码一致，便于理解）。</p>
<h4 id="Consumer-Fetch-请求"><a href="#Consumer-Fetch-请求" class="headerlink" title="Consumer Fetch 请求"></a>Consumer Fetch 请求</h4><p>Consumer 的 Fetch 请求是在 poll 方法中调用的，Fetcher 请求的构造过程及发送如下所示：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/**</span></div><div class="line"> * Set-up a fetch request for any node that we have assigned partitions for which doesn't already have</div><div class="line"> * an in-flight fetch or pending fetch data.</div><div class="line"> * <span class="doctag">@return</span> number of fetches sent</div><div class="line"> */</div><div class="line"><span class="comment">//note: 向订阅的所有 partition （只要该 leader 暂时没有拉取请求）所在 leader 发送 fetch请求</span></div><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">sendFetches</span><span class="params">()</span> </span>&#123;</div><div class="line">    <span class="comment">//note: 1 创建 Fetch Request</span></div><div class="line">    Map&lt;Node, FetchRequest.Builder&gt; fetchRequestMap = createFetchRequests();</div><div class="line">    <span class="keyword">for</span> (Map.Entry&lt;Node, FetchRequest.Builder&gt; fetchEntry : fetchRequestMap.entrySet()) &#123;</div><div class="line">        <span class="keyword">final</span> FetchRequest.Builder request = fetchEntry.getValue();</div><div class="line">        <span class="keyword">final</span> Node fetchTarget = fetchEntry.getKey();</div><div class="line"></div><div class="line">        log.debug(<span class="string">"Sending fetch for partitions &#123;&#125; to broker &#123;&#125;"</span>, request.fetchData().keySet(), fetchTarget);</div><div class="line">        <span class="comment">//note: 2 发送 Fetch Request</span></div><div class="line">        client.send(fetchTarget, request)</div><div class="line">                .addListener(<span class="keyword">new</span> RequestFutureListener&lt;ClientResponse&gt;() &#123;</div><div class="line">                    <span class="meta">@Override</span></div><div class="line">                    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onSuccess</span><span class="params">(ClientResponse resp)</span> </span>&#123;</div><div class="line">                        ...</div><div class="line">                    &#125;</div><div class="line"></div><div class="line">                    <span class="meta">@Override</span></div><div class="line">                    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onFailure</span><span class="params">(RuntimeException e)</span> </span>&#123;</div><div class="line">                        ...</div><div class="line">                    &#125;</div><div class="line">                &#125;);</div><div class="line">    &#125;</div><div class="line">    <span class="keyword">return</span> fetchRequestMap.size();</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="comment">/**</span></div><div class="line"> * Create fetch requests for all nodes for which we have assigned partitions</div><div class="line"> * that have no existing requests in flight.</div><div class="line"> */</div><div class="line"><span class="comment">//note: 为所有 node 创建 fetch request</span></div><div class="line"><span class="keyword">private</span> Map&lt;Node, FetchRequest.Builder&gt; createFetchRequests() &#123;</div><div class="line">    <span class="comment">// create the fetch info</span></div><div class="line">    Cluster cluster = metadata.fetch();</div><div class="line">    Map&lt;Node, LinkedHashMap&lt;TopicPartition, FetchRequest.PartitionData&gt;&gt; fetchable = <span class="keyword">new</span> LinkedHashMap&lt;&gt;();</div><div class="line">    <span class="keyword">for</span> (TopicPartition partition : fetchablePartitions()) &#123;</div><div class="line">        Node node = cluster.leaderFor(partition);</div><div class="line">        <span class="keyword">if</span> (node == <span class="keyword">null</span>) &#123;</div><div class="line">            metadata.requestUpdate();</div><div class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> (<span class="keyword">this</span>.client.pendingRequestCount(node) == <span class="number">0</span>) &#123;</div><div class="line">            <span class="comment">// if there is a leader and no in-flight requests, issue a new fetch</span></div><div class="line">            LinkedHashMap&lt;TopicPartition, FetchRequest.PartitionData&gt; fetch = fetchable.get(node);</div><div class="line">            <span class="keyword">if</span> (fetch == <span class="keyword">null</span>) &#123;</div><div class="line">                fetch = <span class="keyword">new</span> LinkedHashMap&lt;&gt;();</div><div class="line">                fetchable.put(node, fetch);</div><div class="line">            &#125;</div><div class="line"></div><div class="line">            <span class="keyword">long</span> position = <span class="keyword">this</span>.subscriptions.position(partition);</div><div class="line">            <span class="comment">//note: 要 fetch 的 position 以及 fetch 的大小</span></div><div class="line">            fetch.put(partition, <span class="keyword">new</span> FetchRequest.PartitionData(position, <span class="keyword">this</span>.fetchSize));</div><div class="line">            log.trace(<span class="string">"Added fetch request for partition &#123;&#125; at offset &#123;&#125; to node &#123;&#125;"</span>, partition, position, node);</div><div class="line">        &#125; <span class="keyword">else</span> &#123;</div><div class="line">            log.trace(<span class="string">"Skipping fetch for partition &#123;&#125; because there is an in-flight request to &#123;&#125;"</span>, partition, node);</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="comment">// create the fetches</span></div><div class="line">    Map&lt;Node, FetchRequest.Builder&gt; requests = <span class="keyword">new</span> HashMap&lt;&gt;();</div><div class="line">    <span class="keyword">for</span> (Map.Entry&lt;Node, LinkedHashMap&lt;TopicPartition, FetchRequest.PartitionData&gt;&gt; entry : fetchable.entrySet()) &#123;</div><div class="line">        Node node = entry.getKey();</div><div class="line">        <span class="comment">// 构造 Fetch 请求</span></div><div class="line">        FetchRequest.Builder fetch = <span class="keyword">new</span> FetchRequest.Builder(<span class="keyword">this</span>.maxWaitMs, <span class="keyword">this</span>.minBytes, entry.getValue()).</div><div class="line">                setMaxBytes(<span class="keyword">this</span>.maxBytes);<span class="comment">//note: 构建 Fetch Request</span></div><div class="line">        requests.put(node, fetch);</div><div class="line">    &#125;</div><div class="line">    <span class="keyword">return</span> requests;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>从上面可以看出，Consumer 的 Fetcher 请求构造为：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">FetchRequest.Builder fetch = <span class="keyword">new</span> FetchRequest.Builder(<span class="keyword">this</span>.maxWaitMs, <span class="keyword">this</span>.minBytes, entry.getValue()).</div><div class="line">                setMaxBytes(<span class="keyword">this</span>.maxBytes);<span class="comment">//note: 构建 Fetch Request</span></div></pre></td></tr></table></figure>
<h4 id="Replica-同步-Fetch-请求"><a href="#Replica-同步-Fetch-请求" class="headerlink" title="Replica 同步 Fetch 请求"></a>Replica 同步 Fetch 请求</h4><p>在 Replica 同步（Replica 同步流程的讲解将会在下篇文章中详细展开）的 Fetch 请求中，其 Fetch 请求的构造如下所示：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//note: 构造 Fetch 请求</span></div><div class="line"><span class="keyword">protected</span> <span class="function"><span class="keyword">def</span> <span class="title">buildFetchRequest</span></span>(partitionMap: <span class="type">Seq</span>[(<span class="type">TopicPartition</span>, <span class="type">PartitionFetchState</span>)]): <span class="type">FetchRequest</span> = &#123;</div><div class="line">  <span class="keyword">val</span> requestMap = <span class="keyword">new</span> util.<span class="type">LinkedHashMap</span>[<span class="type">TopicPartition</span>, <span class="type">JFetchRequest</span>.<span class="type">PartitionData</span>]</div><div class="line"></div><div class="line">  partitionMap.foreach &#123; <span class="keyword">case</span> (topicPartition, partitionFetchState) =&gt;</div><div class="line">    <span class="comment">// We will not include a replica in the fetch request if it should be throttled.</span></div><div class="line">    <span class="keyword">if</span> (partitionFetchState.isActive &amp;&amp; !shouldFollowerThrottle(quota, topicPartition))</div><div class="line">      requestMap.put(topicPartition, <span class="keyword">new</span> <span class="type">JFetchRequest</span>.<span class="type">PartitionData</span>(partitionFetchState.offset, fetchSize))</div><div class="line">  &#125;</div><div class="line">  <span class="comment">//note: 关键在于 setReplicaId 方法,设置了 replicaId, consumer 的该值为 CONSUMER_REPLICA_ID（-1）</span></div><div class="line">  <span class="keyword">val</span> requestBuilder = <span class="keyword">new</span> <span class="type">JFetchRequest</span>.<span class="type">Builder</span>(maxWait, minBytes, requestMap).</div><div class="line">      setReplicaId(replicaId).setMaxBytes(maxBytes)</div><div class="line">  requestBuilder.setVersion(fetchRequestVersion)</div><div class="line">  <span class="keyword">new</span> <span class="type">FetchRequest</span>(requestBuilder)</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>与 Consumer Fetch 请求进行对比，这里区别仅在于在构造 FetchRequest 时，调用了 <code>setReplicaId()</code> 方法设置了对应的 replicaId，而 Consumer 在构造时则没有进行设置，该值默认为 <code>CONSUMER_REPLICA_ID</code>，即 <strong>-1</strong>，这个值是作为 Consumer 的 Fetch 请求与 Replica 同步的 Fetch 请求的区分。</p>
<h2 id="Server-端的处理"><a href="#Server-端的处理" class="headerlink" title="Server 端的处理"></a>Server 端的处理</h2><p>这里开始真正讲解 Fetch 请求的处理过程，会按照前面图中的处理流程开始讲解，本节主要是 Server 端抽象层的内容。</p>
<h3 id="KafkaApis-如何处理-Fetch-请求"><a href="#KafkaApis-如何处理-Fetch-请求" class="headerlink" title="KafkaApis 如何处理 Fetch 请求"></a>KafkaApis 如何处理 Fetch 请求</h3><p>关于 Fetch 请求的处理，如下所示：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/**</span></div><div class="line"> * Handle a fetch request</div><div class="line"> */</div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">handleFetchRequest</span></span>(request: <span class="type">RequestChannel</span>.<span class="type">Request</span>) &#123;</div><div class="line">  <span class="keyword">val</span> fetchRequest = request.body.asInstanceOf[<span class="type">FetchRequest</span>]</div><div class="line">  <span class="keyword">val</span> versionId = request.header.apiVersion</div><div class="line">  <span class="keyword">val</span> clientId = request.header.clientId</div><div class="line"></div><div class="line">  <span class="comment">//note: 判断 tp 是否存在以及是否有 Describe 权限</span></div><div class="line">  <span class="keyword">val</span> (existingAndAuthorizedForDescribeTopics, nonExistingOrUnauthorizedForDescribeTopics) = fetchRequest.fetchData.asScala.toSeq.partition &#123;</div><div class="line">    <span class="keyword">case</span> (tp, _) =&gt; authorize(request.session, <span class="type">Describe</span>, <span class="keyword">new</span> <span class="type">Resource</span>(auth.<span class="type">Topic</span>, tp.topic)) &amp;&amp; metadataCache.contains(tp.topic)</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  <span class="comment">//note: 判断 tp 是否有 Read 权限</span></div><div class="line">  <span class="keyword">val</span> (authorizedRequestInfo, unauthorizedForReadRequestInfo) = existingAndAuthorizedForDescribeTopics.partition &#123;</div><div class="line">    <span class="keyword">case</span> (tp, _) =&gt; authorize(request.session, <span class="type">Read</span>, <span class="keyword">new</span> <span class="type">Resource</span>(auth.<span class="type">Topic</span>, tp.topic))</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  <span class="comment">//note: 不存在或没有 Describe 权限的 topic 返回 UNKNOWN_TOPIC_OR_PARTITION 错误</span></div><div class="line">  <span class="keyword">val</span> nonExistingOrUnauthorizedForDescribePartitionData = nonExistingOrUnauthorizedForDescribeTopics.map &#123;</div><div class="line">    <span class="keyword">case</span> (tp, _) =&gt; (tp, <span class="keyword">new</span> <span class="type">FetchResponse</span>.<span class="type">PartitionData</span>(<span class="type">Errors</span>.<span class="type">UNKNOWN_TOPIC_OR_PARTITION</span>.code, <span class="number">-1</span>, <span class="type">MemoryRecords</span>.<span class="type">EMPTY</span>))</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  <span class="comment">//note: 没有 Read 权限的 topic 返回 TOPIC_AUTHORIZATION_FAILED 错误</span></div><div class="line">  <span class="keyword">val</span> unauthorizedForReadPartitionData = unauthorizedForReadRequestInfo.map &#123;</div><div class="line">    <span class="keyword">case</span> (tp, _) =&gt; (tp, <span class="keyword">new</span> <span class="type">FetchResponse</span>.<span class="type">PartitionData</span>(<span class="type">Errors</span>.<span class="type">TOPIC_AUTHORIZATION_FAILED</span>.code, <span class="number">-1</span>, <span class="type">MemoryRecords</span>.<span class="type">EMPTY</span>))</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  <span class="comment">// the callback for sending a fetch response</span></div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">sendResponseCallback</span></span>(responsePartitionData: <span class="type">Seq</span>[(<span class="type">TopicPartition</span>, <span class="type">FetchPartitionData</span>)]) &#123;</div><div class="line">    ....</div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">fetchResponseCallback</span></span>(delayTimeMs: <span class="type">Int</span>) &#123;</div><div class="line">      trace(<span class="string">s"Sending fetch response to client <span class="subst">$clientId</span> of "</span> +</div><div class="line">        <span class="string">s"<span class="subst">$&#123;convertedPartitionData.map &#123; case (_, v) =&gt; v.records.sizeInBytes &#125;</span>.sum&#125; bytes"</span>)</div><div class="line">      <span class="keyword">val</span> fetchResponse = <span class="keyword">if</span> (delayTimeMs &gt; <span class="number">0</span>) <span class="keyword">new</span> <span class="type">FetchResponse</span>(versionId, fetchedPartitionData, delayTimeMs) <span class="keyword">else</span> response</div><div class="line">      requestChannel.sendResponse(<span class="keyword">new</span> <span class="type">RequestChannel</span>.<span class="type">Response</span>(request, fetchResponse))</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="comment">// When this callback is triggered, the remote API call has completed</span></div><div class="line">    request.apiRemoteCompleteTimeMs = time.milliseconds</div><div class="line"></div><div class="line">    <span class="comment">//note: 配额情况的处理</span></div><div class="line">    <span class="keyword">if</span> (fetchRequest.isFromFollower) &#123;</div><div class="line">      <span class="comment">// We've already evaluated against the quota and are good to go. Just need to record it now.</span></div><div class="line">      <span class="keyword">val</span> responseSize = sizeOfThrottledPartitions(versionId, fetchRequest, mergedPartitionData, quotas.leader)</div><div class="line">      quotas.leader.record(responseSize)</div><div class="line">      fetchResponseCallback(<span class="number">0</span>)</div><div class="line">    &#125; <span class="keyword">else</span> &#123;</div><div class="line">      quotas.fetch.recordAndMaybeThrottle(request.session.sanitizedUser, clientId, response.sizeOf, fetchResponseCallback)</div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  <span class="keyword">if</span> (authorizedRequestInfo.isEmpty)</div><div class="line">    sendResponseCallback(<span class="type">Seq</span>.empty)</div><div class="line">  <span class="keyword">else</span> &#123;</div><div class="line">    <span class="comment">// call the replica manager to fetch messages from the local replica</span></div><div class="line">    <span class="comment">//note: 从 replica 上拉取数据,满足条件后调用回调函数进行返回</span></div><div class="line">    replicaManager.fetchMessages(</div><div class="line">      fetchRequest.maxWait.toLong, <span class="comment">//note: 拉取请求最长的等待时间</span></div><div class="line">      fetchRequest.replicaId, <span class="comment">//note: Replica 编号，Consumer 的为 -1</span></div><div class="line">      fetchRequest.minBytes, <span class="comment">//note: 拉取请求设置的最小拉取字节</span></div><div class="line">      fetchRequest.maxBytes, <span class="comment">//note: 拉取请求设置的最大拉取字节</span></div><div class="line">      versionId &lt;= <span class="number">2</span>,</div><div class="line">      authorizedRequestInfo,</div><div class="line">      replicationQuota(fetchRequest),</div><div class="line">      sendResponseCallback)</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>Fetch 请求处理的真正实现是在 replicaManager 的 <code>fetchMessages()</code> 方法中，在这里，可以看出，无论是 Fetch 请求还是 Produce 请求，都是通过副本管理器来实现的，副本管理器（ReplicaManager）管理的对象是分区实例（Partition），而每个分区都会与相应的副本实例对应（Replica），在这个节点上的副本又会与唯一的 Log 实例对应，正如流程图的上半部分一样，Server 就是通过这几部分抽象概念来管理真正存储层的内容。</p>
<h3 id="ReplicaManager-如何处理-Fetch-请求"><a href="#ReplicaManager-如何处理-Fetch-请求" class="headerlink" title="ReplicaManager 如何处理 Fetch 请求"></a>ReplicaManager 如何处理 Fetch 请求</h3><p>ReplicaManger 处理 Fetch 请求的入口在 <code>fetchMessages()</code> 方法。</p>
<h4 id="fetchMessages"><a href="#fetchMessages" class="headerlink" title="fetchMessages"></a>fetchMessages</h4><p><code>fetchMessages()</code> 方法的具体如下：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/**</span></div><div class="line"> * Fetch messages from the leader replica, and wait until enough data can be fetched and return;</div><div class="line"> * the callback function will be triggered either when timeout or required fetch info is satisfied</div><div class="line"> */</div><div class="line"><span class="comment">//note: 从 leader 拉取数据,等待拉取到足够的数据或者达到 timeout 时间后返回拉取的结果</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">fetchMessages</span></span>(timeout: <span class="type">Long</span>,</div><div class="line">                  replicaId: <span class="type">Int</span>,</div><div class="line">                  fetchMinBytes: <span class="type">Int</span>,</div><div class="line">                  fetchMaxBytes: <span class="type">Int</span>,</div><div class="line">                  hardMaxBytesLimit: <span class="type">Boolean</span>,</div><div class="line">                  fetchInfos: <span class="type">Seq</span>[(<span class="type">TopicPartition</span>, <span class="type">PartitionData</span>)],</div><div class="line">                  quota: <span class="type">ReplicaQuota</span> = <span class="type">UnboundedQuota</span>,</div><div class="line">                  responseCallback: <span class="type">Seq</span>[(<span class="type">TopicPartition</span>, <span class="type">FetchPartitionData</span>)] =&gt; <span class="type">Unit</span>) &#123;</div><div class="line">  <span class="keyword">val</span> isFromFollower = replicaId &gt;= <span class="number">0</span> <span class="comment">//note: 判断请求是来自 consumer （这个值为 -1）还是副本同步</span></div><div class="line">  <span class="comment">//note: 默认都是从 leader 拉取，推测这个值只是为了后续能从 follower 消费数据而设置的</span></div><div class="line">  <span class="keyword">val</span> fetchOnlyFromLeader: <span class="type">Boolean</span> = replicaId != <span class="type">Request</span>.<span class="type">DebuggingConsumerId</span></div><div class="line">  <span class="comment">//note: 如果拉取请求来自 consumer（true）,只拉取 HW 以内的数据,如果是来自 Replica 同步,则没有该限制（false）。</span></div><div class="line">  <span class="keyword">val</span> fetchOnlyCommitted: <span class="type">Boolean</span> = ! <span class="type">Request</span>.isValidBrokerId(replicaId)</div><div class="line"></div><div class="line">  <span class="comment">// read from local logs</span></div><div class="line">  <span class="comment">//note：获取本地日志</span></div><div class="line">  <span class="keyword">val</span> logReadResults = readFromLocalLog(</div><div class="line">    replicaId = replicaId,</div><div class="line">    fetchOnlyFromLeader = fetchOnlyFromLeader,</div><div class="line">    readOnlyCommitted = fetchOnlyCommitted,</div><div class="line">    fetchMaxBytes = fetchMaxBytes,</div><div class="line">    hardMaxBytesLimit = hardMaxBytesLimit,</div><div class="line">    readPartitionInfo = fetchInfos,</div><div class="line">    quota = quota)</div><div class="line"></div><div class="line">  <span class="comment">// if the fetch comes from the follower,</span></div><div class="line">  <span class="comment">// update its corresponding log end offset</span></div><div class="line">  <span class="comment">//note: 如果 fetch 来自 broker 的副本同步,那么就更新相关的 log end offset</span></div><div class="line">  <span class="keyword">if</span>(<span class="type">Request</span>.isValidBrokerId(replicaId))</div><div class="line">    updateFollowerLogReadResults(replicaId, logReadResults)</div><div class="line"></div><div class="line">  <span class="comment">// check if this fetch request can be satisfied right away</span></div><div class="line">  <span class="keyword">val</span> logReadResultValues = logReadResults.map &#123; <span class="keyword">case</span> (_, v) =&gt; v &#125;</div><div class="line">  <span class="keyword">val</span> bytesReadable = logReadResultValues.map(_.info.records.sizeInBytes).sum</div><div class="line">  <span class="keyword">val</span> errorReadingData = logReadResultValues.foldLeft(<span class="literal">false</span>) ((errorIncurred, readResult) =&gt;</div><div class="line">    errorIncurred || (readResult.error != <span class="type">Errors</span>.<span class="type">NONE</span>))</div><div class="line"></div><div class="line">  <span class="comment">// respond immediately if 1) fetch request does not want to wait</span></div><div class="line">  <span class="comment">//                        2) fetch request does not require any data</span></div><div class="line">  <span class="comment">//                        3) has enough data to respond</span></div><div class="line">  <span class="comment">//                        4) some error happens while reading data</span></div><div class="line">  <span class="comment">//note: 如果满足以下条件的其中一个,将会立马返回结果:</span></div><div class="line">  <span class="comment">//note: 1. timeout 达到; 2. 拉取结果为空; 3. 拉取到足够的数据; 4. 拉取是遇到 error</span></div><div class="line">  <span class="keyword">if</span> (timeout &lt;= <span class="number">0</span> || fetchInfos.isEmpty || bytesReadable &gt;= fetchMinBytes || errorReadingData) &#123;</div><div class="line">    <span class="keyword">val</span> fetchPartitionData = logReadResults.map &#123; <span class="keyword">case</span> (tp, result) =&gt;</div><div class="line">      tp -&gt; <span class="type">FetchPartitionData</span>(result.error, result.hw, result.info.records)</div><div class="line">    &#125;</div><div class="line">    responseCallback(fetchPartitionData)</div><div class="line">  &#125; <span class="keyword">else</span> &#123;</div><div class="line">    <span class="comment">//note： 其他情况下,延迟发送结果</span></div><div class="line">    <span class="comment">// construct the fetch results from the read results</span></div><div class="line">    <span class="keyword">val</span> fetchPartitionStatus = logReadResults.map &#123; <span class="keyword">case</span> (topicPartition, result) =&gt;</div><div class="line">      <span class="keyword">val</span> fetchInfo = fetchInfos.collectFirst &#123;</div><div class="line">        <span class="keyword">case</span> (tp, v) <span class="keyword">if</span> tp == topicPartition =&gt; v</div><div class="line">      &#125;.getOrElse(sys.error(<span class="string">s"Partition <span class="subst">$topicPartition</span> not found in fetchInfos"</span>))</div><div class="line">      (topicPartition, <span class="type">FetchPartitionStatus</span>(result.info.fetchOffsetMetadata, fetchInfo))</div><div class="line">    &#125;</div><div class="line">    <span class="keyword">val</span> fetchMetadata = <span class="type">FetchMetadata</span>(fetchMinBytes, fetchMaxBytes, hardMaxBytesLimit, fetchOnlyFromLeader,</div><div class="line">      fetchOnlyCommitted, isFromFollower, replicaId, fetchPartitionStatus)</div><div class="line">    <span class="keyword">val</span> delayedFetch = <span class="keyword">new</span> <span class="type">DelayedFetch</span>(timeout, fetchMetadata, <span class="keyword">this</span>, quota, responseCallback)</div><div class="line"></div><div class="line">    <span class="comment">// create a list of (topic, partition) pairs to use as keys for this delayed fetch operation</span></div><div class="line">    <span class="keyword">val</span> delayedFetchKeys = fetchPartitionStatus.map &#123; <span class="keyword">case</span> (tp, _) =&gt; <span class="keyword">new</span> <span class="type">TopicPartitionOperationKey</span>(tp) &#125;</div><div class="line"></div><div class="line">    <span class="comment">// try to complete the request immediately, otherwise put it into the purgatory;</span></div><div class="line">    <span class="comment">// this is because while the delayed fetch operation is being created, new requests</span></div><div class="line">    <span class="comment">// may arrive and hence make this operation completable.</span></div><div class="line">    delayedFetchPurgatory.tryCompleteElseWatch(delayedFetch, delayedFetchKeys)</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>整体来说，分为以下几步：</p>
<ol>
<li><code>readFromLocalLog()</code>：调用该方法，从本地日志拉取相应的数据；</li>
<li>判断 Fetch 请求来源，如果来自副本同步，那么更新该副本的 the end offset 记录，如果该副本不在 isr 中，并判断是否需要更新 isr；</li>
<li>返回结果，满足条件的话立马返回，否则的话，通过延迟操作，延迟返回结果。</li>
</ol>
<h4 id="readFromLocalLog"><a href="#readFromLocalLog" class="headerlink" title="readFromLocalLog"></a>readFromLocalLog</h4><p><code>readFromLocalLog()</code> 方法的实现如下：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div><div class="line">113</div><div class="line">114</div><div class="line">115</div><div class="line">116</div><div class="line">117</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/**</span></div><div class="line"> * Read from multiple topic partitions at the given offset up to maxSize bytes</div><div class="line"> */</div><div class="line"><span class="comment">//note: 按 offset 从 tp 列表中读取相应的数据</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">readFromLocalLog</span></span>(replicaId: <span class="type">Int</span>,</div><div class="line">                     fetchOnlyFromLeader: <span class="type">Boolean</span>,</div><div class="line">                     readOnlyCommitted: <span class="type">Boolean</span>,</div><div class="line">                     fetchMaxBytes: <span class="type">Int</span>,</div><div class="line">                     hardMaxBytesLimit: <span class="type">Boolean</span>,</div><div class="line">                     readPartitionInfo: <span class="type">Seq</span>[(<span class="type">TopicPartition</span>, <span class="type">PartitionData</span>)],</div><div class="line">                     quota: <span class="type">ReplicaQuota</span>): <span class="type">Seq</span>[(<span class="type">TopicPartition</span>, <span class="type">LogReadResult</span>)] = &#123;</div><div class="line"></div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">read</span></span>(tp: <span class="type">TopicPartition</span>, fetchInfo: <span class="type">PartitionData</span>, limitBytes: <span class="type">Int</span>, minOneMessage: <span class="type">Boolean</span>): <span class="type">LogReadResult</span> = &#123;</div><div class="line">    <span class="keyword">val</span> offset = fetchInfo.offset</div><div class="line">    <span class="keyword">val</span> partitionFetchSize = fetchInfo.maxBytes</div><div class="line"></div><div class="line">    <span class="type">BrokerTopicStats</span>.getBrokerTopicStats(tp.topic).totalFetchRequestRate.mark()</div><div class="line">    <span class="type">BrokerTopicStats</span>.getBrokerAllTopicsStats().totalFetchRequestRate.mark()</div><div class="line"></div><div class="line">    <span class="keyword">try</span> &#123;</div><div class="line">      trace(<span class="string">s"Fetching log segment for partition <span class="subst">$tp</span>, offset <span class="subst">$offset</span>, partition fetch size <span class="subst">$partitionFetchSize</span>, "</span> +</div><div class="line">        <span class="string">s"remaining response limit <span class="subst">$limitBytes</span>"</span> +</div><div class="line">        (<span class="keyword">if</span> (minOneMessage) <span class="string">s", ignoring response/partition size limits"</span> <span class="keyword">else</span> <span class="string">""</span>))</div><div class="line"></div><div class="line">      <span class="comment">// decide whether to only fetch from leader</span></div><div class="line">      <span class="comment">//note: 根据决定 [是否只从 leader 读取数据] 来获取相应的副本</span></div><div class="line">      <span class="comment">//note: 根据 tp 获取 Partition 对象, 在获取相应的 Replica 对象</span></div><div class="line">      <span class="keyword">val</span> localReplica = <span class="keyword">if</span> (fetchOnlyFromLeader)</div><div class="line">        getLeaderReplicaIfLocal(tp)</div><div class="line">      <span class="keyword">else</span></div><div class="line">        getReplicaOrException(tp)</div><div class="line"></div><div class="line">      <span class="comment">// decide whether to only fetch committed data (i.e. messages below high watermark)</span></div><div class="line">      <span class="comment">//note: 获取 hw 位置，副本同步不设置这个值</span></div><div class="line">      <span class="keyword">val</span> maxOffsetOpt = <span class="keyword">if</span> (readOnlyCommitted)</div><div class="line">        <span class="type">Some</span>(localReplica.highWatermark.messageOffset)</div><div class="line">      <span class="keyword">else</span></div><div class="line">        <span class="type">None</span></div><div class="line"></div><div class="line">      <span class="comment">/* Read the LogOffsetMetadata prior to performing the read from the log.</span></div><div class="line">       * We use the LogOffsetMetadata to determine if a particular replica is in-sync or not.</div><div class="line">       * Using the log end offset after performing the read can lead to a race condition</div><div class="line">       * where data gets appended to the log immediately after the replica has consumed from it</div><div class="line">       * This can cause a replica to always be out of sync.</div><div class="line">       */</div><div class="line">      <span class="keyword">val</span> initialLogEndOffset = localReplica.logEndOffset.messageOffset <span class="comment">//note: the end offset</span></div><div class="line">      <span class="keyword">val</span> initialHighWatermark = localReplica.highWatermark.messageOffset <span class="comment">//note: hw</span></div><div class="line">      <span class="keyword">val</span> fetchTimeMs = time.milliseconds</div><div class="line">      <span class="keyword">val</span> logReadInfo = localReplica.log <span class="keyword">match</span> &#123;</div><div class="line">        <span class="keyword">case</span> <span class="type">Some</span>(log) =&gt;</div><div class="line">          <span class="keyword">val</span> adjustedFetchSize = math.min(partitionFetchSize, limitBytes)</div><div class="line"></div><div class="line">          <span class="comment">// Try the read first, this tells us whether we need all of adjustedFetchSize for this partition</span></div><div class="line">          <span class="comment">//note: 从指定的 offset 位置开始读取数据，副本同步不需要 maxOffsetOpt</span></div><div class="line">          <span class="keyword">val</span> fetch = log.read(offset, adjustedFetchSize, maxOffsetOpt, minOneMessage)</div><div class="line"></div><div class="line">          <span class="comment">// If the partition is being throttled, simply return an empty set.</span></div><div class="line">          <span class="keyword">if</span> (shouldLeaderThrottle(quota, tp, replicaId)) <span class="comment">//note: 如果被限速了,那么返回 空 集合</span></div><div class="line">            <span class="type">FetchDataInfo</span>(fetch.fetchOffsetMetadata, <span class="type">MemoryRecords</span>.<span class="type">EMPTY</span>)</div><div class="line">          <span class="comment">// For FetchRequest version 3, we replace incomplete message sets with an empty one as consumers can make</span></div><div class="line">          <span class="comment">// progress in such cases and don't need to report a `RecordTooLargeException`</span></div><div class="line">          <span class="keyword">else</span> <span class="keyword">if</span> (!hardMaxBytesLimit &amp;&amp; fetch.firstEntryIncomplete)</div><div class="line">            <span class="type">FetchDataInfo</span>(fetch.fetchOffsetMetadata, <span class="type">MemoryRecords</span>.<span class="type">EMPTY</span>)</div><div class="line">          <span class="keyword">else</span> fetch</div><div class="line"></div><div class="line">        <span class="keyword">case</span> <span class="type">None</span> =&gt;</div><div class="line">          error(<span class="string">s"Leader for partition <span class="subst">$tp</span> does not have a local log"</span>)</div><div class="line">          <span class="type">FetchDataInfo</span>(<span class="type">LogOffsetMetadata</span>.<span class="type">UnknownOffsetMetadata</span>, <span class="type">MemoryRecords</span>.<span class="type">EMPTY</span>)</div><div class="line">      &#125;</div><div class="line"></div><div class="line">      <span class="comment">//note: 返回最后的结果,返回的都是 LogReadResult 对象</span></div><div class="line">      <span class="type">LogReadResult</span>(info = logReadInfo,</div><div class="line">                    hw = initialHighWatermark,</div><div class="line">                    leaderLogEndOffset = initialLogEndOffset,</div><div class="line">                    fetchTimeMs = fetchTimeMs,</div><div class="line">                    readSize = partitionFetchSize,</div><div class="line">                    exception = <span class="type">None</span>)</div><div class="line">    &#125; <span class="keyword">catch</span> &#123;</div><div class="line">      <span class="comment">// <span class="doctag">NOTE:</span> Failed fetch requests metric is not incremented for known exceptions since it</span></div><div class="line">      <span class="comment">// is supposed to indicate un-expected failure of a broker in handling a fetch request</span></div><div class="line">      <span class="keyword">case</span> e@ (_: <span class="type">UnknownTopicOrPartitionException</span> |</div><div class="line">               _: <span class="type">NotLeaderForPartitionException</span> |</div><div class="line">               _: <span class="type">ReplicaNotAvailableException</span> |</div><div class="line">               _: <span class="type">OffsetOutOfRangeException</span>) =&gt;</div><div class="line">        <span class="type">LogReadResult</span>(info = <span class="type">FetchDataInfo</span>(<span class="type">LogOffsetMetadata</span>.<span class="type">UnknownOffsetMetadata</span>, <span class="type">MemoryRecords</span>.<span class="type">EMPTY</span>),</div><div class="line">                      hw = <span class="number">-1</span>L,</div><div class="line">                      leaderLogEndOffset = <span class="number">-1</span>L,</div><div class="line">                      fetchTimeMs = <span class="number">-1</span>L,</div><div class="line">                      readSize = partitionFetchSize,</div><div class="line">                      exception = <span class="type">Some</span>(e))</div><div class="line">      <span class="keyword">case</span> e: <span class="type">Throwable</span> =&gt;</div><div class="line">        <span class="type">BrokerTopicStats</span>.getBrokerTopicStats(tp.topic).failedFetchRequestRate.mark()</div><div class="line">        <span class="type">BrokerTopicStats</span>.getBrokerAllTopicsStats().failedFetchRequestRate.mark()</div><div class="line">        error(<span class="string">s"Error processing fetch operation on partition <span class="subst">$tp</span>, offset <span class="subst">$offset</span>"</span>, e)</div><div class="line">        <span class="type">LogReadResult</span>(info = <span class="type">FetchDataInfo</span>(<span class="type">LogOffsetMetadata</span>.<span class="type">UnknownOffsetMetadata</span>, <span class="type">MemoryRecords</span>.<span class="type">EMPTY</span>),</div><div class="line">                      hw = <span class="number">-1</span>L,</div><div class="line">                      leaderLogEndOffset = <span class="number">-1</span>L,</div><div class="line">                      fetchTimeMs = <span class="number">-1</span>L,</div><div class="line">                      readSize = partitionFetchSize,</div><div class="line">                      exception = <span class="type">Some</span>(e))</div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  <span class="keyword">var</span> limitBytes = fetchMaxBytes</div><div class="line">  <span class="keyword">val</span> result = <span class="keyword">new</span> mutable.<span class="type">ArrayBuffer</span>[(<span class="type">TopicPartition</span>, <span class="type">LogReadResult</span>)]</div><div class="line">  <span class="keyword">var</span> minOneMessage = !hardMaxBytesLimit</div><div class="line">  readPartitionInfo.foreach &#123; <span class="keyword">case</span> (tp, fetchInfo) =&gt;</div><div class="line">    <span class="keyword">val</span> readResult = read(tp, fetchInfo, limitBytes, minOneMessage) <span class="comment">//note: 读取该 tp 的数据</span></div><div class="line">    <span class="keyword">val</span> messageSetSize = readResult.info.records.sizeInBytes</div><div class="line">    <span class="comment">// Once we read from a non-empty partition, we stop ignoring request and partition level size limits</span></div><div class="line">    <span class="keyword">if</span> (messageSetSize &gt; <span class="number">0</span>)</div><div class="line">      minOneMessage = <span class="literal">false</span></div><div class="line">    limitBytes = math.max(<span class="number">0</span>, limitBytes - messageSetSize)</div><div class="line">    result += (tp -&gt; readResult)</div><div class="line">  &#125;</div><div class="line">  result</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p><code>readFromLocalLog()</code> 方法的处理过程：</p>
<ol>
<li>先根据要拉取的 topic-partition 获取对应的 Partition 对象，根据 Partition 对象获取对应的 Replica 对象；</li>
<li>根据 Replica 对象找到对应的 Log 对象，然后调用其 <code>read()</code> 方法从指定的位置读取数据。</li>
</ol>
<h2 id="存储层对-Fetch-请求的处理"><a href="#存储层对-Fetch-请求的处理" class="headerlink" title="存储层对 Fetch 请求的处理"></a>存储层对 Fetch 请求的处理</h2><p>接着前面的流程开始往下走。</p>
<h3 id="Log-对象"><a href="#Log-对象" class="headerlink" title="Log 对象"></a>Log 对象</h3><p>每个 Replica 会对应一个 log 对象，而每个 log 对象会管理相应的 LogSegment 实例。</p>
<h4 id="read"><a href="#read" class="headerlink" title="read()"></a>read()</h4><p>Log 对象的 <code>read()</code> 方法的实现如下所示：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//note: 从指定 offset 开始读取数据</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">read</span></span>(startOffset: <span class="type">Long</span>, maxLength: <span class="type">Int</span>, maxOffset: <span class="type">Option</span>[<span class="type">Long</span>] = <span class="type">None</span>, minOneMessage: <span class="type">Boolean</span> = <span class="literal">false</span>): <span class="type">FetchDataInfo</span> = &#123;</div><div class="line">  trace(<span class="string">"Reading %d bytes from offset %d in log %s of length %d bytes"</span>.format(maxLength, startOffset, name, size))</div><div class="line"></div><div class="line">  <span class="comment">// Because we don't use lock for reading, the synchronization is a little bit tricky.</span></div><div class="line">  <span class="comment">// We create the local variables to avoid race conditions with updates to the log.</span></div><div class="line">  <span class="keyword">val</span> currentNextOffsetMetadata = nextOffsetMetadata</div><div class="line">  <span class="keyword">val</span> next = currentNextOffsetMetadata.messageOffset</div><div class="line">  <span class="keyword">if</span>(startOffset == next)</div><div class="line">    <span class="keyword">return</span> <span class="type">FetchDataInfo</span>(currentNextOffsetMetadata, <span class="type">MemoryRecords</span>.<span class="type">EMPTY</span>)</div><div class="line"></div><div class="line">  <span class="comment">//note: 先查找对应的日志分段（segment）</span></div><div class="line">  <span class="keyword">var</span> entry = segments.floorEntry(startOffset)</div><div class="line"></div><div class="line">  <span class="comment">// attempt to read beyond the log end offset is an error</span></div><div class="line">  <span class="keyword">if</span>(startOffset &gt; next || entry == <span class="literal">null</span>)</div><div class="line">    <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">OffsetOutOfRangeException</span>(<span class="string">"Request for offset %d but we only have log segments in the range %d to %d."</span>.format(startOffset, segments.firstKey, next))</div><div class="line"></div><div class="line">  <span class="comment">// Do the read on the segment with a base offset less than the target offset</span></div><div class="line">  <span class="comment">// but if that segment doesn't contain any messages with an offset greater than that</span></div><div class="line">  <span class="comment">// continue to read from successive segments until we get some messages or we reach the end of the log</span></div><div class="line">  <span class="keyword">while</span>(entry != <span class="literal">null</span>) &#123;</div><div class="line">    <span class="comment">// If the fetch occurs on the active segment, there might be a race condition where two fetch requests occur after</span></div><div class="line">    <span class="comment">// the message is appended but before the nextOffsetMetadata is updated. In that case the second fetch may</span></div><div class="line">    <span class="comment">// cause OffsetOutOfRangeException. To solve that, we cap the reading up to exposed position instead of the log</span></div><div class="line">    <span class="comment">// end of the active segment.</span></div><div class="line">    <span class="comment">//note: 如果 Fetch 请求刚好发生在 the active segment 上,当多个 Fetch 请求同时处理,如果 nextOffsetMetadata 更新不及时,可能会导致</span></div><div class="line">    <span class="comment">//note: 发送 OffsetOutOfRangeException 异常; 为了解决这个问题, 这里能读取的最大位置是对应的物理位置（exposedPos）</span></div><div class="line">    <span class="comment">//note: 而不是 the log end of the active segment.</span></div><div class="line">    <span class="keyword">val</span> maxPosition = &#123;</div><div class="line">      <span class="keyword">if</span> (entry == segments.lastEntry) &#123;</div><div class="line">        <span class="comment">//note: nextOffsetMetadata 对应的实际物理位置</span></div><div class="line">        <span class="keyword">val</span> exposedPos = nextOffsetMetadata.relativePositionInSegment.toLong</div><div class="line">        <span class="comment">// Check the segment again in case a new segment has just rolled out.</span></div><div class="line">        <span class="keyword">if</span> (entry != segments.lastEntry) <span class="comment">//note: 可能会有新的 segment 产生,所以需要再次判断</span></div><div class="line">          <span class="comment">// New log segment has rolled out, we can read up to the file end.</span></div><div class="line">          entry.getValue.size</div><div class="line">        <span class="keyword">else</span></div><div class="line">          exposedPos</div><div class="line">      &#125; <span class="keyword">else</span> &#123;</div><div class="line">        entry.getValue.size</div><div class="line">      &#125;</div><div class="line">    &#125;</div><div class="line">    <span class="comment">//note: 从 segment 中读取相应的数据</span></div><div class="line">    <span class="keyword">val</span> fetchInfo = entry.getValue.read(startOffset, maxOffset, maxLength, maxPosition, minOneMessage)</div><div class="line">    <span class="keyword">if</span>(fetchInfo == <span class="literal">null</span>) &#123; <span class="comment">//note: 如果该日志分段没有读取到数据,则读取更高的日志分段</span></div><div class="line">      entry = segments.higherEntry(entry.getKey)</div><div class="line">    &#125; <span class="keyword">else</span> &#123;</div><div class="line">      <span class="keyword">return</span> fetchInfo</div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  <span class="comment">// okay we are beyond the end of the last segment with no data fetched although the start offset is in range,</span></div><div class="line">  <span class="comment">// this can happen when all messages with offset larger than start offsets have been deleted.</span></div><div class="line">  <span class="comment">// In this case, we will return the empty set with log end offset metadata</span></div><div class="line">  <span class="type">FetchDataInfo</span>(nextOffsetMetadata, <span class="type">MemoryRecords</span>.<span class="type">EMPTY</span>)</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>从实现可以看出，该方法会先查找对应的 Segment 对象（日志分段），然后循环直到读取到数据结束，如果当前的日志分段没有读取到相应的数据，那么会更新日志分段及对应的最大位置。</p>
<p>日志分段实际上是逻辑概念，它管理了物理概念的一个数据文件、一个时间索引文件和一个 offset 索引文件，读取日志分段时，会先读取 offset 索引文件再读取数据文件，具体步骤如下：</p>
<ol>
<li>根据要读取的起始偏移量（startOffset）读取 offset 索引文件中对应的物理位置；</li>
<li>查找 offset 索引文件最后返回：起始偏移量对应的最近物理位置（startPosition）；</li>
<li>根据 startPosition 直接定位到数据文件，然后读取数据文件内容；</li>
<li>最多能读到数据文件的结束位置（maxPosition）。</li>
</ol>
<h3 id="LogSegment"><a href="#LogSegment" class="headerlink" title="LogSegment"></a>LogSegment</h3><p>关乎 数据文件、offset 索引文件和时间索引文件真正的操作都是在 LogSegment 对象中的，日志读取也与这个方法息息相关。</p>
<h4 id="read-1"><a href="#read-1" class="headerlink" title="read()"></a>read()</h4><p><code>read()</code> 方法的实现如下：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//note: 读取日志分段（副本同步不会设置 maxSize）</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">read</span></span>(startOffset: <span class="type">Long</span>, maxOffset: <span class="type">Option</span>[<span class="type">Long</span>], maxSize: <span class="type">Int</span>, maxPosition: <span class="type">Long</span> = size,</div><div class="line">         minOneMessage: <span class="type">Boolean</span> = <span class="literal">false</span>): <span class="type">FetchDataInfo</span> = &#123;</div><div class="line">  <span class="keyword">if</span> (maxSize &lt; <span class="number">0</span>)</div><div class="line">    <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">IllegalArgumentException</span>(<span class="string">"Invalid max size for log read (%d)"</span>.format(maxSize))</div><div class="line"></div><div class="line">  <span class="comment">//note: log 文件物理长度</span></div><div class="line">  <span class="keyword">val</span> logSize = log.sizeInBytes <span class="comment">// this may change, need to save a consistent copy</span></div><div class="line">  <span class="comment">//note: 将起始的 offset 转换为起始的实际物理位置</span></div><div class="line">  <span class="keyword">val</span> startOffsetAndSize = translateOffset(startOffset)</div><div class="line"></div><div class="line">  <span class="comment">// if the start position is already off the end of the log, return null</span></div><div class="line">  <span class="keyword">if</span> (startOffsetAndSize == <span class="literal">null</span>)</div><div class="line">    <span class="keyword">return</span> <span class="literal">null</span></div><div class="line"></div><div class="line">  <span class="keyword">val</span> startPosition = startOffsetAndSize.position.toInt</div><div class="line">  <span class="keyword">val</span> offsetMetadata = <span class="keyword">new</span> <span class="type">LogOffsetMetadata</span>(startOffset, <span class="keyword">this</span>.baseOffset, startPosition)</div><div class="line"></div><div class="line">  <span class="keyword">val</span> adjustedMaxSize =</div><div class="line">    <span class="keyword">if</span> (minOneMessage) math.max(maxSize, startOffsetAndSize.size)</div><div class="line">    <span class="keyword">else</span> maxSize</div><div class="line"></div><div class="line">  <span class="comment">// return a log segment but with zero size in the case below</span></div><div class="line">  <span class="keyword">if</span> (adjustedMaxSize == <span class="number">0</span>)</div><div class="line">    <span class="keyword">return</span> <span class="type">FetchDataInfo</span>(offsetMetadata, <span class="type">MemoryRecords</span>.<span class="type">EMPTY</span>)</div><div class="line"></div><div class="line">  <span class="comment">// calculate the length of the message set to read based on whether or not they gave us a maxOffset</span></div><div class="line">  <span class="comment">//note: 计算读取的长度</span></div><div class="line">  <span class="keyword">val</span> length = maxOffset <span class="keyword">match</span> &#123;</div><div class="line">    <span class="comment">//note: 副本同步时的计算方式</span></div><div class="line">    <span class="keyword">case</span> <span class="type">None</span> =&gt;</div><div class="line">      <span class="comment">// no max offset, just read until the max position</span></div><div class="line">      min((maxPosition - startPosition).toInt, adjustedMaxSize) <span class="comment">//note: 直接读取到最大的位置</span></div><div class="line">    <span class="comment">//note: consumer 拉取时,计算方式</span></div><div class="line">    <span class="keyword">case</span> <span class="type">Some</span>(offset) =&gt;</div><div class="line">      <span class="comment">// there is a max offset, translate it to a file position and use that to calculate the max read size;</span></div><div class="line">      <span class="comment">// when the leader of a partition changes, it's possible for the new leader's high watermark to be less than the</span></div><div class="line">      <span class="comment">// true high watermark in the previous leader for a short window. In this window, if a consumer fetches on an</span></div><div class="line">      <span class="comment">// offset between new leader's high watermark and the log end offset, we want to return an empty response.</span></div><div class="line">      <span class="keyword">if</span> (offset &lt; startOffset)</div><div class="line">        <span class="keyword">return</span> <span class="type">FetchDataInfo</span>(offsetMetadata, <span class="type">MemoryRecords</span>.<span class="type">EMPTY</span>, firstEntryIncomplete = <span class="literal">false</span>)</div><div class="line">      <span class="keyword">val</span> mapping = translateOffset(offset, startPosition)</div><div class="line">      <span class="keyword">val</span> endPosition =</div><div class="line">        <span class="keyword">if</span> (mapping == <span class="literal">null</span>)</div><div class="line">          logSize <span class="comment">// the max offset is off the end of the log, use the end of the file</span></div><div class="line">        <span class="keyword">else</span></div><div class="line">          mapping.position</div><div class="line">      min(min(maxPosition, endPosition) - startPosition, adjustedMaxSize).toInt</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  <span class="comment">//note: 根据起始的物理位置和读取长度读取数据文件</span></div><div class="line">  <span class="type">FetchDataInfo</span>(offsetMetadata, log.read(startPosition, length),</div><div class="line">    firstEntryIncomplete = adjustedMaxSize &lt; startOffsetAndSize.size)</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>从上面的实现来看，上述过程分为以下三部分：</p>
<ol>
<li>根据 startOffset 得到实际的物理位置（<code>translateOffset()</code>）；</li>
<li>计算要读取的实际物理长度；</li>
<li>根据实际起始物理位置和要读取实际物理长度读取数据文件。</li>
</ol>
<h4 id="translateOffset"><a href="#translateOffset" class="headerlink" title="translateOffset()"></a>translateOffset()</h4><p><code>translateOffset()</code> 方法的实现过程主要分为两部分：</p>
<ol>
<li>查找 offset 索引文件：调用 offset 索引文件的 <code>lookup()</code> 查找方法，获取离 startOffset 最接近的物理位置；</li>
<li>调用数据文件的 <code>searchFor()</code> 方法，从指定的物理位置开始读取每条数据，知道找到对应 offset 的物理位置。</li>
</ol>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">private</span>[log] <span class="function"><span class="keyword">def</span> <span class="title">translateOffset</span></span>(offset: <span class="type">Long</span>, startingFilePosition: <span class="type">Int</span> = <span class="number">0</span>): <span class="type">LogEntryPosition</span> = &#123;</div><div class="line">  <span class="comment">//note: 获取离 offset 最新的物理位置,返回包括 offset 和物理位置（不是准确值）</span></div><div class="line">  <span class="keyword">val</span> mapping = index.lookup(offset)</div><div class="line">  <span class="comment">//note: 从指定的位置开始消费,直到找到 offset 对应的实际物理位置,返回包括 offset 和物理位置（准确值）</span></div><div class="line">  log.searchForOffsetWithSize(offset, max(mapping.position, startingFilePosition))</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h5 id="查找-offset-索引文件"><a href="#查找-offset-索引文件" class="headerlink" title="查找 offset 索引文件"></a>查找 offset 索引文件</h5><p>offset 索引文件是使用内存映射（不了解的，可以阅读 <a href="http://matt33.com/2018/02/04/linux-mmap/">操作系统之共享对象学习</a>）的方式加载到内存中的，在查询的过程中，内存映射是会发生变化，所以在 <code>lookup()</code> 中先拷贝出来了一个（idx），然后再进行查询，具体实现如下：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//note: 查找小于等于指定 offset 的最大 offset,并且返回对应的 offset 和实际物理位置</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">lookup</span></span>(targetOffset: <span class="type">Long</span>): <span class="type">OffsetPosition</span> = &#123;</div><div class="line">  maybeLock(lock) &#123;</div><div class="line">    <span class="keyword">val</span> idx = mmap.duplicate <span class="comment">//note: 查询时,mmap 会发生变化,先复制出来一个</span></div><div class="line">    <span class="keyword">val</span> slot = indexSlotFor(idx, targetOffset, <span class="type">IndexSearchType</span>.<span class="type">KEY</span>) <span class="comment">//note: 二分查找</span></div><div class="line">    <span class="keyword">if</span>(slot == <span class="number">-1</span>)</div><div class="line">      <span class="type">OffsetPosition</span>(baseOffset, <span class="number">0</span>)</div><div class="line">    <span class="keyword">else</span></div><div class="line">      <span class="comment">//note: 先计算绝对偏移量,再计算物理位置</span></div><div class="line">      parseEntry(idx, slot).asInstanceOf[<span class="type">OffsetPosition</span>]</div><div class="line">  &#125;</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">parseEntry</span></span>(buffer: <span class="type">ByteBuffer</span>, n: <span class="type">Int</span>): <span class="type">IndexEntry</span> = &#123;</div><div class="line">    <span class="type">OffsetPosition</span>(baseOffset + relativeOffset(buffer, n), physical(buffer, n))</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">relativeOffset</span></span>(buffer: <span class="type">ByteBuffer</span>, n: <span class="type">Int</span>): <span class="type">Int</span> = buffer.getInt(n * entrySize)</div><div class="line"></div><div class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">physical</span></span>(buffer: <span class="type">ByteBuffer</span>, n: <span class="type">Int</span>): <span class="type">Int</span> = buffer.getInt(n * entrySize + <span class="number">4</span>)</div></pre></td></tr></table></figure>
<p>关于 relativeOffset 和 physical 的计算方法，可以参考下面这张图（来自《Kafka 计算内幕》）：</p>
<p><img src="/images/kafka/offset-physical.png" alt="根据索引条目编号查找偏移量的值和物理位置的值"></p>
<h5 id="搜索数据文件获取准确的物理位置"><a href="#搜索数据文件获取准确的物理位置" class="headerlink" title="搜索数据文件获取准确的物理位置"></a>搜索数据文件获取准确的物理位置</h5><p>前面通过 offset 索引文件获取的物理位置是一个接近值，下面通过实际读取数据文件将会得到一个真正的准确值，它是通过遍历数据文件实现的。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/**</span></div><div class="line"> * Search forward for the file position of the last offset that is greater than or equal to the target offset</div><div class="line"> * and return its physical position and the size of the message (including log overhead) at the returned offset. If</div><div class="line"> * no such offsets are found, return null.</div><div class="line"> *</div><div class="line"> * @param targetOffset The offset to search for.</div><div class="line"> * @param startingPosition The starting position in the file to begin searching from.</div><div class="line"> */</div><div class="line">public <span class="type">LogEntryPosition</span> searchForOffsetWithSize(long targetOffset, int startingPosition) &#123;</div><div class="line">    <span class="keyword">for</span> (<span class="type">FileChannelLogEntry</span> entry : shallowEntriesFrom(startingPosition)) &#123;</div><div class="line">        long offset = entry.offset();</div><div class="line">        <span class="keyword">if</span> (offset &gt;= targetOffset)</div><div class="line">            <span class="keyword">return</span> <span class="keyword">new</span> <span class="type">LogEntryPosition</span>(offset, entry.position(), entry.sizeInBytes());</div><div class="line">    &#125;</div><div class="line">    <span class="keyword">return</span> <span class="literal">null</span>;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>到这里，一个 Fetch 请求的处理过程算是完成了。</p>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[Kafka 源码解析之 Server 端如何处理 Produce 请求（十二）]]></title>
      <url>http://matt33.com/2018/03/18/kafka-server-handle-produce-request/</url>
      <content type="html"><![CDATA[<p>这部分想了很久应该怎么去写才能更容易让大家明白，本来是计划先把 Kafka 存储层 Log 这块的写操作处理流程先详细介绍一下，但是这块属于比较底层的部分，大家可能对于这部分在整个处理过程处在哪个位置并不是很清楚，所以还是准备以 Server 端如何处理 Producer Client 的 Produce 请求为入口。但是 Server 端的内容较多，本篇文章并不能全部涵盖，涉及到其他内容，在本篇文章暂时先不详细讲述，后面会再分析，本篇文章会以 Server 处理 produce 为主线，主要详细讲解 Kafka 存储层的内容。</p>
<h2 id="produce-请求处理整体流程"><a href="#produce-请求处理整体流程" class="headerlink" title="produce 请求处理整体流程"></a>produce 请求处理整体流程</h2><p>根据在这篇 <a href="http://matt33.com/2017/06/25/kafka-producer-send-module/">Kafka 源码解析之 Producer 发送模型（一）</a> 中的讲解，在 Producer Client 端，Producer 会维护一个 <code>ConcurrentMap&lt;TopicPartition, Deque&lt;RecordBatch&gt;&gt; batches</code> 的变量，然后会根据 topic-partition 的 leader 信息，将 leader 在同一台机器上的 batch 放在一个 request 中，发送到 server，这样可以节省很多网络开销，提高发送效率。</p>
<p>Producer Client 发送请求的方法实现如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//<span class="doctag">NOTE:</span> 发送 produce 请求</span></div><div class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">sendProduceRequest</span><span class="params">(<span class="keyword">long</span> now, <span class="keyword">int</span> destination, <span class="keyword">short</span> acks, <span class="keyword">int</span> timeout, List&lt;RecordBatch&gt; batches)</span> </span>&#123;</div><div class="line">    Map&lt;TopicPartition, MemoryRecords&gt; produceRecordsByPartition = <span class="keyword">new</span> HashMap&lt;&gt;(batches.size());</div><div class="line">    <span class="keyword">final</span> Map&lt;TopicPartition, RecordBatch&gt; recordsByPartition = <span class="keyword">new</span> HashMap&lt;&gt;(batches.size());</div><div class="line">    <span class="keyword">for</span> (RecordBatch batch : batches) &#123;</div><div class="line">        TopicPartition tp = batch.topicPartition;</div><div class="line">        produceRecordsByPartition.put(tp, batch.records());</div><div class="line">        recordsByPartition.put(tp, batch);</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    ProduceRequest.Builder requestBuilder =</div><div class="line">            <span class="keyword">new</span> ProduceRequest.Builder(acks, timeout, produceRecordsByPartition);</div><div class="line">    RequestCompletionHandler callback = <span class="keyword">new</span> RequestCompletionHandler() &#123;</div><div class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onComplete</span><span class="params">(ClientResponse response)</span> </span>&#123;</div><div class="line">            handleProduceResponse(response, recordsByPartition, time.milliseconds());</div><div class="line">        &#125;</div><div class="line">    &#125;;</div><div class="line"></div><div class="line">    String nodeId = Integer.toString(destination);</div><div class="line">    ClientRequest clientRequest = client.newClientRequest(nodeId, requestBuilder, now, acks != <span class="number">0</span>, callback);</div><div class="line">    client.send(clientRequest, now);</div><div class="line">    log.trace(<span class="string">"Sent produce request to &#123;&#125;: &#123;&#125;"</span>, nodeId, requestBuilder);</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>在发送 Produce 的请求里，Client 是把一个 <code>Map&lt;TopicPartition, MemoryRecords&gt;</code> 类型的 <code>produceRecordsByPartition</code> 作为内容发送给了 Server 端，那么 Server 端是如何处理这个请求的呢？这就是本篇文章要讲述的内容，Server 处理这个请求的总体逻辑如下图所示：</p>
<p><img src="/images/kafka/kafka_produce_process.png" alt="Server 端处理 produce 请求的总体过程"></p>
<p>Broker 在收到 Produce 请求后，会有一个 KafkaApis 进行处理，KafkaApis 是 Server 端处理所有请求的入口，它会负责将请求的具体处理交给相应的组件进行处理，从上图可以看到 Produce 请求是交给了 ReplicaManager 对象进行处理了。</p>
<h2 id="Server-端处理"><a href="#Server-端处理" class="headerlink" title="Server 端处理"></a>Server 端处理</h2><p>Server 端的处理过程会按照上图的流程一块一块去介绍。</p>
<h3 id="KafkaApis-处理-Produce-请求"><a href="#KafkaApis-处理-Produce-请求" class="headerlink" title="KafkaApis 处理 Produce 请求"></a>KafkaApis 处理 Produce 请求</h3><p>KafkaApis 处理 produce 请求是在 <code>handleProducerRequest()</code> 方法中完成，具体实现如下：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/**</span></div><div class="line"> * Handle a produce request</div><div class="line"> */</div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">handleProducerRequest</span></span>(request: <span class="type">RequestChannel</span>.<span class="type">Request</span>) &#123;</div><div class="line">  <span class="keyword">val</span> produceRequest = request.body.asInstanceOf[<span class="type">ProduceRequest</span>]</div><div class="line">  <span class="keyword">val</span> numBytesAppended = request.header.sizeOf + produceRequest.sizeOf</div><div class="line"></div><div class="line">  <span class="comment">//note: 按 exist 和有 Describe 权限进行筛选</span></div><div class="line">  <span class="keyword">val</span> (existingAndAuthorizedForDescribeTopics, nonExistingOrUnauthorizedForDescribeTopics) = produceRequest.partitionRecords.asScala.partition &#123;</div><div class="line">    <span class="keyword">case</span> (topicPartition, _) =&gt; authorize(request.session, <span class="type">Describe</span>, <span class="keyword">new</span> <span class="type">Resource</span>(auth.<span class="type">Topic</span>, topicPartition.topic)) &amp;&amp; metadataCache.contains(topicPartition.topic)</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  <span class="comment">//note: 判断有没有 Write 权限</span></div><div class="line">  <span class="keyword">val</span> (authorizedRequestInfo, unauthorizedForWriteRequestInfo) = existingAndAuthorizedForDescribeTopics.partition &#123;</div><div class="line">    <span class="keyword">case</span> (topicPartition, _) =&gt; authorize(request.session, <span class="type">Write</span>, <span class="keyword">new</span> <span class="type">Resource</span>(auth.<span class="type">Topic</span>, topicPartition.topic))</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  <span class="comment">// the callback for sending a produce response</span></div><div class="line">  <span class="comment">//note: 回调函数</span></div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">sendResponseCallback</span></span>(responseStatus: <span class="type">Map</span>[<span class="type">TopicPartition</span>, <span class="type">PartitionResponse</span>]) &#123;</div><div class="line"></div><div class="line">    <span class="keyword">val</span> mergedResponseStatus = responseStatus ++</div><div class="line">      unauthorizedForWriteRequestInfo.mapValues(_ =&gt; <span class="keyword">new</span> <span class="type">PartitionResponse</span>(<span class="type">Errors</span>.<span class="type">TOPIC_AUTHORIZATION_FAILED</span>)) ++</div><div class="line">      nonExistingOrUnauthorizedForDescribeTopics.mapValues(_ =&gt; <span class="keyword">new</span> <span class="type">PartitionResponse</span>(<span class="type">Errors</span>.<span class="type">UNKNOWN_TOPIC_OR_PARTITION</span>))</div><div class="line"></div><div class="line">    <span class="keyword">var</span> errorInResponse = <span class="literal">false</span></div><div class="line"></div><div class="line">    mergedResponseStatus.foreach &#123; <span class="keyword">case</span> (topicPartition, status) =&gt;</div><div class="line">      <span class="keyword">if</span> (status.error != <span class="type">Errors</span>.<span class="type">NONE</span>) &#123;</div><div class="line">        errorInResponse = <span class="literal">true</span></div><div class="line">        debug(<span class="string">"Produce request with correlation id %d from client %s on partition %s failed due to %s"</span>.format(</div><div class="line">          request.header.correlationId,</div><div class="line">          request.header.clientId,</div><div class="line">          topicPartition,</div><div class="line">          status.error.exceptionName))</div><div class="line">      &#125;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">produceResponseCallback</span></span>(delayTimeMs: <span class="type">Int</span>) &#123;</div><div class="line">      <span class="keyword">if</span> (produceRequest.acks == <span class="number">0</span>) &#123;</div><div class="line">        <span class="comment">// no operation needed if producer request.required.acks = 0; however, if there is any error in handling</span></div><div class="line">        <span class="comment">// the request, since no response is expected by the producer, the server will close socket server so that</span></div><div class="line">        <span class="comment">// the producer client will know that some error has happened and will refresh its metadata</span></div><div class="line">        <span class="comment">//note: 因为设置的 ack=0, 相当于 client 会默认发送成功了,如果 server 在处理的过程出现了错误,那么就会关闭 socket 连接来间接地通知 client</span></div><div class="line">        <span class="comment">//note: client 会重新刷新 meta,重新建立相应的连接</span></div><div class="line">        <span class="keyword">if</span> (errorInResponse) &#123;</div><div class="line">          <span class="keyword">val</span> exceptionsSummary = mergedResponseStatus.map &#123; <span class="keyword">case</span> (topicPartition, status) =&gt;</div><div class="line">            topicPartition -&gt; status.error.exceptionName</div><div class="line">          &#125;.mkString(<span class="string">", "</span>)</div><div class="line">          info(</div><div class="line">            <span class="string">s"Closing connection due to error during produce request with correlation id <span class="subst">$&#123;request.header.correlationId&#125;</span> "</span> +</div><div class="line">              <span class="string">s"from client id <span class="subst">$&#123;request.header.clientId&#125;</span> with ack=0\n"</span> +</div><div class="line">              <span class="string">s"Topic and partition to exceptions: <span class="subst">$exceptionsSummary</span>"</span></div><div class="line">          )</div><div class="line">          requestChannel.closeConnection(request.processor, request)</div><div class="line">        &#125; <span class="keyword">else</span> &#123;</div><div class="line">          requestChannel.noOperation(request.processor, request)</div><div class="line">        &#125;</div><div class="line">      &#125; <span class="keyword">else</span> &#123;</div><div class="line">        <span class="keyword">val</span> respBody = request.header.apiVersion <span class="keyword">match</span> &#123;</div><div class="line">          <span class="keyword">case</span> <span class="number">0</span> =&gt; <span class="keyword">new</span> <span class="type">ProduceResponse</span>(mergedResponseStatus.asJava)</div><div class="line">          <span class="keyword">case</span> version@(<span class="number">1</span> | <span class="number">2</span>) =&gt; <span class="keyword">new</span> <span class="type">ProduceResponse</span>(mergedResponseStatus.asJava, delayTimeMs, version)</div><div class="line">          <span class="comment">// This case shouldn't happen unless a new version of ProducerRequest is added without</span></div><div class="line">          <span class="comment">// updating this part of the code to handle it properly.</span></div><div class="line">          <span class="keyword">case</span> version =&gt; <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">IllegalArgumentException</span>(<span class="string">s"Version `<span class="subst">$version</span>` of ProduceRequest is not handled. Code must be updated."</span>)</div><div class="line">        &#125;</div><div class="line"></div><div class="line">        requestChannel.sendResponse(<span class="keyword">new</span> <span class="type">RequestChannel</span>.<span class="type">Response</span>(request, respBody))</div><div class="line">      &#125;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="comment">// When this callback is triggered, the remote API call has completed</span></div><div class="line">    request.apiRemoteCompleteTimeMs = time.milliseconds</div><div class="line"></div><div class="line">    quotas.produce.recordAndMaybeThrottle(</div><div class="line">      request.session.sanitizedUser,</div><div class="line">      request.header.clientId,</div><div class="line">      numBytesAppended,</div><div class="line">      produceResponseCallback)</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  <span class="keyword">if</span> (authorizedRequestInfo.isEmpty)</div><div class="line">    sendResponseCallback(<span class="type">Map</span>.empty)</div><div class="line">  <span class="keyword">else</span> &#123;</div><div class="line">    <span class="keyword">val</span> internalTopicsAllowed = request.header.clientId == <span class="type">AdminUtils</span>.<span class="type">AdminClientId</span></div><div class="line"></div><div class="line">    <span class="comment">// call the replica manager to append messages to the replicas</span></div><div class="line">    <span class="comment">//note: 追加 Record</span></div><div class="line">    replicaManager.appendRecords(</div><div class="line">      produceRequest.timeout.toLong,</div><div class="line">      produceRequest.acks,</div><div class="line">      internalTopicsAllowed,</div><div class="line">      authorizedRequestInfo,</div><div class="line">      sendResponseCallback)</div><div class="line"></div><div class="line">    <span class="comment">// if the request is put into the purgatory, it will have a held reference</span></div><div class="line">    <span class="comment">// and hence cannot be garbage collected; hence we clear its data here in</span></div><div class="line">    <span class="comment">// order to let GC re-claim its memory since it is already appended to log</span></div><div class="line">    produceRequest.clearPartitionRecords()</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>总体来说，处理过程是（在权限系统的情况下）：</p>
<ol>
<li>查看 topic 是否存在，以及 client 是否有相应的 Desribe 权限；</li>
<li>对于已经有 Describe 权限的 topic 查看是否有 Write 权限；</li>
<li>调用 <code>replicaManager.appendRecords()</code> 方法向有 Write 权限的 topic-partition 追加相应的 record。</li>
</ol>
<h3 id="ReplicaManager"><a href="#ReplicaManager" class="headerlink" title="ReplicaManager"></a>ReplicaManager</h3><p>ReplicaManager 顾名思义，它就是副本管理器，副本管理器的作用是管理这台 broker 上的所有副本（replica）。在 Kafka 中，每个副本（replica）都会跟日志实例（Log 对象）一一对应，一个副本会对应一个 Log 对象。</p>
<p>Kafka Server 在启动的时候，会创建 ReplicaManager 对象，如下所示。在 ReplicaManager 的构造方法中，它需要 LogManager 作为成员变量。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//kafka.server.KafkaServer</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">startup</span></span>() &#123;</div><div class="line">  <span class="keyword">try</span> &#123;</div><div class="line">    info(<span class="string">"starting"</span>)</div><div class="line">    <span class="comment">/* start replica manager */</span></div><div class="line">    replicaManager = <span class="keyword">new</span> <span class="type">ReplicaManager</span>(config, metrics, time, zkUtils, kafkaScheduler, logManager, isShuttingDown, quotaManagers.follower)</div><div class="line">    replicaManager.startup()</div><div class="line">  &#125;<span class="keyword">catch</span> &#123;</div><div class="line">    <span class="keyword">case</span> e: <span class="type">Throwable</span> =&gt;</div><div class="line">    fatal(<span class="string">"Fatal error during KafkaServer startup. Prepare to shutdown"</span>, e)</div><div class="line">    isStartingUp.set(<span class="literal">false</span>)</div><div class="line">    shutdown()</div><div class="line">    <span class="keyword">throw</span> e</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>ReplicaManager 的<strong>并不负责具体的日志创建，它只是管理 Broker 上的所有分区</strong>（也就是图中下一步的那个 Partition 对象）。在创建 Partition 对象时，它需要 ReplicaManager 的 logManager 对象，Partition 会通过这个 logManager 对象为每个 replica 创建对应的日志。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/**</span></div><div class="line"> * Data structure that represents a topic partition. The leader maintains the AR, ISR, CUR, RAR</div><div class="line"> */</div><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">Partition</span>(<span class="params">val topic: <span class="type">String</span>,</span></span></div><div class="line">                val partitionId: <span class="type">Int</span>,</div><div class="line">                time: <span class="type">Time</span>,</div><div class="line">                replicaManager: <span class="type">ReplicaManager</span>) <span class="keyword">extends</span> <span class="title">Logging</span> <span class="keyword">with</span> <span class="title">KafkaMetricsGroup</span> &#123;</div><div class="line">  <span class="keyword">val</span> topicPartition = <span class="keyword">new</span> <span class="type">TopicPartition</span>(topic, partitionId)</div><div class="line"></div><div class="line">  <span class="keyword">private</span> <span class="keyword">val</span> localBrokerId = replicaManager.config.brokerId</div><div class="line">  <span class="keyword">private</span> <span class="keyword">val</span> logManager = replicaManager.logManager <span class="comment">//note: 日志管理器</span></div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>ReplicaManager 与 LogManger 对比如下：</p>
<table>
<thead>
<tr>
<th></th>
<th>管理对象</th>
<th>组成部分</th>
</tr>
</thead>
<tbody>
<tr>
<td>日志管理器（LogManager）</td>
<td>日志（Log）</td>
<td>日志分段（LogSegment）</td>
</tr>
<tr>
<td>副本管理器（ReplicaManager）</td>
<td>分区（Partition）</td>
<td>副本（Replica）</td>
</tr>
</tbody>
</table>
<p>关于 ReplicaManager 后面还会介绍，这篇文章先不详细展开。</p>
<h4 id="appendRecords-实现"><a href="#appendRecords-实现" class="headerlink" title="appendRecords() 实现"></a><code>appendRecords()</code> 实现</h4><p>下面我们来看 <code>appendRecords()</code> 方法的具体实现。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//note: 向 partition 的 leader 写入数据</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">appendRecords</span></span>(timeout: <span class="type">Long</span>,</div><div class="line">                  requiredAcks: <span class="type">Short</span>,</div><div class="line">                  internalTopicsAllowed: <span class="type">Boolean</span>,</div><div class="line">                  entriesPerPartition: <span class="type">Map</span>[<span class="type">TopicPartition</span>, <span class="type">MemoryRecords</span>],</div><div class="line">                  responseCallback: <span class="type">Map</span>[<span class="type">TopicPartition</span>, <span class="type">PartitionResponse</span>] =&gt; <span class="type">Unit</span>) &#123;</div><div class="line"></div><div class="line">  <span class="keyword">if</span> (isValidRequiredAcks(requiredAcks)) &#123; <span class="comment">//note: acks 设置有效</span></div><div class="line">    <span class="keyword">val</span> sTime = time.milliseconds</div><div class="line">    <span class="comment">//note: 向本地的副本 log 追加数据</span></div><div class="line">    <span class="keyword">val</span> localProduceResults = appendToLocalLog(internalTopicsAllowed, entriesPerPartition, requiredAcks)</div><div class="line">    debug(<span class="string">"Produce to local log in %d ms"</span>.format(time.milliseconds - sTime))</div><div class="line"></div><div class="line">    <span class="keyword">val</span> produceStatus = localProduceResults.map &#123; <span class="keyword">case</span> (topicPartition, result) =&gt;</div><div class="line">      topicPartition -&gt;</div><div class="line">              <span class="type">ProducePartitionStatus</span>(</div><div class="line">                result.info.lastOffset + <span class="number">1</span>, <span class="comment">// required offset</span></div><div class="line">                <span class="keyword">new</span> <span class="type">PartitionResponse</span>(result.error, result.info.firstOffset, result.info.logAppendTime)) <span class="comment">// response status</span></div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="keyword">if</span> (delayedRequestRequired(requiredAcks, entriesPerPartition, localProduceResults)) &#123;</div><div class="line">      <span class="comment">//note: 处理 ack=-1 的情况,需要等到 isr 的 follower 都写入成功的话,才能返回最后结果</span></div><div class="line">      <span class="comment">// create delayed produce operation</span></div><div class="line">      <span class="keyword">val</span> produceMetadata = <span class="type">ProduceMetadata</span>(requiredAcks, produceStatus)</div><div class="line">      <span class="comment">//note: 延迟 produce 请求</span></div><div class="line">      <span class="keyword">val</span> delayedProduce = <span class="keyword">new</span> <span class="type">DelayedProduce</span>(timeout, produceMetadata, <span class="keyword">this</span>, responseCallback)</div><div class="line"></div><div class="line">      <span class="comment">// create a list of (topic, partition) pairs to use as keys for this delayed produce operation</span></div><div class="line">      <span class="keyword">val</span> producerRequestKeys = entriesPerPartition.keys.map(<span class="keyword">new</span> <span class="type">TopicPartitionOperationKey</span>(_)).toSeq</div><div class="line"></div><div class="line">      <span class="comment">// try to complete the request immediately, otherwise put it into the purgatory</span></div><div class="line">      <span class="comment">// this is because while the delayed produce operation is being created, new</span></div><div class="line">      <span class="comment">// requests may arrive and hence make this operation completable.</span></div><div class="line">      delayedProducePurgatory.tryCompleteElseWatch(delayedProduce, producerRequestKeys)</div><div class="line"></div><div class="line">    &#125; <span class="keyword">else</span> &#123;</div><div class="line">      <span class="comment">// we can respond immediately</span></div><div class="line">      <span class="comment">//note: 通过回调函数直接返回结果</span></div><div class="line">      <span class="keyword">val</span> produceResponseStatus = produceStatus.mapValues(status =&gt; status.responseStatus)</div><div class="line">      responseCallback(produceResponseStatus)</div><div class="line">    &#125;</div><div class="line">  &#125; <span class="keyword">else</span> &#123;</div><div class="line">    <span class="comment">// If required.acks is outside accepted range, something is wrong with the client</span></div><div class="line">    <span class="comment">// Just return an error and don't handle the request at all</span></div><div class="line">    <span class="comment">//note: 返回 INVALID_REQUIRED_ACKS 错误</span></div><div class="line">    <span class="keyword">val</span> responseStatus = entriesPerPartition.map &#123; <span class="keyword">case</span> (topicPartition, _) =&gt;</div><div class="line">      topicPartition -&gt; <span class="keyword">new</span> <span class="type">PartitionResponse</span>(<span class="type">Errors</span>.<span class="type">INVALID_REQUIRED_ACKS</span>,</div><div class="line">        <span class="type">LogAppendInfo</span>.<span class="type">UnknownLogAppendInfo</span>.firstOffset, <span class="type">Record</span>.<span class="type">NO_TIMESTAMP</span>)</div><div class="line">    &#125;</div><div class="line">    responseCallback(responseStatus)</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>从上面的实现来看，<code>appendRecords()</code> 的实现主要分为以下几步：</p>
<ol>
<li>首先判断 acks 设置是否有效（-1，0，1三个值有效），无效的话直接返回异常，不再处理；</li>
<li>acks 设置有效的话，调用 <code>appendToLocalLog()</code> 方法将 records 追加到本地对应的 log 对象中；</li>
<li><code>appendToLocalLog()</code> 处理完后，如果发现 clients 设置的 acks=-1，即需要 isr 的其他的副本同步完成才能返回 response，那么就会创建一个 DelayedProduce 对象，等待 isr 的其他副本进行同步，否则的话直接返回追加的结果。</li>
</ol>
<h4 id="appendToLocalLog-的实现"><a href="#appendToLocalLog-的实现" class="headerlink" title="appendToLocalLog() 的实现"></a><code>appendToLocalLog()</code> 的实现</h4><p>追加日志的实际操作是在 <code>appendToLocalLog()</code>  中完成的，这里看下它的具体实现：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/**</span></div><div class="line"> * Append the messages to the local replica logs</div><div class="line"> */</div><div class="line"><span class="comment">//note: 向本地的 replica 写入数据</span></div><div class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">appendToLocalLog</span></span>(internalTopicsAllowed: <span class="type">Boolean</span>,</div><div class="line">                             entriesPerPartition: <span class="type">Map</span>[<span class="type">TopicPartition</span>, <span class="type">MemoryRecords</span>],</div><div class="line">                             requiredAcks: <span class="type">Short</span>): <span class="type">Map</span>[<span class="type">TopicPartition</span>, <span class="type">LogAppendResult</span>] = &#123;</div><div class="line">  trace(<span class="string">"Append [%s] to local log "</span>.format(entriesPerPartition))</div><div class="line">  entriesPerPartition.map &#123; <span class="keyword">case</span> (topicPartition, records) =&gt; <span class="comment">//note: 遍历要写的所有 topic-partition</span></div><div class="line">    <span class="type">BrokerTopicStats</span>.getBrokerTopicStats(topicPartition.topic).totalProduceRequestRate.mark()</div><div class="line">    <span class="type">BrokerTopicStats</span>.getBrokerAllTopicsStats().totalProduceRequestRate.mark()</div><div class="line"></div><div class="line">    <span class="comment">// reject appending to internal topics if it is not allowed</span></div><div class="line">    <span class="comment">//note: 不能向 kafka 内部使用的 topic 追加数据</span></div><div class="line">    <span class="keyword">if</span> (<span class="type">Topic</span>.isInternal(topicPartition.topic) &amp;&amp; !internalTopicsAllowed) &#123;</div><div class="line">      (topicPartition, <span class="type">LogAppendResult</span>(</div><div class="line">        <span class="type">LogAppendInfo</span>.<span class="type">UnknownLogAppendInfo</span>,</div><div class="line">        <span class="type">Some</span>(<span class="keyword">new</span> <span class="type">InvalidTopicException</span>(<span class="string">s"Cannot append to internal topic <span class="subst">$&#123;topicPartition.topic&#125;</span>"</span>))))</div><div class="line">    &#125; <span class="keyword">else</span> &#123;</div><div class="line">      <span class="keyword">try</span> &#123;</div><div class="line">        <span class="comment">//note: 查找对应的 Partition,并向分区对应的副本写入数据文件</span></div><div class="line">        <span class="keyword">val</span> partitionOpt = getPartition(topicPartition) <span class="comment">//note: 获取 topic-partition 的 Partition 对象</span></div><div class="line">        <span class="keyword">val</span> info = partitionOpt <span class="keyword">match</span> &#123;</div><div class="line">          <span class="keyword">case</span> <span class="type">Some</span>(partition) =&gt;</div><div class="line">            partition.appendRecordsToLeader(records, requiredAcks) <span class="comment">//note: 如果找到了这个对象,就开始追加日志</span></div><div class="line">          <span class="keyword">case</span> <span class="type">None</span> =&gt; <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">UnknownTopicOrPartitionException</span>(<span class="string">"Partition %s doesn't exist on %d"</span></div><div class="line">            .format(topicPartition, localBrokerId)) <span class="comment">//note: 没有找到的话,返回异常</span></div><div class="line">        &#125;</div><div class="line"></div><div class="line">        <span class="comment">//note: 追加的 msg 数</span></div><div class="line">        <span class="keyword">val</span> numAppendedMessages =</div><div class="line">          <span class="keyword">if</span> (info.firstOffset == <span class="number">-1</span>L || info.lastOffset == <span class="number">-1</span>L)</div><div class="line">            <span class="number">0</span></div><div class="line">          <span class="keyword">else</span></div><div class="line">            info.lastOffset - info.firstOffset + <span class="number">1</span></div><div class="line"></div><div class="line">        <span class="comment">// update stats for successfully appended bytes and messages as bytesInRate and messageInRate</span></div><div class="line">        <span class="comment">//note:  更新 metrics</span></div><div class="line">        <span class="type">BrokerTopicStats</span>.getBrokerTopicStats(topicPartition.topic).bytesInRate.mark(records.sizeInBytes)</div><div class="line">        <span class="type">BrokerTopicStats</span>.getBrokerAllTopicsStats.bytesInRate.mark(records.sizeInBytes)</div><div class="line">        <span class="type">BrokerTopicStats</span>.getBrokerTopicStats(topicPartition.topic).messagesInRate.mark(numAppendedMessages)</div><div class="line">        <span class="type">BrokerTopicStats</span>.getBrokerAllTopicsStats.messagesInRate.mark(numAppendedMessages)</div><div class="line"></div><div class="line">        trace(<span class="string">"%d bytes written to log %s-%d beginning at offset %d and ending at offset %d"</span></div><div class="line">          .format(records.sizeInBytes, topicPartition.topic, topicPartition.partition, info.firstOffset, info.lastOffset))</div><div class="line">        (topicPartition, <span class="type">LogAppendResult</span>(info))</div><div class="line">      &#125; <span class="keyword">catch</span> &#123; <span class="comment">//note: 处理追加过程中出现的异常</span></div><div class="line">        <span class="comment">// <span class="doctag">NOTE:</span> Failed produce requests metric is not incremented for known exceptions</span></div><div class="line">        <span class="comment">// it is supposed to indicate un-expected failures of a broker in handling a produce request</span></div><div class="line">        <span class="keyword">case</span> e: <span class="type">KafkaStorageException</span> =&gt;</div><div class="line">          fatal(<span class="string">"Halting due to unrecoverable I/O error while handling produce request: "</span>, e)</div><div class="line">          <span class="type">Runtime</span>.getRuntime.halt(<span class="number">1</span>)</div><div class="line">          (topicPartition, <span class="literal">null</span>)</div><div class="line">        <span class="keyword">case</span> e@ (_: <span class="type">UnknownTopicOrPartitionException</span> |</div><div class="line">                 _: <span class="type">NotLeaderForPartitionException</span> |</div><div class="line">                 _: <span class="type">RecordTooLargeException</span> |</div><div class="line">                 _: <span class="type">RecordBatchTooLargeException</span> |</div><div class="line">                 _: <span class="type">CorruptRecordException</span> |</div><div class="line">                 _: <span class="type">InvalidTimestampException</span>) =&gt;</div><div class="line">          (topicPartition, <span class="type">LogAppendResult</span>(<span class="type">LogAppendInfo</span>.<span class="type">UnknownLogAppendInfo</span>, <span class="type">Some</span>(e)))</div><div class="line">        <span class="keyword">case</span> t: <span class="type">Throwable</span> =&gt;</div><div class="line">          <span class="type">BrokerTopicStats</span>.getBrokerTopicStats(topicPartition.topic).failedProduceRequestRate.mark()</div><div class="line">          <span class="type">BrokerTopicStats</span>.getBrokerAllTopicsStats.failedProduceRequestRate.mark()</div><div class="line">          error(<span class="string">"Error processing append operation on partition %s"</span>.format(topicPartition), t)</div><div class="line">          (topicPartition, <span class="type">LogAppendResult</span>(<span class="type">LogAppendInfo</span>.<span class="type">UnknownLogAppendInfo</span>, <span class="type">Some</span>(t)))</div><div class="line">      &#125;</div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>从上面可以看到 <code>appendToLocalLog()</code> 的实现如下：</p>
<ol>
<li>首先判断要写的 topic 是不是 Kafka 内置的 topic，内置的 topic 是不允许 Producer 写入的；</li>
<li>先查找 topic-partition 对应的 Partition 对象，如果在 <code>allPartitions</code> 中查找到了对应的 partition，那么直接调用 <code>partition.appendRecordsToLeader()</code> 方法追加相应的 records，否则会向 client 抛出异常。</li>
</ol>
<h3 id="Partition-appendRecordsToLeader-方法"><a href="#Partition-appendRecordsToLeader-方法" class="headerlink" title="Partition.appendRecordsToLeader() 方法"></a>Partition.appendRecordsToLeader() 方法</h3><p>ReplicaManager 在追加 records 时，调用的是 Partition 的 <code>appendRecordsToLeader()</code> 方法，其具体的实现如下：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">appendRecordsToLeader</span></span>(records: <span class="type">MemoryRecords</span>, requiredAcks: <span class="type">Int</span> = <span class="number">0</span>) = &#123;</div><div class="line">  <span class="keyword">val</span> (info, leaderHWIncremented) = inReadLock(leaderIsrUpdateLock) &#123;</div><div class="line">    leaderReplicaIfLocal <span class="keyword">match</span> &#123;</div><div class="line">      <span class="keyword">case</span> <span class="type">Some</span>(leaderReplica) =&gt;</div><div class="line">        <span class="keyword">val</span> log = leaderReplica.log.get <span class="comment">//note: 获取对应的 Log 对象</span></div><div class="line">        <span class="keyword">val</span> minIsr = log.config.minInSyncReplicas</div><div class="line">        <span class="keyword">val</span> inSyncSize = inSyncReplicas.size</div><div class="line"></div><div class="line">        <span class="comment">// Avoid writing to leader if there are not enough insync replicas to make it safe</span></div><div class="line">        <span class="comment">//note: 如果 ack 设置为-1, isr 数小于设置的 min.isr 时,就会向 producer 抛出相应的异常</span></div><div class="line">        <span class="keyword">if</span> (inSyncSize &lt; minIsr &amp;&amp; requiredAcks == <span class="number">-1</span>) &#123;</div><div class="line">          <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">NotEnoughReplicasException</span>(<span class="string">"Number of insync replicas for partition %s is [%d], below required minimum [%d]"</span></div><div class="line">            .format(topicPartition, inSyncSize, minIsr))</div><div class="line">        &#125;</div><div class="line"></div><div class="line">        <span class="comment">//note: 向副本对应的 log 追加响应的数据</span></div><div class="line">        <span class="keyword">val</span> info = log.append(records, assignOffsets = <span class="literal">true</span>)</div><div class="line">        <span class="comment">// probably unblock some follower fetch requests since log end offset has been updated</span></div><div class="line">        replicaManager.tryCompleteDelayedFetch(<span class="type">TopicPartitionOperationKey</span>(<span class="keyword">this</span>.topic, <span class="keyword">this</span>.partitionId))</div><div class="line">        <span class="comment">// we may need to increment high watermark since ISR could be down to 1</span></div><div class="line">        <span class="comment">//note: 判断是否需要增加 HHW（追加日志后会进行一次判断）</span></div><div class="line">        (info, maybeIncrementLeaderHW(leaderReplica))</div><div class="line"></div><div class="line">      <span class="keyword">case</span> <span class="type">None</span> =&gt;</div><div class="line">        <span class="comment">//note: leader 不在本台机器上</span></div><div class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">NotLeaderForPartitionException</span>(<span class="string">"Leader not local for partition %s on broker %d"</span></div><div class="line">          .format(topicPartition, localBrokerId))</div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  <span class="comment">// some delayed operations may be unblocked after HW changed</span></div><div class="line">  <span class="keyword">if</span> (leaderHWIncremented)</div><div class="line">    tryCompleteDelayedRequests()</div><div class="line"></div><div class="line">  info</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>在这个方法里，会根据 topic 的 <code>min.isrs</code> 配置以及当前这个 partition 的 isr 情况判断是否可以写入，如果不满足条件，就会抛出 <code>NotEnoughReplicasException</code> 的异常，如果满足条件，就会调用 <code>log.append()</code> 向 replica 追加日志。</p>
<h2 id="存储层"><a href="#存储层" class="headerlink" title="存储层"></a>存储层</h2><p>跟着最开始图中的流程及代码分析，走到这里，才算是到了 Kafka 的存储层部分，在这里会详细讲述在存储层 Kafka 如何写入日志。</p>
<h3 id="Log-对象"><a href="#Log-对象" class="headerlink" title="Log 对象"></a>Log 对象</h3><p>在上面有过一些介绍，每个 replica 会对应一个 log 对象，log 对象是管理当前分区的一个单位，它会包含这个分区的所有 segment 文件（包括对应的 offset 索引和时间戳索引文件），它会提供一些增删查的方法。</p>
<p>在 Log 对象的初始化时，有三个变量是比较重要的：</p>
<ol>
<li><code>nextOffsetMetadata</code>：可以叫做下一个偏移量元数据，它包括 activeSegment 的下一条消息的偏移量，该 activeSegment 的基准偏移量及日志分段的大小；</li>
<li><code>activeSegment</code>：指的是该 Log 管理的 segments 中那个最新的 segment（这里叫做活跃的 segment），一个 Log 中只会有一个活跃的 segment，其他的 segment 都已经被持久化到磁盘了；</li>
<li><code>logEndOffset</code>：表示下一条消息的 offset，它取自 <code>nextOffsetMetadata</code> 的 offset，实际上就是活动日志分段的下一个偏移量。</li>
</ol>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//note: nextOffsetMetadata 声明为 volatile，如果该值被修改，其他使用此变量的线程就可以立刻见到变化后的值，在生产和消费都会使用到这个值</span></div><div class="line"><span class="meta">@volatile</span> <span class="keyword">private</span> <span class="keyword">var</span> nextOffsetMetadata: <span class="type">LogOffsetMetadata</span> = _</div><div class="line"></div><div class="line"><span class="comment">/* Calculate the offset of the next message */</span></div><div class="line"><span class="comment">//note: 下一个偏移量元数据</span></div><div class="line"><span class="comment">//note: 第一个参数：下一条消息的偏移量；第二个参数：日志分段的基准偏移量；第三个参数：日志分段大小</span></div><div class="line">nextOffsetMetadata = <span class="keyword">new</span> <span class="type">LogOffsetMetadata</span>(activeSegment.nextOffset(), activeSegment.baseOffset, activeSegment.size.toInt)</div><div class="line"></div><div class="line"><span class="comment">/**</span></div><div class="line">* The active segment that is currently taking appends</div><div class="line">*/</div><div class="line"><span class="comment">//note: 任何时刻，只会有一个活动的日志分段</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">activeSegment</span> </span>= segments.lastEntry.getValue</div><div class="line"></div><div class="line"><span class="comment">/**</span></div><div class="line">*  The offset of the next message that will be appended to the log</div><div class="line">*/</div><div class="line"><span class="comment">//note: 下一条消息的 offset，从 nextOffsetMetadata 中获取的</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">logEndOffset</span></span>: <span class="type">Long</span> = nextOffsetMetadata.messageOffset</div></pre></td></tr></table></figure>
<h4 id="日志写入"><a href="#日志写入" class="headerlink" title="日志写入"></a>日志写入</h4><p>在 Log 中一个重要的方法就是日志的写入方法，下面来看下这个方法的实现。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div><div class="line">113</div><div class="line">114</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/**</span></div><div class="line"> * Append this message set to the active segment of the log, rolling over to a fresh segment if necessary.</div><div class="line"> *</div><div class="line"> * This method will generally be responsible for assigning offsets to the messages,</div><div class="line"> * however if the assignOffsets=false flag is passed we will only check that the existing offsets are valid.</div><div class="line"> *</div><div class="line"> * @param records The log records to append</div><div class="line"> * @param assignOffsets Should the log assign offsets to this message set or blindly apply what it is given</div><div class="line"> * @throws KafkaStorageException If the append fails due to an I/O error.</div><div class="line"> * @return Information about the appended messages including the first and last offset.</div><div class="line"> */</div><div class="line"><span class="comment">//note: 向 active segment 追加 log,必要的情况下,滚动创建新的 segment</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">append</span></span>(records: <span class="type">MemoryRecords</span>, assignOffsets: <span class="type">Boolean</span> = <span class="literal">true</span>): <span class="type">LogAppendInfo</span> = &#123;</div><div class="line">  <span class="keyword">val</span> appendInfo = analyzeAndValidateRecords(records) <span class="comment">//note: 返回这批消息的该要信息,并对这批 msg 进行校验</span></div><div class="line"></div><div class="line">  <span class="comment">// if we have any valid messages, append them to the log</span></div><div class="line">  <span class="keyword">if</span> (appendInfo.shallowCount == <span class="number">0</span>)</div><div class="line">    <span class="keyword">return</span> appendInfo</div><div class="line"></div><div class="line">  <span class="comment">// trim any invalid bytes or partial messages before appending it to the on-disk log</span></div><div class="line">  <span class="comment">//note: 删除这批消息中无效的消息</span></div><div class="line">  <span class="keyword">var</span> validRecords = trimInvalidBytes(records, appendInfo)</div><div class="line"></div><div class="line">  <span class="keyword">try</span> &#123;</div><div class="line">    <span class="comment">// they are valid, insert them in the log</span></div><div class="line">    lock synchronized &#123;</div><div class="line"></div><div class="line">      <span class="keyword">if</span> (assignOffsets) &#123;</div><div class="line">        <span class="comment">// assign offsets to the message set</span></div><div class="line">        <span class="comment">//note: 计算这个消息集起始 offset，对 offset 的操作是一个原子操作</span></div><div class="line">        <span class="keyword">val</span> offset = <span class="keyword">new</span> <span class="type">LongRef</span>(nextOffsetMetadata.messageOffset)</div><div class="line">        appendInfo.firstOffset = offset.value <span class="comment">//note: 作为消息集的第一个 offset</span></div><div class="line">        <span class="keyword">val</span> now = time.milliseconds <span class="comment">//note: 设置的时间错以 server 收到的时间戳为准</span></div><div class="line">        <span class="comment">//note: 验证消息,并为没条 record 设置相应的 offset 和 timestrap</span></div><div class="line">        <span class="keyword">val</span> validateAndOffsetAssignResult = <span class="keyword">try</span> &#123;</div><div class="line">          <span class="type">LogValidator</span>.validateMessagesAndAssignOffsets(validRecords,</div><div class="line">                                                        offset,</div><div class="line">                                                        now,</div><div class="line">                                                        appendInfo.sourceCodec,</div><div class="line">                                                        appendInfo.targetCodec,</div><div class="line">                                                        config.compact,</div><div class="line">                                                        config.messageFormatVersion.messageFormatVersion,</div><div class="line">                                                        config.messageTimestampType,</div><div class="line">                                                        config.messageTimestampDifferenceMaxMs)</div><div class="line">        &#125; <span class="keyword">catch</span> &#123;</div><div class="line">          <span class="keyword">case</span> e: <span class="type">IOException</span> =&gt; <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">KafkaException</span>(<span class="string">"Error in validating messages while appending to log '%s'"</span>.format(name), e)</div><div class="line">        &#125;</div><div class="line">        <span class="comment">//note: 返回已经计算好 offset 和 timestrap 的 MemoryRecords</span></div><div class="line">        validRecords = validateAndOffsetAssignResult.validatedRecords</div><div class="line">        appendInfo.maxTimestamp = validateAndOffsetAssignResult.maxTimestamp</div><div class="line">        appendInfo.offsetOfMaxTimestamp = validateAndOffsetAssignResult.shallowOffsetOfMaxTimestamp</div><div class="line">        appendInfo.lastOffset = offset.value - <span class="number">1</span> <span class="comment">//note: 最后一条消息的 offset</span></div><div class="line">        <span class="keyword">if</span> (config.messageTimestampType == <span class="type">TimestampType</span>.<span class="type">LOG_APPEND_TIME</span>)</div><div class="line">          appendInfo.logAppendTime = now</div><div class="line"></div><div class="line">        <span class="comment">// re-validate message sizes if there's a possibility that they have changed (due to re-compression or message</span></div><div class="line">        <span class="comment">// format conversion)</span></div><div class="line">        <span class="comment">//note: 更新 metrics 的记录</span></div><div class="line">        <span class="keyword">if</span> (validateAndOffsetAssignResult.messageSizeMaybeChanged) &#123;</div><div class="line">          <span class="keyword">for</span> (logEntry &lt;- validRecords.shallowEntries.asScala) &#123;</div><div class="line">            <span class="keyword">if</span> (logEntry.sizeInBytes &gt; config.maxMessageSize) &#123;</div><div class="line">              <span class="comment">// we record the original message set size instead of the trimmed size</span></div><div class="line">              <span class="comment">// to be consistent with pre-compression bytesRejectedRate recording</span></div><div class="line">              <span class="type">BrokerTopicStats</span>.getBrokerTopicStats(topicPartition.topic).bytesRejectedRate.mark(records.sizeInBytes)</div><div class="line">              <span class="type">BrokerTopicStats</span>.getBrokerAllTopicsStats.bytesRejectedRate.mark(records.sizeInBytes)</div><div class="line">              <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">RecordTooLargeException</span>(<span class="string">"Message size is %d bytes which exceeds the maximum configured message size of %d."</span></div><div class="line">                .format(logEntry.sizeInBytes, config.maxMessageSize))</div><div class="line">            &#125;</div><div class="line">          &#125;</div><div class="line">        &#125;</div><div class="line"></div><div class="line">      &#125; <span class="keyword">else</span> &#123;</div><div class="line">        <span class="comment">// we are taking the offsets we are given</span></div><div class="line">        <span class="keyword">if</span> (!appendInfo.offsetsMonotonic || appendInfo.firstOffset &lt; nextOffsetMetadata.messageOffset)</div><div class="line">          <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">IllegalArgumentException</span>(<span class="string">"Out of order offsets found in "</span> + records.deepEntries.asScala.map(_.offset))</div><div class="line">      &#125;</div><div class="line"></div><div class="line">      <span class="comment">// check messages set size may be exceed config.segmentSize</span></div><div class="line">      <span class="keyword">if</span> (validRecords.sizeInBytes &gt; config.segmentSize) &#123;</div><div class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">RecordBatchTooLargeException</span>(<span class="string">"Message set size is %d bytes which exceeds the maximum configured segment size of %d."</span></div><div class="line">          .format(validRecords.sizeInBytes, config.segmentSize))</div><div class="line">      &#125;</div><div class="line"></div><div class="line">      <span class="comment">// maybe roll the log if this segment is full</span></div><div class="line">      <span class="comment">//note: 如果当前 segment 满了，就需要重新新建一个 segment</span></div><div class="line">      <span class="keyword">val</span> segment = maybeRoll(messagesSize = validRecords.sizeInBytes,</div><div class="line">        maxTimestampInMessages = appendInfo.maxTimestamp,</div><div class="line">        maxOffsetInMessages = appendInfo.lastOffset)</div><div class="line"></div><div class="line"></div><div class="line">      <span class="comment">// now append to the log</span></div><div class="line">      <span class="comment">//note: 追加消息到当前 segment</span></div><div class="line">      segment.append(firstOffset = appendInfo.firstOffset,</div><div class="line">        largestOffset = appendInfo.lastOffset,</div><div class="line">        largestTimestamp = appendInfo.maxTimestamp,</div><div class="line">        shallowOffsetOfMaxTimestamp = appendInfo.offsetOfMaxTimestamp,</div><div class="line">        records = validRecords)</div><div class="line"></div><div class="line">      <span class="comment">// increment the log end offset</span></div><div class="line">      <span class="comment">//note: 修改最新的 next_offset</span></div><div class="line">      updateLogEndOffset(appendInfo.lastOffset + <span class="number">1</span>)</div><div class="line"></div><div class="line">      trace(<span class="string">"Appended message set to log %s with first offset: %d, next offset: %d, and messages: %s"</span></div><div class="line">        .format(<span class="keyword">this</span>.name, appendInfo.firstOffset, nextOffsetMetadata.messageOffset, validRecords))</div><div class="line"></div><div class="line">      <span class="keyword">if</span> (unflushedMessages &gt;= config.flushInterval)<span class="comment">//note: 满足条件的话，刷新磁盘</span></div><div class="line">        flush()</div><div class="line"></div><div class="line">      appendInfo</div><div class="line">    &#125;</div><div class="line">  &#125; <span class="keyword">catch</span> &#123;</div><div class="line">    <span class="keyword">case</span> e: <span class="type">IOException</span> =&gt; <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">KafkaStorageException</span>(<span class="string">"I/O exception in append to log '%s'"</span>.format(name), e)</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>Server 将每个分区的消息追加到日志中时，是以 segment 为单位的，当 segment 的大小到达阈值大小之后，会滚动新建一个日志分段（segment）保存新的消息，而分区的消息总是追加到最新的日志分段（也就是 activeSegment）中。每个日志分段都会有一个基准偏移量（segmentBaseOffset，或者叫做 baseOffset），这个基准偏移量就是分区级别的绝对偏移量，而且这个值在日志分段是固定的。有了这个基准偏移量，就可以计算出来每条消息在分区中的绝对偏移量，最后把数据以及对应的绝对偏移量写到日志文件中。<code>append()</code> 方法的过程可以总结如下：</p>
<ol>
<li><code>analyzeAndValidateRecords()</code>：对这批要写入的消息进行检测，主要是检查消息的大小及 crc 校验；</li>
<li><code>trimInvalidBytes()</code>：会将这批消息中无效的消息删除，返回一个都是有效消息的 MemoryRecords；</li>
<li><code>LogValidator.validateMessagesAndAssignOffsets()</code>：为每条消息设置相应的 offset（绝对偏移量） 和 timestrap；</li>
<li><code>maybeRoll()</code>：判断是否需要新建一个 segment 的，如果当前的 segment 放不下这批消息的话，需要新建一个 segment；</li>
<li><code>segment.append()</code>：向 segment 中添加消息；</li>
<li>更新 logEndOffset 和判断是否需要刷新磁盘（如果需要的话，调用 <code>flush()</code> 方法刷到磁盘）。</li>
</ol>
<p>关于 timestrap 的设置，这里也顺便介绍一下，在新版的 Kafka 中，每条 msg 都会有一个对应的时间戳记录，producer 端可以设置这个字段 <code>message.timestamp.type</code> 来选择 timestrap 的类型，默认是按照创建时间，只能选择从下面的选择中二选一：</p>
<ol>
<li><code>CreateTime</code>，默认值；</li>
<li><code>LogAppendTime</code>。</li>
</ol>
<h4 id="日志分段"><a href="#日志分段" class="headerlink" title="日志分段"></a>日志分段</h4><p>在 Log 的 <code>append()</code> 方法中，会调用 <code>maybeRoll()</code> 方法来判断是否需要进行相应日志分段操作，其具体实现如下：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/**</span></div><div class="line"> * Roll the log over to a new empty log segment if necessary.</div><div class="line"> *</div><div class="line"> * @param messagesSize The messages set size in bytes</div><div class="line"> * @param maxTimestampInMessages The maximum timestamp in the messages.</div><div class="line"> * logSegment will be rolled if one of the following conditions met</div><div class="line"> * &lt;ol&gt;</div><div class="line"> * &lt;li&gt; The logSegment is full</div><div class="line"> * &lt;li&gt; The maxTime has elapsed since the timestamp of first message in the segment (or since the create time if</div><div class="line"> * the first message does not have a timestamp)</div><div class="line"> * &lt;li&gt; The index is full</div><div class="line"> * &lt;/ol&gt;</div><div class="line"> * @return The currently active segment after (perhaps) rolling to a new segment</div><div class="line"> */</div><div class="line"><span class="comment">//note: 判断是否需要创建日志分段,如果不需要返回当前分段,需要的话,返回新创建的日志分段</span></div><div class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">maybeRoll</span></span>(messagesSize: <span class="type">Int</span>, maxTimestampInMessages: <span class="type">Long</span>, maxOffsetInMessages: <span class="type">Long</span>): <span class="type">LogSegment</span> = &#123;</div><div class="line">  <span class="keyword">val</span> segment = activeSegment <span class="comment">//note: 对活跃的日志分段进行判断,它也是最新的一个日志分段</span></div><div class="line">  <span class="keyword">val</span> now = time.milliseconds</div><div class="line">  <span class="comment">//note: 距离上次日志分段的时间是否达到了设置的阈值（log.roll.hours）</span></div><div class="line">  <span class="keyword">val</span> reachedRollMs = segment.timeWaitedForRoll(now, maxTimestampInMessages) &gt; config.segmentMs - segment.rollJitterMs</div><div class="line">  <span class="comment">//note: 这是五个条件: 1. 文件满了,不足以放心这么大的 messageSet; 2. 文件有数据,并且到分段的时间阈值; 3. 索引文件满了;</span></div><div class="line">  <span class="comment">//note: 4. 时间索引文件满了; 5. 最大的 offset，其相对偏移量超过了正整数的阈值</span></div><div class="line">  <span class="keyword">if</span> (segment.size &gt; config.segmentSize - messagesSize ||</div><div class="line">      (segment.size &gt; <span class="number">0</span> &amp;&amp; reachedRollMs) ||</div><div class="line">      segment.index.isFull || segment.timeIndex.isFull || !segment.canConvertToRelativeOffset(maxOffsetInMessages)) &#123;</div><div class="line">    debug(<span class="string">s"Rolling new log segment in <span class="subst">$name</span> (log_size = <span class="subst">$&#123;segment.size&#125;</span>/<span class="subst">$&#123;config.segmentSize&#125;</span>&#125;, "</span> +</div><div class="line">        <span class="string">s"index_size = <span class="subst">$&#123;segment.index.entries&#125;</span>/<span class="subst">$&#123;segment.index.maxEntries&#125;</span>, "</span> +</div><div class="line">        <span class="string">s"time_index_size = <span class="subst">$&#123;segment.timeIndex.entries&#125;</span>/<span class="subst">$&#123;segment.timeIndex.maxEntries&#125;</span>, "</span> +</div><div class="line">        <span class="string">s"inactive_time_ms = <span class="subst">$&#123;segment.timeWaitedForRoll(now, maxTimestampInMessages)&#125;</span>/<span class="subst">$&#123;config.segmentMs - segment.rollJitterMs&#125;</span>)."</span>)</div><div class="line">    roll(maxOffsetInMessages - <span class="type">Integer</span>.<span class="type">MAX_VALUE</span>) <span class="comment">//note: 创建新的日志分段</span></div><div class="line">  &#125; <span class="keyword">else</span> &#123;</div><div class="line">    segment <span class="comment">//note: 使用当前的日志分段</span></div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>从 <code>maybeRoll()</code> 的实现可以看到，是否需要创建新的日志分段，有下面几种情况：</p>
<ol>
<li>当前日志分段的大小加上消息的大小超过了日志分段的阈值（<code>log.segment.bytes</code>）；</li>
<li>距离上次创建日志分段的时间达到了一定的阈值（<code>log.roll.hours</code>），并且数据文件有数据；</li>
<li>索引文件满了；</li>
<li>时间索引文件满了；</li>
<li>最大的 offset，其相对偏移量超过了正整数的阈值。</li>
</ol>
<p>如果上面的其中一个条件，就会创建新的 segment 文件，见 <code>roll()</code> 方法实现：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/**</span></div><div class="line"> * Roll the log over to a new active segment starting with the current logEndOffset.</div><div class="line"> * This will trim the index to the exact size of the number of entries it currently contains.</div><div class="line"> *</div><div class="line"> * @return The newly rolled segment</div><div class="line"> */</div><div class="line"><span class="comment">//note: 滚动创建日志,并添加到日志管理的映射表中</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">roll</span></span>(expectedNextOffset: <span class="type">Long</span> = <span class="number">0</span>): <span class="type">LogSegment</span> = &#123;</div><div class="line">  <span class="keyword">val</span> start = time.nanoseconds</div><div class="line">  lock synchronized &#123;</div><div class="line">    <span class="keyword">val</span> newOffset = <span class="type">Math</span>.max(expectedNextOffset, logEndOffset) <span class="comment">//note: 选择最新的 offset 作为基准偏移量</span></div><div class="line">    <span class="keyword">val</span> logFile = logFilename(dir, newOffset) <span class="comment">//note: 创建数据文件</span></div><div class="line">    <span class="keyword">val</span> indexFile = indexFilename(dir, newOffset) <span class="comment">//note: 创建 offset 索引文件</span></div><div class="line">    <span class="keyword">val</span> timeIndexFile = timeIndexFilename(dir, newOffset) <span class="comment">//note: 创建 time 索引文件</span></div><div class="line">    <span class="keyword">for</span>(file &lt;- <span class="type">List</span>(logFile, indexFile, timeIndexFile); <span class="keyword">if</span> file.exists) &#123;</div><div class="line">      warn(<span class="string">"Newly rolled segment file "</span> + file.getName + <span class="string">" already exists; deleting it first"</span>)</div><div class="line">      file.delete()</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    segments.lastEntry() <span class="keyword">match</span> &#123;</div><div class="line">      <span class="keyword">case</span> <span class="literal">null</span> =&gt;</div><div class="line">      <span class="keyword">case</span> entry =&gt; &#123;</div><div class="line">        <span class="keyword">val</span> seg = entry.getValue</div><div class="line">        seg.onBecomeInactiveSegment()</div><div class="line">        seg.index.trimToValidSize()</div><div class="line">        seg.timeIndex.trimToValidSize()</div><div class="line">        seg.log.trim()</div><div class="line">      &#125;</div><div class="line">    &#125;</div><div class="line">    <span class="comment">//note: 创建一个 segment 对象</span></div><div class="line">    <span class="keyword">val</span> segment = <span class="keyword">new</span> <span class="type">LogSegment</span>(dir,</div><div class="line">                                 startOffset = newOffset,</div><div class="line">                                 indexIntervalBytes = config.indexInterval,</div><div class="line">                                 maxIndexSize = config.maxIndexSize,</div><div class="line">                                 rollJitterMs = config.randomSegmentJitter,</div><div class="line">                                 time = time,</div><div class="line">                                 fileAlreadyExists = <span class="literal">false</span>,</div><div class="line">                                 initFileSize = initFileSize,</div><div class="line">                                 preallocate = config.preallocate)</div><div class="line">    <span class="keyword">val</span> prev = addSegment(segment) <span class="comment">//note: 添加到日志管理中</span></div><div class="line">    <span class="keyword">if</span>(prev != <span class="literal">null</span>)</div><div class="line">      <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">KafkaException</span>(<span class="string">"Trying to roll a new log segment for topic partition %s with start offset %d while it already exists."</span>.format(name, newOffset))</div><div class="line">    <span class="comment">// We need to update the segment base offset and append position data of the metadata when log rolls.</span></div><div class="line">    <span class="comment">// The next offset should not change.</span></div><div class="line">    updateLogEndOffset(nextOffsetMetadata.messageOffset) <span class="comment">//note: 更新 offset</span></div><div class="line">    <span class="comment">// schedule an asynchronous flush of the old segment</span></div><div class="line">    scheduler.schedule(<span class="string">"flush-log"</span>, () =&gt; flush(newOffset), delay = <span class="number">0</span>L)</div><div class="line"></div><div class="line">    info(<span class="string">"Rolled new log segment for '"</span> + name + <span class="string">"' in %.0f ms."</span>.format((<span class="type">System</span>.nanoTime - start) / (<span class="number">1000.0</span>*<span class="number">1000.0</span>)))</div><div class="line"></div><div class="line">    segment</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>创建一个 segment 对象，真正的实现是在 Log 的 <code>roll()</code> 方法中，也就是上面的方法中，创建 segment 对象，主要包括三部分：数据文件、offset 索引文件和 time 索引文件。</p>
<h4 id="offset-索引文件"><a href="#offset-索引文件" class="headerlink" title="offset 索引文件"></a>offset 索引文件</h4><p>这里顺便讲述一下 offset 索引文件，Kafka 的索引文件有下面一个特点：</p>
<ol>
<li>采用 <strong>绝对偏移量+相对偏移量</strong> 的方式进行存储的，每个 segment 最开始绝对偏移量也是其基准偏移量；</li>
<li>数据文件每隔一定的大小创建一个索引条目，而不是每条消息会创建索引条目，通过 <code>index.interval.bytes</code> 来配置，默认是 4096，也就是4KB；</li>
</ol>
<p>这样做的好处也非常明显：</p>
<ol>
<li>因为不是每条消息都创建相应的索引条目，所以索引条目是稀疏的；</li>
<li>索引的相对偏移量占据4个字节，而绝对偏移量占据8个字节，加上物理位置的4个字节，使用相对索引可以将每条索引条目的大小从12字节减少到8个字节；</li>
<li>因为偏移量有序的，再读取数据时，可以按照二分查找的方式去快速定位偏移量的位置；</li>
<li>这样的稀疏索引是可以完全放到内存中，加快偏移量的查找。</li>
</ol>
<h3 id="LogSegment-写入"><a href="#LogSegment-写入" class="headerlink" title="LogSegment 写入"></a>LogSegment 写入</h3><p>真正的日志写入，还是在 LogSegment 的 <code>append()</code> 方法中完成的，LogSegment 会跟 Kafka 最底层的文件通道、mmap 打交道。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div></pre></td><td class="code"><pre><div class="line"> <span class="comment">/**</span></div><div class="line"> * Append the given messages starting with the given offset. Add</div><div class="line"> * an entry to the index if needed.</div><div class="line"> *</div><div class="line"> * It is assumed this method is being called from within a lock.</div><div class="line"> *</div><div class="line"> * @param firstOffset The first offset in the message set.</div><div class="line"> * @param largestTimestamp The largest timestamp in the message set.</div><div class="line"> * @param shallowOffsetOfMaxTimestamp The offset of the message that has the largest timestamp in the messages to append.</div><div class="line"> * @param records The log entries to append.</div><div class="line"> */</div><div class="line"> <span class="comment">//note: 在指定的 offset 处追加指定的 msgs, 需要的情况下追加相应的索引</span></div><div class="line"><span class="meta">@nonthreadsafe</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">append</span></span>(firstOffset: <span class="type">Long</span>, largestOffset: <span class="type">Long</span>, largestTimestamp: <span class="type">Long</span>, shallowOffsetOfMaxTimestamp: <span class="type">Long</span>, records: <span class="type">MemoryRecords</span>) &#123;</div><div class="line">  <span class="keyword">if</span> (records.sizeInBytes &gt; <span class="number">0</span>) &#123;</div><div class="line">    trace(<span class="string">"Inserting %d bytes at offset %d at position %d with largest timestamp %d at shallow offset %d"</span></div><div class="line">        .format(records.sizeInBytes, firstOffset, log.sizeInBytes(), largestTimestamp, shallowOffsetOfMaxTimestamp))</div><div class="line">    <span class="keyword">val</span> physicalPosition = log.sizeInBytes()</div><div class="line">    <span class="keyword">if</span> (physicalPosition == <span class="number">0</span>)</div><div class="line">      rollingBasedTimestamp = <span class="type">Some</span>(largestTimestamp)</div><div class="line">    <span class="comment">// append the messages</span></div><div class="line">    require(canConvertToRelativeOffset(largestOffset), <span class="string">"largest offset in message set can not be safely converted to relative offset."</span>)</div><div class="line">    <span class="keyword">val</span> appendedBytes = log.append(records) <span class="comment">//note: 追加到数据文件中</span></div><div class="line">    trace(<span class="string">s"Appended <span class="subst">$appendedBytes</span> to <span class="subst">$&#123;log.file()&#125;</span> at offset <span class="subst">$firstOffset</span>"</span>)</div><div class="line">    <span class="comment">// Update the in memory max timestamp and corresponding offset.</span></div><div class="line">    <span class="keyword">if</span> (largestTimestamp &gt; maxTimestampSoFar) &#123;</div><div class="line">      maxTimestampSoFar = largestTimestamp</div><div class="line">      offsetOfMaxTimestamp = shallowOffsetOfMaxTimestamp</div><div class="line">    &#125;</div><div class="line">    <span class="comment">// append an entry to the index (if needed)</span></div><div class="line">    <span class="comment">//note: 判断是否需要追加索引（数据每次都会添加到数据文件中,但不是每次都会添加索引的,间隔 indexIntervalBytes 大小才会写入一个索引文件）</span></div><div class="line">    <span class="keyword">if</span>(bytesSinceLastIndexEntry &gt; indexIntervalBytes) &#123;</div><div class="line">      index.append(firstOffset, physicalPosition) <span class="comment">//note: 添加索引</span></div><div class="line">      timeIndex.maybeAppend(maxTimestampSoFar, offsetOfMaxTimestamp)</div><div class="line">      bytesSinceLastIndexEntry = <span class="number">0</span> <span class="comment">//note: 重置为0</span></div><div class="line">    &#125;</div><div class="line">    bytesSinceLastIndexEntry += records.sizeInBytes</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>经过上面的分析，一个消息集（MemoryRecords）在 Kafka 存储层的调用情况如下图所示：</p>
<p><img src="/images/kafka/log_append.png" alt="MemoryRecords 追加过程"></p>
<p>最后还是利用底层的 Java NIO 实现。</p>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[Kafka 源码解析之日志管理（十一）]]></title>
      <url>http://matt33.com/2018/03/12/kafka-log-manager/</url>
      <content type="html"><![CDATA[<p>上篇文章在介绍完 Kafka 的 GroupCoordinator 之后，下面开始介绍 Kafka 存储层的内容，也就是 Kafka Server 端 Log 部分的内容，Log 部分是 Kafka 比较底层的代码，日志的读写、分段、清理和管理都是在这一部分完成的，内容还是比较多的，会分为三篇左右的文章介绍，本篇先介绍最简单的部分，主要是日志的基本概念、日志管理、日志刷新和日志清理四部分（后两个其实也属于日志管理，为便于讲解，这里分开讲述），日志的读写和分段将在下一篇讲述。</p>
<p>本篇主要的内容如下：</p>
<ol>
<li>Kafka 中 Log 的基本概念；</li>
<li>日志管理；</li>
<li>日志刷新；</li>
<li>日志清理；</li>
</ol>
<h2 id="日志的基本概念"><a href="#日志的基本概念" class="headerlink" title="日志的基本概念"></a>日志的基本概念</h2><p>在 Kafka 的官方文档中，最开始介绍 Kafka 的一句话是：</p>
<blockquote>
<p>Kafka is a distributed, partitioned, replicated commit log service. （0.10.0 之前）</p>
<p>Apache Kafka is a distributed streaming platform. （0.10.0 及之后）</p>
</blockquote>
<p>可以说在 KafkaStream 之前，Kafka 最开始的应用场景就是日志场景或 mq 场景，更多的扮演着一个存储系统，这是 Kafka 立家之本。</p>
<p>Kafka 是一个分布式的（distributed）、可分区的（partitioned）、支持多副本（replicated）的日志提交系统，分布式这个概念很好理解，Kafka 本身就是一个分布式系统，那另外两个概念什么意思呢？</p>
<ul>
<li>可分区的：一个 topic 是可以设置多个分区的，可分区解决了单 topic 线性扩展的问题（也解决了负载均衡的问题）；</li>
<li>支持多副本的：使得 topic 可以做到更多容错性，牺牲性能与空间去换取更高的可靠性。</li>
</ul>
<p>一个 Topic 基本结果如下：</p>
<p><img src="/images/2016-03-07-KafkaMessage/topic.png" alt="Topic"></p>
<p>图中的 topic 由三个 partition 组成，topic 在创建开始，每个 partition 在写入时，其 offset 值是从0开始逐渐增加。topic 的 partition 是可以分配到 Kafka 集群的任何节点上，在实际存储时，每个 partition 是按 segment 文件去存储的（segment 的大小是在 server 端配置的，这就是日志的分段），如下图所示：</p>
<p><img src="/images/2016-03-07-KafkaMessage/segment.png" alt="Segment"></p>
<blockquote>
<p>注：上图是 0.8.2.1 版的 segment 的结构，0.10.2.0 版每个 segment 还会有一个对应的 timestrap 文件。</p>
</blockquote>
<p>再简单介绍一下 topic 的副本的概念，kafka 中为了保证一定可靠性，一般会为设置多个副本，假设一个 topic 设置了三个副本：</p>
<ul>
<li>每个 partition 都会有三个副本，这个三个副本需要分配在不同的 broker 上，在同一台 broker 上的话，就没有什么意义了；</li>
<li>这个三个副本中，会有选举出来了一个 leader，另外两个就是 follower，topic 的读写都是在 leader 上进行的，follower 从 leader 同步 partition 的数据。</li>
</ul>
<blockquote>
<p>follower 不支持读的原因，个人感觉是对于流式系统而言，如果允许 follower 也可以读的话，数据一致性、可见性将会很难保证，对最初 Kafka 的设计将会带来很大的复杂性。</p>
</blockquote>
<p>有了对 topic、partition、副本（replica）、segment、leader、follower 概念的理解之后，下面再看 Kafka 存储层的内容，就不会那么云里雾里了。 </p>
<h2 id="日志管理"><a href="#日志管理" class="headerlink" title="日志管理"></a>日志管理</h2><p>Kafka 的日志管理（LogManager）主要的作用是负责日志的创建、检索、清理，日志相关的读写操作实际上是由日志实例对象（Log）来处理的。</p>
<h3 id="KafkaServer-启动-LogManager-线程"><a href="#KafkaServer-启动-LogManager-线程" class="headerlink" title="KafkaServer 启动 LogManager 线程"></a>KafkaServer 启动 LogManager 线程</h3><p>LogManager 线程是在节点的 Kafka 服务启动时启动的，相关代码如下：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//kafka.server.KafkaServer</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">startup</span></span>() &#123;</div><div class="line">  <span class="keyword">try</span> &#123;</div><div class="line">    info(<span class="string">"starting"</span>)</div><div class="line">    <span class="comment">/* start log manager */</span></div><div class="line">    <span class="comment">//note: 启动日志管理线程</span></div><div class="line">    logManager = createLogManager(zkUtils.zkClient, brokerState)</div><div class="line">    logManager.startup()</div><div class="line">    &#125;</div><div class="line">  <span class="keyword">catch</span> &#123;</div><div class="line">    <span class="keyword">case</span> e: <span class="type">Throwable</span> =&gt;</div><div class="line">    fatal(<span class="string">"Fatal error during KafkaServer startup. Prepare to shutdown"</span>, e)</div><div class="line">    isStartingUp.set(<span class="literal">false</span>)</div><div class="line">    shutdown()</div><div class="line">    <span class="keyword">throw</span> e</div><div class="line">  &#125;</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">createLogManager</span></span>(zkClient: <span class="type">ZkClient</span>, brokerState: <span class="type">BrokerState</span>): <span class="type">LogManager</span> = &#123;</div><div class="line">  <span class="keyword">val</span> defaultProps = <span class="type">KafkaServer</span>.copyKafkaConfigToLog(config)</div><div class="line">  <span class="keyword">val</span> defaultLogConfig = <span class="type">LogConfig</span>(defaultProps)</div><div class="line"></div><div class="line">  <span class="keyword">val</span> configs = <span class="type">AdminUtils</span>.fetchAllTopicConfigs(zkUtils).map &#123; <span class="keyword">case</span> (topic, configs) =&gt;</div><div class="line">    topic -&gt; <span class="type">LogConfig</span>.fromProps(defaultProps, configs)</div><div class="line">  &#125;</div><div class="line">  <span class="comment">// read the log configurations from zookeeper</span></div><div class="line">  <span class="keyword">val</span> cleanerConfig = <span class="type">CleanerConfig</span>(numThreads = config.logCleanerThreads, <span class="comment">//note: 日志清理线程数,默认是1</span></div><div class="line">                                    dedupeBufferSize = config.logCleanerDedupeBufferSize, <span class="comment">//note: 日志清理使用的总内容,默认128MB</span></div><div class="line">                                    dedupeBufferLoadFactor = config.logCleanerDedupeBufferLoadFactor, <span class="comment">//note:  buffer load factor</span></div><div class="line">                                    ioBufferSize = config.logCleanerIoBufferSize, <span class="comment">//note:</span></div><div class="line">                                    maxMessageSize = config.messageMaxBytes, <span class="comment">//note:</span></div><div class="line">                                    maxIoBytesPerSecond = config.logCleanerIoMaxBytesPerSecond, <span class="comment">//note:</span></div><div class="line">                                    backOffMs = config.logCleanerBackoffMs, <span class="comment">//note: 没有日志清理时的 sleep 时间,默认 15s</span></div><div class="line">                                    enableCleaner = config.logCleanerEnable) <span class="comment">//note: 是否允许对 compact 日志进行清理</span></div><div class="line">  <span class="keyword">new</span> <span class="type">LogManager</span>(logDirs = config.logDirs.map(<span class="keyword">new</span> <span class="type">File</span>(_)).toArray, <span class="comment">//note: 日志目录列表</span></div><div class="line">                 topicConfigs = configs,</div><div class="line">                 defaultConfig = defaultLogConfig,</div><div class="line">                 cleanerConfig = cleanerConfig,</div><div class="line">                 ioThreads = config.numRecoveryThreadsPerDataDir,<span class="comment">//note: 每个日志目录在开始时用日志恢复以及关闭时日志flush的线程数,默认1</span></div><div class="line">                 flushCheckMs = config.logFlushSchedulerIntervalMs,</div><div class="line">                 flushCheckpointMs = config.logFlushOffsetCheckpointIntervalMs, <span class="comment">//note: 更新 check-point 的频率,默认是60s</span></div><div class="line">                 retentionCheckMs = config.logCleanupIntervalMs, <span class="comment">//note: log-cleaner 检查 topic 是否需要删除的频率,默认是5min</span></div><div class="line">                 scheduler = kafkaScheduler,</div><div class="line">                 brokerState = brokerState,</div><div class="line">                 time = time)</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h3 id="LogManager-初始化"><a href="#LogManager-初始化" class="headerlink" title="LogManager 初始化"></a>LogManager 初始化</h3><p>LogManager 在初始化时，首先会检查 server 端配置的日志目录信息，然后会加载日志目录下的所有分区日志，其实现如下：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div></pre></td><td class="code"><pre><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">LogManager</span>(<span class="params"></span>)</span>&#123;</div><div class="line">  <span class="comment">//note: 检查点表示日志已经刷新到磁盘的位置，主要是用于数据恢复</span></div><div class="line">  <span class="keyword">val</span> <span class="type">RecoveryPointCheckpointFile</span> = <span class="string">"recovery-point-offset-checkpoint"</span> <span class="comment">//note: 检查点文件</span></div><div class="line">  </div><div class="line">  <span class="keyword">private</span> <span class="keyword">val</span> logs = <span class="keyword">new</span> <span class="type">Pool</span>[<span class="type">TopicPartition</span>, <span class="type">Log</span>]() <span class="comment">//note: 分区与日志实例的对应关系</span></div><div class="line"></div><div class="line">  createAndValidateLogDirs(logDirs) <span class="comment">//note: 检查日志目录</span></div><div class="line">  <span class="keyword">private</span> <span class="keyword">val</span> dirLocks = lockLogDirs(logDirs)</div><div class="line">  <span class="comment">//note: 每个数据目录都有一个检查点文件,存储这个数据目录下所有分区的检查点信息</span></div><div class="line">  <span class="keyword">private</span> <span class="keyword">val</span> recoveryPointCheckpoints = logDirs.map(dir =&gt; (dir, <span class="keyword">new</span> <span class="type">OffsetCheckpoint</span>(<span class="keyword">new</span> <span class="type">File</span>(dir, <span class="type">RecoveryPointCheckpointFile</span>)))).toMap</div><div class="line">  loadLogs()</div><div class="line">  </div><div class="line">  <span class="comment">//note: 创建指定的数据目录,并做相应的检查:</span></div><div class="line">  <span class="comment">//note: 1.确保数据目录中没有重复的数据目录;</span></div><div class="line">  <span class="comment">//note: 2.数据不存在的话就创建相应的目录;</span></div><div class="line">  <span class="comment">//note: 3.检查每个目录路径是否是可读的。</span></div><div class="line">  <span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">createAndValidateLogDirs</span></span>(dirs: <span class="type">Seq</span>[<span class="type">File</span>]) &#123;</div><div class="line">    <span class="keyword">if</span>(dirs.map(_.getCanonicalPath).toSet.size &lt; dirs.size)</div><div class="line">      <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">KafkaException</span>(<span class="string">"Duplicate log directory found: "</span> + logDirs.mkString(<span class="string">", "</span>))</div><div class="line">    <span class="keyword">for</span>(dir &lt;- dirs) &#123;</div><div class="line">      <span class="keyword">if</span>(!dir.exists) &#123;</div><div class="line">        info(<span class="string">"Log directory '"</span> + dir.getAbsolutePath + <span class="string">"' not found, creating it."</span>)</div><div class="line">        <span class="keyword">val</span> created = dir.mkdirs()</div><div class="line">        <span class="keyword">if</span>(!created)</div><div class="line">          <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">KafkaException</span>(<span class="string">"Failed to create data directory "</span> + dir.getAbsolutePath)</div><div class="line">      &#125;</div><div class="line">      <span class="keyword">if</span>(!dir.isDirectory || !dir.canRead)</div><div class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">KafkaException</span>(dir.getAbsolutePath + <span class="string">" is not a readable log directory."</span>)</div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  <span class="comment">//note: 加载所有的日志,而每个日志也会调用 loadSegments() 方法加载所有的分段,过程比较慢,所有每个日志都会创建一个单独的线程</span></div><div class="line">  <span class="comment">//note: 日志管理器采用线程池提交任务,标识不用的任务可以同时运行</span></div><div class="line">  <span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">loadLogs</span></span>(): <span class="type">Unit</span> = &#123;</div><div class="line">    info(<span class="string">"Loading logs."</span>)</div><div class="line">    <span class="keyword">val</span> startMs = time.milliseconds</div><div class="line">    <span class="keyword">val</span> threadPools = mutable.<span class="type">ArrayBuffer</span>.empty[<span class="type">ExecutorService</span>]</div><div class="line">    <span class="keyword">val</span> jobs = mutable.<span class="type">Map</span>.empty[<span class="type">File</span>, <span class="type">Seq</span>[<span class="type">Future</span>[_]]]</div><div class="line"></div><div class="line">    <span class="keyword">for</span> (dir &lt;- <span class="keyword">this</span>.logDirs) &#123; <span class="comment">//note: 处理每一个日志目录</span></div><div class="line">      <span class="keyword">val</span> pool = <span class="type">Executors</span>.newFixedThreadPool(ioThreads) <span class="comment">//note: 默认为 1</span></div><div class="line">      threadPools.append(pool) <span class="comment">//note: 每个对应的数据目录都有一个线程池</span></div><div class="line"></div><div class="line">      <span class="keyword">val</span> cleanShutdownFile = <span class="keyword">new</span> <span class="type">File</span>(dir, <span class="type">Log</span>.<span class="type">CleanShutdownFile</span>)</div><div class="line"></div><div class="line">      <span class="keyword">if</span> (cleanShutdownFile.exists) &#123;</div><div class="line">        debug(</div><div class="line">          <span class="string">"Found clean shutdown file. "</span> +</div><div class="line">          <span class="string">"Skipping recovery for all logs in data directory: "</span> +</div><div class="line">          dir.getAbsolutePath)</div><div class="line">      &#125; <span class="keyword">else</span> &#123;</div><div class="line">        <span class="comment">// log recovery itself is being performed by `Log` class during initialization</span></div><div class="line">        brokerState.newState(<span class="type">RecoveringFromUncleanShutdown</span>)</div><div class="line">      &#125;</div><div class="line"></div><div class="line">      <span class="keyword">var</span> recoveryPoints = <span class="type">Map</span>[<span class="type">TopicPartition</span>, <span class="type">Long</span>]()</div><div class="line">      <span class="keyword">try</span> &#123;</div><div class="line">        recoveryPoints = <span class="keyword">this</span>.recoveryPointCheckpoints(dir).read <span class="comment">//note: 读取检查点文件</span></div><div class="line">      &#125; <span class="keyword">catch</span> &#123;</div><div class="line">        <span class="keyword">case</span> e: <span class="type">Exception</span> =&gt;</div><div class="line">          warn(<span class="string">"Error occured while reading recovery-point-offset-checkpoint file of directory "</span> + dir, e)</div><div class="line">          warn(<span class="string">"Resetting the recovery checkpoint to 0"</span>)</div><div class="line">      &#125;</div><div class="line"></div><div class="line">      <span class="keyword">val</span> jobsForDir = <span class="keyword">for</span> &#123;</div><div class="line">        dirContent &lt;- <span class="type">Option</span>(dir.listFiles).toList <span class="comment">//note: 数据目录下的所有日志目录</span></div><div class="line">        logDir &lt;- dirContent <span class="keyword">if</span> logDir.isDirectory <span class="comment">//note: 日志目录下每个分区目录</span></div><div class="line">      &#125; <span class="keyword">yield</span> &#123;</div><div class="line">        <span class="type">CoreUtils</span>.runnable &#123; <span class="comment">//note: 每个分区的目录都对应了一个线程</span></div><div class="line">          debug(<span class="string">"Loading log '"</span> + logDir.getName + <span class="string">"'"</span>)</div><div class="line"></div><div class="line">          <span class="keyword">val</span> topicPartition = <span class="type">Log</span>.parseTopicPartitionName(logDir)</div><div class="line">          <span class="keyword">val</span> config = topicConfigs.getOrElse(topicPartition.topic, defaultConfig)</div><div class="line">          <span class="keyword">val</span> logRecoveryPoint = recoveryPoints.getOrElse(topicPartition, <span class="number">0</span>L)</div><div class="line"></div><div class="line">          <span class="keyword">val</span> current = <span class="keyword">new</span> <span class="type">Log</span>(logDir, config, logRecoveryPoint, scheduler, time)<span class="comment">//note: 创建 Log 对象后，初始化时会加载所有的 segment</span></div><div class="line">          <span class="keyword">if</span> (logDir.getName.endsWith(<span class="type">Log</span>.<span class="type">DeleteDirSuffix</span>)) &#123; <span class="comment">//note: 该目录被标记为删除</span></div><div class="line">            <span class="keyword">this</span>.logsToBeDeleted.add(current)</div><div class="line">          &#125; <span class="keyword">else</span> &#123;</div><div class="line">            <span class="keyword">val</span> previous = <span class="keyword">this</span>.logs.put(topicPartition, current) <span class="comment">//note: 创建日志后,加入日志管理的映射表</span></div><div class="line">            <span class="keyword">if</span> (previous != <span class="literal">null</span>) &#123;</div><div class="line">              <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">IllegalArgumentException</span>(</div><div class="line">                <span class="string">"Duplicate log directories found: %s, %s!"</span>.format(</div><div class="line">                  current.dir.getAbsolutePath, previous.dir.getAbsolutePath))</div><div class="line">            &#125;</div><div class="line">          &#125;</div><div class="line">        &#125;</div><div class="line">      &#125;</div><div class="line"></div><div class="line">      jobs(cleanShutdownFile) = jobsForDir.map(pool.submit).toSeq <span class="comment">//note: 提交任务</span></div><div class="line">    &#125;</div><div class="line"></div><div class="line"></div><div class="line">    <span class="keyword">try</span> &#123;</div><div class="line">      <span class="keyword">for</span> ((cleanShutdownFile, dirJobs) &lt;- jobs) &#123;</div><div class="line">        dirJobs.foreach(_.get)</div><div class="line">        cleanShutdownFile.delete()</div><div class="line">      &#125;</div><div class="line">    &#125; <span class="keyword">catch</span> &#123;</div><div class="line">      <span class="keyword">case</span> e: <span class="type">ExecutionException</span> =&gt; &#123;</div><div class="line">        error(<span class="string">"There was an error in one of the threads during logs loading: "</span> + e.getCause)</div><div class="line">        <span class="keyword">throw</span> e.getCause</div><div class="line">      &#125;</div><div class="line">    &#125; <span class="keyword">finally</span> &#123;</div><div class="line">      threadPools.foreach(_.shutdown())</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    info(<span class="string">s"Logs loading complete in <span class="subst">$&#123;time.milliseconds - startMs&#125;</span> ms."</span>)</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>初始化 LogManger 代码有两个主要方法：</p>
<ol>
<li><code>createAndValidateLogDirs()</code>：创建指定的数据目录，并做相应的检查： 1.确保数据目录中没有重复的数据目录、2.数据目录不存在的话就创建相应的目录；3. 检查每个目录路径是否是可读的；</li>
<li><code>loadLogs()</code>：加载所有的日志分区，而每个日志也会调用 <code>loadSegments()</code> 方法加载该分区所有的 segment 文件，过程比较慢，所以 LogManager 使用线程池的方式，为每个日志的加载都会创建一个单独的线程。</li>
</ol>
<p>虽然使用的是线程池提交任务，并发进行 load 分区日志，但这个任务本身是阻塞式的，只有当所有的分区日志加载完成，才能调用 <code>startup()</code> 启动 LogManager 线程。</p>
<h3 id="LogManager-启动"><a href="#LogManager-启动" class="headerlink" title="LogManager 启动"></a>LogManager 启动</h3><p>在日志目录的所有分区日志都加载完成后，KafkaServer 调用 <code>startup()</code> 方法启动 LogManager 线程，LogManager 启动后，后台会运行四个定时任务，代码实现如下：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">startup</span></span>() &#123;</div><div class="line">  <span class="comment">/* Schedule the cleanup task to delete old logs */</span></div><div class="line">  <span class="keyword">if</span>(scheduler != <span class="literal">null</span>) &#123;</div><div class="line">    <span class="comment">//note: 定时清理过期的日志 segment,并维护日志的大小</span></div><div class="line">    info(<span class="string">"Starting log cleanup with a period of %d ms."</span>.format(retentionCheckMs))</div><div class="line">    scheduler.schedule(<span class="string">"kafka-log-retention"</span>,</div><div class="line">                       cleanupLogs,</div><div class="line">                       delay = <span class="type">InitialTaskDelayMs</span>,</div><div class="line">                       period = retentionCheckMs,</div><div class="line">                       <span class="type">TimeUnit</span>.<span class="type">MILLISECONDS</span>)</div><div class="line">    <span class="comment">//note: 定时刷新还没有写到磁盘上日志</span></div><div class="line">    info(<span class="string">"Starting log flusher with a default period of %d ms."</span>.format(flushCheckMs))</div><div class="line">    scheduler.schedule(<span class="string">"kafka-log-flusher"</span>,</div><div class="line">                       flushDirtyLogs,</div><div class="line">                       delay = <span class="type">InitialTaskDelayMs</span>,</div><div class="line">                       period = flushCheckMs,</div><div class="line">                       <span class="type">TimeUnit</span>.<span class="type">MILLISECONDS</span>)</div><div class="line">    <span class="comment">//note: 定时将所有数据目录所有日志的检查点写到检查点文件中</span></div><div class="line">    scheduler.schedule(<span class="string">"kafka-recovery-point-checkpoint"</span>,</div><div class="line">                       checkpointRecoveryPointOffsets,</div><div class="line">                       delay = <span class="type">InitialTaskDelayMs</span>,</div><div class="line">                       period = flushCheckpointMs,</div><div class="line">                       <span class="type">TimeUnit</span>.<span class="type">MILLISECONDS</span>)</div><div class="line">    <span class="comment">//note: 定时删除标记为 delete 的日志文件</span></div><div class="line">    scheduler.schedule(<span class="string">"kafka-delete-logs"</span>,</div><div class="line">                       deleteLogs,</div><div class="line">                       delay = <span class="type">InitialTaskDelayMs</span>,</div><div class="line">                       period = defaultConfig.fileDeleteDelayMs,</div><div class="line">                       <span class="type">TimeUnit</span>.<span class="type">MILLISECONDS</span>)</div><div class="line">  &#125;</div><div class="line">  <span class="comment">//note: 如果设置为 true， 自动清理 compaction 类型的 topic</span></div><div class="line">  <span class="keyword">if</span>(cleanerConfig.enableCleaner)</div><div class="line">    cleaner.startup()</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>四个后台定时线程的作用：</p>
<ol>
<li><code>cleanupLogs</code>：定时清理过期的日志 segment，并维护日志的大小（默认5min）；</li>
<li><code>flushDirtyLogs</code>：定时刷新将还没有写到磁盘上日志刷新到磁盘（默认 无限大）；</li>
<li><code>checkpointRecoveryPointOffsets</code>：定时将所有数据目录所有日志的检查点写到检查点文件中（默认 60s）；</li>
<li><code>deleteLogs</code>：定时删除标记为 delete 的日志文件（默认 30s）。</li>
</ol>
<h3 id="检查点文件"><a href="#检查点文件" class="headerlink" title="检查点文件"></a>检查点文件</h3><p>在 LogManager 中有一个非常重要的文件——检查点文件：</p>
<ol>
<li>Kafka 启动时创建 LogManager，读取检查点文件，并把每个分区对应的检查点（checkPoint）作为日志的恢复点（recoveryPoint），最后创建分区对应的日志实例；</li>
<li>消息追加到分区对应的日志，在刷新日志时，将最新的偏移量作为日志的检查点（也即是刷新日志时，会更新检查点位置）；</li>
<li>LogManager 会启动一个定时任务，读取所有日志的检查点，并写入全局的检查点文件（定时将检查点的位置更新到检查点文件中）。</li>
</ol>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//note：通常所有数据目录都会一起执行，不会专门操作某一个数据目录的检查点文件</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">checkpointRecoveryPointOffsets</span></span>() &#123;</div><div class="line">  <span class="keyword">this</span>.logDirs.foreach(checkpointLogsInDir)</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="comment">/**</span></div><div class="line"> * Make a checkpoint for all logs in provided directory.</div><div class="line"> */</div><div class="line"><span class="comment">//note: 对数据目录下的所有日志（即所有分区），将其检查点写入检查点文件</span></div><div class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">checkpointLogsInDir</span></span>(dir: <span class="type">File</span>): <span class="type">Unit</span> = &#123;</div><div class="line">  <span class="keyword">val</span> recoveryPoints = <span class="keyword">this</span>.logsByDir.get(dir.toString)</div><div class="line">  <span class="keyword">if</span> (recoveryPoints.isDefined) &#123;</div><div class="line">    <span class="keyword">this</span>.recoveryPointCheckpoints(dir).write(recoveryPoints.get.mapValues(_.recoveryPoint))</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<blockquote>
<p>这里留一个问题：启动时，如果发现检查点文件的 offset 比 segment 中最大的 offset 小时（最新的检查点在更新到文件前机器宕机了），应该怎么处理？答案将在下一篇文章中讲述。</p>
</blockquote>
<h2 id="日志刷新"><a href="#日志刷新" class="headerlink" title="日志刷新"></a>日志刷新</h2><p>日志管理器会定时调度 <code>flushDirtyLogs()</code> 方法，定期将页面缓存中的数据真正刷新到磁盘文件中。如果缓存中的数据（在 pagecache 中）在 flush 到磁盘之前，Broker 宕机了，那么会导致数据丢失（多副本减少了这个风险）。</p>
<p>在 Kafka 中有两种策略，将日志刷新到磁盘上：</p>
<ul>
<li>时间策略，（<code>log.flush.interval.ms</code> 中配置调度周期，默认为无限大，即选择大小策略）：</li>
<li>大小策略，（<code>log.flush.interval.messages</code> 中配置当未刷新的 msg 数超过这个值后，进行刷新）。</li>
</ul>
<p>LogManager 刷新日志的实现方法如下：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//note: LogManager 启动时，会启动一个周期性调度任务，调度这个方法，定时刷新日志。</span></div><div class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">flushDirtyLogs</span></span>() = &#123;</div><div class="line">  debug(<span class="string">"Checking for dirty logs to flush..."</span>)</div><div class="line"></div><div class="line">  <span class="keyword">for</span> ((topicPartition, log) &lt;- logs) &#123;</div><div class="line">    <span class="keyword">try</span> &#123;</div><div class="line">      <span class="comment">//note: 每个日志的刷新时间并不相同</span></div><div class="line">      <span class="keyword">val</span> timeSinceLastFlush = time.milliseconds - log.lastFlushTime</div><div class="line">      debug(<span class="string">"Checking if flush is needed on "</span> + topicPartition.topic + <span class="string">" flush interval  "</span> + log.config.flushMs +</div><div class="line">            <span class="string">" last flushed "</span> + log.lastFlushTime + <span class="string">" time since last flush: "</span> + timeSinceLastFlush)</div><div class="line">      <span class="keyword">if</span>(timeSinceLastFlush &gt;= log.config.flushMs)</div><div class="line">        log.flush</div><div class="line">    &#125; <span class="keyword">catch</span> &#123;</div><div class="line">      <span class="keyword">case</span> e: <span class="type">Throwable</span> =&gt;</div><div class="line">        error(<span class="string">"Error flushing topic "</span> + topicPartition.topic, e)</div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>LogManager 这个方法最后的结果还是调用了 <code>log.flush()</code> 进行刷新操作：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/**</span></div><div class="line"> * Flush all log segments</div><div class="line"> */</div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">flush</span></span>(): <span class="type">Unit</span> = flush(<span class="keyword">this</span>.logEndOffset)</div><div class="line"></div><div class="line"><span class="comment">/**</span></div><div class="line"> * Flush log segments for all offsets up to offset-1</div><div class="line"> *</div><div class="line"> * @param offset The offset to flush up to (non-inclusive); the new recovery point</div><div class="line"> */</div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">flush</span></span>(offset: <span class="type">Long</span>) : <span class="type">Unit</span> = &#123;</div><div class="line">  <span class="keyword">if</span> (offset &lt;= <span class="keyword">this</span>.recoveryPoint)</div><div class="line">    <span class="keyword">return</span></div><div class="line">  debug(<span class="string">"Flushing log '"</span> + name + <span class="string">" up to offset "</span> + offset + <span class="string">", last flushed: "</span> + lastFlushTime + <span class="string">" current time: "</span> +</div><div class="line">        time.milliseconds + <span class="string">" unflushed = "</span> + unflushedMessages)</div><div class="line">  <span class="comment">//note: 刷新检查点到最新偏移量之间的所有日志分段</span></div><div class="line">  <span class="keyword">for</span>(segment &lt;- logSegments(<span class="keyword">this</span>.recoveryPoint, offset))</div><div class="line">    segment.flush()<span class="comment">//note: 刷新数据文件和索引文件（调用操作系统的 fsync）</span></div><div class="line">  lock synchronized &#123;</div><div class="line">    <span class="keyword">if</span>(offset &gt; <span class="keyword">this</span>.recoveryPoint) &#123;</div><div class="line">      <span class="keyword">this</span>.recoveryPoint = offset</div><div class="line">      lastflushedTime.set(time.milliseconds)<span class="comment">//note: 更新刷新时间</span></div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>上面的内容实际上只是按 <code>log.flush.interval.ms</code> 设置去 flush 日志到磁盘，那么 <code>log.flush.interval.messages</code> 策略是在什么地方生效的呢？用心想一下，大家应该能猜出来，是在数据追加到 Log 中的时候，这时候会判断没有 flush 的数据大小是否达到阈值，具体实现如下所示：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// 其他部分这里暂时忽略了</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">append</span></span>(records: <span class="type">MemoryRecords</span>, assignOffsets: <span class="type">Boolean</span> = <span class="literal">true</span>): <span class="type">LogAppendInfo</span> = &#123;</div><div class="line">  <span class="comment">// now append to the log</span></div><div class="line">  segment.append(firstOffset = appendInfo.firstOffset,</div><div class="line">    largestOffset = appendInfo.lastOffset,</div><div class="line">    largestTimestamp = appendInfo.maxTimestamp,</div><div class="line">    shallowOffsetOfMaxTimestamp = appendInfo.offsetOfMaxTimestamp,</div><div class="line">    records = validRecords)</div><div class="line"></div><div class="line">  <span class="comment">// increment the log end offset</span></div><div class="line">  updateLogEndOffset(appendInfo.lastOffset + <span class="number">1</span>)</div><div class="line"></div><div class="line">  trace(<span class="string">"Appended message set to log %s with first offset: %d, next offset: %d, and messages: %s"</span></div><div class="line">    .format(<span class="keyword">this</span>.name, appendInfo.firstOffset, nextOffsetMetadata.messageOffset, validRecords))</div><div class="line"></div><div class="line">  <span class="keyword">if</span> (unflushedMessages &gt;= config.flushInterval)</div><div class="line">    flush()</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h2 id="日志清理"><a href="#日志清理" class="headerlink" title="日志清理"></a>日志清理</h2><p>为了保证分区的总大小不超过阈值（<code>log.retention.bytes</code>），日志管理器会定时清理旧的数据。</p>
<blockquote>
<p>不过一般情况下，都是通过配置 <code>log.retention.hours</code> 来配置 segment 的保存时间，而不是通过单日志的总大小配置，因为不同的 topic，其 partition 大小相差很大，导致最后的保存时间可能也不一致，不利于管理。</p>
</blockquote>
<p>清理旧日志分段方法，主要有两种：</p>
<ol>
<li>删除：超过时间或大小阈值的旧 segment，直接进行删除；</li>
<li>压缩：不是直接删除日志分段，而是采用合并压缩的方式进行。</li>
</ol>
<p>这里主要讲述第一种方法，第二种将会后续文章介绍。</p>
<p>先看下 LogManager 中日志清除任务的实现：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/**</span></div><div class="line"> * Delete any eligible logs. Return the number of segments deleted.</div><div class="line"> * Only consider logs that are not compacted.</div><div class="line"> */</div><div class="line"><span class="comment">//note: 日志清除任务</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">cleanupLogs</span></span>() &#123;</div><div class="line">  debug(<span class="string">"Beginning log cleanup..."</span>)</div><div class="line">  <span class="keyword">var</span> total = <span class="number">0</span></div><div class="line">  <span class="keyword">val</span> startMs = time.milliseconds</div><div class="line">  <span class="keyword">for</span>(log &lt;- allLogs; <span class="keyword">if</span> !log.config.compact) &#123;</div><div class="line">    debug(<span class="string">"Garbage collecting '"</span> + log.name + <span class="string">"'"</span>)</div><div class="line">    total += log.deleteOldSegments() <span class="comment">//note: 清理过期的 segment</span></div><div class="line">  &#125;</div><div class="line">  debug(<span class="string">"Log cleanup completed. "</span> + total + <span class="string">" files deleted in "</span> +</div><div class="line">                (time.milliseconds - startMs) / <span class="number">1000</span> + <span class="string">" seconds"</span>)</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>日志清除任务的实现还是在 Log 的 <code>deleteOldSegments()</code> 中实现的：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/**</span></div><div class="line">  * Delete any log segments that have either expired due to time based retention</div><div class="line">  * or because the log size is &gt; retentionSize</div><div class="line">  */</div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">deleteOldSegments</span></span>(): <span class="type">Int</span> = &#123;</div><div class="line">  <span class="keyword">if</span> (!config.delete) <span class="keyword">return</span> <span class="number">0</span></div><div class="line">  deleteRetenionMsBreachedSegments() + deleteRetentionSizeBreachedSegments()</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="comment">//note: 清除保存时间满足条件的 segment</span></div><div class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">deleteRetenionMsBreachedSegments</span></span>() : <span class="type">Int</span> = &#123;</div><div class="line">  <span class="keyword">if</span> (config.retentionMs &lt; <span class="number">0</span>) <span class="keyword">return</span> <span class="number">0</span></div><div class="line">  <span class="keyword">val</span> startMs = time.milliseconds</div><div class="line">  deleteOldSegments(startMs - _.largestTimestamp &gt; config.retentionMs)</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="comment">//note: 清除保存大小满足条件的 segment</span></div><div class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">deleteRetentionSizeBreachedSegments</span></span>() : <span class="type">Int</span> = &#123;</div><div class="line">  <span class="keyword">if</span> (config.retentionSize &lt; <span class="number">0</span> || size &lt; config.retentionSize) <span class="keyword">return</span> <span class="number">0</span></div><div class="line">  <span class="keyword">var</span> diff = size - config.retentionSize</div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">shouldDelete</span></span>(segment: <span class="type">LogSegment</span>) = &#123;</div><div class="line">    <span class="keyword">if</span> (diff - segment.size &gt;= <span class="number">0</span>) &#123;</div><div class="line">      diff -= segment.size</div><div class="line">      <span class="literal">true</span></div><div class="line">    &#125; <span class="keyword">else</span> &#123;</div><div class="line">      <span class="literal">false</span></div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line">  deleteOldSegments(shouldDelete)</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>清除日志的两个方法：</p>
<ol>
<li><code>deleteRetenionMsBreachedSegments()</code>：如果 segment 保存时间超过设置的时间，那么进行删除；</li>
<li><code>deleteRetentionSizeBreachedSegments()</code>：如果当前最新的日志大小减少下一个即将删除的 segment 分段的大小超过阈值，那么就允许删除该 segment，否则就不允许。</li>
</ol>
<p>调用 <code>deleteOldSegments()</code> 方法删除日志数据文件及索引文件的具体实现如下：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//note: 清除相应的 segment 及相应的索引文件</span></div><div class="line"><span class="comment">//note: 其中 predicate 是一个高阶函数，只有返回值为 true 该 segment 才会被删除</span></div><div class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">deleteOldSegments</span></span>(predicate: <span class="type">LogSegment</span> =&gt; <span class="type">Boolean</span>): <span class="type">Int</span> = &#123;</div><div class="line">  lock synchronized &#123;</div><div class="line">    <span class="keyword">val</span> deletable = deletableSegments(predicate)</div><div class="line">    <span class="keyword">val</span> numToDelete = deletable.size</div><div class="line">    <span class="keyword">if</span> (numToDelete &gt; <span class="number">0</span>) &#123;</div><div class="line">      <span class="comment">// we must always have at least one segment, so if we are going to delete all the segments, create a new one first</span></div><div class="line">      <span class="keyword">if</span> (segments.size == numToDelete)</div><div class="line">        roll()</div><div class="line">      <span class="comment">// remove the segments for lookups</span></div><div class="line">      deletable.foreach(deleteSegment) <span class="comment">//note: 删除 segment</span></div><div class="line">    &#125;</div><div class="line">    numToDelete</div><div class="line">  &#125;</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">deleteSegment</span></span>(segment: <span class="type">LogSegment</span>) &#123;</div><div class="line">  info(<span class="string">"Scheduling log segment %d for log %s for deletion."</span>.format(segment.baseOffset, name))</div><div class="line">  lock synchronized &#123;</div><div class="line">    segments.remove(segment.baseOffset) <span class="comment">//note:  从映射关系表中删除数据</span></div><div class="line">    asyncDeleteSegment(segment) <span class="comment">//note: 异步删除日志 segment</span></div><div class="line">  &#125;</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="comment">/**</span></div><div class="line"> * Perform an asynchronous delete on the given file if it exists (otherwise do nothing)</div><div class="line"> *</div><div class="line"> * @throws KafkaStorageException if the file can't be renamed and still exists</div><div class="line"> */</div><div class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">asyncDeleteSegment</span></span>(segment: <span class="type">LogSegment</span>) &#123;</div><div class="line">  segment.changeFileSuffixes(<span class="string">""</span>, <span class="type">Log</span>.<span class="type">DeletedFileSuffix</span>) <span class="comment">//note: 先将 segment 的数据文件和索引文件后缀添加 `.deleted`</span></div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">deleteSeg</span></span>() &#123;</div><div class="line">    info(<span class="string">"Deleting segment %d from log %s."</span>.format(segment.baseOffset, name))</div><div class="line">    segment.delete()</div><div class="line">  &#125;</div><div class="line">  scheduler.schedule(<span class="string">"delete-file"</span>, deleteSeg, delay = config.fileDeleteDelayMs) <span class="comment">//note: 异步调度进行删除</span></div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>从上面的讲解来看，Kafka LogManager 线程工作还是比较清晰简洁的，它的作用就是负责日志的创建、检索、清理，并不负责日志的读写等实际操作。</p>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[操作系统之共享对象学习]]></title>
      <url>http://matt33.com/2018/02/04/linux-mmap/</url>
      <content type="html"><![CDATA[<p>在 Kafka 的存储层这部分代码时，看到了很多地方使用操作系统的共享内存机制，Kafka 中所有日志文件的索引都是使用了 <code>mmap</code> 做内存映射，<code>mmap</code> 这块刚好也是一个值得深入学习的知识点，于是就就深入地看了一下、做了一下总结，本文的内容主要来自《深入理解操作系统》第三版 9.8 存储器映射部分。</p>
<h2 id="存储器映射"><a href="#存储器映射" class="headerlink" title="存储器映射"></a>存储器映射</h2><p>Linux 通过将一个虚拟存储器区域与一个磁盘上的对象关联起来，以初始化这个虚拟存储器区域的内容，这个过程就被称为 <strong>存储器映射(memory mapping)</strong>，虚拟存储器区域可以映射到下面两种类型的对象中的一种：</p>
<ul>
<li>Unix 文件系统的普通文件：一个区域可以映射到一个普通磁盘文件的连续部分，例如一个可执行的目标文件。文件区会被分成了页大小的片，每一片包含一个虚拟页面的初始内容。因为按需进行页面调度，所以这些虚拟页面没有实际交换进入物理存储器，直到 CPU 第一次引用页面（如果区域比文件区要大，那么就用零来填充这个区域的余下部分）；</li>
<li>匿名文件：一个区域也可以映射到一个匿名文件，匿名文件是由内核创建的，包含的是二进制零。CPU 第一次引用这样一区域内的虚拟页面时，内核就在物理存储器中找到一个合适的牺牲页面，如果该页面被修改过，就将这个页面换出来，用二进制零覆盖牺牲页面并更新页表，将这个页面标记为是驻留在存储器中的，但是要注意的是在磁盘和存储器之间并没有实际的数据传输，因为这个原因，映射到匿名文件区域中的页面有时也叫做 <strong>请求二进制零的页（demand-zero page）</strong>。</li>
</ul>
<p>上面这个是存储器映射的基础内容，理解完这部分之后，我们再来看共享对象（共享内存）和 mmap。</p>
<h2 id="共享对象"><a href="#共享对象" class="headerlink" title="共享对象"></a>共享对象</h2><p>存储器映射的出现，它是为了要解决是什么问题呢？先看一下对于操作系统来说，没有存储器映射的话面临的情况：</p>
<p>在操作系统中，进程这一抽象能够为每个进程提供自己私有的虚拟地址空间，可以免受其他进程的错误读写，但是，对于操作系统的每一个进程，它们都有同样的只读文本区域，如：每个 C 程序都需要调用一些标准的 C 库函数、需要程序需要访问只读运行时库代码的相同拷贝等等。那么如果每个进行都在物理存储器中保持这些常用代码的复制拷贝，那就是极端的浪费了。</p>
<p>而存储器映射机制的出现，就给我们提供了一种清晰的机制，用来 <strong>控制多个进程如何共享对象</strong>。</p>
<p>一个对象可以被映射到虚拟存储器的一个区域，要么作为共享对象，要么作为私有对象：</p>
<ul>
<li>如果是作为共享对象，那么这个进程对这个区域的任何写操作，对于那些也会把这个共享对象映射到它们虚拟存储器的其他进程而言也是可见的，而且这些变化，也会反映在磁盘上的原始对象中；</li>
<li>如果是作为私有对象，这样的改变，对于其他进程来说是不可变的，并且进程对这个区域所做的任何写操作都不会反映在磁盘上的对象中。</li>
</ul>
<p>关于共享对象，举一个例子，如下图所示：</p>
<p><img src="/images/linux/mmap1.png" alt="一个共享对象"></p>
<p>假设进程1将一个共享对象映射到它的虚拟地址存储器的一个区域中，如上图左边所示，现在假设进程2将同一个共享对象映射到它的地址空间（与进程1虚拟地址空间并不一定一样），如右边所示。因为每个对象都有一个唯一的文件名，内核可以迅速地判断进程1已经映射了这个对象，而且可以使进程2中的页表条目指向相应的物理页面。关键点在于即使对象被映射到了多个共享区域，物理存储器中也只需要存放共享对象的一个拷贝。</p>
<h3 id="私有对象的-copy-on-write"><a href="#私有对象的-copy-on-write" class="headerlink" title="私有对象的 copy-on-write"></a>私有对象的 copy-on-write</h3><p>在私有对象中，操作系统是使用了一种叫做 <strong>写时拷贝（copy-on-write）</strong> 的巧妙技术将其映射到虚拟存储器中的。一个私有对象开始生命周期的方式基本上与共享对象一样，在物理存储器中只保存有私有对象的一份拷贝。</p>
<ul>
<li>如下图的左边部分所示，其中两个进程将一个私有对象映射到它们虚拟存储器的不同区域，但是却共享这个对象同一个物理拷贝。这时，对于每个映射私有对象的进程，相应私有区域的页表条目都被标记为只读，并且区域结构被标记为私有的写时拷贝，只要没有进程试图写它自己的私有区域，它们就可以继续共享物理存储器中对象的一个单独拷贝；</li>
<li>如果只有有一个进程试图写私有区域的某个页面，那么这个写操作就会触发一个保护故障：如下图右边所示，该故障处理程序触发的原因是由于进程试图写私有的写时拷贝区域的一个页面引起的，它就会在物理存储器中创建这个页面的一个新拷贝，更新页表条目指向这个新拷贝，然后恢复这个页面的写权限，当故障处理程序返回时，CPU 重新执行这个写操作，现在在新创建的页面上这个写操作就可以正常执行了。</li>
</ul>
<p><img src="/images/linux/mmap2.png" alt="一个写时拷贝对象"></p>
<p>copy-on-write 最充分地使用了稀有的物理存储器。</p>
<h3 id="再看-fork-函数"><a href="#再看-fork-函数" class="headerlink" title="再看 fork 函数"></a>再看 fork 函数</h3><p>学习了虚拟存储器映射进制后，回头再看 Linux 中的 fork 函数，就会明白 fork 函数是如何创建一个带有自己独立虚拟地址控制的新进程。</p>
<ol>
<li>当 fork 函数被当前进程调用时，内核为新进程创建各种数据结构，并分配给它一个唯一的 PID；</li>
<li>为了给新进程创建虚拟存储器，它创建了当前进程的 <code>mm_struct</code>、区域结构和页表的原样拷贝，它将两个进程的每个页面都标记为只读，并将两个进程中的每个区域结构都标记为私有的写时拷贝；</li>
<li>当 fork 函数在新进程中返回时，新进程现在的虚拟存储器刚好和调用 fork 时存在的虚拟存储器相同；</li>
<li>当两个进程中的任一个进行写操作时，写时拷贝机制就会创建新页面，因此，也就为每个进程保持了私有地址空间的抽象概念。</li>
</ol>
<h2 id="mmap-函数"><a href="#mmap-函数" class="headerlink" title="mmap 函数"></a>mmap 函数</h2><p>经过前面的介绍，既然在操作系统中有了存储器映射的机制，那么我们应该怎么使用呢？这就需要引入 UNIX 中另一个重要的函数 —— <code>mmap</code>，它是用来创建新的虚拟存储器区域，并将对象映射到这些区域中。</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">void</span> *<span class="title">mmap</span><span class="params">(<span class="keyword">void</span> *start, <span class="keyword">size_t</span> length, <span class="keyword">int</span> prot, <span class="keyword">int</span> flags, <span class="keyword">int</span> fd, <span class="keyword">off_t</span> offset)</span></span>;</div></pre></td></tr></table></figure>
<p>成功执行时，<code>mmap()</code> 返回指向映射区的指针，失败时，<code>mmap()</code> 返回 <code>MAP_FAILED</code>(-1)， error被设为以下的某个值：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">EACCES：访问出错</div><div class="line">EAGAIN：文件已被锁定，或者太多的内存已被锁定</div><div class="line">EBADF：fd不是有效的文件描述词</div><div class="line">EINVAL：一个或者多个参数无效</div><div class="line">ENFILE：已达到系统对打开文件的限制</div><div class="line">ENODEV：指定文件所在的文件系统不支持内存映射</div><div class="line">ENOMEM：内存不足，或者进程已超出最大内存映射数量</div><div class="line">EPERM：权能不足，操作不允许</div><div class="line">ETXTBSY：已写的方式打开文件，同时指定MAP_DENYWRITE标志</div><div class="line">SIGSEGV：试着向只读区写入</div><div class="line">SIGBUS：试着访问不属于进程的内存区</div></pre></td></tr></table></figure>
<p>mmap 要求内核创建一个新的虚拟存储器区域，最好是从地址 <code>start</code> 开始的一个区域，并将文件描述符 fd 指定的对象的一个连续的片（chunk）映射到这个新的区域，连续的对象片大小为 <code>length</code> 字节，从距文件开始偏移量为 <code>offset</code> 字节的地方开始，<code>start</code> 地址仅仅是一个暗示，通常设置为 NULL，如下图所示。</p>
<p><img src="/images/linux/mmap3.png" alt="mmap 函数解释"></p>
<p>参数 port 包含描述新映射的虚拟存储器区域的访问权限（在相应区域结构中的 <code>vm_port</code> 位）：</p>
<ul>
<li>PORT_EXEC：这个区域内的页面由可以被 CPU 执行的指令组成；</li>
<li>PORT_READ：这个区域内的页面可读；</li>
<li>PORT_WRITE：这个区域内的页面可写；</li>
<li>PORT_NONE：这个区域内的页面不能被访问。</li>
</ul>
<p>参数 <code>flags</code> 指定映射对象的类型，映射选项和映射页是否可以共享（下面列出的只是其中一部分）</p>
<ul>
<li>MAP_ANON：表示被映射的对象就是一个匿名对象，而相应的虚拟页面是请求二进制零的；</li>
<li>MAP_PRIVATE：表示被映射的对象是一个私有的、写时拷贝的对象；</li>
<li>MAP_SHARED：表示是一个共享对象。</li>
</ul>
<p>示例如：<code>bufp = Mmap(-1, size, PORT_READ, MAP_PRIVATE|MAP_ANON, 0, 0);</code>，让内核创建一个新的包含 size 字节的只读、私有、请求二进制零的虚拟存储器区域。</p>
<p>删除虚拟存储器区域，使用 <code>int munmap(void *start, size_t length);</code>，若成功返回0，若出错返回 -1.</p>
<p>下面看一个示例：使用 mmap 实现一个功能：将一个任意大小的磁盘文件拷贝到 stdout，输入文件的名字必须作为一个命令行参数来传递。</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div></pre></td><td class="code"><pre><div class="line"><span class="meta">#<span class="meta-keyword">include</span><span class="meta-string">"csapp.h"</span></span></div><div class="line"><span class="function"><span class="keyword">void</span> <span class="title">mmapcopy</span><span class="params">(<span class="keyword">int</span> fd,<span class="keyword">int</span> size)</span></span>&#123;</div><div class="line">    <span class="keyword">char</span> *bufp;</div><div class="line">    bufp =(<span class="keyword">char</span> *)mmap(<span class="literal">NULL</span>,size,PROT_READ,MAP_PRIVATE,fd,<span class="number">0</span>);<span class="comment">//在进程空间中创建一个新的虚拟存储器区域，将磁盘文件映射到这个区域中</span></div><div class="line">    write(<span class="number">1</span>,bufp,size);<span class="comment">//将信息写入标准输出</span></div><div class="line">    <span class="comment">//POSIX 定义了 STDIN_FILENO、STDOUT_FILENO 和 STDERR_FILENO 来代替 0、1、2。这三个符号常量的定义位于头文件 unistd.h。</span></div><div class="line">        munmap(bufp,size);<span class="comment">//删除虚拟存储器区域</span></div><div class="line">    <span class="keyword">return</span>;</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">(<span class="keyword">int</span> argc,<span class="keyword">char</span> **argv)</span></span>&#123;</div><div class="line">    <span class="keyword">struct</span> stat _stat;  <span class="comment">//文末附上关于这个结构体详细内容的链接</span></div><div class="line">    <span class="keyword">int</span> fd;</div><div class="line">    <span class="keyword">if</span>(argc != <span class="number">2</span>)&#123;</div><div class="line">        <span class="built_in">printf</span>(<span class="string">"usage :%s &lt;filename&gt;"</span>,argv[<span class="number">0</span>]);</div><div class="line">        <span class="built_in">exit</span>(<span class="number">0</span>);</div><div class="line">    &#125;</div><div class="line">    fd = open(argv[<span class="number">1</span>],O_RDONLY,<span class="number">0</span>);</div><div class="line">    <span class="comment">//fd1 = open(argv[2],O_RDWR|O_APPEND,0);  以“读写+追加”模式打开一个额外的文件，将在函数里尝试向它追加信息。</span></div><div class="line"></div><div class="line">    fstat(fd,&amp;_stat);  <span class="comment">//fstat将文件标识符fd所标识的文件状态，复制到结构体stat中</span></div><div class="line">    mmapcopy(fd,_stat.st_size);</div><div class="line"></div><div class="line">    <span class="keyword">return</span> <span class="number">0</span>;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>参考文献：</p>
<ul>
<li>《深入理解操作系统 第三版》；</li>
<li><a href="http://www.cnblogs.com/huxiao-tee/p/4660352.html" target="_blank" rel="external">认真分析mmap：是什么 为什么 怎么用</a>；</li>
<li><a href="http://blog.csdn.net/qq973177663/article/details/51246267" target="_blank" rel="external">使用mmap实现一个文件输出函数</a>.</li>
</ul>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[Kafka 源码解析之 GroupCoordinator 详解（十）]]></title>
      <url>http://matt33.com/2018/01/28/server-group-coordinator/</url>
      <content type="html"><![CDATA[<p>突然发现距离上一篇文章，已经过去两个多月了，有两个月没有写博客了，之前定的是年前把这个系列写完，现在看来只能往后拖了，后面估计还有五篇文章左右，尽量在春节前完成吧。继续之前的内容开始讲解，这篇文章，主要是想把 GroupCoordinator 的内容总结一下，也算是开始了 Kafka Server 端的讲解，Kafka 的 Server 端主要有三块内容：GroupCoordinator、Controller 和 ReplicaManager，其中，GroupCoordinator 的内容是与 Consumer 端紧密结合在一起的，有一部分内容在前面已经断断续续介绍过，这里会做一个总结。</p>
<p>关于 GroupCoordinator，代码中有一段注释介绍得比较清晰，这里引用一下：</p>
<blockquote>
<p>GroupCoordinator handles general group membership and offset management.</p>
<p>Each Kafka server instantiates a coordinator which is responsible for a set of groups. Groups are assigned to coordinators based on their group names.</p>
</blockquote>
<p>简单来说就是，GroupCoordinator 是负责进行 consumer 的 group 成员与 offset 管理（但每个 GroupCoordinator 只是管理一部分的 consumer group member 和 offset 信息），那它是怎么管理的呢？这个从 GroupCoordinator 处理的 client 端请求类型可以看出来，它处理的请求类型主要有以下几种：</p>
<ol>
<li>ApiKeys.OFFSET_COMMIT;</li>
<li>ApiKeys.OFFSET_FETCH;</li>
<li>ApiKeys.JOIN_GROUP;</li>
<li>ApiKeys.LEAVE_GROUP;</li>
<li>ApiKeys.SYNC_GROUP;</li>
<li>ApiKeys.DESCRIBE_GROUPS;</li>
<li>ApiKeys.LIST_GROUPS;</li>
<li>ApiKeys.HEARTBEAT;</li>
</ol>
<p>而 Kafka Server 端要处理的请求总共有以下 21 种，其中有 8 种是由 GroupCoordinator 来完成的。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div></pre></td><td class="code"><pre><div class="line"><span class="type">ApiKeys</span>.forId(request.requestId) <span class="keyword">match</span> &#123;</div><div class="line">  <span class="keyword">case</span> <span class="type">ApiKeys</span>.<span class="type">PRODUCE</span> =&gt; handleProducerRequest(request)</div><div class="line">  <span class="keyword">case</span> <span class="type">ApiKeys</span>.<span class="type">FETCH</span> =&gt; handleFetchRequest(request)</div><div class="line">  <span class="keyword">case</span> <span class="type">ApiKeys</span>.<span class="type">LIST_OFFSETS</span> =&gt; handleOffsetRequest(request)</div><div class="line">  <span class="keyword">case</span> <span class="type">ApiKeys</span>.<span class="type">METADATA</span> =&gt; handleTopicMetadataRequest(request)</div><div class="line">  <span class="keyword">case</span> <span class="type">ApiKeys</span>.<span class="type">LEADER_AND_ISR</span> =&gt; handleLeaderAndIsrRequest(request)</div><div class="line">  <span class="keyword">case</span> <span class="type">ApiKeys</span>.<span class="type">STOP_REPLICA</span> =&gt; handleStopReplicaRequest(request)</div><div class="line">  <span class="keyword">case</span> <span class="type">ApiKeys</span>.<span class="type">UPDATE_METADATA_KEY</span> =&gt; handleUpdateMetadataRequest(request)</div><div class="line">  <span class="keyword">case</span> <span class="type">ApiKeys</span>.<span class="type">CONTROLLED_SHUTDOWN_KEY</span> =&gt; handleControlledShutdownRequest(request)</div><div class="line">  <span class="keyword">case</span> <span class="type">ApiKeys</span>.<span class="type">OFFSET_COMMIT</span> =&gt; handleOffsetCommitRequest(request)</div><div class="line">  <span class="keyword">case</span> <span class="type">ApiKeys</span>.<span class="type">OFFSET_FETCH</span> =&gt; handleOffsetFetchRequest(request)</div><div class="line">  <span class="keyword">case</span> <span class="type">ApiKeys</span>.<span class="type">GROUP_COORDINATOR</span> =&gt; handleGroupCoordinatorRequest(request)</div><div class="line">  <span class="keyword">case</span> <span class="type">ApiKeys</span>.<span class="type">JOIN_GROUP</span> =&gt; handleJoinGroupRequest(request)</div><div class="line">  <span class="keyword">case</span> <span class="type">ApiKeys</span>.<span class="type">HEARTBEAT</span> =&gt; handleHeartbeatRequest(request)</div><div class="line">  <span class="keyword">case</span> <span class="type">ApiKeys</span>.<span class="type">LEAVE_GROUP</span> =&gt; handleLeaveGroupRequest(request)</div><div class="line">  <span class="keyword">case</span> <span class="type">ApiKeys</span>.<span class="type">SYNC_GROUP</span> =&gt; handleSyncGroupRequest(request)</div><div class="line">  <span class="keyword">case</span> <span class="type">ApiKeys</span>.<span class="type">DESCRIBE_GROUPS</span> =&gt; handleDescribeGroupRequest(request)</div><div class="line">  <span class="keyword">case</span> <span class="type">ApiKeys</span>.<span class="type">LIST_GROUPS</span> =&gt; handleListGroupsRequest(request)</div><div class="line">  <span class="keyword">case</span> <span class="type">ApiKeys</span>.<span class="type">SASL_HANDSHAKE</span> =&gt; handleSaslHandshakeRequest(request)</div><div class="line">  <span class="keyword">case</span> <span class="type">ApiKeys</span>.<span class="type">API_VERSIONS</span> =&gt; handleApiVersionsRequest(request)</div><div class="line">  <span class="keyword">case</span> <span class="type">ApiKeys</span>.<span class="type">CREATE_TOPICS</span> =&gt; handleCreateTopicsRequest(request)</div><div class="line">  <span class="keyword">case</span> <span class="type">ApiKeys</span>.<span class="type">DELETE_TOPICS</span> =&gt; handleDeleteTopicsRequest(request)</div><div class="line">  <span class="keyword">case</span> requestId =&gt; <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">KafkaException</span>(<span class="string">"Unknown api code "</span> + requestId)</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h2 id="GroupCoordinator-简介"><a href="#GroupCoordinator-简介" class="headerlink" title="GroupCoordinator 简介"></a>GroupCoordinator 简介</h2><p>这里先简单看下 GroupCoordinator 的基本内容。</p>
<h3 id="GroupCoordinator-的启动"><a href="#GroupCoordinator-的启动" class="headerlink" title="GroupCoordinator 的启动"></a>GroupCoordinator 的启动</h3><p>Broker 在启动时，也就是 KafkaServer 在 <code>startup()</code> 方法中会有以下一段内容，它表示每个 Broker 在启动是都会启动 GroupCoordinator 服务。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/* start group coordinator */</span></div><div class="line"><span class="comment">// Hardcode Time.SYSTEM for now as some Streams tests fail otherwise, it would be good to fix the underlying issue</span></div><div class="line">groupCoordinator = <span class="type">GroupCoordinator</span>(config, zkUtils, replicaManager, <span class="type">Time</span>.<span class="type">SYSTEM</span>)</div><div class="line">groupCoordinator.startup()<span class="comment">//note: 启动 groupCoordinator</span></div></pre></td></tr></table></figure>
<p>GroupCoordinator 服务在调用 <code>setup()</code> 方法启动后，进行的操作如下，实际上只是把一个标志变量值 <code>isActive</code> 设置为 true，并且启动了一个后台线程来删除过期的 group metadata。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/**</span></div><div class="line">* Startup logic executed at the same time when the server starts up.</div><div class="line">*/</div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">startup</span></span>(enableMetadataExpiration: <span class="type">Boolean</span> = <span class="literal">true</span>) &#123;</div><div class="line">  info(<span class="string">"Starting up."</span>)</div><div class="line">  <span class="keyword">if</span> (enableMetadataExpiration)</div><div class="line">    groupManager.enableMetadataExpiration()</div><div class="line">  isActive.set(<span class="literal">true</span>)</div><div class="line">  info(<span class="string">"Startup complete."</span>)</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h3 id="group-如何选择相应的-GroupCoordinator"><a href="#group-如何选择相应的-GroupCoordinator" class="headerlink" title="group 如何选择相应的 GroupCoordinator"></a>group 如何选择相应的 GroupCoordinator</h3><p>要说这个，就必须介绍一下这个 <code>__consumer_offsets</code> topic 了，它是 Kafka 内部使用的一个 topic，专门用来存储 group 消费的情况，默认情况下有50个 partition，每个 partition 默认有三个副本，而具体的一个 group 的消费情况要存储到哪一个 partition 上，是根据 <code>abs(GroupId.hashCode()) % NumPartitions</code> 来计算的（其中，NumPartitions 是 <code>__consumer_offsets</code> 的 partition 数，默认是50个）。</p>
<p>对于 consumer group 而言，是根据其 <code>group.id</code> 进行 hash 并计算得到其具对应的 partition 值，该 partition leader 所在 Broker 即为该 Group 所对应的 GroupCoordinator，GroupCoordinator 会存储与该 group 相关的所有的 Meta 信息。</p>
<h3 id="GroupCoordinator-的-metadata"><a href="#GroupCoordinator-的-metadata" class="headerlink" title="GroupCoordinator 的 metadata"></a>GroupCoordinator 的 metadata</h3><p>对于 consumer group 而言，其对应的 metadata 信息主要包含一下内容：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/**</span></div><div class="line"> * Group contains the following metadata:</div><div class="line"> *</div><div class="line"> *  Membership metadata:</div><div class="line"> *  1. Members registered in this group</div><div class="line"> *  2. Current protocol assigned to the group (e.g. partition assignment strategy for consumers)</div><div class="line"> *  3. Protocol metadata associated with group members</div><div class="line"> *</div><div class="line"> *  State metadata:</div><div class="line"> *  1. group state</div><div class="line"> *  2. generation id</div><div class="line"> *  3. leader id</div><div class="line"> */</div><div class="line"><span class="meta">@nonthreadsafe</span></div><div class="line"><span class="comment">//<span class="doctag">NOTE:</span> group 的 meta 信息,对 group 级别而言,每个 group 都会有一个实例对象</span></div><div class="line"><span class="keyword">private</span>[coordinator] <span class="class"><span class="keyword">class</span> <span class="title">GroupMetadata</span>(<span class="params">val groupId: <span class="type">String</span>, initialState: <span class="type">GroupState</span> = <span class="type">Empty</span></span>) </span>&#123;</div><div class="line"></div><div class="line">  <span class="keyword">private</span> <span class="keyword">var</span> state: <span class="type">GroupState</span> = initialState <span class="comment">// group 的状态</span></div><div class="line">  <span class="keyword">private</span> <span class="keyword">val</span> members = <span class="keyword">new</span> mutable.<span class="type">HashMap</span>[<span class="type">String</span>, <span class="type">MemberMetadata</span>] <span class="comment">// group 的 member 信息</span></div><div class="line">  <span class="keyword">private</span> <span class="keyword">val</span> offsets = <span class="keyword">new</span> mutable.<span class="type">HashMap</span>[<span class="type">TopicPartition</span>, <span class="type">OffsetAndMetadata</span>] <span class="comment">//对应的 commit offset</span></div><div class="line">  <span class="keyword">private</span> <span class="keyword">val</span> pendingOffsetCommits = <span class="keyword">new</span> mutable.<span class="type">HashMap</span>[<span class="type">TopicPartition</span>, <span class="type">OffsetAndMetadata</span>] <span class="comment">// commit offset 成功后更新到上面的 map 中</span></div><div class="line"></div><div class="line">  <span class="keyword">var</span> protocolType: <span class="type">Option</span>[<span class="type">String</span>] = <span class="type">None</span></div><div class="line">  <span class="keyword">var</span> generationId = <span class="number">0</span> <span class="comment">// generation id</span></div><div class="line">  <span class="keyword">var</span> leaderId: <span class="type">String</span> = <span class="literal">null</span> <span class="comment">// leader consumer id</span></div><div class="line">  <span class="keyword">var</span> protocol: <span class="type">String</span> = <span class="literal">null</span></div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>而对于每个 consumer 而言，其 metadata 信息主要包括以下内容：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/**</span></div><div class="line"> * Member metadata contains the following metadata:</div><div class="line"> *</div><div class="line"> * Heartbeat metadata:</div><div class="line"> * 1. negotiated heartbeat session timeout 心跳超时时间</div><div class="line"> * 2. timestamp of the latest heartbeat 上次发送心跳的时间</div><div class="line"> *</div><div class="line"> * Protocol metadata:</div><div class="line"> * 1. the list of supported protocols (ordered by preference) 支持的 partition reassign 协议</div><div class="line"> * 2. the metadata associated with each protocol</div><div class="line"> *</div><div class="line"> * In addition, it also contains the following state information:</div><div class="line"> *</div><div class="line"> * 1. Awaiting rebalance callback: when the group is in the prepare-rebalance state,</div><div class="line"> *                                 its rebalance callback will be kept in the metadata if the</div><div class="line"> *                                 member has sent the join group request</div><div class="line"> * 2. Awaiting sync callback: when the group is in the awaiting-sync state, its sync callback</div><div class="line"> *                            is kept in metadata until the leader provides the group assignment</div><div class="line"> *                            and the group transitions to stable</div><div class="line"> */</div><div class="line"><span class="meta">@nonthreadsafe</span></div><div class="line"><span class="comment">//<span class="doctag">NOTE:</span> 记录 group 中每个成员的状态信息</span></div><div class="line"><span class="keyword">private</span>[coordinator] <span class="class"><span class="keyword">class</span> <span class="title">MemberMetadata</span>(<span class="params">val memberId: <span class="type">String</span>,</span></span></div><div class="line">                                          val groupId: <span class="type">String</span>,</div><div class="line">                                          val clientId: <span class="type">String</span>,</div><div class="line">                                          val clientHost: <span class="type">String</span>,</div><div class="line">                                          val rebalanceTimeoutMs: <span class="type">Int</span>,</div><div class="line">                                          val sessionTimeoutMs: <span class="type">Int</span>,</div><div class="line">                                          val protocolType: <span class="type">String</span>,</div><div class="line">                                          var supportedProtocols: <span class="type">List</span>[(<span class="type">String</span>, <span class="type">Array</span>[<span class="type">Byte</span>])]) &#123;&#125;</div></pre></td></tr></table></figure>
<h2 id="GroupCoordinator-请求处理"><a href="#GroupCoordinator-请求处理" class="headerlink" title="GroupCoordinator 请求处理"></a>GroupCoordinator 请求处理</h2><p>正如前面所述，Kafka Server 端可以介绍的21种请求中，其中有8种是由 GroupCoordinator 来处理的，这里主要介绍一下，GroupCoordinator 如何处理这些请求的。</p>
<h3 id="Offset-请求的处理"><a href="#Offset-请求的处理" class="headerlink" title="Offset 请求的处理"></a>Offset 请求的处理</h3><p>关于 Offset 请求的处理，有两个：</p>
<ul>
<li>OFFSET_FETCH：查询 offset；</li>
<li>OFFSET_COMMIT：提供 offset；</li>
</ul>
<h4 id="OFFSET-FETCH-请求处理"><a href="#OFFSET-FETCH-请求处理" class="headerlink" title="OFFSET_FETCH 请求处理"></a>OFFSET_FETCH 请求处理</h4><p>关于 OFFSET_FETCH 请求，Server 端的处理如下，新版 offset 默认是保存在 Kafka 中，这里也以保存在 Kafka 中为例，从下面的实现中也可以看出，在 fetch commit 是分两种情况：</p>
<ul>
<li>获取 group 所消费的所有 topic-partition 的 offset；</li>
<li>获取指定 topic-partition 的 offset。</li>
</ul>
<p>两种情况都是调用 <code>coordinator.handleFetchOffsets()</code> 方法实现的。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/**</span></div><div class="line"> * Handle an offset fetch request</div><div class="line"> */</div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">handleOffsetFetchRequest</span></span>(request: <span class="type">RequestChannel</span>.<span class="type">Request</span>) &#123;</div><div class="line">  <span class="keyword">val</span> header = request.header</div><div class="line">  <span class="keyword">val</span> offsetFetchRequest = request.body.asInstanceOf[<span class="type">OffsetFetchRequest</span>]</div><div class="line"></div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">authorizeTopicDescribe</span></span>(partition: <span class="type">TopicPartition</span>) =</div><div class="line">    authorize(request.session, <span class="type">Describe</span>, <span class="keyword">new</span> <span class="type">Resource</span>(auth.<span class="type">Topic</span>, partition.topic)) <span class="comment">//note: 验证 Describe 权限</span></div><div class="line"></div><div class="line">  <span class="keyword">val</span> offsetFetchResponse =</div><div class="line">    <span class="comment">// reject the request if not authorized to the group</span></div><div class="line">    <span class="keyword">if</span> (!authorize(request.session, <span class="type">Read</span>, <span class="keyword">new</span> <span class="type">Resource</span>(<span class="type">Group</span>, offsetFetchRequest.groupId)))</div><div class="line">      offsetFetchRequest.getErrorResponse(<span class="type">Errors</span>.<span class="type">GROUP_AUTHORIZATION_FAILED</span>)</div><div class="line">    <span class="keyword">else</span> &#123;</div><div class="line">      <span class="keyword">if</span> (header.apiVersion == <span class="number">0</span>) &#123;</div><div class="line">        <span class="keyword">val</span> (authorizedPartitions, unauthorizedPartitions) = offsetFetchRequest.partitions.asScala</div><div class="line">          .partition(authorizeTopicDescribe)</div><div class="line"></div><div class="line">        <span class="comment">// version 0 reads offsets from ZK</span></div><div class="line">        <span class="keyword">val</span> authorizedPartitionData = authorizedPartitions.map &#123; topicPartition =&gt;</div><div class="line">          <span class="keyword">val</span> topicDirs = <span class="keyword">new</span> <span class="type">ZKGroupTopicDirs</span>(offsetFetchRequest.groupId, topicPartition.topic)</div><div class="line">          <span class="keyword">try</span> &#123;</div><div class="line">            <span class="keyword">if</span> (!metadataCache.contains(topicPartition.topic))</div><div class="line">              (topicPartition, <span class="type">OffsetFetchResponse</span>.<span class="type">UNKNOWN_PARTITION</span>)</div><div class="line">            <span class="keyword">else</span> &#123;</div><div class="line">              <span class="keyword">val</span> payloadOpt = zkUtils.readDataMaybeNull(<span class="string">s"<span class="subst">$&#123;topicDirs.consumerOffsetDir&#125;</span>/<span class="subst">$&#123;topicPartition.partition&#125;</span>"</span>)._1</div><div class="line">              payloadOpt <span class="keyword">match</span> &#123;</div><div class="line">                <span class="keyword">case</span> <span class="type">Some</span>(payload) =&gt;</div><div class="line">                  (topicPartition, <span class="keyword">new</span> <span class="type">OffsetFetchResponse</span>.<span class="type">PartitionData</span>(</div><div class="line">                      payload.toLong, <span class="type">OffsetFetchResponse</span>.<span class="type">NO_METADATA</span>, <span class="type">Errors</span>.<span class="type">NONE</span>))</div><div class="line">                <span class="keyword">case</span> <span class="type">None</span> =&gt;</div><div class="line">                  (topicPartition, <span class="type">OffsetFetchResponse</span>.<span class="type">UNKNOWN_PARTITION</span>)</div><div class="line">              &#125;</div><div class="line">            &#125;</div><div class="line">          &#125; <span class="keyword">catch</span> &#123;</div><div class="line">            <span class="keyword">case</span> e: <span class="type">Throwable</span> =&gt;</div><div class="line">              (topicPartition, <span class="keyword">new</span> <span class="type">OffsetFetchResponse</span>.<span class="type">PartitionData</span>(</div><div class="line">                  <span class="type">OffsetFetchResponse</span>.<span class="type">INVALID_OFFSET</span>, <span class="type">OffsetFetchResponse</span>.<span class="type">NO_METADATA</span>, <span class="type">Errors</span>.forException(e)))</div><div class="line">          &#125;</div><div class="line">        &#125;.toMap</div><div class="line"></div><div class="line">        <span class="keyword">val</span> unauthorizedPartitionData = unauthorizedPartitions.map(_ -&gt; <span class="type">OffsetFetchResponse</span>.<span class="type">UNKNOWN_PARTITION</span>).toMap</div><div class="line">        <span class="keyword">new</span> <span class="type">OffsetFetchResponse</span>(<span class="type">Errors</span>.<span class="type">NONE</span>, (authorizedPartitionData ++ unauthorizedPartitionData).asJava, header.apiVersion)</div><div class="line">      &#125; <span class="keyword">else</span> &#123;</div><div class="line">        <span class="comment">// versions 1 and above read offsets from Kafka</span></div><div class="line">        <span class="keyword">if</span> (offsetFetchRequest.isAllPartitions) &#123;<span class="comment">//note: 获取这个 group 消费的所有 tp offset</span></div><div class="line">          <span class="keyword">val</span> (error, allPartitionData) = coordinator.handleFetchOffsets(offsetFetchRequest.groupId)</div><div class="line">          <span class="keyword">if</span> (error != <span class="type">Errors</span>.<span class="type">NONE</span>)</div><div class="line">            offsetFetchRequest.getErrorResponse(error)</div><div class="line">          <span class="keyword">else</span> &#123;</div><div class="line">            <span class="comment">// clients are not allowed to see offsets for topics that are not authorized for Describe</span></div><div class="line">            <span class="comment">//note: 如果没有 Describe 权限的话,不能查看相应的 offset</span></div><div class="line">            <span class="keyword">val</span> authorizedPartitionData = allPartitionData.filter &#123; <span class="keyword">case</span> (topicPartition, _) =&gt; authorizeTopicDescribe(topicPartition) &#125;</div><div class="line">            <span class="keyword">new</span> <span class="type">OffsetFetchResponse</span>(<span class="type">Errors</span>.<span class="type">NONE</span>, authorizedPartitionData.asJava, header.apiVersion)</div><div class="line">          &#125;</div><div class="line">        &#125; <span class="keyword">else</span> &#123; <span class="comment">//note: 获取指定列表的 tp offset</span></div><div class="line">          <span class="keyword">val</span> (authorizedPartitions, unauthorizedPartitions) = offsetFetchRequest.partitions.asScala</div><div class="line">            .partition(authorizeTopicDescribe)</div><div class="line">          <span class="keyword">val</span> (error, authorizedPartitionData) = coordinator.handleFetchOffsets(offsetFetchRequest.groupId,</div><div class="line">            <span class="type">Some</span>(authorizedPartitions))</div><div class="line">          <span class="keyword">if</span> (error != <span class="type">Errors</span>.<span class="type">NONE</span>)</div><div class="line">            offsetFetchRequest.getErrorResponse(error)</div><div class="line">          <span class="keyword">else</span> &#123;</div><div class="line">            <span class="keyword">val</span> unauthorizedPartitionData = unauthorizedPartitions.map(_ -&gt; <span class="type">OffsetFetchResponse</span>.<span class="type">UNKNOWN_PARTITION</span>).toMap</div><div class="line">            <span class="keyword">new</span> <span class="type">OffsetFetchResponse</span>(<span class="type">Errors</span>.<span class="type">NONE</span>, (authorizedPartitionData ++ unauthorizedPartitionData).asJava, header.apiVersion)</div><div class="line">          &#125;</div><div class="line">        &#125;</div><div class="line">      &#125;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">  trace(<span class="string">s"Sending offset fetch response <span class="subst">$offsetFetchResponse</span> for correlation id <span class="subst">$&#123;header.correlationId&#125;</span> to client <span class="subst">$&#123;header.clientId&#125;</span>."</span>)</div><div class="line">  requestChannel.sendResponse(<span class="keyword">new</span> <span class="type">Response</span>(request, offsetFetchResponse))</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>在 <code>coordinator.handleFetchOffsets()</code> 的实现中，主要是调用了 <code>groupManager.getOffsets()</code> 获取相应的 offset 信息，在查询时加锁的原因应该是为了避免在查询的过程中 offset 不断更新。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">getOffsets</span></span>(groupId: <span class="type">String</span>, topicPartitionsOpt: <span class="type">Option</span>[<span class="type">Seq</span>[<span class="type">TopicPartition</span>]]): <span class="type">Map</span>[<span class="type">TopicPartition</span>, <span class="type">OffsetFetchResponse</span>.<span class="type">PartitionData</span>] = &#123;</div><div class="line">  trace(<span class="string">"Getting offsets of %s for group %s."</span>.format(topicPartitionsOpt.getOrElse(<span class="string">"all partitions"</span>), groupId))</div><div class="line">  <span class="keyword">val</span> group = groupMetadataCache.get(groupId)</div><div class="line">  <span class="keyword">if</span> (group == <span class="literal">null</span>) &#123;</div><div class="line">    topicPartitionsOpt.getOrElse(<span class="type">Seq</span>.empty[<span class="type">TopicPartition</span>]).map &#123; topicPartition =&gt;</div><div class="line">      (topicPartition, <span class="keyword">new</span> <span class="type">OffsetFetchResponse</span>.<span class="type">PartitionData</span>(<span class="type">OffsetFetchResponse</span>.<span class="type">INVALID_OFFSET</span>, <span class="string">""</span>, <span class="type">Errors</span>.<span class="type">NONE</span>))</div><div class="line">    &#125;.toMap</div><div class="line">  &#125; <span class="keyword">else</span> &#123;</div><div class="line">    group synchronized &#123;</div><div class="line">      <span class="keyword">if</span> (group.is(<span class="type">Dead</span>)) &#123; <span class="comment">//note: group 状态已经变成 dead, offset 返回 -1（INVALID_OFFSET）</span></div><div class="line">        topicPartitionsOpt.getOrElse(<span class="type">Seq</span>.empty[<span class="type">TopicPartition</span>]).map &#123; topicPartition =&gt;</div><div class="line">          (topicPartition, <span class="keyword">new</span> <span class="type">OffsetFetchResponse</span>.<span class="type">PartitionData</span>(<span class="type">OffsetFetchResponse</span>.<span class="type">INVALID_OFFSET</span>, <span class="string">""</span>, <span class="type">Errors</span>.<span class="type">NONE</span>))</div><div class="line">        &#125;.toMap</div><div class="line">      &#125; <span class="keyword">else</span> &#123;</div><div class="line">          topicPartitionsOpt <span class="keyword">match</span> &#123;</div><div class="line">            <span class="keyword">case</span> <span class="type">None</span> =&gt; <span class="comment">//note: 返回 group 消费的所有 tp 的 offset 信息（只返回这边已有 offset 的 tp）</span></div><div class="line">              <span class="comment">// Return offsets for all partitions owned by this consumer group. (this only applies to consumers</span></div><div class="line">              <span class="comment">// that commit offsets to Kafka.)</span></div><div class="line">              group.allOffsets.map &#123; <span class="keyword">case</span> (topicPartition, offsetAndMetadata) =&gt;</div><div class="line">                topicPartition -&gt; <span class="keyword">new</span> <span class="type">OffsetFetchResponse</span>.<span class="type">PartitionData</span>(offsetAndMetadata.offset, offsetAndMetadata.metadata, <span class="type">Errors</span>.<span class="type">NONE</span>)</div><div class="line">              &#125;</div><div class="line"></div><div class="line">            <span class="keyword">case</span> <span class="type">Some</span>(topicPartitions) =&gt;</div><div class="line">              topicPartitionsOpt.getOrElse(<span class="type">Seq</span>.empty[<span class="type">TopicPartition</span>]).map &#123; topicPartition =&gt;</div><div class="line">                <span class="keyword">val</span> partitionData = group.offset(topicPartition) <span class="keyword">match</span> &#123;</div><div class="line">                  <span class="keyword">case</span> <span class="type">None</span> =&gt; <span class="comment">//note: offset 没有的话就返回-1</span></div><div class="line">                    <span class="keyword">new</span> <span class="type">OffsetFetchResponse</span>.<span class="type">PartitionData</span>(<span class="type">OffsetFetchResponse</span>.<span class="type">INVALID_OFFSET</span>, <span class="string">""</span>, <span class="type">Errors</span>.<span class="type">NONE</span>)</div><div class="line">                  <span class="keyword">case</span> <span class="type">Some</span>(offsetAndMetadata) =&gt;</div><div class="line">                    <span class="keyword">new</span> <span class="type">OffsetFetchResponse</span>.<span class="type">PartitionData</span>(offsetAndMetadata.offset, offsetAndMetadata.metadata, <span class="type">Errors</span>.<span class="type">NONE</span>)</div><div class="line">                &#125;</div><div class="line">                topicPartition -&gt; partitionData</div><div class="line">              &#125;.toMap</div><div class="line">          &#125;</div><div class="line">      &#125;</div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h4 id="OFFSET-COMMIT-请求处理"><a href="#OFFSET-COMMIT-请求处理" class="headerlink" title="OFFSET_COMMIT 请求处理"></a>OFFSET_COMMIT 请求处理</h4><p>对 OFFSET_COMMIT 请求的处理，部分内容已经介绍过，可以参考 <a href="http://matt33.com/2017/11/18/consumer-subscribe/#commit-offset-%E8%AF%B7%E6%B1%82%E5%A4%84%E7%90%86">commit offset 请求处理</a>，处理过程如下：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">doCommitOffsets</span></span>(group: <span class="type">GroupMetadata</span>,</div><div class="line">                    memberId: <span class="type">String</span>,</div><div class="line">                    generationId: <span class="type">Int</span>,</div><div class="line">                    offsetMetadata: immutable.<span class="type">Map</span>[<span class="type">TopicPartition</span>, <span class="type">OffsetAndMetadata</span>],</div><div class="line">                    responseCallback: immutable.<span class="type">Map</span>[<span class="type">TopicPartition</span>, <span class="type">Short</span>] =&gt; <span class="type">Unit</span>) &#123;</div><div class="line">  <span class="keyword">var</span> delayedOffsetStore: <span class="type">Option</span>[<span class="type">DelayedStore</span>] = <span class="type">None</span></div><div class="line"></div><div class="line">  group synchronized &#123;</div><div class="line">    <span class="keyword">if</span> (group.is(<span class="type">Dead</span>)) &#123;</div><div class="line">      responseCallback(offsetMetadata.mapValues(_ =&gt; <span class="type">Errors</span>.<span class="type">UNKNOWN_MEMBER_ID</span>.code))</div><div class="line">    &#125; <span class="keyword">else</span> <span class="keyword">if</span> (generationId &lt; <span class="number">0</span> &amp;&amp; group.is(<span class="type">Empty</span>)) &#123;<span class="comment">//note: 来自 assign 的情况</span></div><div class="line">      <span class="comment">// the group is only using Kafka to store offsets</span></div><div class="line">      delayedOffsetStore = groupManager.prepareStoreOffsets(group, memberId, generationId,</div><div class="line">        offsetMetadata, responseCallback)</div><div class="line">    &#125; <span class="keyword">else</span> <span class="keyword">if</span> (group.is(<span class="type">AwaitingSync</span>)) &#123;</div><div class="line">      responseCallback(offsetMetadata.mapValues(_ =&gt; <span class="type">Errors</span>.<span class="type">REBALANCE_IN_PROGRESS</span>.code))</div><div class="line">    &#125; <span class="keyword">else</span> <span class="keyword">if</span> (!group.has(memberId)) &#123;<span class="comment">//note: 有可能 simple 与 high level 的冲突了,这里就直接拒绝相应的请求</span></div><div class="line">      responseCallback(offsetMetadata.mapValues(_ =&gt; <span class="type">Errors</span>.<span class="type">UNKNOWN_MEMBER_ID</span>.code))</div><div class="line">    &#125; <span class="keyword">else</span> <span class="keyword">if</span> (generationId != group.generationId) &#123;</div><div class="line">      responseCallback(offsetMetadata.mapValues(_ =&gt; <span class="type">Errors</span>.<span class="type">ILLEGAL_GENERATION</span>.code))</div><div class="line">    &#125; <span class="keyword">else</span> &#123;</div><div class="line">      <span class="keyword">val</span> member = group.get(memberId)</div><div class="line">      completeAndScheduleNextHeartbeatExpiration(group, member)<span class="comment">//note: 更新下次需要的心跳时间</span></div><div class="line">      delayedOffsetStore = groupManager.prepareStoreOffsets(group, memberId, generationId,</div><div class="line">        offsetMetadata, responseCallback) <span class="comment">//note: commit offset</span></div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  <span class="comment">// store the offsets without holding the group lock</span></div><div class="line">  delayedOffsetStore.foreach(groupManager.store)</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>这里主要介绍一下 <code>groupManager.prepareStoreOffsets()</code> 方法，处理逻辑如下，这里简单说一下其 offset 存储的过程：</p>
<ol>
<li>首先过滤掉那些 offset 超过范围的 metadata；</li>
<li>将 offset 信息追加到 replicated log 中；</li>
<li>调用 <code>prepareOffsetCommit()</code> 方法，先将 offset 信息更新到 group 的 pendingOffsetCommits 中（这时还没有真正提交，后面如果失败的话，是可以撤回的）；</li>
<li>在 <code>putCacheCallback</code> 回调函数中，如果 offset 信息追加到 replicated log 成功，那么就更新缓存（将 group 的 pendingOffsetCommits 中的信息更新到 offset 变量中）。</li>
</ol>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/**</span></div><div class="line"> * Store offsets by appending it to the replicated log and then inserting to cache</div><div class="line"> */</div><div class="line"><span class="comment">//note: 记录 commit 的 offset</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">prepareStoreOffsets</span></span>(group: <span class="type">GroupMetadata</span>,</div><div class="line">                        consumerId: <span class="type">String</span>,</div><div class="line">                        generationId: <span class="type">Int</span>,</div><div class="line">                        offsetMetadata: immutable.<span class="type">Map</span>[<span class="type">TopicPartition</span>, <span class="type">OffsetAndMetadata</span>],</div><div class="line">                        responseCallback: immutable.<span class="type">Map</span>[<span class="type">TopicPartition</span>, <span class="type">Short</span>] =&gt; <span class="type">Unit</span>): <span class="type">Option</span>[<span class="type">DelayedStore</span>] = &#123;</div><div class="line">  <span class="comment">// first filter out partitions with offset metadata size exceeding limit</span></div><div class="line">  <span class="comment">//note: 首先过滤掉 offset 信息超过范围的 metadata</span></div><div class="line">  <span class="keyword">val</span> filteredOffsetMetadata = offsetMetadata.filter &#123; <span class="keyword">case</span> (_, offsetAndMetadata) =&gt;</div><div class="line">    validateOffsetMetadataLength(offsetAndMetadata.metadata)</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  <span class="comment">// construct the message set to append</span></div><div class="line">  <span class="comment">//note: 构造一个 msg set 追加</span></div><div class="line">  getMagicAndTimestamp(partitionFor(group.groupId)) <span class="keyword">match</span> &#123;</div><div class="line">    <span class="keyword">case</span> <span class="type">Some</span>((magicValue, timestampType, timestamp)) =&gt;</div><div class="line">      <span class="keyword">val</span> records = filteredOffsetMetadata.map &#123; <span class="keyword">case</span> (topicPartition, offsetAndMetadata) =&gt;</div><div class="line">        <span class="type">Record</span>.create(magicValue, timestampType, timestamp,</div><div class="line">          <span class="type">GroupMetadataManager</span>.offsetCommitKey(group.groupId, topicPartition), <span class="comment">//note: key是一个三元组: group、topic、partition</span></div><div class="line">          <span class="type">GroupMetadataManager</span>.offsetCommitValue(offsetAndMetadata))</div><div class="line">      &#125;.toSeq</div><div class="line"></div><div class="line">      <span class="keyword">val</span> offsetTopicPartition = <span class="keyword">new</span> <span class="type">TopicPartition</span>(<span class="type">Topic</span>.<span class="type">GroupMetadataTopicName</span>, partitionFor(group.groupId))</div><div class="line"></div><div class="line">      <span class="comment">//note: 将 offset 信息追加到 replicated log 中</span></div><div class="line">      <span class="keyword">val</span> entries = <span class="type">Map</span>(offsetTopicPartition -&gt; <span class="type">MemoryRecords</span>.withRecords(timestampType, compressionType, records:_*))</div><div class="line"></div><div class="line">      <span class="comment">// set the callback function to insert offsets into cache after log append completed</span></div><div class="line">      <span class="function"><span class="keyword">def</span> <span class="title">putCacheCallback</span></span>(responseStatus: <span class="type">Map</span>[<span class="type">TopicPartition</span>, <span class="type">PartitionResponse</span>]) &#123;</div><div class="line">        <span class="comment">// the append response should only contain the topics partition</span></div><div class="line">        <span class="keyword">if</span> (responseStatus.size != <span class="number">1</span> || ! responseStatus.contains(offsetTopicPartition))</div><div class="line">          <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">IllegalStateException</span>(<span class="string">"Append status %s should only have one partition %s"</span></div><div class="line">            .format(responseStatus, offsetTopicPartition))</div><div class="line"></div><div class="line">        <span class="comment">// construct the commit response status and insert</span></div><div class="line">        <span class="comment">// the offset and metadata to cache if the append status has no error</span></div><div class="line">        <span class="keyword">val</span> status = responseStatus(offsetTopicPartition)</div><div class="line"></div><div class="line">        <span class="keyword">val</span> responseCode =</div><div class="line">          group synchronized &#123;</div><div class="line">            <span class="keyword">if</span> (status.error == <span class="type">Errors</span>.<span class="type">NONE</span>) &#123; <span class="comment">//note: 如果已经追加到了 replicated log 中了,那么就更新其缓存</span></div><div class="line">              <span class="keyword">if</span> (!group.is(<span class="type">Dead</span>)) &#123; <span class="comment">//note: 更新到 group 的 offset 中</span></div><div class="line">                filteredOffsetMetadata.foreach &#123; <span class="keyword">case</span> (topicPartition, offsetAndMetadata) =&gt;</div><div class="line">                  group.completePendingOffsetWrite(topicPartition, offsetAndMetadata)</div><div class="line">                &#125;</div><div class="line">              &#125;</div><div class="line">              <span class="type">Errors</span>.<span class="type">NONE</span>.code</div><div class="line">            &#125; <span class="keyword">else</span> &#123;</div><div class="line">              <span class="keyword">if</span> (!group.is(<span class="type">Dead</span>)) &#123;</div><div class="line">                filteredOffsetMetadata.foreach &#123; <span class="keyword">case</span> (topicPartition, offsetAndMetadata) =&gt;</div><div class="line">                  group.failPendingOffsetWrite(topicPartition, offsetAndMetadata)</div><div class="line">                &#125;</div><div class="line">              &#125;</div><div class="line"></div><div class="line">              debug(<span class="string">s"Offset commit <span class="subst">$filteredOffsetMetadata</span> from group <span class="subst">$&#123;group.groupId&#125;</span>, consumer <span class="subst">$consumerId</span> "</span> +</div><div class="line">                <span class="string">s"with generation <span class="subst">$generationId</span> failed when appending to log due to <span class="subst">$&#123;status.error.exceptionName&#125;</span>"</span>)</div><div class="line"></div><div class="line">              <span class="comment">// transform the log append error code to the corresponding the commit status error code</span></div><div class="line">              <span class="keyword">val</span> responseError = status.error <span class="keyword">match</span> &#123;</div><div class="line">                <span class="keyword">case</span> <span class="type">Errors</span>.<span class="type">UNKNOWN_TOPIC_OR_PARTITION</span></div><div class="line">                     | <span class="type">Errors</span>.<span class="type">NOT_ENOUGH_REPLICAS</span></div><div class="line">                     | <span class="type">Errors</span>.<span class="type">NOT_ENOUGH_REPLICAS_AFTER_APPEND</span> =&gt;</div><div class="line">                  <span class="type">Errors</span>.<span class="type">GROUP_COORDINATOR_NOT_AVAILABLE</span></div><div class="line"></div><div class="line">                <span class="keyword">case</span> <span class="type">Errors</span>.<span class="type">NOT_LEADER_FOR_PARTITION</span> =&gt;</div><div class="line">                  <span class="type">Errors</span>.<span class="type">NOT_COORDINATOR_FOR_GROUP</span></div><div class="line"></div><div class="line">                <span class="keyword">case</span> <span class="type">Errors</span>.<span class="type">MESSAGE_TOO_LARGE</span></div><div class="line">                     | <span class="type">Errors</span>.<span class="type">RECORD_LIST_TOO_LARGE</span></div><div class="line">                     | <span class="type">Errors</span>.<span class="type">INVALID_FETCH_SIZE</span> =&gt;</div><div class="line">                  <span class="type">Errors</span>.<span class="type">INVALID_COMMIT_OFFSET_SIZE</span></div><div class="line"></div><div class="line">                <span class="keyword">case</span> other =&gt; other</div><div class="line">              &#125;</div><div class="line"></div><div class="line">              responseError.code</div><div class="line">            &#125;</div><div class="line">          &#125;</div><div class="line"></div><div class="line">        <span class="comment">// compute the final error codes for the commit response</span></div><div class="line">        <span class="keyword">val</span> commitStatus = offsetMetadata.map &#123; <span class="keyword">case</span> (topicPartition, offsetAndMetadata) =&gt;</div><div class="line">          <span class="keyword">if</span> (validateOffsetMetadataLength(offsetAndMetadata.metadata))</div><div class="line">            (topicPartition, responseCode)</div><div class="line">          <span class="keyword">else</span></div><div class="line">            (topicPartition, <span class="type">Errors</span>.<span class="type">OFFSET_METADATA_TOO_LARGE</span>.code)</div><div class="line">        &#125;</div><div class="line"></div><div class="line">        <span class="comment">// finally trigger the callback logic passed from the API layer</span></div><div class="line">        responseCallback(commitStatus)</div><div class="line">      &#125;</div><div class="line"></div><div class="line">      group synchronized &#123;</div><div class="line">        group.prepareOffsetCommit(offsetMetadata) <span class="comment">//note: 添加到 group 的 pendingOffsetCommits 中</span></div><div class="line">      &#125;</div><div class="line"></div><div class="line">      <span class="type">Some</span>(<span class="type">DelayedStore</span>(entries, putCacheCallback)) <span class="comment">//note:</span></div><div class="line"></div><div class="line">    <span class="keyword">case</span> <span class="type">None</span> =&gt;</div><div class="line">      <span class="keyword">val</span> commitStatus = offsetMetadata.map &#123; <span class="keyword">case</span> (topicPartition, offsetAndMetadata) =&gt;</div><div class="line">        (topicPartition, <span class="type">Errors</span>.<span class="type">NOT_COORDINATOR_FOR_GROUP</span>.code)</div><div class="line">      &#125;</div><div class="line">      responseCallback(commitStatus)</div><div class="line">      <span class="type">None</span></div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h3 id="group-相关的处理"><a href="#group-相关的处理" class="headerlink" title="group 相关的处理"></a>group 相关的处理</h3><p>这一小节主要介绍 GroupCoordinator 处理 group 相关的请求。</p>
<h4 id="JOIN-GROUP-和-SYNC-GROUP请求处理"><a href="#JOIN-GROUP-和-SYNC-GROUP请求处理" class="headerlink" title="JOIN_GROUP 和 SYNC_GROUP请求处理"></a>JOIN_GROUP 和 SYNC_GROUP请求处理</h4><p>这两个请求的处理实际上在 <a href="http://matt33.com/2017/10/22/consumer-join-group/">Kafka 源码解析之 Consumer 如何加入一个 Group（六）</a> 中已经详细介绍过，这里就不再陈述。</p>
<h4 id="DESCRIBE-GROUPS-请求处理"><a href="#DESCRIBE-GROUPS-请求处理" class="headerlink" title="DESCRIBE_GROUPS 请求处理"></a>DESCRIBE_GROUPS 请求处理</h4><p>关于 DESCRIBE_GROUPS 请求处理实现如下，主要是返回 group 中各个 member 的详细信息，包含的变量信息为 <code>memberId, clientId, clientHost, metadata(protocol), assignment</code>。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">handleDescribeGroup</span></span>(groupId: <span class="type">String</span>): (<span class="type">Errors</span>, <span class="type">GroupSummary</span>) = &#123;</div><div class="line">  <span class="keyword">if</span> (!isActive.get) &#123;</div><div class="line">    (<span class="type">Errors</span>.<span class="type">GROUP_COORDINATOR_NOT_AVAILABLE</span>, <span class="type">GroupCoordinator</span>.<span class="type">EmptyGroup</span>)</div><div class="line">  &#125; <span class="keyword">else</span> <span class="keyword">if</span> (!isCoordinatorForGroup(groupId)) &#123;</div><div class="line">    (<span class="type">Errors</span>.<span class="type">NOT_COORDINATOR_FOR_GROUP</span>, <span class="type">GroupCoordinator</span>.<span class="type">EmptyGroup</span>)</div><div class="line">  &#125; <span class="keyword">else</span> <span class="keyword">if</span> (isCoordinatorLoadingInProgress(groupId)) &#123;</div><div class="line">    (<span class="type">Errors</span>.<span class="type">GROUP_LOAD_IN_PROGRESS</span>, <span class="type">GroupCoordinator</span>.<span class="type">EmptyGroup</span>)</div><div class="line">  &#125; <span class="keyword">else</span> &#123;</div><div class="line">    groupManager.getGroup(groupId) <span class="keyword">match</span> &#123; <span class="comment">//note: 返回 group 详细信息,主要是 member 的详细信息</span></div><div class="line">      <span class="keyword">case</span> <span class="type">None</span> =&gt; (<span class="type">Errors</span>.<span class="type">NONE</span>, <span class="type">GroupCoordinator</span>.<span class="type">DeadGroup</span>)</div><div class="line">      <span class="keyword">case</span> <span class="type">Some</span>(group) =&gt;</div><div class="line">        group synchronized &#123;</div><div class="line">          (<span class="type">Errors</span>.<span class="type">NONE</span>, group.summary)</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h4 id="LEAVE-GROUP-请求处理"><a href="#LEAVE-GROUP-请求处理" class="headerlink" title="LEAVE_GROUP 请求处理"></a>LEAVE_GROUP 请求处理</h4><p>在什么情况下，Server 会收到 LEAVE_GROUP 的请求呢？一般来说是：</p>
<ol>
<li>consumer 调用 <code>unsubscribe()</code> 方法，取消了对所有 topic 的订阅时；</li>
<li>consumer 的心跳线程超时时，这时 consumer 会主动发送 LEAVE_GROUP 请求；</li>
<li>在 server 端，如果在给定的时间没收到 client 的心跳请求，这时候会自动触发 LEAVE_GROUP 操作。</li>
</ol>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">handleLeaveGroup</span></span>(groupId: <span class="type">String</span>, memberId: <span class="type">String</span>, responseCallback: <span class="type">Short</span> =&gt; <span class="type">Unit</span>) &#123;</div><div class="line">  <span class="keyword">if</span> (!isActive.get) &#123;</div><div class="line">    responseCallback(<span class="type">Errors</span>.<span class="type">GROUP_COORDINATOR_NOT_AVAILABLE</span>.code)</div><div class="line">  &#125; <span class="keyword">else</span> <span class="keyword">if</span> (!isCoordinatorForGroup(groupId)) &#123;</div><div class="line">    responseCallback(<span class="type">Errors</span>.<span class="type">NOT_COORDINATOR_FOR_GROUP</span>.code)</div><div class="line">  &#125; <span class="keyword">else</span> <span class="keyword">if</span> (isCoordinatorLoadingInProgress(groupId)) &#123;</div><div class="line">    responseCallback(<span class="type">Errors</span>.<span class="type">GROUP_LOAD_IN_PROGRESS</span>.code)</div><div class="line">  &#125; <span class="keyword">else</span> &#123;</div><div class="line">    groupManager.getGroup(groupId) <span class="keyword">match</span> &#123;</div><div class="line">      <span class="keyword">case</span> <span class="type">None</span> =&gt;</div><div class="line">        <span class="comment">// if the group is marked as dead, it means some other thread has just removed the group</span></div><div class="line">        <span class="comment">// from the coordinator metadata; this is likely that the group has migrated to some other</span></div><div class="line">        <span class="comment">// coordinator OR the group is in a transient unstable phase. Let the consumer to retry</span></div><div class="line">        <span class="comment">// joining without specified consumer id,</span></div><div class="line">        responseCallback(<span class="type">Errors</span>.<span class="type">UNKNOWN_MEMBER_ID</span>.code)</div><div class="line"></div><div class="line">      <span class="keyword">case</span> <span class="type">Some</span>(group) =&gt;</div><div class="line">        group synchronized &#123;</div><div class="line">          <span class="keyword">if</span> (group.is(<span class="type">Dead</span>) || !group.has(memberId)) &#123;</div><div class="line">            responseCallback(<span class="type">Errors</span>.<span class="type">UNKNOWN_MEMBER_ID</span>.code)</div><div class="line">          &#125; <span class="keyword">else</span> &#123;</div><div class="line">            <span class="keyword">val</span> member = group.get(memberId)</div><div class="line">            removeHeartbeatForLeavingMember(group, member)<span class="comment">//<span class="doctag">NOTE:</span> 认为心跳完成</span></div><div class="line">            onMemberFailure(group, member)<span class="comment">//<span class="doctag">NOTE:</span> 从 group 移除当前 member,并进行 rebalance</span></div><div class="line">            responseCallback(<span class="type">Errors</span>.<span class="type">NONE</span>.code)</div><div class="line">          &#125;</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">onMemberFailure</span></span>(group: <span class="type">GroupMetadata</span>, member: <span class="type">MemberMetadata</span>) &#123;</div><div class="line">  trace(<span class="string">"Member %s in group %s has failed"</span>.format(member.memberId, group.groupId))</div><div class="line">  group.remove(member.memberId)<span class="comment">//<span class="doctag">NOTE:</span> 从 Group 移除当前 member 信息</span></div><div class="line">  group.currentState <span class="keyword">match</span> &#123;</div><div class="line">    <span class="keyword">case</span> <span class="type">Dead</span> | <span class="type">Empty</span> =&gt;</div><div class="line">    <span class="keyword">case</span> <span class="type">Stable</span> | <span class="type">AwaitingSync</span> =&gt; maybePrepareRebalance(group)<span class="comment">//<span class="doctag">NOTE:</span> 进行 rebalance</span></div><div class="line">    <span class="keyword">case</span> <span class="type">PreparingRebalance</span> =&gt; joinPurgatory.checkAndComplete(<span class="type">GroupKey</span>(group.groupId))<span class="comment">//<span class="doctag">NOTE:</span> 检查 join-group 是否可以完成</span></div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>从上面可以看出，GroupCoordinator 在处理 LEAVE_GROUP 请求时，实际上就是调用了 <code>onMemberFailure()</code> 方法，从 group 移除了失败的 member 的，并且将进行相应的状态转换：</p>
<ol>
<li>如果 group 原来是在 Dead 或 Empty 时，那么由于 group 本来就没有 member，就不再进行任何操作；</li>
<li>如果 group 原来是在 Stable 或 AwaitingSync 时，那么将会执行 <code>maybePrepareRebalance()</code> 方法，进行 rebalance 操作（后面的过程就跟最开始 join-group 时一样，参考源码分析六）；</li>
<li>如果 group 已经在 PreparingRebalance 状态了，那么这里将检查一下 join-group 的延迟操作是否完成了，如果操作完成了，那么 GroupCoordinator 就会向 group 的 member 发送 join-group response，然后将状态更新为 AwaitingSync.</li>
</ol>
<h3 id="HEARTBEAT-心跳请求处理"><a href="#HEARTBEAT-心跳请求处理" class="headerlink" title="HEARTBEAT 心跳请求处理"></a>HEARTBEAT 心跳请求处理</h3><p>心跳请求是非常重要的请求之一：</p>
<ol>
<li>对于 Server 端来说，它是 GroupCoordinator 判断一个 consumer member 是否存活的重要条件，如果其中一个 consumer 在给定的时间没有发送心跳请求，那么就会将这个 consumer 从这个 group 中移除，并执行 rebalance 操作；</li>
<li>对于 Client 端而言，心跳请求是 client 感应 group 状态变化的一个重要中介，比如：此时有一个新的 consumer 加入到 consumer group 中了，这时候会进行 rebalace 操作，group 端的状态会发送变化，当 group 其他 member 发送心跳请求，GroupCoordinator 就会通知 client 此时这个 group 正处于 rebalance 阶段，让它们 rejoin group。</li>
</ol>
<p>GroupCoordinator 处理心跳请求的过程如下所示。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//<span class="doctag">NOTE:</span> Server 端处理心跳请求</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">handleHeartbeat</span></span>(groupId: <span class="type">String</span>,</div><div class="line">                  memberId: <span class="type">String</span>,</div><div class="line">                  generationId: <span class="type">Int</span>,</div><div class="line">                  responseCallback: <span class="type">Short</span> =&gt; <span class="type">Unit</span>) &#123;</div><div class="line"><span class="keyword">if</span> (!isActive.get) &#123;<span class="comment">//<span class="doctag">NOTE:</span> GroupCoordinator 已经失败</span></div><div class="line">  responseCallback(<span class="type">Errors</span>.<span class="type">GROUP_COORDINATOR_NOT_AVAILABLE</span>.code)</div><div class="line">&#125; <span class="keyword">else</span> <span class="keyword">if</span> (!isCoordinatorForGroup(groupId)) &#123;<span class="comment">//<span class="doctag">NOTE:</span> 当前的 GroupCoordinator 不包含这个 group</span></div><div class="line">  responseCallback(<span class="type">Errors</span>.<span class="type">NOT_COORDINATOR_FOR_GROUP</span>.code)</div><div class="line">&#125; <span class="keyword">else</span> <span class="keyword">if</span> (isCoordinatorLoadingInProgress(groupId)) &#123;<span class="comment">//<span class="doctag">NOTE:</span> group 的状态信息正在 loading,直接返回成功结果</span></div><div class="line">  <span class="comment">// the group is still loading, so respond just blindly</span></div><div class="line">  responseCallback(<span class="type">Errors</span>.<span class="type">NONE</span>.code)</div><div class="line">&#125; <span class="keyword">else</span> &#123;</div><div class="line">  groupManager.getGroup(groupId) <span class="keyword">match</span> &#123;</div><div class="line">    <span class="keyword">case</span> <span class="type">None</span> =&gt; <span class="comment">//<span class="doctag">NOTE:</span> 当前 GroupCoordinator 不包含这个 group</span></div><div class="line">      responseCallback(<span class="type">Errors</span>.<span class="type">UNKNOWN_MEMBER_ID</span>.code)</div><div class="line"></div><div class="line">    <span class="keyword">case</span> <span class="type">Some</span>(group) =&gt; <span class="comment">//<span class="doctag">NOTE:</span> 包含这个 group</span></div><div class="line">      group synchronized &#123;</div><div class="line">        group.currentState <span class="keyword">match</span> &#123;</div><div class="line">          <span class="keyword">case</span> <span class="type">Dead</span> =&gt; <span class="comment">//<span class="doctag">NOTE:</span> group 的状态已经变为 dead,意味着 group 的 meta 已经被清除,返回 UNKNOWN_MEMBER_ID 错误</span></div><div class="line">            <span class="comment">// if the group is marked as dead, it means some other thread has just removed the group</span></div><div class="line">            <span class="comment">// from the coordinator metadata; this is likely that the group has migrated to some other</span></div><div class="line">            <span class="comment">// coordinator OR the group is in a transient unstable phase. Let the member retry</span></div><div class="line">            <span class="comment">// joining without the specified member id,</span></div><div class="line">            responseCallback(<span class="type">Errors</span>.<span class="type">UNKNOWN_MEMBER_ID</span>.code)</div><div class="line"></div><div class="line">          <span class="keyword">case</span> <span class="type">Empty</span> =&gt; <span class="comment">//<span class="doctag">NOTE:</span> group 的状态为 Empty, 意味着 group 的成员为空,返回 UNKNOWN_MEMBER_ID 错误</span></div><div class="line">            responseCallback(<span class="type">Errors</span>.<span class="type">UNKNOWN_MEMBER_ID</span>.code)</div><div class="line"></div><div class="line">          <span class="keyword">case</span> <span class="type">AwaitingSync</span> =&gt; <span class="comment">//<span class="doctag">NOTE:</span> group 状态为 AwaitingSync, 意味着 group 刚 rebalance 结束</span></div><div class="line">            <span class="keyword">if</span> (!group.has(memberId)) <span class="comment">//<span class="doctag">NOTE:</span> group 不包含这个 member,返回 UNKNOWN_MEMBER_ID 错误</span></div><div class="line">              responseCallback(<span class="type">Errors</span>.<span class="type">UNKNOWN_MEMBER_ID</span>.code)</div><div class="line">            <span class="keyword">else</span> <span class="comment">//<span class="doctag">NOTE:</span> 返回当前 group 正在进行 rebalance,要求 client rejoin 这个 group</span></div><div class="line">              responseCallback(<span class="type">Errors</span>.<span class="type">REBALANCE_IN_PROGRESS</span>.code)</div><div class="line"></div><div class="line">          <span class="keyword">case</span> <span class="type">PreparingRebalance</span> =&gt; <span class="comment">//<span class="doctag">NOTE:</span> group 状态为 PreparingRebalance</span></div><div class="line">            <span class="keyword">if</span> (!group.has(memberId)) &#123; <span class="comment">//<span class="doctag">NOTE:</span> group 不包含这个 member,返回 UNKNOWN_MEMBER_ID 错误</span></div><div class="line">              responseCallback(<span class="type">Errors</span>.<span class="type">UNKNOWN_MEMBER_ID</span>.code)</div><div class="line">            &#125; <span class="keyword">else</span> <span class="keyword">if</span> (generationId != group.generationId) &#123;</div><div class="line">              responseCallback(<span class="type">Errors</span>.<span class="type">ILLEGAL_GENERATION</span>.code)</div><div class="line">            &#125; <span class="keyword">else</span> &#123; <span class="comment">//<span class="doctag">NOTE:</span> 正常处理心跳信息,并返回 REBALANCE_IN_PROGRESS 错误</span></div><div class="line">              <span class="keyword">val</span> member = group.get(memberId)</div><div class="line">              <span class="comment">//note: 更新心跳时间,认为心跳完成,并监控下次的调度情况（超时的话,会把这个 member 从 group 中移除）</span></div><div class="line">              completeAndScheduleNextHeartbeatExpiration(group, member)</div><div class="line">              responseCallback(<span class="type">Errors</span>.<span class="type">REBALANCE_IN_PROGRESS</span>.code)</div><div class="line">            &#125;</div><div class="line"></div><div class="line">          <span class="keyword">case</span> <span class="type">Stable</span> =&gt;</div><div class="line">            <span class="keyword">if</span> (!group.has(memberId)) &#123;</div><div class="line">              responseCallback(<span class="type">Errors</span>.<span class="type">UNKNOWN_MEMBER_ID</span>.code)</div><div class="line">            &#125; <span class="keyword">else</span> <span class="keyword">if</span> (generationId != group.generationId) &#123;</div><div class="line">              responseCallback(<span class="type">Errors</span>.<span class="type">ILLEGAL_GENERATION</span>.code)</div><div class="line">            &#125; <span class="keyword">else</span> &#123; <span class="comment">//<span class="doctag">NOTE:</span> 正确处理心跳信息</span></div><div class="line">              <span class="keyword">val</span> member = group.get(memberId)</div><div class="line">              <span class="comment">//note: 更新心跳时间,认为心跳完成,并监控下次的调度情况（超时的话,会把这个 member 从 group 中移除）</span></div><div class="line">              completeAndScheduleNextHeartbeatExpiration(group, member)</div><div class="line">              responseCallback(<span class="type">Errors</span>.<span class="type">NONE</span>.code)</div><div class="line">            &#125;</div><div class="line">        &#125;</div><div class="line">      &#125;</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h2 id="group-的状态机"><a href="#group-的状态机" class="headerlink" title="group 的状态机"></a>group 的状态机</h2><p>GroupCoordinator 在进行 group 和 offset 相关的管理操作时，有一项重要的工作就是处理和维护 group 状态的变化，一个 Group 状态机如下如所示。</p>
<p><img src="/images/kafka/group.png" alt="Group 状态机"></p>
<p>在这个状态机中，最核心就是 rebalance 操作，简单说一下 rebalance 过程：</p>
<ol>
<li>当一些条件发生时将 group 从 <strong>Stable</strong> 状态变为 <strong>PreparingRebalance</strong>；</li>
<li>然后就是等待 group 中的所有 consumer member 发送 join-group 请求加入 group，如果都已经发送 join-group 请求，此时 GroupCoordinator 会向所有 member 发送 join-group response，那么 group 的状态变为 <strong>AwaitingSync</strong>；</li>
<li>leader consumer 会收到各个 member 订阅的 topic 详细信息，等待其分配好 partition 后，通过 sync-group 请求将结果发给 GroupCoordinator（非 leader consumer 发送的 sync-group 请求的 data 是为空的）；</li>
<li>如果 GroupCoordinator 收到了 leader consumer 发送的 response，获取到了这个 group 各个 member 所分配的 topic-partition 列表，group 的状态就会变成 <strong>Stable</strong>。</li>
</ol>
<p>这就是一次完整的 rebalance 过程。</p>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[Kafka 源码解析之 Consumer 两种 commit 机制和 partition 分配机制（九）]]></title>
      <url>http://matt33.com/2017/11/19/consumer-two-summary/</url>
      <content type="html"><![CDATA[<p>紧接着上篇文章，这篇文章讲述 Consumer 提供的两种 commit 机制和两种 partition 分配机制，具体如何使用是需要用户结合具体的场景进行选择，本文讲述一下其底层实现。</p>
<h2 id="两种-commit-机制"><a href="#两种-commit-机制" class="headerlink" title="两种 commit 机制"></a>两种 commit 机制</h2><p>先看下两种不同的 commit 机制，一种是同步 commit，一种是异步 commit，既然其作用都是 offset commit，应该不难猜到它们底层使用接口都是一样的，其调用流程如下图所示：</p>
<p><img src="/images/kafka/two-commit.png" alt="两种 commit 机制"></p>
<h3 id="同步-commit"><a href="#同步-commit" class="headerlink" title="同步 commit"></a>同步 commit</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// 对 poll() 中返回的所有 topics 和 partition 列表进行 commit</span></div><div class="line"><span class="comment">// 这个方法只能将 offset 提交 Kafka 中，Kafka 将会在每次 rebalance 之后的第一次拉取或启动时使用同步 commit</span></div><div class="line"><span class="comment">// 这是同步 commit，它将会阻塞进程，直到 commit 成功或者遇到一些错误</span></div><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">commitSync</span><span class="params">()</span> </span>&#123;&#125;</div><div class="line"><span class="comment">// 只对指定的 topic-partition 列表进行 commit</span></div><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">commitSync</span><span class="params">(<span class="keyword">final</span> Map&lt;TopicPartition, OffsetAndMetadata&gt; offsets)</span> </span>&#123;&#125;</div></pre></td></tr></table></figure>
<p>其实，从上图中，就已经可以看出，同步 commit 的实现方式，<code>client.poll()</code> 方法会阻塞直到这个request 完成或超时才会返回。</p>
<h3 id="异步-commit"><a href="#异步-commit" class="headerlink" title="异步 commit"></a>异步 commit</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// 异步 commit</span></div><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">commitAsync</span><span class="params">()</span> </span>&#123;&#125;</div><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">commitAsync</span><span class="params">(OffsetCommitCallback callback)</span> </span>&#123;&#125;</div><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">commitAsync</span><span class="params">(<span class="keyword">final</span> Map&lt;TopicPartition, OffsetAndMetadata&gt; offsets, OffsetCommitCallback callback)</span> </span>&#123;&#125;</div></pre></td></tr></table></figure>
<p>而对于异步的 commit，最后调用的都是 <code>doCommitOffsetsAsync</code> 方法，其具体实现如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//org.apache.kafka.clients.consumer.internals.ConsumerCoordinator</span></div><div class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">doCommitOffsetsAsync</span><span class="params">(<span class="keyword">final</span> Map&lt;TopicPartition, OffsetAndMetadata&gt; offsets, <span class="keyword">final</span> OffsetCommitCallback callback)</span> </span>&#123;</div><div class="line">    <span class="keyword">this</span>.subscriptions.needRefreshCommits();</div><div class="line">    RequestFuture&lt;Void&gt; future = sendOffsetCommitRequest(offsets);<span class="comment">//note: 发送 offset-commit 请求</span></div><div class="line">    <span class="keyword">final</span> OffsetCommitCallback cb = callback == <span class="keyword">null</span> ? defaultOffsetCommitCallback : callback;</div><div class="line">    future.addListener(<span class="keyword">new</span> RequestFutureListener&lt;Void&gt;() &#123;</div><div class="line">        <span class="meta">@Override</span></div><div class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onSuccess</span><span class="params">(Void value)</span> </span>&#123;</div><div class="line">            <span class="keyword">if</span> (interceptors != <span class="keyword">null</span>)</div><div class="line">                interceptors.onCommit(offsets);</div><div class="line"></div><div class="line">            <span class="comment">//note: 添加成功的请求,以唤醒相应的回调函数</span></div><div class="line">            completedOffsetCommits.add(<span class="keyword">new</span> OffsetCommitCompletion(cb, offsets, <span class="keyword">null</span>));</div><div class="line">        &#125;</div><div class="line"></div><div class="line">        <span class="meta">@Override</span></div><div class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onFailure</span><span class="params">(RuntimeException e)</span> </span>&#123;</div><div class="line">            Exception commitException = e;</div><div class="line"></div><div class="line">            <span class="keyword">if</span> (e <span class="keyword">instanceof</span> RetriableException)</div><div class="line">                commitException = <span class="keyword">new</span> RetriableCommitFailedException(e);</div><div class="line"></div><div class="line">            <span class="comment">//note: 添加失败的请求,以唤醒相应的回调函数</span></div><div class="line">            completedOffsetCommits.add(<span class="keyword">new</span> OffsetCommitCompletion(cb, offsets, commitException));</div><div class="line">        &#125;</div><div class="line">    &#125;);</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>在异步 commit 中，可以添加相应的回调函数，如果 request 处理成功或处理失败，ConsumerCoordinator 会通过 <code>invokeCompletedOffsetCommitCallbacks()</code> 方法唤醒相应的回调函数。</p>
<p>关于 offset commit 请求的处理见上一篇文章中的<a href="http://matt33.com/2017/11/18/consumer-subscribe/#commit-offset-请求处理">Offset Commit 请求处理</a>，对于提交的 offset，GroupCoordinator 会记录在 GroupMetadata 对象中。</p>
<h2 id="两种-partition-分配机制"><a href="#两种-partition-分配机制" class="headerlink" title="两种 partition 分配机制"></a>两种 partition 分配机制</h2><p>consumer 提供的两种不同 partition 分配策略，可以通过 <code>partition.assignment.strategy</code> 参数进行配置，默认情况下使用的是 <code>org.apache.kafka.clients.consumer.RangeAssignor</code>，Kafka 中提供另一种 partition 的分配策略 <code>org.apache.kafka.clients.consumer.RoundRobinAssignor</code>，它们关系如下图所示：</p>
<p><img src="/images/kafka/PartitionAssignor.png" alt="Kafka 系统内置的两种 partition 分配机制"></p>
<p>通过上图可以看出，用户可以自定义相应的 partition 分配机制，只需要继承这个 <code>AbstractPartitionAssignor</code> 抽象类即可。</p>
<h3 id="AbstractPartitionAssignor"><a href="#AbstractPartitionAssignor" class="headerlink" title="AbstractPartitionAssignor"></a>AbstractPartitionAssignor</h3><p>AbstractPartitionAssignor 有一个抽象方法，如下所示：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/**</span></div><div class="line"> * Perform the group assignment given the partition counts and member subscriptions</div><div class="line"> * <span class="doctag">@param</span> partitionsPerTopic The number of partitions for each subscribed topic. Topics not in metadata will be excluded</div><div class="line"> *                           from this map.</div><div class="line"> * <span class="doctag">@param</span> subscriptions Map from the memberId to their respective topic subscription</div><div class="line"> * <span class="doctag">@return</span> Map from each member to the list of partitions assigned to them.</div><div class="line"> */</div><div class="line"><span class="comment">//<span class="doctag">NOTE:</span> 根据 partitionsPerTopic 和 subscriptions 进行分配,具体的实现会在子类中实现（不同的子类的实现各异）</span></div><div class="line"><span class="keyword">public</span> <span class="keyword">abstract</span> Map&lt;String, List&lt;TopicPartition&gt;&gt; assign(Map&lt;String, Integer&gt; partitionsPerTopic,Map&lt;String, List&lt;String&gt;&gt; subscriptions);</div></pre></td></tr></table></figure>
<p><code>assign()</code> 这个方法，有两个参数：</p>
<ul>
<li><code>partitionsPerTopic</code>：所订阅的每个 topic 与其 partition 数的对应关系，metadata 没有的 topic 将会被移除；</li>
<li><code>subscriptions</code>：每个 consumerId 与其所订阅的 topic 列表的关系。</li>
</ul>
<p><code>RangeAssignor</code> 和 <code>RoundRobinAssignor</code> 通过这个方法 <code>assign()</code> 的实现，来进行相应的 partition 分配。</p>
<h3 id="RangeAssignor-分配模式"><a href="#RangeAssignor-分配模式" class="headerlink" title="RangeAssignor 分配模式"></a>RangeAssignor 分配模式</h3><p>直接看一下这个方法的实现：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">public</span> Map&lt;String, List&lt;TopicPartition&gt;&gt; assign(Map&lt;String, Integer&gt; partitionsPerTopic,</div><div class="line">                                                Map&lt;String, List&lt;String&gt;&gt; subscriptions) &#123;</div><div class="line">    Map&lt;String, List&lt;String&gt;&gt; consumersPerTopic = consumersPerTopic(subscriptions);<span class="comment">//note: (topic, List&lt;consumerId&gt;)</span></div><div class="line">    Map&lt;String, List&lt;TopicPartition&gt;&gt; assignment = <span class="keyword">new</span> HashMap&lt;&gt;();</div><div class="line">    <span class="keyword">for</span> (String memberId : subscriptions.keySet())</div><div class="line">        assignment.put(memberId, <span class="keyword">new</span> ArrayList&lt;TopicPartition&gt;());<span class="comment">//note: 初始化</span></div><div class="line"></div><div class="line">    <span class="keyword">for</span> (Map.Entry&lt;String, List&lt;String&gt;&gt; topicEntry : consumersPerTopic.entrySet()) &#123;</div><div class="line">        String topic = topicEntry.getKey();</div><div class="line">        List&lt;String&gt; consumersForTopic = topicEntry.getValue();</div><div class="line"></div><div class="line">        Integer numPartitionsForTopic = partitionsPerTopic.get(topic);</div><div class="line">        <span class="keyword">if</span> (numPartitionsForTopic == <span class="keyword">null</span>)</div><div class="line">            <span class="keyword">continue</span>;</div><div class="line"></div><div class="line">        Collections.sort(consumersForTopic);</div><div class="line"></div><div class="line">        <span class="comment">//note: 假设 partition 有 7个,consumer 有5个</span></div><div class="line">        <span class="keyword">int</span> numPartitionsPerConsumer = numPartitionsForTopic / consumersForTopic.size();<span class="comment">//note: 1</span></div><div class="line">        <span class="keyword">int</span> consumersWithExtraPartition = numPartitionsForTopic % consumersForTopic.size();<span class="comment">//note: 2</span></div><div class="line"></div><div class="line">        List&lt;TopicPartition&gt; partitions = AbstractPartitionAssignor.partitions(topic, numPartitionsForTopic);</div><div class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>, n = consumersForTopic.size(); i &lt; n; i++) &#123;</div><div class="line">            <span class="comment">//note: i=0, start: 0, length: 2, topic-partition: p0,p1</span></div><div class="line">            <span class="comment">//note: i=1, start: 2, length: 2, topic-partition: p2,p3</span></div><div class="line">            <span class="comment">//note: i=2, start: 4, length: 1, topic-partition: p4</span></div><div class="line">            <span class="comment">//note: i=3, start: 5, length: 1, topic-partition: p5</span></div><div class="line">            <span class="comment">//note: i=4, start: 6, length: 1, topic-partition: p6</span></div><div class="line">            <span class="keyword">int</span> start = numPartitionsPerConsumer * i + Math.min(i, consumersWithExtraPartition);</div><div class="line">            <span class="keyword">int</span> length = numPartitionsPerConsumer + (i + <span class="number">1</span> &gt; consumersWithExtraPartition ? <span class="number">0</span> : <span class="number">1</span>);</div><div class="line">            assignment.get(consumersForTopic.get(i)).addAll(partitions.subList(start, start + length));</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line">    <span class="keyword">return</span> assignment;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>假设 topic 的 partition 数为 numPartitionsForTopic，group 中订阅这个 topic 的 member 数为 <code>consumersForTopic.size()</code>，首先需要算出两个值：</p>
<ul>
<li><code>numPartitionsPerConsumer = numPartitionsForTopic / consumersForTopic.size()</code>：表示平均每个 consumer 会分配到几个 partition；    </li>
<li><code>consumersWithExtraPartition = numPartitionsForTopic % consumersForTopic.size()</code>：表示平均分配后还剩下多少个 partition 未分配。</li>
</ul>
<p>分配的规则是：对于剩下的那些 partition 分配到前 consumersWithExtraPartition 个 consumer 上，也就是前 consumersWithExtraPartition 个 consumer 获得 topic-partition 列表会比后面多一个。</p>
<p>在上述的程序中，举了一个例子，假设有一个 topic 有 7 个 partition，group 有5个 consumer，这个5个 consumer 都订阅这个 topic，那么 range 的分配方式如下：</p>
<ul>
<li>consumer 0：start: 0, length: 2, topic-partition: p0,p1；</li>
<li>consumer 1：start: 2, length: 2, topic-partition: p2,p3；</li>
<li>consumer 2：start: 4, length: 1, topic-partition: p4；</li>
<li>consumer 3：start: 5, length: 1, topic-partition: p5；</li>
<li>consumer 4：start: 6, length: 1, topic-partition: p6</li>
</ul>
<p>而如果 group 中有 consumer 没有订阅这个 topic，那么这个 consumer 将不会参与分配。下面再举个例子，将有两个 topic，一个 partition 有5个，一个 partition 有7个，group 有5个 consumer，但是只有前3个订阅第一个 topic，而另一个 topic 是所有 consumer 都订阅了，那么其分配结果如下：</p>
<table>
<thead>
<tr>
<th>consumer</th>
<th>订阅的 topic1 的列表</th>
<th>订阅的 topic2 的列表</th>
</tr>
</thead>
<tbody>
<tr>
<td>consumer 0</td>
<td>t1p0, t1p1</td>
<td>t2p0, t2p1</td>
</tr>
<tr>
<td>consumer 1</td>
<td>t1p2, t1p3</td>
<td>t2p2, t2p3</td>
</tr>
<tr>
<td>consumer 2</td>
<td>t1p4</td>
<td>t2p4</td>
</tr>
<tr>
<td>consumer 3</td>
<td></td>
<td>t2p5</td>
</tr>
<tr>
<td>consumer 4</td>
<td></td>
<td>t2p6</td>
</tr>
</tbody>
</table>
<h3 id="RoundRobinAssignor"><a href="#RoundRobinAssignor" class="headerlink" title="RoundRobinAssignor"></a>RoundRobinAssignor</h3><p>这个是 roundrobin 的实现，其实现方法如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div></pre></td><td class="code"><pre><div class="line"><span class="meta">@Override</span></div><div class="line"><span class="keyword">public</span> Map&lt;String, List&lt;TopicPartition&gt;&gt; assign(Map&lt;String, Integer&gt; partitionsPerTopic,</div><div class="line">                                                Map&lt;String, List&lt;String&gt;&gt; subscriptions) &#123;</div><div class="line">    Map&lt;String, List&lt;TopicPartition&gt;&gt; assignment = <span class="keyword">new</span> HashMap&lt;&gt;();</div><div class="line">    <span class="keyword">for</span> (String memberId : subscriptions.keySet())</div><div class="line">        assignment.put(memberId, <span class="keyword">new</span> ArrayList&lt;TopicPartition&gt;());</div><div class="line"></div><div class="line">    CircularIterator&lt;String&gt; assigner = <span class="keyword">new</span> CircularIterator&lt;&gt;(Utils.sorted(subscriptions.keySet()));<span class="comment">//note: 环行迭代</span></div><div class="line">    <span class="keyword">for</span> (TopicPartition partition : allPartitionsSorted(partitionsPerTopic, subscriptions)) &#123;</div><div class="line">        <span class="keyword">final</span> String topic = partition.topic();</div><div class="line">        <span class="keyword">while</span> (!subscriptions.get(assigner.peek()).contains(topic))<span class="comment">//note: 遍历直到找到订阅这个 topic 的 partition</span></div><div class="line">            assigner.next();</div><div class="line">        assignment.get(assigner.next()).add(partition);</div><div class="line">    &#125;</div><div class="line">    <span class="keyword">return</span> assignment;</div><div class="line">&#125;</div><div class="line"></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">public</span> List&lt;TopicPartition&gt; <span class="title">allPartitionsSorted</span><span class="params">(Map&lt;String, Integer&gt; partitionsPerTopic,</span></span></div><div class="line">                                                Map&lt;String, List&lt;String&gt;&gt; subscriptions) &#123;</div><div class="line">    SortedSet&lt;String&gt; topics = <span class="keyword">new</span> TreeSet&lt;&gt;();<span class="comment">//<span class="doctag">NOTE:</span> 所有的 topics（有序）</span></div><div class="line">    <span class="keyword">for</span> (List&lt;String&gt; subscription : subscriptions.values())</div><div class="line">        topics.addAll(subscription);</div><div class="line"></div><div class="line">    List&lt;TopicPartition&gt; allPartitions = <span class="keyword">new</span> ArrayList&lt;&gt;();<span class="comment">//<span class="doctag">NOTE:</span> 订阅的 Topic的所有的 TopicPartition 集合</span></div><div class="line">    <span class="keyword">for</span> (String topic : topics) &#123;</div><div class="line">        Integer numPartitionsForTopic = partitionsPerTopic.get(topic);</div><div class="line">        <span class="keyword">if</span> (numPartitionsForTopic != <span class="keyword">null</span>)</div><div class="line">            <span class="comment">//note: topic 的所有 partition 都添加进去</span></div><div class="line">            allPartitions.addAll(AbstractPartitionAssignor.partitions(topic, numPartitionsForTopic));</div><div class="line">    &#125;</div><div class="line">    <span class="keyword">return</span> allPartitions;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>roundrobin 的实现原则，简单来说就是：列出所有 topic-partition 和列出所有的 consumer member，然后开始分配，一轮之后继续下一轮，假设有有一个 topic，它有7个 partition，group 有3个 consumer 都订阅了这个 topic，那么其分配方式为：</p>
<table>
<thead>
<tr>
<th>consumer</th>
<th>分配列表</th>
</tr>
</thead>
<tbody>
<tr>
<td>consumer 0</td>
<td>tp0, tp3, tp6</td>
</tr>
<tr>
<td>consumer 1</td>
<td>tp1, tp4</td>
</tr>
<tr>
<td>consumer 2</td>
<td>tp2, tp5</td>
</tr>
</tbody>
</table>
<p>对于多个 topic 的订阅，将有两个 topic，一个 partition 有5个，一个 partition 有7个，group 有5个 consumer，但是只有前3个订阅第一个 topic，而另一个 topic 是所有 consumer 都订阅了，那么其分配结果如下：</p>
<table>
<thead>
<tr>
<th>consumer</th>
<th>订阅的 topic1 的列表</th>
<th>订阅的 topic2 的列表</th>
</tr>
</thead>
<tbody>
<tr>
<td>consumer 0</td>
<td>t1p0, t1p3</td>
<td>t2p0, t2p5</td>
</tr>
<tr>
<td>consumer 1</td>
<td>t1p1, t1p4</td>
<td>t2p1, t2p6</td>
</tr>
<tr>
<td>consumer 2</td>
<td>t1p2</td>
<td>t2p2</td>
</tr>
<tr>
<td>consumer 3</td>
<td></td>
<td>t2p3</td>
</tr>
<tr>
<td>consumer 4</td>
<td></td>
<td>t2p4</td>
</tr>
</tbody>
</table>
<p>roundrobin 分配方式与 range 的分配方式还是略有不同。</p>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[Kafka 源码解析之 Consumer 两种订阅模式（八）]]></title>
      <url>http://matt33.com/2017/11/18/consumer-subscribe/</url>
      <content type="html"><![CDATA[<p>在前面两篇 Kafka Consumer 的文章中，Consumer Poll 模型这部分基本上已经完整结束，Consumer 这块的文章计划是要写五篇，这篇是 Consumer 这块的第三篇，本来计划是要从其中的三个小块细节内容着手，这三个地方有一个相同之处，那就是在 Kafka Consumer 中都提供了两个不同的解决方案，但具体怎么去使用是需要用户根据自己的业务场景去配置，这里会讲述其底层的具体实现（但为了阅读得更为方便，本来计划的这篇文章将拆分为两篇来，第一篇先讲述第一点，后面两点放在一起讲述）。</p>
<p>本篇文章讲述的这三点内容分别是：</p>
<ol>
<li>consumer 的两种订阅模式， <code>subscribe()</code>和<code>assign()</code> 模式，一种是 topic 粒度（使用 group 管理），一种是 topic-partition 粒度（用户自己去管理）；</li>
<li>consumer 的两种 commit 实现，<code>commitAsync()</code>和<code>commitSync()</code>，即同步 commit 和异步 commit；</li>
<li>consumer 提供的两种不同 <code>partition.assignment.strategy</code>，这是关于一个 group 订阅一些 topic 后，group 内各个 consumer 实例的 partition 分配策略。</li>
</ol>
<p>0.9.X 之前 Kafka Consumer 是支持两个不同的订阅模型 —— high level 和 simple level，这两种模型的最大区别是：第一个其 offset 管理是由 Kafka 来做，包括 rebalance 操作，第二个则是由使用者自己去做，自己去管理相关的 offset，以及自己去进行 rebalance。</p>
<p>在新版的 consumer 中对 high level 和 simple level 的接口实现了统一，简化了相应的相应的编程模型。</p>
<h2 id="订阅模式"><a href="#订阅模式" class="headerlink" title="订阅模式"></a>订阅模式</h2><p>在新版的 Consumer 中，high level 模型现在叫做订阅模式，KafkaConsumer 提供了三种 API，如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// 订阅指定的 topic 列表,并且会自动进行动态 partition 订阅</span></div><div class="line"><span class="comment">// 当发生以下情况时,会进行 rebalance: 1.订阅的 topic 列表改变; 2.topic 被创建或删除; 3.consumer 线程 die; 4. 加一个新的 consumer 线程</span></div><div class="line"><span class="comment">// 当发生 rebalance 时，会唤醒 ConsumerRebalanceListener 线程</span></div><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">subscribe</span><span class="params">(Collection&lt;String&gt; topics, ConsumerRebalanceListener listener)</span></span>&#123;&#125;</div><div class="line"><span class="comment">// 同上，但是这里没有设置 listener</span></div><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">subscribe</span><span class="params">(Collection&lt;String&gt; topics)</span> </span>&#123;&#125;</div><div class="line"><span class="comment">//note: 订阅那些满足一定规则(pattern)的 topic</span></div><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">subscribe</span><span class="params">(Pattern pattern, ConsumerRebalanceListener listener)</span></span>&#123;&#125;</div></pre></td></tr></table></figure>
<p>以上三种 API 都是按照 topic 级别去订阅，可以动态地获取其分配的 topic-partition，这是使用 <strong>Group 动态管理</strong>，它不能与手动 partition 管理一起使用。当监控到发生下面的事件时，Group 将会触发 rebalance 操作：</p>
<ol>
<li>订阅的 topic 列表变化；</li>
<li>topic 被创建或删除；</li>
<li>consumer group 的某个 consumer 实例挂掉；</li>
<li>一个新的 consumer 实例通过 <code>join</code> 方法加入到一个 group 中。</li>
</ol>
<p>在这种模式下，当 KafkaConsumer 调用 pollOnce 方法时，第一步会首先加入到一个 group 中，并获取其分配的 topic-partition 列表（见<a href="http://matt33.com/2017/10/22/consumer-join-group/">Kafka 源码解析之 Consumer 如何加入一个 Group（六）</a>），前面两篇文章都是以这种情况来讲述的。</p>
<p>这里介绍一下当调用 <code>subscribe()</code> 方法之后，Consumer 所做的事情，分两种情况介绍，一种按 topic 列表订阅，一种是按 pattern 模式订阅：</p>
<ol>
<li>topic 列表订阅<ol>
<li>更新 SubscriptionState 中记录的 <code>subscription</code>（记录的是订阅的 topic 列表），将 SubscriptionType 类型设置为 <strong>AUTO_TOPICS</strong>；</li>
<li>更新 metadata 中的 topic 列表（<code>topics</code> 变量），并请求更新 metadata；</li>
</ol>
</li>
<li>pattern 模式订阅<ol>
<li>更新 SubscriptionState 中记录的 <code>subscribedPattern</code>，设置为 pattern，将 SubscriptionType 类型设置为 <strong>AUTO_PATTERN</strong>；</li>
<li>设置 Metadata 的 needMetadataForAllTopics 为 true，即在请求 metadata 时，需要更新所有 topic 的 metadata 信息，设置后再请求更新 metadata；</li>
<li>调用 <code>coordinator.updatePatternSubscription()</code> 方法，遍历所有 topic 的 metadata，找到所有满足 pattern 的 topic 列表，更新到 SubscriptionState 的 <code>subscriptions</code> 和 Metadata 的 <code>topics</code> 中；</li>
<li>通过在 ConsumerCoordinator 中调用 <code>addMetadataListener()</code> 方法在 Metadata 中添加 listener 当每次 metadata update 时就调用第三步的方法更新，但是只有当本地缓存的 topic 列表与现在要订阅的 topic 列表不同时，才会触发 rebalance 操作。</li>
</ol>
</li>
</ol>
<p>其他部分，两者基本一样，只是 pattern 模型在每次更新 topic-metadata 时，获取全局的 topic 列表，如果发现有新加入的符合条件的 topic，就立马去订阅，其他的地方，包括 Group 管理、topic-partition 的分配都是一样的。</p>
<h2 id="分配模式"><a href="#分配模式" class="headerlink" title="分配模式"></a>分配模式</h2><p>下面来看一下 Consumer 提供的分配模式，熟悉 0.8.X 版本的人，可能会把这种方法称为 simple consumer 的接口，当调用 <code>assign()</code> 方法手动分配 topic-partition 列表时，是不会使用 consumer 的 Group 管理机制，也即是当 consumer group member 变化或 topic 的 metadata 信息变化时是不会触发 rebalance 操作的。比如：当 topic 的 partition 增加时，这里是无法感知，需要用户进行相应的处理，Apache Flink 就是使用的这种方式，后续我会写篇文章介绍 Flink 是如何实现这种机制的。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//note: 手动向 consumer 分配一些 topic-partition 列表，并且这个接口不允许增加分配的 topic-partition 列表，将会覆盖之前分配的 topic-partition 列表，如果给定的 topic-partition 列表为空，它的作用将会与 unsubscribe() 方法一样。</span></div><div class="line"><span class="comment">//note: 这种手动 topic 分配是不会使用 consumer 的 group 管理，当 group 的 member 变化或 topic 的 metadata 变化也不会触发 rebalance 操作。</span></div><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">assign</span><span class="params">(Collection&lt;TopicPartition&gt; partitions)</span> </span>&#123;&#125;</div></pre></td></tr></table></figure>
<p>这里来看一下 Kafka 提供的 Group 管理到底是什么？</p>
<p>如果有印象的话，在<a href="http://matt33.com/2017/10/22/consumer-join-group/">Kafka 源码解析之 Consumer 如何加入一个 Group（六）</a>中介绍 Poll 模型的第一步中，详细介绍了 <code>ConsumerCoordinator.poll()</code> 方法，我们再来看一下这个方法：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// note: 它确保了这个 group 的 coordinator 是已知的,并且这个 consumer 是已经加入到了 group 中,也用于 offset 周期性的 commit</span></div><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">poll</span><span class="params">(<span class="keyword">long</span> now)</span> </span>&#123;</div><div class="line">    invokeCompletedOffsetCommitCallbacks();<span class="comment">// note: 用于测试</span></div><div class="line"></div><div class="line">    <span class="comment">// note: Step1 通过 subscribe() 方法订阅 topic,并且 coordinator 未知,初始化 Consumer Coordinator</span></div><div class="line">    <span class="keyword">if</span> (subscriptions.partitionsAutoAssigned() &amp;&amp; coordinatorUnknown()) &#123;</div><div class="line">        <span class="comment">// note: 获取 GroupCoordinator 地址,并且建立连接</span></div><div class="line">        ensureCoordinatorReady();</div><div class="line">        now = time.milliseconds();</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="comment">// note: Step2 判断是否需要重新加入 group,如果订阅的 partition 变化或则分配的 partition 变化时,需要 rejoin</span></div><div class="line">    <span class="comment">// note: 如果订阅模式不是 AUTO_TOPICS 或 AUTO_PATTERN,直接跳过</span></div><div class="line">    <span class="keyword">if</span> (needRejoin()) &#123;</div><div class="line">        <span class="comment">// note: rejoin group 之前先刷新一下 metadata（对于 AUTO_PATTERN 而言）</span></div><div class="line">        <span class="keyword">if</span> (subscriptions.hasPatternSubscription())</div><div class="line">            client.ensureFreshMetadata();</div><div class="line"></div><div class="line">        <span class="comment">// note: 确保 group 是 active; 加入 group; 分配订阅的 partition</span></div><div class="line">        ensureActiveGroup();</div><div class="line">        now = time.milliseconds();</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="comment">// note: Step3 检查心跳线程运行是否正常,如果心跳线程失败,则抛出异常,反之更新 poll 调用的时间</span></div><div class="line">    <span class="comment">// note: 发送心跳请求是在 ensureCoordinatorReady() 中调用的</span></div><div class="line">    pollHeartbeat(now);</div><div class="line">    <span class="comment">// note: Step4 自动 commit 时,当定时达到时,进行自动 commit</span></div><div class="line">    maybeAutoCommitOffsetsAsync(now);</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>如果使用的是 assign 模式，也即是非 AUTO_TOPICS 或 AUTO_PATTERN 模式时，Consumer 实例在调用 poll 方法时，是不会向 GroupCoordinator 发送 join-group/sync-group/heartbeat 请求的，也就是说 GroupCoordinator 是拿不到这个 Consumer 实例的相关信息，也不会去维护这个 member 是否存活，这种情况下就需要用户自己管理自己的处理程序。但是在这种模式是可以进行 offset commit的。</p>
<h3 id="commit-offset-请求处理"><a href="#commit-offset-请求处理" class="headerlink" title="commit offset 请求处理"></a>commit offset 请求处理</h3><p>当 Kafka Serve 端受到来自 client 端的 Offset Commit 请求时，其处理逻辑如下所示，是在 <code>kafka.coordinator.GroupCoordinator</code> 中实现的。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// kafka.coordinator.GroupCoordinator</span></div><div class="line"><span class="comment">//note: GroupCoordinator 处理 Offset Commit 请求</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">handleCommitOffsets</span></span>(groupId: <span class="type">String</span>,</div><div class="line">                        memberId: <span class="type">String</span>,</div><div class="line">                        generationId: <span class="type">Int</span>,</div><div class="line">                        offsetMetadata: immutable.<span class="type">Map</span>[<span class="type">TopicPartition</span>, <span class="type">OffsetAndMetadata</span>],</div><div class="line">                        responseCallback: immutable.<span class="type">Map</span>[<span class="type">TopicPartition</span>, <span class="type">Short</span>] =&gt; <span class="type">Unit</span>) &#123;</div><div class="line">  <span class="keyword">if</span> (!isActive.get) &#123;</div><div class="line">    responseCallback(offsetMetadata.mapValues(_ =&gt; <span class="type">Errors</span>.<span class="type">GROUP_COORDINATOR_NOT_AVAILABLE</span>.code))</div><div class="line">  &#125; <span class="keyword">else</span> <span class="keyword">if</span> (!isCoordinatorForGroup(groupId)) &#123;</div><div class="line">    responseCallback(offsetMetadata.mapValues(_ =&gt; <span class="type">Errors</span>.<span class="type">NOT_COORDINATOR_FOR_GROUP</span>.code))</div><div class="line">  &#125; <span class="keyword">else</span> <span class="keyword">if</span> (isCoordinatorLoadingInProgress(groupId)) &#123;</div><div class="line">    responseCallback(offsetMetadata.mapValues(_ =&gt; <span class="type">Errors</span>.<span class="type">GROUP_LOAD_IN_PROGRESS</span>.code))</div><div class="line">  &#125; <span class="keyword">else</span> &#123;</div><div class="line">    groupManager.getGroup(groupId) <span class="keyword">match</span> &#123;</div><div class="line">      <span class="keyword">case</span> <span class="type">None</span> =&gt;</div><div class="line">        <span class="keyword">if</span> (generationId &lt; <span class="number">0</span>) &#123;</div><div class="line">          <span class="comment">// the group is not relying on Kafka for group management, so allow the commit</span></div><div class="line">          <span class="comment">//note: 不使用 group-coordinator 管理的情况</span></div><div class="line">          <span class="comment">//note: 如果 groupID不存在,就新建一个 GroupMetadata, 其group 状态为 Empty,否则就返回已有的 groupid</span></div><div class="line">          <span class="comment">//note: 如果 simple 的 groupId 与一个 active 的 group 重复了,这里就有可能被覆盖掉了</span></div><div class="line">          <span class="keyword">val</span> group = groupManager.addGroup(<span class="keyword">new</span> <span class="type">GroupMetadata</span>(groupId))</div><div class="line">          doCommitOffsets(group, memberId, generationId, offsetMetadata, responseCallback)</div><div class="line">        &#125; <span class="keyword">else</span> &#123;</div><div class="line">          <span class="comment">// or this is a request coming from an older generation. either way, reject the commit</span></div><div class="line">          <span class="comment">//note: 过期的 offset-commit</span></div><div class="line">          responseCallback(offsetMetadata.mapValues(_ =&gt; <span class="type">Errors</span>.<span class="type">ILLEGAL_GENERATION</span>.code))</div><div class="line">        &#125;</div><div class="line"></div><div class="line">      <span class="keyword">case</span> <span class="type">Some</span>(group) =&gt;</div><div class="line">        doCommitOffsets(group, memberId, generationId, offsetMetadata, responseCallback)</div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="comment">//note: 真正的处理逻辑</span></div><div class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">doCommitOffsets</span></span>(group: <span class="type">GroupMetadata</span>,</div><div class="line">                    memberId: <span class="type">String</span>,</div><div class="line">                    generationId: <span class="type">Int</span>,</div><div class="line">                    offsetMetadata: immutable.<span class="type">Map</span>[<span class="type">TopicPartition</span>, <span class="type">OffsetAndMetadata</span>],</div><div class="line">                    responseCallback: immutable.<span class="type">Map</span>[<span class="type">TopicPartition</span>, <span class="type">Short</span>] =&gt; <span class="type">Unit</span>) &#123;</div><div class="line">  <span class="keyword">var</span> delayedOffsetStore: <span class="type">Option</span>[<span class="type">DelayedStore</span>] = <span class="type">None</span></div><div class="line"></div><div class="line">  group synchronized &#123;</div><div class="line">    <span class="keyword">if</span> (group.is(<span class="type">Dead</span>)) &#123;</div><div class="line">      responseCallback(offsetMetadata.mapValues(_ =&gt; <span class="type">Errors</span>.<span class="type">UNKNOWN_MEMBER_ID</span>.code))</div><div class="line">    &#125; <span class="keyword">else</span> <span class="keyword">if</span> (generationId &lt; <span class="number">0</span> &amp;&amp; group.is(<span class="type">Empty</span>)) &#123;<span class="comment">//note: 来自 assign 的情况</span></div><div class="line">      <span class="comment">// the group is only using Kafka to store offsets</span></div><div class="line">      delayedOffsetStore = groupManager.prepareStoreOffsets(group, memberId, generationId,</div><div class="line">        offsetMetadata, responseCallback)</div><div class="line">    &#125; <span class="keyword">else</span> <span class="keyword">if</span> (group.is(<span class="type">AwaitingSync</span>)) &#123;</div><div class="line">      responseCallback(offsetMetadata.mapValues(_ =&gt; <span class="type">Errors</span>.<span class="type">REBALANCE_IN_PROGRESS</span>.code))</div><div class="line">    &#125; <span class="keyword">else</span> <span class="keyword">if</span> (!group.has(memberId)) &#123;<span class="comment">//note: 有可能 simple 与 high level 的冲突了,这里就直接拒绝相应的请求</span></div><div class="line">      responseCallback(offsetMetadata.mapValues(_ =&gt; <span class="type">Errors</span>.<span class="type">UNKNOWN_MEMBER_ID</span>.code))</div><div class="line">    &#125; <span class="keyword">else</span> <span class="keyword">if</span> (generationId != group.generationId) &#123;</div><div class="line">      responseCallback(offsetMetadata.mapValues(_ =&gt; <span class="type">Errors</span>.<span class="type">ILLEGAL_GENERATION</span>.code))</div><div class="line">    &#125; <span class="keyword">else</span> &#123;</div><div class="line">      <span class="keyword">val</span> member = group.get(memberId)</div><div class="line">      completeAndScheduleNextHeartbeatExpiration(group, member)<span class="comment">//note: 更新下次需要的心跳时间</span></div><div class="line">      delayedOffsetStore = groupManager.prepareStoreOffsets(group, memberId, generationId,</div><div class="line">        offsetMetadata, responseCallback)</div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  <span class="comment">// store the offsets without holding the group lock</span></div><div class="line">  delayedOffsetStore.foreach(groupManager.store)</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>处理过程如下：</p>
<ol>
<li>如果这个 group 还不存在（groupManager没有这个 group 信息），并且 generation 为 -1（一般情况下应该都是这样），就新建一个 GroupMetadata, 其 Group 状态为 Empty；</li>
<li>现在 group 已经存在，就调用 <code>doCommitOffsets()</code> 提交 offset；</li>
<li>如果是来自 assign 模式的请求，并且其对应的 group 的状态为 Empty（generationId &lt; 0 &amp;&amp; group.is(Empty)），那么就记录这个 offset；</li>
<li>如果是来自 assign 模式的请求，但这个 group 的状态不为 Empty（!group.has(memberId)），也就是说，这个 group 已经处在活跃状态，assign 模式下的 group 是不会处于的活跃状态的，可以认为是 assign 模式使用的 group.id 与 subscribe 模式下使用的 group 相同，这种情况下就会拒绝 assign 模式下的这个 offset commit 请求。</li>
</ol>
<h3 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h3><p>根据上面的讲述，这里做一下小节，如下图所示：</p>
<p><img src="/images/kafka/two-subscribe.png" alt="两种订阅模式"></p>
<p>简单做一下总结：</p>
<table>
<thead>
<tr>
<th>模式</th>
<th>不同之处</th>
<th>相同之处</th>
</tr>
</thead>
<tbody>
<tr>
<td>subscribe()</td>
<td>使用 Kafka Group 管理，自动进行 rebalance 操作</td>
<td>可以在 Kafka 保存 offset</td>
</tr>
<tr>
<td>assign()</td>
<td>用户自己进行相关的处理</td>
<td>也可以进行 offset commit，但是尽量保证 group.id 唯一性，如果使用一个与上面模式一样的 group，offset commit 请求将会被拒绝</td>
</tr>
</tbody>
</table>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[Kafka 源码解析之 Consumer Poll 模型（七）]]></title>
      <url>http://matt33.com/2017/11/11/consumer-pollonce/</url>
      <content type="html"><![CDATA[<p>在上一篇问文章中已经介绍一个 Consumer 实例如何加入到一个 group 中，它是 Consumer Poll 模型第一步要做的事件，本文会完整讲述一个 Consumer 实例在 poll 模型过程中会做哪些事情，只有理解了 poll 模型才能更好地理解 Consumer 端的处理逻辑。</p>
<h2 id="Consumer-示例"><a href="#Consumer-示例" class="headerlink" title="Consumer 示例"></a>Consumer 示例</h2><p>这里以一个 Consumer 的实例代码作为开始，一个比较常见的 Consumer 示例代码如下所示，其主要包含一下几个步骤：</p>
<ol>
<li>构造 Propertity，进行 consumer 相关的配置；</li>
<li>创建 KafkaConsumer 的对象 consumer；</li>
<li>订阅相应的 topic 列表；</li>
<li>调用 consumer 的 poll 方法拉取订阅的消息。</li>
</ol>
<p>前面两步在 Consumer 底层上只是创建了一个 consumer 对象，第三步只有记录一下订阅的 topic 信息，consumer 实际的操作都是第四步，也就是在 <code>poll</code> 方法中实现的，这也是 poll 模型对于理解 consumer 设计非常重要的原因。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> org.apache.kafka.clients.consumer.ConsumerRecord;</div><div class="line"><span class="keyword">import</span> org.apache.kafka.clients.consumer.ConsumerRecords;</div><div class="line"><span class="keyword">import</span> org.apache.kafka.clients.consumer.KafkaConsumer;</div><div class="line"></div><div class="line"><span class="keyword">import</span> java.util.Arrays;</div><div class="line"><span class="keyword">import</span> java.util.Properties;</div><div class="line"></div><div class="line"><span class="comment">/**</span></div><div class="line"> * 自动 commit 的情况</div><div class="line"> * Created by matt on 16/7/14.</div><div class="line"> */</div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ConsumerAutoOffsetCommit</span> </span>&#123;</div><div class="line">    <span class="keyword">private</span> <span class="keyword">static</span> String topic;</div><div class="line">    <span class="keyword">private</span> <span class="keyword">static</span> String group;</div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</div><div class="line">        Properties props = <span class="keyword">new</span> Properties();</div><div class="line">        topic=args[<span class="number">0</span>];</div><div class="line">        group=args[<span class="number">1</span>]; <span class="comment">// auto-offset-commit</span></div><div class="line">        props.put(<span class="string">"bootstrap.servers"</span>, <span class="string">"XXX:9092,XXX:9092"</span>);</div><div class="line">        props.put(<span class="string">"group.id"</span>, group);</div><div class="line">        props.put(<span class="string">"auto.offset.reset"</span>, <span class="string">"earliest"</span>);</div><div class="line">        props.put(<span class="string">"enable.auto.commit"</span>, <span class="string">"true"</span>); <span class="comment">// 自动commit</span></div><div class="line">        props.put(<span class="string">"auto.commit.interval.ms"</span>, <span class="string">"1000"</span>); <span class="comment">// 自动commit的间隔</span></div><div class="line">        props.put(<span class="string">"session.timeout.ms"</span>, <span class="string">"30000"</span>);</div><div class="line">        props.put(<span class="string">"key.deserializer"</span>, <span class="string">"org.apache.kafka.common.serialization.StringDeserializer"</span>);</div><div class="line">        props.put(<span class="string">"value.deserializer"</span>, <span class="string">"org.apache.kafka.common.serialization.StringDeserializer"</span>);</div><div class="line">        KafkaConsumer&lt;String, String&gt; consumer = <span class="keyword">new</span> KafkaConsumer&lt;&gt;(props);</div><div class="line">        consumer.subscribe(Arrays.asList(topic)); <span class="comment">// 可消费多个topic,组成一个list</span></div><div class="line">        <span class="keyword">while</span> (<span class="keyword">true</span>) &#123;</div><div class="line">            ConsumerRecords&lt;String, String&gt; records = consumer.poll(<span class="number">100</span>);</div><div class="line">            <span class="keyword">for</span> (ConsumerRecord&lt;String, String&gt; record : records) &#123;</div><div class="line">                System.out.printf(<span class="string">"offset = %d, key = %s, value = %s \n"</span>, record.offset(), record.key(), record.value());</div><div class="line">                <span class="keyword">try</span> &#123;</div><div class="line">                    Thread.sleep(<span class="number">100</span>);</div><div class="line">                &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</div><div class="line">                    e.printStackTrace();</div><div class="line">                &#125;</div><div class="line">            &#125;</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h2 id="Poll-模型综述"><a href="#Poll-模型综述" class="headerlink" title="Poll 模型综述"></a>Poll 模型综述</h2><p>当一个 consumer 对象创建之后，只有 poll 方法调用时，consumer 才会真正去连接 kafka 集群，进行相关的操作，其 poll 方法具体实现如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//timeout(ms): buffer 中的数据未就绪情况下，等待的最长时间，如果设置为0，立即返回 buffer 中已经就绪的数据</span></div><div class="line"><span class="function"><span class="keyword">public</span> ConsumerRecords&lt;K, V&gt; <span class="title">poll</span><span class="params">(<span class="keyword">long</span> timeout)</span> </span>&#123;</div><div class="line">    acquire();</div><div class="line">    <span class="keyword">try</span> &#123;</div><div class="line">        <span class="keyword">if</span> (timeout &lt; <span class="number">0</span>)</div><div class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> IllegalArgumentException(<span class="string">"Timeout must not be negative"</span>);</div><div class="line"></div><div class="line">        <span class="keyword">if</span> (<span class="keyword">this</span>.subscriptions.hasNoSubscriptionOrUserAssignment())</div><div class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> IllegalStateException(<span class="string">"Consumer is not subscribed to any topics or assigned any partitions"</span>);</div><div class="line"></div><div class="line">        <span class="comment">// poll for new data until the timeout expires</span></div><div class="line">        <span class="keyword">long</span> start = time.milliseconds();</div><div class="line">        <span class="keyword">long</span> remaining = timeout;</div><div class="line">        <span class="keyword">do</span> &#123;</div><div class="line">            Map&lt;TopicPartition, List&lt;ConsumerRecord&lt;K, V&gt;&gt;&gt; records = pollOnce(remaining);</div><div class="line">            <span class="comment">//note: 从订阅的 partition 中拉取数据,pollOnce() 才是对 Consumer 客户端拉取数据的核心实现</span></div><div class="line">            <span class="keyword">if</span> (!records.isEmpty()) &#123;</div><div class="line">                <span class="comment">// 在返回数据之前，发送下次的 fetch 请求，避免用户在下次获取数据时线程 block</span></div><div class="line">                <span class="keyword">if</span> (fetcher.sendFetches() &gt; <span class="number">0</span> || client.pendingRequestCount() &gt; <span class="number">0</span>)</div><div class="line">                    client.pollNoWakeup();</div><div class="line"></div><div class="line">                <span class="keyword">if</span> (<span class="keyword">this</span>.interceptors == <span class="keyword">null</span>)</div><div class="line">                    <span class="keyword">return</span> <span class="keyword">new</span> ConsumerRecords&lt;&gt;(records);</div><div class="line">                <span class="keyword">else</span></div><div class="line">                    <span class="keyword">return</span> <span class="keyword">this</span>.interceptors.onConsume(<span class="keyword">new</span> ConsumerRecords&lt;&gt;(records));</div><div class="line">            &#125;</div><div class="line"></div><div class="line">            <span class="keyword">long</span> elapsed = time.milliseconds() - start;</div><div class="line">            remaining = timeout - elapsed;</div><div class="line">        &#125; <span class="keyword">while</span> (remaining &gt; <span class="number">0</span>);</div><div class="line"></div><div class="line">        <span class="keyword">return</span> ConsumerRecords.empty();</div><div class="line">    &#125; <span class="keyword">finally</span> &#123;</div><div class="line">        release();</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>consumer <code>poll</code> 方法主要做了以下几件事情：</p>
<ol>
<li>检查这个 consumer 是否订阅的相应的 topic-partition；</li>
<li>调用 <code>pollOnce()</code> 方法获取相应的 records；</li>
<li>在返回获取的 records 前，发送下一次的 fetch 请求，避免用户在下次请求时线程 block 在 <code>pollOnce()</code> 方法中；</li>
<li>如果在给定的时间（timeout）内获取不到可用的 records，返回空数据。</li>
</ol>
<p>这里可以看出，poll 方法的真正实现是在 pollOnce 方法中，poll 方法通过 pollOnce 方法获取可用的数据。</p>
<h3 id="pollOnce-方法"><a href="#pollOnce-方法" class="headerlink" title="pollOnce 方法"></a>pollOnce 方法</h3><p>这里看下 pollOnce 方法主要做了哪些事情，其具体实现如下所示：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// note: 一次 poll 过程，除了获取新数据外，还会做一些必要的 offset-commit 核 reset-offset  的操作</span></div><div class="line"><span class="keyword">private</span> Map&lt;TopicPartition, List&lt;ConsumerRecord&lt;K, V&gt;&gt;&gt; pollOnce(<span class="keyword">long</span> timeout) &#123;</div><div class="line">    <span class="comment">// note： 1. 获取 GroupCoordinator 地址并连接、加入 Group、sync Group、自动 commit, join 及 sync 期间 group 会进行 rebalance</span></div><div class="line">    coordinator.poll(time.milliseconds());</div><div class="line">    <span class="comment">// note: 2. 更新订阅的 topic-partition 的 offset（如果订阅的 topic-partition list 没有有效的 offset 的情况下）</span></div><div class="line">    <span class="keyword">if</span> (!subscriptions.hasAllFetchPositions())</div><div class="line">        updateFetchPositions(<span class="keyword">this</span>.subscriptions.missingFetchPositions());</div><div class="line"></div><div class="line">    <span class="comment">// note: 3. 获取 fetcher 已经拉取到的数据</span></div><div class="line">    Map&lt;TopicPartition, List&lt;ConsumerRecord&lt;K, V&gt;&gt;&gt; records = fetcher.fetchedRecords();</div><div class="line">    <span class="keyword">if</span> (!records.isEmpty())</div><div class="line">        <span class="keyword">return</span> records;</div><div class="line">    <span class="comment">// note: 说明上次 fetch 到是的数据已经全部拉取了,需要再次发送 fetch 请求,从 broker 拉取数据</span></div><div class="line"></div><div class="line">    <span class="comment">// note: 4. 发送 fetch 请求,会从多个 topic-partition 拉取数据（只要对应的 topic-partition 没有未完成的请求）</span></div><div class="line">    fetcher.sendFetches();</div><div class="line"></div><div class="line">    <span class="keyword">long</span> now = time.milliseconds();</div><div class="line">    <span class="keyword">long</span> pollTimeout = Math.min(coordinator.timeToNextPoll(now), timeout);</div><div class="line"></div><div class="line">    <span class="comment">//note: 5. 调用 poll 方法发送请求（底层发送请求的接口）</span></div><div class="line">    client.poll(pollTimeout, now, <span class="keyword">new</span> PollCondition() &#123;</div><div class="line">        <span class="meta">@Override</span></div><div class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">shouldBlock</span><span class="params">()</span> </span>&#123;</div><div class="line">            <span class="keyword">return</span> !fetcher.hasCompletedFetches();<span class="comment">//note: 有完成的 fetcher 请求的话,这里就不会 block,但是 block 也是有最大时间限制</span></div><div class="line">        &#125;</div><div class="line">    &#125;);</div><div class="line"></div><div class="line">    <span class="comment">//note: 6. 如果 group 需要 rebalance,直接返回空数据,这样更快地让 group 进行稳定状态</span></div><div class="line">    <span class="keyword">if</span> (coordinator.needRejoin())</div><div class="line">        <span class="keyword">return</span> Collections.emptyMap();</div><div class="line"></div><div class="line">    <span class="keyword">return</span> fetcher.fetchedRecords();</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>pollOnce 可以简单分为6步来看，其作用分别如下：</p>
<ol>
<li><code>coordinator.poll()</code>：获取 GroupCoordinator 的地址，并建立相应 tcp 连接，发送 join-group、sync-group，之后才真正加入到了一个 group 中，这时会获取其要消费的 topic-partition 列表，如果设置了自动 commit，也会在这一步进行 commit，具体可见 <a href="http://matt33.com/2017/10/22/consumer-join-group/">Kafka 源码解析之 Consumer 如何加入一个 Group（六）</a>，总之，对于一个新建的 group，group 状态将会从 <strong>Empty –&gt; PreparingRebalance –&gt; AwaiSync –&gt; Stable</strong>；</li>
<li><code>updateFetchPositions()</code>： 在上一步中已经获取到了这个 consumer 实例要订阅的 topic-partition list，这一步更新其 fetch-position offset，以便进行拉取；</li>
<li><code>fetcher.sendFetches()</code>：返回其 fetched records，并更新其 fetch-position offset，只有在 offset-commit 时（自动 commit 时，是在第一步实现的），才会更新其 committed offset；</li>
<li><code>fetcher.sendFetches()</code>：只要订阅的 topic-partition list 没有未处理的 fetch 请求，就发送对这个 topic-partition 的 fetch 请求，在真正发送时，还是会按 node 级别去发送，leader 是同一个 node 的 topic-partition 会合成一个请求去发送；</li>
<li><code>client.poll()</code>：调用底层 NetworkClient 提供的接口去发送相应的请求；</li>
<li><code>coordinator.needRejoin()</code>：如果当前实例分配的 topic-partition 列表发送了变化，那么这个 consumer group 就需要进行 rebalance。</li>
</ol>
<h3 id="PollOnce-整体流程"><a href="#PollOnce-整体流程" class="headerlink" title="PollOnce 整体流程"></a>PollOnce 整体流程</h3><p>通过上面一节的介绍，pollOnce 方法做的事情现在已经有了一个比较清晰的认识，PollOnce 其详细流程图如下所示：</p>
<p><img src="/images/kafka/pollonce_only.png" alt="pollOnce 总体流程"></p>
<p>从上图可以看出，Consumer 在实现上，其调用还是比较复杂，不过复杂的地方都封装在底层了，Consumer 的网络模型如下图所示：</p>
<p><img src="/images/kafka/consumer-network.png" alt="Consumer 网络模型"></p>
<p>上面这张图，主要介绍了 KafkaConsumer 的封装模型。</p>
<h2 id="PollOnce-模型详解"><a href="#PollOnce-模型详解" class="headerlink" title="PollOnce 模型详解"></a>PollOnce 模型详解</h2><p>这一节详细讲述一下 PollOnce 模型的实现，主要讲述其前4步，最后的两步比较简单（跟之前也有重复），这里就不再细讲了。</p>
<h3 id="coordinator-poll"><a href="#coordinator-poll" class="headerlink" title="coordinator.poll()"></a><code>coordinator.poll()</code></h3><p>这部分的内容还是挺多的，其详细内部见：<a href="http://matt33.com/2017/10/22/consumer-join-group/">Kafka 源码解析之 Consumer 如何加入一个 Group（六）</a>，一个 consumer 实例在这一步实现的内容是：</p>
<ol>
<li>获取 GroupCoordinator 的地址，并建立相应 tcp 连接；</li>
<li>发送 join-group 请求，然后 group 将会进行 rebalance；</li>
<li>发送 sync-group 请求，之后才正在加入到了一个 group 中，这时会通过请求获取其要消费的 topic-partition 列表；</li>
<li>如果设置了自动 commit，也会在这一步进行 commit offset。</li>
</ol>
<p>通过前面的 pollOnce 流程图也能清楚地看到各个部分是在哪个方法中实现的。</p>
<h3 id="updateFetchPositions"><a href="#updateFetchPositions" class="headerlink" title="updateFetchPositions()"></a><code>updateFetchPositions()</code></h3><p>这个方法主要是用来更新这个 consumer 实例订阅的 topic-partition 列表的 fetch-offset 信息。</p>
<p>在 Fetcher 中，这个 consumer 实例订阅的每个 topic-partition 都会有一个对应的 TopicPartitionState 对象，在这个对象中会记录以下这些内容：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//note: 记录 tp 的一些 offset 信息</span></div><div class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">TopicPartitionState</span> </span>&#123;</div><div class="line">    <span class="keyword">private</span> Long position; <span class="comment">// last consumed position</span></div><div class="line">    <span class="keyword">private</span> Long highWatermark; <span class="comment">// the high watermark from last fetch</span></div><div class="line">    <span class="keyword">private</span> OffsetAndMetadata committed;  <span class="comment">// last committed position</span></div><div class="line">    <span class="keyword">private</span> <span class="keyword">boolean</span> paused;  <span class="comment">// whether this partition has been paused by the user</span></div><div class="line">    <span class="keyword">private</span> OffsetResetStrategy resetStrategy;  <span class="comment">// the strategy to use if the offset needs resetting</span></div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>其中需要关注的几个属性是：</p>
<ol>
<li>position：Fetcher 下次去拉取时的 offset，Fecher 在拉取时需要知道这个值；</li>
<li>committed：consumer 已经处理完的最新一条消息的 offset，consumer 主动调用 offset-commit 时会更新这个值；</li>
<li>resetStrategy：这 topic-partition offset 重置的策略，重置之后，这个策略就会改为 null，防止再次操作。</li>
</ol>
<p><code>updateFetchPositions()</code> 这个方法的目的就是为了获取其订阅的每个 topic-partition 对应的 position，这样 Fetcher 才知道从哪个 offset 开始去拉取这个 topic-partition 的数据。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//将 the fetch position 设置为 the committed position（如果有 committed offset 的话），否则就使用配置的重置策略去设置 offset</span></div><div class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">updateFetchPositions</span><span class="params">(Set&lt;TopicPartition&gt; partitions)</span> </span>&#123;</div><div class="line">    <span class="comment">//note: 先重置那些调用 seekToBegin 和 seekToEnd 的 offset 的 tp,设置其  the fetch position 的 offset</span></div><div class="line">    fetcher.resetOffsetsIfNeeded(partitions);</div><div class="line"></div><div class="line">    <span class="keyword">if</span> (!subscriptions.hasAllFetchPositions(partitions)) &#123;</div><div class="line">        <span class="comment">//note: 获取所有分配 tp 的 offset, 即 committed offset, 更新到 TopicPartitionState 中的 committed offset 中</span></div><div class="line">        coordinator.refreshCommittedOffsetsIfNeeded();</div><div class="line"></div><div class="line">        <span class="comment">//note: 如果 the fetch position 值无效,则将上步获取的 committed offset 设置为 the fetch position</span></div><div class="line">        fetcher.updateFetchPositions(partitions);</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>上述过程主要分为三步，可以结合前面的流程来看，这里就不再详细去介绍其下面几层调用的实现了：</p>
<ol>
<li><code>fetcher.resetOffsetsIfNeeded()</code>：处理那些 resetStrategy 不为 null 的 topic-partition（一般是使用了 <code>seekToBegin()</code> 和 <code>seekToEnd()</code> 方法的 topic-partition），Fetcher 会发送 list-offset 请求去获取相应的 offset，实际上在获取时，是根据时间戳（earliest：-2， latest：-1）去查找的相应的 offset，因为从 0.10.2 之后系统在保存 topic 数据时，会保存相应的 timestrap 信息；</li>
<li><code>coordinator.refreshCommittedOffsetsIfNeeded()</code>：发送 offset-fetch 请求获取其所订阅的所有 topic-partition 的 commited offset，如果这个 group 没有关于这个 topic-partition 的 offset 就会根据其默认的 <code>auto.offset.reset</code> 信息返回 -1或-2，并将获取到的信息更新到 committed offset 中；</li>
<li><code>fetcher.updateFetchPositions()</code>：如果 the fetch position 还没有有效值（第一步处理的那些 topic-partition 已经有了有效值），那么就将 the fetch position 设置为 committed offset。</li>
</ol>
<p>到这一步，这个 consumer 订阅的 topic-partition list 都有了相应的 the fetch position，Fetcher 在发送 fetch 请求就知道应该从哪个 offset 开始去拉取这个 topic-partition，自此，发送 fetch 请求前的准备都已经完成。</p>
<h3 id="fetcher-sendFetches"><a href="#fetcher-sendFetches" class="headerlink" title="fetcher.sendFetches()"></a><code>fetcher.sendFetches()</code></h3><p>这个虽然是 pollOnce 的第四步，但我们这里放在第三步来讲，只有在发送 fetch 请求后，才能调用 <code>fetcher.fetchedRecords()</code> 获取到其拉取的数据，所以这里先介绍这个方法，其具体实现如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//note: 向订阅的所有 partition （只要该 leader 暂时没有拉取请求）所在 leader 发送 fetch 请求</span></div><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">sendFetches</span><span class="params">()</span> </span>&#123;</div><div class="line">    <span class="comment">//note: 1 创建 Fetch Request</span></div><div class="line">    Map&lt;Node, FetchRequest.Builder&gt; fetchRequestMap = createFetchRequests();</div><div class="line">    <span class="keyword">for</span> (Map.Entry&lt;Node, FetchRequest.Builder&gt; fetchEntry : fetchRequestMap.entrySet()) &#123;</div><div class="line">        <span class="keyword">final</span> FetchRequest.Builder request = fetchEntry.getValue();</div><div class="line">        <span class="keyword">final</span> Node fetchTarget = fetchEntry.getKey();</div><div class="line"></div><div class="line">        log.debug(<span class="string">"Sending fetch for partitions &#123;&#125; to broker &#123;&#125;"</span>, request.fetchData().keySet(), fetchTarget);</div><div class="line">        <span class="comment">//note: 2 发送 Fetch Request</span></div><div class="line">        client.send(fetchTarget, request)</div><div class="line">                .addListener(<span class="keyword">new</span> RequestFutureListener&lt;ClientResponse&gt;() &#123;</div><div class="line">                    <span class="meta">@Override</span></div><div class="line">                    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onSuccess</span><span class="params">(ClientResponse resp)</span> </span>&#123;</div><div class="line">                        FetchResponse response = (FetchResponse) resp.responseBody();</div><div class="line">                        <span class="keyword">if</span> (!matchesRequestedPartitions(request, response)) &#123;</div><div class="line">                            <span class="comment">// obviously we expect the broker to always send us valid responses, so this check</span></div><div class="line">                            <span class="comment">// is mainly for test cases where mock fetch responses must be manually crafted.</span></div><div class="line">                            log.warn(<span class="string">"Ignoring fetch response containing partitions &#123;&#125; since it does not match "</span> +</div><div class="line">                                    <span class="string">"the requested partitions &#123;&#125;"</span>, response.responseData().keySet(),</div><div class="line">                                    request.fetchData().keySet());</div><div class="line">                            <span class="keyword">return</span>;</div><div class="line">                        &#125;</div><div class="line"></div><div class="line">                        Set&lt;TopicPartition&gt; partitions = <span class="keyword">new</span> HashSet&lt;&gt;(response.responseData().keySet());</div><div class="line">                        FetchResponseMetricAggregator metricAggregator = <span class="keyword">new</span> FetchResponseMetricAggregator(sensors, partitions);</div><div class="line"></div><div class="line">                        <span class="keyword">for</span> (Map.Entry&lt;TopicPartition, FetchResponse.PartitionData&gt; entry : response.responseData().entrySet()) &#123;</div><div class="line">                            TopicPartition partition = entry.getKey();</div><div class="line">                            <span class="keyword">long</span> fetchOffset = request.fetchData().get(partition).offset;</div><div class="line">                            FetchResponse.PartitionData fetchData = entry.getValue();</div><div class="line">                            completedFetches.add(<span class="keyword">new</span> CompletedFetch(partition, fetchOffset, fetchData, metricAggregator,</div><div class="line">                                    request.version()));<span class="comment">//note: 成功后加入 CompletedFetch</span></div><div class="line">                        &#125;</div><div class="line"></div><div class="line">                        sensors.fetchLatency.record(resp.requestLatencyMs());</div><div class="line">                        sensors.fetchThrottleTimeSensor.record(response.getThrottleTime());</div><div class="line">                    &#125;</div><div class="line"></div><div class="line">                    <span class="meta">@Override</span></div><div class="line">                    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onFailure</span><span class="params">(RuntimeException e)</span> </span>&#123;</div><div class="line">                        log.debug(<span class="string">"Fetch request to &#123;&#125; for partitions &#123;&#125; failed"</span>, fetchTarget, request.fetchData().keySet(), e);</div><div class="line">                    &#125;</div><div class="line">                &#125;);</div><div class="line">    &#125;</div><div class="line">    <span class="keyword">return</span> fetchRequestMap.size();</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>在发送的 fetch 的过程中，总共分为以下两步：</p>
<ol>
<li><code>createFetchRequests()</code>：为订阅的所有 topic-partition list 创建 fetch 请求（只要该topic-partition 没有还在处理的请求），创建的 fetch 请求依然是按照 node 级别创建的；</li>
<li><code>client.send()</code>：发送 fetch 请求，并设置相应的 Listener，请求处理成功的话，就加入到 completedFetches 中，在加入这个 completedFetches 集合时，是按照 topic-partition 级别去加入，这样也就方便了后续的处理。</li>
</ol>
<p>从这里可以看出，在每次发送 fetch 请求时，都会向所有可发送的 topic-partition 发送 fetch 请求，调用一次 <code>fetcher.sendFetches</code>，拉取到的数据，可需要多次 pollOnce 循环才能处理完，因为 Fetcher 线程是在后台运行，这也保证了尽可能少地阻塞用户的处理线程，因为如果 Fetcher 中没有可处理的数据，用户的线程是会阻塞在 poll 方法中的。</p>
<h3 id="fetcher-fetchedRecords"><a href="#fetcher-fetchedRecords" class="headerlink" title="fetcher.fetchedRecords()"></a><code>fetcher.fetchedRecords()</code></h3><p>这个方法的作用就获取已经从 Server 拉取到的 Records，其源码实现如下所示：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// 返回获取到的 the fetched records， 并更新 the consumed position</span></div><div class="line"><span class="keyword">public</span> Map&lt;TopicPartition, List&lt;ConsumerRecord&lt;K, V&gt;&gt;&gt; fetchedRecords() &#123;</div><div class="line">    Map&lt;TopicPartition, List&lt;ConsumerRecord&lt;K, V&gt;&gt;&gt; drained = <span class="keyword">new</span> HashMap&lt;&gt;();</div><div class="line">    <span class="keyword">int</span> recordsRemaining = maxPollRecords;<span class="comment">//<span class="doctag">NOTE:</span> 在 max.poll.records 中设置单词最大的拉取条数</span></div><div class="line"></div><div class="line">    <span class="keyword">while</span> (recordsRemaining &gt; <span class="number">0</span>) &#123;</div><div class="line">        <span class="keyword">if</span> (nextInLineRecords == <span class="keyword">null</span> || nextInLineRecords.isDrained()) &#123; <span class="comment">//note: nextInLineRecords 为空时</span></div><div class="line">            CompletedFetch completedFetch = completedFetches.poll();<span class="comment">//note: 当一个 nextInLineRecords 处理完,就从 completedFetches 处理下一个完成的 Fetch 请求</span></div><div class="line">            <span class="keyword">if</span> (completedFetch == <span class="keyword">null</span>)</div><div class="line">                <span class="keyword">break</span>;</div><div class="line"></div><div class="line">            nextInLineRecords = parseCompletedFetch(completedFetch);<span class="comment">//note: 获取下一个要处理的 nextInLineRecords</span></div><div class="line">        &#125; <span class="keyword">else</span> &#123;</div><div class="line">            TopicPartition partition = nextInLineRecords.partition;</div><div class="line">            List&lt;ConsumerRecord&lt;K, V&gt;&gt; records = drainRecords(nextInLineRecords, recordsRemaining);<span class="comment">//note:拉取records,更新 position</span></div><div class="line">            <span class="keyword">if</span> (!records.isEmpty()) &#123;</div><div class="line">                List&lt;ConsumerRecord&lt;K, V&gt;&gt; currentRecords = drained.get(partition);</div><div class="line">                <span class="keyword">if</span> (currentRecords == <span class="keyword">null</span>) &#123; <span class="comment">//note: 正常情况下,一个 node 只会发送一个 request,一般只会有一个</span></div><div class="line">                    drained.put(partition, records);</div><div class="line">                &#125; <span class="keyword">else</span> &#123;</div><div class="line">                    List&lt;ConsumerRecord&lt;K, V&gt;&gt; newRecords = <span class="keyword">new</span> ArrayList&lt;&gt;(records.size() + currentRecords.size());</div><div class="line">                    newRecords.addAll(currentRecords);</div><div class="line">                    newRecords.addAll(records);</div><div class="line">                    drained.put(partition, newRecords);</div><div class="line">                &#125;</div><div class="line">                recordsRemaining -= records.size();</div><div class="line">            &#125;</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="keyword">return</span> drained;</div><div class="line">&#125;</div><div class="line"></div><div class="line"></div><div class="line"><span class="keyword">private</span> List&lt;ConsumerRecord&lt;K, V&gt;&gt; drainRecords(PartitionRecords&lt;K, V&gt; partitionRecords, <span class="keyword">int</span> maxRecords) &#123;</div><div class="line">    <span class="keyword">if</span> (!subscriptions.isAssigned(partitionRecords.partition)) &#123;</div><div class="line">        <span class="comment">// this can happen when a rebalance happened before fetched records are returned to the consumer's poll call</span></div><div class="line">        log.debug(<span class="string">"Not returning fetched records for partition &#123;&#125; since it is no longer assigned"</span>, partitionRecords.partition);</div><div class="line">    &#125; <span class="keyword">else</span> &#123;</div><div class="line">        <span class="comment">// note that the consumed position should always be available as long as the partition is still assigned</span></div><div class="line">        <span class="keyword">long</span> position = subscriptions.position(partitionRecords.partition);</div><div class="line">        <span class="keyword">if</span> (!subscriptions.isFetchable(partitionRecords.partition)) &#123;<span class="comment">//note: 这个 tp 不能来消费了,比如调用 pause</span></div><div class="line">            log.debug(<span class="string">"Not returning fetched records for assigned partition &#123;&#125; since it is no longer fetchable"</span>, partitionRecords.partition);</div><div class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> (partitionRecords.fetchOffset == position) &#123;<span class="comment">//note: offset 对的上,也就是拉取是按顺序拉的</span></div><div class="line">            <span class="comment">//note: 获取该 tp 对应的records,并更新 partitionRecords 的 fetchOffset（用于判断是否顺序）</span></div><div class="line">            List&lt;ConsumerRecord&lt;K, V&gt;&gt; partRecords = partitionRecords.drainRecords(maxRecords);</div><div class="line">            <span class="keyword">if</span> (!partRecords.isEmpty()) &#123;</div><div class="line">                <span class="keyword">long</span> nextOffset = partRecords.get(partRecords.size() - <span class="number">1</span>).offset() + <span class="number">1</span>;</div><div class="line">                log.trace(<span class="string">"Returning fetched records at offset &#123;&#125; for assigned partition &#123;&#125; and update "</span> +</div><div class="line">                        <span class="string">"position to &#123;&#125;"</span>, position, partitionRecords.partition, nextOffset);</div><div class="line"></div><div class="line">                subscriptions.position(partitionRecords.partition, nextOffset);<span class="comment">//note: 更新消费的到 offset（ the fetch position）</span></div><div class="line">            &#125;</div><div class="line"></div><div class="line">            <span class="comment">//note: 获取 Lag（即 position与 hw 之间差值）,hw 为 null 时,才返回 null</span></div><div class="line">            Long partitionLag = subscriptions.partitionLag(partitionRecords.partition);</div><div class="line">            <span class="keyword">if</span> (partitionLag != <span class="keyword">null</span>)</div><div class="line">                <span class="keyword">this</span>.sensors.recordPartitionLag(partitionRecords.partition, partitionLag);</div><div class="line"></div><div class="line">            <span class="keyword">return</span> partRecords;</div><div class="line">        &#125; <span class="keyword">else</span> &#123;</div><div class="line">            <span class="comment">// these records aren't next in line based on the last consumed position, ignore them</span></div><div class="line">            <span class="comment">// they must be from an obsolete request</span></div><div class="line">            log.debug(<span class="string">"Ignoring fetched records for &#123;&#125; at offset &#123;&#125; since the current position is &#123;&#125;"</span>,</div><div class="line">                    partitionRecords.partition, partitionRecords.fetchOffset, position);</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    partitionRecords.drain();</div><div class="line">    <span class="keyword">return</span> Collections.emptyList();</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>PartitionRecords 是 <code>parseCompletedFetch()</code> 处理后的类型，其成员变量如下所示：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">PartitionRecords</span>&lt;<span class="title">K</span>, <span class="title">V</span>&gt; </span>&#123;</div><div class="line">    <span class="keyword">private</span> <span class="keyword">long</span> fetchOffset;</div><div class="line">    <span class="keyword">private</span> TopicPartition partition;</div><div class="line">    <span class="keyword">private</span> List&lt;ConsumerRecord&lt;K, V&gt;&gt; records;</div><div class="line">    <span class="keyword">private</span> <span class="keyword">int</span> position = <span class="number">0</span>;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>consumer 的 Fetcher 处理从 server 获取的 fetch response 大致分为以下几个过程：</p>
<ol>
<li>通过 <code>completedFetches.poll()</code> 获取已经成功的 fetch response（在 <code>sendFetches()</code> 方法中会把成功的结果放在这个集合中，是拆分为 topic-partition 的粒度放进去的）；</li>
<li><code>parseCompletedFetch()</code> 处理上面获取的 completedFetch，构造成 PartitionRecords 类型；</li>
<li>通过 <code>drainRecords()</code> 方法处理 PartitionRecords 对象，在这个里面会去验证 fetchOffset 是否能对得上，只有 fetchOffset 是一致的情况下才会去处理相应的数据，并更新 the fetch offset 的信息，如果 fetchOffset 不一致，这里就不会处理，the fetch offset 就不会更新，下次 fetch 请求时是会接着 the fetch offset 的位置去请求相应的数据。</li>
<li>返回相应的 Records 数据。</li>
</ol>
<p>自此，consumer 的 poll 模型处理的逻辑就已经基本上讲完了，下篇博客会讲述下面三点内容：</p>
<ol>
<li>consumer 的两种订阅模型；</li>
<li>consumer 的同步 commit 和异步 commit；</li>
<li>consumer 提供的两种 <code>partition.assignment.strategy</code>。</li>
</ol>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[Kafka 源码解析之 Consumer 如何加入一个 Group（六）]]></title>
      <url>http://matt33.com/2017/10/22/consumer-join-group/</url>
      <content type="html"><![CDATA[<p>距离上一篇博客（2017-09-10），到现在已经过去一个多月了，理论上这篇文章在上个月就应该写完，无奈拖延症又犯了，一直以这部分过于复杂为借口拖了好久，这两天逼了自己一把，先整理出其中的一篇，后续要加把劲，要不然今年的年度计划（年底前把这个系列写完）就完不成了，废话到此为止，下面步入正文。在 Kafka 中，Consumer 的复杂度要比 producer 高出很多，对于 Producer 而言，没有 producer 组的概念的、也不需要 care offset 等问题，而 Consumer 就不一样了，它需要关注的内容很多，需要考虑分布式消费（Consumer Group），为了防止重复消费或者部分数据未消费需要考虑 offset，这些都对 Consumer 的设计以及 Server 对其处理提出了很高的要求。本来计划是先进行综述，然后再分别介绍各个模块，现在打算反过来，先介绍各个模块，最后再进行综述，本篇为 Consumer 源码分析开篇，先从一个 Consumer 实例如何加入一个 Consumer Group 讲起。</p>
<p>这里的分析是以 0.10.2 为准，在 0.10.2 版的 KafkaConsumer 中，相比于老版的 KafkaConsumer（0.9以前的），新版从0.9开始做了很大改进，总结起来，其优势有以下两点：</p>
<ul>
<li>实现了 High Level 与 Simple Level Consumer API 的统一，极大地简化了实现的复杂度；</li>
<li>增加了 GroupCoordinator 角色，它作用是：<code>GroupCoordinator handles general group membership and offset management</code>；</li>
</ul>
<p>接下来会按照下面这个流程来讲述：</p>
<ol>
<li>GroupCoordinator 简单介绍；</li>
<li>Consumer poll 模型：join-group 是 poll 模型的第一步，其他部分后续再讲；</li>
<li>Consumer join-group 的详细过程以及在这个过程中 group 状态的变化。</li>
</ol>
<h2 id="GroupCoordinator-简介"><a href="#GroupCoordinator-简介" class="headerlink" title="GroupCoordinator 简介"></a>GroupCoordinator 简介</h2><p>这里先简单介绍一下 GroupCoordinator 这个角色，后续有一篇文章进行专门讲述，GroupCoordinator 是运行在 Kafka Broker 上的一个服务，每台 Broker 在运行时都会启动一个这样的服务，但一个 consumer 具体与哪个 Broker 上这个服务交互，就需要先介绍一下 <code>__consumer_offsets</code> 这个 topic。</p>
<h3 id="consumer-offsets-topic"><a href="#consumer-offsets-topic" class="headerlink" title="__consumer_offsets topic"></a><code>__consumer_offsets</code> topic</h3><p><code>__consumer_offsets</code> 是 Kafka 内部使用的一个 topic，专门用来存储 group 消费的情况，默认情况下有50个 partition，每个 partition 三副本，如下图所示（只列出了30 个 partition）：</p>
<p><img src="/images/kafka/consumer_offsets.png" alt="__consumer_offsets topic"></p>
<h3 id="GroupCoordinator"><a href="#GroupCoordinator" class="headerlink" title="GroupCoordinator"></a>GroupCoordinator</h3><p>GroupCoordinator 是负责 consumer group member 管理以及 offset 管理。</p>
<p>每个 Consumer Group 都有其对应的 GroupCoordinator，但具体是由哪个 GroupCoordinator 负责与 group.id 的 hash 值有关，通过这个 <strong>abs(GroupId.hashCode()) % NumPartitions</strong> 来计算出一个值（其中，NumPartitions 是 <code>__consumer_offsets</code> 的 partition 数，默认是50个），这个值代表了 <code>__consumer_offsets</code> 的一个 partition，而这个 partition 的 leader 即为这个 Group 要交互的 GroupCoordinator 所在的节点。</p>
<h2 id="Consumer-poll-模型"><a href="#Consumer-poll-模型" class="headerlink" title="Consumer poll 模型"></a>Consumer poll 模型</h2><p>Consumer poll 方法的真正实现是在 <code>pollOnce()</code> 方法中，这里直接看下其源码：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/**</span></div><div class="line"> * Do one round of polling. In addition to checking for new data, this does any needed offset commits</div><div class="line"> * (if auto-commit is enabled), and offset resets (if an offset reset policy is defined).</div><div class="line"> * <span class="doctag">@param</span> timeout The maximum time to block in the underlying call to &#123;<span class="doctag">@link</span> ConsumerNetworkClient#poll(long)&#125;.</div><div class="line"> * <span class="doctag">@return</span> The fetched records (may be empty)</div><div class="line"> */</div><div class="line"><span class="comment">// note: 一次 poll 过程,包括检查新的数据、做一些必要的 commit 以及 offset  重置操作</span></div><div class="line"><span class="keyword">private</span> Map&lt;TopicPartition, List&lt;ConsumerRecord&lt;K, V&gt;&gt;&gt; pollOnce(<span class="keyword">long</span> timeout) &#123;</div><div class="line">    <span class="comment">// note： 1. 获取 GroupCoordinator 并连接、加入 Group、sync Group, 期间 group 会进行 rebalance 并获取</span></div><div class="line">    coordinator.poll(time.milliseconds());</div><div class="line">    <span class="comment">// assignment</span></div><div class="line"></div><div class="line">    <span class="comment">// fetch positions if we have partitions we're subscribed to that we</span></div><div class="line">    <span class="comment">// don't know the offset for</span></div><div class="line">    <span class="comment">// note: 2. 更新要拉取 partition 的 offset（如果需要更新的话）</span></div><div class="line">    <span class="keyword">if</span> (!subscriptions.hasAllFetchPositions())</div><div class="line">        updateFetchPositions(<span class="keyword">this</span>.subscriptions.missingFetchPositions());</div><div class="line"></div><div class="line">    <span class="comment">// if data is available already, return it immediately</span></div><div class="line">    <span class="comment">// note: 3. 获取 fetcher 已经拉取到的数据</span></div><div class="line">    Map&lt;TopicPartition, List&lt;ConsumerRecord&lt;K, V&gt;&gt;&gt; records = fetcher.fetchedRecords();</div><div class="line">    <span class="keyword">if</span> (!records.isEmpty())</div><div class="line">        <span class="keyword">return</span> records;</div><div class="line">    <span class="comment">// note: 说明上次 fetch 到是的数据已经全部拉取了,需要再次发送 fetch 请求,从 broker 拉取数据</span></div><div class="line"></div><div class="line">    <span class="comment">// send any new fetches (won't resend pending fetches)</span></div><div class="line">    <span class="comment">// note: 4. 向订阅的所有 partition 发送 fetch 请求,会从多个 partition 拉取数据</span></div><div class="line">    fetcher.sendFetches();</div><div class="line"></div><div class="line">    <span class="keyword">long</span> now = time.milliseconds();</div><div class="line">    <span class="keyword">long</span> pollTimeout = Math.min(coordinator.timeToNextPoll(now), timeout);</div><div class="line"></div><div class="line">    <span class="comment">//note: 5. 调用 poll 方法发送数据</span></div><div class="line">    client.poll(pollTimeout, now, <span class="keyword">new</span> PollCondition() &#123;</div><div class="line">        <span class="meta">@Override</span></div><div class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">shouldBlock</span><span class="params">()</span> </span>&#123;</div><div class="line">            <span class="comment">// since a fetch might be completed by the background thread, we need this poll condition</span></div><div class="line">            <span class="comment">// to ensure that we do not block unnecessarily in poll()</span></div><div class="line">            <span class="keyword">return</span> !fetcher.hasCompletedFetches();</div><div class="line">        &#125;</div><div class="line">    &#125;);</div><div class="line"></div><div class="line">    <span class="comment">// after the long poll, we should check whether the group needs to rebalance</span></div><div class="line">    <span class="comment">// prior to returning data so that the group can stabilize faster</span></div><div class="line">    <span class="comment">//note: 6. 如果 group 需要 rebalance, 直接返回空数据,这样更快地让 group 进行稳定状态</span></div><div class="line">    <span class="keyword">if</span> (coordinator.needRejoin())</div><div class="line">        <span class="keyword">return</span> Collections.emptyMap();</div><div class="line"></div><div class="line">    <span class="keyword">return</span> fetcher.fetchedRecords();</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>在这里，我们把一个 pollOnce 模型分为6个部分，这里简单介绍一下：</p>
<ol>
<li>连接 GroupCoordinator，并发送 join-group、sync-group 请求，加入 group 成功，并获取其分配的 tp 列表；</li>
<li>更新这些分配的 tp 列表的 the last committed offset（没有的话，根据其设置进行获取 offset）；</li>
<li>调用 Fetcher 获取拉取的数据，如果有数据，立马返回，没有的话就进行下面的操作；</li>
<li>调用 Fetcher 发送 fetch 请求（只是加入队列，并未真正发送）；</li>
<li>调用 poll() 方法发送请求；</li>
<li>如果 group 之前是需要 rebalacne 的，直接返回空集合，这样可以便于 group 尽快达到一个稳定的状态。</li>
</ol>
<p>一个 Consumer 实例消费数据的前提是能够加入一个 group 成功，并获取其要订阅的 tp（topic-partition）列表，这都是在第一步中完成的，如果这个 group 是一个新的 group，那么 group 的状态将会由 <strong>Empty –&gt; PreparingRebalance –&gt; AwaitSync –&gt; Stable</strong> 的变化过程，下面将会详细介绍。</p>
<h2 id="Consumer-join-group-详解"><a href="#Consumer-join-group-详解" class="headerlink" title="Consumer join-group 详解"></a>Consumer join-group 详解</h2><p>通过上面，我们知道，poll 模型的第一步是在 <code>ConsumerCoordinator.poll()</code> 中实现的，其整体过程如下所示。</p>
<p><img src="/images/kafka/join-group.png" alt="Consumer 加入一个 group 的整体流程"></p>
<blockquote>
<p>其实，主要观察图中左边的部分即可，也就是 ConsumerCoordinator 和 AbstractCoordinator 中的方法。</p>
</blockquote>
<p>对于一个 Consumer Group，其状态变化图下图所示（后面会讲到）。</p>
<p><img src="/images/kafka/group.png" alt="Group 状态变化图"></p>
<h3 id="ConsumerCoordinator-poll"><a href="#ConsumerCoordinator-poll" class="headerlink" title="ConsumerCoordinator.poll()"></a><code>ConsumerCoordinator.poll()</code></h3><p>先看一下 <code>ConsumerCoordinator.poll()</code> 的具体实现</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// note: 它确保了这个 group 的 coordinator 是已知的,并且这个 consumer 是已经加入到了 group 中,也用于 offset 周期性的 commit</span></div><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">poll</span><span class="params">(<span class="keyword">long</span> now)</span> </span>&#123;</div><div class="line">    invokeCompletedOffsetCommitCallbacks();<span class="comment">// note: 用于测试</span></div><div class="line"></div><div class="line">    <span class="comment">// note: Step1 通过 subscribe() 方法订阅 topic,并且 coordinator 未知,初始化 Consumer Coordinator</span></div><div class="line">    <span class="keyword">if</span> (subscriptions.partitionsAutoAssigned() &amp;&amp; coordinatorUnknown()) &#123;</div><div class="line">        <span class="comment">// note: 获取 GroupCoordinator 地址,并且建立连接</span></div><div class="line">        ensureCoordinatorReady();</div><div class="line">        now = time.milliseconds();</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="comment">// note: Step2 判断是否需要重新加入 group,如果订阅的 partition 变化或则分配的 partition 变化时,需要 rejoin</span></div><div class="line">    <span class="keyword">if</span> (needRejoin()) &#123;</div><div class="line">        <span class="comment">// due to a race condition between the initial metadata fetch and the initial rebalance,</span></div><div class="line">        <span class="comment">// we need to ensure that the metadata is fresh before joining initially. This ensures</span></div><div class="line">        <span class="comment">// that we have matched the pattern against the cluster's topics at least once before joining.</span></div><div class="line">        <span class="comment">// note: rejoin group 之前先刷新一下 metadata（对于 AUTO_PATTERN 而言）</span></div><div class="line">        <span class="keyword">if</span> (subscriptions.hasPatternSubscription())</div><div class="line">            client.ensureFreshMetadata();</div><div class="line"></div><div class="line">        <span class="comment">// note: 确保 group 是 active; 加入 group; 分配订阅的 partition</span></div><div class="line">        ensureActiveGroup();</div><div class="line">        now = time.milliseconds();</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="comment">// note: Step3 检查心跳线程运行是否正常,如果心跳线程失败,则抛出异常,反之更新 poll 调用的时间</span></div><div class="line">    pollHeartbeat(now);</div><div class="line">    <span class="comment">// note: Step4 自动 commit 时,当定时达到时,进行自动 commit</span></div><div class="line">    maybeAutoCommitOffsetsAsync(now);</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>在 poll 方法中，具体实现，可以分为以下三步：</p>
<ol>
<li>通过 <code>subscribe()</code> 方法订阅 topic, 并且 coordinator 未知，就初始化 Consumer Coordinator（在 <code>ensureCoordinatorReady()</code> 中实现，主要的作用是发送 GroupCoordinator 请求，并建立连接）；</li>
<li>判断是否需要重新加入 group，如果订阅的 partition 变化或则分配的 partition 变化时，需要 rejoin，通过 <code>ensureActiveGroup()</code> 发送 join-group、sync-group 请求，加入 group 并获取其 assign 的 tp list；</li>
<li>检测心跳线程运行是否正常（需要定时向 GroupCoordinator 发送心跳线程，长时间未发送的话 group就会认为该实例已经挂了）；</li>
<li>如果设置的是自动 commit，如果定时达到自动 commit。</li>
</ol>
<p>这其中，有两个地方需要详细介绍，那就是第一步中的 <code>ensureCoordinatorReady()</code> 方法和第二步中的 <code>ensureActiveGroup()</code> 方法。</p>
<h3 id="ensureCoordinatorReady"><a href="#ensureCoordinatorReady" class="headerlink" title="ensureCoordinatorReady()"></a><code>ensureCoordinatorReady()</code></h3><p>这个方法的作用是：选择一个连接数最小的 broker，向其发送 GroupCoordinator 请求，并建立相应的 TCP 连接。</p>
<ul>
<li>其方法的调用如前面的流程图所示：ensureCoordinatorReady() –&gt; lookupCoordinator() –&gt; sendGroupCoordinatorRequest()。</li>
<li>如果 client 获取到 Server response，那么就会与 GroupCoordinator 建立连接；</li>
</ul>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// note: 确保 coordinator 已经 ready（已经连接,并可以发送请求）</span></div><div class="line"><span class="comment">// note: 如果 coordinator 已经 ready 返回 true,否则返回 flase。</span></div><div class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">synchronized</span> <span class="keyword">boolean</span> <span class="title">ensureCoordinatorReady</span><span class="params">(<span class="keyword">long</span> startTimeMs, <span class="keyword">long</span> timeoutMs)</span> </span>&#123;</div><div class="line">    <span class="keyword">long</span> remainingMs = timeoutMs;</div><div class="line"></div><div class="line">    <span class="keyword">while</span> (coordinatorUnknown()) &#123;</div><div class="line">        <span class="comment">// note:  获取 GroupCoordinator,并建立连接</span></div><div class="line">        RequestFuture&lt;Void&gt; future = lookupCoordinator();</div><div class="line">        client.poll(future, remainingMs);</div><div class="line"></div><div class="line">        <span class="keyword">if</span> (future.failed()) &#123;<span class="comment">// note: 如果获取的过程中失败了</span></div><div class="line">            <span class="keyword">if</span> (future.isRetriable()) &#123;</div><div class="line">                remainingMs = timeoutMs - (time.milliseconds() - startTimeMs);</div><div class="line">                <span class="keyword">if</span> (remainingMs &lt;= <span class="number">0</span>)</div><div class="line">                    <span class="keyword">break</span>;</div><div class="line"></div><div class="line">                log.debug(<span class="string">"Coordinator discovery failed for group &#123;&#125;, refreshing metadata"</span>, groupId);</div><div class="line">                client.awaitMetadataUpdate(remainingMs);</div><div class="line">            &#125; <span class="keyword">else</span></div><div class="line">                <span class="keyword">throw</span> future.exception();</div><div class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> (coordinator != <span class="keyword">null</span> &amp;&amp; client.connectionFailed(coordinator)) &#123;</div><div class="line">            <span class="comment">// we found the coordinator, but the connection has failed, so mark</span></div><div class="line">            <span class="comment">// it dead and backoff before retrying discovery</span></div><div class="line">            coordinatorDead();</div><div class="line">            time.sleep(retryBackoffMs);</div><div class="line">        &#125;</div><div class="line"></div><div class="line">        remainingMs = timeoutMs - (time.milliseconds() - startTimeMs);</div><div class="line">        <span class="keyword">if</span> (remainingMs &lt;= <span class="number">0</span>)</div><div class="line">            <span class="keyword">break</span>;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="keyword">return</span> !coordinatorUnknown();</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="comment">// note: 选择一个连接最小的节点,发送 groupCoordinator 请求</span></div><div class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">synchronized</span> RequestFuture&lt;Void&gt; <span class="title">lookupCoordinator</span><span class="params">()</span> </span>&#123;</div><div class="line">    <span class="keyword">if</span> (findCoordinatorFuture == <span class="keyword">null</span>) &#123;</div><div class="line">        <span class="comment">// find a node to ask about the coordinator</span></div><div class="line">        Node node = <span class="keyword">this</span>.client.leastLoadedNode();<span class="comment">//<span class="doctag">NOTE:</span> 找一个节点,发送 groupCoordinator 的请求</span></div><div class="line">        <span class="keyword">if</span> (node == <span class="keyword">null</span>) &#123;</div><div class="line">            <span class="comment">// <span class="doctag">TODO:</span> If there are no brokers left, perhaps we should use the bootstrap set</span></div><div class="line">            <span class="comment">// from configuration?</span></div><div class="line">            log.debug(<span class="string">"No broker available to send GroupCoordinator request for group &#123;&#125;"</span>, groupId);</div><div class="line">            <span class="keyword">return</span> RequestFuture.noBrokersAvailable();</div><div class="line">        &#125; <span class="keyword">else</span></div><div class="line">            findCoordinatorFuture = sendGroupCoordinatorRequest(node);<span class="comment">//<span class="doctag">NOTE:</span> 发送请求，并对 response 进行处理</span></div><div class="line">    &#125;</div><div class="line">    <span class="keyword">return</span> findCoordinatorFuture;</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="comment">//<span class="doctag">NOTE:</span> 发送 GroupCoordinator 的请求</span></div><div class="line"><span class="function"><span class="keyword">private</span> RequestFuture&lt;Void&gt; <span class="title">sendGroupCoordinatorRequest</span><span class="params">(Node node)</span> </span>&#123;</div><div class="line">    <span class="comment">// initiate the group metadata request</span></div><div class="line">    log.debug(<span class="string">"Sending GroupCoordinator request for group &#123;&#125; to broker &#123;&#125;"</span>, groupId, node);</div><div class="line">    GroupCoordinatorRequest.Builder requestBuilder =</div><div class="line">            <span class="keyword">new</span> GroupCoordinatorRequest.Builder(<span class="keyword">this</span>.groupId);</div><div class="line">    <span class="keyword">return</span> client.send(node, requestBuilder)</div><div class="line">                 .compose(<span class="keyword">new</span> GroupCoordinatorResponseHandler());</div><div class="line">    <span class="comment">//<span class="doctag">NOTE:</span> compose 的作用是将 GroupCoordinatorResponseHandler 类转换为 RequestFuture</span></div><div class="line">    <span class="comment">//<span class="doctag">NOTE:</span> 实际上就是为返回的 Future 类重置 onSuccess() 和 onFailure() 方法</span></div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="comment">//<span class="doctag">NOTE:</span> 对 GroupCoordinator 的 response 进行处理,回调</span></div><div class="line"><span class="keyword">private</span> <span class="class"><span class="keyword">class</span> <span class="title">GroupCoordinatorResponseHandler</span> <span class="keyword">extends</span> <span class="title">RequestFutureAdapter</span>&lt;<span class="title">ClientResponse</span>, <span class="title">Void</span>&gt; </span>&#123;</div><div class="line"></div><div class="line">    <span class="meta">@Override</span></div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onSuccess</span><span class="params">(ClientResponse resp, RequestFuture&lt;Void&gt; future)</span> </span>&#123;</div><div class="line">        log.debug(<span class="string">"Received GroupCoordinator response &#123;&#125; for group &#123;&#125;"</span>, resp, groupId);</div><div class="line"></div><div class="line">        GroupCoordinatorResponse groupCoordinatorResponse = (GroupCoordinatorResponse) resp.responseBody();</div><div class="line">        <span class="comment">// use MAX_VALUE - node.id as the coordinator id to mimic separate connections</span></div><div class="line">        <span class="comment">// for the coordinator in the underlying network client layer</span></div><div class="line">        <span class="comment">// <span class="doctag">TODO:</span> this needs to be better handled in KAFKA-1935</span></div><div class="line">        Errors error = Errors.forCode(groupCoordinatorResponse.errorCode());</div><div class="line">        clearFindCoordinatorFuture();</div><div class="line">        <span class="keyword">if</span> (error == Errors.NONE) &#123;</div><div class="line">            <span class="comment">// note: 如果正确获取 GroupCoordinator 时, 建立连接,并更新心跳时间</span></div><div class="line">            <span class="keyword">synchronized</span> (AbstractCoordinator.<span class="keyword">this</span>) &#123;</div><div class="line">                AbstractCoordinator.<span class="keyword">this</span>.coordinator = <span class="keyword">new</span> Node(</div><div class="line">                        Integer.MAX_VALUE - groupCoordinatorResponse.node().id(),</div><div class="line">                        groupCoordinatorResponse.node().host(),</div><div class="line">                        groupCoordinatorResponse.node().port());</div><div class="line">                log.info(<span class="string">"Discovered coordinator &#123;&#125; for group &#123;&#125;."</span>, coordinator, groupId);</div><div class="line">                client.tryConnect(coordinator);<span class="comment">//note: 初始化 tcp 连接</span></div><div class="line">                heartbeat.resetTimeouts(time.milliseconds());<span class="comment">//note: 更新心跳时间</span></div><div class="line">            &#125;</div><div class="line">            future.complete(<span class="keyword">null</span>);</div><div class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> (error == Errors.GROUP_AUTHORIZATION_FAILED) &#123;</div><div class="line">            future.raise(<span class="keyword">new</span> GroupAuthorizationException(groupId));</div><div class="line">        &#125; <span class="keyword">else</span> &#123;</div><div class="line">            log.debug(<span class="string">"Group coordinator lookup for group &#123;&#125; failed: &#123;&#125;"</span>, groupId, error.message());</div><div class="line">            future.raise(error);</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="meta">@Override</span></div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onFailure</span><span class="params">(RuntimeException e, RequestFuture&lt;Void&gt; future)</span> </span>&#123;</div><div class="line">        clearFindCoordinatorFuture();</div><div class="line">        <span class="keyword">super</span>.onFailure(e, future);</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h3 id="ensureActiveGroup"><a href="#ensureActiveGroup" class="headerlink" title="ensureActiveGroup()"></a><code>ensureActiveGroup()</code></h3><p>这个方法的作用是：向 GroupCoordinator 发送 join-group、sync-group 请求，获取 assign 的 tp list。</p>
<ul>
<li>如前面图中所示，ensureActiveGroup 方法的调用过程：ensureActiveGroup() –&gt; ensureCoordinatorReady() –&gt; startHeartbeatThreadIfNeeded() –&gt; joinGroupIfNeeded()；</li>
<li><code>joinGroupIfNeeded()</code> 方法中最重要的方法是 <code>initiateJoinGroup()</code>，其方法的调用过程为：initiateJoinGroup() –&gt; sendJoinGroupRequest() –&gt; JoinGroupResponseHandler.handle().succeed –&gt; onJoinLeader()/onJoinFollower() –&gt; sendSyncGroupRequest() –&gt; SyncGroupResponseHandler。</li>
</ul>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//<span class="doctag">NOTE:</span> 确保 Group 是 active,并且加入该 group</span></div><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">ensureActiveGroup</span><span class="params">()</span> </span>&#123;</div><div class="line">    <span class="comment">// always ensure that the coordinator is ready because we may have been disconnected</span></div><div class="line">    <span class="comment">// when sending heartbeats and does not necessarily require us to rejoin the group.</span></div><div class="line">    ensureCoordinatorReady();<span class="comment">//<span class="doctag">NOTE:</span> 确保 GroupCoordinator 已经连接</span></div><div class="line">    startHeartbeatThreadIfNeeded();<span class="comment">//<span class="doctag">NOTE:</span> 启动心跳发送线程（并不一定发送心跳,满足条件后才会发送心跳）</span></div><div class="line">    joinGroupIfNeeded();<span class="comment">//<span class="doctag">NOTE:</span> 发送 JoinGroup 请求,并对返回的信息进行处理</span></div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>join-group 的请求是在 <code>joinGroupIfNeeded()</code> 中实现的。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// note: join group</span></div><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">joinGroupIfNeeded</span><span class="params">()</span> </span>&#123;</div><div class="line">    <span class="keyword">while</span> (needRejoin() || rejoinIncomplete()) &#123;</div><div class="line">        ensureCoordinatorReady();</div><div class="line">        <span class="comment">// call onJoinPrepare if needed. We set a flag to make sure that we do not call it a second</span></div><div class="line">        <span class="comment">// time if the client is woken up before a pending rebalance completes. This must be called</span></div><div class="line">        <span class="comment">// on each iteration of the loop because an event requiring a rebalance (such as a metadata</span></div><div class="line">        <span class="comment">// refresh which changes the matched subscription set) can occur while another rebalance is</span></div><div class="line">        <span class="comment">// still in progress.</span></div><div class="line">        <span class="comment">//note: 触发 onJoinPrepare, 包括 offset commit 和 rebalance listener</span></div><div class="line">        <span class="keyword">if</span> (needsJoinPrepare) &#123;</div><div class="line">            onJoinPrepare(generation.generationId, generation.memberId);</div><div class="line">            needsJoinPrepare = <span class="keyword">false</span>;</div><div class="line">        &#125;</div><div class="line"></div><div class="line">        <span class="comment">// note: 初始化 JoinGroup 请求,并发送该请求</span></div><div class="line">        RequestFuture&lt;ByteBuffer&gt; future = initiateJoinGroup();</div><div class="line">        client.poll(future);</div><div class="line">        resetJoinGroupFuture();<span class="comment">//<span class="doctag">NOTE:</span> 重置 joinFuture 为空</span></div><div class="line"></div><div class="line">        <span class="keyword">if</span> (future.succeeded()) &#123;<span class="comment">//note: join succeed,这一步时,时间上 sync-group 已经成功了</span></div><div class="line">            needsJoinPrepare = <span class="keyword">true</span>;</div><div class="line">            onJoinComplete(generation.generationId, generation.memberId, generation.protocol, future.value());</div><div class="line">        &#125; <span class="keyword">else</span> &#123;</div><div class="line">            RuntimeException exception = future.exception();</div><div class="line">            <span class="keyword">if</span> (exception <span class="keyword">instanceof</span> UnknownMemberIdException ||</div><div class="line">                    exception <span class="keyword">instanceof</span> RebalanceInProgressException ||</div><div class="line">                    exception <span class="keyword">instanceof</span> IllegalGenerationException)</div><div class="line">                <span class="keyword">continue</span>;</div><div class="line">            <span class="keyword">else</span> <span class="keyword">if</span> (!future.isRetriable())</div><div class="line">                <span class="keyword">throw</span> exception;</div><div class="line">            time.sleep(retryBackoffMs);</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p><code>sendJoinGroupRequest()</code> 方法是由 <code>initiateJoinGroup()</code> 方法来调用的。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//<span class="doctag">NOTE:</span> 发送 JoinGroup 的请求, 并添加 listener</span></div><div class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">synchronized</span> RequestFuture&lt;ByteBuffer&gt; <span class="title">initiateJoinGroup</span><span class="params">()</span> </span>&#123;</div><div class="line">    <span class="comment">// we store the join future in case we are woken up by the user after beginning the</span></div><div class="line">    <span class="comment">// rebalance in the call to poll below. This ensures that we do not mistakenly attempt</span></div><div class="line">    <span class="comment">// to rejoin before the pending rebalance has completed.</span></div><div class="line">    <span class="keyword">if</span> (joinFuture == <span class="keyword">null</span>) &#123;</div><div class="line">        <span class="comment">// fence off the heartbeat thread explicitly so that it cannot interfere with the join group.</span></div><div class="line">        <span class="comment">// Note that this must come after the call to onJoinPrepare since we must be able to continue</span></div><div class="line">        <span class="comment">// sending heartbeats if that callback takes some time.</span></div><div class="line">        <span class="comment">// note: rebalance 期间,心跳线程停止</span></div><div class="line">        disableHeartbeatThread();</div><div class="line"></div><div class="line">        state = MemberState.REBALANCING;<span class="comment">//<span class="doctag">NOTE:</span> 标记为 rebalance</span></div><div class="line">        joinFuture = sendJoinGroupRequest();<span class="comment">//<span class="doctag">NOTE:</span> 发送 JoinGroup 请求</span></div><div class="line">        joinFuture.addListener(<span class="keyword">new</span> RequestFutureListener&lt;ByteBuffer&gt;() &#123;</div><div class="line">            <span class="meta">@Override</span></div><div class="line">            <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onSuccess</span><span class="params">(ByteBuffer value)</span> </span>&#123;</div><div class="line">                <span class="comment">// handle join completion in the callback so that the callback will be invoked</span></div><div class="line">                <span class="comment">// even if the consumer is woken up before finishing the rebalance</span></div><div class="line">                <span class="keyword">synchronized</span> (AbstractCoordinator.<span class="keyword">this</span>) &#123;</div><div class="line">                    log.info(<span class="string">"Successfully joined group &#123;&#125; with generation &#123;&#125;"</span>, groupId, generation.generationId);</div><div class="line">                    state = MemberState.STABLE;<span class="comment">//<span class="doctag">NOTE:</span> 标记 Consumer 为 stable</span></div><div class="line"></div><div class="line">                    <span class="keyword">if</span> (heartbeatThread != <span class="keyword">null</span>)</div><div class="line">                        heartbeatThread.enable();</div><div class="line">                &#125;</div><div class="line">            &#125;</div><div class="line"></div><div class="line">            <span class="meta">@Override</span></div><div class="line">            <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onFailure</span><span class="params">(RuntimeException e)</span> </span>&#123;</div><div class="line">                <span class="comment">// we handle failures below after the request finishes. if the join completes</span></div><div class="line">                <span class="comment">// after having been woken up, the exception is ignored and we will rejoin</span></div><div class="line">                <span class="keyword">synchronized</span> (AbstractCoordinator.<span class="keyword">this</span>) &#123;</div><div class="line">                    state = MemberState.UNJOINED;<span class="comment">//<span class="doctag">NOTE:</span> 标记 Consumer 为 Unjoined</span></div><div class="line">                &#125;</div><div class="line">            &#125;</div><div class="line">        &#125;);</div><div class="line">    &#125;</div><div class="line">    <span class="keyword">return</span> joinFuture;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>sendJoinGroupRequest() 及其处理如下所示。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/**</span></div><div class="line"> * Join the group and return the assignment for the next generation. This function handles both</div><div class="line"> * JoinGroup and SyncGroup, delegating to &#123;<span class="doctag">@link</span> #performAssignment(String, String, Map)&#125; if</div><div class="line"> * elected leader by the coordinator.</div><div class="line"> * <span class="doctag">@return</span> A request future which wraps the assignment returned from the group leader</div><div class="line"> */</div><div class="line"><span class="comment">//<span class="doctag">NOTE:</span> 发送 JoinGroup 请求并返回 the assignment for the next generation（这个是在 JoinGroupResponseHandler 中做的）</span></div><div class="line"><span class="function"><span class="keyword">private</span> RequestFuture&lt;ByteBuffer&gt; <span class="title">sendJoinGroupRequest</span><span class="params">()</span> </span>&#123;</div><div class="line">    <span class="keyword">if</span> (coordinatorUnknown())</div><div class="line">        <span class="keyword">return</span> RequestFuture.coordinatorNotAvailable();</div><div class="line"></div><div class="line">    <span class="comment">// send a join group request to the coordinator</span></div><div class="line">    log.info(<span class="string">"(Re-)joining group &#123;&#125;"</span>, groupId);</div><div class="line">    JoinGroupRequest.Builder requestBuilder = <span class="keyword">new</span> JoinGroupRequest.Builder(</div><div class="line">            groupId,</div><div class="line">            <span class="keyword">this</span>.sessionTimeoutMs,</div><div class="line">            <span class="keyword">this</span>.generation.memberId,</div><div class="line">            protocolType(),</div><div class="line">            metadata()).setRebalanceTimeout(<span class="keyword">this</span>.rebalanceTimeoutMs);</div><div class="line"></div><div class="line">    log.debug(<span class="string">"Sending JoinGroup (&#123;&#125;) to coordinator &#123;&#125;"</span>, requestBuilder, <span class="keyword">this</span>.coordinator);</div><div class="line">    <span class="keyword">return</span> client.send(coordinator, requestBuilder)</div><div class="line">            .compose(<span class="keyword">new</span> JoinGroupResponseHandler());</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="comment">//<span class="doctag">NOTE:</span> 处理 JoinGroup response 的 handler（同步 group 信息）</span></div><div class="line"><span class="keyword">private</span> <span class="class"><span class="keyword">class</span> <span class="title">JoinGroupResponseHandler</span> <span class="keyword">extends</span> <span class="title">CoordinatorResponseHandler</span>&lt;<span class="title">JoinGroupResponse</span>, <span class="title">ByteBuffer</span>&gt; </span>&#123;</div><div class="line">    <span class="meta">@Override</span></div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">handle</span><span class="params">(JoinGroupResponse joinResponse, RequestFuture&lt;ByteBuffer&gt; future)</span> </span>&#123;</div><div class="line">        Errors error = Errors.forCode(joinResponse.errorCode());</div><div class="line">        <span class="keyword">if</span> (error == Errors.NONE) &#123;</div><div class="line">            log.debug(<span class="string">"Received successful JoinGroup response for group &#123;&#125;: &#123;&#125;"</span>, groupId, joinResponse);</div><div class="line">            sensors.joinLatency.record(response.requestLatencyMs());</div><div class="line"></div><div class="line">            <span class="keyword">synchronized</span> (AbstractCoordinator.<span class="keyword">this</span>) &#123;</div><div class="line">                <span class="keyword">if</span> (state != MemberState.REBALANCING) &#123;<span class="comment">//<span class="doctag">NOTE:</span> 如果此时 Consumer 的状态不是 rebalacing,就引起异常</span></div><div class="line">                    <span class="comment">// if the consumer was woken up before a rebalance completes, we may have already left</span></div><div class="line">                    <span class="comment">// the group. In this case, we do not want to continue with the sync group.</span></div><div class="line">                    future.raise(<span class="keyword">new</span> UnjoinedGroupException());</div><div class="line">                &#125; <span class="keyword">else</span> &#123;</div><div class="line">                    AbstractCoordinator.<span class="keyword">this</span>.generation = <span class="keyword">new</span> Generation(joinResponse.generationId(),</div><div class="line">                            joinResponse.memberId(), joinResponse.groupProtocol());</div><div class="line">                    AbstractCoordinator.<span class="keyword">this</span>.rejoinNeeded = <span class="keyword">false</span>;</div><div class="line">                    <span class="comment">//<span class="doctag">NOTE:</span> join group 成功,下面需要进行 sync-group,获取分配的 tp 列表。</span></div><div class="line">                    <span class="keyword">if</span> (joinResponse.isLeader()) &#123;</div><div class="line">                        onJoinLeader(joinResponse).chain(future);</div><div class="line">                    &#125; <span class="keyword">else</span> &#123;</div><div class="line">                        onJoinFollower().chain(future);</div><div class="line">                    &#125;</div><div class="line">                &#125;</div><div class="line">            &#125;</div><div class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> (error == Errors.GROUP_LOAD_IN_PROGRESS) &#123;</div><div class="line">            log.debug(<span class="string">"Attempt to join group &#123;&#125; rejected since coordinator &#123;&#125; is loading the group."</span>, groupId,</div><div class="line">                    coordinator());</div><div class="line">            <span class="comment">// backoff and retry</span></div><div class="line">            future.raise(error);</div><div class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> (error == Errors.UNKNOWN_MEMBER_ID) &#123;</div><div class="line">            <span class="comment">// reset the member id and retry immediately</span></div><div class="line">            resetGeneration();</div><div class="line">            log.debug(<span class="string">"Attempt to join group &#123;&#125; failed due to unknown member id."</span>, groupId);</div><div class="line">            future.raise(Errors.UNKNOWN_MEMBER_ID);</div><div class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> (error == Errors.GROUP_COORDINATOR_NOT_AVAILABLE</div><div class="line">                || error == Errors.NOT_COORDINATOR_FOR_GROUP) &#123;</div><div class="line">            <span class="comment">// re-discover the coordinator and retry with backoff</span></div><div class="line">            coordinatorDead();</div><div class="line">            log.debug(<span class="string">"Attempt to join group &#123;&#125; failed due to obsolete coordinator information: &#123;&#125;"</span>, groupId, error.message());</div><div class="line">            future.raise(error);</div><div class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> (error == Errors.INCONSISTENT_GROUP_PROTOCOL</div><div class="line">                || error == Errors.INVALID_SESSION_TIMEOUT</div><div class="line">                || error == Errors.INVALID_GROUP_ID) &#123;</div><div class="line">            <span class="comment">// log the error and re-throw the exception</span></div><div class="line">            log.error(<span class="string">"Attempt to join group &#123;&#125; failed due to fatal error: &#123;&#125;"</span>, groupId, error.message());</div><div class="line">            future.raise(error);</div><div class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> (error == Errors.GROUP_AUTHORIZATION_FAILED) &#123;</div><div class="line">            future.raise(<span class="keyword">new</span> GroupAuthorizationException(groupId));</div><div class="line">        &#125; <span class="keyword">else</span> &#123;</div><div class="line">            <span class="comment">// unexpected error, throw the exception</span></div><div class="line">            future.raise(<span class="keyword">new</span> KafkaException(<span class="string">"Unexpected error in join group response: "</span> + error.message()));</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>sendJoinGroupRequest()：向 GroupCoordinator 发送 join-group 请求</p>
<ol>
<li>如果 group 是新的 group.id，那么此时 group 初始化的状态为 <strong>Empty</strong>；</li>
<li>当 GroupCoordinator 接收到 consumer 的 join-group 请求后，由于此时这个 group 的 member 列表还是空（group 是新建的，每个 consumer 实例被称为这个 group 的一个 member），第一个加入的 member 将被选为 leader，也就是说，对于一个新的 consumer group 而言，当第一个 consumer 实例加入后将会被选为 leader；</li>
<li>如果 GroupCoordinator 接收到 leader 发送 join-group 请求，将会触发 rebalance，group 的状态变为 <strong>PreparingRebalance</strong>；</li>
<li>此时，GroupCoordinator 将会等待一定的时间，如果在一定时间内，接收到 join-group 请求的 consumer 将被认为是依然存活的，此时 group 会变为 <strong>AwaitSync</strong> 状态，并且 GroupCoordinator 会向这个 group 的所有 member 返回其 response；</li>
<li>consumer 在接收到 GroupCoordinator 的 response 后，如果这个 consumer 是 group 的 leader，那么这个 consumer 将会负责为整个 group assign partition 订阅安排（默认是按 range 的策略，目前也可选 roundrobin），然后 leader 将分配后的信息以 <code>sendSyncGroupRequest()</code> 请求的方式发给 GroupCoordinator，而作为 follower 的 consumer 实例会发送一个空列表；</li>
<li>GroupCoordinator 在接收到 leader 发来的请求后，会将 assign 的结果返回给所有已经发送 sync-group 请求的 consumer 实例，并且 group 的状态将会转变为 <strong>Stable</strong>，如果后续再收到 sync-group 请求，由于 group 的状态已经是 Stable，将会直接返回其分配结果。</li>
</ol>
<p>sync-group 请求的发送及其实现如下所示。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//note: 当 consumer 为 follower 时,从 GroupCoordinator 拉取分配结果</span></div><div class="line"><span class="function"><span class="keyword">private</span> RequestFuture&lt;ByteBuffer&gt; <span class="title">onJoinFollower</span><span class="params">()</span> </span>&#123;</div><div class="line">    <span class="comment">// send follower's sync group with an empty assignment</span></div><div class="line">    SyncGroupRequest.Builder requestBuilder =</div><div class="line">            <span class="keyword">new</span> SyncGroupRequest.Builder(groupId, generation.generationId, generation.memberId,</div><div class="line">                    Collections.&lt;String, ByteBuffer&gt;emptyMap());</div><div class="line">    log.debug(<span class="string">"Sending follower SyncGroup for group &#123;&#125; to coordinator &#123;&#125;: &#123;&#125;"</span>, groupId, <span class="keyword">this</span>.coordinator,</div><div class="line">            requestBuilder);</div><div class="line">    <span class="keyword">return</span> sendSyncGroupRequest(requestBuilder);</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="comment">//note: 当 consumer 客户端为 leader 时,对 group 下的所有实例进行分配,将 assign 的结果发送到 GroupCoordinator</span></div><div class="line"><span class="function"><span class="keyword">private</span> RequestFuture&lt;ByteBuffer&gt; <span class="title">onJoinLeader</span><span class="params">(JoinGroupResponse joinResponse)</span> </span>&#123;</div><div class="line">    <span class="keyword">try</span> &#123;</div><div class="line">        <span class="comment">// perform the leader synchronization and send back the assignment for the group</span></div><div class="line">        Map&lt;String, ByteBuffer&gt; groupAssignment = performAssignment(joinResponse.leaderId(), joinResponse.groupProtocol(),</div><div class="line">                joinResponse.members());<span class="comment">//<span class="doctag">NOTE:</span> 进行 assign 操作</span></div><div class="line"></div><div class="line">        SyncGroupRequest.Builder requestBuilder =</div><div class="line">                <span class="keyword">new</span> SyncGroupRequest.Builder(groupId, generation.generationId, generation.memberId, groupAssignment);</div><div class="line">        log.debug(<span class="string">"Sending leader SyncGroup for group &#123;&#125; to coordinator &#123;&#125;: &#123;&#125;"</span>,</div><div class="line">                groupId, <span class="keyword">this</span>.coordinator, requestBuilder);</div><div class="line">        <span class="keyword">return</span> sendSyncGroupRequest(requestBuilder);<span class="comment">//<span class="doctag">NOTE:</span> 发送 sync-group 请求</span></div><div class="line">    &#125; <span class="keyword">catch</span> (RuntimeException e) &#123;</div><div class="line">        <span class="keyword">return</span> RequestFuture.failure(e);</div><div class="line">    &#125;</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="comment">//<span class="doctag">NOTE:</span> 发送 SyncGroup 请求,获取对 partition 分配的安排</span></div><div class="line"><span class="function"><span class="keyword">private</span> RequestFuture&lt;ByteBuffer&gt; <span class="title">sendSyncGroupRequest</span><span class="params">(SyncGroupRequest.Builder requestBuilder)</span> </span>&#123;</div><div class="line">    <span class="keyword">if</span> (coordinatorUnknown())</div><div class="line">        <span class="keyword">return</span> RequestFuture.coordinatorNotAvailable();</div><div class="line">    <span class="keyword">return</span> client.send(coordinator, requestBuilder)</div><div class="line">            .compose(<span class="keyword">new</span> SyncGroupResponseHandler());</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="keyword">private</span> <span class="class"><span class="keyword">class</span> <span class="title">SyncGroupResponseHandler</span> <span class="keyword">extends</span> <span class="title">CoordinatorResponseHandler</span>&lt;<span class="title">SyncGroupResponse</span>, <span class="title">ByteBuffer</span>&gt; </span>&#123;</div><div class="line">    <span class="meta">@Override</span></div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">handle</span><span class="params">(SyncGroupResponse syncResponse,</span></span></div><div class="line">                       RequestFuture&lt;ByteBuffer&gt; future) &#123;</div><div class="line">        Errors error = Errors.forCode(syncResponse.errorCode());</div><div class="line">        <span class="keyword">if</span> (error == Errors.NONE) &#123;<span class="comment">//note: 同步成功</span></div><div class="line">            sensors.syncLatency.record(response.requestLatencyMs());</div><div class="line">            future.complete(syncResponse.memberAssignment());</div><div class="line">        &#125; <span class="keyword">else</span> &#123;</div><div class="line">            requestRejoin();<span class="comment">//note: join 的标志位设置为 true</span></div><div class="line"></div><div class="line">            <span class="keyword">if</span> (error == Errors.GROUP_AUTHORIZATION_FAILED) &#123;</div><div class="line">                future.raise(<span class="keyword">new</span> GroupAuthorizationException(groupId));</div><div class="line">            &#125; <span class="keyword">else</span> <span class="keyword">if</span> (error == Errors.REBALANCE_IN_PROGRESS) &#123;<span class="comment">//<span class="doctag">NOTE:</span> group 正在进行 rebalance,任务失败</span></div><div class="line">                log.debug(<span class="string">"SyncGroup for group &#123;&#125; failed due to coordinator rebalance"</span>, groupId);</div><div class="line">                future.raise(error);</div><div class="line">            &#125; <span class="keyword">else</span> <span class="keyword">if</span> (error == Errors.UNKNOWN_MEMBER_ID</div><div class="line">                    || error == Errors.ILLEGAL_GENERATION) &#123;</div><div class="line">                log.debug(<span class="string">"SyncGroup for group &#123;&#125; failed due to &#123;&#125;"</span>, groupId, error);</div><div class="line">                resetGeneration();</div><div class="line">                future.raise(error);</div><div class="line">            &#125; <span class="keyword">else</span> <span class="keyword">if</span> (error == Errors.GROUP_COORDINATOR_NOT_AVAILABLE</div><div class="line">                    || error == Errors.NOT_COORDINATOR_FOR_GROUP) &#123;</div><div class="line">                log.debug(<span class="string">"SyncGroup for group &#123;&#125; failed due to &#123;&#125;"</span>, groupId, error);</div><div class="line">                coordinatorDead();</div><div class="line">                future.raise(error);</div><div class="line">            &#125; <span class="keyword">else</span> &#123;</div><div class="line">                future.raise(<span class="keyword">new</span> KafkaException(<span class="string">"Unexpected error from SyncGroup: "</span> + error.message()));</div><div class="line">            &#125;</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h3 id="onJoinComplete"><a href="#onJoinComplete" class="headerlink" title="onJoinComplete()"></a><code>onJoinComplete()</code></h3><p>经过上面的步骤，一个 consumer 实例就已经加入 group 成功了，加入 group 成功后，将会触发ConsumerCoordinator 的 <code>onJoinComplete()</code> 方法，其作用就是：更新订阅的 tp 列表、更新其对应的 metadata 及触发注册的 listener。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// note: 加入 group 成功</span></div><div class="line"><span class="meta">@Override</span></div><div class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">onJoinComplete</span><span class="params">(<span class="keyword">int</span> generation,</span></span></div><div class="line">                              String memberId,</div><div class="line">                              String assignmentStrategy,</div><div class="line">                              ByteBuffer assignmentBuffer) &#123;</div><div class="line">    <span class="comment">// only the leader is responsible for monitoring for metadata changes (i.e. partition changes)</span></div><div class="line">    <span class="keyword">if</span> (!isLeader)</div><div class="line">        assignmentSnapshot = <span class="keyword">null</span>;</div><div class="line"></div><div class="line">    PartitionAssignor assignor = lookupAssignor(assignmentStrategy);</div><div class="line">    <span class="keyword">if</span> (assignor == <span class="keyword">null</span>)</div><div class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> IllegalStateException(<span class="string">"Coordinator selected invalid assignment protocol: "</span> + assignmentStrategy);</div><div class="line"></div><div class="line">    Assignment assignment = ConsumerProtocol.deserializeAssignment(assignmentBuffer);</div><div class="line"></div><div class="line">    <span class="comment">// set the flag to refresh last committed offsets</span></div><div class="line">    <span class="comment">//note: 设置是否需要拉取 last committed offsets 为 true</span></div><div class="line">    subscriptions.needRefreshCommits();</div><div class="line"></div><div class="line">    <span class="comment">// update partition assignment</span></div><div class="line">    <span class="comment">//note: 更新订阅的 tp list</span></div><div class="line">    subscriptions.assignFromSubscribed(assignment.partitions());</div><div class="line"></div><div class="line">    <span class="comment">// check if the assignment contains some topics that were not in the original</span></div><div class="line">    <span class="comment">// subscription, if yes we will obey what leader has decided and add these topics</span></div><div class="line">    <span class="comment">// into the subscriptions as long as they still match the subscribed pattern</span></div><div class="line">    <span class="comment">//</span></div><div class="line">    <span class="comment">// TODO this part of the logic should be removed once we allow regex on leader assign</span></div><div class="line">    Set&lt;String&gt; addedTopics = <span class="keyword">new</span> HashSet&lt;&gt;();</div><div class="line">    <span class="keyword">for</span> (TopicPartition tp : subscriptions.assignedPartitions()) &#123;</div><div class="line">        <span class="keyword">if</span> (!joinedSubscription.contains(tp.topic()))</div><div class="line">            addedTopics.add(tp.topic());</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="keyword">if</span> (!addedTopics.isEmpty()) &#123;</div><div class="line">        Set&lt;String&gt; newSubscription = <span class="keyword">new</span> HashSet&lt;&gt;(subscriptions.subscription());</div><div class="line">        Set&lt;String&gt; newJoinedSubscription = <span class="keyword">new</span> HashSet&lt;&gt;(joinedSubscription);</div><div class="line">        newSubscription.addAll(addedTopics);</div><div class="line">        newJoinedSubscription.addAll(addedTopics);</div><div class="line"></div><div class="line">        <span class="keyword">this</span>.subscriptions.subscribeFromPattern(newSubscription);</div><div class="line">        <span class="keyword">this</span>.joinedSubscription = newJoinedSubscription;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="comment">// update the metadata and enforce a refresh to make sure the fetcher can start</span></div><div class="line">    <span class="comment">// fetching data in the next iteration</span></div><div class="line">    <span class="comment">//note: 更新 metadata,确保在下一次循环中可以拉取</span></div><div class="line">    <span class="keyword">this</span>.metadata.setTopics(subscriptions.groupSubscription());</div><div class="line">    client.ensureFreshMetadata();</div><div class="line"></div><div class="line">    <span class="comment">// give the assignor a chance to update internal state based on the received assignment</span></div><div class="line">    assignor.onAssignment(assignment);</div><div class="line"></div><div class="line">    <span class="comment">// reschedule the auto commit starting from now</span></div><div class="line">    <span class="keyword">this</span>.nextAutoCommitDeadline = time.milliseconds() + autoCommitIntervalMs;</div><div class="line"></div><div class="line">    <span class="comment">// execute the user's callback after rebalance</span></div><div class="line">    <span class="comment">//note: 执行 listener</span></div><div class="line">    ConsumerRebalanceListener listener = subscriptions.listener();</div><div class="line">    log.info(<span class="string">"Setting newly assigned partitions &#123;&#125; for group &#123;&#125;"</span>, subscriptions.assignedPartitions(), groupId);</div><div class="line">    <span class="keyword">try</span> &#123;</div><div class="line">        Set&lt;TopicPartition&gt; assigned = <span class="keyword">new</span> HashSet&lt;&gt;(subscriptions.assignedPartitions());</div><div class="line">        listener.onPartitionsAssigned(assigned);</div><div class="line">    &#125; <span class="keyword">catch</span> (WakeupException | InterruptException e) &#123;</div><div class="line">        <span class="keyword">throw</span> e;</div><div class="line">    &#125; <span class="keyword">catch</span> (Exception e) &#123;</div><div class="line">        log.error(<span class="string">"User provided listener &#123;&#125; for group &#123;&#125; failed on partition assignment"</span>,</div><div class="line">                listener.getClass().getName(), groupId, e);</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>至此，一个 consumer 实例算是真正上意义上加入 group 成功。</p>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[Kafka 源码解析之 Producer 单 Partition 顺序性实现及配置说明（五）]]></title>
      <url>http://matt33.com/2017/09/10/produccer-end/</url>
      <content type="html"><![CDATA[<p>今天把 Kafka Producer 最后一部分给讲述一下，Producer 大部分内容都已经在前面几篇文章介绍过了，这里简单做个收尾，但并不是对前面的总结，本文从两块来讲述：RecordAccumulator 类的实现、Kafka Producer 如何保证其顺序性以及 Kafka Producer 的配置说明，每个 Producer 线程都会有一个 RecordAccumulator 对象，它负责缓存要发送 RecordBatch、记录发送的状态并且进行相应的处理，这里会详细讲述 Kafka Producer 如何保证单 Partition 的有序性。最后，简单介绍一下 Producer 的参数配置说明，只有正确地理解 Producer 相关的配置参数，才能更好地使用 Producer，发挥其相应的作用。</p>
<h2 id="RecordAccumulator"><a href="#RecordAccumulator" class="headerlink" title="RecordAccumulator"></a>RecordAccumulator</h2><p>这里再看一下 RecordAccumulator 的数据结构，如下图所示，每个 topic-partition 都有一个对应的 deque，deque 中存储的是 RecordBatch，它是发送的基本单位，只有这个 topic-partition 的 RecordBatch 达到大小或时间要求才会触发发送操作（但并不是只有达到这两个条件之一才会被发送，这点要理解清楚）。</p>
<p><img src="/images/kafka/recordbatch.png" alt="RecordAccumulator 模型"></p>
<p>再看一下 RecordAccumulator 类的主要方法介绍，如下图所示。</p>
<p><img src="/images/kafka/RecordAccumulator.png" alt="RecordAccumulator 主要方法及其说明"></p>
<p>这张图基本上涵盖了 RecordAccumulator 的主要方法，下面会选择其中几个方法详细讲述，会围绕着 Kafka Producer 如何实现单 Partition 顺序性这个主题来讲述。</p>
<h3 id="mutePartition-与-unmutePartition"><a href="#mutePartition-与-unmutePartition" class="headerlink" title="mutePartition() 与 unmutePartition()"></a>mutePartition() 与 unmutePartition()</h3><p>先看下 <code>mutePartition()</code> 与 <code>unmutePartition()</code> 这两个方法，它们是保证有序性关键之一，其主要做用就是将指定的 topic-partition 从 muted 集合中加入或删除，后面会看到它们的作用。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">private</span> <span class="keyword">final</span> Set&lt;TopicPartition&gt; muted;</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">mutePartition</span><span class="params">(TopicPartition tp)</span> </span>&#123;</div><div class="line">    muted.add(tp);</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">unmutePartition</span><span class="params">(TopicPartition tp)</span> </span>&#123;</div><div class="line">    muted.remove(tp);</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>这里先说一下这两个方法调用的条件，这样的话，下面在介绍其他方法时才会更容易理解：</p>
<ul>
<li><code>mutePartition()</code>：如果要求保证顺序性，那么这个 tp 对应的 RecordBatch 如果要开始发送，就将这个 tp 加入到 <code>muted</code> 集合中；</li>
<li><code>unmutePartition()</code>：如果 tp 对应的 RecordBatch 发送完成，tp 将会从 <code>muted</code> 集合中移除。</li>
</ul>
<p>也就是说，<code>muted</code> 是用来记录这个 tp 是否有还有未完成的 RecordBatch。</p>
<h3 id="ready"><a href="#ready" class="headerlink" title="ready()"></a>ready()</h3><p><code>ready()</code> 是在 Sender 线程中调用的，其作用选择那些可以发送的 node，也就是说，如果这个 tp 对应的 batch 可以发送（达到时间或大小要求），就把 tp 对应的 leader 选出来。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">public</span> ReadyCheckResult <span class="title">ready</span><span class="params">(Cluster cluster, <span class="keyword">long</span> nowMs)</span> </span>&#123;</div><div class="line">    Set&lt;Node&gt; readyNodes = <span class="keyword">new</span> HashSet&lt;&gt;();</div><div class="line">    <span class="keyword">long</span> nextReadyCheckDelayMs = Long.MAX_VALUE;</div><div class="line">    Set&lt;String&gt; unknownLeaderTopics = <span class="keyword">new</span> HashSet&lt;&gt;();</div><div class="line"></div><div class="line">    <span class="keyword">boolean</span> exhausted = <span class="keyword">this</span>.free.queued() &gt; <span class="number">0</span>;</div><div class="line">    <span class="keyword">for</span> (Map.Entry&lt;TopicPartition, Deque&lt;RecordBatch&gt;&gt; entry : <span class="keyword">this</span>.batches.entrySet()) &#123;</div><div class="line">        TopicPartition part = entry.getKey();</div><div class="line">        Deque&lt;RecordBatch&gt; deque = entry.getValue();</div><div class="line"></div><div class="line">        Node leader = cluster.leaderFor(part);</div><div class="line">        <span class="keyword">synchronized</span> (deque) &#123;</div><div class="line">            <span class="keyword">if</span> (leader == <span class="keyword">null</span> &amp;&amp; !deque.isEmpty()) &#123;</div><div class="line">                <span class="comment">// This is a partition for which leader is not known, but messages are available to send.</span></div><div class="line">                <span class="comment">// Note that entries are currently not removed from batches when deque is empty.</span></div><div class="line">                unknownLeaderTopics.add(part.topic());</div><div class="line">            &#125; <span class="keyword">else</span> <span class="keyword">if</span> (!readyNodes.contains(leader) &amp;&amp; !muted.contains(part)) &#123;<span class="comment">//note: part 如果 mute 就不会遍历</span></div><div class="line">                RecordBatch batch = deque.peekFirst();</div><div class="line">                <span class="keyword">if</span> (batch != <span class="keyword">null</span>) &#123;</div><div class="line">                    <span class="keyword">boolean</span> backingOff = batch.attempts &gt; <span class="number">0</span> &amp;&amp; batch.lastAttemptMs + retryBackoffMs &gt; nowMs;</div><div class="line">                    <span class="comment">//note: 是否是在重试</span></div><div class="line">                    <span class="keyword">long</span> waitedTimeMs = nowMs - batch.lastAttemptMs;</div><div class="line">                    <span class="keyword">long</span> timeToWaitMs = backingOff ? retryBackoffMs : lingerMs;</div><div class="line">                    <span class="keyword">long</span> timeLeftMs = Math.max(timeToWaitMs - waitedTimeMs, <span class="number">0</span>);</div><div class="line">                    <span class="keyword">boolean</span> full = deque.size() &gt; <span class="number">1</span> || batch.isFull(); <span class="comment">//note: batch 满了</span></div><div class="line">                    <span class="keyword">boolean</span> expired = waitedTimeMs &gt;= timeToWaitMs; <span class="comment">//note: batch 超时</span></div><div class="line">                    <span class="keyword">boolean</span> sendable = full || expired || exhausted || closed || flushInProgress();</div><div class="line">                    <span class="keyword">if</span> (sendable &amp;&amp; !backingOff) &#123;</div><div class="line">                        readyNodes.add(leader);<span class="comment">// note: 将可以发送的 leader 添加到集合中</span></div><div class="line">                    &#125; <span class="keyword">else</span> &#123;</div><div class="line">                        <span class="comment">// Note that this results in a conservative estimate since an un-sendable partition may have</span></div><div class="line">                        <span class="comment">// a leader that will later be found to have sendable data. However, this is good enough</span></div><div class="line">                        <span class="comment">// since we'll just wake up and then sleep again for the remaining time.</span></div><div class="line">                        nextReadyCheckDelayMs = Math.min(timeLeftMs, nextReadyCheckDelayMs);</div><div class="line">                    &#125;</div><div class="line">                &#125;</div><div class="line">            &#125;</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="keyword">return</span> <span class="keyword">new</span> ReadyCheckResult(readyNodes, nextReadyCheckDelayMs, unknownLeaderTopics);</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>可以看到这一行 <code>(!readyNodes.contains(leader) &amp;&amp; !muted.contains(part))</code>，如果 <code>muted</code> 集合包含这个 tp，那么在遍历时将不会处理它对应的 deque，也就是说，如果一个 tp 加入了 <code>muted</code> 集合中，即使它对应的 RecordBatch 可以发送了，也不会触发引起其对应的 leader 被选择出来。</p>
<h3 id="drain"><a href="#drain" class="headerlink" title="drain()"></a>drain()</h3><p><code>drain()</code> 是用来遍历可发送请求的 node，然后再遍历在这个 node 上所有 tp，如果 tp 对应的 deque 有数据，将会被选择出来直到超过一个请求的最大长度（<code>max.request.size</code>）为止，也就说说即使 RecordBatch 没有达到条件，但为了保证每个 request 尽快多地发送数据提高发送效率，这个 RecordBatch 依然会被提前选出来并进行发送。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//note: 返回该 node 对应的可以发送的 RecordBatch 的 batches,并从 queue 中移除（最大的大小为maxSize,超过的话,下次再发送）</span></div><div class="line"><span class="keyword">public</span> Map&lt;Integer, List&lt;RecordBatch&gt;&gt; drain(Cluster cluster,</div><div class="line">                                             Set&lt;Node&gt; nodes,</div><div class="line">                                             <span class="keyword">int</span> maxSize,</div><div class="line">                                             <span class="keyword">long</span> now) &#123;</div><div class="line">    <span class="keyword">if</span> (nodes.isEmpty())</div><div class="line">        <span class="keyword">return</span> Collections.emptyMap();</div><div class="line"></div><div class="line">    Map&lt;Integer, List&lt;RecordBatch&gt;&gt; batches = <span class="keyword">new</span> HashMap&lt;&gt;();</div><div class="line">    <span class="keyword">for</span> (Node node : nodes) &#123;</div><div class="line">        <span class="keyword">int</span> size = <span class="number">0</span>;</div><div class="line">        List&lt;PartitionInfo&gt; parts = cluster.partitionsForNode(node.id());</div><div class="line">        List&lt;RecordBatch&gt; ready = <span class="keyword">new</span> ArrayList&lt;&gt;();</div><div class="line">        <span class="comment">/* to make starvation less likely this loop doesn't start at 0 */</span></div><div class="line">        <span class="keyword">int</span> start = drainIndex = drainIndex % parts.size();</div><div class="line">        <span class="keyword">do</span> &#123;</div><div class="line">            PartitionInfo part = parts.get(drainIndex);</div><div class="line">            TopicPartition tp = <span class="keyword">new</span> TopicPartition(part.topic(), part.partition());</div><div class="line">            <span class="comment">// Only proceed if the partition has no in-flight batches.</span></div><div class="line">            <span class="keyword">if</span> (!muted.contains(tp)) &#123;<span class="comment">//note: 被 mute 的 tp 依然不会被遍历</span></div><div class="line">                Deque&lt;RecordBatch&gt; deque = getDeque(<span class="keyword">new</span> TopicPartition(part.topic(), part.partition()));</div><div class="line">                <span class="keyword">if</span> (deque != <span class="keyword">null</span>) &#123;</div><div class="line">                    <span class="keyword">synchronized</span> (deque) &#123;</div><div class="line">                        RecordBatch first = deque.peekFirst();</div><div class="line">                        <span class="keyword">if</span> (first != <span class="keyword">null</span>) &#123;</div><div class="line">                            <span class="keyword">boolean</span> backoff = first.attempts &gt; <span class="number">0</span> &amp;&amp; first.lastAttemptMs + retryBackoffMs &gt; now;</div><div class="line">                            <span class="comment">// Only drain the batch if it is not during backoff period.</span></div><div class="line">                            <span class="keyword">if</span> (!backoff) &#123;</div><div class="line">                                <span class="keyword">if</span> (size + first.sizeInBytes() &gt; maxSize &amp;&amp; !ready.isEmpty()) &#123;</div><div class="line">                                    <span class="comment">// there is a rare case that a single batch size is larger than the request size due</span></div><div class="line">                                    <span class="comment">// to compression; in this case we will still eventually send this batch in a single</span></div><div class="line">                                    <span class="comment">// request</span></div><div class="line">                                    <span class="keyword">break</span>;</div><div class="line">                                &#125; <span class="keyword">else</span> &#123;</div><div class="line">                                    RecordBatch batch = deque.pollFirst();</div><div class="line">                                    batch.close();</div><div class="line">                                    size += batch.sizeInBytes();</div><div class="line">                                    ready.add(batch);</div><div class="line">                                    batch.drainedMs = now;</div><div class="line">                                &#125;</div><div class="line">                            &#125;</div><div class="line">                        &#125;</div><div class="line">                    &#125;</div><div class="line">                &#125;</div><div class="line">            &#125;</div><div class="line">            <span class="keyword">this</span>.drainIndex = (<span class="keyword">this</span>.drainIndex + <span class="number">1</span>) % parts.size();</div><div class="line">        &#125; <span class="keyword">while</span> (start != drainIndex);</div><div class="line">        batches.put(node.id(), ready);</div><div class="line">    &#125;</div><div class="line">    <span class="keyword">return</span> batches;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>在遍历 node 的所有 tp 时，可以看到是有条件的 —— <code>!muted.contains(tp)</code>，如果这个 tp 被添加到 <code>muted</code> 集合中，那么它将不会被遍历，也就不会作为 request 一部分被发送出去，这也就保证了 tp 如果还有未完成的 RecordBatch，那么其对应 deque 中其他 RecordBatch 即使达到条件也不会被发送，就保证了 tp 在任何时刻只有一个 RecordBatch 在发送。</p>
<h3 id="顺序性如何保证？"><a href="#顺序性如何保证？" class="headerlink" title="顺序性如何保证？"></a>顺序性如何保证？</h3><p>是否保证顺序性，还是在 Sender 线程中实现的，<code>mutePartition()</code> 与 <code>unmutePartition()</code> 也都是在 Sender 中调用的，这里看一下 KafkaProducer 是如何初始化一个 Sender 对象的。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// from KafkaProducer</span></div><div class="line"><span class="keyword">this</span>.sender = <span class="keyword">new</span> Sender(client,</div><div class="line">                         <span class="keyword">this</span>.metadata,</div><div class="line">                         his.accumulator,</div><div class="line">                         config.getInt(ProducerConfig.MAX_IN_FLIGHT_REQUESTS_PER_CONNECTION) == <span class="number">1</span>,</div><div class="line">                         config.getInt(ProducerConfig.MAX_REQUEST_SIZE_CONFIG),</div><div class="line">                         (<span class="keyword">short</span>) parseAcks(config.getString(ProducerConfig.ACKS_CONFIG)),</div><div class="line">                         config.getInt(ProducerConfig.RETRIES_CONFIG),</div><div class="line">                         <span class="keyword">this</span>.metrics,</div><div class="line">                         Time.SYSTEM,</div><div class="line">                         <span class="keyword">this</span>.requestTimeoutMs);<span class="comment">//<span class="doctag">NOTE:</span> Sender 实例,发送请求的后台线程</span></div><div class="line"></div><div class="line"><span class="comment">// from Sender</span></div><div class="line"><span class="function"><span class="keyword">public</span> <span class="title">Sender</span><span class="params">(KafkaClient client,</span></span></div><div class="line">              Metadata metadata,</div><div class="line">              RecordAccumulator accumulator,</div><div class="line">              <span class="keyword">boolean</span> guaranteeMessageOrder,</div><div class="line">              <span class="keyword">int</span> maxRequestSize,</div><div class="line">              <span class="keyword">short</span> acks,</div><div class="line">              <span class="keyword">int</span> retries,</div><div class="line">              Metrics metrics,</div><div class="line">              Time time,</div><div class="line">              <span class="keyword">int</span> requestTimeout) &#123;</div><div class="line">        <span class="keyword">this</span>.client = client;</div><div class="line">        <span class="keyword">this</span>.accumulator = accumulator;</div><div class="line">        <span class="keyword">this</span>.metadata = metadata;</div><div class="line">        <span class="keyword">this</span>.guaranteeMessageOrder = guaranteeMessageOrder;</div><div class="line">        <span class="keyword">this</span>.maxRequestSize = maxRequestSize;</div><div class="line">        <span class="keyword">this</span>.running = <span class="keyword">true</span>; <span class="comment">//note: 默认为 true</span></div><div class="line">        <span class="keyword">this</span>.acks = acks;</div><div class="line">        <span class="keyword">this</span>.retries = retries;</div><div class="line">        <span class="keyword">this</span>.time = time;</div><div class="line">        <span class="keyword">this</span>.sensors = <span class="keyword">new</span> SenderMetrics(metrics);</div><div class="line">        <span class="keyword">this</span>.requestTimeout = requestTimeout;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>对于上述过程可以这样进行解读</p>
<p><code>this.guaranteeMessageOrder = (config.getInt(ProducerConfig.MAX_IN_FLIGHT_REQUESTS_PER_CONNECTION) == 1)</code></p>
<p>如果 KafkaProducer 的 <code>max.in.flight.requests.per.connection</code> 设置为1，那么就可以保证其顺序性，否则的话，就不保证顺序性，从下面这段代码也可以看出。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//from Sender</span></div><div class="line"><span class="comment">//note: max.in.flight.requests.per.connection 设置为1时会保证</span></div><div class="line"><span class="keyword">if</span> (guaranteeMessageOrder) &#123;</div><div class="line">    <span class="comment">// Mute all the partitions draine</span></div><div class="line">    <span class="keyword">for</span> (List&lt;RecordBatch&gt; batchList : batches.values()) &#123;</div><div class="line">         <span class="keyword">for</span> (RecordBatch batch : batchList)</div><div class="line">             <span class="keyword">this</span>.accumulator.mutePartition(batch.topicPartition);</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>也就是说，如果要保证单 Partition 的顺序性，需要在 Producer 中配置 <code>max.in.flight.requests.per.connection=1</code>，而其实现机制则是在 RecordAccumulator 中实现的。</p>
<h2 id="Producer-Configs"><a href="#Producer-Configs" class="headerlink" title="Producer Configs"></a>Producer Configs</h2><p>这里是关于 Kafka Producer 一些配置的说明，内容来自官方文档<a href="http://kafka.apache.org/0102/documentation.html#producerconfigs" target="_blank" rel="external">Producer Configs</a>以及自己的一些个人理解，这里以官方文档保持一致，按其重要性分为三个级别进行讲述（涉及到权限方面的参数，这里先不介绍）。</p>
<h3 id="high-importance"><a href="#high-importance" class="headerlink" title="high importance"></a>high importance</h3><table>
<thead>
<tr>
<th>参数名</th>
<th>说明</th>
<th>默认值</th>
</tr>
</thead>
<tbody>
<tr>
<td>bootstrap.servers</td>
<td>Kafka Broker 的一个列表，不用包含所有的 Broker，它用于初始化连接时，通过这几个 broker 来获取集群的信息，比如：<code>127.0.0.1：9092,127.0.0.2：9092,127.0.0.3：9092</code></td>
<td>-</td>
</tr>
<tr>
<td>key.serializer</td>
<td>对 key 进行序列化的 class，一般使用<code>StringSerializer</code></td>
<td>-</td>
</tr>
<tr>
<td>value.serializer</td>
<td>对 value 进行序列化的 class，一般使用 <code>StringDeserializer</code></td>
<td>-</td>
</tr>
<tr>
<td>acks</td>
<td>用于设置在什么情况一条才被认为已经发送成功了。acks=0：msg 只要被 producer 发送出去就认为已经发送完成了；acks=1：如果 leader 接收到消息并发送 ack （不会等会该 msg 是否同步到其他副本）就认为 msg 发送成功了； acks=all或者-1：leader 接收到 msg 并从所有 isr 接收到 ack 后再向 producer 发送 ack，这样才认为 msg 发送成功了，这是最高级别的可靠性保证。</td>
<td>1</td>
</tr>
<tr>
<td>buffer.memory</td>
<td>producer 可以使用的最大内存，如果超过这个值，producer 将会 block <code>max.block.ms</code> 之后抛出异常。</td>
<td>33554432（32MB）</td>
</tr>
<tr>
<td>compression.type</td>
<td>Producer 数据的压缩格式，可以选择 none、gzip、snappy、lz4</td>
<td>none</td>
</tr>
<tr>
<td>retries</td>
<td>msg 发送失败后重试的次数，允许重试，如果 <code>max.in.flight.requests.per.connection</code> 设置不为1，可能会导致乱序</td>
<td>0</td>
</tr>
</tbody>
</table>
<h3 id="medium-importance"><a href="#medium-importance" class="headerlink" title="medium importance"></a>medium importance</h3><p>下面的这些参数虽然被描述为 medium，但实际上对 Producer 的吞吐量等影响也同样很大，在实践中跟 high 参数的重要性基本一样。</p>
<table>
<thead>
<tr>
<th>参数名</th>
<th>说明</th>
<th>默认值</th>
</tr>
</thead>
<tbody>
<tr>
<td>batch.size</td>
<td>producer 向 partition 发送数据时，是以 batch 形式的发送数据，当 batch 的大小超过 <code>batch.size</code> 或者时间达到 <code>linger.ms</code> 就会发送 batch，根据经验，设置为1MB 吞吐会更高，太小的话吞吐小，太大的话导致内存浪费进而影响吞吐量</td>
<td>16384（16KB）</td>
</tr>
<tr>
<td>linger.ms</td>
<td>在一个 batch 达不到 <code>batch.size</code> 时，这个 batch 最多将会等待 <code>linger.ms</code> 时间，超过这个时间这个 batch 就会被发送，但也会带来相应的延迟，可以根据具体的场景进行设置</td>
<td>0</td>
</tr>
<tr>
<td>client.id</td>
<td>client 的 id，主要用于追踪 request 的来源</td>
<td>null</td>
</tr>
<tr>
<td>connections.max.idle.ms</td>
<td>如果 connection 连续空闲时间超过了这个值，将会被关闭，主要使用 Selector 的 <code>maybeCloseOldestConnection</code> 方法</td>
<td>540000（9min）</td>
</tr>
<tr>
<td>max.block.ms</td>
<td>控制 <code>KafkaProducer.send()</code> 和 <code>KafkaProducer.partitionsFor()</code> block 的最大时间，block 的原因是 buffer 满了或者 metadata 不可用导致。</td>
<td>60000</td>
</tr>
<tr>
<td>max.request.size</td>
<td>一个请求的最大长度</td>
<td>1048576（1MB）</td>
</tr>
<tr>
<td>partitioner.class</td>
<td>获取 topic 分区的 class</td>
<td>org.apache.kafka.clients.producer.internals.DefaultPartitioner</td>
</tr>
<tr>
<td>receive.buffer.bytes</td>
<td>在读取数据时 TCP receive buffer （SO_RCVBUF）的大小</td>
<td>32768（32KB）</td>
</tr>
<tr>
<td>request.timeout.ms</td>
<td>如果 producer 超过这么长时间没有收到 response，将会再次发送请求</td>
<td>30000</td>
</tr>
<tr>
<td>timeout.ms</td>
<td>用于配置 leader 等待 isr 返回 ack 的最大时间，如果超过了这个时间，将会返回给 producer 一个错误。</td>
<td>30000</td>
</tr>
</tbody>
</table>
<h3 id="low-importance"><a href="#low-importance" class="headerlink" title="low importance"></a>low importance</h3><table>
<thead>
<tr>
<th>参数名</th>
<th>说明</th>
<th>默认值</th>
</tr>
</thead>
<tbody>
<tr>
<td>block.on.buffer.full</td>
<td>当 Producer 使用 buffer 达到最大设置时，如果设置为 false，将会 block <code>max.block.ms</code> 后然后抛出 <code>TimeoutException</code> 异常，如果设置为 true，将会把 <code>max.block.ms</code> 设置为 <code>Long.MAX_VALUE</code>。</td>
<td>false</td>
</tr>
<tr>
<td>interceptor.classes</td>
<td>使用拦截器，实现这个 <code>ProducerInterceptor</code> 接口，可以对 topic 进行简单的处理。</td>
<td>null</td>
</tr>
<tr>
<td>max.in.flight.requests.per.connection</td>
<td>对一个 connection，同时发送最大请求数，不为1时，不能保证顺序性。</td>
<td>5</td>
</tr>
<tr>
<td>metadata.fetch.timeout.ms</td>
<td>获取 metadata 时的超时时间</td>
<td>60000</td>
</tr>
<tr>
<td>metadata.max.age.ms</td>
<td>强制 metadata 定时刷新的间隔</td>
<td>300000（5min）</td>
</tr>
<tr>
<td>metric.reporters</td>
<td>A list of classes to use as metrics reporters. Implementing the MetricReporter interface，JmxReporter 是默认被添加的。</td>
<td>“”</td>
</tr>
<tr>
<td>metrics.num.samples</td>
<td>统计 metrics 时采样的次数</td>
<td>2</td>
</tr>
<tr>
<td>metrics.sample.window.ms</td>
<td>metrics 采样计算的时间窗口</td>
<td>30000</td>
</tr>
<tr>
<td>reconnect.backoff.ms</td>
<td>重新建立建立连接的间隔</td>
<td>50</td>
</tr>
<tr>
<td>retry.backoff.ms</td>
<td>发送重试的间隔</td>
<td>100</td>
</tr>
</tbody>
</table>
<p>对于不同的场景，合理配置相应的 Kafka Producer 参数。</p>
<p>至此，Kafka Producer 部分的源码分析已经结束，从下周开始将开始对 Kafka Consumer 部分进行分析。</p>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[Kafka 最佳实践【译】]]></title>
      <url>http://matt33.com/2017/09/04/kafka-best-pratice/</url>
      <content type="html"><![CDATA[<p>这里翻译一篇关于 Kafka 实践的文章，内容来自 DataWorks Summit/Hadoop Summit（<a href="https://dataworkssummit.com/munich-2017/sessions/apache-kafka-best-practices/" target="_blank" rel="external">Hadoop Summit</a>）上一篇分享，PPT 见<a href="https://www.slideshare.net/HadoopSummit/apache-kafka-best-practices" target="_blank" rel="external">Apache Kafka Best Pratices</a>，里面讲述了很多关于 Kafka 配置、监控、优化的内容，绝对是在实践中总结出的精华，有很大的借鉴参考意义，本文主要是根据 PPT 的内容进行翻译及适当补充。</p>
<p>Kafka 的架构这里就不多做介绍了，直接不如正题。</p>
<h2 id="Kafka-基本配置及性能优化"><a href="#Kafka-基本配置及性能优化" class="headerlink" title="Kafka 基本配置及性能优化"></a>Kafka 基本配置及性能优化</h2><p>这里主要是 Kafka 集群基本配置的相关内容。</p>
<h3 id="硬件要求"><a href="#硬件要求" class="headerlink" title="硬件要求"></a>硬件要求</h3><p>Kafka 集群基本硬件的保证</p>
<table>
<thead>
<tr>
<th></th>
<th>集群规模</th>
<th>内存</th>
<th>CPU</th>
<th>存储</th>
</tr>
</thead>
<tbody>
<tr>
<td>Kafka Brokers</td>
<td>3+</td>
<td>24GB+（小规模）；64GB+（大规模）</td>
<td>多核（12CPU+），并允许超线程</td>
<td>6+ 1TB 的专属磁盘（RAID 或 JBOD）</td>
</tr>
<tr>
<td>Zookeeper</td>
<td>3（小规模）；5（大规模）</td>
<td>8GB+（小规模）；24GB+（大规模）</td>
<td>2核+</td>
<td>SSD 用于中间的日志传输</td>
</tr>
</tbody>
</table>
<h3 id="OS-调优"><a href="#OS-调优" class="headerlink" title="OS 调优"></a>OS 调优</h3><ul>
<li>OS page cache：应当可以缓存所有活跃的 Segment（Kafka 中最基本的数据存储单位）；</li>
<li>fd 限制：100k+；</li>
<li>禁用 swapping：简单来说，swap 作用是当内存的使用达到一个临界值时就会将内存中的数据移动到 swap 交换空间，但是此时，内存可能还有很多空余资源，swap 走的是磁盘 IO，对于内存读写很在意的系统，最好禁止使用 swap 分区（参考<a href="https://www.quora.com/What-is-swapping-in-an-OS" target="_blank" rel="external">What is swapping in an OS?</a>）；</li>
<li>TCP 调优；</li>
<li>JVM 配置<ol>
<li>JDK 8 并且使用 G1 垃圾收集器；</li>
<li>至少要分配 6-8 GB 的堆内存。</li>
</ol>
</li>
</ul>
<h3 id="Kafka-磁盘存储"><a href="#Kafka-磁盘存储" class="headerlink" title="Kafka 磁盘存储"></a>Kafka 磁盘存储</h3><ul>
<li>使用多块磁盘，并配置为 Kafka 专用的磁盘；</li>
<li>JBOD vs RAID10；</li>
<li>JBOD（Just a Bunch of Disks，简单来说它表示一个没有控制软件提供协调控制的磁盘集合，它将多个物理磁盘串联起来，提供一个巨大的逻辑磁盘，数据是按序存储，它的性能与单块磁盘类似）</li>
<li>JBOD 的一些缺陷：<ul>
<li>任何磁盘的损坏都会导致异常关闭，并且需要较长的时间恢复；</li>
<li>数据不保证一致性；</li>
<li>多级目录；</li>
</ul>
</li>
<li>社区也正在解决这么问题，可以关注 KIP 112、113：<ul>
<li>必要的工具用于管理 JBOD；</li>
<li>自动化的分区管理；</li>
<li>磁盘损坏时，Broker 可以将 replicas 迁移到好的磁盘上；</li>
<li>在同一个 Broker 的磁盘间 reassign replicas；</li>
</ul>
</li>
<li>RAID 10 的特点：<ul>
<li>可以允许单磁盘的损坏；</li>
<li>性能和保护；</li>
<li>不同磁盘间的负载均衡；</li>
<li>高命中来减少 space；</li>
<li>单一的 mount point；</li>
</ul>
</li>
<li>文件系统：<ul>
<li>使用 EXT 或 XFS；</li>
<li>SSD；</li>
</ul>
</li>
</ul>
<h3 id="基本的监控"><a href="#基本的监控" class="headerlink" title="基本的监控"></a>基本的监控</h3><p>Kafka 集群需要监控的一些指标，这些指标反应了集群的健康度。</p>
<ul>
<li>CPU 负载；</li>
<li>Network Metrics；</li>
<li>File Handle 使用；</li>
<li>磁盘空间；</li>
<li>磁盘 IO 性能；</li>
<li>GC 信息；</li>
<li>ZooKeeper 监控。</li>
</ul>
<h2 id="Kafka-replica-相关配置及监控"><a href="#Kafka-replica-相关配置及监控" class="headerlink" title="Kafka replica 相关配置及监控"></a>Kafka replica 相关配置及监控</h2><h3 id="Kafka-Replication"><a href="#Kafka-Replication" class="headerlink" title="Kafka Replication"></a>Kafka Replication</h3><ul>
<li>Partition 有两种副本：Leader，Follower；</li>
<li>Leader 负责维护 in-sync-replicas(ISR)<ul>
<li><code>replica.lag.time.max.ms</code>：默认为10000，如果 follower 落后于 leader 的消息数超过这个数值时，leader 就将 follower 从 isr 列表中移除；</li>
<li><code>num.replica.fetchers</code>，默认为1，用于从 leader 同步数据的 fetcher 线程数；</li>
<li><code>min.insync.replica</code>：Producer 端使用来用于保证 Durability（持久性）；</li>
</ul>
</li>
</ul>
<h3 id="Under-Replicated-Partitions"><a href="#Under-Replicated-Partitions" class="headerlink" title="Under Replicated Partitions"></a>Under Replicated Partitions</h3><p>当发现 replica 的配置与集群的不同时，一般情况都是集群上的 replica 少于配置数时，可以从以下几个角度来排查问题：</p>
<ul>
<li>JMX 监控项：kafka.server:type=ReplicaManager,name=UnderReplicatedPartitions；</li>
<li>可能的原因：<ul>
<li>Broker 挂了？</li>
<li>Controller 的问题？</li>
<li>ZooKeeper 的问题？</li>
<li>Network 的问题？</li>
</ul>
</li>
<li>解决办法：<ul>
<li>调整 ISR 的设置；</li>
<li>Broker 扩容。</li>
</ul>
</li>
</ul>
<h3 id="Controller"><a href="#Controller" class="headerlink" title="Controller"></a>Controller</h3><ul>
<li>负责管理 partition 生命周期；</li>
<li>避免 Controller’s ZK 会话超时：<ul>
<li>ISR 抖动；</li>
<li>ZK Server 性能问题；</li>
<li>Broker 长时间的 GC；</li>
<li>网络 IO 问题；</li>
</ul>
</li>
<li>监控：<ul>
<li>kafka.controller:type=KafkaController,name=ActiveControllerCount，应该为1；</li>
<li>LeaderElectionRate。</li>
</ul>
</li>
</ul>
<h3 id="Unclean-leader-选举"><a href="#Unclean-leader-选举" class="headerlink" title="Unclean leader 选举"></a>Unclean leader 选举</h3><p>允许不在 isr 中 replica 被选举为 leader。</p>
<ul>
<li>这是 Availability 和 Correctness 之间选择，Kafka 默认选择了可用性；</li>
<li><code>unclean.leader.election.enable</code>：默认为 true，即允许不在 isr 中 replica 选为 leader，这个配置可以全局配置，也可以在 topic 级别配置；</li>
<li>监控：kafka.controller:type=ControllerStats,name=UncleanLeaderElectionsPerSec。</li>
</ul>
<h2 id="Broker-配置"><a href="#Broker-配置" class="headerlink" title="Broker 配置"></a>Broker 配置</h2><p>Broker 级别有几个比较重要的配置，一般需要根据实际情况进行相应配置的：</p>
<ul>
<li><code>log.retention.{ms, minutes, hours}</code> , <code>log.retention.bytes</code>：数据保存时间；</li>
<li><code>message.max.bytes</code>, <code>replica.fetch.max.bytes</code>；</li>
<li><code>delete.topic.enable</code>：默认为 false，是否允许通过 admin tool 来删除 topic；</li>
<li><code>unclean.leader.election.enable</code> = false，参见上面；</li>
<li><code>min.insync.replicas</code> = 2：当 Producer 的 acks 设置为 all 或 -1 时，<code>min.insync.replicas</code> 代表了必须进行确认的最小 replica 数，如果不够的话 Producer 将会报 <code>NotEnoughReplicas</code> 或 <code>NotEnoughReplicasAfterAppend</code> 异常；</li>
<li><code>replica.lag.time.max.ms</code>（超过这个时间没有发送请求的话，follower 将从 isr 中移除）, num.replica.fetchers；</li>
<li><code>replica.fetch.response.max.bytes</code>；</li>
<li><code>zookeeper.session.timeout.ms</code> = 30s；</li>
<li><code>num.io.threads</code>：默认为8，KafkaRequestHandlerPool 的大小。</li>
</ul>
<h2 id="Kafka-相关资源的评估"><a href="#Kafka-相关资源的评估" class="headerlink" title="Kafka 相关资源的评估"></a>Kafka 相关资源的评估</h2><h3 id="集群评估"><a href="#集群评估" class="headerlink" title="集群评估"></a>集群评估</h3><ul>
<li>Broker 评估<ul>
<li>每个 Broker 的 Partition 数不应该超过2k；</li>
<li>控制 partition 大小（不要超过25GB）；</li>
</ul>
</li>
<li>集群评估（Broker 的数量根据以下条件配置）<ul>
<li>数据保留时间；</li>
<li>集群的流量大小；</li>
</ul>
</li>
<li>集群扩容：<ul>
<li>磁盘使用率应该在 60% 以下；</li>
<li>网络使用率应该在 75% 以下；</li>
</ul>
</li>
<li>集群监控<ul>
<li>保持负载均衡；</li>
<li>确保 topic 的 partition 均匀分布在所有 Broker 上；</li>
<li>确保集群的阶段没有耗尽磁盘或带宽。</li>
</ul>
</li>
</ul>
<h3 id="Broker-监控"><a href="#Broker-监控" class="headerlink" title="Broker 监控"></a>Broker 监控</h3><ul>
<li>Partition 数：kafka.server:type=ReplicaManager,name=PartitionCount；</li>
<li>Leader 副本数：kafka.server:type=ReplicaManager,name=LeaderCount；</li>
<li>ISR 扩容/缩容率：kafka.server:type=ReplicaManager,name=IsrExpandsPerSec；</li>
<li>读写速率：Message in rate/Byte in rate/Byte out rate；</li>
<li>网络请求的平均空闲率：NetworkProcessorAvgIdlePercent；</li>
<li>请求处理平均空闲率：RequestHandlerAvgIdlePercent。</li>
</ul>
<h3 id="Topic-评估"><a href="#Topic-评估" class="headerlink" title="Topic 评估"></a>Topic 评估</h3><ul>
<li>partition 数<ul>
<li>Partition 数应该至少与最大 consumer group 中 consumer 线程数一致；</li>
<li>对于使用频繁的 topic，应该设置更多的 partition；</li>
<li>控制 partition 的大小（25GB 左右）；</li>
<li>考虑应用未来的增长（可以使用一种机制进行自动扩容）；</li>
</ul>
</li>
<li>使用带 key 的 topic；</li>
<li>partition 扩容：当 partition 的数据量超过一个阈值时应该自动扩容（实际上还应该考虑网络流量）。</li>
</ul>
<h3 id="合理地设置-partition"><a href="#合理地设置-partition" class="headerlink" title="合理地设置 partition"></a>合理地设置 partition</h3><ul>
<li>根据吞吐量的要求设置 partition 数：<ul>
<li>假设 Producer 单 partition 的吞吐量为 P；</li>
<li>consumer 消费一个 partition 的吞吐量为 C；</li>
<li>而要求的吞吐量为 T；</li>
<li>那么 partition 数至少应该大于 T/P、T/c 的最大值；</li>
</ul>
</li>
<li>更多的 partition，意味着：<ul>
<li>更多的 fd；</li>
<li>可能增加 Unavailability（可能会增加不可用的时间）；</li>
<li>可能增加端到端的延迟；</li>
<li>client 端将会使用更多的内存。</li>
</ul>
</li>
</ul>
<p>关于 Partition 的设置可以参考这篇文章<a href="https://www.confluent.io/blog/how-to-choose-the-number-of-topicspartitions-in-a-kafka-cluster/" target="_blank" rel="external">How to choose the number of topics/partitions in a Kafka cluster?</a>，这里简单讲述一下，Partition 的增加将会带来以下几个优点和缺点：</p>
<ol>
<li>增加吞吐量：对于 consumer 来说，一个 partition 只能被一个 consumer 线程所消费，适当增加 partition 数，可以增加 consumer 的并发，进而增加系统的吞吐量；</li>
<li>需要更多的 fd：对于每一个 segment，在 broker 都会有一个对应的 index 和实际数据文件，而对于 Kafka Broker，它将会对于每个 segment 每个 index 和数据文件都会打开相应的 file handle（可以理解为 fd），因此，partition 越多，将会带来更多的 fd；</li>
<li>可能会增加数据不可用性（主要是指增加不可用时间）：主要是指 broker 宕机的情况，越多的 partition 将会意味着越多的 partition 需要 leader 选举（leader 在宕机这台 broker 的 partition 需要重新选举），特别是如果刚好 controller 宕机，重新选举的 controller 将会首先读取所有 partition 的 metadata，然后才进行相应的 leader 选举，这将会带来更大不可用时间；</li>
<li>可能增加 End-to-end 延迟：一条消息只有其被同步到 isr 的所有 broker 上后，才能被消费，partition 越多，不同节点之间同步就越多，这可能会带来毫秒级甚至数十毫秒级的延迟；</li>
<li>Client 将会需要更多的内存：Producer 和 Consumer 都会按照 partition 去缓存数据，每个 partition 都会带来数十 KB 的消耗，partition 越多, Client 将会占用更多的内存。</li>
</ol>
<h2 id="Producer-的相关配置、性能调优及监控"><a href="#Producer-的相关配置、性能调优及监控" class="headerlink" title="Producer 的相关配置、性能调优及监控"></a>Producer 的相关配置、性能调优及监控</h2><h3 id="Quotas"><a href="#Quotas" class="headerlink" title="Quotas"></a>Quotas</h3><ul>
<li>避免被恶意 Client 攻击，保证 SLA；</li>
<li>设置 produce 和 fetch 请求的字节速率阈值；</li>
<li>可以应用在 user、client-id、或者 user 和 client-id groups；</li>
<li>Broker 端的 metrics 监控：throttle-rate、byte-rate；</li>
<li><code>replica.fetch.response.max.bytes</code>：用于限制 replica 拉取请求的内存使用；</li>
<li>进行数据迁移时限制贷款的使用，<code>kafka-reassign-partitions.sh -- -throttle option</code>。</li>
</ul>
<h3 id="Kafka-Producer"><a href="#Kafka-Producer" class="headerlink" title="Kafka Producer"></a>Kafka Producer</h3><ul>
<li>使用 Java 版的 Client；</li>
<li>使用 <code>kafka-producer-perf-test.sh</code> 测试你的环境；</li>
<li>设置内存、CPU、batch 压缩；<ul>
<li>batch.size：该值设置越大，吞吐越大，但延迟也会越大；</li>
<li>linger.ms：表示 batch 的超时时间，该值越大，吞吐越大、但延迟也会越大；</li>
<li><code>max.in.flight.requests.per.connection</code>：默认为5，表示 client 在 blocking 之前向单个连接（broker）发送的未确认请求的最大数，超过1时，将会影响数据的顺序性；</li>
<li><code>compression.type</code>：压缩设置，会提高吞吐量；</li>
<li><code>acks</code>：数据 durability 的设置；</li>
</ul>
</li>
<li>避免大消息<ul>
<li>会使用更多的内存；</li>
<li>降低 Broker 的处理速度；</li>
</ul>
</li>
</ul>
<h3 id="性能调优"><a href="#性能调优" class="headerlink" title="性能调优"></a>性能调优</h3><ul>
<li>如果吞吐量小于网络带宽<ul>
<li>增加线程；</li>
<li>提高 batch.size；</li>
<li>增加更多 producer 实例；</li>
<li>增加 partition 数；</li>
</ul>
</li>
<li>设置 acks=-1 时，如果延迟增大：可以增大 <code>num.replica.fetchers</code>（follower 同步数据的线程数）来调解；</li>
<li>跨数据中心的传输：增加 socket 缓冲区设置以及 OS tcp 缓冲区设置。</li>
</ul>
<h3 id="Prodcuer-监控"><a href="#Prodcuer-监控" class="headerlink" title="Prodcuer 监控"></a>Prodcuer 监控</h3><ul>
<li>batch-size-avg</li>
<li>compression-rate-avg</li>
<li>waiting-threads</li>
<li>buffer-available-bytes</li>
<li>record-queue-time-max</li>
<li>record-send-rate</li>
<li>records-per-request-avg</li>
</ul>
<h2 id="Kafka-Consumer-配置、性能调优及监控"><a href="#Kafka-Consumer-配置、性能调优及监控" class="headerlink" title="Kafka Consumer 配置、性能调优及监控"></a>Kafka Consumer 配置、性能调优及监控</h2><h3 id="Kafka-Consumer"><a href="#Kafka-Consumer" class="headerlink" title="Kafka Consumer"></a>Kafka Consumer</h3><ul>
<li>使用 <code>kafka-consumer-perf-test.sh</code> 测试环境；</li>
<li>吞吐量问题：<ul>
<li>partition 数太少；</li>
<li>OS page cache：分配足够的内存来缓存数据；</li>
<li>应用的处理逻辑；</li>
</ul>
</li>
<li>offset topic（<code>__consumer_offsets</code>）<ul>
<li><code>offsets.topic.replication.factor</code>：默认为3；</li>
<li><code>offsets.retention.minutes</code>：默认为1440，即 1day；<br>– MonitorISR，topicsize；</li>
</ul>
</li>
<li>offset commit较慢：异步 commit 或 手动 commit。</li>
</ul>
<h3 id="Consumer-配置"><a href="#Consumer-配置" class="headerlink" title="Consumer 配置"></a>Consumer 配置</h3><ul>
<li><code>fetch.min.bytes</code> 、<code>fetch.max.wait.ms</code>；</li>
<li><code>max.poll.interval.ms</code>：调用 <code>poll()</code> 之后延迟的最大时间，超过这个时间没有调用 <code>poll()</code> 的话，就会认为这个 consumer 挂掉了，将会进行 rebalance；</li>
<li><code>max.poll.records</code>：当调用 <code>poll()</code> 之后返回最大的 record 数，默认为500；</li>
<li><code>session.timeout.ms</code>；</li>
<li>Consumer Rebalance<br>– check timeouts<br>– check processing times/logic<br>– GC Issues</li>
<li>网络配置；</li>
</ul>
<h3 id="Consumer-监控"><a href="#Consumer-监控" class="headerlink" title="Consumer 监控"></a>Consumer 监控</h3><p>consumer 是否跟得上数据的发送速度。</p>
<ul>
<li>Consumer Lag：consumer offset 与 the end of log（partition 可以消费的最大 offset） 的差值；</li>
<li>监控<ul>
<li>metric 监控：records-lag-max；</li>
<li>通过 <code>bin/kafka-consumer-groups.sh</code> 查看；</li>
<li>用于 consumer 监控的 LinkedIn’s Burrow；</li>
</ul>
</li>
<li>减少 Lag<ul>
<li>分析 consumer：是 GC 问题还是 Consumer hang 住了；</li>
<li>增加 Consumer 的线程；</li>
<li>增加分区数和 consumer 线程；</li>
</ul>
</li>
</ul>
<h2 id="如何保证数据不丢"><a href="#如何保证数据不丢" class="headerlink" title="如何保证数据不丢"></a>如何保证数据不丢</h2><p>这个是常用的配置，这里截了 PPT 中的内容</p>
<p><img src="/images/kafka/not-data-less.png" alt="Kafka 数据不丢配置"></p>
<ul>
<li><code>block.on.buffer.full</code>：默认设置为 false，当达到内存设置时，可能通过 block 停止接受新的 record 或者抛出一些错误，默认情况下，Producer 将不会抛出  BufferExhaustException，而是当达到 <code>max.block.ms</code> 这个时间后直接抛出 TimeoutException。设置为 true 的意义就是将 <code>max.block.ms</code> 设置为 Long.MAX_VALUE，未来版本中这个设置将被遗弃，推荐设置 <code>max.block.ms</code>。</li>
</ul>
<hr>
<p>参考：</p>
<ol>
<li><a href="https://www.slideshare.net/HadoopSummit/apache-kafka-best-practices" target="_blank" rel="external">Apache Kafka Best Pratices</a>；</li>
<li>胡夕-<a href="http://www.cnblogs.com/huxi2b/p/6720292.html" target="_blank" rel="external">【译】Kafka最佳实践 / Kafka Best Practices</a>；</li>
<li><a href="https://www.confluent.io/blog/how-to-choose-the-number-of-topicspartitions-in-a-kafka-cluster/" target="_blank" rel="external">How to choose the number of topics/partitions in a Kafka cluster?</a>；</li>
<li><a href="https://www.zhihu.com/question/20131784" target="_blank" rel="external">raid有哪几种有什么区别？希望讲通俗点</a>；</li>
<li><a href="https://stackoverflow.com/questions/33536061/file-descriptors-and-file-handles-and-c#" target="_blank" rel="external">File Descriptors and File Handles (and C)</a>.</li>
</ol>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[Kafka 源码解析之 Producer NIO 网络模型（四）]]></title>
      <url>http://matt33.com/2017/08/22/producer-nio/</url>
      <content type="html"><![CDATA[<p>本文是 Kafka 源码解析的第四篇，在写这篇文章之前，专门看了一下 Java NIO 相关的内容，只有理解了 Java NIO 模型才能更好地理解 NIO 在 Kafka 中是如何应用的以及 Producer 如何利用 Java NIO 构建其网络模型（不了解的，可以先看一下上一篇文章：<a href="http://matt33.com/2017/08/12/java-nio/">谈一谈 Java IO 模型</a>），同时，本文也是对 Producer 整个流程的一个总结，主要讲述以下两个问题：</p>
<ol>
<li>Producer 的大概网络模型，与 Java NIO 模型之间关系；</li>
<li>Producer 整体流程及其整体流程详解。</li>
</ol>
<h1 id="Producer-的网络模型"><a href="#Producer-的网络模型" class="headerlink" title="Producer 的网络模型"></a>Producer 的网络模型</h1><p>KafkaProducer 通过 Sender 进行相应的 IO 操作，而 Sender 又调用 NetworkClient 来进行 IO 操作，NetworkClient 底层是对 Java NIO 进行相应的封装，其网络模型如下图所示（该图参考：<a href="http://blog.csdn.net/chunlongyu/article/details/52636762" target="_blank" rel="external">Kafka源码深度解析－序列3 －Producer －Java NIO</a>，在其基础上增加一个 KafkaProducer 成员变量的图形）。</p>
<p><img src="/images/kafka/producer-network.png" alt="Prodcuer 网络模型"></p>
<p>从图中可以看出，Sender 为最上层的接口，即调用层，Sender 调用 NetworkClient，NetworkClient 调用 Selector，而 Selector 底层封装了 Java NIO 的相关接口，从右边的图也可以看出它们之间的关系。</p>
<h1 id="Producer-整体流程"><a href="#Producer-整体流程" class="headerlink" title="Producer 整体流程"></a>Producer 整体流程</h1><p>有了对 Producer 网络模型的大概框架认识之后，下面再深入进去，看一下它们之间的调用关系以及 Producer 是如何调用 Java NIO 的相关接口，Producer 端的整体流程如下图所示。</p>
<p><img src="/images/kafka/producer-nio-flow.png" alt="Producer 整体流程"></p>
<p>这里涉及到的主要方法是：</p>
<ul>
<li><code>KafkaProducer.dosend()</code>；</li>
<li><code>Sender.run()</code>；</li>
<li><code>NetworkClient.poll()</code>（<code>NetworkClient.dosend()</code>）；</li>
<li><code>Selector.poll()</code>；</li>
</ul>
<p>下面会结合上图，对这几个方法做详细的讲解，本文下面的内容都是结合上图进行讲解。</p>
<h2 id="KafkaProducer-dosend"><a href="#KafkaProducer-dosend" class="headerlink" title="KafkaProducer.dosend()"></a>KafkaProducer.dosend()</h2><p><code>dosend()</code> 方法是读懂 Producer 的入口，具体可以参考 <a href="http://matt33.com/2017/06/25/kafka-producer-send-module/#Producer-的-doSend-实现">dosend()</a>，<code>dosend()</code> 主要做了两个事情：</p>
<ol>
<li><code>waitOnMetadata()</code>：请求更新 tp（topic-partition） meta，中间会调用 <code>sender.wakeup()</code>；</li>
<li><code>accumulator.append()</code>：将 msg 写入到其 tp 对应的 deque 中，如果该 tp 对应的 deque 新建了一个 Batch，最后也会调用 <code>sender.wakeup()</code>。</li>
</ol>
<p>这里主要关注的是 <code>sender.wakeup()</code> 方法，它的作用是将 Sender 线程从阻塞中唤醒。</p>
<h3 id="sender-wakeup-方法"><a href="#sender-wakeup-方法" class="headerlink" title="sender.wakeup() 方法"></a><code>sender.wakeup()</code> 方法</h3><p>这里来看一下 <code>sender.wakeup()</code> 具体实现：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// org.apache.kafka.clients.producer.internals.Sender</span></div><div class="line"><span class="comment">/**</span></div><div class="line">* Wake up the selector associated with this send thread</div><div class="line">*/</div><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">wakeup</span><span class="params">()</span> </span>&#123;</div><div class="line">    <span class="keyword">this</span>.client.wakeup();</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="comment">// org.apache.kafka.clients.NetworkClient</span></div><div class="line"><span class="comment">/**</span></div><div class="line">* Interrupt the client if it is blocked waiting on I/O.</div><div class="line">*/</div><div class="line"><span class="meta">@Override</span></div><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">wakeup</span><span class="params">()</span> </span>&#123;</div><div class="line">    <span class="keyword">this</span>.selector.wakeup();</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="comment">// org.apache.kafka.common.network.Selector</span></div><div class="line"><span class="comment">/**</span></div><div class="line">* Interrupt the nioSelector if it is blocked waiting to do I/O.</div><div class="line">*/</div><div class="line"><span class="comment">//note: 如果 selector 是阻塞的话,就唤醒</span></div><div class="line"><span class="meta">@Override</span></div><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">wakeup</span><span class="params">()</span> </span>&#123;</div><div class="line">    <span class="keyword">this</span>.nioSelector.wakeup();</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>这个方法很简单，但也很有意思，其调用过程是下面这个样子：</p>
<ul>
<li>Sender -&gt; NetworkClient -&gt; Selector(Kafka 封装的) -&gt; Selector(Java NIO)</li>
</ul>
<p>跟上面两张图中 KafkaProducer 的总体调用过程大概一致，它的作用就是将 Sender 线程从 <code>select()</code> 方法的阻塞中唤醒，<code>select()</code> 方法的作用是轮询注册在多路复用器上的 Channel，它会一直阻塞在这个方法上，除非满足下面条件中的一个：</p>
<ul>
<li>at least one channel is selected;</li>
<li>this selector’s {@link #wakeup wakeup} method is invoked;</li>
<li>the current thread is interrupted;</li>
<li>the given timeout period expires.</li>
</ul>
<p>否则 <code>select()</code> 将会一直轮询，阻塞在这个地方，直到条件满足。</p>
<p>分析到这里，KafkaProducer 中 <code>dosend()</code> 方法调用 <code>sender.wakeup()</code> 方法作用就很明显的，作用就是：当有新的 RecordBatch 创建后，旧的 RecordBatch 就可以发送了（或者此时有 Metadata 请求需要发送），如果线程阻塞在 <code>select()</code> 方法中，就将其唤醒，Sender 重新开始运行 <code>run()</code> 方法，在这个方法中，旧的 RecordBatch （或相应的 Metadata 请求）将会被选中，进而可以及时将这些请求发送出去。</p>
<h2 id="Sender-run"><a href="#Sender-run" class="headerlink" title="Sender.run()"></a>Sender.run()</h2><p>每次循环都是从 Sender 的 <code>run()</code> 方法开始，具体代码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//note: Sender 线程每次循环具体执行的地方</span></div><div class="line">    <span class="function"><span class="keyword">void</span> <span class="title">run</span><span class="params">(<span class="keyword">long</span> now)</span> </span>&#123;</div><div class="line">        Cluster cluster = metadata.fetch();</div><div class="line">        <span class="comment">//note: Step1 获取那些已经可以发送的 RecordBatch 对应的 nodes</span></div><div class="line">        RecordAccumulator.ReadyCheckResult result = <span class="keyword">this</span>.accumulator.ready(cluster, now);</div><div class="line"></div><div class="line">        <span class="comment">//note: Step2  如果有 topic-partition 的 leader 是未知的,就强制 metadata 更新</span></div><div class="line">        <span class="keyword">if</span> (!result.unknownLeaderTopics.isEmpty()) &#123;</div><div class="line">            <span class="keyword">for</span> (String topic : result.unknownLeaderTopics)</div><div class="line">                <span class="keyword">this</span>.metadata.add(topic);</div><div class="line">            <span class="keyword">this</span>.metadata.requestUpdate();</div><div class="line">        &#125;</div><div class="line"></div><div class="line">        <span class="comment">//note: 如果与node 没有连接（如果可以连接,会初始化该连接）,暂时先移除该 node</span></div><div class="line">        Iterator&lt;Node&gt; iter = result.readyNodes.iterator();</div><div class="line">        <span class="keyword">long</span> notReadyTimeout = Long.MAX_VALUE;</div><div class="line">        <span class="keyword">while</span> (iter.hasNext()) &#123;</div><div class="line">            Node node = iter.next();</div><div class="line">            <span class="keyword">if</span> (!<span class="keyword">this</span>.client.ready(node, now)) &#123;<span class="comment">//note: 没有建立连接的 broker,这里会与其建立连接</span></div><div class="line">                iter.remove();</div><div class="line">                notReadyTimeout = Math.min(notReadyTimeout, <span class="keyword">this</span>.client.connectionDelay(node, now));</div><div class="line">            &#125;</div><div class="line">        &#125;</div><div class="line"></div><div class="line">        <span class="comment">//note: Step3  返回该 node 对应的所有可以发送的 RecordBatch 组成的 batches（key 是 node.id,这些 batches 将会在一个 request 中发送）</span></div><div class="line">        Map&lt;Integer, List&lt;RecordBatch&gt;&gt; batches = <span class="keyword">this</span>.accumulator.drain(cluster,</div><div class="line">                                                                         result.readyNodes,</div><div class="line">                                                                         <span class="keyword">this</span>.maxRequestSize,</div><div class="line">                                                                         now);</div><div class="line">        <span class="comment">//note: 保证一个 tp 只有一个 RecordBatch 在发送,保证有序性</span></div><div class="line">        <span class="comment">//note: max.in.flight.requests.per.connection 设置为1时会保证</span></div><div class="line">        <span class="keyword">if</span> (guaranteeMessageOrder) &#123;</div><div class="line">            <span class="comment">// Mute all the partitions draine</span></div><div class="line">            <span class="keyword">for</span> (List&lt;RecordBatch&gt; batchList : batches.values()) &#123;</div><div class="line">                <span class="keyword">for</span> (RecordBatch batch : batchList)</div><div class="line">                    <span class="keyword">this</span>.accumulator.mutePartition(batch.topicPartition);</div><div class="line">            &#125;</div><div class="line">        &#125;</div><div class="line"></div><div class="line">        <span class="comment">//note: 将由于元数据不可用而导致发送超时的 RecordBatch 移除</span></div><div class="line">        List&lt;RecordBatch&gt; expiredBatches = <span class="keyword">this</span>.accumulator.abortExpiredBatches(<span class="keyword">this</span>.requestTimeout, now);</div><div class="line">        <span class="keyword">for</span> (RecordBatch expiredBatch : expiredBatches)</div><div class="line">            <span class="keyword">this</span>.sensors.recordErrors(expiredBatch.topicPartition.topic(), expiredBatch.recordCount);</div><div class="line"></div><div class="line">        sensors.updateProduceRequestMetrics(batches);</div><div class="line"></div><div class="line">        <span class="keyword">long</span> pollTimeout = Math.min(result.nextReadyCheckDelayMs, notReadyTimeout);</div><div class="line">        <span class="keyword">if</span> (!result.readyNodes.isEmpty()) &#123;</div><div class="line">            log.trace(<span class="string">"Nodes with data ready to send: &#123;&#125;"</span>, result.readyNodes);</div><div class="line">            pollTimeout = <span class="number">0</span>;</div><div class="line">        &#125;</div><div class="line">        <span class="comment">//note: Step4 发送 RecordBatch</span></div><div class="line">        sendProduceRequests(batches, now);</div><div class="line"></div><div class="line">        <span class="comment">//note: 如果有 partition 可以立马发送数据,那么 pollTimeout 为0.</span></div><div class="line">        <span class="comment">//note: Step5 关于 socket 的一些实际的读写操作</span></div><div class="line">        <span class="keyword">this</span>.client.poll(pollTimeout, now);</div><div class="line">    &#125;</div></pre></td></tr></table></figure>
<p><code>Sender.run()</code> 的大概流程总共有以下五步：</p>
<ol>
<li><code>accumulator.ready()</code>：遍历所有的 tp（topic-partition），如果其对应的 RecordBatch 可以发送（大小达到 <code>batch.size</code> 大小或时间达到 <code>linger.ms</code>），就将其对应的 leader 选出来，最后会返回一个可以发送 Produce request 的 <code>Set&lt;Node&gt;</code>（实际返回的是 <code>ReadyCheckResult</code> 实例，不过 <code>Set&lt;Node&gt;</code> 是最主要的成员变量）；</li>
<li>如果发现有 tp 没有 leader，那么这里就调用 <code>requestUpdate()</code> 方法更新 metadata，实际上还是在第一步对 tp 的遍历中，遇到没有 leader 的 tp 就将其加入到一个叫做  <code>unknownLeaderTopics</code> 的 set 中，然后会请求这个 tp 的 meta（meta 的更新策略可以参考之前的一篇博客 <a href="http://matt33.com/2017/07/08/kafka-producer-metadata/#Producer-Metadata-的更新策略">Producer Metadata 的更新策略</a>）；</li>
<li><code>accumulator.drain()</code>：遍历每个 leader （第一步中选出）上的所有 tp，如果该 tp 对应的 RecordBatch 不在 backoff 期间（没有重试过，或者重试了但是间隔已经达到了 retryBackoffMs ），并且加上这个 RecordBatch 其大小不超过 maxSize（一个 request 的最大限制，默认为 1MB），那么就把这个 RecordBatch 添加 list 中，最终返回的类型为 <code>Map&lt;Integer, List&lt;RecordBatch&gt;&gt;</code>，key 为 leader.id，value 为要发送的 RecordBatch 的列表；</li>
<li><code>sendProduceRequests()</code>：发送 Produce 请求，从图中，可以看出，这个方法会调用 <code>NetworkClient.send()</code> 来发送 clientRequest；</li>
<li><code>NetworkClient.poll()</code>：关于 socket 的 IO 操作都是在这个方法进行的，它还是调用 Selector 进行的相应操作，而 Selector 底层则是封装的 Java NIO 的相关接口，这个下面会详细讲述。</li>
</ol>
<p>在第三步中，可以看到，如果要向一个 leader 发送 Produce 请求，那么这 leader 对应 tp，如果其 RecordBatch 没有达到要求（<code>batch.size</code> 或 <code>linger.ms</code> 都没达到）还是可能会发送，这样做的好处是：可以减少 request 的频率，有利于提供发送效率。</p>
<h2 id="NetworkClient-poll"><a href="#NetworkClient-poll" class="headerlink" title="NetworkClient.poll()"></a>NetworkClient.poll()</h2><p>这个方法也是一个非常重要的方法，其作用简单来说有三点：</p>
<ul>
<li>如果需要更新 Metadata，那么就发送 Metadata 请求；</li>
<li>调用 Selector 进行相应的 IO 操作；</li>
<li>处理 Server 端的 response 及一些其他的操作。</li>
</ul>
<p>具体代码如下所示：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">public</span> List&lt;ClientResponse&gt; <span class="title">poll</span><span class="params">(<span class="keyword">long</span> timeout, <span class="keyword">long</span> now)</span> </span>&#123;</div><div class="line">        <span class="comment">//note: Step1 判断是否需要更新 meta,如果需要就更新（请求更新 metadata 的地方）</span></div><div class="line">        <span class="keyword">long</span> metadataTimeout = metadataUpdater.maybeUpdate(now);</div><div class="line">        <span class="comment">//note: Step2 调用 Selector.poll() 进行 socket 相关的 IO 操作</span></div><div class="line">        <span class="keyword">try</span> &#123;</div><div class="line">            <span class="keyword">this</span>.selector.poll(Utils.min(timeout, metadataTimeout, requestTimeoutMs));</div><div class="line">        &#125; <span class="keyword">catch</span> (IOException e) &#123;</div><div class="line">            log.error(<span class="string">"Unexpected error during I/O"</span>, e);</div><div class="line">        &#125;</div><div class="line"></div><div class="line">        <span class="comment">//note: Step3 处理完成后的操作</span></div><div class="line">        <span class="keyword">long</span> updatedNow = <span class="keyword">this</span>.time.milliseconds();</div><div class="line">        List&lt;ClientResponse&gt; responses = <span class="keyword">new</span> ArrayList&lt;&gt;();</div><div class="line">        handleAbortedSends(responses);</div><div class="line">        <span class="comment">//note: 处理已经完成的 send（不需要 response 的 request,如 send）</span></div><div class="line">        handleCompletedSends(responses, updatedNow);<span class="comment">//note: 通过 selector 中获取 Server 端的 response</span></div><div class="line">        <span class="comment">//note: 处理从 server 端接收到 Receive（如 Metadata 请求）</span></div><div class="line">        handleCompletedReceives(responses, updatedNow);<span class="comment">//note: 在返回的 handler 中，会处理 metadata 的更新</span></div><div class="line">        <span class="comment">//note: 处理连接失败那些连接,重新请求 meta</span></div><div class="line">        handleDisconnections(responses, updatedNow);</div><div class="line">        <span class="comment">//note: 处理新建立的那些连接（还不能发送请求,比如:还未认证）</span></div><div class="line">        handleConnections();</div><div class="line">        handleInitiateApiVersionRequests(updatedNow);</div><div class="line">        handleTimedOutRequests(responses, updatedNow);</div><div class="line"></div><div class="line">        <span class="comment">// invoke callbacks</span></div><div class="line">        <span class="keyword">for</span> (ClientResponse response : responses) &#123;</div><div class="line">            <span class="keyword">try</span> &#123;</div><div class="line">                response.onComplete();</div><div class="line">            &#125; <span class="keyword">catch</span> (Exception e) &#123;</div><div class="line">                log.error(<span class="string">"Uncaught error in request completion:"</span>, e);</div><div class="line">            &#125;</div><div class="line">        &#125;</div><div class="line"></div><div class="line">        <span class="keyword">return</span> responses;</div><div class="line">    &#125;</div></pre></td></tr></table></figure>
<p>这个方法大致分为三步，这里详述讲述一下：</p>
<ol>
<li><code>metadataUpdater.maybeUpdate()</code>：如果 Metadata 需要更新，那么就选择连接数最小的 node，发送 Metadata 请求，详细流程可以参考之前那篇博客<a href="http://matt33.com/2017/07/08/kafka-producer-metadata/#Producer-的-Metadata-更新流程">Producer 的 Metadata 更新流程</a>；</li>
<li><code>selector.poll()</code>：进行 socket IO 相关的操作，下面会详细讲述；</li>
<li>process completed actions：在一个 <code>select()</code> 过程之后的相关处理。<ul>
<li><code>handleAbortedSends(responses)</code>：处理那么在发送过程出现 <code>UnsupportedVersionException</code> 异常的 request；</li>
<li><code>handleCompletedSends(responses, updatedNow)</code>：处理那些已经完成的 request，如果是那些不需要 response 的 request 的话，这里直接调用 <code>request.completed()</code>，标志着这个 request 发送处理完成；</li>
<li><code>handleCompletedReceives(responses, updatedNow)</code>：处理那些从 Server 端接收的 Receive，metadata 更新就是在这里处理的（以及 <code>ApiVersionsResponse</code>）；</li>
<li><code>handleDisconnections(responses, updatedNow)</code>：处理连接失败那些连接,重新请求 metadata；</li>
<li><code>handleConnections()</code>：处理新建立的那些连接（还不能发送请求,比如:还未认证）；</li>
<li><code>handleInitiateApiVersionRequests(updatedNow)</code>：对那些新建立的连接，发送 apiVersionRequest（默认情况：第一次建立连接时，需要向 Broker 发送 ApiVersionRequest 请求）；</li>
<li><code>handleTimedOutRequests(responses, updatedNow)</code>：处理 timeout 的连接，关闭该连接，并刷新 Metadata。</li>
</ul>
</li>
</ol>
<h2 id="Selector-poll"><a href="#Selector-poll" class="headerlink" title="Selector.poll()"></a>Selector.poll()</h2><p> Selector 类是 Kafka 对 Java NIO 相关接口的封装，socket IO 相关的操作都是这个类中完成的，这里先看一下 <code>poll()</code> 方法，主要的操作都是这个方法中调用的，其代码实现如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">poll</span><span class="params">(<span class="keyword">long</span> timeout)</span> <span class="keyword">throws</span> IOException </span>&#123;</div><div class="line">        <span class="keyword">if</span> (timeout &lt; <span class="number">0</span>)</div><div class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> IllegalArgumentException(<span class="string">"timeout should be &gt;= 0"</span>);</div><div class="line"></div><div class="line">        <span class="comment">//note: Step1 清除相关记录</span></div><div class="line">        clear();</div><div class="line"></div><div class="line">        <span class="keyword">if</span> (hasStagedReceives() || !immediatelyConnectedKeys.isEmpty())</div><div class="line">            timeout = <span class="number">0</span>;</div><div class="line"></div><div class="line">        <span class="comment">/* check ready keys */</span></div><div class="line">        <span class="comment">//note: Step2 获取就绪事件的数</span></div><div class="line">        <span class="keyword">long</span> startSelect = time.nanoseconds();</div><div class="line">        <span class="keyword">int</span> readyKeys = select(timeout);</div><div class="line">        <span class="keyword">long</span> endSelect = time.nanoseconds();</div><div class="line">        <span class="keyword">this</span>.sensors.selectTime.record(endSelect - startSelect, time.milliseconds());</div><div class="line"></div><div class="line">        <span class="comment">//note: Step3 处理 io 操作</span></div><div class="line">        <span class="keyword">if</span> (readyKeys &gt; <span class="number">0</span> || !immediatelyConnectedKeys.isEmpty()) &#123;</div><div class="line">            pollSelectionKeys(<span class="keyword">this</span>.nioSelector.selectedKeys(), <span class="keyword">false</span>, endSelect);</div><div class="line">            pollSelectionKeys(immediatelyConnectedKeys, <span class="keyword">true</span>, endSelect);</div><div class="line">        &#125;</div><div class="line"></div><div class="line">        <span class="comment">//note: Step4 将处理得到的 stagedReceives 添加到 completedReceives 中</span></div><div class="line">        addToCompletedReceives();</div><div class="line"></div><div class="line">        <span class="keyword">long</span> endIo = time.nanoseconds();</div><div class="line">        <span class="keyword">this</span>.sensors.ioTime.record(endIo - endSelect, time.milliseconds());</div><div class="line"></div><div class="line">        <span class="comment">// we use the time at the end of select to ensure that we don't close any connections that</span></div><div class="line">        <span class="comment">// have just been processed in pollSelectionKeys</span></div><div class="line">        <span class="comment">//note: 每次 poll 之后会调用一次</span></div><div class="line">        <span class="comment">//<span class="doctag">TODO:</span> 连接虽然关闭了,但是 Client 端的缓存依然存在</span></div><div class="line">        maybeCloseOldestConnection(endSelect);</div><div class="line">    &#125;</div></pre></td></tr></table></figure>
<p><code>Selector.poll()</code> 方法会进行四步操作，这里分别来介绍一些。</p>
<h3 id="clear"><a href="#clear" class="headerlink" title="clear()"></a>clear()</h3><p><code>clear()</code> 方法是在每次 <code>poll()</code> 执行的第一步，它作用的就是清理上一次 poll 过程产生的部分缓存。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//note: 每次 poll 调用前都会清除以下缓存</span></div><div class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">clear</span><span class="params">()</span> </span>&#123;</div><div class="line">    <span class="keyword">this</span>.completedSends.clear();</div><div class="line">    <span class="keyword">this</span>.completedReceives.clear();</div><div class="line">    <span class="keyword">this</span>.connected.clear();</div><div class="line">    <span class="keyword">this</span>.disconnected.clear();</div><div class="line">    <span class="comment">// Remove closed channels after all their staged receives have been processed or if a send was requested</span></div><div class="line">    <span class="keyword">for</span> (Iterator&lt;Map.Entry&lt;String, KafkaChannel&gt;&gt; it = closingChannels.entrySet().iterator(); it.hasNext(); ) &#123;</div><div class="line">        KafkaChannel channel = it.next().getValue();</div><div class="line">        Deque&lt;NetworkReceive&gt; deque = <span class="keyword">this</span>.stagedReceives.get(channel);</div><div class="line">        <span class="keyword">boolean</span> sendFailed = failedSends.remove(channel.id());</div><div class="line">        <span class="keyword">if</span> (deque == <span class="keyword">null</span> || deque.isEmpty() || sendFailed) &#123;</div><div class="line">            doClose(channel, <span class="keyword">true</span>);</div><div class="line">            it.remove();</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line">    <span class="keyword">this</span>.disconnected.addAll(<span class="keyword">this</span>.failedSends);</div><div class="line">    <span class="keyword">this</span>.failedSends.clear();</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h3 id="select"><a href="#select" class="headerlink" title="select()"></a>select()</h3><p>Selector 的 <code>select()</code> 方法在实现上底层还是调用 Java NIO 原生的接口，这里的 <code>nioSelector</code> 其实就是 <code>java.nio.channels.Selector</code> 的实例对象，这个方法最坏情况下，会阻塞 ms 的时间，如果在一次轮询，只要有一个 Channel 的事件就绪，它就会立马返回。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">int</span> <span class="title">select</span><span class="params">(<span class="keyword">long</span> ms)</span> <span class="keyword">throws</span> IOException </span>&#123;</div><div class="line">    <span class="keyword">if</span> (ms &lt; <span class="number">0L</span>)</div><div class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> IllegalArgumentException(<span class="string">"timeout should be &gt;= 0"</span>);</div><div class="line"></div><div class="line">    <span class="keyword">if</span> (ms == <span class="number">0L</span>)</div><div class="line">        <span class="keyword">return</span> <span class="keyword">this</span>.nioSelector.selectNow();</div><div class="line">    <span class="keyword">else</span></div><div class="line">        <span class="keyword">return</span> <span class="keyword">this</span>.nioSelector.select(ms);</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h3 id="pollSelectionKeys"><a href="#pollSelectionKeys" class="headerlink" title="pollSelectionKeys()"></a>pollSelectionKeys()</h3><p>这部分是 socket IO 的主要部分，发送 Send 及接收 Receive 都是在这里完成的，在 <code>poll()</code> 方法中，这个方法会调用两次：</p>
<ol>
<li>第一次调用的目的是：处理已经就绪的事件，进行相应的 IO 操作；</li>
<li>第二次调用的目的是：处理新建立的那些连接，添加缓存及传输层（Kafka 又封装了一次，这里后续文章会讲述）的握手与认证。</li>
</ol>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">pollSelectionKeys</span><span class="params">(Iterable&lt;SelectionKey&gt; selectionKeys,</span></span></div><div class="line">                                   <span class="keyword">boolean</span> isImmediatelyConnected,</div><div class="line">                                   <span class="keyword">long</span> currentTimeNanos) &#123;</div><div class="line">        Iterator&lt;SelectionKey&gt; iterator = selectionKeys.iterator();</div><div class="line">        <span class="keyword">while</span> (iterator.hasNext()) &#123;</div><div class="line">            SelectionKey key = iterator.next();</div><div class="line">            iterator.remove();</div><div class="line">            KafkaChannel channel = channel(key);</div><div class="line"></div><div class="line">            <span class="comment">// register all per-connection metrics at once</span></div><div class="line">            sensors.maybeRegisterConnectionMetrics(channel.id());</div><div class="line">            <span class="keyword">if</span> (idleExpiryManager != <span class="keyword">null</span>)</div><div class="line">                idleExpiryManager.update(channel.id(), currentTimeNanos);</div><div class="line"></div><div class="line">            <span class="keyword">try</span> &#123;</div><div class="line"></div><div class="line">                <span class="comment">/* complete any connections that have finished their handshake (either normally or immediately) */</span></div><div class="line">                <span class="comment">//note: 处理一些刚建立 tcp 连接的 channel</span></div><div class="line">                <span class="keyword">if</span> (isImmediatelyConnected || key.isConnectable()) &#123;</div><div class="line">                    <span class="keyword">if</span> (channel.finishConnect()) &#123;<span class="comment">//note: 连接已经建立</span></div><div class="line">                        <span class="keyword">this</span>.connected.add(channel.id());</div><div class="line">                        <span class="keyword">this</span>.sensors.connectionCreated.record();</div><div class="line">                        SocketChannel socketChannel = (SocketChannel) key.channel();</div><div class="line">                        log.debug(<span class="string">"Created socket with SO_RCVBUF = &#123;&#125;, SO_SNDBUF = &#123;&#125;, SO_TIMEOUT = &#123;&#125; to node &#123;&#125;"</span>,</div><div class="line">                                socketChannel.socket().getReceiveBufferSize(),</div><div class="line">                                socketChannel.socket().getSendBufferSize(),</div><div class="line">                                socketChannel.socket().getSoTimeout(),</div><div class="line">                                channel.id());</div><div class="line">                    &#125; <span class="keyword">else</span></div><div class="line">                        <span class="keyword">continue</span>;</div><div class="line">                &#125;</div><div class="line"></div><div class="line">                <span class="comment">/* if channel is not ready finish prepare */</span></div><div class="line">                <span class="comment">//note: 处理 tcp 连接还未完成的连接,进行传输层的握手及认证</span></div><div class="line">                <span class="keyword">if</span> (channel.isConnected() &amp;&amp; !channel.ready())</div><div class="line">                    channel.prepare();</div><div class="line"></div><div class="line">                <span class="comment">/* if channel is ready read from any connections that have readable data */</span></div><div class="line">                <span class="keyword">if</span> (channel.ready() &amp;&amp; key.isReadable() &amp;&amp; !hasStagedReceive(channel)) &#123;</div><div class="line">                    NetworkReceive networkReceive;</div><div class="line">                    <span class="keyword">while</span> ((networkReceive = channel.read()) != <span class="keyword">null</span>)<span class="comment">//note: 知道读取一个完整的 Receive,才添加到集合中</span></div><div class="line">                        addToStagedReceives(channel, networkReceive);<span class="comment">//note: 读取数据</span></div><div class="line">                &#125;</div><div class="line"></div><div class="line">                <span class="comment">/* if channel is ready write to any sockets that have space in their buffer and for which we have data */</span></div><div class="line">                <span class="keyword">if</span> (channel.ready() &amp;&amp; key.isWritable()) &#123;</div><div class="line">                    Send send = channel.write();</div><div class="line">                    <span class="keyword">if</span> (send != <span class="keyword">null</span>) &#123;</div><div class="line">                        <span class="keyword">this</span>.completedSends.add(send);<span class="comment">//note: 将完成的 send 添加到 list 中</span></div><div class="line">                        <span class="keyword">this</span>.sensors.recordBytesSent(channel.id(), send.size());</div><div class="line">                    &#125;</div><div class="line">                &#125;</div><div class="line"></div><div class="line">                <span class="comment">/* cancel any defunct sockets */</span></div><div class="line">                <span class="comment">//note: 关闭断开的连接</span></div><div class="line">                <span class="keyword">if</span> (!key.isValid())</div><div class="line">                    close(channel, <span class="keyword">true</span>);</div><div class="line"></div><div class="line">            &#125; <span class="keyword">catch</span> (Exception e) &#123;</div><div class="line">                String desc = channel.socketDescription();</div><div class="line">                <span class="keyword">if</span> (e <span class="keyword">instanceof</span> IOException)</div><div class="line">                    log.debug(<span class="string">"Connection with &#123;&#125; disconnected"</span>, desc, e);</div><div class="line">                <span class="keyword">else</span></div><div class="line">                    log.warn(<span class="string">"Unexpected error from &#123;&#125;; closing connection"</span>, desc, e);</div><div class="line">                close(channel, <span class="keyword">true</span>);</div><div class="line">            &#125;</div><div class="line">        &#125;</div><div class="line">    &#125;</div></pre></td></tr></table></figure>
<h3 id="addToCompletedReceives"><a href="#addToCompletedReceives" class="headerlink" title="addToCompletedReceives()"></a>addToCompletedReceives()</h3><p>这个方法的目的是处理接收到的 Receive，由于 Selector 这个类在 Client 和 Server 端都会调用，这里分两种情况讲述一下：</p>
<ol>
<li>应用在 Server 端时，后续文章会详细介绍，这里简单说一下，Server 为了保证消息的时序性，在 Selector 中提供了两个方法：<code>mute(String id)</code> 和 <code>unmute(String id)</code>，对该 KafkaChannel 做标记来保证同时只能处理这个 Channel 的一个 request（可以理解为排它锁）。当 Server 端接收到 request 后，先将其放入 <code>stagedReceives</code> 集合中，此时该 Channel 还未 mute，这个 Receive 会被放入 <code>completedReceives</code> 集合中。Server 在对 <code>completedReceives</code> 集合中的 request 进行处理时，会先对该 Channel mute，处理后的 response 发送完成后再对该 Channel unmute，然后才能处理该 Channel 其他的请求；</li>
<li>应用在 Client 端时，Client 并不会调用 Selector 的 <code>mute()</code> 和 <code>unmute()</code> 方法，client 的时序性而是通过 <code>InFlightRequests</code> 和 RecordAccumulator 的 <code>mutePartition</code> 来保证的（下篇文章会讲述），因此对于 Client 端而言，这里接收到的所有 Receive 都会被放入到 <code>completedReceives</code> 的集合中等待后续处理。</li>
</ol>
<p>这个方法只有配合 Server 端的调用才能看明白其作用，它统一 Client 和 Server 调用的 api，使得都可以使用 Selector 这个类。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/**</span></div><div class="line"> * checks if there are any staged receives and adds to completedReceives</div><div class="line"> */</div><div class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">addToCompletedReceives</span><span class="params">()</span> </span>&#123;</div><div class="line">    <span class="keyword">if</span> (!<span class="keyword">this</span>.stagedReceives.isEmpty()) &#123;<span class="comment">//note: 处理 stagedReceives</span></div><div class="line">        Iterator&lt;Map.Entry&lt;KafkaChannel, Deque&lt;NetworkReceive&gt;&gt;&gt; iter = <span class="keyword">this</span>.stagedReceives.entrySet().iterator();</div><div class="line">        <span class="keyword">while</span> (iter.hasNext()) &#123;</div><div class="line">            Map.Entry&lt;KafkaChannel, Deque&lt;NetworkReceive&gt;&gt; entry = iter.next();</div><div class="line">            KafkaChannel channel = entry.getKey();</div><div class="line">            <span class="keyword">if</span> (!channel.isMute()) &#123;</div><div class="line">                Deque&lt;NetworkReceive&gt; deque = entry.getValue();</div><div class="line">                addToCompletedReceives(channel, deque);</div><div class="line">                <span class="keyword">if</span> (deque.isEmpty())</div><div class="line">                    iter.remove();</div><div class="line">            &#125;</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">addToCompletedReceives</span><span class="params">(KafkaChannel channel, Deque&lt;NetworkReceive&gt; stagedDeque)</span> </span>&#123;</div><div class="line">    NetworkReceive networkReceive = stagedDeque.poll();</div><div class="line">    <span class="keyword">this</span>.completedReceives.add(networkReceive); <span class="comment">//note: 添加到 completedReceives 中</span></div><div class="line">    <span class="keyword">this</span>.sensors.recordBytesReceived(channel.id(), networkReceive.payload().limit());</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h2 id="Network-send-方法"><a href="#Network-send-方法" class="headerlink" title="Network.send() 方法"></a>Network.send() 方法</h2><p>至此，文章的主要内容已经讲述得差不多了，第二张图中最上面的那个调用关系已经讲述完，下面讲述一下另外一个小分支，也就是从 <code>Sender.run()</code> 调用 <code>NetworkClient.send()</code> 开始的那部分，其调用过程如下：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">Sender.run()</div><div class="line">Sender.sendProduceRequests()</div><div class="line">NetworkClient.send()</div><div class="line">NetworkClient.dosend()</div><div class="line">Selector.send()</div><div class="line">KafkaChannel.setSend()</div></pre></td></tr></table></figure>
<h3 id="NetworkClient-dosend"><a href="#NetworkClient-dosend" class="headerlink" title="NetworkClient.dosend()"></a>NetworkClient.dosend()</h3><p>Producer 端的请求都是通过 <code>NetworkClient.dosend()</code> 来发送的，其作用就是：</p>
<ul>
<li>检查版本信息，并根据 <code>apiKey()</code> 构建 Request；</li>
<li>创建 <code>NetworkSend</code> 实例；</li>
<li>调用 <code>Selector.send</code> 发送该 Send。</li>
</ul>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//note: 发送请求</span></div><div class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">doSend</span><span class="params">(ClientRequest clientRequest, <span class="keyword">boolean</span> isInternalRequest, <span class="keyword">long</span> now)</span> </span>&#123;</div><div class="line">        String nodeId = clientRequest.destination();</div><div class="line">        <span class="keyword">if</span> (!isInternalRequest) &#123;</div><div class="line">            <span class="comment">// If this request came from outside the NetworkClient, validate</span></div><div class="line">            <span class="comment">// that we can send data.  If the request is internal, we trust</span></div><div class="line">            <span class="comment">// that that internal code has done this validation.  Validation</span></div><div class="line">            <span class="comment">// will be slightly different for some internal requests (for</span></div><div class="line">            <span class="comment">// example, ApiVersionsRequests can be sent prior to being in</span></div><div class="line">            <span class="comment">// READY state.)</span></div><div class="line">            <span class="keyword">if</span> (!canSendRequest(nodeId))</div><div class="line">                <span class="keyword">throw</span> <span class="keyword">new</span> IllegalStateException(<span class="string">"Attempt to send a request to node "</span> + nodeId + <span class="string">" which is not ready."</span>);</div><div class="line">        &#125;</div><div class="line">        AbstractRequest request = <span class="keyword">null</span>;</div><div class="line">        AbstractRequest.Builder&lt;?&gt; builder = clientRequest.requestBuilder();</div><div class="line">        <span class="comment">//note: 构建 AbstractRequest, 检查其版本信息</span></div><div class="line">        <span class="keyword">try</span> &#123;</div><div class="line">            NodeApiVersions versionInfo = nodeApiVersions.get(nodeId);</div><div class="line">            <span class="comment">// Note: if versionInfo is null, we have no server version information. This would be</span></div><div class="line">            <span class="comment">// the case when sending the initial ApiVersionRequest which fetches the version</span></div><div class="line">            <span class="comment">// information itself.  It is also the case when discoverBrokerVersions is set to false.</span></div><div class="line">            <span class="keyword">if</span> (versionInfo == <span class="keyword">null</span>) &#123;</div><div class="line">                <span class="keyword">if</span> (discoverBrokerVersions &amp;&amp; log.isTraceEnabled())</div><div class="line">                    log.trace(<span class="string">"No version information found when sending message of type &#123;&#125; to node &#123;&#125;. "</span> +</div><div class="line">                            <span class="string">"Assuming version &#123;&#125;."</span>, clientRequest.apiKey(), nodeId, builder.version());</div><div class="line">            &#125; <span class="keyword">else</span> &#123;</div><div class="line">                <span class="keyword">short</span> version = versionInfo.usableVersion(clientRequest.apiKey());</div><div class="line">                builder.setVersion(version);</div><div class="line">            &#125;</div><div class="line">            <span class="comment">// The call to build may also throw UnsupportedVersionException, if there are essential</span></div><div class="line">            <span class="comment">// fields that cannot be represented in the chosen version.</span></div><div class="line">            request = builder.build();<span class="comment">//note: 当为 Produce 请求时,转化为 ProduceRequest,Metadata 请求时,转化为 Metadata 请求</span></div><div class="line">        &#125; <span class="keyword">catch</span> (UnsupportedVersionException e) &#123;</div><div class="line">            <span class="comment">// If the version is not supported, skip sending the request over the wire.</span></div><div class="line">            <span class="comment">// Instead, simply add it to the local queue of aborted requests.</span></div><div class="line">            log.debug(<span class="string">"Version mismatch when attempting to send &#123;&#125; to &#123;&#125;"</span>,</div><div class="line">                    clientRequest.toString(), clientRequest.destination(), e);</div><div class="line">            ClientResponse clientResponse = <span class="keyword">new</span> ClientResponse(clientRequest.makeHeader(),</div><div class="line">                    clientRequest.callback(), clientRequest.destination(), now, now,</div><div class="line">                    <span class="keyword">false</span>, e, <span class="keyword">null</span>);</div><div class="line">            abortedSends.add(clientResponse);</div><div class="line">            <span class="keyword">return</span>;</div><div class="line">        &#125;</div><div class="line">        RequestHeader header = clientRequest.makeHeader();</div><div class="line">        <span class="keyword">if</span> (log.isDebugEnabled()) &#123;</div><div class="line">            <span class="keyword">int</span> latestClientVersion = ProtoUtils.latestVersion(clientRequest.apiKey().id);</div><div class="line">            <span class="keyword">if</span> (header.apiVersion() == latestClientVersion) &#123;</div><div class="line">                log.trace(<span class="string">"Sending &#123;&#125; to node &#123;&#125;."</span>, request, nodeId);</div><div class="line">            &#125; <span class="keyword">else</span> &#123;</div><div class="line">                log.debug(<span class="string">"Using older server API v&#123;&#125; to send &#123;&#125; to node &#123;&#125;."</span>,</div><div class="line">                    header.apiVersion(), request, nodeId);</div><div class="line">            &#125;</div><div class="line">        &#125;</div><div class="line">        <span class="comment">//note: Send是一个接口，这里返回的是 NetworkSend，而 NetworkSend 继承 ByteBufferSend</span></div><div class="line">        Send send = request.toSend(nodeId, header);</div><div class="line">        InFlightRequest inFlightRequest = <span class="keyword">new</span> InFlightRequest(</div><div class="line">                header,</div><div class="line">                clientRequest.createdTimeMs(),</div><div class="line">                clientRequest.destination(),</div><div class="line">                clientRequest.callback(),</div><div class="line">                clientRequest.expectResponse(),</div><div class="line">                isInternalRequest,</div><div class="line">                send,</div><div class="line">                now);</div><div class="line">        <span class="keyword">this</span>.inFlightRequests.add(inFlightRequest);</div><div class="line">        <span class="comment">//note: 将 send 和对应 kafkaChannel 绑定起来，并开启该 kafkaChannel 底层 socket 的写事件</span></div><div class="line">        selector.send(inFlightRequest.send);</div><div class="line">    &#125;</div></pre></td></tr></table></figure>
<h3 id="Selector-send"><a href="#Selector-send" class="headerlink" title="Selector.send()"></a>Selector.send()</h3><p>这个方法就比较容易理解了，它的作用就是获取该 Send 对应的 KafkaChannel，调用 <code>setSend()</code> 向 KafkaChannel 注册一个 <code>Write</code> 事件。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//note: 发送请求</span></div><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">send</span><span class="params">(Send send)</span> </span>&#123;</div><div class="line">    String connectionId = send.destination();</div><div class="line">    <span class="keyword">if</span> (closingChannels.containsKey(connectionId))</div><div class="line">        <span class="keyword">this</span>.failedSends.add(connectionId);</div><div class="line">    <span class="keyword">else</span> &#123;</div><div class="line">        KafkaChannel channel = channelOrFail(connectionId, <span class="keyword">false</span>);</div><div class="line">        <span class="keyword">try</span> &#123;</div><div class="line">            channel.setSend(send);</div><div class="line">        &#125; <span class="keyword">catch</span> (CancelledKeyException e) &#123;</div><div class="line">            <span class="keyword">this</span>.failedSends.add(connectionId);</div><div class="line">            close(channel, <span class="keyword">false</span>);</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h3 id="KafkaChannel-setSend"><a href="#KafkaChannel-setSend" class="headerlink" title="KafkaChannel.setSend()"></a>KafkaChannel.setSend()</h3><p><code>setSend()</code> 方法需要配合 <code>write()</code>（该方法是在 <code>Selector.poll()</code> 中调用的） 方法一起来看</p>
<ul>
<li><code>setSend()</code>：将当前 KafkaChannel 的 Send 赋值为要发送的 Send，并注册一个 <code>OP_WRITE</code> 事件；</li>
<li><code>write()</code>：发送当前的 Send，发送完后删除注册的 <code>OP_WRITE</code> 事件。</li>
</ul>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//note: 每次调用时都会注册一个 OP_WRITE 事件</span></div><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setSend</span><span class="params">(Send send)</span> </span>&#123;</div><div class="line">    <span class="keyword">if</span> (<span class="keyword">this</span>.send != <span class="keyword">null</span>)</div><div class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> IllegalStateException(<span class="string">"Attempt to begin a send operation with prior send operation still in progress."</span>);</div><div class="line">    <span class="keyword">this</span>.send = send;</div><div class="line">    <span class="keyword">this</span>.transportLayer.addInterestOps(SelectionKey.OP_WRITE);</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="comment">//note: 调用 send() 发送 Send</span></div><div class="line"><span class="function"><span class="keyword">public</span> Send <span class="title">write</span><span class="params">()</span> <span class="keyword">throws</span> IOException </span>&#123;</div><div class="line">    Send result = <span class="keyword">null</span>;</div><div class="line">    <span class="keyword">if</span> (send != <span class="keyword">null</span> &amp;&amp; send(send)) &#123;</div><div class="line">        result = send;</div><div class="line">        send = <span class="keyword">null</span>;</div><div class="line">    &#125;</div><div class="line">    <span class="keyword">return</span> result;</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="comment">//note: 发送完成后,就删除这个 WRITE 事件</span></div><div class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">boolean</span> <span class="title">send</span><span class="params">(Send send)</span> <span class="keyword">throws</span> IOException </span>&#123;</div><div class="line">    send.writeTo(transportLayer);</div><div class="line">    <span class="keyword">if</span> (send.completed())</div><div class="line">        transportLayer.removeInterestOps(SelectionKey.OP_WRITE);</div><div class="line"></div><div class="line">    <span class="keyword">return</span> send.completed();</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>最后，简单总结一下，可以回过头再看一下第一张图，对于 KafkaProducer 而言，其直接调用是 Sender，而 Sender 底层调用的是 NetworkClient，NetworkClient 则是通过 Selector 实现，Selector 则是对 Java NIO 原生接口的封装。</p>
<hr>
<p>参考文献：</p>
<ul>
<li><a href="http://blog.csdn.net/chunlongyu/article/details/52636762" target="_blank" rel="external">Kafka源码深度解析－序列3 －Producer －Java NIO</a></li>
<li><a href="http://blog.csdn.net/chunlongyu/article/details/52651960" target="_blank" rel="external"> Kafka源码深度解析－序列4 －Producer －network层核心原理</a></li>
</ul>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[谈一谈 Java IO 模型]]></title>
      <url>http://matt33.com/2017/08/12/java-nio/</url>
      <content type="html"><![CDATA[<p>Java IO 模型对于 Java 开发工程师来说，是日常工作中经常接触的内容，特别是随着分布式系统的兴起，IO 也显得越来越重要，Java 的 IO 模型本质上还是利用操作系统提供的接口来实现，不熟悉这一部分内容的话，可以先看一下上篇文章<a href="http://matt33.com/2017/08/06/unix-io/">Unix 网络 IO 模型及 Linux 的 IO 多路复用模型</a>，本文跟上篇的内容是紧密相连的，特别是本文的重点 —— Java NIO 部分，其底层原理就是 UNIX 的 IO 多路复用，IO 多路复用在上篇文章中讲述了很多。</p>
<p>这篇文章大概内容如下：</p>
<ol>
<li>Java IO 模型的简单介绍；</li>
<li>BIO 、NIO、AIO 模型的介绍，会详细介绍 NIO；</li>
<li>几种 IO 模型的对比。</li>
</ol>
<h1 id="Java-IO-模型介绍"><a href="#Java-IO-模型介绍" class="headerlink" title="Java IO 模型介绍"></a>Java IO 模型介绍</h1><p>在 JDK 推出 Java NIO 之前，基于 Java 的所有 Socket 通信都采用了同步阻塞模式（BIO），这种一对一的通信模型虽然简化了开发的难度，但在性能和可靠性方面却存在这巨大的瓶颈，特别是无法处理高并发的场景，使得 Java 在服务器端应用十分有限。</p>
<p>正是由于 Java 传统 BIO 的拙劣表现，使得 Java 不得不去开发新版的 IO 模型，最终，JDK1.4 提供了新的 NIO 类库，Java 可以支持非阻塞 IO；之后，JDK1.7 正式发布，不但对 NIO 进行了升级，还提供了 AIO 功能。本文就是在对 Java 这些 IO 模型学习后，总结的一篇笔记。</p>
<h2 id="网络编程"><a href="#网络编程" class="headerlink" title="网络编程"></a>网络编程</h2><p>网络编程的基本模型是 Client/Server 模型，也就是两个进程之间进行相互通信，其中服务端提供位置信息（绑定的 IP 地址和端口），客户端通过连接操作向服务端监听的地址发起连接请求，通过三次握手建立连接，如果连接成功，双方就可以通过网络套接字（socket）进行通信（可以参考<a href="http://localhost:8080/2016/08/30/http-protocol/" target="_blank" rel="external">TCP的三次握手和四次挥手</a>），下面先看一下两种对 IO 模型常见的分类方式。</p>
<h2 id="同步与异步"><a href="#同步与异步" class="headerlink" title="同步与异步"></a>同步与异步</h2><p>描述的是用户线程与内核的交互方式，与消息的通知机制有关：</p>
<ol>
<li>同步：当一个同步调用发出后，需要等待返回消息（用户线程不断去询问），才能继续进行；</li>
<li>异步：当一个异步调用发出后，调用者不能立即得到返回消息，完成后会通过状态、通知和回调来通知调用者。</li>
</ol>
<p>简单来说就是：</p>
<ol>
<li>同步：同步等待消息通知，消息返回才能继续进行；</li>
<li>异步：异步等待消息通知，完成后被调系统通过回调等来通过调用者。</li>
</ol>
<h2 id="阻塞与非阻塞"><a href="#阻塞与非阻塞" class="headerlink" title="阻塞与非阻塞"></a>阻塞与非阻塞</h2><p>阻塞和非阻塞指的是不能立刻得到结果之前，会不会阻塞当前线程。</p>
<ol>
<li>阻塞：当前线程会被挂起，直到结果返回；</li>
<li>非阻塞：指在不能立刻得到结果之前，该函数不会阻塞当前线程，而会立刻返回（会导致线程切换的增加）。</li>
</ol>
<p>举个栗子说明：</p>
<table>
<thead>
<tr>
<th>类别</th>
<th>示例</th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td>同步阻塞</td>
<td>在银行排队，不干别的事情</td>
<td>效率最低</td>
</tr>
<tr>
<td>同步非阻塞</td>
<td>排队时，边打电话边抬头看是否到自己了</td>
<td>效率低下</td>
</tr>
<tr>
<td>异步阻塞</td>
<td>在银行领一个号后，在银行里等，不能做别的事情</td>
<td></td>
</tr>
<tr>
<td>异步非阻塞</td>
<td>领完号后，在忙着自己的事情，直到柜台通知</td>
<td>效率较高</td>
</tr>
</tbody>
</table>
<h1 id="BIO"><a href="#BIO" class="headerlink" title="BIO"></a>BIO</h1><p>BIO 模型是 Java IO 最开始提供的一种 IO 模型，BIO 又可以细分为两种模型，一是传统的同步阻塞模型，二是在对传统 BIO 模型的基本上进行的优化，又称为伪异步 IO 模型。</p>
<h2 id="传统的-BIO-模型"><a href="#传统的-BIO-模型" class="headerlink" title="传统的 BIO 模型"></a>传统的 BIO 模型</h2><p>传统 BIO 中，ServerSocket 负责绑定 IP 地址，启动监听端口；Socket 负责发起连接操作，连接成功后，双方通过输入和输出流进行同步阻塞通信。采用 BIO 通信模型的 Server，通常由一个独立的 Acceptor 线程负责监听 Client 端的连接，它接受到 Client 端连接请求后为每个 Client 创建一个新的线程进行处理，处理完之后，通过输出流返回给 Client 端，线程销毁，过程如下图所示（图来自《Netty 权威指南》）。</p>
<p><img src="/images/java/BIO.png" alt="传统 Java BIO 模型"></p>
<p>这个模型最大的问题是：</p>
<ul>
<li>缺乏扩展性，不能处理高性能、高并发场景，线程是 JVM 中非常宝贵的资源，当线程数膨胀后，系统的性能就会急剧下降，随着并发访问量的继续增大，系统就会出现线程堆栈溢出、创建新线程失败等问题，导致 Server 不能对外提供服务。</li>
</ul>
<p>示例代码参考 <a href="https://github.com/wangzzu/ProgramlLearn/tree/aab89008091660f1f231763660eb329eb5928bde/java_learn/java_socket/src/main/java/bio/" target="_blank" rel="external">Java BIO 示例</a>。</p>
<h2 id="伪异步-IO-模型"><a href="#伪异步-IO-模型" class="headerlink" title="伪异步 IO 模型"></a>伪异步 IO 模型</h2><p>为了改进这种一对一的连接模型，后来又演进出了一种通过线程池或者消息队列实现 1 个或者多个线程处理所有 Client 请求的模型，由于它底层依然是同步阻塞 IO，所以被称为【伪异步 IO 模型】。相比于传统 BIO 后端不断创建新的线程处理 Client 请求，它在后端使用一个<strong>线程池</strong>来代替，通过线程池可以灵活的调配线程资源，设置线程的最大值，防止由于海量并发接入导致线程资源耗尽，过程如下图所示（图来自《Netty 权威指南》）。</p>
<p><img src="/images/java/BIO2.png" alt="伪异步 IO 模型"></p>
<p>看似这个模型解决了 BIO 面对的问题，实际上，由于它是面向数据流的模型，底层依然是同步阻塞模型，在处理一个 socket 输入流，它会一直阻塞下去，除非：有数据可读、可用数据读取完毕、有异常，否则会一直一直阻塞下去。这个模型最大的问题是：</p>
<ul>
<li>阻塞的时间取决于对应 IO 线程的处理速度和网络 IO 的传输速度，处理效率不可控。</li>
</ul>
<h1 id="Java-NIO"><a href="#Java-NIO" class="headerlink" title="Java NIO"></a>Java NIO</h1><p>Java NIO 是 Java IO 模型中最重要的 IO 模型，也是本文主要讲述的内容，正式由于 NIO 的出现，Java 才能在服务端获得跟 C 和 C++ 一样的运行效率，NIO 是 New IO（或者 Non-block IO）的简称。</p>
<p>与 Socket 类和 ServerSocket 类相对应，NIO 也提供了 SocketChannel 和 ServerSocketChannel 两种不同套接字通道的实现，它们都支持阻塞和非阻塞两种模式。一般来说，低负载、低并发的应用程序可以选择同步阻塞 IO 以降低复杂度，但是高负载、高并发的网络应用，需要使用 NIO 的非阻塞模式进行开发。</p>
<h2 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h2><p>在 NIO 中有三种非常重要的概念：</p>
<ul>
<li>缓冲区（buffer）：本质上是一个数组，它包含一些要读写的数据；</li>
<li>通道（channel）：是一个通道，通过它读写数据，类似于自来水管；</li>
<li>多路复用器（selector）：用于选择已经就绪的任务，selector 会轮询注册在其上的 channel，选出已经就绪的 channel。</li>
</ul>
<p><img src="/images/java/NIO.png" alt="NIO 的简单模型"></p>
<p>三者之间的关系如上图所示，这里先简单概括一下：</p>
<ul>
<li>Buffer：是缓冲区，任何时候访问 NIO 数据，都是通过 Buffer 进行；</li>
<li>Channel：通过它读写 Buffer 中的数据，可以用于读、写或同时读写；</li>
<li>Selector：多路复用器，Selector 不断轮询注册在其上的 Channel，如果某个 Channel 有新的 TCP 链接接入、读和写事件，这个 Channel 就处于就绪状态，会被 Selector 轮组出来，然后通过<code>SelectionKey()</code> 可以获取就绪 Channel 的集合，进行后续的 IO 操作。</li>
</ul>
<p>下面详细介绍一下这三个概念。</p>
<h3 id="Channel"><a href="#Channel" class="headerlink" title="Channel"></a>Channel</h3><p>Channel 是全双工的，可以比流更好地映射底层操作系统的 API，与流也非常相似，有以下几点区别：</p>
<ul>
<li>Channel 可以读也可以写，但流（InputStream 或 OutputStream）是单向的；</li>
<li>通道可以异步读写；</li>
<li>它是基于缓冲区（Buffer）进行读写；</li>
</ul>
<p>在 Java 中提供以下几种 Channel：</p>
<ol>
<li>FileChannel：用于文件的读写；</li>
<li>DatagramChannel：用于 UDP 数据读写；</li>
<li>SocketChannel：用于 Socket 数据读写；</li>
<li>ServerSocketChannel：监听 TCP 连接请求。</li>
</ol>
<p>这些 Channel 类之间的继承关系如下图所示</p>
<p><img src="/images/java/channel.png" alt="Channel 之间的继承关系"></p>
<p>从上图中，可以看出，Channel 可以分为两大类：用于网络读写的 <code>SelectableChannel</code> 和用于文件操作的 <code>FileChannel</code>。</p>
<p>其中，FileChannel 只能在阻塞模式下工作，具体可以参考<a href="http://wiki.jikexueyuan.com/project/java-nio-zh/java-nio-filechannel.html" target="_blank" rel="external">Java NIO FileChannel文件通道</a>。</p>
<h4 id="NIO-Scatter-Gather"><a href="#NIO-Scatter-Gather" class="headerlink" title="NIO Scatter/Gather"></a>NIO Scatter/Gather</h4><p>Java NIO 发布时内置了对 scatter/gather的支持：</p>
<ul>
<li>Scattering read 指的是从通道读取的操作能把数据写入多个 Buffer，也就是 sctters 代表了数据从一个 Channel 到多个 Buffer的过程。</li>
<li>Gathering write 则正好相反，表示的是从多个 Buffer 把数据写入到一个 Channel中。</li>
</ul>
<p><img src="/images/java/scatter-gather.png" alt="Channel 之间的继承关系"></p>
<p>示例如下，具体参考 <a href="http://wiki.jikexueyuan.com/project/java-nio-zh/java-nio-scatter-gather.html" target="_blank" rel="external">Java NIO Scatter / Gather</a></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// Scattering read</span></div><div class="line">ByteBuffer header = ByteBuffer.allocate(<span class="number">128</span>);</div><div class="line">ByteBuffer body   = ByteBuffer.allocate(<span class="number">1024</span>);</div><div class="line"></div><div class="line">ByteBuffer[] bufferArray = &#123; header, body &#125;;</div><div class="line">channel.read(bufferArray);</div><div class="line"></div><div class="line"><span class="comment">// Gathering write</span></div><div class="line">ByteBuffer header = ByteBuffer.allocate(<span class="number">128</span>);</div><div class="line">ByteBuffer body   = ByteBuffer.allocate(<span class="number">1024</span>);</div><div class="line"></div><div class="line">ByteBuffer[] bufferArray = &#123; header, body &#125;;</div><div class="line">channel.write(bufferArray);</div></pre></td></tr></table></figure>
<h3 id="Buffer"><a href="#Buffer" class="headerlink" title="Buffer"></a>Buffer</h3><p>Buffer，本质上是一块内存区，可以用来读写数据，它包含一些要写入或者要读出的数据。在 NIO 中，所有数据都是通过 Buffer 处理的，读取数据时，它是直接读到缓冲区中，写入数据时，写入到缓冲区。</p>
<p>最常用的缓冲区是 ByteBuffer，一个 ByteBuffer 提供了一组功能用于操作 byte 数组，除了 ByteBuffer，还有其他的一些 Buffer，如：CharBuffer、IntBuffer 等，它们之间的关系如下图所示。</p>
<p><img src="/images/java/buffer.png" alt="Buffer 之间的继承关系"></p>
<h4 id="基本用法"><a href="#基本用法" class="headerlink" title="基本用法"></a>基本用法</h4><p>Buffer 基本用法（读写数据过程）：</p>
<ol>
<li>把数据写入 Buffer；</li>
<li>调用 <code>flip()</code>，Buffer 由写模式变为读模式；</li>
<li>Buffer 中读取数据；</li>
<li>调用 <code>clear()</code> 清空 buffer，等待下次写入。</li>
</ol>
<p>示例如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">byte</span>[] req = <span class="string">"QUERY TIME ORDER"</span>.getBytes();</div><div class="line">ByteBuffer byteBuffer = ByteBuffer.allocate(req.length);</div><div class="line">byteBuffer.put(req);</div><div class="line">byteBuffer.flip();</div><div class="line"><span class="keyword">while</span> (byteBuffer.hasRemaining())&#123;</div><div class="line">     System.out.println((<span class="keyword">char</span>) byteBuffer.get());</div><div class="line">&#125;</div><div class="line">byteBuffer.clear();</div></pre></td></tr></table></figure>
<h4 id="Buffer-位置信息"><a href="#Buffer-位置信息" class="headerlink" title="Buffer 位置信息"></a>Buffer 位置信息</h4><p>Buffer 实质上就是一块内存，用于读写数据，这块内存被 NIO Buffer 管理，一个 Buffer 有三个属性是必须掌握的，分别是：</p>
<ul>
<li>capacity：容量；</li>
<li>position：位置；</li>
<li>limit：限制；</li>
</ul>
<p>其中，position 和 limit 的具体含义取决于当前 buffer 的模式，capacity 在两种模式下都表示容量，Buffer 读模式和写模式如下图所示。</p>
<p><img src="/images/java/buffer-position.png" alt="Buffer 的位置信息"></p>
<ol>
<li>容量（capacity）<ul>
<li>Buffer 有一块固定的内存，其大小就是 capacity，一旦 Buffer 写满，就需要清空已读数据以便下次继续写入新的数据；</li>
</ul>
</li>
<li>位置（Position）<ul>
<li>写模式时，当写入数据到 Buffer 的时候从一个确定的位置开始，初始化时这个位置 position 为0，写入数据后，position 的值就会指向数据之后的单元，position 最大的值可以达到 <code>capacity-1</code>；</li>
<li>读模式时，也需要从一个确定的位置开始，Buffer 从写模式变为读模式时，position 会归零，每次读取后，position 向后移动；</li>
</ul>
</li>
<li>上限（limit）<ul>
<li>写模式时，limit 就是能写入的最大数据量，等同于 Buffer 的容量；</li>
<li>读模式时，limit 代表我们能读取的最大容量，它的值等同于写模式下 position 位置。</li>
</ul>
</li>
</ol>
<h4 id="Buffer-常用方法"><a href="#Buffer-常用方法" class="headerlink" title="Buffer 常用方法"></a>Buffer 常用方法</h4><ul>
<li><code>flip()</code>：把 buffer 从模式调整为读模式，在读模式下，可以读取所有已经写入的数据；</li>
<li><code>clear()</code>：清空整个 buffer；</li>
<li><code>compact()</code>：只清空已读取的数据，未被读取的数据会被移动到 buffer 的开始位置，写入位置则紧跟着未读数据之后；</li>
<li><code>rewind()</code>：将 position 置为0，这样我们可以重复读取 Buffer 中的数据，limit 保持不变；</li>
<li><code>mark()</code>和<code>reset()</code>：通过mark方法可以标记当前的position，通过reset来恢复mark的位置</li>
<li><code>equals()</code>：判断两个 Buffer 是否相等，需满足：类型相同、Buffer 中剩余字节数相同、所有剩余字节相等；</li>
<li><code>compareTo()</code>：compareTo 比较 Buffer 中的剩余元素，只不过这个方法适用于比较排序的。</li>
</ul>
<h3 id="Selector"><a href="#Selector" class="headerlink" title="Selector"></a>Selector</h3><p>Selector 是 Java NIO 核心部分，简单来说，它的作用就是：Selector 不断轮询注册在其上的 Channel，如果某个 Channel 上面有新的 TCP 连接、读和写事件，这个 Channel 就处于就绪状态，会被 Selector 轮询出来，然后通过 <code>SelectorKey()</code> 可以获取就绪 Channel 的集合，进行后续的 IO 操作。</p>
<p>一个 Selector 可以轮询多个 Channel，由于 JDK 底层使用了 <code>epoll()</code> 实现，它并没有最大连接句柄 1024/2048 的限制，这就意味着只需要一个线程负责 Selector 的轮询，就可以连接上千上万的 Client。</p>
<h4 id="注册-Channel"><a href="#注册-Channel" class="headerlink" title="注册 Channel"></a>注册 Channel</h4><p>举一个栗子，简单介绍 <code>Selector</code> 的使用。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// 创建一个 Selector</span></div><div class="line">Selector selector = Selector.open();</div><div class="line"><span class="comment">// 将一个 Channel 注册到 Selector 上</span></div><div class="line">channel.configureBlocking(<span class="keyword">false</span>);</div><div class="line">SelectionKey key = channel.register(selector, SelectionKey.OP_READ);</div></pre></td></tr></table></figure>
<p><code>register()</code> 的第二个参数代表的是 selector 监听的事件类型，Selector 可以监听事件类型总共有以下四种：</p>
<ol>
<li>SelectionKey.OP_CONNECT：只会注册一次，成功之后（TCP 连接建立之后），这个监听事件就取消了；</li>
<li>SelectionKey.OP_ACCEPT：主要用于服务端，就是监听是否有新的连接请求；</li>
<li>SelectionKey.OP_READ：注册之后不会取消，监听是否数据到来；</li>
<li>SelectionKey.OP_WRITE：最好的使用方法是每当发送数据时，就注册一次，然后再取消，否则每次 select 轮询时，注册 OP_WRITE 事件的 Channel 都是 ready 的，除非 socket send buffer 满了（参考 <a href="https://stackoverflow.com/questions/23136079/communicating-between-nio-op-read-and-op-write-operations" target="_blank" rel="external">Communicating between nio OP_READ and OP_WRITE operations</a>）。</li>
</ol>
<h4 id="SelectionKey"><a href="#SelectionKey" class="headerlink" title="SelectionKey"></a>SelectionKey</h4><p><code>Set&lt;SelectionKey&gt; selectionKeys = selector.selectedKeys();</code> 返回的是已经就绪的 Channel 集合，<code>SelectionKey</code> 对象的详细属性如下图所示。</p>
<p><img src="/images/java/SelectionKey.png" alt="SelectionKey 的详情"></p>
<h2 id="NIO-原理"><a href="#NIO-原理" class="headerlink" title="NIO 原理"></a>NIO 原理</h2><p>Java NIO 实现的关键是 IO 多路复用（具体可以参考上篇文章：<a href="http://matt33.com/2017/08/06/unix-io/#Linux-的-IO-多路复用模型">Linux 的 IO 多路复用模型</a>），在 Linux 平台，Java NIO 是基于 epoll（2.6以上，之前是 Select） 来实现的。</p>
<p>Linux 的 select/epoll  使用的是 Reactor 网络 IO 模式。网络编程中，有两种常用的设计模式，它们都是基于事件驱动：</p>
<ul>
<li>Reactor 模式：主动模式，应用程序不断去轮询，问操作系统 IO 是否就绪，实际的 IO 操作还是由应用实现（IO 多路复用采用的模式）；</li>
<li>Proactor 模式：被动模式，操作系统把 IO 完成后通知应用程序，此时数据已经就绪。</li>
</ul>
<p>这两种模式详细内容可以参考<a href="http://daoluan.net/linux/%E5%AD%A6%E4%B9%A0%E6%80%BB%E7%BB%93/%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B/2013/08/20/two-high-performance-io-design-patterns.html" target="_blank" rel="external">两种高性能 I/O 设计模式 Reactor 和 Proactor</a>一文。</p>
<h2 id="NIO-编程"><a href="#NIO-编程" class="headerlink" title="NIO 编程"></a>NIO 编程</h2><p>关于 Java NIO，有两种最常见的使用方式：</p>
<ul>
<li>使用原生的 Java NIO（如 Kafka）；</li>
<li>使用 Netty（Hadoop 的 RPC 框架 Avro 底层使用 Netty 做通信框架）。</li>
</ul>
<p>在实际使用中，推荐第二种，使用 Netty 将会大大提高开发效率，后续会写篇关于 Netty 的文章，介绍一下 Netty 的具体内容，这里使用一个基于 Java 原生 NIO API 的小示例，讲述一下 NIO 的使用方法。</p>
<h3 id="Client-端"><a href="#Client-端" class="headerlink" title="Client 端"></a>Client 端</h3><p>NIO Client 创建序列图如下图所示（图片来自《Netty 权威指南》）。</p>
<p><img src="/images/java/nio-client.png" alt="NIO Client 端序列图"></p>
<p>具体的代码及注释参考：<a href="https://github.com/wangzzu/ProgramlLearn/tree/aab89008091660f1f231763660eb329eb5928bde/java_learn/java_socket/src/main/java/nio/client/" target="_blank" rel="external">NIO Client 端代码</a>。</p>
<h3 id="Server-端"><a href="#Server-端" class="headerlink" title="Server 端"></a>Server 端</h3><p>NIO Server 创建序列图如下图所示（图片来自《Netty 权威指南》）。</p>
<p><img src="/images/java/nio-server.png" alt="NIO Server 端序列图"></p>
<p>具体的代码及注释参考：<a href="https://github.com/wangzzu/ProgramlLearn/tree/aab89008091660f1f231763660eb329eb5928bde/java_learn/java_socket/src/main/java/nio/server/" target="_blank" rel="external">NIO Server 端代码</a>。</p>
<h1 id="IO-模型对比"><a href="#IO-模型对比" class="headerlink" title="IO 模型对比"></a>IO 模型对比</h1><p>在对比之前，先简单介绍 Java AIO 模型，这里就不再进行相应的展开了。</p>
<h2 id="AIO"><a href="#AIO" class="headerlink" title="AIO"></a>AIO</h2><p>NIO 2.0 中引入异步通道的概念，并提供了异步文件通道和异步套接字导通的实现，它是真正的异步非阻塞I IO，底层是利用事件驱动（AIO）实现，不需要多路复用器（Selector）对注册的通道进行轮组操作即可实现异步读写。</p>
<p>可以参考<a href="https://www.ibm.com/developerworks/cn/java/j-lo-nio2/" target="_blank" rel="external">在 Java 7 中体会 NIO.2 异步执行的快乐</a></p>
<h2 id="几种-IO-模型功能和特性对比"><a href="#几种-IO-模型功能和特性对比" class="headerlink" title="几种 IO 模型功能和特性对比"></a>几种 IO 模型功能和特性对比</h2><table>
<thead>
<tr>
<th></th>
<th>传统 BIO</th>
<th>伪异步 IO</th>
<th>NIO</th>
<th>AIO</th>
</tr>
</thead>
<tbody>
<tr>
<td>client 数：IO 线程数</td>
<td>1：1</td>
<td>M：N（M 可以大于 N）</td>
<td>M：1</td>
<td>M：0（不需要额外的线程，被动回调）</td>
</tr>
<tr>
<td>IO 类型（阻塞）</td>
<td>阻塞IO</td>
<td>阻塞IO</td>
<td>非阻塞IO</td>
<td>非阻塞IO</td>
</tr>
<tr>
<td>IO 类型（同步）</td>
<td>同步 IO</td>
<td>同步 IO</td>
<td>同步 IO（IO 多路复用）</td>
<td>异步 IO</td>
</tr>
<tr>
<td>可靠性</td>
<td>非常差</td>
<td>差</td>
<td>高</td>
<td>高</td>
</tr>
<tr>
<td>吞吐量</td>
<td>低</td>
<td>中</td>
<td>高</td>
<td>高</td>
</tr>
</tbody>
</table>
<p>本文主要是对 Java IO 模型总结，特别是对 NIO 模型的总结。</p>
<hr>
<p>参考</p>
<ul>
<li>《Netty 权威指南》；</li>
<li>Java NIO <a href="http://tutorials.jenkov.com/java-nio/index.html" target="_blank" rel="external">英文版</a>，<a href="http://ifeve.com/java-nio-all/" target="_blank" rel="external">中文版</a>；</li>
</ul>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[Unix 网络 IO 模型及 Linux 的 IO 多路复用模型]]></title>
      <url>http://matt33.com/2017/08/06/unix-io/</url>
      <content type="html"><![CDATA[<p>近段在看 Kafka 的网络模型时，遇到了很多 Java NIO 的内容，在学习 Java NIO 的过程中，发现需要把 UNIX 的这几种网络 IO 模型以及 Linux 的 IO 多路复用理解清楚，才能更好地理解 Java NIO，本文就是在学习 UNIX 的五种网络 IO 模型以及 Linux IO 多路复用模型后，做的一篇总结。</p>
<p>本文主要探讨的问题有以下两个：</p>
<ol>
<li>Unix 中的五种网络 IO 模型；</li>
<li>Linux 中 IO 多路复用的实现。</li>
</ol>
<h2 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h2><p>在介绍网络模型之前，先简单介绍一些基本概念。</p>
<h3 id="文件描述符-fd"><a href="#文件描述符-fd" class="headerlink" title="文件描述符 fd"></a>文件描述符 fd</h3><p>文件描述符（file descriptor，简称 fd）在形式上是一个非负整数。实际上，它是一个索引值，指向内核为每一个进程所维护的该进程打开文件的记录表。当程序打开一个现有文件或者创建一个新文件时，内核向进程返回一个文件描述符。在程序设计中，一些涉及底层的程序编写往往会围绕着文件描述符展开。但是文件描述符这一概念往往只适用于UNIX、Linux这样的操作系统。</p>
<p>在 Linux 中，内核将所有的外部设备都当做一个文件来进行操作，而对一个文件的读写操作会调用内核提供的系统命令，返回一个 fd，对一个 socket 的读写也会有相应的描述符，称为 socketfd（socket 描述符），实际上描述符就是一个数字，它指向内核中的一个结构体（文件路径、数据区等一些属性）。</p>
<h3 id="用户空间与内核空间、内核态与用户态"><a href="#用户空间与内核空间、内核态与用户态" class="headerlink" title="用户空间与内核空间、内核态与用户态"></a>用户空间与内核空间、内核态与用户态</h3><p>这个是经常提到的概念，具体含义可以参考这篇文章<a href="http://www.cnblogs.com/Anker/p/3269106.html" target="_blank" rel="external">用户空间与内核空间，进程上下文与中断上下文【总结】</a>，大概内容如下：</p>
<p>现在操作系统都是采用虚拟存储器，那么对32位操作系统而言，它的寻址空间（虚拟存储空间）为4G（2的32次方）。操心系统的核心是内核，独立于普通的应用程序，可以访问受保护的内存空间，也有访问底层硬件设备的所有权限。为了保证用户进程不能直接操作内核，保证内核的安全，操心系统将虚拟空间划分为两部分，一部分为内核空间，一部分为用户空间。针对 linux 操作系统而言（以32位操作系统为例）</p>
<ul>
<li>将最高的 1G 字节（从虚拟地址 0xC0000000 到 0xFFFFFFFF），供内核使用，称为内核空间；</li>
<li>将较低的 3G 字节（从虚拟地址 0x00000000 到 0xBFFFFFFF），供各个进程使用，称为用户空间。</li>
</ul>
<p>每个进程可以通过系统调用进入内核，因此，Linux 内核由系统内的所有进程共享。于是，从具体进程的角度来看，每个进程可以拥有 4G 字节的虚拟空间。</p>
<ul>
<li>当一个任务（进程）执行系统调用而陷入内核代码中执行时，称进程处于内核运行态（<strong>内核态</strong>）。此时处理器处于特权级最高的（0级）内核代码中执行。当进程处于内核态时，执行的内核代码会使用当前进程的内核栈，每个进程都有自己的内核栈；</li>
<li>当进程在执行用户自己的代码时，则称其处于用户运行态（<strong>用户态</strong>）。此时处理器在特权级最低的（3级）用户代码中运行。当正在执行用户程序而突然被中断程序中断时，此时用户程序也可以象征性地称为处于进程的内核态。因为中断处理程序将使用当前进程的内核栈。</li>
</ul>
<h3 id="上下文切换"><a href="#上下文切换" class="headerlink" title="上下文切换"></a>上下文切换</h3><p>当一个进程在执行时，CPU 的所有寄存器中的值、进程的状态以及堆栈中的内容被称为该进程的上下文。</p>
<p>当内核需要切换到另一个进程时，它需要保存当前进程的所有状态，即保存当前进程的上下文，以便在再次执行该进程时，能够必得到切换时的状态执行下去。在 Linux 中，当前进程上下文均保存在进程的任务数据结构中。在发生中断时，内核就在被中断进程的上下文中，在内核态下执行中断服务例程。但同时会保留所有需要用到的资源，以便中继服务结束时能恢复被中断进程的执行。</p>
<h2 id="UNIX-的网络-IO-模型"><a href="#UNIX-的网络-IO-模型" class="headerlink" title="UNIX 的网络 IO 模型"></a>UNIX 的网络 IO 模型</h2><p>根据 UNIX 网络编程对 IO 模型的分类，UNIX 提供了以下 5 种 IO 模型。</p>
<h3 id="阻塞-IO-模型"><a href="#阻塞-IO-模型" class="headerlink" title="阻塞 IO 模型"></a>阻塞 IO 模型</h3><p>最常用的 IO 模型就是阻塞 IO 模型，在缺省条件下，所有文件操作都是阻塞的，以 socket 读为例来介绍一下此模型，如下图所示。</p>
<p><img src="/images/linux/BIO.png" alt="阻塞 IO 模型"></p>
<p>在用户空间调用 <code>recvfrom</code>，系统调用直到数据包达到且被复制到应用进程的缓冲区中或中间发生异常返回，在这个期间进程会一直等待。进程从调用 <code>recvfrom</code> 开始到它返回的整段时间内都是被阻塞的，因此，被称为阻塞 IO 模型。</p>
<h3 id="非阻塞-IO-模型"><a href="#非阻塞-IO-模型" class="headerlink" title="非阻塞 IO 模型"></a>非阻塞 IO 模型</h3><p><code>recvfrom</code> 从应用到内核的时，如果该缓冲区没有数据，就会直接返回 <code>EWOULDBLOCK</code> 错误，一般都对非阻塞 IO 模型进行轮询检查这个状态，看看内核是不是有数据到来，流程如下图所示。</p>
<p><img src="/images/linux/N-BIO.png" alt="非阻塞 IO 模型"></p>
<p>也就是说非阻塞的 <code>recvform</code> 系统调用调用之后，进程并没有被阻塞，内核马上返回给进程。</p>
<ul>
<li>如果数据还没准备好，此时会返回一个 error。进程在返回之后，可以干点别的事情，然后再发起 <code>recvform</code> 系统调用。重复上面的过程，循环往复的进行 <code>recvform</code> 系统调用，这个过程通常被称之为<strong>轮询</strong>。</li>
</ul>
<p>轮询检查内核数据，直到数据准备好，再拷贝数据到进程，进行数据处理。需要注意，拷贝数据整个过程，进程仍然是属于阻塞的状态。</p>
<p>在 Linux 下，可以通过设置 socket 使其变为 non-blocking。</p>
<h3 id="IO-多路复用模型"><a href="#IO-多路复用模型" class="headerlink" title="IO 多路复用模型"></a>IO 多路复用模型</h3><p>Linux 提供 select、poll、epoll，进程通过讲一个或者多个 fd 传递给 select、poll、epoll 系统调用，阻塞在 select 操作（这个是内核级别的调用）上，这样的话，可以同时监听多个 fd 是否处于就绪状态。其中，</p>
<ul>
<li>select/poll 是顺序扫描 fd 是否就绪，而且支持的 fd 数量有限；</li>
<li>epoll 是基于事件驱动方式代替顺序扫描性能更高。</li>
</ul>
<p>这个后面详细讲述，具体流程如下图所示。</p>
<p><img src="/images/linux/Multi-IO.png" alt="IO 多路复用模型"></p>
<p>多路复用的特点是通过一种机制一个进程能同时等待 IO 文件描述符，内核监视这些文件描述符（套接字描述符），其中的任意一个进入读就绪状态，select， poll，epoll 函数就可以返回，它最大的优势就是可以同时处理多个连接。</p>
<h3 id="信号驱动-IO-模型"><a href="#信号驱动-IO-模型" class="headerlink" title="信号驱动 IO 模型"></a>信号驱动 IO 模型</h3><p>首先需要开启 socket 信号驱动 IO 功能，并通过系统调用 <code>sigaction</code> 执行一个信号处理函数（非阻塞，立即返回）。当数据就绪时，会为该进程生成一个 SIGIO 信号，通过信号回调通知应用程序调用 <code>recvfrom</code> 来读取数据，并通知主循环喊出处理数据，流程如下图所示。</p>
<p><img src="/images/linux/single-IO.png" alt="信号驱动 IO 模型"></p>
<h3 id="异步-IO-模型"><a href="#异步-IO-模型" class="headerlink" title="异步 IO 模型"></a>异步 IO 模型</h3><p>告知内核启动某个事件，并让内核在整个操作完成后（包括将数据从内核复制到用户自己的缓冲区）通过我们，流程如下图所示。</p>
<p><img src="/images/linux/AIO.png" alt="异步 IO 模型"></p>
<p>与信号驱动模式的主要区别是：</p>
<ul>
<li>信号驱动 IO 由内核通知我们何时可以开始一个 IO 操作；</li>
<li>异步 IO 操作由内核通知我们 IO 何时完成。</li>
</ul>
<p>内核是通过向应用程序发送 signal 或执行一个基于线程的回调函数来完成这次 IO 处理过程，告诉用户 read 操作已经完成，在 Linux 中，通知的方式是信号：</p>
<ol>
<li>当进程正处于用户态时，应用需要立马进行处理，一般情况下，是先将事件登记一下，放进一个队列中；</li>
<li>当进程正处于内核态时，比如正在以同步阻塞模式读磁盘，那么只能先把这个通知挂起来，等内核态的事情完成之后，再触发信号通知；</li>
<li>如果这个进程现在被挂起来了，比如 sleep，那就把这个进程唤醒，等 CPU 空闲时，就会调度这个进程，触发信号通知。</li>
</ol>
<h3 id="几种-IO-模型比较"><a href="#几种-IO-模型比较" class="headerlink" title="几种 IO 模型比较"></a>几种 IO 模型比较</h3><p><img src="/images/linux/IO-compact.png" alt="几种模型的比较"></p>
<h2 id="Linux-的-IO-多路复用模型"><a href="#Linux-的-IO-多路复用模型" class="headerlink" title="Linux 的 IO 多路复用模型"></a>Linux 的 IO 多路复用模型</h2><p>IO 多路复用通过把多个 IO 阻塞复用到同一个 select 的阻塞上，从而使得系统在单线程的情况下，可以同时处理多个 client 请求，与传统的多线程/多进程模型相比，IO 多路复用的最大优势是系统开销小，系统不需要创建新的额外的进程或线程，也不需要维护这些进程和线程的运行，节省了系统资源，IO 多路复用的主要场景如下：</p>
<ol>
<li>Server 需要同时处理多个处于监听状态或者连接状态的 socket；</li>
<li>Server 需要同时处理多种网络协议的 socket。</li>
</ol>
<p>IO 多路复用实际上就是通过一种机制，一个进程可以监视多个描 fd，一旦某个 fd 就绪（一般是读就绪或者写就绪），能够通知程序进行相应的读写操作，目前支持 IO 多路复用的系统有 select、pselect、poll、epoll，但它们本质上都是同步 IO。</p>
<p>在 Linux 网络编程中，最初是选用 select 做轮询和网络事件通知，然而 select 的一些固有缺陷导致了它的应用受到了很大的限制，最终 Linux 选择 epoll。</p>
<h3 id="select"><a href="#select" class="headerlink" title="select"></a>select</h3><p>select 函数监视的 fd 分3类，分别是 <code>writefds</code>、<code>readfds</code>、和 <code>exceptfds</code>。调用后select 函数会阻塞，直到有 fd 就绪（有数据 可读、可写、或者有 except），或者超时（timeout 指定等待时间，如果立即返回设为 null 即可），函数返回。当select函数返回后，可以通过遍历 fdset，来找到就绪的 fd。</p>
<p>select 目前几乎在所有的平台上支持，其良好跨平台支持也是它的一个优点。select 的一个最大的缺陷就是单个进程对打开的 fd 是有一定限制的，它由 <code>FD_SETSIZE</code> 限制，默认值是1024，如果修改的话，就需要重新编译内核，不过这会带来网络效率的下降。</p>
<p>select 和 poll 另一个缺陷就是随着 fd 数目的增加，可能只有很少一部分 socket 是活跃的，但是 select/poll 每次调用时都会线性扫描全部的集合，导致效率呈现线性的下降。</p>
<h3 id="poll"><a href="#poll" class="headerlink" title="poll"></a>poll</h3><p>poll 本质上和 select 没有区别，它将用户传入的数组拷贝到内核空间，然后查询每个 fd 对应的设备状态，如果设备就绪则在设备等待队列中加入一项并继续遍历，如果遍历完所有 fd 后没有发现就绪设备，则挂起当前进程，直到设备就绪或者主动超时，被唤醒后它又要再次遍历 fd。这个过程经历了多次无谓的遍历。</p>
<p>它没有最大连接数的限制，原因是它是基于链表来存储的，但是同样以下两个缺点：</p>
<ol>
<li>大量的 fd 的数组被整体复制于用户态和内核地址空间之间；</li>
<li>poll 还有一个特点是【水平触发】，如果报告了 fd 后，没有被处理，那么下次 poll 时会再次报告该 fd；</li>
<li>fd 增加时，线性扫描导致性能下降。</li>
</ol>
<h3 id="epoll"><a href="#epoll" class="headerlink" title="epoll"></a>epoll</h3><p>epoll 支持水平触发和边缘触发，最大的特点在于边缘触发，它只告诉进程哪些 fd 变为就绪态，并且只会通知一次。还有一个特点是，epoll 使用【事件】的就绪通知方式，通过 <code>epoll_ctl</code> 注册 fd，一旦该 fd 就绪，内核就会采用类似 callback 的回调机制来激活该 fd，<code>epoll_wait</code> 便可以收到通知。</p>
<p>epoll的优点：</p>
<ol>
<li>没有最大并发连接的限制，它支持的 fd 上限受操作系统最大文件句柄数；</li>
<li>效率提升，不是轮询的方式，不会随着 fd 数目的增加效率下降。epoll 只会对【活跃】的 socket 进行操作，这是因为在内核实现中 epoll 是根据每个 fd 上面的 callback 函数实现的，只有【活跃】的 socket 才会主动的去调用 callback 函数，其他 idle 状态的 socket 则不会。epoll 的性能不会受 fd 总数的限制。</li>
<li>select/poll 都需要内核把 fd 消息通知给用户空间，而 epoll 是通过内核和用户空间 <code>mmap</code> 同一块内存实现。</li>
</ol>
<p>epoll 对 fd 的操作有两种模式：LT（level trigger）和ET（edge trigger）。LT 模式是默认模式，LT 模式与 ET 模式的区别如下：</p>
<ul>
<li>LT 模式：当 <code>epoll_wait</code> 检测到描述符事件发生并将此事件通知应用程序，应用程序可以不立即处理该事件，下次调用 <code>epoll_wait</code> 时，会再次响应应用程序并通知此事件；</li>
<li>ET 模式：当 <code>epoll_wait</code> 检测到描述符事件发生并将此事件通知应用程序，应用程序必须立即处理该事件，如果不处理，下次调用 <code>epoll_wait</code> 时，不会再次响应应用程序并通知此事件。</li>
</ul>
<h3 id="三种模型的区别"><a href="#三种模型的区别" class="headerlink" title="三种模型的区别"></a>三种模型的区别</h3><table>
<thead>
<tr>
<th>类别</th>
<th>select</th>
<th>poll</th>
<th>epoll</th>
</tr>
</thead>
<tbody>
<tr>
<td>支持的最大连接数</td>
<td>由 <code>FD_SETSIZE</code> 限制</td>
<td>基于链表存储，没有限制</td>
<td>受系统最大句柄数限制</td>
</tr>
<tr>
<td>fd 剧增的影响</td>
<td>线性扫描 fd 导致性能很低</td>
<td>同 select</td>
<td>基于 fd 上 callback 实现，没有性能下降的问题</td>
</tr>
<tr>
<td>消息传递机制</td>
<td>内核需要将消息传递到用户空间，需要内核拷贝</td>
<td>同 select</td>
<td>epoll 通过内核与用户空间共享内存来实现</td>
</tr>
</tbody>
</table>
<p>介绍完 IO 多路复用之后，后续我们看一下 Java 网络编程中的 NIO 模型及其背后的实现机制。</p>
<hr>
<p>参考</p>
<ul>
<li>《Netty 权威指南》</li>
<li><a href="http://www.cnblogs.com/Anker/p/3269106.html" target="_blank" rel="external">用户空间与内核空间，进程上下文与中断上下文【总结】</a></li>
<li><a href="http://www.jianshu.com/p/486b0965c296" target="_blank" rel="external">聊聊 Linux 中的五种 IO 模型</a></li>
<li><a href="http://www.jianshu.com/p/dfd940e7fca2" target="_blank" rel="external">聊聊IO多路复用之select、poll、epoll详解</a></li>
<li><a href="http://www.jianshu.com/p/2461535c38f3" target="_blank" rel="external">高性能Server—Reactor模型</a></li>
</ul>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[Kafka 源码解析之 topic 创建过程（三）]]></title>
      <url>http://matt33.com/2017/07/21/kafka-topic-create/</url>
      <content type="html"><![CDATA[<p>本文是 Kafka 源码解析的第三篇，主要讲述一个 topic 的创建过程，从 topic 是如何创建到 topic 真正创建成功的中间详细过程，文章主要内容可以分为以下几个部分：</p>
<ol>
<li>topic 是如何创建的？<ul>
<li>命令行创建；</li>
<li>Producer 发送数据时，自动创建；</li>
</ul>
</li>
<li>topic 创建时，replicas 是如何分配的？<ul>
<li>指定 replicas 的分配；</li>
<li>自动 replicas 分配；</li>
</ul>
</li>
<li>replicas 更新到 zk 后，底层如何创建一个 topic？<ul>
<li>创建 Partition 对象及状态更新；</li>
<li>创建 Partition 的 replica 对象及状态更新。</li>
</ul>
</li>
</ol>
<p>一个 topic 的完整创建过程如下图所示（以 topic 的 replicas 自动创建，且 broker 没有机架感知为例）</p>
<p><img src="/images/kafka/create_topic.png" alt="Topic 完整创建过程"></p>
<p>上图只是列出一些主要的方法调用，具体内容下面会详细讲述（在看下面的内容时，最后配合上面这张图来看）。</p>
<h2 id="topic-介绍"><a href="#topic-介绍" class="headerlink" title="topic 介绍"></a>topic 介绍</h2><p>topic 是 Kafka 中的一个消息队列的标识，也可以认为是消息队列的一个 id，用于区分不同的消息队列，一个 topic 由多个 partition 组成，这些 partition 是通常是分布在不同的多台 Broker 上的，为了保证数据的可靠性，一个 partition 又会设置为多个副本（replica），通常会设置两副本或三副本。如下图所示，这个一个名为『topic』的 topic，它由三个 partition 组成，两副本，假设 Kafka 集群有三台 Broker（replica 0_1 代表 partition 0 的第一个副本）。</p>
<p><img src="/images/kafka/topic-replicas.png" alt="Kafka Topic 的组成"></p>
<p>在设置副本时，副本数是必须小于集群的 Broker 数的，副本只有设置在不同的机器上才有作用。</p>
<h2 id="topic-如何创建"><a href="#topic-如何创建" class="headerlink" title="topic 如何创建"></a>topic 如何创建</h2><p>topic 在创建时有两种方式：</p>
<ol>
<li>通过 <code>kafka-topics.sh</code> 创建一个 topic，可以设置相应的副本数让 Server 端自动进行 replica 分配，也可以直接指定手动 replica 的分配；</li>
<li>Server 端如果 <code>auto.create.topics.enable</code> 设置为 true 时，那么当 Producer 向一个不存在的 topic 发送数据时，该 topic 同样会被创建出来，此时，副本数默认是1。</li>
</ol>
<p>下面看一下这两种方式的底层实现。</p>
<h3 id="kafka-topics-sh-创建-topic"><a href="#kafka-topics-sh-创建-topic" class="headerlink" title="kafka-topics.sh 创建 topic"></a>kafka-topics.sh 创建 topic</h3><p>在 Kafka 的安装目录下，通过下面这条命令可以创建一个 partition 为3，replica 为2的 topic（test）</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">./bin/kafka-topics.sh --create --topic <span class="built_in">test</span> --zookeeper XXXX --partitions 3 --replication-factor 2</div></pre></td></tr></table></figure>
<p><code>kafka-topics.sh</code> 实际上是调用 <code>kafka.admin.TopicCommand</code> 的方法来创建 topic，其实现如下：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//note: 创建 topic</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">createTopic</span></span>(zkUtils: <span class="type">ZkUtils</span>, opts: <span class="type">TopicCommandOptions</span>) &#123;</div><div class="line">  <span class="keyword">val</span> topic = opts.options.valueOf(opts.topicOpt)</div><div class="line">  <span class="keyword">val</span> configs = parseTopicConfigsToBeAdded(opts)</div><div class="line">  <span class="keyword">val</span> ifNotExists = opts.options.has(opts.ifNotExistsOpt)</div><div class="line">  <span class="keyword">if</span> (<span class="type">Topic</span>.hasCollisionChars(topic))</div><div class="line">    println(<span class="string">"WARNING: Due to limitations in metric names, topics with a period ('.') or underscore ('_') could collide. To avoid issues it is best to use either, but not both."</span>)</div><div class="line">  <span class="keyword">try</span> &#123;</div><div class="line">    <span class="keyword">if</span> (opts.options.has(opts.replicaAssignmentOpt)) &#123;<span class="comment">//note: 指定 replica 的分配,直接向 zk 更新即可</span></div><div class="line">      <span class="keyword">val</span> assignment = parseReplicaAssignment(opts.options.valueOf(opts.replicaAssignmentOpt))</div><div class="line">      <span class="type">AdminUtils</span>.createOrUpdateTopicPartitionAssignmentPathInZK(zkUtils, topic, assignment, configs, update = <span class="literal">false</span>)</div><div class="line">    &#125; <span class="keyword">else</span> &#123;<span class="comment">//note: 未指定 replica 的分配,调用自动分配算法进行分配</span></div><div class="line">      <span class="type">CommandLineUtils</span>.checkRequiredArgs(opts.parser, opts.options, opts.partitionsOpt, opts.replicationFactorOpt)</div><div class="line">      <span class="keyword">val</span> partitions = opts.options.valueOf(opts.partitionsOpt).intValue</div><div class="line">      <span class="keyword">val</span> replicas = opts.options.valueOf(opts.replicationFactorOpt).intValue</div><div class="line">      <span class="keyword">val</span> rackAwareMode = <span class="keyword">if</span> (opts.options.has(opts.disableRackAware)) <span class="type">RackAwareMode</span>.<span class="type">Disabled</span></div><div class="line">                          <span class="keyword">else</span> <span class="type">RackAwareMode</span>.<span class="type">Enforced</span></div><div class="line">      <span class="type">AdminUtils</span>.createTopic(zkUtils, topic, partitions, replicas, configs, rackAwareMode)</div><div class="line">    &#125;</div><div class="line">    println(<span class="string">"Created topic \"%s\"."</span>.format(topic))</div><div class="line">  &#125; <span class="keyword">catch</span>  &#123;</div><div class="line">    <span class="keyword">case</span> e: <span class="type">TopicExistsException</span> =&gt; <span class="keyword">if</span> (!ifNotExists) <span class="keyword">throw</span> e</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>如果指定了 partition 各个 replica 的分布，那么将 partition replicas 的结果验证之后直接更新到 zk 上，验证的 replicas 的代码是在 <code>parseReplicaAssignment</code> 中实现的，如下所示</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">parseReplicaAssignment</span></span>(replicaAssignmentList: <span class="type">String</span>): <span class="type">Map</span>[<span class="type">Int</span>, <span class="type">List</span>[<span class="type">Int</span>]] = &#123;</div><div class="line">  <span class="keyword">val</span> partitionList = replicaAssignmentList.split(<span class="string">","</span>)</div><div class="line">  <span class="keyword">val</span> ret = <span class="keyword">new</span> mutable.<span class="type">HashMap</span>[<span class="type">Int</span>, <span class="type">List</span>[<span class="type">Int</span>]]()</div><div class="line">  <span class="keyword">for</span> (i &lt;- <span class="number">0</span> until partitionList.size) &#123;</div><div class="line">    <span class="keyword">val</span> brokerList = partitionList(i).split(<span class="string">":"</span>).map(s =&gt; s.trim().toInt)</div><div class="line">    <span class="keyword">val</span> duplicateBrokers = <span class="type">CoreUtils</span>.duplicates(brokerList)</div><div class="line">    <span class="keyword">if</span> (duplicateBrokers.nonEmpty)<span class="comment">//note: 同一个 partition 对应的 replica 是不能相同的</span></div><div class="line">      <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">AdminCommandFailedException</span>(<span class="string">"Partition replica lists may not contain duplicate entries: %s"</span>.format(duplicateBrokers.mkString(<span class="string">","</span>)))</div><div class="line">    ret.put(i, brokerList.toList)</div><div class="line">    <span class="keyword">if</span> (ret(i).size != ret(<span class="number">0</span>).size)<span class="comment">//note: 同一个 topic 的副本数必须相同</span></div><div class="line">      <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">AdminOperationException</span>(<span class="string">"Partition "</span> + i + <span class="string">" has different replication factor: "</span> + brokerList)</div><div class="line">  &#125;</div><div class="line">  ret.toMap</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>如果没有指定 parittion replicas 分配的话，将会调用 <code>AdminUtils.createTopic</code> 方法创建 topic，这个方法首先会检测当前的 Kafka 集群是否机架感知，如果有的话先获取 Broker 的机架信息，接着再使用 Replica 自动分配算法来分配 Partition 的 replica，最后就跟指定 replica 方式一样，将 replicas 的结果更新到 zk 中。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">createTopic</span></span>(zkUtils: <span class="type">ZkUtils</span>,</div><div class="line">                topic: <span class="type">String</span>,</div><div class="line">                partitions: <span class="type">Int</span>,</div><div class="line">                replicationFactor: <span class="type">Int</span>,</div><div class="line">                topicConfig: <span class="type">Properties</span> = <span class="keyword">new</span> <span class="type">Properties</span>,</div><div class="line">                rackAwareMode: <span class="type">RackAwareMode</span> = <span class="type">RackAwareMode</span>.<span class="type">Enforced</span>) &#123;</div><div class="line">  <span class="keyword">val</span> brokerMetadatas = getBrokerMetadatas(zkUtils, rackAwareMode)<span class="comment">//note: 有机架感知的情况下,返回 Broker 与机架之间的信息</span></div><div class="line">  <span class="keyword">val</span> replicaAssignment = <span class="type">AdminUtils</span>.assignReplicasToBrokers(brokerMetadatas, partitions, replicationFactor)<span class="comment">//note: 获取 partiiton 的 replicas 分配</span></div><div class="line">  <span class="type">AdminUtils</span>.createOrUpdateTopicPartitionAssignmentPathInZK(zkUtils, topic, replicaAssignment, topicConfig)<span class="comment">//note: 更新到 zk 上</span></div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h3 id="Producer-创建-topic"><a href="#Producer-创建-topic" class="headerlink" title="Producer 创建 topic"></a>Producer 创建 topic</h3><p>只有当 Server 端的 <code>auto.create.topics.enable</code> 设置为 true 时，Producer 向一个不存在的 topic 发送数据，该 topic 才会被自动创建。</p>
<p>当 Producer 在向一个 topic 发送 produce 请求前，会先通过发送 Metadata 请求来获取这个 topic 的 metadata。Server 端在处理 Metadata 请求时，如果发现要获取 metadata 的 topic 不存在但 Server 允许 producer 自动创建 topic 的话（如果开启权限时，要求 Producer 需要有相应权限：对 topic 有 Describe 权限，并且对当前集群有 Create 权限），那么 Server 将会自动创建该 topic.</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//note: 获取 topic 的 metadata 信息</span></div><div class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">getTopicMetadata</span></span>(topics: <span class="type">Set</span>[<span class="type">String</span>], listenerName: <span class="type">ListenerName</span>, errorUnavailableEndpoints: <span class="type">Boolean</span>): <span class="type">Seq</span>[<span class="type">MetadataResponse</span>.<span class="type">TopicMetadata</span>] = &#123;</div><div class="line">  <span class="keyword">val</span> topicResponses = metadataCache.getTopicMetadata(topics, listenerName, errorUnavailableEndpoints)</div><div class="line">  <span class="keyword">if</span> (topics.isEmpty || topicResponses.size == topics.size) &#123;</div><div class="line">    topicResponses</div><div class="line">  &#125; <span class="keyword">else</span> &#123;</div><div class="line">    <span class="keyword">val</span> nonExistentTopics = topics -- topicResponses.map(_.topic).toSet<span class="comment">//note: 集群上暂时不存在的 topic 列表</span></div><div class="line">    <span class="keyword">val</span> responsesForNonExistentTopics = nonExistentTopics.map &#123; topic =&gt;</div><div class="line">      <span class="keyword">if</span> (topic == <span class="type">Topic</span>.<span class="type">GroupMetadataTopicName</span>) &#123;</div><div class="line">        createGroupMetadataTopic()</div><div class="line">      &#125; <span class="keyword">else</span> <span class="keyword">if</span> (config.autoCreateTopicsEnable) &#123;<span class="comment">//note: auto.create.topics.enable 为 true 时,即允许自动创建 topic</span></div><div class="line">        createTopic(topic, config.numPartitions, config.defaultReplicationFactor)</div><div class="line">      &#125; <span class="keyword">else</span> &#123;</div><div class="line">        <span class="keyword">new</span> <span class="type">MetadataResponse</span>.<span class="type">TopicMetadata</span>(<span class="type">Errors</span>.<span class="type">UNKNOWN_TOPIC_OR_PARTITION</span>, topic, <span class="literal">false</span>,</div><div class="line">          java.util.<span class="type">Collections</span>.emptyList())</div><div class="line">      &#125;</div><div class="line">    &#125;</div><div class="line">    topicResponses ++ responsesForNonExistentTopics</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>其中 <code>createTopic</code> 还是调用了 <code>AdminUtils.createTopic</code> 来创建 topic，与命令行创建的底层实现是一样。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">createTopic</span></span>(topic: <span class="type">String</span>,</div><div class="line">                        numPartitions: <span class="type">Int</span>,</div><div class="line">                        replicationFactor: <span class="type">Int</span>,</div><div class="line">                        properties: <span class="type">Properties</span> = <span class="keyword">new</span> <span class="type">Properties</span>()): <span class="type">MetadataResponse</span>.<span class="type">TopicMetadata</span> = &#123;</div><div class="line">  <span class="keyword">try</span> &#123;</div><div class="line">    <span class="comment">//note: 还是调用 AdminUtils 命令创建 topic</span></div><div class="line">    <span class="type">AdminUtils</span>.createTopic(zkUtils, topic, numPartitions, replicationFactor, properties, <span class="type">RackAwareMode</span>.<span class="type">Safe</span>)</div><div class="line">    info(<span class="string">"Auto creation of topic %s with %d partitions and replication factor %d is successful"</span></div><div class="line">      .format(topic, numPartitions, replicationFactor))</div><div class="line">    <span class="keyword">new</span> <span class="type">MetadataResponse</span>.<span class="type">TopicMetadata</span>(<span class="type">Errors</span>.<span class="type">LEADER_NOT_AVAILABLE</span>, topic, <span class="type">Topic</span>.isInternal(topic),</div><div class="line">      java.util.<span class="type">Collections</span>.emptyList())</div><div class="line">  &#125; <span class="keyword">catch</span> &#123;</div><div class="line">    <span class="keyword">case</span> _: <span class="type">TopicExistsException</span> =&gt; <span class="comment">// let it go, possibly another broker created this topic</span></div><div class="line">      <span class="keyword">new</span> <span class="type">MetadataResponse</span>.<span class="type">TopicMetadata</span>(<span class="type">Errors</span>.<span class="type">LEADER_NOT_AVAILABLE</span>, topic, <span class="type">Topic</span>.isInternal(topic),</div><div class="line">        java.util.<span class="type">Collections</span>.emptyList())</div><div class="line">    <span class="keyword">case</span> ex: <span class="type">Throwable</span>  =&gt; <span class="comment">// Catch all to prevent unhandled errors</span></div><div class="line">      <span class="keyword">new</span> <span class="type">MetadataResponse</span>.<span class="type">TopicMetadata</span>(<span class="type">Errors</span>.forException(ex), topic, <span class="type">Topic</span>.isInternal(topic),</div><div class="line">        java.util.<span class="type">Collections</span>.emptyList())</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h2 id="replica-如何分配"><a href="#replica-如何分配" class="headerlink" title="replica 如何分配"></a>replica 如何分配</h2><p>通过前面的内容，可以看到，无论使用哪种方式，最后都是通过 <code>AdminUtils.createOrUpdateTopicPartitionAssignmentPathInZK()</code> 将 topic 的 Partition replicas 的更新到 zk 上，这中间关键的一点在于：Partition 的 replicas 是如何分配的。在创建时，我们既可以指定相应 replicas 分配，也可以使用默认的算法自动分配。</p>
<h3 id="创建时指定-replicas-分配"><a href="#创建时指定-replicas-分配" class="headerlink" title="创建时指定 replicas 分配"></a>创建时指定 replicas 分配</h3><p>在创建 topic 时，可以通过以下形式直接指定 topic 的 replica</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">./bin/kafka-topics.sh --create --topic <span class="built_in">test</span> --zookeeper XXXX --replica-assignment 1:2,3:4,5:6</div></pre></td></tr></table></figure>
<p>该 topic 有三个 partition，其中，partition 0 的 replica 分布在1和2上，partition 1 的 replica 分布在3和4上，partition 3 的 replica 分布在4和5上。</p>
<p>这样情况下，在创建 topic 时，Server 端会将该 replica 分布直接更新到 zk 上。</p>
<h3 id="replicas-自动分配算法"><a href="#replicas-自动分配算法" class="headerlink" title="replicas 自动分配算法"></a>replicas 自动分配算法</h3><p>在创建 topic 时，Server 通过 <code>AdminUtils.assignReplicasToBrokers()</code> 方法来获取该 topic partition 的 replicas 分配。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/**</span></div><div class="line">   * 副本分配时,有三个原则:</div><div class="line">   * 1. 将副本平均分布在所有的 Broker 上;</div><div class="line">   * 2. partition 的多个副本应该分配在不同的 Broker 上;</div><div class="line">   * 3. 如果所有的 Broker 有机架信息的话, partition 的副本应该分配到不同的机架上。</div><div class="line">   *</div><div class="line">   * 为实现上面的目标,在没有机架感知的情况下，应该按照下面两个原则分配 replica:</div><div class="line">   * 1. 从 broker.list 随机选择一个 Broker,使用 round-robin 算法分配每个 partition 的第一个副本;</div><div class="line">   * 2. 对于这个 partition 的其他副本,逐渐增加 Broker.id 来选择 replica 的分配。</div><div class="line">   *</div><div class="line">   * @param brokerMetadatas</div><div class="line">   * @param nPartitions</div><div class="line">   * @param replicationFactor</div><div class="line">   * @param fixedStartIndex</div><div class="line">   * @param startPartitionId</div><div class="line">   * @return</div><div class="line">   */</div><div class="line"> <span class="function"><span class="keyword">def</span> <span class="title">assignReplicasToBrokers</span></span>(brokerMetadatas: <span class="type">Seq</span>[<span class="type">BrokerMetadata</span>],</div><div class="line">                             nPartitions: <span class="type">Int</span>,</div><div class="line">                             replicationFactor: <span class="type">Int</span>,</div><div class="line">                             fixedStartIndex: <span class="type">Int</span> = <span class="number">-1</span>,</div><div class="line">                             startPartitionId: <span class="type">Int</span> = <span class="number">-1</span>): <span class="type">Map</span>[<span class="type">Int</span>, <span class="type">Seq</span>[<span class="type">Int</span>]] = &#123;</div><div class="line">   <span class="keyword">if</span> (nPartitions &lt;= <span class="number">0</span>) <span class="comment">// note: 要增加的 partition 数需要大于0</span></div><div class="line">     <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">InvalidPartitionsException</span>(<span class="string">"number of partitions must be larger than 0"</span>)</div><div class="line">   <span class="keyword">if</span> (replicationFactor &lt;= <span class="number">0</span>) <span class="comment">//note: replicas 应该大于0</span></div><div class="line">     <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">InvalidReplicationFactorException</span>(<span class="string">"replication factor must be larger than 0"</span>)</div><div class="line">   <span class="keyword">if</span> (replicationFactor &gt; brokerMetadatas.size) <span class="comment">//note: replicas 超过了 broker 数</span></div><div class="line">     <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">InvalidReplicationFactorException</span>(<span class="string">s"replication factor: <span class="subst">$replicationFactor</span> larger than available brokers: <span class="subst">$&#123;brokerMetadatas.size&#125;</span>"</span>)</div><div class="line">   <span class="keyword">if</span> (brokerMetadatas.forall(_.rack.isEmpty))<span class="comment">//note: 没有开启机架感知</span></div><div class="line">     assignReplicasToBrokersRackUnaware(nPartitions, replicationFactor, brokerMetadatas.map(_.id), fixedStartIndex,</div><div class="line">       startPartitionId)</div><div class="line">   <span class="keyword">else</span> &#123; <span class="comment">//note: 机架感知的情况</span></div><div class="line">     <span class="keyword">if</span> (brokerMetadatas.exists(_.rack.isEmpty)) <span class="comment">//note: 并不是所有的机架都有机架感知</span></div><div class="line">       <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">AdminOperationException</span>(<span class="string">"Not all brokers have rack information for replica rack aware assignment"</span>)</div><div class="line">     assignReplicasToBrokersRackAware(nPartitions, replicationFactor, brokerMetadatas, fixedStartIndex,</div><div class="line">       startPartitionId)</div><div class="line">   &#125;</div><div class="line"> &#125;</div></pre></td></tr></table></figure>
<p>这里没有开启机架感知模式来介绍 topic partition replicas 的分配情况，其分配算法主要是 <code>assignReplicasToBrokersRackUnaware()</code> 方法中实现。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//note: partition 分配</span></div><div class="line"> <span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">assignReplicasToBrokersRackUnaware</span></span>(nPartitions: <span class="type">Int</span>,</div><div class="line">                                                replicationFactor: <span class="type">Int</span>,</div><div class="line">                                                brokerList: <span class="type">Seq</span>[<span class="type">Int</span>],</div><div class="line">                                                fixedStartIndex: <span class="type">Int</span>,</div><div class="line">                                                startPartitionId: <span class="type">Int</span>): <span class="type">Map</span>[<span class="type">Int</span>, <span class="type">Seq</span>[<span class="type">Int</span>]] = &#123;</div><div class="line">   <span class="keyword">val</span> ret = mutable.<span class="type">Map</span>[<span class="type">Int</span>, <span class="type">Seq</span>[<span class="type">Int</span>]]()</div><div class="line">   <span class="keyword">val</span> brokerArray = brokerList.toArray</div><div class="line">   <span class="keyword">val</span> startIndex = <span class="keyword">if</span> (fixedStartIndex &gt;= <span class="number">0</span>) fixedStartIndex <span class="keyword">else</span> rand.nextInt(brokerArray.length) <span class="comment">//note: 随机选择一个Broker</span></div><div class="line">   <span class="keyword">var</span> currentPartitionId = math.max(<span class="number">0</span>, startPartitionId) <span class="comment">//note: 开始增加的第一个 partition</span></div><div class="line">   <span class="keyword">var</span> nextReplicaShift = <span class="keyword">if</span> (fixedStartIndex &gt;= <span class="number">0</span>) fixedStartIndex <span class="keyword">else</span> rand.nextInt(brokerArray.length)</div><div class="line">   <span class="keyword">for</span> (_ &lt;- <span class="number">0</span> until nPartitions) &#123; <span class="comment">//note: 对每个 partition 进行分配</span></div><div class="line">     <span class="keyword">if</span> (currentPartitionId &gt; <span class="number">0</span> &amp;&amp; (currentPartitionId % brokerArray.length == <span class="number">0</span>))</div><div class="line">       nextReplicaShift += <span class="number">1</span> <span class="comment">//note: 防止 partition 过大时,其中某些 partition 的分配（leader、follower）完全一样</span></div><div class="line">     <span class="keyword">val</span> firstReplicaIndex = (currentPartitionId + startIndex) % brokerArray.length <span class="comment">//note: partition 的第一个 replica</span></div><div class="line">     <span class="keyword">val</span> replicaBuffer = mutable.<span class="type">ArrayBuffer</span>(brokerArray(firstReplicaIndex))</div><div class="line">     <span class="keyword">for</span> (j &lt;- <span class="number">0</span> until replicationFactor - <span class="number">1</span>) <span class="comment">//note: 其他 replica 的分配</span></div><div class="line">       replicaBuffer += brokerArray(replicaIndex(firstReplicaIndex, nextReplicaShift, j, brokerArray.length))</div><div class="line">     ret.put(currentPartitionId, replicaBuffer)</div><div class="line">     currentPartitionId += <span class="number">1</span></div><div class="line">   &#125;</div><div class="line">   ret</div><div class="line"> &#125;</div><div class="line"></div><div class="line"> <span class="comment">//note: 为 partition 设置完第一个 replica 后,其他 replica 分配的计算</span></div><div class="line"> <span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">replicaIndex</span></span>(firstReplicaIndex: <span class="type">Int</span>, secondReplicaShift: <span class="type">Int</span>, replicaIndex: <span class="type">Int</span>, nBrokers: <span class="type">Int</span>): <span class="type">Int</span> = &#123;</div><div class="line">   <span class="keyword">val</span> shift = <span class="number">1</span> + (secondReplicaShift + replicaIndex) % (nBrokers - <span class="number">1</span>)<span class="comment">//note: 在 secondReplicaShift 的基础上增加一个 replicaIndex</span></div><div class="line">   (firstReplicaIndex + shift) % nBrokers</div><div class="line"> &#125;</div></pre></td></tr></table></figure>
<p>这里举一个栗子，假设一个 Kafka 集群有5个节点，新建的 topic 有10个 partition，并且是三副本，假设最初随机选择的 <code>startIndex</code> 和 <code>nextReplicaShift</code> 节点均为0</p>
<ul>
<li>partition 为0时，那第一副本在 <code>(0+0)%5=0</code>，第二个副本在 <code>(0+(1+(0+0)%4)))%5=1</code>，第三副本在 <code>(0+(1+(0+1)%4)))%5=2</code>；</li>
<li>partition 为2时，那第一副本在 <code>(0+2)%5=2</code>，第二个副本在 <code>(2+(1+(0+0)%4)))%5=3</code>，第三副本在 <code>(2+(1+(0+1)%4)))%5=4</code>；</li>
<li>partition 为5时，那第一副本在 <code>(0+5)%5=0</code>，第二个副本在 <code>(0+(1+(1+0)%4)))%5=2</code>，第三副本在 <code>(0+(1+(1+1)%4)))%5=3</code>（partition 数是 Broker 数一倍时，<code>nextReplicaShift</code> 值会增加1）；</li>
<li>partition 为8时，那第一副本在 <code>(0+8)%5=3</code>，第二个副本在 <code>(3+(1+(1+0)%4)))%5=0</code>，第三副本在 <code>(3+(1+(1+1)%4)))%5=1</code>。</li>
</ul>
<p>分配如下表所示：</p>
<table>
<thead>
<tr>
<th>broker-0</th>
<th>broker-1</th>
<th>broker-2</th>
<th>broker-3</th>
<th>broker-4</th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td>p0</td>
<td>p1</td>
<td>p2</td>
<td>p3</td>
<td>p4</td>
<td>(1st replica)</td>
</tr>
<tr>
<td>p5</td>
<td>p6</td>
<td>p7</td>
<td>p8</td>
<td>p9</td>
<td>(1st replica)</td>
</tr>
<tr>
<td>p4</td>
<td>p0</td>
<td>p1</td>
<td>p2</td>
<td>p3</td>
<td>(2nd replica)</td>
</tr>
<tr>
<td>p8</td>
<td>p9</td>
<td>p5</td>
<td>p6</td>
<td>p7</td>
<td>(2nd replica)</td>
</tr>
<tr>
<td>p3</td>
<td>p4</td>
<td>p0</td>
<td>p1</td>
<td>p2</td>
<td>(3nd replica)</td>
</tr>
<tr>
<td>p7</td>
<td>p8</td>
<td>p9</td>
<td>p5</td>
<td>p6</td>
<td>(3nd replica)</td>
</tr>
</tbody>
</table>
<h2 id="replicas-更新到-zk-后触发的操作"><a href="#replicas-更新到-zk-后触发的操作" class="headerlink" title="replicas 更新到 zk 后触发的操作"></a>replicas 更新到 zk 后触发的操作</h2><p>这一部分的内容是由 Kafka Controller 来控制的（Kafka Controller 将会在后续文章中讲解），当一个 topic 的 replicas 更新到 zk 上后，监控 zk 这个目录的方法会被触发（<code>TopicChangeListener.doHandleChildChange()</code>方法），可以配合文章第一张图来看。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//note: 当 zk 上 topic 节点上有变更时,这个方法就会调用</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">doHandleChildChange</span></span>(parentPath: <span class="type">String</span>, children: <span class="type">Seq</span>[<span class="type">String</span>]) &#123;</div><div class="line">      inLock(controllerContext.controllerLock) &#123;</div><div class="line">        <span class="keyword">if</span> (hasStarted.get) &#123;</div><div class="line">          <span class="keyword">try</span> &#123;</div><div class="line">            <span class="keyword">val</span> currentChildren = &#123;</div><div class="line">              debug(<span class="string">"Topic change listener fired for path %s with children %s"</span>.format(parentPath, children.mkString(<span class="string">","</span>)))</div><div class="line">              children.toSet</div><div class="line">            &#125;</div><div class="line">            <span class="keyword">val</span> newTopics = currentChildren -- controllerContext.allTopics<span class="comment">//note: 新创建的 topic 列表</span></div><div class="line">            <span class="keyword">val</span> deletedTopics = controllerContext.allTopics -- currentChildren<span class="comment">//note: 已经删除的 topic 列表</span></div><div class="line">            controllerContext.allTopics = currentChildren</div><div class="line"></div><div class="line">            <span class="comment">//note: 新创建 topic 对应的 partition 列表</span></div><div class="line">            <span class="keyword">val</span> addedPartitionReplicaAssignment = zkUtils.getReplicaAssignmentForTopics(newTopics.toSeq)</div><div class="line">            controllerContext.partitionReplicaAssignment = controllerContext.partitionReplicaAssignment.filter(p =&gt;</div><div class="line">              !deletedTopics.contains(p._1.topic))<span class="comment">//note: 把已经删除 partition 过滤掉</span></div><div class="line">            controllerContext.partitionReplicaAssignment.++=(addedPartitionReplicaAssignment)<span class="comment">//note: 将新增的 tp-replicas 更新到缓存中</span></div><div class="line">            info(<span class="string">"New topics: [%s], deleted topics: [%s], new partition replica assignment [%s]"</span>.format(newTopics,</div><div class="line">              deletedTopics, addedPartitionReplicaAssignment))</div><div class="line">            <span class="keyword">if</span> (newTopics.nonEmpty)<span class="comment">//note: 处理新建的 topic</span></div><div class="line">              controller.onNewTopicCreation(newTopics, addedPartitionReplicaAssignment.keySet)</div><div class="line">          &#125; <span class="keyword">catch</span> &#123;</div><div class="line">            <span class="keyword">case</span> e: <span class="type">Throwable</span> =&gt; error(<span class="string">"Error while handling new topic"</span>, e)</div><div class="line">          &#125;</div><div class="line">        &#125;</div><div class="line">      &#125;</div><div class="line">    &#125;</div></pre></td></tr></table></figure>
<p>这个方法主要做了以下内容：</p>
<ul>
<li>获取 zk 的 topic 变更信息，得到新创建的 topic 列表（<code>newTopics</code>）以及被删除的 topic 列表（<code>deletedTopics</code>）；</li>
<li>将 <code>deletedTopics</code> 的 replicas 从 controller 的缓存中删除，并将新增 topic 的 replicas 更新到 controller 的缓存中；</li>
<li>调用 KafkaController 的 <code>onNewTopicCreation()</code> 创建 partition 和 replica 对象。</li>
</ul>
<p>KafkaController 中 <code>onNewTopicCreation()</code> 方法先对这些 topic 注册 <code>PartitionChangeListener</code>，然后再调用 <code>onNewPartitionCreation()</code> 方法创建 partition 和 replicas 的实例对象，<strong>topic 创建的主要实现是在 KafkaController <code>onNewPartitionCreation()</code> 这个方法中</strong>。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//note: 当 partition state machine 监控到有新 topic 或 partition 时,这个方法将会被调用</span></div><div class="line"> <span class="comment">/**</span></div><div class="line">   * 1. 注册 partition change listener;</div><div class="line">   * 2. 触发 the new partition callback,也即是 onNewPartitionCreation()</div><div class="line">   * 3. 发送 metadata 请求给所有的 Broker</div><div class="line">   * @param topics</div><div class="line">   * @param newPartitions</div><div class="line">   */</div><div class="line"> <span class="function"><span class="keyword">def</span> <span class="title">onNewTopicCreation</span></span>(topics: <span class="type">Set</span>[<span class="type">String</span>], newPartitions: <span class="type">Set</span>[<span class="type">TopicAndPartition</span>]) &#123;</div><div class="line">   info(<span class="string">"New topic creation callback for %s"</span>.format(newPartitions.mkString(<span class="string">","</span>)))</div><div class="line">   <span class="comment">// subscribe to partition changes</span></div><div class="line">   topics.foreach(topic =&gt; partitionStateMachine.registerPartitionChangeListener(topic))</div><div class="line">   onNewPartitionCreation(newPartitions)</div><div class="line"> &#125;</div><div class="line"></div><div class="line"> <span class="comment">//note: topic 变化时,这个方法将会被调用</span></div><div class="line"> <span class="comment">//note: 1. 将新创建的 partition 置为 NewPartition 状态; 2.从 NewPartition 改为 OnlinePartition 状态</span></div><div class="line"> <span class="comment">//note: 1. 将新创建的 Replica 置为 NewReplica 状态; 2.从 NewReplica 改为 OnlineReplica 状态</span></div><div class="line"> <span class="function"><span class="keyword">def</span> <span class="title">onNewPartitionCreation</span></span>(newPartitions: <span class="type">Set</span>[<span class="type">TopicAndPartition</span>]) &#123;</div><div class="line">   info(<span class="string">"New partition creation callback for %s"</span>.format(newPartitions.mkString(<span class="string">","</span>)))</div><div class="line">   partitionStateMachine.handleStateChanges(newPartitions, <span class="type">NewPartition</span>)</div><div class="line">   replicaStateMachine.handleStateChanges(controllerContext.replicasForPartition(newPartitions), <span class="type">NewReplica</span>)</div><div class="line">   partitionStateMachine.handleStateChanges(newPartitions, <span class="type">OnlinePartition</span>, offlinePartitionSelector)</div><div class="line">   replicaStateMachine.handleStateChanges(controllerContext.replicasForPartition(newPartitions), <span class="type">OnlineReplica</span>)</div><div class="line"> &#125;</div></pre></td></tr></table></figure>
<p>在详细介绍这四个方法的调用之前，先简单详述一下 Partition 和 Replica 状态机的变化。</p>
<h3 id="Partition-状态机"><a href="#Partition-状态机" class="headerlink" title="Partition 状态机"></a>Partition 状态机</h3><p>关于 Partition 状态的变化可以参考 Kafka 中的这个方法 <a href="https://github.com/apache/kafka/blob/0.10.2/core/src/main/scala/kafka/controller/PartitionStateMachine.scala" target="_blank" rel="external">PartitionStateMachine</a>，状态机的具体转换情况如下图所示</p>
<p><img src="/images/kafka/partition_state.png" alt="Partition 状态机"></p>
<p>一个 Partition 对象有四种状态：</p>
<ol>
<li><code>NonExistentPartition</code>：这个 partition 不存在；</li>
<li><code>NewPartition</code>：这个 partition 刚创建，有对应的 replicas，但还没有 leader 和 isr；</li>
<li><code>OnlinePartition</code>：这个 partition 的 leader 已经选举出来了，处理正常的工作状态；</li>
<li><code>OfflinePartition</code>：partition 的 leader 挂了。</li>
</ol>
<p>partition 只有在 <code>OnlinePartition</code> 这个状态时，才是可用状态。</p>
<h3 id="Replica-状态机"><a href="#Replica-状态机" class="headerlink" title="Replica 状态机"></a>Replica 状态机</h3><p>关于 Replica 状态的变化可以参考 Kafka 中的这个方法 <a href="https://github.com/apache/kafka/blob/0.10.2/core/src/main/scala/kafka/controller/ReplicaStateMachine.scala" target="_blank" rel="external">ReplicaStateMachine</a>，，状态机的具体转换情况如下图所示</p>
<p><img src="/images/kafka/replica_state.png" alt="Replica 状态机"></p>
<p>Replica 对象有七种状态，中文解释的比较难以理解，直接上原文对这几种状态的解释。</p>
<ol>
<li><code>NewReplica</code>：The controller can create new replicas during partition reassignment. In this state, a replica can only get become follower state change request.</li>
<li><code>OnlineReplica</code>：Once a replica is started and part of the assigned replicas for its partition, it is in this state. In this state, it can get either become leader or become follower state change requests.</li>
<li><code>OfflineReplica</code>：If a replica dies, it moves to this state. This happens when the broker hosting the replica is down.</li>
<li><code>ReplicaDeletionStarted</code>：If replica deletion starts, it is moved to this state.</li>
<li><code>ReplicaDeletionSuccessful</code>：If replica responds with no error code in response to a delete replica request, it is moved to this state.</li>
<li><code>ReplicaDeletionIneligible</code>：If replica deletion fails, it is moved to this state.</li>
<li><code>NonExistentReplica</code>：If a replica is deleted successfully, it is moved to this state.</li>
</ol>
<h3 id="onNewPartitionCreation-详解"><a href="#onNewPartitionCreation-详解" class="headerlink" title="onNewPartitionCreation() 详解"></a><code>onNewPartitionCreation()</code> 详解</h3><p>这个方法有以下四步操作：</p>
<ol>
<li><code>partitionStateMachine.handleStateChanges(newPartitions, NewPartition)</code>： 创建 Partition 对象，并将其状态置为 <code>NewPartition</code> 状态</li>
<li><code>replicaStateMachine.handleStateChanges(controllerContext.replicasForPartition(newPartitions), NewReplica)</code>：创建 Replica 对象，并将其状态置为 <code>NewReplica</code> 状态；</li>
<li><code>partitionStateMachine.handleStateChanges(newPartitions, OnlinePartition, offlinePartitionSelector)</code>：将 partition 对象从 <code>NewPartition</code> 改为 <code>OnlinePartition</code> 状态；</li>
<li><code>replicaStateMachine.handleStateChanges(controllerContext.replicasForPartition(newPartitions), OnlineReplica)</code>：将 Replica 对象从 <code>NewReplica</code> 改为 <code>OnlineReplica</code> 状态。</li>
</ol>
<h4 id="partitionStateMachine-gt-NewPartition"><a href="#partitionStateMachine-gt-NewPartition" class="headerlink" title="partitionStateMachine &gt; NewPartition"></a>partitionStateMachine &gt; NewPartition</h4><p>这部分的作用是，创建分区对象，并将其状态设置为 <code>NewPartition</code>。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">case</span> <span class="type">NewPartition</span> =&gt;</div><div class="line">  <span class="comment">//note: 新建一个 partition</span></div><div class="line">  assertValidPreviousStates(topicAndPartition, <span class="type">List</span>(<span class="type">NonExistentPartition</span>), <span class="type">NewPartition</span>)</div><div class="line">  partitionState.put(topicAndPartition, <span class="type">NewPartition</span>) <span class="comment">//note: 缓存 partition 的状态</span></div><div class="line">  <span class="keyword">val</span> assignedReplicas = controllerContext.partitionReplicaAssignment(topicAndPartition).mkString(<span class="string">","</span>)</div><div class="line">  stateChangeLogger.trace(<span class="string">"Controller %d epoch %d changed partition %s state from %s to %s with assigned replicas %s"</span></div><div class="line">                            .format(controllerId, controller.epoch, topicAndPartition, currState, targetState,</div><div class="line">                                    assignedReplicas))</div></pre></td></tr></table></figure>
<h4 id="replicaStateMachine-gt-NewReplica"><a href="#replicaStateMachine-gt-NewReplica" class="headerlink" title="replicaStateMachine &gt; NewReplica"></a>replicaStateMachine &gt; NewReplica</h4><p>这部分是为每个 Partition 创建对应的 replica 对象，并将其状态设置为 <code>NewReplica</code>，参照状态机的变化图更好理解。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">case</span> <span class="type">NewReplica</span> =&gt;</div><div class="line">          assertValidPreviousStates(partitionAndReplica, <span class="type">List</span>(<span class="type">NonExistentReplica</span>), targetState)  <span class="comment">//note: 验证</span></div><div class="line">          <span class="comment">// start replica as a follower to the current leader for its partition</span></div><div class="line">          <span class="keyword">val</span> leaderIsrAndControllerEpochOpt = <span class="type">ReplicationUtils</span>.getLeaderIsrAndEpochForPartition(zkUtils, topic, partition)</div><div class="line">          leaderIsrAndControllerEpochOpt <span class="keyword">match</span> &#123;</div><div class="line">            <span class="keyword">case</span> <span class="type">Some</span>(leaderIsrAndControllerEpoch) =&gt;</div><div class="line">              <span class="keyword">if</span>(leaderIsrAndControllerEpoch.leaderAndIsr.leader == replicaId)<span class="comment">//note: 这个状态的 Replica 不能作为 leader</span></div><div class="line">                <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">StateChangeFailedException</span>(<span class="string">"Replica %d for partition %s cannot be moved to NewReplica"</span></div><div class="line">                  .format(replicaId, topicAndPartition) + <span class="string">"state as it is being requested to become leader"</span>)</div><div class="line">              <span class="comment">//note: 向所有 replicaId 发送 LeaderAndIsr 请求,这个方法同时也会向所有的 broker 发送 updateMeta 请求</span></div><div class="line">              brokerRequestBatch.addLeaderAndIsrRequestForBrokers(<span class="type">List</span>(replicaId),</div><div class="line">                                                                  topic, partition, leaderIsrAndControllerEpoch,</div><div class="line">                                                                  replicaAssignment)</div><div class="line">            <span class="keyword">case</span> <span class="type">None</span> =&gt; <span class="comment">// new leader request will be sent to this replica when one gets elected</span></div></pre></td></tr></table></figure>
<h4 id="partitionStateMachine-gt-OnlinePartition"><a href="#partitionStateMachine-gt-OnlinePartition" class="headerlink" title="partitionStateMachine &gt; OnlinePartition"></a>partitionStateMachine &gt; OnlinePartition</h4><p>这个方法的主要的作用是将 partition 对象的状态由 <code>NewPartition</code> 设置为 <code>OnlinePartition</code>，从状态机图中可以看到，会有以下两步操作：</p>
<ol>
<li>初始化 leader 和 isr，replicas 中的第一个 replica 将作为 leader，所有 replica 作为 isr，并把 leader 和 isr 信息更新到 zk；</li>
<li>发送 LeaderAndIsr 请求给所有的 replica，发送 UpdateMetadata 给所有 Broker。</li>
</ol>
<p>具体操作如下：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// post: partition has been assigned replicas</span></div><div class="line">       <span class="keyword">case</span> <span class="type">OnlinePartition</span> =&gt;</div><div class="line">         assertValidPreviousStates(topicAndPartition, <span class="type">List</span>(<span class="type">NewPartition</span>, <span class="type">OnlinePartition</span>, <span class="type">OfflinePartition</span>), <span class="type">OnlinePartition</span>)</div><div class="line">         partitionState(topicAndPartition) <span class="keyword">match</span> &#123;</div><div class="line">           <span class="keyword">case</span> <span class="type">NewPartition</span> =&gt;</div><div class="line">             <span class="comment">// initialize leader and isr path for new partition</span></div><div class="line">             initializeLeaderAndIsrForPartition(topicAndPartition) <span class="comment">//note: 为新建的 partition 初始化 leader 和 isr</span></div><div class="line">           <span class="keyword">case</span> <span class="type">OfflinePartition</span> =&gt;</div><div class="line">             electLeaderForPartition(topic, partition, leaderSelector)</div><div class="line">           <span class="keyword">case</span> <span class="type">OnlinePartition</span> =&gt; <span class="comment">// invoked when the leader needs to be re-elected</span></div><div class="line">             electLeaderForPartition(topic, partition, leaderSelector)</div><div class="line">           <span class="keyword">case</span> _ =&gt; <span class="comment">// should never come here since illegal previous states are checked above</span></div><div class="line">         &#125;</div></pre></td></tr></table></figure>
<p>实际的操作是在 <code>initializeLeaderAndIsrForPartition()</code> 方法中完成，这个方法是当 partition 对象的状态由 NewPartition 变为 OnlinePartition 时触发的，用来初始化该 partition 的 leader 和 isr。简单来说，就是选取 Replicas 中的第一个 Replica 作为 leader，所有的 Replica 作为 isr，最后调用 <code>brokerRequestBatch.addLeaderAndIsrRequestForBrokers</code> 向所有 replicaId 发送 LeaderAndIsr 请求以及向所有的 broker 发送 UpdateMetadata 请求（关于 Server 对 LeaderAndIsr 和 UpdateMetadata 请求的处理将会后续文章中讲述）。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//note: 当 partition 状态由 NewPartition 变为 OnlinePartition 时,将触发这一方法,用来初始化 partition 的 leader 和 isr</span></div><div class="line"> <span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">initializeLeaderAndIsrForPartition</span></span>(topicAndPartition: <span class="type">TopicAndPartition</span>) &#123;</div><div class="line">   <span class="keyword">val</span> replicaAssignment = controllerContext.partitionReplicaAssignment(topicAndPartition)</div><div class="line">   <span class="keyword">val</span> liveAssignedReplicas = replicaAssignment.filter(r =&gt; controllerContext.liveBrokerIds.contains(r))</div><div class="line">   liveAssignedReplicas.size <span class="keyword">match</span> &#123;</div><div class="line">     <span class="keyword">case</span> <span class="number">0</span> =&gt;</div><div class="line">       <span class="keyword">val</span> failMsg = (<span class="string">"encountered error during state change of partition %s from New to Online, assigned replicas are [%s], "</span> +</div><div class="line">                      <span class="string">"live brokers are [%s]. No assigned replica is alive."</span>)</div><div class="line">                        .format(topicAndPartition, replicaAssignment.mkString(<span class="string">","</span>), controllerContext.liveBrokerIds)</div><div class="line">       stateChangeLogger.error(<span class="string">"Controller %d epoch %d "</span>.format(controllerId, controller.epoch) + failMsg)</div><div class="line">       <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">StateChangeFailedException</span>(failMsg)</div><div class="line">     <span class="keyword">case</span> _ =&gt;</div><div class="line">       debug(<span class="string">"Live assigned replicas for partition %s are: [%s]"</span>.format(topicAndPartition, liveAssignedReplicas))</div><div class="line">       <span class="comment">// make the first replica in the list of assigned replicas, the leader</span></div><div class="line">       <span class="keyword">val</span> leader = liveAssignedReplicas.head <span class="comment">//note: replicas 中的第一个 replica 选做 leader</span></div><div class="line">       <span class="keyword">val</span> leaderIsrAndControllerEpoch = <span class="keyword">new</span> <span class="type">LeaderIsrAndControllerEpoch</span>(<span class="keyword">new</span> <span class="type">LeaderAndIsr</span>(leader, liveAssignedReplicas.toList),</div><div class="line">         controller.epoch)</div><div class="line">       debug(<span class="string">"Initializing leader and isr for partition %s to %s"</span>.format(topicAndPartition, leaderIsrAndControllerEpoch))</div><div class="line">       <span class="keyword">try</span> &#123;</div><div class="line">         zkUtils.createPersistentPath(</div><div class="line">           getTopicPartitionLeaderAndIsrPath(topicAndPartition.topic, topicAndPartition.partition),</div><div class="line">           zkUtils.leaderAndIsrZkData(leaderIsrAndControllerEpoch.leaderAndIsr, controller.epoch))<span class="comment">//note: zk 上初始化节点信息</span></div><div class="line">         <span class="comment">// <span class="doctag">NOTE:</span> the above write can fail only if the current controller lost its zk session and the new controller</span></div><div class="line">         <span class="comment">// took over and initialized this partition. This can happen if the current controller went into a long</span></div><div class="line">         <span class="comment">// GC pause</span></div><div class="line">         controllerContext.partitionLeadershipInfo.put(topicAndPartition, leaderIsrAndControllerEpoch)</div><div class="line">         brokerRequestBatch.addLeaderAndIsrRequestForBrokers(liveAssignedReplicas, topicAndPartition.topic,</div><div class="line">           topicAndPartition.partition, leaderIsrAndControllerEpoch, replicaAssignment)<span class="comment">//note: 向 live 的 Replica 发送  LeaderAndIsr 请求</span></div><div class="line">       &#125; <span class="keyword">catch</span> &#123;</div><div class="line">         <span class="keyword">case</span> _: <span class="type">ZkNodeExistsException</span> =&gt;</div><div class="line">           <span class="comment">// read the controller epoch</span></div><div class="line">           <span class="keyword">val</span> leaderIsrAndEpoch = <span class="type">ReplicationUtils</span>.getLeaderIsrAndEpochForPartition(zkUtils, topicAndPartition.topic,</div><div class="line">             topicAndPartition.partition).get</div><div class="line">           <span class="keyword">val</span> failMsg = (<span class="string">"encountered error while changing partition %s's state from New to Online since LeaderAndIsr path already "</span> +</div><div class="line">                          <span class="string">"exists with value %s and controller epoch %d"</span>)</div><div class="line">                            .format(topicAndPartition, leaderIsrAndEpoch.leaderAndIsr.toString(), leaderIsrAndEpoch.controllerEpoch)</div><div class="line">           stateChangeLogger.error(<span class="string">"Controller %d epoch %d "</span>.format(controllerId, controller.epoch) + failMsg)</div><div class="line">           <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">StateChangeFailedException</span>(failMsg)</div><div class="line">       &#125;</div><div class="line">   &#125;</div></pre></td></tr></table></figure>
<h4 id="replicaStateMachine-gt-OnlineReplica"><a href="#replicaStateMachine-gt-OnlineReplica" class="headerlink" title="replicaStateMachine &gt; OnlineReplica"></a>replicaStateMachine &gt; OnlineReplica</h4><p>这一步也就是最后一步，将 Replica 对象的状态由 <code>NewReplica</code> 更新为 <code>OnlineReplica</code> 状态，这些 Replica 才真正可用。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">case</span> <span class="type">OnlineReplica</span> =&gt;</div><div class="line">          assertValidPreviousStates(partitionAndReplica,</div><div class="line">            <span class="type">List</span>(<span class="type">NewReplica</span>, <span class="type">OnlineReplica</span>, <span class="type">OfflineReplica</span>, <span class="type">ReplicaDeletionIneligible</span>), targetState)</div><div class="line">          replicaState(partitionAndReplica) <span class="keyword">match</span> &#123;</div><div class="line">            <span class="keyword">case</span> <span class="type">NewReplica</span> =&gt;</div><div class="line">              <span class="comment">// add this replica to the assigned replicas list for its partition</span></div><div class="line">              <span class="comment">//note: 向 the assigned replicas list 添加这个 replica（正常情况下这些 replicas 已经更新到 list 中了）</span></div><div class="line">              <span class="keyword">val</span> currentAssignedReplicas = controllerContext.partitionReplicaAssignment(topicAndPartition)</div><div class="line">              <span class="keyword">if</span>(!currentAssignedReplicas.contains(replicaId))</div><div class="line">                controllerContext.partitionReplicaAssignment.put(topicAndPartition, currentAssignedReplicas :+ replicaId)</div><div class="line">              stateChangeLogger.trace(<span class="string">"Controller %d epoch %d changed state of replica %d for partition %s from %s to %s"</span></div><div class="line">                                        .format(controllerId, controller.epoch, replicaId, topicAndPartition, currState,</div><div class="line">                                                targetState))</div></pre></td></tr></table></figure>
<p>一直到这一步，一个 topic 就才算真正被创建完成。</p>
<hr>
<p>参考：</p>
<ul>
<li><a href="http://www.cnblogs.com/huxi2b/p/5923252.html" target="_blank" rel="external">Kafka如何创建topic？</a></li>
</ul>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[Linux 常用的一些系统命令]]></title>
      <url>http://matt33.com/2017/07/16/linux-system-cmd/</url>
      <content type="html"><![CDATA[<p>文章的内容，基本来自<a href="http://www.cnblogs.com/peida/tag/%E6%AF%8F%E6%97%A5%E4%B8%80linux%E5%91%BD%E4%BB%A4/" target="_blank" rel="external">每日一个 linux 命令</a>，选取了几个在工作常用的命令，有：top、iostat、netstat 、free 和 ps，本文的主要目的是在学习这几条命令的过程中，简单做一些记录，便于日后工作中更加熟练地使用这些命令。</p>
<h1 id="top"><a href="#top" class="headerlink" title="top"></a>top</h1><p>top 命令是 Linux 下面实时展示系统运行情况的一个命令，它也可以显示当前每个任务的系统信息。在对系统的性能进行分析，它是一个最常用的命令。</p>
<h2 id="命令常用参数"><a href="#命令常用参数" class="headerlink" title="命令常用参数"></a>命令常用参数</h2><ol>
<li>命令格式：<ul>
<li>top [参数]</li>
</ul>
</li>
<li>命令功能：<ul>
<li>显示当前系统正在执行的进程的相关信息，包括进程ID、内存占用率、CPU占用率等</li>
</ul>
</li>
<li>命令参数：<ul>
<li><code>-b</code>: 批处理</li>
<li><code>-c</code>: 显示完整的治命令</li>
<li><code>-I</code>: 忽略失效过程</li>
<li><code>-s</code>: 保密模式</li>
<li><code>-S</code>: 累积模式</li>
<li><code>-i&lt;时间&gt;</code>: 设置间隔时间</li>
<li><code>-u&lt;用户名&gt;</code>: 指定用户名</li>
<li><code>-p&lt;进程号&gt;</code>: 指定进程</li>
<li><code>-n&lt;次数&gt;</code>: 循环显示的次数</li>
</ul>
</li>
</ol>
<h2 id="显示说明"><a href="#显示说明" class="headerlink" title="显示说明"></a>显示说明</h2><p>在命令行输入 <code>top</code> 命令，终端会展示当前系统的信息，如下所示</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">[matt@XXX ~]$ top</div><div class="line">top - 21:04:19 up 129 days, 20:31,  1 user,  load average: 58.32, 57.85, 57.50</div><div class="line">Tasks: 589 total,   1 running, 584 sleeping,   0 stopped,   4 zombie</div><div class="line">Cpu(s): 22.3%us, 11.8%sy,  0.0%ni, 63.2%id,  0.2%wa,  0.0%hi,  2.5%si,  0.0%st</div><div class="line">Mem:  132103752k total, 122070628k used, 10033124k free,    42940k buffers</div><div class="line">Swap:        0k total,        0k used,        0k free, 58734284k cached</div><div class="line"></div><div class="line">   PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  COMMAND</div><div class="line"> 51179	matt   20   0 70.6g  24g  80m S 704.9 19.2  39244,38 java</div><div class="line">     1 root      20   0 1155m 1.1g  592 S  0.0  0.9   4020:57 init</div><div class="line">     2 root      20   0     0    0    0 S  0.0  0.0   0:00.01 kthreadd</div></pre></td></tr></table></figure>
<p>上面只是截取了部分的信息，这里介绍以下上面的一些信息的说明。上面的前五行是当前系统情况整体的统计信息区。</p>
<ol>
<li>任务的队列信息，同 uptime 命令的执行结果<ul>
<li><code>21:04:19</code>: 当前系统时间；</li>
<li><code>up 129 days, 20:31</code>: 系统已经运行了129天20小时31分钟（这期间系统没有重启）；</li>
<li><code>1 users</code>: 当前有1个用户登录系统；</li>
<li><code>load average: 58.32, 57.85, 57.50</code>: load average 后面的三个数分别是1分钟、5分钟、15分钟的负载情况（<strong>这个数除以逻辑 CPU 的数量，结果高于5的时候就表明系统在超负荷运转</strong>）</li>
</ul>
</li>
<li>Tasks — 任务（进程）的统计信息<ul>
<li>系统现在共有589个进程，其中处于运行中的有1个，584个在休眠（sleep），stoped 状态的有0个，zombie 状态（僵尸）的有4个；</li>
</ul>
</li>
<li>cpu 的状态信息<ul>
<li><code>22.3%us</code>: 用户空间占用 CPU 的百分比</li>
<li><code>11.8% sy</code>: 内核空间占用 CPU 的百分比</li>
<li><code>0.0% ni</code>: 改变过优先级的进程占用 CPU 的百分比</li>
<li><code>63.2% id</code>: 空闲 CPU 百分比</li>
<li><code>0.2% wa</code>: IO 等待占用 CPU 的百分比</li>
<li><code>0.0% hi</code>: 硬中断（Hardware IRQ）占用 CPU 的百分比</li>
<li><code>2.5% si</code>: 软中断（Software Interrupts）占用 CPU 的百分比</li>
<li><code>0.0% st</code>: 虚拟机占用的百分比</li>
</ul>
</li>
<li>内存的状态信息<ul>
<li><code>132103752k total</code>： 物理内存总量（128GB）</li>
<li><code>122070628k used</code>： 使用中的内存总量（118GB）</li>
<li><code>10033124k free</code>： 空闲内存总量（10GB）</li>
<li><code>42940k buffers</code>： 缓存的内存量 （42M）</li>
</ul>
</li>
<li>swap交换分区信息<ul>
<li><code>0k total</code>: 交换区总量（0K）</li>
<li><code>0k used</code>: 使用的交换区总量（0K）</li>
<li><code>0k free</code>: 空闲交换区总量（0K）</li>
<li><code>58734284k cached</code>: 缓冲的交换区总量（56GB）</li>
</ul>
</li>
<li>空行，作为系统信息与进程信息的分界线</li>
<li>各进程（任务）的状态监控<ul>
<li><code>PID</code>: 进程id</li>
<li><code>USER</code>: 进程所有者</li>
<li><code>PR</code>: 进程优先级</li>
<li><code>NI</code>: nice 值，负值表示高优先级，正值表示低优先级</li>
<li><code>VIRT</code>: 进程使用的虚拟内存总量，单位 kb。VIRT=SWAP+RES</li>
<li><code>RES</code>: 进程使用的、未被换出的物理内存大小，单位 kb。RES=CODE+DATA</li>
<li><code>SHR</code>: 共享内存大小，单位 kb</li>
<li><code>S</code>: 进程状态。D= 不可中断的睡眠状态 R= 运行 S= 睡眠 T= 跟踪/停止 Z= 僵尸进程</li>
<li><code>%CPU</code>: 上次更新到现在的CPU时间占用百分比</li>
<li><code>%MEM</code>: 进程使用的物理内存百分比</li>
<li><code>TIME+</code>: 进程使用的CPU时间总计，单位1/100秒</li>
<li><code>COMMAND</code>: 进程名称</li>
</ul>
</li>
</ol>
<p>其中，第四行中使用中的内存总量（used）指的是现在系统内核控制的内存数，空闲内存总量（free）是内核还未纳入其管控范围的数量。纳入内核管理的内存不见得都在使用中，还包括过去使用过的现在可以被重复利用的内存，内核并不把这些可被重新使用的内存交还到 free 中去，因此在 linux 上 free 内存会越来越少，但不用为此担心。</p>
<h2 id="常用命令"><a href="#常用命令" class="headerlink" title="常用命令"></a>常用命令</h2><p>在工作中，常用的几个命令在 <a href="http://www.cnblogs.com/peida/archive/2012/12/24/2831353.html" target="_blank" rel="external">每天一个linux命令（44）：top命令</a> 都已经介绍得比较全面了，这里，再简单重复一下。</p>
<h3 id="多-CPU-监控"><a href="#多-CPU-监控" class="headerlink" title="多 CPU 监控"></a>多 CPU 监控</h3><p>在 top 的基本视图中，按键盘数字<strong>1</strong>，可监控每个逻辑CPU的状况：</p>
<p><img src="/images/linux/top1.png" alt="TOP 多 CPU 监控"></p>
<h3 id="高亮显示当前进程"><a href="#高亮显示当前进程" class="headerlink" title="高亮显示当前进程"></a>高亮显示当前进程</h3><p>敲击键盘<strong>b</strong>（打开/关闭加亮效果），top 的视图变化如下（图来自<a href="http://www.cnblogs.com/peida/archive/2012/12/24/2831353.html" target="_blank" rel="external">每天一个linux命令（44）：top命令</a>）。</p>
<p><img src="/images/linux/top2.png" alt="TOP 高亮"></p>
<h3 id="进程字段排序"><a href="#进程字段排序" class="headerlink" title="进程字段排序"></a>进程字段排序</h3><p>默认进入 top 时，各进程是按照 CPU 的占用量来排序的，敲击键盘<strong>x</strong>（打开/关闭排序列的加亮效果），top 的视图变化如下所示，会将 CPU 占用量这行高亮（图来自<a href="http://www.cnblogs.com/peida/archive/2012/12/24/2831353.html" target="_blank" rel="external">每天一个linux命令（44）：top命令</a>）。</p>
<p><img src="/images/linux/top4.png" alt="TOP 按 CPU 占用量排序"></p>
<p>通过 <code>shift + &gt;</code>或<code>shift + &lt;</code>可以向右或左改变排序列，下图是按一次<code>shift + &gt;</code>的效果图，视图现在已经按照 <code>%MEM</code> 来排序（图来自<a href="http://www.cnblogs.com/peida/archive/2012/12/24/2831353.html" target="_blank" rel="external">每天一个linux命令（44）：top命令</a>）。</p>
<p><img src="/images/linux/top5.png" alt="TOP 按内存排序"></p>
<h3 id="显示进程完成命令"><a href="#显示进程完成命令" class="headerlink" title="显示进程完成命令"></a>显示进程完成命令</h3><p>敲击键盘<strong>c</strong>（打开/关闭进程完成命令），top 的视图变化如下（图来自<a href="http://www.cnblogs.com/peida/archive/2012/12/24/2831353.html" target="_blank" rel="external">每天一个linux命令（44）：top命令</a>）。</p>
<p><img src="/images/linux/top6.png" alt="TOP 显示完整命令"></p>
<h3 id="其他命令"><a href="#其他命令" class="headerlink" title="其他命令"></a>其他命令</h3><ul>
<li><code>top -p 574</code>: 显示指定的进程信息</li>
<li><code>top -d 3</code>: 设置信息更新时间</li>
<li><code>top -n 2</code>: 设置信息更新次数</li>
<li><code>top -S</code>: 以累积模式显示程序信息</li>
<li><code>top -Hp 2050</code>：显示该进程所有线程的详细信息</li>
</ul>
<h1 id="iostat"><a href="#iostat" class="headerlink" title="iostat"></a>iostat</h1><p>iostat 也即 I/O statistics（输入/输出统计），iostat 会对系统的磁盘操作活动进行监视。它的特点是汇报磁盘活动统计情况，同时也会汇报出 CPU 使用情况。但它不能对某个进程进行深入分析，仅对系统的整体情况进行分析。</p>
<h2 id="命令常用参数-1"><a href="#命令常用参数-1" class="headerlink" title="命令常用参数"></a>命令常用参数</h2><p>1．命令格式：</p>
<ul>
<li>iostat [参数][时间][次数]<br>2．命令功能：</li>
<li>通过 iostat 方便查看 CPU、网卡、tty设备、磁盘、CD-ROM 等等设备的活动情况，负载信息。<br>3．命令参数：</li>
<li><code>-C</code>: 显示CPU使用情况</li>
<li><code>-d</code>: 显示磁盘使用情况</li>
<li><code>-k</code>: 以 KB 为单位显示</li>
<li><code>-m</code>: 以 M 为单位显示</li>
<li><code>-N</code>: 显示磁盘阵列(LVM) 信息</li>
<li><code>-n</code>: 显示NFS 使用情况</li>
<li><code>-p[磁盘]</code>: 显示磁盘和分区的情况</li>
<li><code>-t</code>: 显示终端和CPU的信息</li>
<li><code>-x</code>: 显示详细信息</li>
<li><code>-V</code>: 显示版本信息</li>
</ul>
<h2 id="显示说明-1"><a href="#显示说明-1" class="headerlink" title="显示说明"></a>显示说明</h2><p>使用 iostat 命令时，终端会显示很多很多的信息，这里介绍一下这些信息的含义。</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">[matt@XXX ~]$ iostat</div><div class="line">Linux 2.6.32-431.20.3.el6.mt20150216.x86_64 (XXX) 	2017年07月16日 	_x86_64_	(32 CPU)</div><div class="line"></div><div class="line">avg-cpu:  %user   %nice %system %iowait  %steal   %idle</div><div class="line">          22.28    0.00   14.26    0.25    0.00   63.22</div><div class="line"></div><div class="line">Device:            tps   Blk_read/s   Blk_wrtn/s   Blk_read   Blk_wrtn</div><div class="line">sda              20.65       205.78       452.71 9429827972 20744862776</div></pre></td></tr></table></figure>
<ol>
<li>CPU 属性值说明：<ul>
<li><code>%user</code>：CPU 处在用户模式下的时间百分比</li>
<li><code>%nice</code>：CPU 处在带 NICE 值的用户模式下的时间百分比</li>
<li><code>%system</code>：CPU 处在系统模式下的时间百分比</li>
<li><code>%iowait</code>：CPU 等待输入输出完成时间的百分比</li>
<li><code>%steal</code>：管理程序维护另一个虚拟处理器时，虚拟 CPU 的无意识等待时间百分比</li>
<li><code>%idle</code>：CPU 空闲时间百分比</li>
</ul>
</li>
<li>disk 属性<ul>
<li><code>tps</code>：该设备每秒的传输次数（Indicate the number of transfers per second that were issued to the device.）。</li>
<li><code>kB_read/s</code>：每秒从设备（drive expressed）读取的数据量；</li>
<li><code>kB_wrtn/s</code>：每秒向设备（drive expressed）写入的数据量；</li>
<li><code>kB_read</code>：读取的总数据量；</li>
<li><code>kB_wrtn</code>：写入的总数量数据量，这些单位都为Kilobytes。</li>
</ul>
</li>
</ol>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">[matt@XXX ~]$ iostat -xm 3</div><div class="line">Linux 2.6.32-431.20.3.el6.mt20150216.x86_64 (XXX) 	2017年07月16日 	_x86_64_	(32 CPU)</div><div class="line"></div><div class="line">avg-cpu:  %user   %nice %system %iowait  %steal   %idle</div><div class="line">          22.28    0.00   14.26    0.25    0.00   63.21</div><div class="line"></div><div class="line">Device:         rrqm/s   wrqm/s     r/s     w/s    rMB/s    wMB/s avgrq-sz avgqu-sz   await  svctm  %util</div><div class="line">sda               0.50    42.34    6.47   14.18     0.10     0.22    31.90     0.02    1.20   0.44   0.90</div></pre></td></tr></table></figure>
<p>这里 disk 属性与上面的不太相同</p>
<ul>
<li><code>rrqm/s</code>: 每秒进行 merge 的读操作数目。即 rmerge/s</li>
<li><code>wrqm/s</code>: 每秒进行 merge 的写操作数目。即 wmerge/s</li>
<li><code>r/s</code>: 每秒完成的读 I/O 设备次数。即 rio/s</li>
<li><code>w/s</code>: 每秒完成的写 I/O 设备次数。即 wio/s</li>
<li><code>rsec/s</code>: 每秒读扇区数。即 rsect/s</li>
<li><code>wsec/s</code>: 每秒写扇区数。即 wsect/s</li>
<li><code>rkB/s</code>: 每秒读K字节数。是 rsect/s 的一半，因为每扇区大小为512字节。</li>
<li><code>wkB/s</code>: 每秒写K字节数。是 wsect/s 的一半。</li>
<li><code>avgrq-sz</code>: 平均每次设备 I/O 操作的数据大小 (扇区)。</li>
<li><code>avgqu-sz</code>: 平均 I/O 队列长度。</li>
<li><code>await</code>: 平均每次设备 I/O 操作的等待时间 (毫秒)。</li>
<li><code>svctm</code>: 平均每次设备 I/O 操作的服务时间 (毫秒)。</li>
<li><code>%util</code>: 一秒中有百分之多少的时间用于 I/O 操作，即被 IO 消耗的 CPU 百分比。</li>
</ul>
<p>其中，下面是在实践中积累的一些经验</p>
<ol>
<li>如果 <code>%iowait</code> 的值过高，表示硬盘存在 I/O 瓶颈；</li>
<li><code>%idle</code> 值高，表示 CPU 较空闲，如果 <code>%idle</code> 值高但系统响应慢时，有可能是 CPU 等待分配内存，此时应加大内存容量。<code>%idle</code> 值如果持续低于 10，那么系统的 CPU 处理能力相对较低，表明系统中最需要解决的资源是 CPU；</li>
<li>如果 <code>%util</code> 接近 100%，说明产生的I/O请求太多，I/O 系统已经满负荷，该磁盘可能存在瓶颈，其值大于 70% 时，磁盘的压力就很大了；</li>
<li>如果 <code>svctm</code> 比较接近 <code>await</code>，说明 I/O 几乎没有等待时间；如果 <code>await</code> 远大于 <code>svctm</code>，说明 I/O 队列太长，IO 响应太慢，则需要进行必要优化；</li>
<li>如果 <code>avgqu-sz</code> 比较大，也表示有当量 IO 在等待，它是 IO 调优时需要注意的地方，它是直接每次操作的数据的大小，如果次数多，但数据拿的小的话，其实 IO 也会很小；</li>
<li>await 的大小一般取决于服务时间(svctm) 以及 I/O 队列的长度和 I/O 请求的发出模式。如果 svctm 比较接近 await，说明 I/O 几乎没有等待时间；如果 await 远大于 svctm，说明 I/O 队列太长，应用得到的响应时间变慢，如果响应时间超过了用户可以容许的范围，这时可以考虑更换更快的磁盘，调整内核 elevator 算法，优化应用，或者升级 CPU。</li>
</ol>
<h2 id="常用示例"><a href="#常用示例" class="headerlink" title="常用示例"></a>常用示例</h2><ul>
<li><code>iostat 2 3</code>: 每隔 2 秒刷新显示，且显示 3 次；</li>
<li><code>iostat -d sda</code>: 显示指定磁盘信息；</li>
<li><code>iostat -t</code>: 显示 tty 和 CPU 信息；</li>
<li><code>iostat -m</code>: 以M为单位显示所有信息；</li>
<li><code>iostat -d -k 1 1</code>: 查看TPS和吞吐量信息；</li>
<li><code>iostat -c 1 3</code>: 查看cpu状态；</li>
</ul>
<h1 id="ps"><a href="#ps" class="headerlink" title="ps"></a>ps</h1><p>ps —— 是 process status 的简称，它列出的是当前时刻那些进程的快照，如果想要动态的显示进程信息内容，可以使用 top 命令。</p>
<p>使用 ps 可以做以下事情：</p>
<ul>
<li>确定有哪些进程正在运行、查看运行的状态；</li>
<li>进程是否结束；</li>
<li>进程有没有僵死；</li>
<li>哪些进程占用了过多的资源等等。</li>
</ul>
<h2 id="Linux-进程的五种状态"><a href="#Linux-进程的五种状态" class="headerlink" title="Linux 进程的五种状态"></a>Linux 进程的五种状态</h2><p>在 Linux 上进程有5种状态，每种状态对应着不同的标识，如下表所示：</p>
<table>
<thead>
<tr>
<th>Linux 上状态</th>
<th>ps 的状态码</th>
</tr>
</thead>
<tbody>
<tr>
<td>运行（正在运行或在运行队列中等待）</td>
<td>R（running or on run queue）</td>
</tr>
<tr>
<td>中断（休眠中、受阻、在等待某个条件的形成和接收到信号）</td>
<td>S（sleeping）</td>
</tr>
<tr>
<td>不可中断（收到信号不唤醒和不可运行, 进程必须等待直到有中断发生）</td>
<td>D（uninterruptible sleep）</td>
</tr>
<tr>
<td>僵死（进程已终止，但进程描述符存在，直到父进程调用wait4()后才会释放）</td>
<td>Z（a defunct zombie process）</td>
</tr>
<tr>
<td>停止（进程收到SIGSTOP, SIGSTP, SIGTIN, SIGTOU信号后停止运行运行）</td>
<td>T（traced or stopped）</td>
</tr>
</tbody>
</table>
<h2 id="命令常用参数-2"><a href="#命令常用参数-2" class="headerlink" title="命令常用参数"></a>命令常用参数</h2><ol>
<li>命令格式<ul>
<li>ps [参数]</li>
</ul>
</li>
<li>命令参数<ul>
<li><code>a</code>：显示所有进程</li>
<li><code>-a</code>：显示同一终端下的所有程序</li>
<li><code>-A</code>：显示所有进程</li>
<li><code>c</code>：显示进程的真实名称</li>
<li><code>-N</code>：反向选择</li>
<li><code>e</code>：显示环境变量</li>
<li><code>f</code>：显示程序间的关系</li>
<li><code>-H</code>：显示树状结构</li>
<li><code>r</code>：显示当前终端的进程</li>
<li><code>T</code>：显示当前终端的所有程序</li>
<li><code>u</code>：指定用户的所有进程</li>
<li><code>-au</code>：显示较详细的资讯</li>
<li><code>-aux</code>：显示所有包含其他使用者的行程</li>
<li><code>-C&lt;命令&gt;</code>：列出指定命令的状况</li>
<li><code>--lines&lt;行数&gt;</code>：每页显示的行数</li>
<li><code>--width&lt;字符数&gt;</code>：每页显示的字符数</li>
<li><code>--help</code>：显示帮助信息</li>
<li><code>--version</code>：显示版本显示</li>
</ul>
</li>
</ol>
<h2 id="显示说明-2"><a href="#显示说明-2" class="headerlink" title="显示说明"></a>显示说明</h2><h3 id="将当前这次登入的-PID-与相关信息列示出来"><a href="#将当前这次登入的-PID-与相关信息列示出来" class="headerlink" title="将当前这次登入的 PID 与相关信息列示出来"></a>将当前这次登入的 PID 与相关信息列示出来</h3><figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">[matt@XXX ~]$ ps <span class="_">-l</span></div><div class="line">F S   UID    PID   PPID  C PRI  NI ADDR SZ WCHAN  TTY          TIME CMD</div><div class="line">0 S   10 120177 120176  0  80   0 - 27078 <span class="built_in">wait</span>   pts/0    00:00:00 bash</div><div class="line">0 R   10 137912 120177  0  80   0 - 27031 -      pts/0    00:00:00 ps</div></pre></td></tr></table></figure>
<p>上面各个参数的含义：</p>
<ul>
<li><code>F</code>: 代表这个程序的旗标 (flag)， 4 代表使用者为 super user</li>
<li><code>S</code>: 代表这个程序的状态 (STAT)，关于各 STAT 的意义将在内文介绍</li>
<li><code>UID</code>: 程序被该 UID 所拥有</li>
<li><code>PID</code>: 就是这个程序的 ID</li>
<li><code>PPID</code>: 则是其上级父程序的ID</li>
<li><code>C</code>: CPU 使用的资源百分比</li>
<li><code>PRI</code>: 这个是 Priority (优先执行序) 的缩写</li>
<li><code>NI</code>: 这个是 Nice 值</li>
<li><code>ADDR</code>: 这个是 kernel function，指出该程序在内存的那个部分。如果是个 running的程序，一般就是 “-“</li>
<li><code>SZ</code>: 使用掉的内存大小</li>
<li><code>WCHAN</code>: 目前这个程序是否正在运作当中，若为 - 表示正在运作</li>
<li><code>TTY</code>: 登入者的终端机位置</li>
<li><code>TIME</code>: 使用掉的 CPU 时间。</li>
<li><code>CMD</code>: 所下达的指令为何</li>
</ul>
<h3 id="ps-aux"><a href="#ps-aux" class="headerlink" title="ps aux"></a>ps aux</h3><figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">[matt@XXX ~]$ ps aux</div><div class="line">USER        PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMAND</div><div class="line">root          1  0.5  0.8 1184632 1166268 ?     Ss    2016 4029:48 /sbin/init</div><div class="line">root          2  0.0  0.0      0     0 ?        S     2016   0:00 [kthreadd]</div><div class="line">root          3  0.0  0.0      0     0 ?        S     2016  36:36 [migration/0]</div></pre></td></tr></table></figure>
<p>上面各个参数的含义：</p>
<ul>
<li><code>USER</code>：该 process 属于那个使用者账号的</li>
<li><code>PID</code>：该 process 的号码</li>
<li><code>%CPU</code>：该 process 使用掉的 CPU 资源百分比</li>
<li><code>%MEM</code>：该 process 所占用的物理内存百分比</li>
<li><code>VSZ</code>：该 process 使用掉的虚拟内存量 (Kbytes)</li>
<li><code>RSS</code>：该 process 占用的固定的内存量 (Kbytes)</li>
<li><code>TTY</code>：该 process 是在那个终端机上面运作，若与终端机无关，则显示 <code>?</code>，若为 <code>pts/0</code> 等等的，则表示为由网络连接进主机的程序。</li>
<li><code>STAT</code>：该程序目前的状态</li>
<li><code>START</code>：该 process 被触发启动的时间</li>
<li><code>TIME</code>：该 process 实际使用 CPU 运作的时间</li>
<li><code>COMMAND</code>：该程序的实际指令</li>
</ul>
<h2 id="使用示例"><a href="#使用示例" class="headerlink" title="使用示例"></a>使用示例</h2><p>ps 的常用命令主要有以下几种用法：</p>
<ul>
<li><code>ps -A</code>: 显示所有进程信息</li>
<li><code>ps -u root</code>: 显示指定用户信息</li>
<li><code>ps -ef</code>: 显示所有进程信息，连同命令行</li>
<li>与 <code>grep</code> 一起，来查看指定的进程。</li>
</ul>
<h1 id="netstat"><a href="#netstat" class="headerlink" title="netstat"></a>netstat</h1><p>Netstat 是一款命令行工具，可用于列出系统上所有的网络套接字连接情况，包括 tcp, udp 以及 unix 套接字。</p>
<h2 id="命令常用参数-3"><a href="#命令常用参数-3" class="headerlink" title="命令常用参数"></a>命令常用参数</h2><ul>
<li>命令格式：<br>netstat [-acCeFghilMnNoprstuvVwx][-A&lt;网络类型&gt;][–ip]</li>
<li>命令参数：<ol>
<li>-a 或 –all 显示所有连线中的Socket。</li>
<li>-A &lt;网络类型&gt;或–&lt;网络类型&gt; 列出该网络类型连线中的相关地址。</li>
<li>-c 或 –continuous 持续列出网络状态。</li>
<li>-C 或 –cache 显示路由器配置的快取信息。</li>
<li>-e 或 –extend 显示网络其他相关信息。</li>
<li>-F 或 –fib 显示FIB。</li>
<li>-g 或 –groups 显示多重广播功能群组组员名单。</li>
<li>-h 或 –help 在线帮助。</li>
<li>-i 或 –interfaces 显示网络界面信息表单。</li>
<li>-l 或 –listening 显示监控中的服务器的Socket。</li>
<li>-M 或 –masquerade 显示伪装的网络连线。</li>
<li>-n 或 –numeric 直接使用IP地址，而不通过域名服务器。</li>
<li>-N 或 –netlink 或 –symbolic 显示网络硬件外围设备的符号连接名称。</li>
<li>-o 或 –timers 显示计时器。</li>
<li>-p 或 –programs 显示正在使用Socket的程序识别码和程序名称。</li>
<li>-r 或 –route 显示Routing Table。</li>
<li>-s 或 –statistice 显示网络工作信息统计表。</li>
<li>-t 或 –tcp 显示TCP传输协议的连线状况。</li>
<li>-u 或 –udp 显示UDP传输协议的连线状况。</li>
<li>-v 或 –verbose 显示指令执行过程。</li>
<li>-V 或 –version 显示版本信息。</li>
<li>-w 或 –raw 显示RAW传输协议的连线状况。</li>
<li>-x 或 –unix 此参数的效果和指定”-A unix”参数相同。</li>
<li>–ip 或 –inet 此参数的效果和指定”-A inet”参数相同。</li>
</ol>
</li>
</ul>
<h2 id="显示说明-3"><a href="#显示说明-3" class="headerlink" title="显示说明"></a>显示说明</h2><p>这里看下在命令行下输入 <code>netstat</code> 显示内容的含义：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line">[matt@XXXX ~]$ netstat</div><div class="line">Active Internet connections (w/o servers)</div><div class="line">Proto Recv-Q Send-Q Local Address               Foreign Address             State</div><div class="line">tcp        0      0 0.0.0.0:55030 0.0.0.0:XmlIpcRegSvc ESTABLISHED</div><div class="line">tcp        0      0 localhost:18103             localhost:tr-rsrb-p2        TIME_WAIT</div><div class="line">tcp        0      0 localhost:18137             localhost:tr-rsrb-p2        TIME_WAIT</div><div class="line">tcp        0      0 0.0.0.0:5266 0.0.0.0:16011 ESTABLISHED</div><div class="line"></div><div class="line">Active UNIX domain sockets (w/o servers)</div><div class="line">Proto RefCnt Flags       Type       State         I-Node Path</div><div class="line">unix  11     [ ]         DGRAM                    72685074 /dev/<span class="built_in">log</span></div><div class="line">unix  2      [ ]         DGRAM                    8702   /var/run/portreserve/socket</div><div class="line">unix  2      [ ]         DGRAM                    7565   @/org/kernel/udev/udevd</div><div class="line">unix  2      [ ]         DGRAM                    339609275</div><div class="line">unix  2      [ ]         DGRAM                    339608880</div><div class="line">unix  3      [ ]         STREAM     CONNECTED     339608854 /var/run/nss-cache.sock</div></pre></td></tr></table></figure>
<p>netstat 的输出结果可分为两部分：</p>
<ol>
<li>是 Active Internet connections，称为有源 TCP 连接，其中 <code>Recv-Q</code> 和 <code>Send-Q</code> 指的是接收队列和发送队列，这些数字一般都应该是0，如果不是则表示软件包正在队列中堆积，这种情况只能在非常少的情况见到；</li>
<li>另一个是 Active UNIX domain sockets，称为有源 Unix 域套接口(和网络套接字一样，但是只能用于本机通信，性能可以提高一倍。</li>
</ol>
<p>其中：</p>
<ul>
<li>Proto 显示连接使用的协议；</li>
<li>RefCnt 表示连接到本套接口上的进程号；</li>
<li>Types 显示套接口的类型；</li>
<li>State 显示套接口当前的状态；</li>
<li>Path 表示连接到套接口的其它进程使用的路径名。</li>
</ul>
<p>套接口类型：</p>
<ul>
<li>-t ：TCP</li>
<li>-u ：UDP</li>
<li>-raw ：RAW类型</li>
<li>–unix ：UNIX域类型</li>
<li>–ax25 ：AX25类型</li>
<li>–ipx ：ipx类型</li>
<li>–netrom ：netrom类型</li>
</ul>
<p>状态说明：</p>
<ul>
<li>LISTEN：侦听来自远方的TCP端口的连接请求</li>
<li>SYN-SENT：再发送连接请求后等待匹配的连接请求（如果有大量这样的状态包，检查是否中招了）</li>
<li>SYN-RECEIVED：再收到和发送一个连接请求后等待对方对连接请求的确认（如有大量此状态，估计被flood攻击了）</li>
<li>ESTABLISHED：代表一个打开的连接</li>
<li>FIN-WAIT-1：等待远程TCP连接中断请求，或先前的连接中断请求的确认</li>
<li>FIN-WAIT-2：从远程TCP等待连接中断请求</li>
<li>CLOSE-WAIT：等待从本地用户发来的连接中断请求</li>
<li>CLOSING：等待远程TCP对连接中断的确认</li>
<li>LAST-ACK：等待原来的发向远程TCP的连接中断请求的确认（不是什么好东西，此项出现，检查是否被攻击）</li>
<li>TIME-WAIT：等待足够的时间以确保远程TCP接收到连接中断请求的确认</li>
<li>CLOSED：没有任何连接状态</li>
</ul>
<h2 id="常用命令-1"><a href="#常用命令-1" class="headerlink" title="常用命令"></a>常用命令</h2><h3 id="列出所有的符合某些条件的连接"><a href="#列出所有的符合某些条件的连接" class="headerlink" title="列出所有的符合某些条件的连接"></a>列出所有的符合某些条件的连接</h3><figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 累出所有连接</span></div><div class="line">netstat <span class="_">-a</span></div><div class="line"></div><div class="line"><span class="comment"># 只列出 tcp</span></div><div class="line">netstat -at</div><div class="line"></div><div class="line"><span class="comment"># 只列出 udp</span></div><div class="line">netstat -au</div><div class="line"></div><div class="line"><span class="comment"># 只列出 tcp，加-n 禁止域名解析，之查看 ip 地址</span></div><div class="line">netstat -ant</div><div class="line"></div><div class="line"><span class="comment"># 只列出监听中的连接，-l：只列出监听的套接字</span></div><div class="line">netstat -tnl</div><div class="line"></div><div class="line"><span class="comment"># netstat 的 -c 选项持续输出信息</span></div><div class="line">netstat -ct</div><div class="line"></div><div class="line"><span class="comment"># 显示 pid</span></div><div class="line">netstat -pt</div></pre></td></tr></table></figure>
<h3 id="统计数据"><a href="#统计数据" class="headerlink" title="统计数据"></a>统计数据</h3><figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">netstat <span class="_">-s</span></div></pre></td></tr></table></figure>
<h3 id="显示路由信息"><a href="#显示路由信息" class="headerlink" title="显示路由信息"></a>显示路由信息</h3><figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">netstat -rn</div></pre></td></tr></table></figure>
<h3 id="显示UDP端口号的使用情况"><a href="#显示UDP端口号的使用情况" class="headerlink" title="显示UDP端口号的使用情况"></a>显示UDP端口号的使用情况</h3><figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">netstat -apu</div></pre></td></tr></table></figure>
<h3 id="统计机器中网络连接各个状态个数"><a href="#统计机器中网络连接各个状态个数" class="headerlink" title="统计机器中网络连接各个状态个数"></a>统计机器中网络连接各个状态个数</h3><figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">netstat <span class="_">-a</span> | awk <span class="string">'/^tcp/ &#123;++S[$NF]&#125; END &#123;for(a in S) print a, S[a]&#125;'</span></div></pre></td></tr></table></figure>
<h3 id="找出运行在指定端口的进程"><a href="#找出运行在指定端口的进程" class="headerlink" title="找出运行在指定端口的进程"></a>找出运行在指定端口的进程</h3><figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">netstat -anpt | grep <span class="string">':16064'</span></div></pre></td></tr></table></figure>
<h1 id="kill"><a href="#kill" class="headerlink" title="kill"></a>kill</h1><p>kill 主要使用结束 linux 后台进程的命令，kill命令是通过向进程发送指定的信号来结束相应进程的。</p>
<h2 id="命令常用参数-4"><a href="#命令常用参数-4" class="headerlink" title="命令常用参数"></a>命令常用参数</h2><ul>
<li>命令格式<ul>
<li>kill[参数][进程号]</li>
</ul>
</li>
<li>命令功能<ul>
<li>发送指定的信号到相应进程。不指定信号时将发送 <code>SIGTERM</code>（15）终止指定进程。如果任无法终止该程序，可使用发送的信号为 <code>SIGKILL</code>(9) ，将强制结束进程，使用 ps 命令或者 jbs 命令可以查看进程号。</li>
</ul>
</li>
<li>命令参数：<ol>
<li>-l  信号，若果不加信号的编号参数，则使用 <code>-l</code> 参数会列出全部的信号名称;</li>
<li>-a  当处理当前进程时，不限制命令名和进程号的对应关系</li>
<li>-p  指定 kill 命令只打印相关进程的进程号，而不发送任何信号</li>
<li>-s  指定发送信号</li>
<li>-u  指定用户</li>
</ol>
</li>
</ul>
<p>注意：</p>
<ol>
<li>kill 命令可以带信号号码选项，也可以不带。如果没有信号，kill 命令就会发出终止信号(15)，这个信号可以被进程捕获，使得进程在退出之前可以清理并释放资源。也可以用 kill 向进程发送特定的信号。</li>
<li>kill 可以带有进程 PID 号作为参数。当用 kill 向这些进程发送信号时，必须是这些进程的主人。</li>
<li>可以向多个进程发信号或终止它们。</li>
<li>应注意，信号使进程强行终止，这常会带来一些副作用，如数据丢失或者终端无法恢复到正常状态。发送信号时必须小心，只有在万不得已时，才用 kill 信号(9)，因为进程不能首先捕获它。要撤销所有的后台作业，可以输入kill 0。</li>
</ol>
<h2 id="常用方法"><a href="#常用方法" class="headerlink" title="常用方法"></a>常用方法</h2><h3 id="所有的信号名称"><a href="#所有的信号名称" class="headerlink" title="所有的信号名称"></a>所有的信号名称</h3><figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div></pre></td><td class="code"><pre><div class="line">[XXX@XXX ~]$ <span class="built_in">kill</span> <span class="_">-l</span></div><div class="line"> 1) SIGHUP	 2) SIGINT	 3) SIGQUIT	 4) SIGILL	 5) SIGTRAP</div><div class="line"> 6) SIGABRT	 7) SIGBUS	 8) SIGFPE	 9) SIGKILL	10) SIGUSR1</div><div class="line">11) SIGSEGV	12) SIGUSR2	13) SIGPIPE	14) SIGALRM	15) SIGTERM</div><div class="line">16) SIGSTKFLT	17) SIGCHLD	18) SIGCONT	19) SIGSTOP	20) SIGTSTP</div><div class="line">21) SIGTTIN	22) SIGTTOU	23) SIGURG	24) SIGXCPU	25) SIGXFSZ</div><div class="line">26) SIGVTALRM	27) SIGPROF	28) SIGWINCH	29) SIGIO	30) SIGPWR</div><div class="line">31) SIGSYS	34) SIGRTMIN	35) SIGRTMIN+1	36) SIGRTMIN+2	37) SIGRTMIN+3</div><div class="line">38) SIGRTMIN+4	39) SIGRTMIN+5	40) SIGRTMIN+6	41) SIGRTMIN+7	42) SIGRTMIN+8</div><div class="line">43) SIGRTMIN+9	44) SIGRTMIN+10	45) SIGRTMIN+11	46) SIGRTMIN+12	47) SIGRTMIN+13</div><div class="line">48) SIGRTMIN+14	49) SIGRTMIN+15	50) SIGRTMAX-14	51) SIGRTMAX-13	52) SIGRTMAX-12</div><div class="line">53) SIGRTMAX-11	54) SIGRTMAX-10	55) SIGRTMAX-9	56) SIGRTMAX-8	57) SIGRTMAX-7</div><div class="line">58) SIGRTMAX-6	59) SIGRTMAX-5	60) SIGRTMAX-4	61) SIGRTMAX-3	62) SIGRTMAX-2</div><div class="line">63) SIGRTMAX-1	64) SIGRTMAX</div><div class="line"></div><div class="line"><span class="comment"># 列出指定的信号的值</span></div><div class="line">[XXX@XXX ~]$ <span class="built_in">kill</span> <span class="_">-l</span> TERM</div><div class="line">15</div></pre></td></tr></table></figure>
<p>其中，只有第 <strong>9</strong> 种信号( <code>SIGKILL</code> )才可以无条件终止进程，其他信号进程都有权利忽略。    下面是常用的信号：</p>
<ul>
<li>HUP 1 终端断线</li>
<li>INT 2 中断（同 Ctrl + C）</li>
<li>QUIT 3 退出（同 Ctrl + \）</li>
<li>TERM 15 终止</li>
<li>KILL 9 强制终止</li>
<li>CONT 18 继续（与STOP相反， fg/bg命令）</li>
<li>STOP 19 暂停（同 Ctrl + Z）</li>
</ul>
<h3 id="彻底杀死进程"><a href="#彻底杀死进程" class="headerlink" title="彻底杀死进程"></a>彻底杀死进程</h3><figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="built_in">kill</span> –9 3268</div></pre></td></tr></table></figure>
<hr>
<p>参考：</p>
<ul>
<li><a href="http://www.cnblogs.com/peida/archive/2012/12/24/2831353.html" target="_blank" rel="external">每天一个linux命令（44）：top命令</a></li>
<li><a href="http://www.cnblogs.com/peida/archive/2013/03/08/2949194.html" target="_blank" rel="external">每天一个linux命令（56）：netstat命令</a></li>
<li><a href="http://www.cnblogs.com/peida/archive/2012/12/28/2837345.html" target="_blank" rel="external">每天一个linux命令（47）：iostat命令</a></li>
<li><a href="http://www.cnblogs.com/peida/archive/2012/12/19/2824418.html" target="_blank" rel="external">每天一个linux命令（41）：ps命令</a></li>
<li><a href="http://www.cnblogs.com/peida/archive/2012/12/25/2831814.html" target="_blank" rel="external">每天一个linux命令（45）：free 命令</a></li>
</ul>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[Kafka 源码解析之 Producer Metadata 更新机制（二）]]></title>
      <url>http://matt33.com/2017/07/08/kafka-producer-metadata/</url>
      <content type="html"><![CDATA[<p>在上一篇文章中，已经介绍了 Producer 的发送模型，Producer <code>dosend()</code> 方法中的第一步，就是获取相关的 topic 的 metadata，但在上篇中并没有深入展开，因为这部分的内容比较多，所以本文单独一篇文章进行介绍，本文主要来讲述以下三个问题：</p>
<ol>
<li>metadata 内容是什么；</li>
<li>Producer 更新 metadata 的流程；</li>
<li>Producer 在什么情况下会去更新 metadata；</li>
</ol>
<h2 id="Metadata-内容"><a href="#Metadata-内容" class="headerlink" title="Metadata 内容"></a>Metadata 内容</h2><p>Metadata 信息的内容可以通过源码看明白：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// 这个类被 client 线程和后台 sender 所共享,它只保存了所有 topic 的部分数据,当我们请求一个它上面没有的 topic meta 时,它会通过发送 metadata update 来更新 meta 信息,</span></div><div class="line"><span class="comment">// 如果 topic meta 过期策略是允许的,那么任何 topic 过期的话都会被从集合中移除,</span></div><div class="line"><span class="comment">// 但是 consumer 是不允许 topic 过期的因为它明确地知道它需要管理哪些 topic</span></div><div class="line"><span class="keyword">public</span> <span class="keyword">final</span> <span class="class"><span class="keyword">class</span> <span class="title">Metadata</span> </span>&#123;</div><div class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> Logger log = LoggerFactory.getLogger(Metadata.class);</div><div class="line"></div><div class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">long</span> TOPIC_EXPIRY_MS = <span class="number">5</span> * <span class="number">60</span> * <span class="number">1000</span>;</div><div class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">long</span> TOPIC_EXPIRY_NEEDS_UPDATE = -<span class="number">1L</span>;</div><div class="line"></div><div class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">long</span> refreshBackoffMs; <span class="comment">// metadata 更新失败时,为避免频繁更新 meta,最小的间隔时间,默认 100ms</span></div><div class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">long</span> metadataExpireMs; <span class="comment">// metadata 的过期时间, 默认 60,000ms</span></div><div class="line">    <span class="keyword">private</span> <span class="keyword">int</span> version; <span class="comment">// 每更新成功1次，version自增1,主要是用于判断 metadata 是否更新</span></div><div class="line">    <span class="keyword">private</span> <span class="keyword">long</span> lastRefreshMs; <span class="comment">// 最近一次更新时的时间（包含更新失败的情况）</span></div><div class="line">    <span class="keyword">private</span> <span class="keyword">long</span> lastSuccessfulRefreshMs; <span class="comment">// 最近一次成功更新的时间（如果每次都成功的话，与前面的值相等, 否则，lastSuccessulRefreshMs &lt; lastRefreshMs)</span></div><div class="line">    <span class="keyword">private</span> Cluster cluster; <span class="comment">// 集群中一些 topic 的信息</span></div><div class="line">    <span class="keyword">private</span> <span class="keyword">boolean</span> needUpdate; <span class="comment">// 是都需要更新 metadata</span></div><div class="line">    <span class="comment">/* Topics with expiry time */</span></div><div class="line">    <span class="keyword">private</span> <span class="keyword">final</span> Map&lt;String, Long&gt; topics; <span class="comment">// topic 与其过期时间的对应关系</span></div><div class="line">    <span class="keyword">private</span> <span class="keyword">final</span> List&lt;Listener&gt; listeners; <span class="comment">// 事件监控者</span></div><div class="line">    <span class="keyword">private</span> <span class="keyword">final</span> ClusterResourceListeners clusterResourceListeners; <span class="comment">//当接收到 metadata 更新时, ClusterResourceListeners的列表</span></div><div class="line">    <span class="keyword">private</span> <span class="keyword">boolean</span> needMetadataForAllTopics; <span class="comment">// 是否强制更新所有的 metadata</span></div><div class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">boolean</span> topicExpiryEnabled; <span class="comment">// 默认为 true, Producer 会定时移除过期的 topic,consumer 则不会移除</span></div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>关于 topic 的详细信息（leader 所在节点、replica 所在节点、isr 列表）都是在 <code>Cluster</code> 实例中保存的。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// 并不是一个全集,metadata的主要组成部分</span></div><div class="line"><span class="keyword">public</span> <span class="keyword">final</span> <span class="class"><span class="keyword">class</span> <span class="title">Cluster</span> </span>&#123;</div><div class="line"></div><div class="line">    <span class="comment">// 从命名直接就看出了各个变量的用途</span></div><div class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">boolean</span> isBootstrapConfigured;</div><div class="line">    <span class="keyword">private</span> <span class="keyword">final</span> List&lt;Node&gt; nodes; <span class="comment">// node 列表</span></div><div class="line">    <span class="keyword">private</span> <span class="keyword">final</span> Set&lt;String&gt; unauthorizedTopics; <span class="comment">// 未认证的 topic 列表</span></div><div class="line">    <span class="keyword">private</span> <span class="keyword">final</span> Set&lt;String&gt; internalTopics; <span class="comment">// 内置的 topic 列表</span></div><div class="line">    <span class="keyword">private</span> <span class="keyword">final</span> Map&lt;TopicPartition, PartitionInfo&gt; partitionsByTopicPartition; <span class="comment">// partition 的详细信息</span></div><div class="line">    <span class="keyword">private</span> <span class="keyword">final</span> Map&lt;String, List&lt;PartitionInfo&gt;&gt; partitionsByTopic; <span class="comment">// topic 与 partition 的对应关系</span></div><div class="line">    <span class="keyword">private</span> <span class="keyword">final</span> Map&lt;String, List&lt;PartitionInfo&gt;&gt; availablePartitionsByTopic; <span class="comment">//  可用（leader 不为 null）的 topic 与 partition 的对应关系</span></div><div class="line">    <span class="keyword">private</span> <span class="keyword">final</span> Map&lt;Integer, List&lt;PartitionInfo&gt;&gt; partitionsByNode; <span class="comment">// node 与 partition 的对应关系</span></div><div class="line">    <span class="keyword">private</span> <span class="keyword">final</span> Map&lt;Integer, Node&gt; nodesById; <span class="comment">// node 与 id 的对应关系</span></div><div class="line">    <span class="keyword">private</span> <span class="keyword">final</span> ClusterResource clusterResource;</div><div class="line">&#125;</div><div class="line"></div><div class="line"></div><div class="line"><span class="comment">// org.apache.kafka.common.PartitionInfo</span></div><div class="line"><span class="comment">// topic-partition: 包含 topic、partition、leader、replicas、isr</span></div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">PartitionInfo</span> </span>&#123;</div><div class="line">    <span class="keyword">private</span> <span class="keyword">final</span> String topic;</div><div class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">int</span> partition;</div><div class="line">    <span class="keyword">private</span> <span class="keyword">final</span> Node leader;</div><div class="line">    <span class="keyword">private</span> <span class="keyword">final</span> Node[] replicas;</div><div class="line">    <span class="keyword">private</span> <span class="keyword">final</span> Node[] inSyncReplicas;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p><code>Cluster</code> 实例主要是保存：</p>
<ol>
<li>broker.id 与 <code>node</code> 的对应关系；</li>
<li>topic 与 partition （<code>PartitionInfo</code>）的对应关系；</li>
<li><code>node</code> 与 partition （<code>PartitionInfo</code>）的对应关系。</li>
</ol>
<h2 id="Producer-的-Metadata-更新流程"><a href="#Producer-的-Metadata-更新流程" class="headerlink" title="Producer 的 Metadata 更新流程"></a>Producer 的 Metadata 更新流程</h2><p>Producer 在调用 <code>dosend()</code> 方法时，第一步就是通过 <code>waitOnMetadata</code> 方法获取该 topic 的 metadata 信息.</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// 等待 metadata 的更新</span></div><div class="line"><span class="function"><span class="keyword">private</span> ClusterAndWaitTime <span class="title">waitOnMetadata</span><span class="params">(String topic, Integer partition, <span class="keyword">long</span> maxWaitMs)</span> <span class="keyword">throws</span> InterruptedException </span>&#123;</div><div class="line">    metadata.add(topic);<span class="comment">// 在 metadata 中添加 topic 后,如果 metadata 中没有这个 topic 的 meta，那么 metadata 的更新标志设置为了 true</span></div><div class="line">    Cluster cluster = metadata.fetch();</div><div class="line">    Integer partitionsCount = cluster.partitionCountForTopic(topic);<span class="comment">// 如果 topic 已经存在 meta 中,则返回该 topic 的 partition 数,否则返回 null</span></div><div class="line"></div><div class="line">    <span class="comment">// 当前 metadata 中如果已经有这个 topic 的 meta 的话,就直接返回</span></div><div class="line">    <span class="keyword">if</span> (partitionsCount != <span class="keyword">null</span> &amp;&amp; (partition == <span class="keyword">null</span> || partition &lt; partitionsCount))</div><div class="line">        <span class="keyword">return</span> <span class="keyword">new</span> ClusterAndWaitTime(cluster, <span class="number">0</span>);</div><div class="line"></div><div class="line">    <span class="keyword">long</span> begin = time.milliseconds();</div><div class="line">    <span class="keyword">long</span> remainingWaitMs = maxWaitMs;</div><div class="line">    <span class="keyword">long</span> elapsed;</div><div class="line"></div><div class="line">    <span class="comment">// 发送 metadata 请求,直到获取了这个 topic 的 metadata 或者请求超时</span></div><div class="line">    <span class="keyword">do</span> &#123;</div><div class="line">        log.trace(<span class="string">"Requesting metadata update for topic &#123;&#125;."</span>, topic);</div><div class="line">        <span class="keyword">int</span> version = metadata.requestUpdate();<span class="comment">// 返回当前版本号,初始值为0,每次更新时会自增,并将 needUpdate 设置为 true</span></div><div class="line">        sender.wakeup();<span class="comment">// 唤起 sender，发送 metadata 请求</span></div><div class="line">        <span class="keyword">try</span> &#123;</div><div class="line">            metadata.awaitUpdate(version, remainingWaitMs);<span class="comment">// 等待 metadata 的更新</span></div><div class="line">        &#125; <span class="keyword">catch</span> (TimeoutException ex) &#123;</div><div class="line">            <span class="comment">// Rethrow with original maxWaitMs to prevent logging exception with remainingWaitMs</span></div><div class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> TimeoutException(<span class="string">"Failed to update metadata after "</span> + maxWaitMs + <span class="string">" ms."</span>);</div><div class="line">        &#125;</div><div class="line">        cluster = metadata.fetch();</div><div class="line">        elapsed = time.milliseconds() - begin;</div><div class="line">        <span class="keyword">if</span> (elapsed &gt;= maxWaitMs)</div><div class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> TimeoutException(<span class="string">"Failed to update metadata after "</span> + maxWaitMs + <span class="string">" ms."</span>);<span class="comment">// 超时</span></div><div class="line">        <span class="keyword">if</span> (cluster.unauthorizedTopics().contains(topic))<span class="comment">// 认证失败，对当前 topic 没有 Write 权限</span></div><div class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> TopicAuthorizationException(topic);</div><div class="line">        remainingWaitMs = maxWaitMs - elapsed;</div><div class="line">        partitionsCount = cluster.partitionCountForTopic(topic);</div><div class="line">    &#125; <span class="keyword">while</span> (partitionsCount == <span class="keyword">null</span>);<span class="comment">// 不停循环,直到 partitionsCount 不为 null（即直到 metadata 中已经包含了这个 topic 的相关信息）</span></div><div class="line"></div><div class="line">    <span class="keyword">if</span> (partition != <span class="keyword">null</span> &amp;&amp; partition &gt;= partitionsCount) &#123;</div><div class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> KafkaException(</div><div class="line">                String.format(<span class="string">"Invalid partition given with record: %d is not in the range [0...%d)."</span>, partition, partitionsCount));</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="keyword">return</span> <span class="keyword">new</span> ClusterAndWaitTime(cluster, elapsed);</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>如果 metadata 中不存在这个 topic 的 metadata，那么就请求更新 metadata，如果 metadata 没有更新的话，方法就一直处在 <code>do ... while</code> 的循环之中，在循环之中，主要做以下操作：</p>
<ol>
<li><code>metadata.requestUpdate()</code> 将 metadata 的 <code>needUpdate</code> 变量设置为 true（强制更新），并返回当前的版本号（version），通过版本号来判断 metadata 是否完成更新；</li>
<li><code>sender.wakeup()</code> 唤醒 sender 线程，sender 线程又会去唤醒 <code>NetworkClient</code> 线程，<code>NetworkClient</code> 线程进行一些实际的操作（后面详细介绍）；</li>
<li><code>metadata.awaitUpdate(version, remainingWaitMs)</code> 等待 metadata 的更新。</li>
</ol>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// 更新 metadata 信息（根据当前 version 值来判断）</span></div><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">synchronized</span> <span class="keyword">void</span> <span class="title">awaitUpdate</span><span class="params">(<span class="keyword">final</span> <span class="keyword">int</span> lastVersion, <span class="keyword">final</span> <span class="keyword">long</span> maxWaitMs)</span> <span class="keyword">throws</span> InterruptedException </span>&#123;</div><div class="line">    <span class="keyword">if</span> (maxWaitMs &lt; <span class="number">0</span>) &#123;</div><div class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> IllegalArgumentException(<span class="string">"Max time to wait for metadata updates should not be &lt; 0 milli seconds"</span>);</div><div class="line">    &#125;</div><div class="line">    <span class="keyword">long</span> begin = System.currentTimeMillis();</div><div class="line">    <span class="keyword">long</span> remainingWaitMs = maxWaitMs;</div><div class="line">    <span class="keyword">while</span> (<span class="keyword">this</span>.version &lt;= lastVersion) &#123;<span class="comment">// 不断循环,直到 metadata 更新成功,version 自增</span></div><div class="line">        <span class="keyword">if</span> (remainingWaitMs != <span class="number">0</span>)</div><div class="line">            wait(remainingWaitMs);<span class="comment">// 阻塞线程，等待 metadata 的更新</span></div><div class="line">        <span class="keyword">long</span> elapsed = System.currentTimeMillis() - begin;</div><div class="line">        <span class="keyword">if</span> (elapsed &gt;= maxWaitMs)<span class="comment">// timeout</span></div><div class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> TimeoutException(<span class="string">"Failed to update metadata after "</span> + maxWaitMs + <span class="string">" ms."</span>);</div><div class="line">        remainingWaitMs = maxWaitMs - elapsed;</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>在 <code>Metadata.awaitUpdate()</code> 方法中，线程会阻塞在 <code>while</code> 循环中，直到 metadata 更新成功或者 timeout。</p>
<p>从前面可以看出，此时 Producer 线程会阻塞在两个 <code>while</code> 循环中，直到 metadata 信息更新，那么 metadata 是如何更新的呢？如果有印象的话，前面应该已经介绍过了，主要是通过 <code>sender.wakeup()</code> 来唤醒 sender 线程，间接唤醒 NetworkClient 线程，NetworkClient 线程来负责发送 Metadata 请求，并处理 Server 端的响应。</p>
<p>在 <a href="http://matt33.com/2017/06/25/kafka-producer-send-module/">Kafka 源码分析之 Producer 发送模型（一）</a> 中介绍 Producer 发送模型时，在第五步 <code>sender</code> 线程会调用 <code>NetworkClient.poll()</code> 方法进行实际的操作，其源码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">public</span> List&lt;ClientResponse&gt; <span class="title">poll</span><span class="params">(<span class="keyword">long</span> timeout, <span class="keyword">long</span> now)</span> </span>&#123;</div><div class="line">        <span class="keyword">long</span> metadataTimeout = metadataUpdater.maybeUpdate(now);<span class="comment">// 判断是否需要更新 meta,如果需要就更新（请求更新 metadata 的地方）</span></div><div class="line">        <span class="keyword">try</span> &#123;</div><div class="line">            <span class="keyword">this</span>.selector.poll(Utils.min(timeout, metadataTimeout, requestTimeoutMs));</div><div class="line">        &#125; <span class="keyword">catch</span> (IOException e) &#123;</div><div class="line">            log.error(<span class="string">"Unexpected error during I/O"</span>, e);</div><div class="line">        &#125;</div><div class="line"></div><div class="line">        <span class="comment">// process completed actions</span></div><div class="line">        <span class="keyword">long</span> updatedNow = <span class="keyword">this</span>.time.milliseconds();</div><div class="line">        List&lt;ClientResponse&gt; responses = <span class="keyword">new</span> ArrayList&lt;&gt;();</div><div class="line">        handleAbortedSends(responses);</div><div class="line">        handleCompletedSends(responses, updatedNow);<span class="comment">// 通过 selector 中获取 Server 端的 response</span></div><div class="line">        handleCompletedReceives(responses, updatedNow);<span class="comment">// 在返回的 handler 中，会处理 metadata 的更新</span></div><div class="line">        handleDisconnections(responses, updatedNow);</div><div class="line">        handleConnections();</div><div class="line">        handleInitiateApiVersionRequests(updatedNow);</div><div class="line">        handleTimedOutRequests(responses, updatedNow);</div><div class="line"></div><div class="line">        <span class="comment">// invoke callbacks</span></div><div class="line">        <span class="keyword">for</span> (ClientResponse response : responses) &#123;</div><div class="line">            <span class="keyword">try</span> &#123;</div><div class="line">                response.onComplete();</div><div class="line">            &#125; <span class="keyword">catch</span> (Exception e) &#123;</div><div class="line">                log.error(<span class="string">"Uncaught error in request completion:"</span>, e);</div><div class="line">            &#125;</div><div class="line">        &#125;</div><div class="line">        <span class="keyword">return</span> responses;</div><div class="line">    &#125;</div></pre></td></tr></table></figure>
<p>在这个方法中，主要会以下操作：</p>
<ul>
<li><code>metadataUpdater.maybeUpdate(now)</code>：判断是否需要更新 Metadata，如果需要更新的话，先与 Broker 建立连接，然后发送更新 metadata 的请求；</li>
<li>处理 Server 端的一些响应，这里主要讨论的是 <code>handleCompletedReceives(responses, updatedNow)</code> 方法，它会处理 Server 端返回的 Metadata 结果。</li>
</ul>
<p>先看一下 <code>metadataUpdater.maybeUpdate()</code> 的具体实现：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div></pre></td><td class="code"><pre><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">long</span> <span class="title">maybeUpdate</span><span class="params">(<span class="keyword">long</span> now)</span> </span>&#123;</div><div class="line">        <span class="comment">// should we update our metadata?</span></div><div class="line">        <span class="comment">// metadata 是否应该更新</span></div><div class="line">        <span class="keyword">long</span> timeToNextMetadataUpdate = metadata.timeToNextUpdate(now);<span class="comment">// metadata 下次更新的时间（需要判断是强制更新还是 metadata 过期更新,前者是立马更新,后者是计算 metadata 的过期时间）</span></div><div class="line">        <span class="comment">// 如果一条 metadata 的 fetch 请求还未从 server 收到恢复,那么时间设置为 waitForMetadataFetch（默认30s）</span></div><div class="line">        <span class="keyword">long</span> waitForMetadataFetch = <span class="keyword">this</span>.metadataFetchInProgress ? requestTimeoutMs : <span class="number">0</span>;</div><div class="line"></div><div class="line">        <span class="keyword">long</span> metadataTimeout = Math.max(timeToNextMetadataUpdate, waitForMetadataFetch);</div><div class="line">        <span class="keyword">if</span> (metadataTimeout &gt; <span class="number">0</span>) &#123;<span class="comment">// 时间未到时,直接返回下次应该更新的时间</span></div><div class="line">            <span class="keyword">return</span> metadataTimeout;</div><div class="line">        &#125;</div><div class="line"></div><div class="line">        Node node = leastLoadedNode(now);<span class="comment">// 选择一个连接数最小的节点</span></div><div class="line">        <span class="keyword">if</span> (node == <span class="keyword">null</span>) &#123;</div><div class="line">            log.debug(<span class="string">"Give up sending metadata request since no node is available"</span>);</div><div class="line">            <span class="keyword">return</span> reconnectBackoffMs;</div><div class="line">        &#125;</div><div class="line"></div><div class="line">        <span class="keyword">return</span> maybeUpdate(now, node); <span class="comment">// 可以发送 metadata 请求的话,就发送 metadata 请求</span></div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="comment">/**</span></div><div class="line">     * Add a metadata request to the list of sends if we can make one</div><div class="line">     */</div><div class="line">    <span class="comment">// 判断是否可以发送请求,可以的话将 metadata 请求加入到发送列表中</span></div><div class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">long</span> <span class="title">maybeUpdate</span><span class="params">(<span class="keyword">long</span> now, Node node)</span> </span>&#123;</div><div class="line">        String nodeConnectionId = node.idString();</div><div class="line"></div><div class="line">        <span class="keyword">if</span> (canSendRequest(nodeConnectionId)) &#123;<span class="comment">// 通道已经 ready 并且支持发送更多的请求</span></div><div class="line">            <span class="keyword">this</span>.metadataFetchInProgress = <span class="keyword">true</span>; <span class="comment">// 准备开始发送数据,将 metadataFetchInProgress 置为 true</span></div><div class="line">            MetadataRequest.Builder metadataRequest; <span class="comment">// 创建 metadata 请求</span></div><div class="line">            <span class="keyword">if</span> (metadata.needMetadataForAllTopics())<span class="comment">// 强制更新所有 topic 的 metadata（虽然默认不会更新所有 topic 的 metadata 信息，但是每个 Broker 会保存所有 topic 的 meta 信息）</span></div><div class="line">                metadataRequest = MetadataRequest.Builder.allTopics();</div><div class="line">            <span class="keyword">else</span> <span class="comment">// 只更新 metadata 中的 topics 列表（列表中的 topics 由 metadata.add() 得到）</span></div><div class="line">                metadataRequest = <span class="keyword">new</span> MetadataRequest.Builder(<span class="keyword">new</span> ArrayList&lt;&gt;(metadata.topics()));</div><div class="line"></div><div class="line"></div><div class="line">            log.debug(<span class="string">"Sending metadata request &#123;&#125; to node &#123;&#125;"</span>, metadataRequest, node.id());</div><div class="line">            sendInternalMetadataRequest(metadataRequest, nodeConnectionId, now);/ 发送 metadata 请求</div><div class="line">            <span class="keyword">return</span> requestTimeoutMs;</div><div class="line">        &#125;</div><div class="line"></div><div class="line">        <span class="comment">// If there's any connection establishment underway, wait until it completes. This prevents</span></div><div class="line">        <span class="comment">// the client from unnecessarily connecting to additional nodes while a previous connection</span></div><div class="line">        <span class="comment">// attempt has not been completed.</span></div><div class="line">        <span class="keyword">if</span> (isAnyNodeConnecting()) &#123;<span class="comment">// 如果 client 正在与任何一个 node 的连接状态是 connecting,那么就进行等待</span></div><div class="line">            <span class="comment">// Strictly the timeout we should return here is "connect timeout", but as we don't</span></div><div class="line">            <span class="comment">// have such application level configuration, using reconnect backoff instead.</span></div><div class="line">            <span class="keyword">return</span> reconnectBackoffMs;</div><div class="line">        &#125;</div><div class="line"></div><div class="line">        <span class="keyword">if</span> (connectionStates.canConnect(nodeConnectionId, now)) &#123;<span class="comment">// 如果没有连接这个 node,那就初始化连接</span></div><div class="line">            <span class="comment">// we don't have a connection to this node right now, make one</span></div><div class="line">            log.debug(<span class="string">"Initialize connection to node &#123;&#125; for sending metadata request"</span>, node.id());</div><div class="line">            initiateConnect(node, now);<span class="comment">// 初始化连接</span></div><div class="line">            <span class="keyword">return</span> reconnectBackoffMs;</div><div class="line">        &#125;</div><div class="line">        <span class="keyword">return</span> Long.MAX_VALUE;</div><div class="line">    &#125;</div><div class="line"></div><div class="line"> <span class="comment">// 发送 Metadata 请求   </span></div><div class="line"> <span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">sendInternalMetadataRequest</span><span class="params">(MetadataRequest.Builder builder,</span></span></div><div class="line">                                         String nodeConnectionId, <span class="keyword">long</span> now) &#123;</div><div class="line">    ClientRequest clientRequest = newClientRequest(nodeConnectionId, builder, now, <span class="keyword">true</span>);<span class="comment">// 创建 metadata 请求</span></div><div class="line">    doSend(clientRequest, <span class="keyword">true</span>, now);</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>所以，每次 Producer 请求更新 metadata 时，会有以下几种情况：</p>
<ol>
<li>如果 node 可以发送请求，则直接发送请求；</li>
<li>如果该 node 正在建立连接，则直接返回；</li>
<li>如果该 node 还没建立连接，则向 broker 初始化链接。</li>
</ol>
<p>而 KafkaProducer 线程之前是一直阻塞在两个 <code>while</code> 循环中，直到 metadata 更新</p>
<ol>
<li>sender 线程第一次调用 <code>poll()</code> 方法时，初始化与 node 的连接；</li>
<li>sender 线程第二次调用 <code>poll()</code> 方法时，发送 <code>Metadata</code> 请求；</li>
<li>sender 线程第三次调用 <code>poll()</code> 方法时，获取 <code>metadataResponse</code>，并更新 metadata。</li>
</ol>
<p>经过上述 sender 线程三次调用 <code>poll()</code>方法，所请求的 metadata 信息才会得到更新，此时 Producer 线程也不会再阻塞，开始发送消息。</p>
<p><code>NetworkClient</code> 接收到 Server 端对 Metadata 请求的响应后，更新 Metadata 信息。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// 处理任何已经完成的接收响应</span></div><div class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">handleCompletedReceives</span><span class="params">(List&lt;ClientResponse&gt; responses, <span class="keyword">long</span> now)</span> </span>&#123;</div><div class="line">        <span class="keyword">for</span> (NetworkReceive receive : <span class="keyword">this</span>.selector.completedReceives()) &#123;</div><div class="line">            String source = receive.source();</div><div class="line">            InFlightRequest req = inFlightRequests.completeNext(source);</div><div class="line">            AbstractResponse body = parseResponse(receive.payload(), req.header);</div><div class="line">            log.trace(<span class="string">"Completed receive from node &#123;&#125;, for key &#123;&#125;, received &#123;&#125;"</span>, req.destination, req.header.apiKey(), body);</div><div class="line">            <span class="keyword">if</span> (req.isInternalRequest &amp;&amp; body <span class="keyword">instanceof</span> MetadataResponse)<span class="comment">// 如果是 meta 响应</span></div><div class="line">                metadataUpdater.handleCompletedMetadataResponse(req.header, now, (MetadataResponse) body);</div><div class="line">            <span class="keyword">else</span> <span class="keyword">if</span> (req.isInternalRequest &amp;&amp; body <span class="keyword">instanceof</span> ApiVersionsResponse)</div><div class="line">                handleApiVersionsResponse(responses, req, now, (ApiVersionsResponse) body); <span class="comment">// 如果是其他响应</span></div><div class="line">            <span class="keyword">else</span></div><div class="line">                responses.add(req.completed(body, now));</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">        <span class="comment">// 处理 Server 端对 Metadata 请求处理后的 response</span></div><div class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">handleCompletedMetadataResponse</span><span class="params">(RequestHeader requestHeader, <span class="keyword">long</span> now, MetadataResponse response)</span> </span>&#123;</div><div class="line">            <span class="keyword">this</span>.metadataFetchInProgress = <span class="keyword">false</span>;</div><div class="line">            Cluster cluster = response.cluster();</div><div class="line">            <span class="comment">// check if any topics metadata failed to get updated</span></div><div class="line">            Map&lt;String, Errors&gt; errors = response.errors();</div><div class="line">            <span class="keyword">if</span> (!errors.isEmpty())</div><div class="line">                log.warn(<span class="string">"Error while fetching metadata with correlation id &#123;&#125; : &#123;&#125;"</span>, requestHeader.correlationId(), errors);</div><div class="line"></div><div class="line">            <span class="comment">// don't update the cluster if there are no valid nodes...the topic we want may still be in the process of being</span></div><div class="line">            <span class="comment">// created which means we will get errors and no nodes until it exists</span></div><div class="line">            <span class="keyword">if</span> (cluster.nodes().size() &gt; <span class="number">0</span>) &#123;</div><div class="line">                <span class="keyword">this</span>.metadata.update(cluster, now);<span class="comment">// 更新 meta 信息</span></div><div class="line">            &#125; <span class="keyword">else</span> &#123;<span class="comment">// 如果 metadata 中 node 信息无效,则不更新 metadata 信息</span></div><div class="line">                log.trace(<span class="string">"Ignoring empty metadata response with correlation id &#123;&#125;."</span>, requestHeader.correlationId());</div><div class="line">                <span class="keyword">this</span>.metadata.failedUpdate(now);</div><div class="line">            &#125;</div><div class="line">        &#125;</div></pre></td></tr></table></figure>
<h2 id="Producer-Metadata-的更新策略"><a href="#Producer-Metadata-的更新策略" class="headerlink" title="Producer Metadata 的更新策略"></a>Producer Metadata 的更新策略</h2><p>Metadata 会在下面两种情况下进行更新</p>
<ol>
<li>KafkaProducer 第一次发送消息时强制更新，其他时间周期性更新，它会通过 Metadata 的 <code>lastRefreshMs</code>, <code>lastSuccessfulRefreshMs</code> 这2个字段来实现；</li>
<li>强制更新： 调用 <code>Metadata.requestUpdate()</code> 将 <code>needUpdate</code> 置成了 true 来强制更新。</li>
</ol>
<p>在 NetworkClient 的 <code>poll()</code> 方法调用时，就会去检查这两种更新机制，只要达到其中一种，就行触发更新操作。</p>
<p>Metadata 的强制更新会在以下几种情况下进行：</p>
<ol>
<li><code>initConnect</code> 方法调用时，初始化连接；</li>
<li><code>poll()</code> 方法中对 <code>handleDisconnections()</code> 方法调用来处理连接断开的情况，这时会触发强制更新；</li>
<li><code>poll()</code> 方法中对 <code>handleTimedOutRequests()</code> 来处理请求超时时；</li>
<li>发送消息时，如果无法找到 partition 的 leader；</li>
<li>处理 Producer 响应（<code>handleProduceResponse</code>），如果返回关于 Metadata 过期的异常，比如：没有 topic-partition 的相关 meta 或者 client 没有权限获取其 metadata。</li>
</ol>
<p>强制更新主要是用于处理各种异常情况。</p>
<p>参考文档：</p>
<ul>
<li><a href="http://blog.csdn.net/chunlongyu/article/details/52622422" target="_blank" rel="external">Kafka源码深度解析－序列2 －Producer －Metadata的数据结构与读取、更新策略</a>；</li>
<li><a href="http://luodw.cc/2017/05/02/kafka02/" target="_blank" rel="external">kafka源码分析之Producer</a>。</li>
</ul>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[买房感想]]></title>
      <url>http://matt33.com/2017/07/02/buy-little-room/</url>
      <content type="html"><![CDATA[<p>落户+买房的事情终于搞定得差不多了（就差贷款合同的签署），六月份这个月已经往来杭州3趟，从四月底开始看房到现在，这一路真是五味杂粮、感慨颇多，亲身地感觉到生活之不易，无忧无虑的生活从离开大学的那一刻开始就已经结束，读研这两年半看似浑浑噩噩，但早已没有大学时的那种轻松惬意，或许这就是成长。</p>
<h2 id="去库存历史进程"><a href="#去库存历史进程" class="headerlink" title="去库存历史进程"></a>去库存历史进程</h2><p>从四月底看房到7.1签合同，杭州房价整体至少涨了20%（间接地上涨，刚需买房的成本涨得更多），简单举几个例子，都是个人的亲身经历：</p>
<ul>
<li>万科杭宸，成品装修，同学三月购入，当时三成首付、单价 2w 出头，五月我去看房时，销售态度也很好，让等认筹通知，等到六月份时，杭宸通知只接受全款或七成首付（最后情况是只接受全款）；</li>
<li>西溪璞园，四月底去看，当时有特价房，125 平大概 245w（均价1.9w，位置还好），6月初通知有一套小户型房源，顶楼，单价2.2w，遂吧；</li>
<li>东海闲湖城，三月开盘三幢楼，由于政府限价，均价只有1.2w，结果很明显，两三天就被抢完（当时市场还并不是太热），后面由于备案价格上不去，开发商目前选择直接封盘（后面三幢据说下半年开盘），车位从5月开始由 13w 涨到 16w；</li>
<li>万家之星，六月初去看盘，销售不怎么搭理，直接明说，现在要买的话只能去找关系，让去找滨江或旭辉的内部人员；</li>
<li>雅居乐国际花园，六月初第一次看，开盘当天小户型全部售罄，只剩 128 平，不过户型很好，只是没有看上这个小区，感觉小区人太多、楼太高（32层，4000户），后来六月再次开盘时，小户型依然是难抢；</li>
<li>….</li>
</ul>
<p>上面都是自己去踩过的盘，也都是真实的信息，我们可以再看一下去年7月份之前一些楼盘的价格，比如杭宸1.8w（现在2.3w）、桃源小镇 8k（现在1.8w）、科技城 1.5w（现在中心地带已经 3w+）、蒋村二手 2w 多点（现在 3.7w+）…，如果按 2016 年初的价格现在基本平均已经翻了 2-3 倍，当然并不是仅仅是杭州，全国一线城市和强二线城市都一样，郑州东区均价都到 1.5w、北京东西城均价 13w+ 朝阳海淀均价 9w+（目前调控虽说降了，但没什么卵用）、天津杭州均价到了 2w（之前是 1w），浩浩荡荡，当一线二线城市开始猛涨时，我们才意识到原来特么这就是<strong>去库存</strong>，通过房子把政府的债务轻轻松松转移到了普通百姓的身上，我们拿着纸面上的财富开始为银行打工。当然如果你有机会去为银行打工，那证明你还算是幸运的，因为你抓住机会已经买了房，更多的人根本就没抓住机会（就像楼主我），有人在这一历史进程中 all in 杭州，在短短一年的时间赚了几百万。</p>
<p>能看到机会的人毕竟是少数，当所有人都意识到机会的时候，市场已经变得疯狂，而且各种限购政策开始实施，这时候入场的人能赚到大钱的已经很少，很多可能已经开始站岗。去库存这一历史进程，在共和国、乃至中华民族史上都是可以载入史册的大事件（好坏无法评论，很多东西只有过些年才能看清楚其意义），它让一线城市有房的人身价迅速加了 500w+（多套房的就增加了千万），强二线城市有房的人身价涨了 100w+，这一切短短只需要一年，在这之前恐怕很少人相信现实是这么疯狂。而对于那些房价没有翻倍的城市，从此消彼长的角度看相当于其财富洗劫了，被一线二线城市洗劫，而且即使三四线城市的房价翻一倍，也免不了被洗劫的命运，北京翻一倍就是几百万上千万，而三四线只是几十万，这没有任何可比性。去库存造就了多少百万富翁，实在想不出来建国以来除了改革开放还有什么能造就这么多富翁。</p>
<p>任何事情都有好坏两方面，对于政府来说，可以实现两个效果：一、地方债务转移；二、一二线城市开始驱逐低收入或者买不起房的人，表面上看对于政府都是利好的，深层次分析，就不好说了，长征五号连续发射失败对于政府应该是一个警钟。从个人的角度来说，买到房的人（上车的人）个人资产迅速翻倍，没有买到房的人离买房越来越遥远。而买到房抓住机会的永远是少数，大部分人是这次去库存的受害者，去库存前可能马上就攒够了首付的钱，但一年之后却发现首付涨得远远超过了攒钱的速度，收入高点的还好说，可以去二线城市占坑，但另外一些人，他们已经被遗忘了。</p>
<p>现实就是这么残酷，没有人会去同情，我们只能去依靠自己，努力工作，为自己也为家人，其他的我们又能做些什么呢？</p>
<p>亲身经历浩浩荡荡的去库存历史进程，也算是大开眼界，这种事情在全世界史上都不是很常见，我们再次用了极短的时间完成发达国家几十年甚至上百年的进程，不出意外，未来我们还会经历更多可以载入史册的事件，但此时我们希望的是自己能够抓住机会，历史告诉我们，大事件背后隐藏的都是巨大的机会（过去的已经成为历史，历史不会重复，但我们可以从历史中去学习经验）。就像雄安一出来，那么多人跑过去买房，但是雄安早已封盘，而且雄安的商品房规划可能会像新加坡一样，政府全面提供廉租房，商品房在雄安将会退出历史舞台，这并不是那些炒房客的机会，他们只是得了去库存的后遗症。</p>
<h2 id="一线赶人，二线抢人"><a href="#一线赶人，二线抢人" class="headerlink" title="一线赶人，二线抢人"></a>一线赶人，二线抢人</h2><p>小时候，我们一直被灌输一种概念：人口是负担，如果我们人少一些，我们也可以过上美国人一样的生活。但是，现在我们却发现，人口是国家财富，看看那些鬼城，没有人的话规划得再好，没有任何用。北上深，这三个一线城市，他们在过去三十年的快速发展，既有政府集全国之力去发展（深圳除外，主要指北京和上海），可以修建的东方明珠、鸟巢，花得是全国公民的钱，但是却修在了上海和北京，这就是政策利好，然后到现在，以北京为例，出了以下这些政策：</p>
<ul>
<li>北京落户名额每年都在缩减；</li>
<li>北京控地，近两年新增住宅用地达到历史最低水平；</li>
<li>北京高校对非京籍博士总额做限制；</li>
<li>疏解低端产业，未来北京人口减少到 X；</li>
<li>…</li>
</ul>
<p>这都在向我们传递一个信号：北京不是想呆就能呆的地方，曾经<code>北京欢迎你</code>的时代已经过去，现在是一个新的时代。同时，也可以看到政府规划了各种城市群，来缓解一线的压力，中国 2016 的城市化率是 57%，经验告诉我们，一旦达到这个值之后，后面的城市化率将会以更快速度的增长，在之前，大部分高校毕业生都去了一线城市，做起了北漂、上漂、深漂，然而这几个大城市的容量是有限的，早些年来的人已经在一线扎根，现在留给我们的就会已经很少了。现在政府开始鼓励毕业生去二线城市发展，比较牛的二线城市，像杭州、南京、武汉以及一线城市深圳，都开始搞出了各种吸引人才政策，希望能把相关专业的高校毕业生（所谓的才人）吸引到本地，杭州和深圳本地高校少，只能从外地吸引，武汉和南京本地高校多，想的是怎么把自己培养的毕业生留下来，不得不说这几个城市哪个能吸引到更多高校毕业生，哪个城市未来的潜力就会更大一些。对于高校毕业生来说，大家主要关心是两方面：一个就业机会、一个是房价，一线城市的房价已经远远超出普通人的承受能力，甚至可以说，年薪100w（税前）在北上深都很有压力。所以对于二线城市来说，拥有较好就业机会以及较低房价的城市，未来肯定会吸引到更多的人才，只有把人吸引来了，这个城市未来才能飞速发展，中国确实需要培养更多的大城市，仅仅靠北上深三个城市，是带不起整个中国的。</p>
<h2 id="生活之不易，最难的永远在后面"><a href="#生活之不易，最难的永远在后面" class="headerlink" title="生活之不易，最难的永远在后面"></a>生活之不易，最难的永远在后面</h2><p>在国内，这几年讨论最多的就是房价，记得高中时，房价就已经是家常便饭，尤其是《蜗居》这部电视剧热播，全民开始讨论房价，但从现在来看，那时的房价真叫一个便宜。房子是我们的生活必需品，更何况房子跟户口、学校都是绑定在一起的，这就让房子成为家庭的必需品，结婚要婚房、小孩上学要学区房。。。一套房贷款之后，基本上要还30年，未来就要为银行工作30年，如果不买房，自己就是在为房东打工，甚至随时都会面对房租的上涨，所有的一切都逼着你去买房。</p>
<p>昨天正式签了合同，刚需的问题总算解决了，买的位置不是很好，未来的前景很难说，但是不买又没办法，今天还能买这，过半年可能就只能买更远的地方了。买完之后，跟一个朋友聊天，突然觉得压力更大了，贷款的压力还可以接受。但未来一旦有了孩子，孩子的支出、上学等等，这些都不是小数目，真的怀疑自己能不能承受住这么大支出，现在真的很理解那些选择不要孩子的一族。经济越发达的地方，生育率就越低，尤其是东亚这边深受儒家文化影响的民族，像日本韩国生育率比欧洲、澳洲、美洲低很多，东亚民族普遍对孩子投入较多，导致父母压力更大，所以越来越多的人不愿意去生孩子。</p>
<p>眼前的问题解决了，去年定一个的最重要的年度计划完成了，但是更大、更难的问题还在后面，然而<strong>现在能做的只能是花更多的时间去投资自己</strong>，不然的话真的害怕自己没有足够的能力为家庭提供一个好的生活。内地一年毕业600w+的大学生，在这样的竞争压力下，你若不努力，就会被淘汰，这就是现实社会中的达尔文主义。</p>
<h2 id="寒门再难在一二线扎根"><a href="#寒门再难在一二线扎根" class="headerlink" title="寒门再难在一二线扎根"></a>寒门再难在一二线扎根</h2><p>之前看到一个说法，说的是：中国70-90年代的精英大多来自农村，而90年代后的精英大都来自中产阶级。以互联网为例，这些大佬们，马云、马化腾、李彦宏、周鸿祎、刘强东、王兴等，家境较差的也只有刘强东了，其他人的家庭背景至少都是中产，农村走出来的人，在目前的精英阶层中还占有一定比例，未来的话这个比例估计会越来越低，最明显的是今年（2017）的高考状元，没有一个农村出身（网上的新闻），虽然这个并不能完全反映，但至少间接地反映了一些问题。</p>
<p>回到本文的主题 —- 房子，现在普遍有一种说法，想在北京扎根，家庭至少要能提供 200w 资金，要不然几乎不太有可能在北京扎根，昌平顺义的房子现在都已经 4w+ 了，离地铁近的恐怕都得 5w+，一般家庭的人如何负担得起。在去库存的这一历史进程中，一二城市的房价都已经翻倍，没有房子的人，相当于自己的财富被洗劫了一番，因为他并没有增加任何财富，而自己未来购房的成本却翻了不止一倍。对于普通人，尤其是来自农村家庭的孩子，感觉未来真的很难在一二线城市扎根，农村的孩子受到的教育本来就比城市差一些，而且父母管教得也不多，如果这些孩子再不知道努力的话，他们以后如何突破？甚至有可能会导致一个恶性循环，就像美国贫民区一样。</p>
<p>以前的时候在政治、历史书老是看到什么农民阶级的愚昧无知，鲁迅先生经常就会批判，因为自己出身于农村，每次回到家里，其实都能明显感觉到这一点，他们对于很多新鲜的事务都不是很了解、不懂理财不懂投资、更不懂得去投资自己，想想这样教育出来好孩子的几率有多大？成长的环境、父母的局限性对孩子性格、思维的培养影响是很大的，可是又能怎么办？这些父母可能并不知道未来他们孩子的竞争压力有多大，今年一个高考状元的采访，大概就是说：自己在城市长大，能接触到更好的学习方法、教育资源，而且父母对自己教育也非常上心，但农村孩子，很多人大学之前可能连电脑都没摸过，很难跟这些城市的孩子去竞争。唉，这就是残酷的现实，未来随着更多人去二线城市扎根，相信二线城市的房价还会再上升一部分，而这些想二线城市扎根的人付出的成本将会更大，给寒门出身的孩子们，留得机会并不多了，希望他们都能努力些。</p>
<h2 id="杂想"><a href="#杂想" class="headerlink" title="杂想"></a>杂想</h2><p>想想自己有了孩子之后，可能要为孩子牺牲很多，然后去慢慢培养孩子，等孩子长大后孩子在接着重复着我之前的生活，那人生的意义到底在哪里？仅仅为了繁衍么？近段在看《未来简史》，现在人文主义主宰世界，犹如之前宗教之于世界，人类不断为自己的生命寻找意义，以前我们认为自己是上帝伟大计划的一部分，这就是我们人类的全部意义，可是现在，估计很少有人相信这些，每个人都在寻找自己的信仰——follow your heart，都在试图找寻自己人生的意义。每当想到这些，看到那些为了孩子牺牲自己很多的父母时，我感觉到很可悲，这样的人生意义在哪里？以前很不明白为什么这样，现在有些明白了，但这完全不是我想要的生活。之前网上听到北京四中的校长讲到：一个为孩子付出一切的家庭，最后得到的往往是悲剧。这句话用在农村里，真的不为过，我们这代人，父母多生于文革年代，记事时赶上了恢复高考、改革开放，村里抓住机会的那批人已经在一站二线城市扎根，有的甚至已经在国外定居，每个乡每个镇多多少少都会有这样的人，这些走出去的人现在被称为当今社会的精英阶层，能走去的这些人大部分靠得都是高考，少数靠得是头脑和商机，他们的生活让依然生活在农村的父母一代羡慕。有长远眼光的父母就会从小对孩子管理严格，教育上投入更大，当然，在农村，投入更大也只是意味着找关系送礼上个当地更好的学校，最多寒暑假再上个补习班，幸运的是，我的父母属于这一类，父母一直希望我能走出农村，虽然他们只是初中文凭，但他们知道未来没有学历没有知识在这个社会很难有好的出路，打我记事开始，父母工作就很努力（在镇上做小生意），他们希望的是当我未来买房或者结婚的时候，能给我提供更大的支持，希望我能在二线甚至一线生存下去，非常感谢自己的父母，这么多年来，父母对自己默默付出了那么多。现在每次看到曾经的小学同学早已结婚生子，现在很多都在大城市里打工，在农村，如果没有考上大学，大部分走的都是这条路，这种生活明显不是我想要的生活，但是少年时代的自己并不知道这些、并不知道什么是自己想要的什么不是自己想要的，很幸运自己能够考上大学，走了农村孩子的另外一条路。而大部分的农村孩子并没有这种幸运，当然也有一些孩子，父母不怎么管教最后走出了一条很好的路，一是这种孩子较少，另一个是一个孩子性格的养成离不开其生活环境，父母在教育上没有管理太多，但在其他方面（隐性方面）对孩子的投入不见得小，这种孩子也很幸运，因为他们进入了一个正循环中，但是最多的那种，是没有考上大学而父母也没有为其提供一个很好出路的农村孩子，他们父母在孩子的投入不见得比别的孩子少，但结果并不如想象的那样，这中间有个体差异的原因，但是更多的是可悲、是无可奈何、或者说是不公平，这些孩子跟城里孩子是一样的，然而不同的生活环境造就了不同的人生路径，出身对一个人的影响有多大是不言而喻的，正所谓橘生淮南则为橘、橘生淮北则为枳。BBC有个纪录片叫做《七年》，有兴趣的朋友可以看一下，让人生走向一个正循环多么重要，而一个社会底层的人要想让人生走向正循环比例很低，中产阶级的孩子比例会大很多倍，这些中产阶级的孩子从小会接受更好的教育，成长的环境也比农村孩子强太多倍，但未来这些孩子们都将在同一个赛道上竞争，公平在这里显得苍白无力，随着经济的发展，更多私立中小学的兴起，公平又会从何而来？内心感觉很悲凉，可又无可奈何，未来自己终究也会走入这样的漩涡，明知不知道自己想要的生活，但又无法摆脱这种束缚，当想到这时，就会不由自主地去质疑人生的意义何在？《未来简史》没有告诉我答案，有信仰的人为自己的信仰而生，而我这种没有信仰的人却又当如何？为房子而活？为未来的孩子而活？为家庭而活？这都不是我想要的答案，为民族而活这句话说出来我自己都不相信，这些都不是我人生的意义，但又该是什么呢？我自己现在也不知道，但我会不停地去寻找答案。</p>
<h2 id="杭州看房的一些建议"><a href="#杭州看房的一些建议" class="headerlink" title="杭州看房的一些建议"></a>杭州看房的一些建议</h2><p>最后，再说一下买房的一些建议吧，杭州看房的话，有两个网站比较推荐：</p>
<ol>
<li>透明房，新房的最新消息，预售证信息、备案家都会在这个网站发布；</li>
<li>口水楼市，杭州方式论坛楼盘的论坛，有很多重要信息。</li>
</ol>
<p>我在看房的时候，主要记录以下这些信息，大家可以自行参考，选择自己认为比较重要的部分。</p>
<table>
<thead>
<tr>
<th>楼盘名</th>
<th>板块</th>
<th>状态</th>
<th>单价（中间套/边套）</th>
<th>面积</th>
<th>大概总价</th>
<th>得房率</th>
<th>交房时间</th>
<th>精装/毛坯</th>
<th>楼盘优惠</th>
<th>地铁（规划）</th>
<th>幼儿园</th>
<th>小学</th>
</tr>
</thead>
<tbody>
<tr>
<td>滨江旭辉·万家之星</td>
<td>勾庄北、拱辰北</td>
<td>目前还有三幢等待开售，预计价格是2.1-2.2万</td>
<td>2.2万</td>
<td>89 平</td>
<td>195w</td>
<td>-</td>
<td>-</td>
<td>毛坯</td>
<td>-</td>
<td>4号线</td>
<td>良渚通运幼儿园(公办)、勾庄中心幼儿园(公办)、12班幼儿园(规划)</td>
<td>运河小学(在建)、良渚二小运河校区</td>
</tr>
<tr>
<td>海德公园</td>
<td>勾庄北、拱辰北</td>
<td>开盘都已经卖完，下个月会在开盘一幢</td>
<td>~</td>
<td>83、89平</td>
<td>-</td>
<td>76%</td>
<td>2019年中旬交付</td>
<td>毛坯</td>
<td>-</td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p>最后，这篇文章是在杭州回北京的火车上完成的，这一路真的是感慨颇多，文章也如流水账一番，逻辑性不是很强，或许几年之后回头再看，就会嘲笑自己当年怎么这么无知。。</p>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[Kafka 源码解析之 Producer 发送模型（一）]]></title>
      <url>http://matt33.com/2017/06/25/kafka-producer-send-module/</url>
      <content type="html"><![CDATA[<p>早就开始计划写 Kafka 源码分析的文章，但却一直迟迟没有动手，直到看到一位同事的博客 <a href="http://blog.bcmeng.com/" target="_blank" rel="external">编程小梦</a>，彻底受到了打击，这位同事是去年本科毕业，年龄算起来应该比我小两岁，但是非常厉害，在刚工作半年的时候就成为了 Apache Kylin 的 commiter，看到身边同事这么优秀，而且还这么努力 （<a href="http://blog.bcmeng.com/post/booklist.html" target="_blank" rel="external">编程小梦-我的书单</a>），自己实在没有理由不努力了，因此，在 github 上给自己提了一个 issue <a href="https://github.com/wangzzu/awesome/issues/7" target="_blank" rel="external">Kafka 源码分析系列</a>，希望自己能够在未来半年里，至少每两周输出一篇 Kafka 源码分析的文章，本文是这个系列的第一篇 —— Producer 的发送模型（以 <strong>Kafka 0.10.2</strong> 为例）。</p>
<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>Kafka，作为目前在大数据领域应用最为广泛的消息队列，其内部实现和设计有很多值得深入研究和分析的地方。</p>
<p>再 0.10.2 的 Kafka 中，其 Client 端是由 Java 实现，Server 端是由 Scala 来实现的，在使用 Kafka 时，Client 是用户最先接触到部分，因此，计划写的源码分析也会从 Client 端开始，会先从 Producer 端开始，今天讲的是 Producer 端的发送模型的实现。</p>
<h1 id="Producer-使用"><a href="#Producer-使用" class="headerlink" title="Producer 使用"></a>Producer 使用</h1><p>在分析 Producer 发送模型之前，先看一下用户是如何使用 Producer 向 Kafka 写数据的，下面是一个关于 Producer 最简单的应用示例。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> org.apache.kafka.clients.producer.KafkaProducer;</div><div class="line"><span class="keyword">import</span> org.apache.kafka.clients.producer.ProducerRecord;</div><div class="line"><span class="keyword">import</span> org.apache.kafka.clients.producer.Producer;</div><div class="line"></div><div class="line"><span class="keyword">import</span> java.util.Properties;</div><div class="line"></div><div class="line"><span class="comment">/**</span></div><div class="line"> * Created by matt on 16/7/26.</div><div class="line"> */</div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ProducerTest</span> </span>&#123;</div><div class="line">    <span class="keyword">private</span> <span class="keyword">static</span> String topicName;</div><div class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">int</span> msgNum;</div><div class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">int</span> key;</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</div><div class="line">        Properties props = <span class="keyword">new</span> Properties();</div><div class="line">        props.put(<span class="string">"bootstrap.servers"</span>, <span class="string">"127.0.0.1:9092,127.0.0.2:9092"</span>);</div><div class="line">        props.put(<span class="string">"key.serializer"</span>, <span class="string">"org.apache.kafka.common.serialization.StringSerializer"</span>);</div><div class="line">        props.put(<span class="string">"value.serializer"</span>, <span class="string">"org.apache.kafka.common.serialization.StringSerializer"</span>);</div><div class="line"></div><div class="line">        topicName = <span class="string">"test"</span>;</div><div class="line">        msgNum = <span class="number">10</span>; <span class="comment">// 发送的消息数</span></div><div class="line"></div><div class="line">        Producer&lt;String, String&gt; producer = <span class="keyword">new</span> KafkaProducer&lt;&gt;(props);</div><div class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; msgNum; i++) &#123;</div><div class="line">            String msg = i + <span class="string">" This is matt's blog."</span>;</div><div class="line">            producer.send(<span class="keyword">new</span> ProducerRecord&lt;String, String&gt;(topicName, msg));</div><div class="line">        &#125;</div><div class="line">        producer.close();</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>从上面的代码可以看出 Kafka 为用户提供了非常简单的 API，在使用时，只需要如下两步：</p>
<ol>
<li>初始化 <code>KafkaProducer</code> 实例；</li>
<li>调用 <code>send</code> 接口发送数据。</li>
</ol>
<p>本文主要是围绕着 Producer 在内部是如何实现 <code>send</code> 接口而展开的。</p>
<h1 id="Producer-数据发送流程"><a href="#Producer-数据发送流程" class="headerlink" title="Producer 数据发送流程"></a>Producer 数据发送流程</h1><p>下面通过对 <code>send</code> 源码分析来一步步剖析 Producer 数据的发送流程。</p>
<h2 id="Producer-的-send-实现"><a href="#Producer-的-send-实现" class="headerlink" title="Producer 的 send 实现"></a>Producer 的 send 实现</h2><p>用户是直接使用 <code>producer.send()</code> 发送的数据，先看一下 <code>send()</code> 接口的实现</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// 异步向一个 topic 发送数据</span></div><div class="line"><span class="meta">@Override</span></div><div class="line"><span class="function"><span class="keyword">public</span> Future&lt;RecordMetadata&gt; <span class="title">send</span><span class="params">(ProducerRecord&lt;K, V&gt; record)</span> </span>&#123;</div><div class="line">    <span class="keyword">return</span> send(record, <span class="keyword">null</span>);</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="comment">// 向 topic 异步地发送数据，当发送确认后唤起回调函数</span></div><div class="line"><span class="meta">@Override</span></div><div class="line"><span class="function"><span class="keyword">public</span> Future&lt;RecordMetadata&gt; <span class="title">send</span><span class="params">(ProducerRecord&lt;K, V&gt; record, Callback callback)</span> </span>&#123;</div><div class="line">    <span class="comment">// intercept the record, which can be potentially modified; this method does not throw exceptions</span></div><div class="line">    ProducerRecord&lt;K, V&gt; interceptedRecord = <span class="keyword">this</span>.interceptors == <span class="keyword">null</span> ? record : <span class="keyword">this</span>.interceptors.onSend(record);</div><div class="line">    <span class="keyword">return</span> doSend(interceptedRecord, callback);</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>数据发送的最终实现还是调用了 Producer 的 <code>doSend()</code> 接口。</p>
<h2 id="Producer-的-doSend-实现"><a href="#Producer-的-doSend-实现" class="headerlink" title="Producer 的 doSend 实现"></a>Producer 的 doSend 实现</h2><p>下面是 <code>doSend()</code> 的具体实现</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">private</span> Future&lt;RecordMetadata&gt; <span class="title">doSend</span><span class="params">(ProducerRecord&lt;K, V&gt; record, Callback callback)</span> </span>&#123;</div><div class="line">       TopicPartition tp = <span class="keyword">null</span>;</div><div class="line">       <span class="keyword">try</span> &#123;</div><div class="line">           <span class="comment">// 1.确认数据要发送到的 topic 的 metadata 是可用的</span></div><div class="line">           ClusterAndWaitTime clusterAndWaitTime = waitOnMetadata(record.topic(), record.partition(), maxBlockTimeMs);</div><div class="line">           <span class="keyword">long</span> remainingWaitMs = Math.max(<span class="number">0</span>, maxBlockTimeMs - clusterAndWaitTime.waitedOnMetadataMs);</div><div class="line">           Cluster cluster = clusterAndWaitTime.cluster;</div><div class="line">           <span class="comment">// 2.序列化 record 的 key 和 value</span></div><div class="line">           <span class="keyword">byte</span>[] serializedKey;</div><div class="line">           <span class="keyword">try</span> &#123;</div><div class="line">               serializedKey = keySerializer.serialize(record.topic(), record.key());</div><div class="line">           &#125; <span class="keyword">catch</span> (ClassCastException cce) &#123;</div><div class="line">               <span class="keyword">throw</span> <span class="keyword">new</span> SerializationException(<span class="string">"Can't convert key of class "</span> + record.key().getClass().getName() +</div><div class="line">                       <span class="string">" to class "</span> + producerConfig.getClass(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG).getName() +</div><div class="line">                       <span class="string">" specified in key.serializer"</span>);</div><div class="line">           &#125;</div><div class="line">           <span class="keyword">byte</span>[] serializedValue;</div><div class="line">           <span class="keyword">try</span> &#123;</div><div class="line">               serializedValue = valueSerializer.serialize(record.topic(), record.value());</div><div class="line">           &#125; <span class="keyword">catch</span> (ClassCastException cce) &#123;</div><div class="line">               <span class="keyword">throw</span> <span class="keyword">new</span> SerializationException(<span class="string">"Can't convert value of class "</span> + record.value().getClass().getName() +</div><div class="line">                       <span class="string">" to class "</span> + producerConfig.getClass(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG).getName() +</div><div class="line">                       <span class="string">" specified in value.serializer"</span>);</div><div class="line">           &#125;</div><div class="line"></div><div class="line">           <span class="comment">// 3. 获取该 record 的 partition 的值（可以指定,也可以根据算法计算）</span></div><div class="line">           <span class="keyword">int</span> partition = partition(record, serializedKey, serializedValue, cluster);</div><div class="line">           <span class="keyword">int</span> serializedSize = Records.LOG_OVERHEAD + Record.recordSize(serializedKey, serializedValue);</div><div class="line">           ensureValidRecordSize(serializedSize); <span class="comment">// record 的字节超出限制或大于内存限制时,就会抛出 RecordTooLargeException 异常</span></div><div class="line">           tp = <span class="keyword">new</span> TopicPartition(record.topic(), partition);</div><div class="line">           <span class="keyword">long</span> timestamp = record.timestamp() == <span class="keyword">null</span> ? time.milliseconds() : record.timestamp(); <span class="comment">// 时间戳</span></div><div class="line">           log.trace(<span class="string">"Sending record &#123;&#125; with callback &#123;&#125; to topic &#123;&#125; partition &#123;&#125;"</span>, record, callback, record.topic(), partition);</div><div class="line">           Callback interceptCallback = <span class="keyword">this</span>.interceptors == <span class="keyword">null</span> ? callback : <span class="keyword">new</span> InterceptorCallback&lt;&gt;(callback, <span class="keyword">this</span>.interceptors, tp);</div><div class="line">           <span class="comment">// 4. 向 accumulator 中追加数据</span></div><div class="line">           RecordAccumulator.RecordAppendResult result = accumulator.append(tp, timestamp, serializedKey, serializedValue, interceptCallback, remainingWaitMs);</div><div class="line">           <span class="comment">// 5. 如果 batch 已经满了,唤醒 sender 线程发送数据</span></div><div class="line">           <span class="keyword">if</span> (result.batchIsFull || result.newBatchCreated) &#123;</div><div class="line">               log.trace(<span class="string">"Waking up the sender since topic &#123;&#125; partition &#123;&#125; is either full or getting a new batch"</span>, record.topic(), partition);</div><div class="line">               <span class="keyword">this</span>.sender.wakeup();</div><div class="line">           &#125;</div><div class="line">           <span class="keyword">return</span> result.future;</div><div class="line">       &#125; <span class="keyword">catch</span> (ApiException e) &#123;</div><div class="line">           log.debug(<span class="string">"Exception occurred during message send:"</span>, e);</div><div class="line">           <span class="keyword">if</span> (callback != <span class="keyword">null</span>)</div><div class="line">               callback.onCompletion(<span class="keyword">null</span>, e);</div><div class="line">           <span class="keyword">this</span>.errors.record();</div><div class="line">           <span class="keyword">if</span> (<span class="keyword">this</span>.interceptors != <span class="keyword">null</span>)</div><div class="line">               <span class="keyword">this</span>.interceptors.onSendError(record, tp, e);</div><div class="line">           <span class="keyword">return</span> <span class="keyword">new</span> FutureFailure(e);</div><div class="line">       &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</div><div class="line">           <span class="keyword">this</span>.errors.record();</div><div class="line">           <span class="keyword">if</span> (<span class="keyword">this</span>.interceptors != <span class="keyword">null</span>)</div><div class="line">               <span class="keyword">this</span>.interceptors.onSendError(record, tp, e);</div><div class="line">           <span class="keyword">throw</span> <span class="keyword">new</span> InterruptException(e);</div><div class="line">       &#125; <span class="keyword">catch</span> (BufferExhaustedException e) &#123;</div><div class="line">           <span class="keyword">this</span>.errors.record();</div><div class="line">           <span class="keyword">this</span>.metrics.sensor(<span class="string">"buffer-exhausted-records"</span>).record();</div><div class="line">           <span class="keyword">if</span> (<span class="keyword">this</span>.interceptors != <span class="keyword">null</span>)</div><div class="line">               <span class="keyword">this</span>.interceptors.onSendError(record, tp, e);</div><div class="line">           <span class="keyword">throw</span> e;</div><div class="line">       &#125; <span class="keyword">catch</span> (KafkaException e) &#123;</div><div class="line">           <span class="keyword">this</span>.errors.record();</div><div class="line">           <span class="keyword">if</span> (<span class="keyword">this</span>.interceptors != <span class="keyword">null</span>)</div><div class="line">               <span class="keyword">this</span>.interceptors.onSendError(record, tp, e);</div><div class="line">           <span class="keyword">throw</span> e;</div><div class="line">       &#125; <span class="keyword">catch</span> (Exception e) &#123;</div><div class="line">           <span class="keyword">if</span> (<span class="keyword">this</span>.interceptors != <span class="keyword">null</span>)</div><div class="line">               <span class="keyword">this</span>.interceptors.onSendError(record, tp, e);</div><div class="line">           <span class="keyword">throw</span> e;</div><div class="line">       &#125;</div><div class="line">   &#125;</div></pre></td></tr></table></figure>
<p>在 <code>dosend()</code> 方法的实现上，一条 Record 数据的发送，可以分为以下五步：</p>
<ol>
<li>确认数据要发送到的 topic 的 metadata 是可用的（如果该 partition 的 leader 存在则是可用的，如果开启权限时，client 有相应的权限），如果没有 topic 的 metadata 信息，就需要获取相应的 metadata；</li>
<li>序列化 record 的 key 和 value；</li>
<li>获取该 record 要发送到的 partition（可以指定，也可以根据算法计算）；</li>
<li>向 accumulator 中追加 record 数据，数据会先进行缓存；</li>
<li>如果追加完数据后，对应的 RecordBatch 已经达到了 batch.size 的大小（或者batch 的剩余空间不足以添加下一条 Record），则唤醒 <code>sender</code> 线程发送数据。</li>
</ol>
<p>数据的发送过程，可以简单总结为以上五点，下面会这几部分的具体实现进行详细分析。</p>
<h1 id="发送过程详解"><a href="#发送过程详解" class="headerlink" title="发送过程详解"></a>发送过程详解</h1><h2 id="获取-topic-的-metadata-信息"><a href="#获取-topic-的-metadata-信息" class="headerlink" title="获取 topic 的 metadata 信息"></a>获取 topic 的 metadata 信息</h2><p>Producer 通过 <code>waitOnMetadata()</code> 方法来获取对应 topic 的 metadata 信息，这部分后面会单独抽出一篇文章来介绍，这里就不再详述，总结起来就是：在数据发送前，需要先该 topic 是可用的。</p>
<h2 id="key-和-value-的序列化"><a href="#key-和-value-的序列化" class="headerlink" title="key 和 value 的序列化"></a>key 和 value 的序列化</h2><p>Producer 端对 record 的 <code>key</code> 和 <code>value</code> 值进行序列化操作，在 Consumer 端再进行相应的反序列化，Kafka 内部提供的序列化和反序列化算法如下图所示：</p>
<p><img src="/images/kafka/serialize.png" alt="Kafka serialize &amp; deserialize"></p>
<p>当然我们也是可以自定义序列化的具体实现，不过一般情况下，Kafka 内部提供的这些方法已经足够使用。</p>
<h2 id="获取-partition-值"><a href="#获取-partition-值" class="headerlink" title="获取 partition 值"></a>获取 partition 值</h2><p>关于 partition 值的计算，分为三种情况：</p>
<ol>
<li>指明 partition 的情况下，直接将指明的值直接作为 partiton 值；</li>
<li>没有指明 partition 值但有 key 的情况下，将 key 的 hash 值与 topic 的 partition 数进行取余得到 partition 值；</li>
<li>既没有 partition 值又没有 key 值的情况下，第一次调用时随机生成一个整数（后面每次调用在这个整数上自增），将这个值与 topic 可用的 partition 总数取余得到 partition 值，也就是常说的 <code>round-robin</code> 算法。</li>
</ol>
<p>具体实现如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// 当 record 中有 partition 值时，直接返回，没有的情况下调用 partitioner 的类的 partition 方法去计算（KafkaProducer.class）</span></div><div class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">int</span> <span class="title">partition</span><span class="params">(ProducerRecord&lt;K, V&gt; record, <span class="keyword">byte</span>[] serializedKey, <span class="keyword">byte</span>[] serializedValue, Cluster cluster)</span> </span>&#123;</div><div class="line">    Integer partition = record.partition();</div><div class="line">    <span class="keyword">return</span> partition != <span class="keyword">null</span> ?</div><div class="line">            partition :</div><div class="line">            partitioner.partition(</div><div class="line">                    record.topic(), record.key(), serializedKey, record.value(), serializedValue, cluster);</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>Producer 默认使用的 <code>partitioner</code> 是 <code>org.apache.kafka.clients.producer.internals.DefaultPartitioner</code>，用户也可以自定义 partition 的策略，下面是这个类两个方法的具体实现：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">partition</span><span class="params">(String topic, Object key, <span class="keyword">byte</span>[] keyBytes, Object value, <span class="keyword">byte</span>[] valueBytes, Cluster cluster)</span> </span>&#123;</div><div class="line">        List&lt;PartitionInfo&gt; partitions = cluster.partitionsForTopic(topic);</div><div class="line">        <span class="keyword">int</span> numPartitions = partitions.size();</div><div class="line">        <span class="keyword">if</span> (keyBytes == <span class="keyword">null</span>) &#123;<span class="comment">// 没有指定 key 的情况下</span></div><div class="line">            <span class="keyword">int</span> nextValue = nextValue(topic); <span class="comment">// 第一次的时候产生一个随机整数,后面每次调用在之前的基础上自增;</span></div><div class="line">            List&lt;PartitionInfo&gt; availablePartitions = cluster.availablePartitionsForTopic(topic);</div><div class="line">            <span class="comment">// leader 不为 null,即为可用的 partition</span></div><div class="line">            <span class="keyword">if</span> (availablePartitions.size() &gt; <span class="number">0</span>) &#123;</div><div class="line">                <span class="keyword">int</span> part = Utils.toPositive(nextValue) % availablePartitions.size();</div><div class="line">                <span class="keyword">return</span> availablePartitions.get(part).partition();</div><div class="line">            &#125; <span class="keyword">else</span> &#123;</div><div class="line">                <span class="keyword">return</span> Utils.toPositive(nextValue) % numPartitions;</div><div class="line">            &#125;</div><div class="line">        &#125; <span class="keyword">else</span> &#123;<span class="comment">// 有 key 的情况下,使用 key 的 hash 值进行计算</span></div><div class="line">            <span class="keyword">return</span> Utils.toPositive(Utils.murmur2(keyBytes)) % numPartitions; <span class="comment">// 选择 key 的 hash 值</span></div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="comment">// 根据 topic 获取对应的整数变量</span></div><div class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">int</span> <span class="title">nextValue</span><span class="params">(String topic)</span> </span>&#123;</div><div class="line">        AtomicInteger counter = topicCounterMap.get(topic);</div><div class="line">        <span class="keyword">if</span> (<span class="keyword">null</span> == counter) &#123; <span class="comment">// 第一次调用时，随机产生</span></div><div class="line">            counter = <span class="keyword">new</span> AtomicInteger(<span class="keyword">new</span> Random().nextInt());</div><div class="line">            AtomicInteger currentCounter = topicCounterMap.putIfAbsent(topic, counter);</div><div class="line">            <span class="keyword">if</span> (currentCounter != <span class="keyword">null</span>) &#123;</div><div class="line">                counter = currentCounter;</div><div class="line">            &#125;</div><div class="line">        &#125;</div><div class="line">        <span class="keyword">return</span> counter.getAndIncrement(); <span class="comment">// 后面再调用时，根据之前的结果自增</span></div><div class="line">    &#125;</div></pre></td></tr></table></figure>
<p>这就是 Producer 中默认的 partitioner 实现。</p>
<h2 id="向-accumulator-写数据"><a href="#向-accumulator-写数据" class="headerlink" title="向 accumulator 写数据"></a>向 accumulator 写数据</h2><p>Producer 会先将 record 写入到 buffer 中，当达到一个 <code>batch.size</code> 的大小时，再唤起 <code>sender</code> 线程去发送 <code>RecordBatch</code>（第五步），这里先详细分析一下 Producer 是如何向 buffer 中写入数据的。</p>
<p>Producer 是通过 <code>RecordAccumulator</code> 实例追加数据，<code>RecordAccumulator</code> 模型如下图所示，一个重要的变量就是 <code>ConcurrentMap&lt;TopicPartition, Deque&lt;RecordBatch&gt;&gt; batches</code>，每个 <code>TopicPartition</code> 都会对应一个 <code>Deque&lt;RecordBatch&gt;</code>，当添加数据时，会向其 topic-partition 对应的这个 queue 最新创建的一个 <code>RecordBatch</code> 中添加 record，而发送数据时，则会先从 queue 中最老的那个 <code>RecordBatch</code> 开始发送。</p>
<p><img src="/images/kafka/recordbatch.png" alt="Producer RecordAccumulator 模型"></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// org.apache.kafka.clients.producer.internals.RecordAccumulator</span></div><div class="line">     <span class="comment">// 向 accumulator 添加一条 record，并返回添加后的结果（结果主要包含: future metadata、batch 是否满的标志以及新 batch 是否创建）其中， maxTimeToBlock 是 buffer.memory 的 block 的最大时间</span></div><div class="line">    <span class="function"><span class="keyword">public</span> RecordAppendResult <span class="title">append</span><span class="params">(TopicPartition tp,</span></span></div><div class="line">                                     <span class="keyword">long</span> timestamp,</div><div class="line">                                     <span class="keyword">byte</span>[] key,</div><div class="line">                                     <span class="keyword">byte</span>[] value,</div><div class="line">                                     Callback callback,</div><div class="line">                                     <span class="keyword">long</span> maxTimeToBlock) <span class="keyword">throws</span> InterruptedException &#123;</div><div class="line">        appendsInProgress.incrementAndGet();</div><div class="line">        <span class="keyword">try</span> &#123;</div><div class="line">            Deque&lt;RecordBatch&gt; dq = getOrCreateDeque(tp);<span class="comment">// 每个 topicPartition 对应一个 queue</span></div><div class="line">            <span class="keyword">synchronized</span> (dq) &#123;<span class="comment">// 在对一个 queue 进行操作时,会保证线程安全</span></div><div class="line">                <span class="keyword">if</span> (closed)</div><div class="line">                    <span class="keyword">throw</span> <span class="keyword">new</span> IllegalStateException(<span class="string">"Cannot send after the producer is closed."</span>);</div><div class="line">                RecordAppendResult appendResult = tryAppend(timestamp, key, value, callback, dq); <span class="comment">// 追加数据</span></div><div class="line">                <span class="keyword">if</span> (appendResult != <span class="keyword">null</span>)<span class="comment">// 这个 topic-partition 已经有记录了</span></div><div class="line">                    <span class="keyword">return</span> appendResult;</div><div class="line">            &#125;</div><div class="line"></div><div class="line">            <span class="comment">// 为 topic-partition 创建一个新的 RecordBatch, 需要初始化相应的 RecordBatch，要为其分配的大小是: max（batch.size, 加上头文件的本条消息的大小）</span></div><div class="line">            <span class="keyword">int</span> size = Math.max(<span class="keyword">this</span>.batchSize, Records.LOG_OVERHEAD + Record.recordSize(key, value));</div><div class="line">            log.trace(<span class="string">"Allocating a new &#123;&#125; byte message buffer for topic &#123;&#125; partition &#123;&#125;"</span>, size, tp.topic(), tp.partition());</div><div class="line">            ByteBuffer buffer = free.allocate(size, maxTimeToBlock);<span class="comment">// 给这个 RecordBatch 初始化一个 buffer</span></div><div class="line">            <span class="keyword">synchronized</span> (dq) &#123;</div><div class="line">                <span class="keyword">if</span> (closed)</div><div class="line">                    <span class="keyword">throw</span> <span class="keyword">new</span> IllegalStateException(<span class="string">"Cannot send after the producer is closed."</span>);</div><div class="line"></div><div class="line">                RecordAppendResult appendResult = tryAppend(timestamp, key, value, callback, dq);</div><div class="line">                <span class="keyword">if</span> (appendResult != <span class="keyword">null</span>) &#123;<span class="comment">// 如果突然发现这个 queue 已经存在，那么就释放这个已经分配的空间</span></div><div class="line">                    free.deallocate(buffer);</div><div class="line">                    <span class="keyword">return</span> appendResult;</div><div class="line">                &#125;</div><div class="line">                <span class="comment">// 给 topic-partition 创建一个 RecordBatch</span></div><div class="line">                MemoryRecordsBuilder recordsBuilder = MemoryRecords.builder(buffer, compression, TimestampType.CREATE_TIME, <span class="keyword">this</span>.batchSize);</div><div class="line">                RecordBatch batch = <span class="keyword">new</span> RecordBatch(tp, recordsBuilder, time.milliseconds());</div><div class="line">                <span class="comment">// 向新的 RecordBatch 中追加数据</span></div><div class="line">                FutureRecordMetadata future = Utils.notNull(batch.tryAppend(timestamp, key, value, callback, time.milliseconds()));</div><div class="line"></div><div class="line">                dq.addLast(batch);<span class="comment">// 将 RecordBatch 添加到对应的 queue 中</span></div><div class="line">                incomplete.add(batch);<span class="comment">// 向未 ack 的 batch 集合添加这个 batch</span></div><div class="line">                <span class="comment">// 如果 dp.size()&gt;1 就证明这个 queue 有一个 batch 是可以发送了</span></div><div class="line">                <span class="keyword">return</span> <span class="keyword">new</span> RecordAppendResult(future, dq.size() &gt; <span class="number">1</span> || batch.isFull(), <span class="keyword">true</span>);</div><div class="line">            &#125;</div><div class="line">        &#125; <span class="keyword">finally</span> &#123;</div><div class="line">            appendsInProgress.decrementAndGet();</div><div class="line">        &#125;</div><div class="line">    &#125;</div></pre></td></tr></table></figure>
<p>总结一下其 record 写入的具体流程如下图所示：</p>
<p><img src="/images/kafka/RecordBatch_append.png" alt="Producer RecordAccumulator record 写入流程"></p>
<ol>
<li>获取该 topic-partition 对应的 queue，没有的话会创建一个空的 queue；</li>
<li>向 queue 中追加数据，先获取 queue 中最新加入的那个 <code>RecordBatch</code>，如果不存在或者存在但剩余空余不足以添加本条 record 则返回 null，成功写入的话直接返回结果，写入成功；</li>
<li>创建一个新的 <code>RecordBatch</code>，初始化内存大小根据 <code>max(batch.size, Records.LOG_OVERHEAD + Record.recordSize(key, value))</code> 来确定（防止单条 record 过大的情况）；</li>
<li>向新建的 <code>RecordBatch</code> 写入 record，并将 <code>RecordBatch</code> 添加到 queue 中，返回结果，写入成功。</li>
</ol>
<h2 id="发送-RecordBatch"><a href="#发送-RecordBatch" class="headerlink" title="发送 RecordBatch"></a>发送 RecordBatch</h2><p>当 record 写入成功后，如果发现 <code>RecordBatch</code> 已满足发送的条件（通常是 queue 中有多个 batch，那么最先添加的那些 batch 肯定是可以发送了），那么就会唤醒 <code>sender</code> 线程，发送 <code>RecordBatch</code>。</p>
<p><code>sender</code> 线程对 <code>RecordBatch</code> 的处理是在 <code>run()</code> 方法中进行的，该方法具体实现如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">void</span> <span class="title">run</span><span class="params">(<span class="keyword">long</span> now)</span> </span>&#123;</div><div class="line">        Cluster cluster = metadata.fetch();</div><div class="line">        <span class="comment">// 获取那些已经可以发送的 RecordBatch 对应的 nodes</span></div><div class="line">        RecordAccumulator.ReadyCheckResult result = <span class="keyword">this</span>.accumulator.ready(cluster, now);</div><div class="line"></div><div class="line">        <span class="comment">// 如果有 topic-partition 的 leader 是未知的,就强制 metadata 更新</span></div><div class="line">        <span class="keyword">if</span> (!result.unknownLeaderTopics.isEmpty()) &#123;</div><div class="line">            <span class="keyword">for</span> (String topic : result.unknownLeaderTopics)</div><div class="line">                <span class="keyword">this</span>.metadata.add(topic);</div><div class="line">            <span class="keyword">this</span>.metadata.requestUpdate();</div><div class="line">        &#125;</div><div class="line"></div><div class="line">        <span class="comment">// 如果与node 没有连接（如果可以连接,同时初始化该连接）,就证明该 node 暂时不能发送数据,暂时移除该 node</span></div><div class="line">        Iterator&lt;Node&gt; iter = result.readyNodes.iterator();</div><div class="line">        <span class="keyword">long</span> notReadyTimeout = Long.MAX_VALUE;</div><div class="line">        <span class="keyword">while</span> (iter.hasNext()) &#123;</div><div class="line">            Node node = iter.next();</div><div class="line">            <span class="keyword">if</span> (!<span class="keyword">this</span>.client.ready(node, now)) &#123;</div><div class="line">                iter.remove();</div><div class="line">                notReadyTimeout = Math.min(notReadyTimeout, <span class="keyword">this</span>.client.connectionDelay(node, now));</div><div class="line">            &#125;</div><div class="line">        &#125;</div><div class="line"></div><div class="line">        <span class="comment">// 返回该 node 对应的所有可以发送的 RecordBatch 组成的 batches（key 是 node.id）,并将 RecordBatch 从对应的 queue 中移除</span></div><div class="line">        Map&lt;Integer, List&lt;RecordBatch&gt;&gt; batches = <span class="keyword">this</span>.accumulator.drain(cluster, result.readyNodes, <span class="keyword">this</span>.maxRequestSize, now);</div><div class="line">        <span class="keyword">if</span> (guaranteeMessageOrder) &#123;</div><div class="line">            <span class="comment">//记录将要发送的 RecordBatch</span></div><div class="line">            <span class="keyword">for</span> (List&lt;RecordBatch&gt; batchList : batches.values()) &#123;</div><div class="line">                <span class="keyword">for</span> (RecordBatch batch : batchList)</div><div class="line">                    <span class="keyword">this</span>.accumulator.mutePartition(batch.topicPartition);</div><div class="line">            &#125;</div><div class="line">        &#125;</div><div class="line"></div><div class="line">        <span class="comment">// 将由于元数据不可用而导致发送超时的 RecordBatch 移除</span></div><div class="line">        List&lt;RecordBatch&gt; expiredBatches = <span class="keyword">this</span>.accumulator.abortExpiredBatches(<span class="keyword">this</span>.requestTimeout, now);</div><div class="line">        <span class="keyword">for</span> (RecordBatch expiredBatch : expiredBatches)</div><div class="line">            <span class="keyword">this</span>.sensors.recordErrors(expiredBatch.topicPartition.topic(), expiredBatch.recordCount);</div><div class="line"></div><div class="line">        sensors.updateProduceRequestMetrics(batches);</div><div class="line"></div><div class="line">        <span class="keyword">long</span> pollTimeout = Math.min(result.nextReadyCheckDelayMs, notReadyTimeout);</div><div class="line">        <span class="keyword">if</span> (!result.readyNodes.isEmpty()) &#123;</div><div class="line">            log.trace(<span class="string">"Nodes with data ready to send: &#123;&#125;"</span>, result.readyNodes);</div><div class="line">            pollTimeout = <span class="number">0</span>;</div><div class="line">        &#125;</div><div class="line">        <span class="comment">// 发送 RecordBatch</span></div><div class="line">        sendProduceRequests(batches, now);</div><div class="line"></div><div class="line">        <span class="keyword">this</span>.client.poll(pollTimeout, now); <span class="comment">// 关于 socket 的一些实际的读写操作（其中包括 meta 信息的更新）</span></div><div class="line">    &#125;</div></pre></td></tr></table></figure>
<p>这段代码前面有很多是其他的逻辑处理，如：移除暂时不可用的 node、处理由于元数据不可用导致的超时 <code>RecordBatch</code>，真正进行发送发送 <code>RecordBatch</code> 的是 <code>sendProduceRequests(batches, now)</code> 这个方法，具体是：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/**</span></div><div class="line"> * Transfer the record batches into a list of produce requests on a per-node basis</div><div class="line"> */</div><div class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">sendProduceRequests</span><span class="params">(Map&lt;Integer, List&lt;RecordBatch&gt;&gt; collated, <span class="keyword">long</span> now)</span> </span>&#123;</div><div class="line">    <span class="keyword">for</span> (Map.Entry&lt;Integer, List&lt;RecordBatch&gt;&gt; entry : collated.entrySet())</div><div class="line">        sendProduceRequest(now, entry.getKey(), acks, requestTimeout, entry.getValue());</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="comment">/**</span></div><div class="line"> * Create a produce request from the given record batches</div><div class="line"> */</div><div class="line"><span class="comment">// 发送 produce 请求</span></div><div class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">sendProduceRequest</span><span class="params">(<span class="keyword">long</span> now, <span class="keyword">int</span> destination, <span class="keyword">short</span> acks, <span class="keyword">int</span> timeout, List&lt;RecordBatch&gt; batches)</span> </span>&#123;</div><div class="line">    Map&lt;TopicPartition, MemoryRecords&gt; produceRecordsByPartition = <span class="keyword">new</span> HashMap&lt;&gt;(batches.size());</div><div class="line">    <span class="keyword">final</span> Map&lt;TopicPartition, RecordBatch&gt; recordsByPartition = <span class="keyword">new</span> HashMap&lt;&gt;(batches.size());</div><div class="line">    <span class="keyword">for</span> (RecordBatch batch : batches) &#123;</div><div class="line">        TopicPartition tp = batch.topicPartition;</div><div class="line">        produceRecordsByPartition.put(tp, batch.records());</div><div class="line">        recordsByPartition.put(tp, batch);</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    ProduceRequest.Builder requestBuilder =</div><div class="line">            <span class="keyword">new</span> ProduceRequest.Builder(acks, timeout, produceRecordsByPartition);</div><div class="line">    RequestCompletionHandler callback = <span class="keyword">new</span> RequestCompletionHandler() &#123;</div><div class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onComplete</span><span class="params">(ClientResponse response)</span> </span>&#123;</div><div class="line">            handleProduceResponse(response, recordsByPartition, time.milliseconds());</div><div class="line">        &#125;</div><div class="line">    &#125;;</div><div class="line"></div><div class="line">    String nodeId = Integer.toString(destination);</div><div class="line">    ClientRequest clientRequest = client.newClientRequest(nodeId, requestBuilder, now, acks != <span class="number">0</span>, callback);</div><div class="line">    client.send(clientRequest, now);</div><div class="line">    log.trace(<span class="string">"Sent produce request to &#123;&#125;: &#123;&#125;"</span>, nodeId, requestBuilder);</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>这段代码就简单很多，总来起来就是，将 <code>batches</code> 中 leader 为同一个 node 的所有 RecordBatch 放在一个请求中进行发送。</p>
<h1 id="最后"><a href="#最后" class="headerlink" title="最后"></a>最后</h1><p>本文是对 Kafka Producer 端发送模型的一个简单分析，下一篇文章将会详细介绍 metadata 相关的内容，包括 metadata 的内容以及在 Producer 端 metadata 的更新机制。</p>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[CSS 一些常用方法的总结]]></title>
      <url>http://matt33.com/2017/06/21/css-summary/</url>
      <content type="html"><![CDATA[<p>CSS 指的是层叠样式表（Cascading StyleSheet），在网页制作时采用层叠样式表技术，可以有效地对页面的布局、字体、颜色、背景和其它效果实现更加精确的控制，本文对 css 一些基本内容及常用功能进行一下总结，总结的内容主要是来自实验楼的 <a href="https://www.shiyanlou.com/courses/53" target="_blank" rel="external">CSS 速成教程</a>，这篇文章会实时更新，后续如果遇到什么好的有用功能，也会更新到这篇文章中。</p>
<h1 id="css-基础语法"><a href="#css-基础语法" class="headerlink" title="css 基础语法"></a>css 基础语法</h1><p>CSS 规则由两个主要的部分构成：选择器，以及一条或多条声明。</p>
<figure class="highlight"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">selector &#123;</div><div class="line">    declaration1;</div><div class="line">    declaration2;</div><div class="line">    ...</div><div class="line">    declarationN;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>选择器通常是需要改变的 HTML 元素，每条声明都由一个属性和一个值组成，每个属性都有一个值，属性和值被冒号分开。</p>
<figure class="highlight css"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="selector-tag">h1</span>&#123;</div><div class="line">   <span class="attribute">color</span>:red;</div><div class="line">   <span class="attribute">font-size</span>:<span class="number">14px</span>;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h1 id="css-基本样式"><a href="#css-基本样式" class="headerlink" title="css 基本样式"></a>css 基本样式</h1><p>介绍 css 的一些基本样式，这些都是 css 中一些常用的设置。</p>
<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>css 是允许使用纯色作为背景，也允许使用背景图像实现一些相当复杂的效果。</p>
<table>
<thead>
<tr>
<th>属性</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td>background-attachment</td>
<td>背景图像是否固定或者随着页面的其余部分滚动</td>
</tr>
<tr>
<td>background-color</td>
<td>设置元素的背景颜色</td>
</tr>
<tr>
<td>background-image</td>
<td>把图片设置为背景</td>
</tr>
<tr>
<td>background-position</td>
<td>设置背景图片的起始位置</td>
</tr>
<tr>
<td>background-repeat</td>
<td>设置背景图片是否及如何重复，其中，<code>no-repeat</code>：表示不能重复，<code>repeat</code>：可重复（默认值），<code>repeat-x</code>：表示 x 轴重复，<code>repeat-y</code>：表示 y 轴重</td>
</tr>
<tr>
<td>background-size</td>
<td>规定背景图片的尺寸</td>
</tr>
<tr>
<td>background-origin</td>
<td>规定背景图片的定位区域</td>
</tr>
<tr>
<td>background-clip</td>
<td>规定背景的绘制区域</td>
</tr>
</tbody>
</table>
<p>举个例子，如下所示</p>
<figure class="highlight"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line">body&#123;</div><div class="line">   background-color: red;</div><div class="line">   background-image: url("hha.jpg");</div><div class="line">   background-repeat: no-repeat;</div><div class="line">   background-position: center top;</div><div class="line">   background-attachment: fixed;</div><div class="line">   background-size：100px 100px;</div><div class="line">&#125;</div><div class="line"></div><div class="line">p&#123;</div><div class="line">    width: 150px;</div><div class="line">    padding: 10px;</div><div class="line">    background-color: #0014ff;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<figure class="highlight html"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line"><span class="meta">&lt;!doctype html&gt;</span></div><div class="line"><span class="tag">&lt;<span class="name">html</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">head</span>&gt;</span></div><div class="line">        <span class="tag">&lt;<span class="name">meta</span> <span class="attr">charset</span>=<span class="string">"UTF-8"</span>&gt;</span></div><div class="line">        <span class="tag">&lt;<span class="name">title</span>&gt;</span><span class="tag">&lt;/<span class="name">title</span>&gt;</span></div><div class="line">        <span class="tag">&lt;<span class="name">link</span> <span class="attr">rel</span>=<span class="string">"stylesheet"</span> <span class="attr">href</span>=<span class="string">"style.css"</span> <span class="attr">type</span>=<span class="string">"text/css"</span>&gt;</span></div><div class="line">    <span class="tag">&lt;/<span class="name">head</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">body</span>&gt;</span></div><div class="line">        <span class="tag">&lt;<span class="name">p</span>&gt;</span>matt's blog<span class="tag">&lt;/<span class="name">p</span>&gt;</span></div><div class="line">    <span class="tag">&lt;/<span class="name">body</span>&gt;</span></div><div class="line"><span class="tag">&lt;/<span class="name">html</span>&gt;</span></div></pre></td></tr></table></figure>
<p>效果如下下图所示：</p>
<p><img src="/images/web/css1.png" alt="效果图"></p>
<h2 id="文本"><a href="#文本" class="headerlink" title="文本"></a>文本</h2><p>css 文本可定义文本的外观，通过文本的属性，可以改变文本的颜色、字符间距、对齐方式等等。</p>
<table>
<thead>
<tr>
<th>属性</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td>color</td>
<td>文本颜色</td>
</tr>
<tr>
<td>direction</td>
<td>文本方向</td>
</tr>
<tr>
<td>line-height</td>
<td>行高</td>
</tr>
<tr>
<td>letter-spacing</td>
<td>字符间距</td>
</tr>
<tr>
<td>text-align</td>
<td>对齐元素中的文本，可选择 left、right 和 center</td>
</tr>
<tr>
<td>text-decoration</td>
<td>向文本添加修饰</td>
</tr>
<tr>
<td>text-indent</td>
<td>缩进元素中文本的首行</td>
</tr>
<tr>
<td>text-transform</td>
<td>元素中的字母</td>
</tr>
<tr>
<td>unicode-bidi</td>
<td>设置文本方向</td>
</tr>
<tr>
<td>white-space</td>
<td>元素中空白的处理方式</td>
</tr>
<tr>
<td>word-spacing</td>
<td>字间距</td>
</tr>
</tbody>
</table>
<p>应用时，可以进行以下设置</p>
<figure class="highlight css"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="selector-tag">body</span>&#123;</div><div class="line">   <span class="attribute">color</span>: red;</div><div class="line">   <span class="attribute">text-align</span>: center;</div><div class="line">&#125;</div><div class="line"><span class="selector-tag">p</span> &#123;<span class="attribute">text-indent</span>: <span class="number">5em</span>;&#125;</div></pre></td></tr></table></figure>
<p>在网页展现时，标签 <code>body</code> 和 <code>p</code> 中元素就会按照设置进行显示。</p>
<h2 id="链接"><a href="#链接" class="headerlink" title="链接"></a>链接</h2><p>在 css 的链接属性中，可以对其颜色、字体、背景进行相应的设置，不同的状态我们可以设置对应的样式。</p>
<h3 id="4种链接状态"><a href="#4种链接状态" class="headerlink" title="4种链接状态"></a>4种链接状态</h3><p>css 共有以下几种链接状态：</p>
<ol>
<li><code>a:link</code>：普通的、未被访问的链接；</li>
<li><code>a:visited</code>：用户已访问的链接；</li>
<li><code>a:hover</code>：鼠标指针位于链接的上方；</li>
<li><code>a:active</code>：链接被点击的时刻。</li>
</ol>
<p>在进行设置中，有以下两种要求：</p>
<ul>
<li><code>a:hover</code> 必须位于 <code>a:link</code> 和 <code>a:visited</code> 之后；</li>
<li><code>a:active</code> 必须位于 <code>a:hover</code> 之后。</li>
</ul>
<h3 id="修改链接下划线"><a href="#修改链接下划线" class="headerlink" title="修改链接下划线"></a>修改链接下划线</h3><p>只需要在链接属性中添加 <code>text-decoration</code> 属性，将对应的值设置为空即可。</p>
<figure class="highlight css"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="selector-tag">a</span><span class="selector-pseudo">:link</span>&#123;</div><div class="line">    <span class="attribute">background-color</span>:<span class="number">#B2FF99</span>;</div><div class="line">    <span class="attribute">text-decoration</span>:none;</div><div class="line">&#125;</div><div class="line"><span class="selector-tag">a</span><span class="selector-pseudo">:visited</span> &#123;<span class="attribute">background-color</span>:<span class="number">#FFFF85</span>;&#125;</div><div class="line"><span class="selector-tag">a</span><span class="selector-pseudo">:hover</span> &#123;<span class="attribute">background-color</span>:<span class="number">#FF704D</span>;&#125;</div><div class="line"><span class="selector-tag">a</span><span class="selector-pseudo">:active</span> &#123;<span class="attribute">background-color</span>:<span class="number">#FF704D</span>;&#125;</div></pre></td></tr></table></figure>
<h2 id="列表"><a href="#列表" class="headerlink" title="列表"></a>列表</h2><p>在 html 中学习过列表的一些设置，这里主要讲述的是如何通过 css 进行列表的设置。</p>
<h3 id="简单的列表类型"><a href="#简单的列表类型" class="headerlink" title="简单的列表类型"></a>简单的列表类型</h3><p>列表有无序、有序之分，无序列表又可以用不同的标记来区分，而 <code>list-style-type</code> 这个属性我们就可以用来控制标记类型。</p>
<figure class="highlight html"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line">/* html 中添加以下内容 */</div><div class="line"><span class="tag">&lt;<span class="name">ul</span> <span class="attr">class</span>=<span class="string">"circle"</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">li</span>&gt;</span>haha<span class="tag">&lt;/<span class="name">li</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">li</span>&gt;</span>wawa<span class="tag">&lt;/<span class="name">li</span>&gt;</span></div><div class="line"><span class="tag">&lt;/<span class="name">ul</span>&gt;</span></div><div class="line"></div><div class="line"><span class="tag">&lt;<span class="name">olclass="square"</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">li</span>&gt;</span>haha<span class="tag">&lt;/<span class="name">li</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">li</span>&gt;</span>wawa<span class="tag">&lt;/<span class="name">li</span>&gt;</span></div><div class="line"><span class="tag">&lt;/<span class="name">ol</span>&gt;</span></div><div class="line"></div><div class="line">/* css 中的设置 */</div><div class="line">ul.circle &#123;list-style-type:circle&#125;</div><div class="line">ol.square &#123;list-style-type:upper-roman&#125;&#125;</div></pre></td></tr></table></figure>
<h3 id="列表项图片"><a href="#列表项图片" class="headerlink" title="列表项图片"></a>列表项图片</h3><p>在无序列表中，除了进行一些默认的设置外，并没有其他可选的内容，但是 css 可以提供图片来作为标记。</p>
<figure class="highlight css"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="selector-tag">ul</span><span class="selector-class">.img1</span>&#123;<span class="attribute">list-style-image</span>:<span class="built_in">url</span>(<span class="string">"1.ico"</span>)&#125;</div></pre></td></tr></table></figure>
<h2 id="表格"><a href="#表格" class="headerlink" title="表格"></a>表格</h2><p>在 css 表格的设置中，需要先了解一下属性：</p>
<table>
<thead>
<tr>
<th>属性</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td>border-collapse</td>
<td>设置是否把表格边框合并为单一的边框</td>
</tr>
<tr>
<td>border-spacing</td>
<td>设置分隔单元格边框的距离。</td>
</tr>
<tr>
<td>caption-side</td>
<td>设置表格标题的位置。</td>
</tr>
<tr>
<td>empty-cells</td>
<td>设置是否显示表格中的空单元格。</td>
</tr>
<tr>
<td>table-layout</td>
<td>设置显示单元、行和列的算法。</td>
</tr>
</tbody>
</table>
<p>这里也以一个例子来说明：</p>
<figure class="highlight html"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div></pre></td><td class="code"><pre><div class="line">/* html 部分 */</div><div class="line"><span class="tag">&lt;<span class="name">table</span> <span class="attr">id</span>=<span class="string">"tb"</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">tr</span>&gt;</span></div><div class="line">        <span class="tag">&lt;<span class="name">th</span>&gt;</span>name<span class="tag">&lt;/<span class="name">th</span>&gt;</span></div><div class="line">        <span class="tag">&lt;<span class="name">th</span>&gt;</span>age<span class="tag">&lt;/<span class="name">th</span>&gt;</span></div><div class="line">        <span class="tag">&lt;<span class="name">th</span>&gt;</span>number<span class="tag">&lt;/<span class="name">th</span>&gt;</span></div><div class="line">    <span class="tag">&lt;/<span class="name">tr</span>&gt;</span></div><div class="line"></div><div class="line">    <span class="tag">&lt;<span class="name">tr</span>&gt;</span></div><div class="line">        <span class="tag">&lt;<span class="name">td</span>&gt;</span>li<span class="tag">&lt;/<span class="name">td</span>&gt;</span></div><div class="line">        <span class="tag">&lt;<span class="name">td</span>&gt;</span>3<span class="tag">&lt;/<span class="name">td</span>&gt;</span></div><div class="line">        <span class="tag">&lt;<span class="name">td</span>&gt;</span>4<span class="tag">&lt;/<span class="name">td</span>&gt;</span></div><div class="line">    <span class="tag">&lt;/<span class="name">tr</span>&gt;</span></div><div class="line"></div><div class="line">    <span class="tag">&lt;<span class="name">tr</span> <span class="attr">class</span>=<span class="string">"tr2"</span>&gt;</span></div><div class="line">        <span class="tag">&lt;<span class="name">td</span>&gt;</span>li<span class="tag">&lt;/<span class="name">td</span>&gt;</span></div><div class="line">        <span class="tag">&lt;<span class="name">td</span>&gt;</span>3<span class="tag">&lt;/<span class="name">td</span>&gt;</span></div><div class="line">        <span class="tag">&lt;<span class="name">td</span>&gt;</span>4<span class="tag">&lt;/<span class="name">td</span>&gt;</span></div><div class="line">    <span class="tag">&lt;/<span class="name">tr</span>&gt;</span></div><div class="line"></div><div class="line">    <span class="tag">&lt;<span class="name">tr</span>&gt;</span></div><div class="line">        <span class="tag">&lt;<span class="name">td</span>&gt;</span>li<span class="tag">&lt;/<span class="name">td</span>&gt;</span></div><div class="line">        <span class="tag">&lt;<span class="name">td</span>&gt;</span>3<span class="tag">&lt;/<span class="name">td</span>&gt;</span></div><div class="line">        <span class="tag">&lt;<span class="name">td</span>&gt;</span>4<span class="tag">&lt;/<span class="name">td</span>&gt;</span></div><div class="line">    <span class="tag">&lt;/<span class="name">tr</span>&gt;</span></div><div class="line"></div><div class="line">    <span class="tag">&lt;<span class="name">tr</span> <span class="attr">class</span>=<span class="string">"tr2"</span>&gt;</span></div><div class="line">        <span class="tag">&lt;<span class="name">td</span>&gt;</span>li<span class="tag">&lt;/<span class="name">td</span>&gt;</span></div><div class="line">        <span class="tag">&lt;<span class="name">td</span>&gt;</span>3<span class="tag">&lt;/<span class="name">td</span>&gt;</span></div><div class="line">        <span class="tag">&lt;<span class="name">td</span>&gt;</span>4<span class="tag">&lt;/<span class="name">td</span>&gt;</span></div><div class="line">    <span class="tag">&lt;/<span class="name">tr</span>&gt;</span></div><div class="line"><span class="tag">&lt;/<span class="name">table</span>&gt;</span></div></pre></td></tr></table></figure>
<figure class="highlight css"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/* css 部分*/</span></div><div class="line"><span class="selector-id">#tb</span> <span class="selector-tag">td</span>,<span class="selector-tag">th</span>&#123;</div><div class="line">    <span class="attribute">border</span>: <span class="number">1px</span> solid green;</div><div class="line">    <span class="attribute">padding</span>: <span class="number">5px</span>;</div><div class="line">&#125;</div><div class="line"><span class="selector-id">#tb</span>&#123;</div><div class="line">    <span class="attribute">border-collapse</span>: collapse;</div><div class="line">    <span class="attribute">width</span>: <span class="number">500px</span>;</div><div class="line">    <span class="attribute">text-align</span>: center;</div><div class="line">&#125;</div><div class="line"><span class="selector-id">#tb</span> <span class="selector-tag">th</span>&#123;</div><div class="line">    <span class="attribute">text-align</span>: center;</div><div class="line">    <span class="attribute">color</span>: black;</div><div class="line">    <span class="attribute">background-color</span>: lightseagreen;</div><div class="line">&#125;</div><div class="line"><span class="selector-id">#tb</span> <span class="selector-tag">tr</span><span class="selector-class">.tr2</span> <span class="selector-tag">td</span>&#123;</div><div class="line">    <span class="attribute">color</span>: black;</div><div class="line">    <span class="attribute">background-color</span>: <span class="number">#B2FF99</span>;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>显示效果如下图</p>
<p><img src="/images/web/css3.png" alt="效果图"></p>
<h2 id="轮廓"><a href="#轮廓" class="headerlink" title="轮廓"></a>轮廓</h2><p>轮廓（outline）是绘制于元素周围的一条线，位于边框边缘的外围，可起到突出元素的作用。CSS outline 属性规定元素轮廓的样式、颜色和宽度。涉及到的属性有：</p>
<table>
<thead>
<tr>
<th>属性</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td>outline</td>
<td>在一个声明中设置所有的轮廓属性。</td>
</tr>
<tr>
<td>outline-color</td>
<td>设置轮廓的颜色.</td>
</tr>
<tr>
<td>outline-style</td>
<td>设置轮廓的样式。</td>
</tr>
<tr>
<td>outline-width</td>
<td>设置轮廓的宽度。</td>
</tr>
</tbody>
</table>
<figure class="highlight html"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line">/* html 部分 */</div><div class="line"><span class="tag">&lt;<span class="name">p</span> <span class="attr">id</span>=<span class="string">"p1"</span>&gt;</span>matt's blog<span class="tag">&lt;/<span class="name">p</span>&gt;</span></div><div class="line"><span class="tag">&lt;<span class="name">p</span> <span class="attr">id</span>=<span class="string">"p2"</span>&gt;</span>This is mtt's blog.<span class="tag">&lt;/<span class="name">p</span>&gt;</span></div><div class="line"></div><div class="line">/* css 部分 */</div><div class="line">#p1&#123;</div><div class="line">    outline-color: #FF704D;</div><div class="line">    outline-style: groove;</div><div class="line">    outline-width: 10px;</div><div class="line">&#125;</div><div class="line"></div><div class="line">#p2&#123;</div><div class="line">    outline-style: dotted;</div><div class="line">    outline-color: green;</div><div class="line">    outline-width: 5px;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>显示效果如下图所示：</p>
<p><img src="/images/web/css2.png" alt="效果图"></p>
<h1 id="css-选择器"><a href="#css-选择器" class="headerlink" title="css 选择器"></a>css 选择器</h1><p>选择器是 css 中最常用的组件，本节就介绍一下 css 中最常见的几种选择器。</p>
<h2 id="元素选择器"><a href="#元素选择器" class="headerlink" title="元素选择器"></a>元素选择器</h2><p>最常见的选择器就是元素选择器，文档的元素的就是最基本的选择器。比如<code>h1</code>、<code>a</code>等，在 css 中可以这样实现：</p>
<figure class="highlight css"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/*第一种，直接对某个元素进行相应的设置*/</span></div><div class="line"><span class="selector-tag">h1</span>&#123;</div><div class="line">  <span class="attribute">color</span>: cadetblue;  </div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="comment">/*第二种，对多个元素执行同样的操作*/</span></div><div class="line"><span class="selector-tag">h1</span>,<span class="selector-tag">h2</span>,<span class="selector-tag">h3</span>,<span class="selector-tag">h4</span>&#123;</div><div class="line">  <span class="attribute">color</span>: cadetblue;</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="comment">/*第三种，对没有特别特定元素设置的元素都执行同样的操作（除 h4外，其他执行的操作都一样）*/</span></div><div class="line">*&#123;</div><div class="line">  <span class="attribute">color</span>: cadetblue;</div><div class="line">&#125;</div><div class="line"><span class="selector-tag">h4</span>&#123;</div><div class="line">    <span class="attribute">color</span>: darkslategray;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h2 id="类选择器"><a href="#类选择器" class="headerlink" title="类选择器"></a>类选择器</h2><p>类选择器允许以一种独立与文档元素的方式来制定样式。<code>.class{}</code> 这是类选择器的标志，点后面是属性名，大括号里面就是具体的设置，如：</p>
<figure class="highlight css"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/*第一种，最简单的使用方法*/</span></div><div class="line"><span class="comment">/* 调用方式：&lt;div class="div"&gt;matt&lt;/div&gt; */</span></div><div class="line"><span class="selector-class">.div</span>&#123;</div><div class="line">    <span class="attribute">color</span>: cadetblue;</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="comment">/*第二种，将类选择器结合元素选择器来使用，下面的例子这个 .div 就只会对 h1 起作用*/</span></div><div class="line"><span class="comment">/* 调用方式：&lt;h1 class="div"&gt;matt&lt;/div&gt; */</span></div><div class="line"><span class="selector-tag">h1</span><span class="selector-class">.div</span>&#123;</div><div class="line">    <span class="attribute">color</span>: cadetblue;</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="comment">/*第三种，多类选择器（.class.class&#123;&#125;），它可以继承多个类的作用*/</span></div><div class="line"><span class="comment">/* 调用方式：&lt;p class="p1 p2"&gt;shiyanlou is my home&lt;/p&gt; */</span></div><div class="line"><span class="selector-class">.p1</span>&#123;</div><div class="line">    <span class="attribute">color</span>: cadetblue;</div><div class="line">&#125;</div><div class="line"><span class="selector-class">.p2</span>&#123;</div><div class="line">    <span class="attribute">font-size</span>: <span class="number">20px</span>;</div><div class="line">&#125;</div><div class="line"><span class="selector-class">.p1</span><span class="selector-class">.p2</span>&#123;</div><div class="line">    <span class="attribute">font-style</span>: italic;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h2 id="id-选择器"><a href="#id-选择器" class="headerlink" title="id 选择器"></a>id 选择器</h2><p>id 选择器类似于类选择器，id 选择器的引入是用<code>#</code>，就和类选择器的<code>.</code>是一样的效果，它与类选择器的区别是：</p>
<ul>
<li>id 顾名思义只能在文档中使用一次，而类可以使用多次；</li>
<li>id 选择器不能像刚才类选择器一样结合使用。</li>
</ul>
<figure class="highlight"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">/* html 中的用法 */</div><div class="line">&lt;p id="div"&gt;matt's blog&lt;/p&gt;</div><div class="line"></div><div class="line">/* css 中的配置*/</div><div class="line">#div&#123;</div><div class="line">    color: cadetblue;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h2 id="属性选择器"><a href="#属性选择器" class="headerlink" title="属性选择器"></a>属性选择器</h2><p>对带有指定属性的 HTML 元素设置样式。</p>
<figure class="highlight css"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/* 第一种，对带有 title 属性的所有元素设置样式 */</span></div><div class="line"><span class="selector-attr">[title]</span> &#123;<span class="attribute">color</span>:red;&#125;</div><div class="line"></div><div class="line"><span class="comment">/* 第二种，为 title="te" 的所有元素设置样式 */</span></div><div class="line"><span class="selector-attr">[title=te]</span>&#123;</div><div class="line">    <span class="attribute">color</span>: red;</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="comment">/* 第三种，为 href="http://matt33.com" 的标签 a 设置元素样式 */</span></div><div class="line"><span class="comment">/* 调用方式：&lt;a href="http://matt33.com"&gt;matt's blog&lt;/a&gt; */</span></div><div class="line"><span class="selector-tag">a</span><span class="selector-attr">[href="http://matt33.com"]</span>&#123;</div><div class="line">    <span class="attribute">color</span>: cornflowerblue;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h2 id="其他选择器"><a href="#其他选择器" class="headerlink" title="其他选择器"></a>其他选择器</h2><p>其他的还有：</p>
<ul>
<li>后代选择器</li>
<li>子元素选择器</li>
<li>相邻兄弟选择器</li>
</ul>
<p>下面仅列出一种后代选择器</p>
<figure class="highlight"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">/* html */</div><div class="line">&lt;p&gt;This is &lt;strong&gt;my&lt;/strong&gt; blog.&lt;/p&gt;</div><div class="line"></div><div class="line">/* css */</div><div class="line">p strong&#123;</div><div class="line">    color: cadetblue;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h1 id="css-盒子模型"><a href="#css-盒子模型" class="headerlink" title="css 盒子模型"></a>css 盒子模型</h1><p> css 的盒子模型主要适用于网页的布局。</p>
<h2 id="盒子模型概述"><a href="#盒子模型概述" class="headerlink" title="盒子模型概述"></a>盒子模型概述</h2><p>盒子的组成包括：</p>
<ul>
<li>margin(外边距)：边框以外就是外边距，默认外边距是透明的（可以为负）；</li>
<li>border(边框)：内边距的边缘就是边框；</li>
<li>padding(内边距)：直接包围内容的部分，它呈现了元素的背景；</li>
<li>content(内容)：正文框的最内部分就是实际的内容.</li>
</ul>
<p>其中，内边距、边框和外边距都是可选的，默认值是0。下面用一张简单的图来描述它们的结构</p>
<p><img src="/images/web/css4.png" alt="盒子模型"></p>
<h2 id="内边距"><a href="#内边距" class="headerlink" title="内边距"></a>内边距</h2><p>内边据在正文（content）外、边框（border）内，控制该区域最简单的属性是 <code>padding</code> 属性</p>
<ul>
<li><code>padding</code> 属性接受长度值或百分比值，但不允许使用负值；</li>
<li>也可以进行统一的内边距设置，也可以进行单边的内边距设置。</li>
<li>设置某一边的边据时，可以通过以下四个属性：<code>padding-top</code>、<code>padding-right</code>、<code>padding-bottom</code>、<code>padding-left</code>.</li>
</ul>
<p>举个栗子</p>
<figure class="highlight html"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line">/* html 部分 */</div><div class="line"><span class="tag">&lt;<span class="name">table</span> <span class="attr">border</span>=<span class="string">"1"</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">tr</span>&gt;</span></div><div class="line">        <span class="tag">&lt;<span class="name">td</span>&gt;</span></div><div class="line">            <span class="tag">&lt;<span class="name">h1</span>&gt;</span>正文<span class="tag">&lt;/<span class="name">h1</span>&gt;</span></div><div class="line">        <span class="tag">&lt;/<span class="name">td</span>&gt;</span></div><div class="line">    <span class="tag">&lt;/<span class="name">tr</span>&gt;</span></div><div class="line"><span class="tag">&lt;/<span class="name">table</span>&gt;</span></div><div class="line"></div><div class="line">/* css 部分 */</div><div class="line">h1 &#123;</div><div class="line">    padding-left: 5cm;</div><div class="line">    padding-right: 5cm;</div><div class="line">    padding-top: 30px;</div><div class="line">    padding-bottom: 30px;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p><img src="/images/web/css5.png" alt="内边距"></p>
<h2 id="边框"><a href="#边框" class="headerlink" title="边框"></a>边框</h2><p>元素的边框 (border) 是围绕元素内容和内边距的一条或多条线。</p>
<ul>
<li>边框的宽度可以通过这几个参数来设置：<code>border-top-width</code>、<code>border-right-width</code>、<code>border-bottom-width</code>、<code>border-left-width</code>；</li>
<li>同样可以使用属性控制各个边框的颜色：<code>border-top-color</code>、<code>border-right-color</code>、<code>border-bottom-color</code>、<code>border-left-color</code>。</li>
</ul>
<h2 id="外边距"><a href="#外边距" class="headerlink" title="外边距"></a>外边距</h2><p> 外边距就是围绕在内容框的区域，也可以使用任何长度的单位、百分数来进行设置。</p>
<ul>
<li>宽度的设置：<code>margin-top</code>、<code>margin-right</code>、<code>margin-bottom</code>、<code>margin-left</code>；</li>
<li>margin 的默认值是 0;</li>
<li>在宽度设置时，可以借助于对称复制；</li>
</ul>
<figure class="highlight html"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div></pre></td><td class="code"><pre><div class="line">/* html 部分 */</div><div class="line"><span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">"wb"</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">"bk"</span>&gt;</span></div><div class="line">        <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">"nj"</span>&gt;</span></div><div class="line">            <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">"zw"</span>&gt;</span></div><div class="line">                matt's blog</div><div class="line">            <span class="tag">&lt;/<span class="name">div</span>&gt;</span></div><div class="line">        <span class="tag">&lt;/<span class="name">div</span>&gt;</span></div><div class="line">    <span class="tag">&lt;/<span class="name">div</span>&gt;</span></div><div class="line"><span class="tag">&lt;/<span class="name">div</span>&gt;</span></div><div class="line"></div><div class="line">/* css 部分 */</div><div class="line">.wb&#123;</div><div class="line">    margin: 100px;</div><div class="line">&#125;</div><div class="line">.bk&#123;</div><div class="line">    border-style: groove;</div><div class="line">&#125;</div><div class="line">.nj&#123;</div><div class="line">    padding: 10px;</div><div class="line">&#125;</div><div class="line">.zw&#123;</div><div class="line">    background-color: cornflowerblue;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p><img src="/images/web/css5.png" alt="盒子模型举例"></p>
<h1 id="css-一些高级用法"><a href="#css-一些高级用法" class="headerlink" title="css 一些高级用法"></a>css 一些高级用法</h1><p> 这里是 css 中一些高级的常见用法</p>
<h2 id="定位"><a href="#定位" class="headerlink" title="定位"></a>定位</h2><p>定位，就是定义元素框相对于其正常位置应该出现的位置，或者相对于父元素、另一个元素甚至浏览器窗口本身的位置。</p>
<p>在 css 中，有三种基本的定位机制：</p>
<ol>
<li>普通流：在位置顺序决定排版顺序；</li>
<li>浮动：浮动的框可以向左或向右移动，直到它的外边缘碰到包含框或另一个浮动框的边框为止；</li>
<li>绝对定位：绝对定位使元素的位置与文档流无关，因此不占据空间。这一点与相对定位不同，相对定位实际上被看作普通流定位模型的一部分，因为元素的位置相对于它在普通流中的位置。</li>
</ol>
<p>定位有以下几个属性:</p>
<ul>
<li>position：将元素放在一个静态的，相对的，绝对的或固定的位置；</li>
<li>通过对 top、left、right、bottom 这四个属性的赋值让元素向对应的方向偏移；</li>
<li>overflow：设置元素溢出其区域发生的事情；</li>
<li>clip：设置元素的显示形状，多用于图片；</li>
<li>vertical-align：设置元素的垂直对其方式；</li>
<li>z-index：设置元素的堆叠顺序。</li>
</ul>
<p><code>position</code> 属性，有以下四种设置：</p>
<ol>
<li>relative：就是普通流；</li>
<li>absolute：这个就是绝对定位，该元素区域会与文档区域重合，因为它使用该元素与文档流无关；</li>
<li>fixed：将元素固定下来,就算滚动屏幕,它也会在同一个地方不会动；</li>
<li>static：设置以后,偏移量什么的就没用了。</li>
</ol>
<figure class="highlight css"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="selector-class">.position1</span>&#123;</div><div class="line">    <span class="attribute">width</span>: <span class="number">100px</span>;</div><div class="line">    <span class="attribute">height</span>: <span class="number">100px</span>;</div><div class="line">    <span class="attribute">background-color</span>: cornflowerblue;</div><div class="line">    <span class="attribute">position</span>: relative;</div><div class="line">    <span class="attribute">left</span>: <span class="number">60px</span>;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h2 id="浮动"><a href="#浮动" class="headerlink" title="浮动"></a>浮动</h2><p>这里涉及到的属性就是 <code>float</code>，其值可以赋值为：</p>
<ul>
<li>left: 元素向左浮动；</li>
<li>right: 元素向右浮动；</li>
<li>none: 不浮动；</li>
<li>inherit: 从父级继承浮动的属性；</li>
<li>clear: 主要用于去掉向各方向的浮动属性(包括继承来的属性)。</li>
</ul>
<figure class="highlight html"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div></pre></td><td class="code"><pre><div class="line">/* html 部分 */</div><div class="line"><span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">"qd"</span>&gt;</span><span class="tag">&lt;/<span class="name">div</span>&gt;</span></div><div class="line"><span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">"wd"</span>&gt;</span><span class="tag">&lt;/<span class="name">div</span>&gt;</span></div><div class="line"><span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">"ed"</span>&gt;</span><span class="tag">&lt;/<span class="name">div</span>&gt;</span></div><div class="line"></div><div class="line">/* css 部分 */</div><div class="line">.qd&#123;</div><div class="line">    width: 100px;</div><div class="line">    height: 100px;</div><div class="line">    background-color: lightskyblue;</div><div class="line">    float: left;</div><div class="line">&#125;</div><div class="line">.wd&#123;</div><div class="line">    width: 100px;</div><div class="line">    height: 100px;</div><div class="line">    background-color: lightseagreen;</div><div class="line">    float: left;</div><div class="line">&#125;</div><div class="line">.ed&#123;</div><div class="line">    width: 100px;</div><div class="line">    height: 100px;</div><div class="line">    background-color: lightsalmon;</div><div class="line">    float: right;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>效果如下图所示：</p>
<p><img src="/images/web/css7.png" alt="css 浮动"></p>
<h2 id="尺寸"><a href="#尺寸" class="headerlink" title="尺寸"></a>尺寸</h2><p>尺寸属性允许你控制元素的高度和宽度。同样，它允许你增加行间距。涉及到的属性有：</p>
<ul>
<li>height– 设置元素的高度。</li>
<li>line-height –设置行高。</li>
<li>max-height– 设置元素的最大高度。</li>
<li>max-width –设置元素的最大宽度。</li>
<li>min-height –设置元素的最小高度。</li>
<li>min-width –设置元素的最小宽度。</li>
<li><p>width –设置元素的宽度。</p>
<p>举例说明</p>
<figure class="highlight css"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line"> <span class="selector-class">.p1</span>&#123;</div><div class="line">    <span class="attribute">line-height</span>: normal;</div><div class="line">    <span class="attribute">width</span>: <span class="number">400px</span>;</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="selector-class">.p2</span>&#123;</div><div class="line">    <span class="attribute">line-height</span>: <span class="number">50%</span>;</div><div class="line">    <span class="attribute">width</span>: <span class="number">400px</span>;</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="selector-class">.p3</span>&#123;</div><div class="line">    <span class="attribute">line-height</span>: <span class="number">200%</span>;</div><div class="line">   <span class="attribute">width</span>: <span class="number">400px</span>;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
</li>
</ul>
<h2 id="导航栏"><a href="#导航栏" class="headerlink" title="导航栏"></a>导航栏</h2><p>这里通过一个示例来实现导航栏的功能。</p>
<figure class="highlight html"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div></pre></td><td class="code"><pre><div class="line">/* html 部分 */</div><div class="line"><span class="tag">&lt;<span class="name">ul</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">li</span>&gt;</span><span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">"http://matt33.com"</span>&gt;</span>blog1<span class="tag">&lt;/<span class="name">a</span>&gt;</span><span class="tag">&lt;/<span class="name">li</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">li</span>&gt;</span><span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">"http://matt33.com"</span>&gt;</span>blog2<span class="tag">&lt;/<span class="name">a</span>&gt;</span><span class="tag">&lt;/<span class="name">li</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">li</span>&gt;</span><span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">"http://matt33.com"</span>&gt;</span>blog3<span class="tag">&lt;/<span class="name">a</span>&gt;</span><span class="tag">&lt;/<span class="name">li</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">li</span>&gt;</span><span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">"http://matt33.com"</span>&gt;</span>blog4<span class="tag">&lt;/<span class="name">a</span>&gt;</span><span class="tag">&lt;/<span class="name">li</span>&gt;</span></div><div class="line"><span class="tag">&lt;/<span class="name">ul</span>&gt;</span></div><div class="line"></div><div class="line">/* css 部分 */</div><div class="line">ul&#123;</div><div class="line">    list-style: none;</div><div class="line">&#125;</div><div class="line"></div><div class="line">li&#123;</div><div class="line">    float:left;</div><div class="line">&#125;</div><div class="line"></div><div class="line">a:link,a:visited&#123;</div><div class="line">   text-decoration: none;</div><div class="line">   background-color: lightgray;</div><div class="line">   display: block;</div><div class="line">   width: 100px;</div><div class="line">   margin:5px 10px;</div><div class="line">&#125;</div><div class="line">a:active,a:hover&#123;</div><div class="line">    background-color: cadetblue;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>显示效果如下：</p>
<p><img src="/images/web/css9.png" alt="水平导航栏"></p>
<h2 id="图片"><a href="#图片" class="headerlink" title="图片"></a>图片</h2><p>插入一张图片，加上一句描述符，使用 <code>div</code> 继承</p>
<figure class="highlight html"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div></pre></td><td class="code"><pre><div class="line">/* html 部分 */</div><div class="line"><span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">"image"</span>&gt;</span></div><div class="line">        <span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">"./hha.jpg"</span> <span class="attr">target</span>=<span class="string">"_self"</span>&gt;</span></div><div class="line">            <span class="tag">&lt;<span class="name">img</span> <span class="attr">src</span>=<span class="string">"hha.jpg"</span> <span class="attr">width</span>=<span class="string">"150px"</span> <span class="attr">height</span>=<span class="string">"150px"</span>&gt;</span></div><div class="line">        <span class="tag">&lt;/<span class="name">a</span>&gt;</span></div><div class="line">        <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">"text"</span>&gt;</span>haha<span class="tag">&lt;/<span class="name">div</span>&gt;</span></div><div class="line"><span class="tag">&lt;/<span class="name">div</span>&gt;</span></div><div class="line"></div><div class="line">/* css 部分 */</div><div class="line">.image&#123;</div><div class="line">    border: 2px solid darkgrey;</div><div class="line">    width: auto;</div><div class="line">    height: auto;</div><div class="line">    float: left;</div><div class="line">    text-align: center;</div><div class="line">    padding: 5px;</div><div class="line">&#125;</div><div class="line">img&#123;</div><div class="line">    padding: 5px;</div><div class="line">&#125;</div><div class="line">.text&#123;</div><div class="line">    font-size: 20px;</div><div class="line">    margin-bottom: 5px;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>显示效果如下：</p>
<p><img src="/images/web/css8.png" alt="css 图片"></p>
<p>然后可以通过 <code>opacity</code> 属性来设置透明度，属性值的范围为0-1，0是完全透明，1是完全不透明。</p>
<p>到这里，css 基本内容已经总结完了，不过本文后续会一直更新，遇到什么常用的设置，都会更新到本文中。</p>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[HTML 一些常用方法的总结]]></title>
      <url>http://matt33.com/2017/06/18/html-summary/</url>
      <content type="html"><![CDATA[<p>HTML 是一种语言，是用来描述网页的语言，它是一种标记语言，HTML 就是使用标记标签来描述网页。</p>
<p>HTML 算是最容易学习的语言之一，它也是必须掌握的一门语言，之前对 HTML 只是大概了解，并没有开发过前端页面，现在在工作中，会使用前端框架已经成为了一项必备技能，所以花了点时间简单看了一下<a href="https://www.shiyanlou.com/courses/19" target="_blank" rel="external">实验楼-HTML 基础课</a>，稍微再学习一下 HTML 的相关知识，本文记录一下一些常用的 HTML 内容，后期还会对 css 简单总结一下。</p>
<h1 id="HTML-最基本用法"><a href="#HTML-最基本用法" class="headerlink" title="HTML 最基本用法"></a>HTML 最基本用法</h1><p>这里先介绍一下 HTML 的最基本用法。</p>
<h2 id="文档"><a href="#文档" class="headerlink" title="文档"></a>文档</h2><p>HTML 文档也被称为网页，它包括标签和文本。Web 浏览器的作用就是读取 HTML 文档，并以网页的形式显示出它们，浏览器不会显示 HTML 标签，而是使用标签来解释页面的内容。</p>
<figure class="highlight html"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="tag">&lt;<span class="name">html</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">body</span>&gt;</span></div><div class="line">        <span class="tag">&lt;<span class="name">h1</span>&gt;</span>First Heading<span class="tag">&lt;/<span class="name">h1</span>&gt;</span></div><div class="line">         <span class="tag">&lt;<span class="name">p</span>&gt;</span>first paragraph<span class="tag">&lt;/<span class="name">p</span>&gt;</span></div><div class="line">    <span class="tag">&lt;/<span class="name">body</span>&gt;</span></div><div class="line"><span class="tag">&lt;/<span class="name">html</span>&gt;</span></div></pre></td></tr></table></figure>
<p>上面是最简单的一个网页，其中：</p>
<ol>
<li>&lt; html&gt; 与 &lt; /html&gt; 之间的文本描述网页；</li>
<li>&lt; body&gt; 与 &lt; /body&gt; 之间的文本是可见的页面内容；</li>
<li>&lt; h1&gt; 与 &lt; /h1&gt; 之间的文本被显示为标题；</li>
<li>&lt; p&gt; 与 &lt; /p&gt; 之间的文本被显示为段落。</li>
</ol>
<h2 id="标签"><a href="#标签" class="headerlink" title="标签"></a>标签</h2><h3 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h3><ul>
<li>标签：就是上面这些 <code>&lt;head&gt;</code>、<code>&lt;body&gt;</code>、<code>&lt;table&gt;</code> 等被尖括号<code>&lt;</code>和<code>&gt;</code>包起来的对象，绝大部分的标签都是成对出现的，如 <code>&lt;table&gt;&lt;/talbe&gt;</code>、<code>&lt;form&gt;&lt;/form&gt;</code>；</li>
<li>标签对中的第一个标签是开始标签，第二个标签是结束标签，开始和结束标签也被称为开放标签和闭合标签；</li>
<li>也有少部分不是成对出现的，如<code>&lt;br&gt;</code>、<code>&lt;hr&gt;</code>等；</li>
<li>标签就是用来标记 HTML 元素的，位于起始标签和结束标签之间的文本就是HTML元素的内容。</li>
<li>HTML 元素就是通过使用 HTML 标签进行定义的，比如 <code>&lt;p&gt;</code> 这就是一个标签，而 <code>&lt;p&gt;内容&lt;/p&gt;</code> 这就是一个<strong>元素</strong>，也就是说<code>元素由一个开始的标签和结束的标签组成，用来包含某些内容</code>，这里有一个值得注意的例外，即 <code>&lt;br&gt;</code> 本身既是开始标签也是结束标签，但不包含任何内容，所以这只是个标签。</li>
</ul>
<h3 id="常用标签"><a href="#常用标签" class="headerlink" title="常用标签"></a>常用标签</h3><p>四种最基本的标签：</p>
<ol>
<li>标题：通过 <code>&lt;h1&gt;</code> - <code>&lt;h6&gt;</code> 等标签进行定义的；</li>
<li>段落：通过 <code>&lt;p&gt;</code> 标签进行定义的；</li>
<li>链接：是通过 <code>&lt;a&gt;</code> 标签进行定义的，<code>&lt;a href=&quot;http://matt33.com&quot;&gt;matt&lt;/a&gt;</code>；</li>
<li>图像：通过 <code>&lt;img&gt;</code> 标签进行定义的，<code>&lt;img src=&quot;matt.jpg&quot; width=&quot;100&quot; height=&quot;142&quot; /&gt;</code>；</li>
</ol>
<p>注： HTML 标签对大小写不敏感：<code>&lt;P&gt;</code> 等同于 <code>&lt;p&gt;</code>.</p>
<h1 id="HTML-文本"><a href="#HTML-文本" class="headerlink" title="HTML 文本"></a>HTML 文本</h1><h2 id="HTML-元素"><a href="#HTML-元素" class="headerlink" title="HTML 元素"></a>HTML 元素</h2><p><strong>HTML 元素</strong>指的是从开始标签（start tag）到结束标签（end tag）的所有代码。</p>
<p>HTML网页实际上就是由许许多多各种各样的HTML元素构成的文本文件，并且任何网页浏览器都可以直接运行HTML文件。</p>
<h3 id="元素语法"><a href="#元素语法" class="headerlink" title="元素语法"></a>元素语法</h3><p>元素语法特点：</p>
<ul>
<li>HTML 元素以开始标签起始；</li>
<li>HTML 元素以结束标签终止；</li>
<li>元素的内容是开始标签与结束标签之间的内容；</li>
<li>某些 HTML 元素具有空内容（empty content）；</li>
<li>空元素在开始标签中进行关闭（以开始标签的结束而结束）；</li>
<li>大多数 HTML 元素可拥有属性。</li>
</ul>
<h3 id="空元素"><a href="#空元素" class="headerlink" title="空元素"></a>空元素</h3><p>HTML 元素的内容是开始标签与结束标签之间的内容，而某些 HTML 元素具有空内容（empty content），这种元素被叫做<strong>空元素</strong>，比如说换行符<code>&lt;br&gt;</code>。</p>
<p>为了规范起见，换行符最好还是用 <code>&lt;br/&gt;</code>。</p>
<p><code>&lt;p&gt;</code> 标签结束以后也后一个换行的动作，那 <code>&lt;p&gt;</code> 标签和 <code>&lt;br/&gt;</code> 标签有什么异同呢？</p>
<ol>
<li>相同之处是 <code>&lt;br&gt;</code> 和 <code>&lt;p&gt;</code> 都是有换行的属性及作用；</li>
<li>区别 <code>&lt;br/&gt;</code> 是只需一个单独使用，而 <code>&lt;p&gt;</code> 和 <code>&lt;/p&gt;</code> 是一对使用；</li>
<li><code>&lt;br/&gt;</code> 标签是小换行提行（相当于我们平时文本中输入一个回车），<code>&lt;p&gt;</code> 标签是大换行（分段，相当与两个回车）,隔行作用。</li>
</ol>
<h2 id="HTML-属性"><a href="#HTML-属性" class="headerlink" title="HTML 属性"></a>HTML 属性</h2><p>某些标签要按照开发者的意愿来实现在网页上，就得需要一定信息的补充，这信息就叫<strong>属性</strong>，HTML 标签可以加上属性的描述，属性提供了有关 HTML 元素的更多的信息。</p>
<p>关于属性有以下语法规则：</p>
<ul>
<li>是在 HTML 元素的开始标签中定义；</li>
<li>总是以名称和值对应的形式出现，比如：<code>name=&quot;value&quot;</code>。</li>
<li>属性值应该始终被包括在引号内。双引号是最常用的，不过使用单引号也没有问题。</li>
</ul>
<p>举例，下面这个就是 <code>&lt;a&gt;</code> 标签的属性，是对 <code>&lt;a&gt;</code> 标签的补充说明，既指向网页。</p>
<figure class="highlight html"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">"http://matt33.com"</span>&gt;</span>matt<span class="tag">&lt;/<span class="name">a</span>&gt;</span></div></pre></td></tr></table></figure>
<p>大多数的标签都会有各种各样的属性，没必要记住所有的属性，只需要在实践中多积累，知道哪些属性是常用的，知道如何查资料即可。</p>
<h2 id="HTML-文本格式化"><a href="#HTML-文本格式化" class="headerlink" title="HTML 文本格式化"></a>HTML 文本格式化</h2><p>一般我们在网页中能看见有各种各样的字体、文本样式，这就是文本格式化标签的功劳。下面的文本格式化标签是比较常用的：</p>
<table>
<thead>
<tr>
<th>标签</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>&lt;b&gt;</code></td>
<td>（bold）粗体</td>
</tr>
<tr>
<td><code>&lt;big&gt;</code></td>
<td>（big）大字体</td>
</tr>
<tr>
<td><code>&lt;em&gt;</code></td>
<td>（emphasized）强调字</td>
</tr>
<tr>
<td><code>&lt;i&gt;</code></td>
<td>（italic）斜体</td>
</tr>
<tr>
<td><code>&lt;small&gt;</code></td>
<td>（small）小字体</td>
</tr>
<tr>
<td><code>&lt;strong&gt;</code></td>
<td>(strong)加重语气</td>
</tr>
</tbody>
</table>
<h2 id="HTML-样式"><a href="#HTML-样式" class="headerlink" title="HTML 样式"></a>HTML 样式</h2><p>style 提供了一种改变所有 HTML 元素的样式的通用方法。这里可以将，背景颜色，字体样式，字体尺寸，字体颜色，对齐方式一并定义好。</p>
<figure class="highlight html"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="tag">&lt;<span class="name">html</span>&gt;</span></div><div class="line"><span class="tag">&lt;<span class="name">body</span>&gt;</span></div><div class="line"><span class="tag">&lt;<span class="name">p</span> <span class="attr">style</span>=<span class="string">"text-align:center;font-family:verdana;color:gray"</span>&gt;</span> verdana and white<span class="tag">&lt;/<span class="name">p</span>&gt;</span></div><div class="line"><span class="tag">&lt;<span class="name">p</span> <span class="attr">style</span>=<span class="string">"font-family:time;color:greeen"</span>&gt;</span> time and green words<span class="tag">&lt;/<span class="name">p</span>&gt;</span></div><div class="line"><span class="tag">&lt;/<span class="name">body</span>&gt;</span></div><div class="line"><span class="tag">&lt;/<span class="name">html</span>&gt;</span></div></pre></td></tr></table></figure>
<h1 id="HTML-超文本"><a href="#HTML-超文本" class="headerlink" title="HTML 超文本"></a>HTML 超文本</h1><h2 id="HTML-链接"><a href="#HTML-链接" class="headerlink" title="HTML 链接"></a>HTML 链接</h2><p>通过网页中超链接，可以连接到自己感兴趣的地方。</p>
<h3 id="给文字及图片添加超链接"><a href="#给文字及图片添加超链接" class="headerlink" title="给文字及图片添加超链接"></a>给文字及图片添加超链接</h3><p>最简单的链接就是将文字添加链接连接到网页和另外的 HTML 文件，给图片添加链接。</p>
<figure class="highlight html"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div></pre></td><td class="code"><pre><div class="line"><span class="tag">&lt;<span class="name">html</span>&gt;</span></div><div class="line"><span class="tag">&lt;<span class="name">body</span>&gt;</span></div><div class="line"></div><div class="line">    <span class="tag">&lt;<span class="name">p</span>&gt;</span>let's have an example<span class="tag">&lt;/<span class="name">p</span>&gt;</span></div><div class="line"></div><div class="line">    <span class="tag">&lt;<span class="name">p</span>&gt;</span>   </div><div class="line">        <span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">"http://matt33.com"</span>&gt;</span>matt<span class="tag">&lt;/<span class="name">a</span>&gt;</span></div><div class="line">    <span class="tag">&lt;/<span class="name">p</span>&gt;</span></div><div class="line"></div><div class="line">    <span class="tag">&lt;<span class="name">p</span>&gt;</span></div><div class="line">        <span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">"matt.html"</span>&gt;</span>another html<span class="tag">&lt;/<span class="name">a</span>&gt;</span></div><div class="line">    <span class="tag">&lt;/<span class="name">p</span>&gt;</span></div><div class="line"></div><div class="line">    <span class="tag">&lt;<span class="name">p</span>&gt;</span></div><div class="line">         <span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">"http://matt33.com"</span>&gt;</span><span class="tag">&lt;<span class="name">img</span> <span class="attr">src</span>=<span class="string">"touxiang.jpg"</span> /&gt;</span><span class="tag">&lt;/<span class="name">a</span>&gt;</span></div><div class="line">    <span class="tag">&lt;/<span class="name">p</span>&gt;</span></div><div class="line"></div><div class="line"><span class="tag">&lt;/<span class="name">body</span>&gt;</span></div><div class="line"><span class="tag">&lt;/<span class="name">html</span>&gt;</span></div></pre></td></tr></table></figure>
<h3 id="超链接的打开方式"><a href="#超链接的打开方式" class="headerlink" title="超链接的打开方式"></a>超链接的打开方式</h3><p>打开方式分为在本页打开和在新的浏览器窗口打开，超级链接标签提供了 <code>target</code> 属性进行设置，取值分别为<code>_self</code>（在本页打开，默认）、<code>_blank</code>（创建新窗口打开新）。</p>
<figure class="highlight html"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line"><span class="tag">&lt;<span class="name">html</span>&gt;</span></div><div class="line"><span class="tag">&lt;<span class="name">body</span>&gt;</span></div><div class="line"></div><div class="line">    <span class="tag">&lt;<span class="name">p</span>&gt;</span>let's have an example<span class="tag">&lt;/<span class="name">p</span>&gt;</span></div><div class="line"></div><div class="line">    <span class="tag">&lt;<span class="name">p</span>&gt;</span>   </div><div class="line">        <span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">"http://matt33.com"</span> <span class="attr">target</span>=<span class="string">"_blank"</span>&gt;</span>matt<span class="tag">&lt;/<span class="name">a</span>&gt;</span></div><div class="line">    <span class="tag">&lt;/<span class="name">p</span>&gt;</span></div><div class="line"></div><div class="line"><span class="tag">&lt;/<span class="name">body</span>&gt;</span></div><div class="line"><span class="tag">&lt;/<span class="name">html</span>&gt;</span></div></pre></td></tr></table></figure>
<h3 id="超链接添加提示文字"><a href="#超链接添加提示文字" class="headerlink" title="超链接添加提示文字"></a>超链接添加提示文字</h3><p>有些时候超链接文字不足以说明点击以后所要链接的内容，所以这个时候我们就需要给超链接添加提示文字，加以描述下一个链接的内容，当光标停留在超链接上时，提示语言就会显现，会让页面显现的很简介。</p>
<figure class="highlight html"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line"><span class="tag">&lt;<span class="name">html</span>&gt;</span></div><div class="line"><span class="tag">&lt;<span class="name">body</span>&gt;</span></div><div class="line"></div><div class="line">    <span class="tag">&lt;<span class="name">p</span>&gt;</span>let's have an example<span class="tag">&lt;/<span class="name">p</span>&gt;</span></div><div class="line"></div><div class="line">    <span class="tag">&lt;<span class="name">p</span>&gt;</span>   </div><div class="line">        <span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">"http://matt33.com"</span> <span class="attr">title</span>=<span class="string">"this word will link to the wed of matt's blog."</span>&gt;</span>matt<span class="tag">&lt;/<span class="name">a</span>&gt;</span></div><div class="line">    <span class="tag">&lt;/<span class="name">p</span>&gt;</span></div><div class="line"></div><div class="line"><span class="tag">&lt;/<span class="name">body</span>&gt;</span></div><div class="line"><span class="tag">&lt;/<span class="name">html</span>&gt;</span></div></pre></td></tr></table></figure>
<h3 id="超链接实现书签"><a href="#超链接实现书签" class="headerlink" title="超链接实现书签"></a>超链接实现书签</h3><p>在阅读小说时，会发现当在点击相应章节的题目时，可以跳转到相应的章节，想实现这种效果，就必须要了解什么是锚（anchor），实际上就是锚用于在单个网页内不同位置的跳转，锚也叫做书签。</p>
<ul>
<li>涉及到的标签还是 <code>&lt;a&gt;</code> 标签，超级链接标签的 <code>name</code> 属性用于定义锚的名称；</li>
<li>一个页面可以定义多个锚，通过超级链接的 <code>href</code> 属性可以根据 <code>name</code> 跳转到对应的锚。</li>
</ul>
<figure class="highlight html"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div></pre></td><td class="code"><pre><div class="line"><span class="tag">&lt;<span class="name">html</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">head</span>&gt;</span></div><div class="line">        <span class="tag">&lt;<span class="name">title</span>&gt;</span>HTML<span class="tag">&lt;/<span class="name">title</span>&gt;</span>  </div><div class="line">    <span class="tag">&lt;/<span class="name">head</span>&gt;</span>  </div><div class="line">    <span class="tag">&lt;<span class="name">body</span> <span class="attr">style</span>=<span class="string">"font-size:20px"</span>&gt;</span></div><div class="line"></div><div class="line">        <span class="tag">&lt;<span class="name">p</span> <span class="attr">style</span>=<span class="string">"text-align:center"</span>&gt;</span>HTML LEARNING<span class="tag">&lt;/<span class="name">p</span>&gt;</span></div><div class="line"></div><div class="line">        <span class="tag">&lt;<span class="name">p</span>&gt;</span></div><div class="line">            <span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">"#c1"</span>&gt;</span>  HTML first<span class="tag">&lt;/<span class="name">a</span>&gt;</span></div><div class="line">        <span class="tag">&lt;/<span class="name">p</span>&gt;</span></div><div class="line">        <span class="tag">&lt;<span class="name">p</span>&gt;</span></div><div class="line">            <span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">"#c2"</span>&gt;</span>HTML second <span class="tag">&lt;/<span class="name">a</span>&gt;</span></div><div class="line">        <span class="tag">&lt;/<span class="name">p</span>&gt;</span></div><div class="line">        <span class="tag">&lt;<span class="name">p</span>&gt;</span></div><div class="line">            <span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">"#c3"</span>&gt;</span>HTML third <span class="tag">&lt;/<span class="name">a</span>&gt;</span></div><div class="line">        <span class="tag">&lt;/<span class="name">p</span>&gt;</span></div><div class="line"></div><div class="line"></div><div class="line">        <span class="tag">&lt;<span class="name">h1</span>&gt;</span><span class="tag">&lt;<span class="name">a</span> <span class="attr">name</span>=<span class="string">"c1"</span>&gt;</span><span class="tag">&lt;/<span class="name">a</span>&gt;</span>chapter 1 first HTML<span class="tag">&lt;/<span class="name">h1</span>&gt;</span></div><div class="line">        <span class="tag">&lt;<span class="name">p</span>&gt;</span>lalalaalalal<span class="tag">&lt;/<span class="name">p</span>&gt;</span></div><div class="line">        <span class="tag">&lt;<span class="name">p</span>&gt;</span>lalalaalalal<span class="tag">&lt;/<span class="name">p</span>&gt;</span></div><div class="line">        <span class="tag">&lt;<span class="name">p</span>&gt;</span>lalalaalalal<span class="tag">&lt;/<span class="name">p</span>&gt;</span></div><div class="line"></div><div class="line">        <span class="tag">&lt;<span class="name">h1</span>&gt;</span><span class="tag">&lt;<span class="name">a</span> <span class="attr">name</span>=<span class="string">"c2"</span>&gt;</span><span class="tag">&lt;/<span class="name">a</span>&gt;</span>chapter 2 second HTML<span class="tag">&lt;/<span class="name">h1</span>&gt;</span></div><div class="line">        <span class="tag">&lt;<span class="name">p</span>&gt;</span>lalalaalalal<span class="tag">&lt;/<span class="name">p</span>&gt;</span></div><div class="line">        <span class="tag">&lt;<span class="name">p</span>&gt;</span>lalalaalalal<span class="tag">&lt;/<span class="name">p</span>&gt;</span></div><div class="line">        <span class="tag">&lt;<span class="name">p</span>&gt;</span>lalalaalalal<span class="tag">&lt;/<span class="name">p</span>&gt;</span></div><div class="line"></div><div class="line">        <span class="tag">&lt;<span class="name">h1</span>&gt;</span><span class="tag">&lt;<span class="name">a</span> <span class="attr">name</span>=<span class="string">"c3"</span>&gt;</span><span class="tag">&lt;/<span class="name">a</span>&gt;</span>chapter 3 chaowenben 1 HTML<span class="tag">&lt;/<span class="name">h1</span>&gt;</span></div><div class="line">        <span class="tag">&lt;<span class="name">p</span>&gt;</span>lalalaalalal<span class="tag">&lt;/<span class="name">p</span>&gt;</span></div><div class="line">        <span class="tag">&lt;<span class="name">p</span>&gt;</span>lalalaalalal<span class="tag">&lt;/<span class="name">p</span>&gt;</span></div><div class="line">        <span class="tag">&lt;<span class="name">p</span>&gt;</span>lalalaalalal<span class="tag">&lt;/<span class="name">p</span>&gt;</span></div><div class="line">    <span class="tag">&lt;/<span class="name">body</span>&gt;</span></div><div class="line"><span class="tag">&lt;/<span class="name">html</span>&gt;</span></div></pre></td></tr></table></figure>
<h2 id="HTML-表格"><a href="#HTML-表格" class="headerlink" title="HTML 表格"></a>HTML 表格</h2><p>表格在 HTML 中是不可缺少的元素，表格主要包括了 <code>table</code>、<code>tr</code> 和 <code>td</code> 这几个标签：</p>
<ol>
<li>表格由 <code>&lt;table&gt;</code> 标签来定义；</li>
<li>每个表格均有若干行（由 <code>&lt;tr&gt;</code> 标签定义）；</li>
<li>每行被分割为若干单元格（由 <code>&lt;td&gt;</code> 标签定义）;</li>
<li>字母 <code>td</code> 指表格数据（table data），即数据单元格的内容。<code>&lt;th&gt;</code>标签用来定义表头;</li>
<li><code>border=&quot;1&quot;</code>定义的是最外面边框粗细，为1，你也可以设置为0，就是不显示边框；</li>
<li><code>colspan</code>：控制此单位所占列数；</li>
<li><code>rowspan</code>：控制此单位所占行数；</li>
</ol>
<p>还有一些其他的属性：</p>
<ul>
<li>标签：<code>&lt;th&gt;表头&lt;/th&gt;</code>：设置表头；</li>
<li>标签：<code>&lt;caption&gt;标题&lt;/caption&gt;</code>：设置表的标题；</li>
<li>属性：<code>cellpadding=&quot;...&quot;</code> 设置单元格边距；</li>
<li><p>属性：<code>bgcolor=&quot;...&quot;</code> 设置表格背景颜色；</p>
</li>
<li><p>属性：<code>background=&quot;...&quot;</code> 以某张图片作为表格背景。</p>
</li>
</ul>
<figure class="highlight html"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div></pre></td><td class="code"><pre><div class="line"><span class="tag">&lt;<span class="name">html</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">title</span> &gt;</span>TABLE<span class="tag">&lt;/<span class="name">title</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">body</span> <span class="attr">style</span>=<span class="string">"font-size:30px"</span>&gt;</span></div><div class="line">        <span class="tag">&lt;<span class="name">p</span> <span class="attr">style</span>=<span class="string">"text-align:center"</span>&gt;</span>table practice<span class="tag">&lt;/<span class="name">p</span>&gt;</span></div><div class="line">        <span class="tag">&lt;<span class="name">table</span>  <span class="attr">align</span>=<span class="string">"center"</span> <span class="attr">border</span>=<span class="string">"15"</span> &gt;</span></div><div class="line">            <span class="tag">&lt;<span class="name">tr</span>&gt;</span></div><div class="line">                 <span class="tag">&lt;<span class="name">td</span> <span class="attr">align</span>=<span class="string">"center"</span> <span class="attr">colspan</span>=<span class="string">"2"</span>&gt;</span>first row and first column<span class="tag">&lt;/<span class="name">td</span>&gt;</span></div><div class="line">             <span class="tag">&lt;/<span class="name">tr</span>&gt;</span></div><div class="line">             <span class="tag">&lt;<span class="name">tr</span>&gt;</span></div><div class="line">                 <span class="tag">&lt;<span class="name">td</span> <span class="attr">rowspan</span>=<span class="string">"2"</span>&gt;</span>second row and first column <span class="tag">&lt;/<span class="name">td</span>&gt;</span></div><div class="line">                 <span class="tag">&lt;<span class="name">td</span>&gt;</span>second row and second column <span class="tag">&lt;/<span class="name">td</span>&gt;</span></div><div class="line">                 <span class="tag">&lt;<span class="name">td</span> &gt;</span>second row and third column<span class="tag">&lt;/<span class="name">td</span>&gt;</span></div><div class="line">             <span class="tag">&lt;/<span class="name">tr</span>&gt;</span></div><div class="line">             <span class="tag">&lt;<span class="name">tr</span>&gt;</span></div><div class="line">                 <span class="tag">&lt;<span class="name">td</span>&gt;</span>third row and first column <span class="tag">&lt;/<span class="name">td</span>&gt;</span></div><div class="line">                 <span class="tag">&lt;<span class="name">td</span>&gt;</span>third row and second column <span class="tag">&lt;/<span class="name">td</span>&gt;</span></div><div class="line">             <span class="tag">&lt;/<span class="name">tr</span>&gt;</span></div><div class="line">        <span class="tag">&lt;/<span class="name">table</span>&gt;</span>   </div><div class="line">    <span class="tag">&lt;/<span class="name">body</span>&gt;</span></div><div class="line"><span class="tag">&lt;/<span class="name">html</span>&gt;</span></div></pre></td></tr></table></figure>
<h2 id="HTML-图像"><a href="#HTML-图像" class="headerlink" title="HTML 图像"></a>HTML 图像</h2><p>对于 HTML 图像，一般涉及到的就是以下几类：</p>
<ul>
<li>将图片作为背景；</li>
<li>插入图片</li>
<li>将图片作为链接。</li>
</ul>
<h3 id="图片作为背景"><a href="#图片作为背景" class="headerlink" title="图片作为背景"></a>图片作为背景</h3><p>在 <code>body</code> 属性中添加 <code>background</code> 属性来添加背景图片。</p>
<figure class="highlight html"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="tag">&lt;<span class="name">body</span> <span class="attr">background</span>=<span class="string">"./qwe.gif"</span>&gt;</span></div><div class="line"><span class="tag">&lt;/<span class="name">body</span>&gt;</span></div></pre></td></tr></table></figure>
<h3 id="插入一张图片"><a href="#插入一张图片" class="headerlink" title="插入一张图片"></a>插入一张图片</h3><p>通过 <code>img</code> 标签给网页插入一张图片。</p>
<figure class="highlight html"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="tag">&lt;<span class="name">img</span> <span class="attr">src</span>=<span class="string">"图片的路径"</span>&gt;</span></div></pre></td></tr></table></figure>
<p>在 <code>&lt;img&gt;</code> 标签中加入 <code>align</code> 属性，来对其进行调整，可以进行调整的参数有：</p>
<ul>
<li>可以上下调整的参数有：<code>bottom</code>、<code>middle</code>、<code>top</code>，默认是 <code>bottom</code>；</li>
<li>可以左右调整的参数有：<code>right</code> 和 <code>left</code>，默认为 <code>right</code>；</li>
<li>尺寸的调整：<code>width</code> 和 <code>height</code> 两个属性。</li>
</ul>
<figure class="highlight html"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="tag">&lt;<span class="name">p</span>&gt;</span> align top<span class="tag">&lt;<span class="name">img</span> <span class="attr">src</span>=<span class="string">"./julizi.png"</span> <span class="attr">align</span>=<span class="string">"top"</span> <span class="attr">width</span>=<span class="string">"10%"</span> <span class="attr">height</span>=<span class="string">"100"</span>&gt;</span><span class="tag">&lt;/<span class="name">p</span>&gt;</span></div></pre></td></tr></table></figure>
<h3 id="将图片作为链接"><a href="#将图片作为链接" class="headerlink" title="将图片作为链接"></a>将图片作为链接</h3><p>将图片做链接，一般情况下，触发链接的方式就是点击图片的任何地方都可以链接到跳转地址，但有时需要实现，点击图片的不同地方跳转到不同的地方，也就是，一张图片可以创建带有可供点击区域的图像地图，其中每个区域就是一个超链接。</p>
<p>涉及到的标签就是 <code>&lt;map&gt;</code> 标签，用来指定图片，<code>&lt;area&gt;</code> 用来指定超链接区域。</p>
<p>在 <code>&lt;area&gt;</code> 标签中我们会涉及到 <code>shape</code> ，<code>coords</code>， <code>href</code> 属性，分别用来指定超链接区域形状，超链接区域坐标，还有超链接跳转地。</p>
<figure class="highlight"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line">&lt;html&gt;</div><div class="line">&lt;head&gt;</div><div class="line">    &lt;title&gt;image test&lt;/title&gt;</div><div class="line">    &lt;/head&gt;</div><div class="line">    &lt;body background="./qwe.gif"&gt;</div><div class="line"></div><div class="line">    &lt;p&gt;tap the li zi &lt;/p&gt;</div><div class="line">    &lt;img src="./julizi.png" usemap="#lizi"/&gt;</div><div class="line"></div><div class="line">    &lt;map name="lizi"&gt;</div><div class="line">     &lt;area shape="rect" coords="50,10,100,60" href="img.html" target="_blank"</div><div class="line">    &lt;/map&gt;  </div><div class="line"></div><div class="line">    &lt;/body&gt;</div><div class="line">&lt;/html&gt;</div></pre></td></tr></table></figure>
<p>其中</p>
<ul>
<li><code>shape</code> 属性的取值可以是：<code>rect</code>(矩形)、<code>circle</code>(圆形)、<code>poly</code>(多边形)和 <code>default</code> (整个图像区域)，这里采用的是矩形。</li>
<li><code>coords</code> 属性对于矩形而言，<code>coords</code> 有4个值，分别用逗号隔开，表示矩形区域左上角x坐标、左上角y坐标、右下角x坐标和右下角y坐标，这里获取坐标的方式，就用截图工具帮忙就好。</li>
</ul>
<h2 id="HTML-列表"><a href="#HTML-列表" class="headerlink" title="HTML 列表"></a>HTML 列表</h2><h3 id="有序列表"><a href="#有序列表" class="headerlink" title="有序列表"></a>有序列表</h3><p>有序列表始于 <code>&lt;ol&gt;</code> 标签。每个列表项始于 <code>&lt;li&gt;</code> 标签。列表项内部可以使用段落、换行符、图片、链接以及其他列表等等。</p>
<p>在有序列表中我们还能定义其他的排序方式，上面是默认的数字排序，下面我们再加上字母排序和罗马数字排序</p>
<ol>
<li>通过添加 <code>type</code> 属性来设置排序方式，<code>a</code> 表示以小写字母来排序，<code>A</code> 就是使用大写字母来排序，<code>i</code> 就是以小写罗马数字来排序，<code>I</code> 就是以大写罗马数字来排序；</li>
<li>还可以添加 <code>start</code> 属性，决定起始的序号。</li>
</ol>
<figure class="highlight html"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div></pre></td><td class="code"><pre><div class="line"><span class="tag">&lt;<span class="name">html</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">head</span>&gt;</span></div><div class="line">        <span class="tag">&lt;<span class="name">title</span>&gt;</span>test<span class="tag">&lt;/<span class="name">title</span>&gt;</span></div><div class="line">    <span class="tag">&lt;/<span class="name">head</span>&gt;</span></div><div class="line">        <span class="tag">&lt;<span class="name">body</span> <span class="attr">style</span>=<span class="string">"font-size:20px;background-color:gray"</span> &gt;</span></div><div class="line"></div><div class="line">        <span class="tag">&lt;<span class="name">ol</span> <span class="attr">start</span>=<span class="string">"2"</span>&gt;</span></div><div class="line">            <span class="tag">&lt;<span class="name">li</span>&gt;</span>hadoop<span class="tag">&lt;/<span class="name">li</span>&gt;</span></div><div class="line">            <span class="tag">&lt;<span class="name">li</span>&gt;</span>linux<span class="tag">&lt;/<span class="name">li</span>&gt;</span></div><div class="line">            <span class="tag">&lt;<span class="name">li</span>&gt;</span>c <span class="tag">&lt;/<span class="name">li</span>&gt;</span></div><div class="line">        <span class="tag">&lt;/<span class="name">ol</span>&gt;</span></div><div class="line"></div><div class="line">        <span class="tag">&lt;<span class="name">ol</span> <span class="attr">type</span>=<span class="string">"a"</span>&gt;</span></div><div class="line">            <span class="tag">&lt;<span class="name">li</span>&gt;</span>hadoop<span class="tag">&lt;/<span class="name">li</span>&gt;</span></div><div class="line">            <span class="tag">&lt;<span class="name">li</span>&gt;</span>linux<span class="tag">&lt;/<span class="name">li</span>&gt;</span></div><div class="line">            <span class="tag">&lt;<span class="name">li</span>&gt;</span>c <span class="tag">&lt;/<span class="name">li</span>&gt;</span></div><div class="line">        <span class="tag">&lt;/<span class="name">ol</span>&gt;</span>       </div><div class="line">    <span class="tag">&lt;/<span class="name">body</span>&gt;</span></div><div class="line"><span class="tag">&lt;/<span class="name">html</span>&gt;</span></div></pre></td></tr></table></figure>
<h3 id="无序列表"><a href="#无序列表" class="headerlink" title="无序列表"></a>无序列表</h3><p>无序列表始于 <code>&lt;ul&gt;</code> 标签，每个列表项始于 <code>&lt;li&gt;</code>。</p>
<p>无需列表排序的时候就是给每个列表项加各种小符号其中分为<code>Disc</code>（默认）实心黑点，<code>Circle</code>小圈，<code>square</code>方点，与有序列表的属性都是用的一样的。</p>
<figure class="highlight html"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="tag">&lt;<span class="name">ul</span> <span class="attr">type</span>=<span class="string">"circle"</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">li</span>&gt;</span>hadoop<span class="tag">&lt;/<span class="name">li</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">li</span>&gt;</span>linux<span class="tag">&lt;/<span class="name">li</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">li</span>&gt;</span>c<span class="tag">&lt;/<span class="name">li</span>&gt;</span></div><div class="line"><span class="tag">&lt;/<span class="name">ul</span>&gt;</span></div></pre></td></tr></table></figure>
<h3 id="定义性列表"><a href="#定义性列表" class="headerlink" title="定义性列表"></a>定义性列表</h3><p>定义列表通常用于术语的定义和解释。定义列表由 <code>&lt;dl&gt;</code> 开始，术语由 <code>&lt;dt&gt;</code> 开始，解释说明由 <code>&lt;dd&gt;</code> 开始，<code>&lt;dd&gt;....&lt;/dd&gt;</code> 里的文字缩进显示。</p>
<figure class="highlight html"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="tag">&lt;<span class="name">dl</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">dt</span>&gt;</span>hadoop<span class="tag">&lt;/<span class="name">dt</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">dd</span>&gt;</span>it's useful!<span class="tag">&lt;/<span class="name">dd</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">dt</span>&gt;</span>linux<span class="tag">&lt;/<span class="name">dt</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">dd</span>&gt;</span>ti's nice!<span class="tag">&lt;/<span class="name">dd</span>&gt;</span></div><div class="line"><span class="tag">&lt;/<span class="name">dl</span>&gt;</span></div></pre></td></tr></table></figure>
<h2 id="HTML-块"><a href="#HTML-块" class="headerlink" title="HTML 块"></a>HTML 块</h2><p>HTML元素被定义为块级元素或内联元素。</p>
<ul>
<li>块级元素(block)特性：<ol>
<li>总是独占一行，表现为另起一行开始，而且其后的元素也必须另起一行显示；</li>
<li>宽度(width)、高度(height)、内边距(padding)和外边距(margin)都可控制，就像以前用到的 <code>&lt;h1&gt;</code>, <code>&lt;p&gt;</code>, <code>&lt;ul&gt;</code>, <code>&lt;table&gt;</code>标签。</li>
</ol>
</li>
<li>内联元素(inline)特性：<ol>
<li>和相邻的内联元素在同一行；</li>
<li>宽度(width)、高度(height)、内边距的 <code>top</code>/<code>bottom</code>(<code>padding-top</code>/<code>padding-bottom</code>)和外边距的<code>top</code>/<code>bottom</code>(<code>margin-top</code>/<code>margin-bottom</code>)都不可改变，就是里面文字或图片的大小，就像以前用到的<code>&lt;b&gt;</code>, <code>&lt;td&gt;</code>, <code>&lt;a&gt;</code>, <code>&lt;img&gt;</code> 标签。</li>
</ol>
</li>
</ul>
<p>在这里我们先介绍两个标签 <code>&lt;div&gt;</code> 标签和 <code>&lt;span&gt;</code> 标签。</p>
<ul>
<li><code>&lt;div&gt;</code> 用来定义文档中的分区或节（division/section），没有特定的含义，它是可用于组合其他 HTML 元素的容器；</li>
<li><code>&lt;span&gt;</code> 用来组合文档中的行内元素，也没有特定的含义.</li>
</ul>
<figure class="highlight html"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="tag">&lt;<span class="name">div</span> <span class="attr">style</span>=<span class="string">"color:white"</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">h3</span>&gt;</span>This is a header.<span class="tag">&lt;/<span class="name">h3</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">p</span>&gt;</span>This is a paragrph.<span class="tag">&lt;/<span class="name">p</span>&gt;</span></div><div class="line"><span class="tag">&lt;/<span class="name">div</span>&gt;</span></div></pre></td></tr></table></figure>
<h2 id="HTML-布局"><a href="#HTML-布局" class="headerlink" title="HTML 布局"></a>HTML 布局</h2><p>大多的网页布局是需要配合 css 来完成，后面会总结一篇关于 css 基本用法的文章，这里先不涉及太多。</p>
<p>这里通过一个示例，它是使用 <code>&lt;table&gt;</code> 元素和 <code>&lt;div&gt;</code> 元素实现的。</p>
<figure class="highlight html"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div></pre></td><td class="code"><pre><div class="line"><span class="tag">&lt;<span class="name">html</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">body</span> <span class="attr">bgcolor</span>=<span class="string">"gray"</span>&gt;</span></div><div class="line"></div><div class="line">        <span class="tag">&lt;<span class="name">table</span> <span class="attr">width</span>=<span class="string">"1000"</span>&gt;</span></div><div class="line">            <span class="tag">&lt;<span class="name">tr</span>&gt;</span></div><div class="line">                <span class="tag">&lt;<span class="name">td</span> <span class="attr">colspan</span>=<span class="string">"2"</span> <span class="attr">style</span>=<span class="string">"background-color: royalblue"</span>&gt;</span></div><div class="line">                    <span class="tag">&lt;<span class="name">h1</span> <span class="attr">align</span>=<span class="string">"center"</span>&gt;</span>matt' blog<span class="tag">&lt;/<span class="name">h1</span>&gt;</span></div><div class="line">                <span class="tag">&lt;/<span class="name">td</span>&gt;</span></div><div class="line">            <span class="tag">&lt;/<span class="name">tr</span>&gt;</span></div><div class="line"></div><div class="line">            <span class="tag">&lt;<span class="name">tr</span> <span class="attr">valign</span>=<span class="string">"top"</span>&gt;</span></div><div class="line">                <span class="tag">&lt;<span class="name">td</span> <span class="attr">style</span>=<span class="string">"background-color: darkorange;width:300px"</span>&gt;</span></div><div class="line">                  <span class="tag">&lt;<span class="name">dl</span>&gt;</span></div><div class="line">                      <span class="tag">&lt;<span class="name">dt</span>&gt;</span>list of blogs<span class="tag">&lt;/<span class="name">dt</span>&gt;</span></div><div class="line">                      <span class="tag">&lt;<span class="name">dd</span>&gt;</span></div><div class="line">                          <span class="tag">&lt;<span class="name">ol</span>&gt;</span></div><div class="line">                              <span class="tag">&lt;<span class="name">li</span>&gt;</span>hadoop<span class="tag">&lt;/<span class="name">li</span>&gt;</span></div><div class="line">                              <span class="tag">&lt;<span class="name">li</span>&gt;</span>java<span class="tag">&lt;/<span class="name">li</span>&gt;</span></div><div class="line">                              <span class="tag">&lt;<span class="name">li</span>&gt;</span>kafka<span class="tag">&lt;/<span class="name">li</span>&gt;</span></div><div class="line">                          <span class="tag">&lt;/<span class="name">ol</span>&gt;</span></div><div class="line">                      <span class="tag">&lt;/<span class="name">dd</span>&gt;</span></div><div class="line">                  <span class="tag">&lt;/<span class="name">dl</span>&gt;</span></div><div class="line">                <span class="tag">&lt;/<span class="name">td</span>&gt;</span></div><div class="line">                <span class="tag">&lt;<span class="name">td</span> <span class="attr">style</span>=<span class="string">"background-color: forestgreen;height:500px;width:700px;"</span>&gt;</span></div><div class="line">                    <span class="tag">&lt;<span class="name">h1</span> <span class="attr">style</span>=<span class="string">"font-size: 20px;text-align: center"</span>&gt;</span>hello world<span class="tag">&lt;/<span class="name">h1</span>&gt;</span></div><div class="line">                    this is matt's blog</div><div class="line">                <span class="tag">&lt;/<span class="name">td</span>&gt;</span></div><div class="line">            <span class="tag">&lt;/<span class="name">tr</span>&gt;</span></div><div class="line">            <span class="tag">&lt;<span class="name">tr</span>&gt;</span></div><div class="line">                <span class="tag">&lt;<span class="name">td</span> <span class="attr">colspan</span>=<span class="string">"2"</span> <span class="attr">style</span>=<span class="string">"background-color: powderblue;text-align:center;height: 100px"</span>&gt;</span></div><div class="line">                    good good study day day up<span class="tag">&lt;/<span class="name">td</span>&gt;</span></div><div class="line">            <span class="tag">&lt;/<span class="name">tr</span>&gt;</span></div><div class="line"></div><div class="line">        <span class="tag">&lt;/<span class="name">table</span>&gt;</span></div><div class="line">    <span class="tag">&lt;/<span class="name">body</span>&gt;</span></div><div class="line"><span class="tag">&lt;/<span class="name">html</span>&gt;</span></div></pre></td></tr></table></figure>
<p>通过表格来设计一个网页如下图所示。</p>
<p><img src="/images/web/html_lianxi.png" alt="示例"></p>
<p>上面的示例使用表格来进行表示的一个网页，如果使用 <code>div</code> 元素应该怎么做，下面使用 <code>div</code> 元素来重新设计一下上面的网页。</p>
<figure class="highlight html"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div></pre></td><td class="code"><pre><div class="line"><span class="tag">&lt;<span class="name">html</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">head</span>&gt;</span></div><div class="line">        <span class="tag">&lt;<span class="name">style</span>&gt;</span><span class="css"></span></div><div class="line">            <span class="selector-tag">div</span><span class="selector-id">#container</span>&#123;<span class="attribute">width</span>:<span class="number">1000px</span>&#125;</div><div class="line">            <span class="selector-tag">div</span><span class="selector-id">#header</span> &#123;<span class="attribute">background-color</span>: royalblue ;<span class="attribute">height</span>: <span class="number">100px</span>;<span class="attribute">text-align</span>:center;<span class="attribute">font-size</span>: <span class="number">20px</span>&#125;</div><div class="line">            <span class="selector-tag">div</span><span class="selector-id">#sidebar</span>&#123;<span class="attribute">background-color</span>: darkorange;<span class="attribute">height</span>:<span class="number">400px</span>;<span class="attribute">width</span>:<span class="number">300px</span>;<span class="attribute">float</span>:left;&#125;</div><div class="line">            <span class="selector-tag">div</span><span class="selector-id">#mainbody</span> &#123;<span class="attribute">background-color</span>: forestgreen;<span class="attribute">height</span>:<span class="number">400px</span>;<span class="attribute">width</span>:<span class="number">700px</span>;<span class="attribute">float</span>:left;&#125;</div><div class="line">            <span class="selector-tag">div</span><span class="selector-id">#footer</span> &#123;<span class="attribute">background-color</span>: powderblue;<span class="attribute">height</span>: <span class="number">100px</span>;<span class="attribute">clear</span>:both;<span class="attribute">text-align</span>:center;&#125;</div><div class="line">        <span class="tag">&lt;/<span class="name">style</span>&gt;</span></div><div class="line">    <span class="tag">&lt;/<span class="name">head</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">body</span>&gt;</span></div><div class="line">        <span class="tag">&lt;<span class="name">div</span> <span class="attr">id</span>=<span class="string">"container"</span>&gt;</span></div><div class="line">            <span class="tag">&lt;<span class="name">div</span> <span class="attr">id</span>=<span class="string">"header"</span>&gt;</span></div><div class="line">                <span class="tag">&lt;<span class="name">h1</span>&gt;</span>matt's blog<span class="tag">&lt;/<span class="name">h1</span>&gt;</span></div><div class="line">            <span class="tag">&lt;/<span class="name">div</span>&gt;</span></div><div class="line">            <span class="tag">&lt;<span class="name">div</span> <span class="attr">id</span>=<span class="string">"sidebar"</span>&gt;</span></div><div class="line">               <span class="tag">&lt;<span class="name">dl</span>&gt;</span></div><div class="line">                   <span class="tag">&lt;<span class="name">dt</span>&gt;</span>list of blogs<span class="tag">&lt;/<span class="name">dt</span>&gt;</span></div><div class="line">                    <span class="tag">&lt;<span class="name">dd</span>&gt;</span></div><div class="line">                        <span class="tag">&lt;<span class="name">ol</span>&gt;</span></div><div class="line">                            <span class="tag">&lt;<span class="name">li</span>&gt;</span>hadoop<span class="tag">&lt;/<span class="name">li</span>&gt;</span></div><div class="line">                            <span class="tag">&lt;<span class="name">li</span>&gt;</span>java<span class="tag">&lt;/<span class="name">li</span>&gt;</span></div><div class="line">                            <span class="tag">&lt;<span class="name">li</span>&gt;</span>kafka<span class="tag">&lt;/<span class="name">li</span>&gt;</span></div><div class="line">                        <span class="tag">&lt;/<span class="name">ol</span>&gt;</span></div><div class="line">                    <span class="tag">&lt;/<span class="name">dd</span>&gt;</span></div><div class="line">               <span class="tag">&lt;/<span class="name">dl</span>&gt;</span></div><div class="line">            <span class="tag">&lt;/<span class="name">div</span>&gt;</span></div><div class="line">            <span class="tag">&lt;<span class="name">div</span> <span class="attr">id</span>=<span class="string">"mainbody"</span>&gt;</span></div><div class="line">                <span class="tag">&lt;<span class="name">h1</span>&gt;</span>hello word<span class="tag">&lt;/<span class="name">h1</span>&gt;</span></div><div class="line">                <span class="tag">&lt;<span class="name">p</span>&gt;</span>this is matt's blog<span class="tag">&lt;/<span class="name">p</span>&gt;</span></div><div class="line">            <span class="tag">&lt;/<span class="name">div</span>&gt;</span></div><div class="line">            <span class="tag">&lt;<span class="name">div</span> <span class="attr">id</span>=<span class="string">"footer"</span>&gt;</span>good good study day day up<span class="tag">&lt;/<span class="name">div</span>&gt;</span></div><div class="line">        <span class="tag">&lt;/<span class="name">div</span>&gt;</span></div><div class="line">    <span class="tag">&lt;/<span class="name">body</span>&gt;</span></div><div class="line"><span class="tag">&lt;/<span class="name">html</span>&gt;</span></div></pre></td></tr></table></figure>
<h2 id="HTML-表单"><a href="#HTML-表单" class="headerlink" title="HTML 表单"></a>HTML 表单</h2><p>表单标签是什么呢？这个是在网页是很常见的，表单标签就是用于网页中的数据提交，比如我们注册网页，在留言板中留言、评论等可以填写数据，提交处理地方都需要表单标签，<code>form</code> 表单标签内有输入框 input、单选、多选、<code>select</code> 下拉列表菜单与跳转菜单、提交按钮等标签内容。</p>
<figure class="highlight html"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div></pre></td><td class="code"><pre><div class="line"><span class="tag">&lt;<span class="name">form</span>&gt;</span></div><div class="line">    user：</div><div class="line">    <span class="tag">&lt;<span class="name">input</span> <span class="attr">type</span>=<span class="string">"text"</span> <span class="attr">name</span>=<span class="string">"user"</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">br</span>/&gt;</span></div><div class="line">    password：</div><div class="line">    <span class="tag">&lt;<span class="name">input</span> <span class="attr">type</span>=<span class="string">"password"</span> <span class="attr">name</span>=<span class="string">"password"</span>&gt;</span></div><div class="line"><span class="tag">&lt;/<span class="name">form</span>&gt;</span></div><div class="line"></div><div class="line"><span class="tag">&lt;<span class="name">form</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">input</span> <span class="attr">type</span>=<span class="string">"radio"</span> <span class="attr">name</span>=<span class="string">"sex"</span> <span class="attr">value</span>=<span class="string">"male"</span> /&gt;</span> Male</div><div class="line">    <span class="tag">&lt;<span class="name">br</span>/&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">input</span> <span class="attr">type</span>=<span class="string">"radio"</span> <span class="attr">name</span>=<span class="string">"sex"</span> <span class="attr">value</span>=<span class="string">"female"</span> /&gt;</span> Female</div><div class="line"><span class="tag">&lt;/<span class="name">form</span>&gt;</span></div><div class="line"></div><div class="line"><span class="tag">&lt;<span class="name">form</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">input</span> <span class="attr">type</span>=<span class="string">"checkbox"</span> <span class="attr">name</span>=<span class="string">"married"</span> /&gt;</span></div><div class="line">    married</div><div class="line">    <span class="tag">&lt;<span class="name">br</span>/&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">input</span> <span class="attr">type</span>=<span class="string">"checkbox"</span> <span class="attr">name</span>=<span class="string">"have a job"</span> /&gt;</span></div><div class="line">    have a job</div><div class="line">    <span class="tag">&lt;<span class="name">br</span>/&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">input</span> <span class="attr">type</span>=<span class="string">"checkbox"</span> <span class="attr">name</span>=<span class="string">"chinese"</span> /&gt;</span></div><div class="line">    chinese</div><div class="line"><span class="tag">&lt;/<span class="name">form</span>&gt;</span></div></pre></td></tr></table></figure>
<p>其中，name 是明文显示，password 是隐藏的，<code>radio</code> 属性是单选，<code>checkbox</code> 属性是双选，上面展示的效果如下图所示。</p>
<p><img src="/images/web/html_form.png" alt="示例"></p>
<p>后面还会单独写一篇文章对 css 进行一下总结，html 和 css 的这两篇文章，会不定时更新，以后用到什么比较常用内容或者遇到什么好的方法，会更新到这两篇文章中。</p>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[入职培训感想]]></title>
      <url>http://matt33.com/2017/05/27/induction-training-think/</url>
      <content type="html"><![CDATA[<p>这周参加了公司的封闭式入职培训，总共是五天的时间，今年是公司第一次进行校招封闭式培训。记得去年七月份来公司实习，一起入职的校招同事参加的入职培训才两天时间，而且也不是封闭式的，一年的时间，变化还是很大的，这也间接证明公司的发展速度很快。作为公司第一届参加封闭式入职培训的员工（不是这届的第一批），在这五天中明显感觉到了收获了很多，这里记录总结一下。</p>
<h2 id="周一"><a href="#周一" class="headerlink" title="周一"></a>周一</h2><p>今天上午九点从公司出发到酒店，早上起来的时候还只是小雨，九点多出发的时候已经变成了大到暴雨，京城的雨本来就很少，但是很多时候一旦雨一下来就收不住了。从公司门口到大巴车只有短短的100米，但全身已被淋湿了很多，好在到了酒店之后雨已经差不多停了。</p>
<p>到了酒店会议室之后，已经快到中午了，同组同学相互认识一下，然后负责培训的同事介绍一下培训期间的一些规则，之后就到了吃午饭的时间（关于伙食就不想多介绍了，冷暖自知😂）。</p>
<h3 id="下午"><a href="#下午" class="headerlink" title="下午"></a>下午</h3><p>下午的第一节课，是对公司的一些基本介绍，第一节课讲课的老师是大熊老师，大熊老师现在在公司从事人力资源方向的工作，有近十年的工作经验，从他身上看到了一些值得我们去学习的地方：</p>
<ol>
<li>他对公司业务的理解，虽然大熊老师现在是从事人力资源方向，但是无论在技术还是业务方向都有很多认识，尤其是在业务方面，他思考的还很深的，包括对公司发展战略、客户的需求等方面，他都有一些很独特的见解；</li>
<li>对新事物充满<strong>好奇心</strong>，课上大熊老师问了一句：有多少人用过快手？好像当时课上没什么人举手，但是大熊老师说：快手现在这么火，我们还是应该去试用一下，看看这个产品为什么这么火，对这些新事物，我们应该保持一颗好奇心（包括阿里提出的”新零售”战略）；</li>
<li>思考问题时，很多时候并不能只站在自己的角度去想，上个台阶去看问题，可能会就会明白公司或者领导的要求了，<strong>低头做事时也要时常抬头，要有大局观</strong>；</li>
</ol>
<p>下午后面几节课就是介绍公司的一些规章制度，不过作为一名资深的老员工（实习近八个月），这些我基本上已经很了解了😄。</p>
<p>课程结束后，接着就去了酒店一楼的餐厅吃饭，饭后直接回到了会议室等待晚上的课程，结果竟错过北京近几年来最美的晚霞，只能默默在朋友圈欣赏他人的晚霞了，很可惜（这里选了一张网上的图片镇楼）。</p>
<p><img src="/images/essary/070522night.jpeg" alt="难得一遇的晚霞"></p>
<h3 id="晚上-《国家联盟》"><a href="#晚上-《国家联盟》" class="headerlink" title="晚上 《国家联盟》"></a>晚上 《国家联盟》</h3><p>这个游戏可能很多公司的培训都会使用，我是第一次玩这个游戏，我们组是巨人国，我们国家的战力很强，但是却极度缺乏资源，所以我们在第二年的时候为了完成目标就率先发动了战争，但是战争的结果并不如预期那样，如果严格按照比赛规则的话，可能我们就直接被淘汰了。关于这个游戏，个人有以下几点感想：</p>
<ol>
<li>首先我们并没有完全搞清楚游戏的规则，规则没有搞懂就进入了游戏，这基本上就注定了失败的结局；</li>
<li>在与其他团队沟通的过程中，应该有相应的技巧，在谈判的过程中，要理性地看待问题，然而时间紧迫的情况下，很多人并不理性，也包括我自己；</li>
<li>与他人合作的过程中，我们应该更多是考虑共赢合作，而不是损人利己；</li>
<li>既然彼此要合作，就应该相互信任；</li>
</ol>
<p>游戏结束，就进入了一个很开心的游戏——狼人杀，狼人杀在培训期间给我们增加了很多的欢乐，在高玩的带领下，学到了很多的技巧😀。</p>
<h2 id="周二"><a href="#周二" class="headerlink" title="周二"></a>周二</h2><h3 id="上午"><a href="#上午" class="headerlink" title="上午"></a>上午</h3><p>今天上午只有一节课 —— 职场必修课，这个应该算是入职培训的标配课程吧。</p>
<p>课程的核心有以下几点：</p>
<ul>
<li>人生的职业生涯大致分为几个阶段，在前期最主要的是<strong>学习、成长</strong>；</li>
<li>对于职场小白，如何学习、如何成长？其中很关键的一点是要有人去带你，<strong>跟着带你的人去学习成长</strong>；</li>
<li>职场礼仪：与他人沟通时要注意<strong>聆听</strong>，对同时表扬或称赞时，要<strong>基于事实去称赞</strong>。</li>
</ul>
<p>讲解这门课程的老师，在培训行业深耕近十年，她曾经在 LG 的培训界创造了很多的神话，现在她依然奋战在培训行业的第一线，未来的职业规划也是继续从事培训行业，很优秀、职业规划很清晰的一位培训老师。</p>
<h3 id="下午-户外拓展活动"><a href="#下午-户外拓展活动" class="headerlink" title="下午 户外拓展活动"></a>下午 户外拓展活动</h3><p>今天下午是一节户外扩展课，全员分为四组进行比赛，比赛的项目基本都是围绕着团队合作的目的进行的。这节课是这几天培训中最让人印象深刻的课程之一，这里说一下个人的感想以及一些感悟和收获：</p>
<ul>
<li><strong>增强了队员之间的相互了解</strong>，在之前大家基本上都是在上课，只是混了个面熟，并不是很熟悉，名字也没有记很清楚，但经过这个活动之后，至少我们小组内部（11个人）有了更多的了解；</li>
<li><strong>团队合作</strong>，五个比赛的小项目，都是需要全员参与的，需要团队之间的相互配合；</li>
<li>整个过程中，游戏并不难，难的地方主要在于大家的互相合作，大家之前并不认识，性格、思维也有很大差异，但却需要我们一起在短时间内完成一个需要强力配合的游戏，这对我们也是很大的挑战，<strong>在很短的时间内，大家要熟悉起来，并且找到默契</strong>。</li>
</ul>
<p>活动大概是6点结束的，很遗憾我们组只拿到了第二名，与第一名只有1分之差，不过这个活动最赞的地方是给了我们大家一个互相了解的机会，它并不是一个简简单单的比赛。</p>
<h3 id="晚上"><a href="#晚上" class="headerlink" title="晚上"></a>晚上</h3><p>今晚的讲师是公司一位很优秀的员工，他15年本科毕业，现在正式入职还不到两年，已经开始带了7个人的团队，个人有以下几点感想：</p>
<ol>
<li>他的升职历程，在其他行业可能是不可思议的，但是在互联网行业，由于公司业务发展迅速，这样例子是数不胜数的，<strong>既是机遇也是挑战，做好准备的人才能脱颖而出</strong>；</li>
<li>虽然他工作不到两年，但他却从工作和管理的过程中，总结了很多方法论，先不说方法论的对错，仅这些就能证明他这个人很好学、爱总结，他是一个<strong>爱看书、爱总结、上进心很强</strong>的一个工程师；</li>
<li><strong>对新技术的关注以及对业务的理解</strong>，全程我可能提到了很多次这个概念 —— 对业务的理解，主要是因为我一直处于一个唯技术论的圈子里，大家讨论更多的是技术，对业务关注不是很多，然而<strong>经济是检验技术的唯一标准</strong>（当然有些技术的价值可能需要长远才能体现出来，但牛逼的技术依然是需要有经济价值的），所以每次遇到对业务理解很深的人，我都会不自由自主地感觉这个人很厉害。</li>
<li>他的演讲能力很不错，这个要跟他的工作年限一起看，非常值得我去学习。</li>
</ol>
<p>课程结束之后，又到了狼人杀时间，印象最深的就是猎人被假冒预言家的狼查杀但是却没有将狼带走、而且预言家还没有上警，这局游戏竟然成了一个我们培训中的一个槽点了😂。</p>
<h2 id="周三"><a href="#周三" class="headerlink" title="周三"></a>周三</h2><h3 id="上午-1"><a href="#上午-1" class="headerlink" title="上午"></a>上午</h3><p>今天上午的课程 —— 客服听音，对于服务性的企业，很多公司也都会有这项课程，主要有以下几点感想：</p>
<ol>
<li><strong>以客户为中心</strong> 是公司的价值观与企业文化，但是如何将这个条进行落实，客服是挽回用户的最后一道防线，所以客服这项工作对于公司整体发展而言是非常重要的，之前用过很多次美团，当时对美团的印象非常好，就是因为客服非常 nice，效率很高；</li>
<li>给用户提供超预期的服务。</li>
</ol>
<h3 id="下午-1"><a href="#下午-1" class="headerlink" title="下午"></a>下午</h3><p>下午是关于公司业务流程的讲解，有五六个前辈来讲解，印象最深的有两个：一个外卖，另一个是丽人。</p>
<h4 id="外卖业务"><a href="#外卖业务" class="headerlink" title="外卖业务"></a>外卖业务</h4><p>关于外卖，这个是公司最近几年最重视的业务，通过这位前辈的讲解，对外卖的整体有了更进一步的了解：</p>
<ul>
<li>前辈完整地经历过外卖的发展和成长，虽然在外卖领域我们是后来者，但是最后我们与饿了么一起进入了下半场，而且从目前的数据来看美团外卖的优势会更明显一些，美团有自己的智能配送系统，有可能未来会向京东物流一样发展成一个配送平台，而反观饿了么现在正在与阿里云合作去做智能配送（这两天刚爆出的新闻），这也间接地证明了美团外卖在配送领域确实与饿了么拉开了一定的差距；</li>
<li>从她的介绍过程中，明确能感觉到他对整个行业那洞察力，对商业、战略的理解已经远超我们普通人，着实很厉害，<strong>如果在一个公司里能跟随一个新业务迅速成长起来，这是非常幸运的，这样迅速成长的机会并不是常有的</strong>；</li>
<li>虽然与饿了么是竞争对手，但是外卖这边还是很<strong>尊重竞争对手的（学习对方的长处）</strong> ，饿了么那边的团队也是非常厉害的，要不然两家不会焦灼这么长时间，美团这边也是很希望有个竞争对手的，因为这样才能逼迫着我们自己去进步；</li>
<li>外卖市场现在还没有哪一家公司是占有绝对优势的，稍不留神可能就会被对手远远甩在后面，外卖现在是不盈利的，而且我们并不着急地去盈利，<strong>不为了盈利而盈利，否则就可能会损害用户的利益</strong>；</li>
<li><strong>产品在设计时一定要走在业务之前</strong>，要为业务开展以及未来的发展做准备，而不是说业务有这个需要了才开始去改进产品（期间也一定要考虑风控，这个是很重要，要不然很多的钱可能就白花了）；</li>
<li>竞争时，<strong>差异化竞争很重要，但前提是你走的是正确的道路</strong>，如果对手选择了一个正确的道路，你这时候选择差异化，那么就是在自己作死。</li>
</ul>
<p>虽然前辈只讲了不到两个小时，但让我们感觉收获了很多，无论是关于公司业务的理解还是关于一些商业行为的思考，很感谢！</p>
<h4 id="丽人业务"><a href="#丽人业务" class="headerlink" title="丽人业务"></a>丽人业务</h4><p>丽人业务，在之前并没有了解太多，后来才知道丽人业务里也有三驾马车——美发、美甲、美容美体（细心的人可能会发现这就是美团 app 中丽人栏目里的三个大图标），虽然丽人并不是一个很高频的业务，但是从这位前辈的讲述中，能感觉到的是这个团队非常有战斗力和自信心，有以下几点感触：</p>
<ul>
<li>每个细分领域，都面对着很多竞争对手，但前辈给人的感觉是他们这个团队非常有激情、对这块业务非常自信；</li>
<li>他们这个团队在这个细分的领域做了很多的事情，并没有因为这是个低频业务就不重视，他们紧紧追随着竞争对手的步伐，并没有丝毫懈怠，很赞。</li>
</ul>
<h3 id="晚上-1"><a href="#晚上-1" class="headerlink" title="晚上"></a>晚上</h3><p>晚上是趣味运动会，也是一些考察团队合作的小项目，只不过这些活动是可以在室内做的，运动量也不大，总体来说玩得还是很开心的。</p>
<p>之后，又进行了2局的狼人杀，都是九人局的，唉，不堪回首，全输了，不做太多解释，第一局猎人背锅，第二局女巫背锅。</p>
<h2 id="周四"><a href="#周四" class="headerlink" title="周四"></a>周四</h2><h3 id="上午-2"><a href="#上午-2" class="headerlink" title="上午"></a>上午</h3><p>今天上午只有一节课 —— 有效沟通，从两个方面来说：一是对老师的感觉，二是课程的内容：</p>
<p>关于对老师的感觉：</p>
<ol>
<li>这节课的内容<strong>总结了很多的方法论</strong>，这证明这位老师平时还是很喜欢读书和思考的；</li>
<li>课程也涉及了一些心理学的内容，再次证明了这位老师爱看书；</li>
<li>他自己是带团队的，在工作过程中，也需要跟其他的部门进行合作，课程的内容也是根据他看到的一些方法论和工作经验进行总结的，<strong>学以致用，并在用的过程中进行总结</strong>，这点是很值得学习的。</li>
</ol>
<p>关于课程内容，核心内容主要有以下四点：</p>
<ol>
<li>Ask；</li>
<li>Listen：听明白事、感受、以及背后被满足与不满足的需要；</li>
<li>Look：肢体语言，在不同场合着装、动作都要注意；</li>
<li>Speak：察情传理，主要是要考虑他人的感受。</li>
</ol>
<h3 id="下午-2"><a href="#下午-2" class="headerlink" title="下午"></a>下午</h3><p>今天下午的课程，是一位公司的高 P 来讲解的，这节课主要是讲解思维方式的。这里先总结一下课程的内容：</p>
<ul>
<li>思维方式分类<ol>
<li>惯性思维：是靠经验、直觉是判断；</li>
<li>逻辑思维：推理+逻辑分析（垂直思维）；</li>
<li>水平思维：创意天马行空，很有可能碰撞出一个非常好的灵感；</li>
<li>结构化思维：先框架再细节，强调快速、系统地解决问题。</li>
</ol>
</li>
<li>结构化思维的分析方式：<ol>
<li>先聚焦问题与目标；</li>
<li>从假设入手进行分析；</li>
<li>分析问题的关键；</li>
<li>从这些关键点入手。</li>
</ol>
</li>
<li>分析的三个原则：<ol>
<li>以终为始；</li>
<li>MECE：建立分析结构（相互独立、完全穷尽）；</li>
<li>二八原则：抓住关键的少数。</li>
</ol>
</li>
<li>麦肯锡的电梯理论：<ol>
<li>最短的时间把问题表达清楚——直奔主题与结果；</li>
<li>归纳的话，尽量三条以内。</li>
</ol>
</li>
</ul>
<p>老师的课程很风趣，课上互动也较多，从课程中也能明显地感觉到这位老师是一位<strong>爱思考、爱读书、爱总结</strong>的优秀工程师。无论是在各行各业，那些优秀人才基本上都有这些共性，这几点可以说成为优秀人才的至尊宝典，只是能够一直坚持下去的人很少，我本人的毅力也不是很强，很多的时候只能逼迫自己呆在一个充满竞争力的环境中，让竞争激烈的环境逼迫着自己去努力，也希望自己未来能够从主观上有所改变。</p>
<h3 id="晚上-2"><a href="#晚上-2" class="headerlink" title="晚上"></a>晚上</h3><p>今晚没有安排额外的课程，然而却比上课都累，因为明天下午我们要做毕业呈现，各个小组的产品设计要进行比赛，我们团队基本上是通宵进行的产品设计，自从上了研究生之后就没怎么熬过夜了，第一次熬那么久，还是值得记录一下的。</p>
<ol>
<li>方向篇：想在一晚上就把一个产品的设计方案做出来还是很难的，不说别的，单纯的方向就很难找。我们刚开始想的是把美团与慈善结合起来，后来发现太难做了，而且可行性较差，后来又想到的是借鉴趣运动，做运动场馆的预定。美团app在运动场馆方面只能进行团购，而不能去预定时间段，这是不能够满足用户需求的，这是一个很好的方向，而且实施起来比较简单。本来方向已经确定了这个，结果我再次查看美团app时，发现我经常去的那个场馆已经可以直接预定时间段了，天呐，美团已经开始做了！！！我们只能放弃这个方案，去寻找新的方向，后来突然想到了 app 的积分商城，我们就确定了去做积分商城这个方向，这个时候已经是晚上10点了，我们才确定了产品的方向。</li>
<li>产品设计篇：然后就是具体的改进方向，我们决定设计了一个美食达人类似的晋级策略，鼓励用户使用美团品尝美食，然后进行达人升级，后面就是具体产品实现、落地档案以及产品呈现。细节还没有讨论清楚会议室就到了关门时间，我们全组只好转战到了酒店的二楼继续进行。</li>
<li>激烈讨论：在讨论的过程中，我们有很多的争执，做 RD 的总是感觉没必要这么较真，一直聚焦在产品细节的设计上，时间有限，应该直接开始做，后面有时间的话，我们再去优化产品。而组里的另外两名 QA 和 PM 却认为这很重要，一直聚焦在产品的具体表现形式上。最后觉得争执也没有什么用，我只好开始先做 PPT，具体产品实现由他们来做。</li>
<li>感慨：通过这次的产品设计，能明确感受到我们之间思维的差异，这当然没有对错之分，作为工程师，我们在乎的是能不能按时完成，或者是更有效率地完成，而产品经理考虑则是产品的细节上。</li>
</ol>
<p>最后奋战到了凌晨四点半，直到 PPT 做得差不多了，我们才回去休息，这时候脑袋基本上已经停止了思考，实在是太困了，这是近三年来睡得最晚的一次。</p>
<h2 id="周五"><a href="#周五" class="headerlink" title="周五"></a>周五</h2><p>凌晨5点才睡觉，睡到早上九点爬起来去上课。</p>
<h3 id="上午-3"><a href="#上午-3" class="headerlink" title="上午"></a>上午</h3><p>上午的课程是介绍产品相关的内容，但是这节课说实话并不是很好，可能一个是自己比较困，并没有认真听讲，但在跟其他的学员交流后，发现我们的感受都差不多，在课程中并没有想象中收获的那么多。培训的同学大都是 rd，pm 很少，我们很希望这门课应该是一个产品经理的入门课程，通过这节课至少会对一个产品经理的日常工作以及产品的设计方面有一个基本的了解，但是这节课的安排并没有那么好，感觉太偏理论性，先介绍理论然后快速把案例过了一下，并没有很好地将理论与具体的案例结合起来，这样的话培训的效果就会很差，作为一个入门的产品小白，并没有从这节课中收获到更多的东西。</p>
<h3 id="下午-3"><a href="#下午-3" class="headerlink" title="下午"></a>下午</h3><p>上午的课程结束之后，我们就赶紧修改了我们的 PPT，好在最后在1点半前把 PPT 完成了，由于 PPT 的第一部分是我写的，所以这部分的内容是由我来讲解的，在台上讲解并没有想象中的那么紧张😝，但是演讲技能还是需要很大提高的，很多的时候心里想的东西，在台上讲解时就很自然地忘记了，还是有待锻炼的。虽然我们产品的呈现并不是很理想，但在这个过程中，收获了很多，有以下几点感想：</p>
<ol>
<li>现在我依然认为我们确实是找到了产品的一个缺陷，但是业内目前都没有一个很好的解决方案，应用场景基本上都一致，但是我们在分析其他公司的积分商城时，只考虑 IT 行业，并没有去研究一些传统行业的做法，没有<strong>使用水平思维去看待问题</strong>；</li>
<li>优秀的产品一定要是简单，我们产品设计和呈现都有些过于复杂， 而且还没有对他人讲解清楚，一个好的产品呈现，应该是能够简单清晰地表达出来的；</li>
<li>并没有更多地去分析如果推出了这个产品之后的效果，是不是会像预期的效果那样，用户会不会去 care 这样的一个变动；</li>
<li>其他组的产品在呈现上设计得更加优美，而且有几个产品的设计得确实很不错，简单名了。</li>
</ol>
<p>虽然我们并没有拿到大奖，但是通过这次活动，了解到了一个产品设计的设计过程，尤其是当你去寻找方向时，会发现很多的领域都已经被巨头占领了，创业公司很难能够有所突破。</p>
<h3 id="高管交流会"><a href="#高管交流会" class="headerlink" title="高管交流会"></a>高管交流会</h3><p>这次来交流的是公司的穆总，去年初到公司时，就听同事说到过穆总的大名，后来也参加过一次搜狐的高管交流会，中间也听到了搜狐北研的负责人讲起了穆总当年的那些事，而这次终于有机会能够与穆总面对面交流。听穆总讲话确实收获颇丰，交流会全程分为两个部分：先是穆总给我们的一些建议，后面是穆总的一些 QA。</p>
<p>穆总给我们的三个建议，也是穆总的一些感概：</p>
<ol>
<li><strong>学习成长，持续的学习和成长</strong>，这个社会变化很快，离开学校只是一个起点，并不是学习的终点，未来的社会可能会变化更快，这就要求我们必须<strong>活到老学到老</strong>，去拥抱变化；</li>
<li>要<strong>下苦功夫</strong>，10000小时理论是大家广泛周知的一个理论，听说过这个理论可能有50%的人，但真正去做的可能不到25%，而最后能够下苦功夫坚持做下来的连10%也不到，而最终能够做到的这10%的人将会去管理这剩下90%的人；</li>
<li><strong>耐心</strong>，现在的互联网发展很快，也使得很多人都变得浮躁，没有耐心去认真地做事情，当年（07年左右）从 BAT 离职创业的那些人90%的并没有他们之前的同事过得更好，现在我们的面前充满着各种各样的”机会”，但是我们要去分辨着这些”机会”，看看这些是不是真的”机会”（通过商业的本质去分析一家公司的机会）。</li>
</ol>
<p>穆总讲完这三点之后，给我们留了足够的时间进行 QA，QA 的三个问题都是业务方面，能明确感受到大家对美团点评前景的担心，毕竟公司的负面新闻太多，我们确实也在各个领域均遇到强劲的对手，在穆总的耐心解答中，总结了以下几点，有对穆总的感觉，也有穆总对公司业务的分析：</p>
<ul>
<li>穆总对商业的洞察力、对产品的思考，都很深入的，<strong>商业的本质就是去解决现实中存在的问题</strong>；</li>
<li>穆总非常<strong>务实</strong>，他现在负责美团金融，我们问未来美团会不会出一款类似与微信支付或支付宝的产品时，穆总很直接地说了，现在的市场是不需要一家类似于支付宝或微信支付的产品，但是我们依然有东西要去做，当把一些基本的东西做好之后，未来如果出现新的变革，我们就有机会去做一些事情；</li>
<li>创新：应该多去尝试，很多业务都是尝试出来的，以现在要发展的美团打车为例，打车领域有巨头，但不代表我们必须要放弃这个市场，出行市场是足够大的，不应该只有一家公司存在，如果这样的话，其实对于用户也不是很好的选择，<strong>就像电商领域，虽然阿里占据垄断地位，但是京东、唯品会依然过得不错</strong>，打车领域做到第一很难，但我们可以去做第二或第三，既然打车是吃喝玩乐的一部分，而美团点评是定位为吃喝玩乐一站式的平台，那么打车就必须要做，还有一点是很重要就是：打车领域的需求并不是都被满足了，至少对于打车师傅而言，由于滴滴抽成太高师傅们都是不满的；</li>
<li>居安思危：这点从穆总的交流中，能明显感觉出来，美团是一家很谨慎的公司，创业公司稍不留神可能就会被淘汰，所以美团的高管们<strong>危机意识</strong>很强，在去年的时候，当时我就能感受到未来支付宝可能是美团最强劲的对手，而糯米并不足以为率，当时只是纳闷为什么美团不进行正面反击，支付宝通过口碑、饿了么对美团发起强攻，但美团除了外卖高歌猛进其他的业务似乎是一直在守，这个令我很不解，现在再去回头看，就清晰很多了，一个是公司没有那么大的财力去多线强烈作战，另一个是公司在过去一到两年里一直在勤练内功，避免像 BAT 那样浪费资源，相信过不了多久美团就会强力反击，但前提是内功要先练好；</li>
<li>总结教训：穆总是从百度出来的，离开百度的时候还是 BAT，现在已经变成 AT 了，百度的没落有很多种原因，我们能做的就是从中吸取教训，避免走百度的老路，可能<strong>谷歌的退出就是百度没落的开始</strong>，没有竞争对手就会让一家企业忘乎所以。</li>
</ul>
<p>通过近两个多小时的交流，关于业务一些不理解的地方，瞬间开朗了很多，也对公司未来的前景非常看好。</p>
<h2 id="最后"><a href="#最后" class="headerlink" title="最后"></a>最后</h2><p>五天的培训，很快就结束了，通过这次培训，感觉很幸运能够加入美团点评 —— 一个认真做实事的公司，希望美团点评明天更好，下面是一张我们全体学员的合照，希望大家明天更好！</p>
<p><img src="/images/essary/070523training.jpeg" alt="大家庭"></p>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[腾讯传，一个激情澎湃的时代]]></title>
      <url>http://matt33.com/2017/04/16/tencent-read/</url>
      <content type="html"><![CDATA[<p>这两周把<a href="https://book.douban.com/subject/26929955/" target="_blank" rel="external">《腾讯传》</a>看完了，这本书去年出版的时候就想去看，但是一拖就拖到了现在，直到上周出去玩，回来的时候路上遇到了堵车，车上实在无聊，就开始看这本书。我平时是比较喜欢看这类科技史或科技公司史的书，第一次看这种类型的书，读的吴军老师的<a href="https://book.douban.com/subject/6709783/" target="_blank" rel="external">《浪潮之巅》</a>，当时真叫是一个过瘾，至今还记得当时那种情景 —— 怎一个爽字了得，一口气连着两天在图书馆把这本书看完了。可是现在在看《腾讯传》时，已经没有了那种感觉，但最后还是在两周的时间里把这本书看完了，跟着吴晓波一起重温了一个伟大互联网公司（3Q 之后的腾讯）发展历程 —— 一个激情澎湃的时代。</p>
<p>改革开放三十多年以来，个人认为给中国经济带来最大贡献的应该是两个方面：制造业和互联网。这十几年来，互联网公司上市造富神话，可以说是激励一批又一批的有志青年投身创业大潮。互联网这个行业应该可以说是所有行业里面竞争最透明、最激烈的行业了，它成功冲破了国企垄断的壁垒、也幸运地战胜了美国的一些互联网巨头的入侵，使得中国市场在全球显得独树一帜。从八十年代中国第一次连入到全球互联网开始，中国的互联网主要经历了三个重要阶段：</p>
<ol>
<li>1999年左右，以新闻行业（靠广告挣钱）为基本生态，出现了新浪、搜狐和网易三巨头；</li>
<li>2007年之后，出现了以应用平台为基本业态的大洗牌，门户们陷入“模式困境”，出现了成长乏力的态势，而百度、阿里巴巴和腾讯则分别从搜索、电子商务和即时通信工具三个方向出发，到2010年前后完成了反向超越，成为“新三巨头”，它们被合称为 BAT。</li>
<li>从2012年开始，智能手机异军突起，互联网的用户重心从电脑端向移动端快速平移，移动互联网时代开始，出现了诸如小米、美团、滴滴、头条的几个小巨头，百度在不到5年的时间里由于没有抓住机遇迅速衰退，互联网进入白热化时代 —— 腾讯阿里争霸时代。</li>
</ol>
<p>曾经有段时间，我们感觉互联网行业好像机会已经很少了，各个方向都有巨头在做，可是在2014年，大数据开始火热，2016年，人工智能开始迅速走进了所有人的视野，斯坦福也开始设置数据科学的专业，美国中国的政府都开始发力，抢占人工智能的风口。可以这样说从2016年开始，互联网开始进入人工智能争战的时代，估计在2020年左右也会出现几个像美团、滴滴、头条这样的小巨头，互联网行业似乎时刻都充满着机会，竞争也从来没有间断，稍不留心可能就会被对手迅速甩开。但腾讯似乎总能抓住这些热潮，至少从目前来看是这样的，这本书就是带领我们去看一下腾讯这家巨头的发家史。</p>
<p>说到腾讯发家史，有个故事，大家应该都听过 —— 马化腾当年要以100W 的价格将 QQ 卖掉，可是别人只出50W，最后因为价格没谈拢，交易就没成功。那个时期应该是腾讯起家时最困难的一段时间，其他的公司，像网易通过卖邮件系统和广告、搜狐新浪也是通过卖广告已经过得很滋润了，甚至都开始到美国上市了，而腾讯当时还在破产边缘挣扎。腾讯在推出 QQ 之后，并没有找到一个合适的商业模式，后来随着 QQ 用户达到100W、1000W，需要越来越多的服务器，腾讯在其他领域挣的钱全都投入到 QQ 这个项目上了，但公司维持起来依然很艰难，幸好腾讯在2000年互联网泡沫前拿到了风险投资，否则腾讯可能真的就不撑不下去了。</p>
<p>拿到投资之后的腾讯，暂时缓解资金的压力，但是如果找不到合适的变现途径，这种模式依然是不能持续下去的。腾讯甚至在一段时间里由于用户量暴增，不得不对每天的 QQ 注册量进行限制，在这期间，腾讯可以说被用户骂得要死，而且其他的竞争对手公司，像网易都开始推出自己的即时通信工具（网易泡泡）来狙击腾讯，腾讯被迫只能继续开放 QQ 免费注册。腾讯在这段时间内依然面对着巨大的资金压力，腾讯找到的第一个商业模式，就是与中国移动合作，当时中国移动刚从中国电信中独立出来，同样需要迅速找到一种商业模式与中国电信、联通进行竞争，于是乎推出了一个移动梦网的项目，腾讯从这中间拿到分成，曾经一度这个项目就是腾讯生存下去的基础（如果后来不是移动自己推出飞信并取消其他公司分成的话，恐怕腾讯也不会变得这么骁勇）。直到后来 QQ 秀的出现，这应该是腾讯历史上的一个重要事件，算是腾讯找到了第二个商业模式。QQ 秀是从韩国的一款产品中借鉴而来的，腾讯对其进行了本土化的改造，中间进行了很多的微创新，腾讯自己都没想到这款款产品一推出就获得出乎意料的欢迎，腾讯推出第一个砖石系列以及 QQ 币等支付产品，这是腾讯第一次从 QQ 用户直接获取收入，腾讯这个时候才开始意识到 QQ 强大的商业价值。在很长的时间里，腾讯陆续推出了网游、棋牌、QQ 空间（偷菜）、QQ 音乐、腾讯网门户网站、搜搜等产品，大多数的产品都获得了巨大的成功，腾讯过得是不亦乐乎，腾讯也基本上也形成了抄袭+微创新+对产品打磨这个套路，靠着这个套路，腾讯攻城掠地，到了2010年，腾讯已经成为了中国互联网的老大。腾讯自己过得很滋润，正所谓此消彼长，其他人过得就不如人意了，尤其是那些被腾讯抄袭并彻底打垮的公司。腾讯凭借自己 QQ 强大的用户基础不断抄袭（借鉴）其他公司的产品，并将其移植到自己的生态下，而被抄袭的企业后来基本上都跪了。</p>
<p>在当时，对于这位互联网老大，整个业界都是敢怒不敢言，当时很多创业公司在融资时，都会面对一个问题 —— 如果腾讯也做这个的话，怎么办？后来就出现了互联网史上比较出名的 3Q 大战。具体的孰对孰错，现在来说已经不重要了，不过这个事件显示了业界对腾讯的愤怒，腾讯几乎成了众矢之的。腾讯在这次危机中，面临着很大的舆论压力，后来腾讯开始进入半年的调整期，后来决定拥抱开放（互联网的基本精神）。腾讯确定了”连接一切”的战略，开始开放自己的平台，也开始承担自己应该承担的责任，陆续投资了很多的互联网公司，像大众点评、滴滴、微票儿等等，建立了一个很强大的生态（又称腾讯系），现在也只有阿里可以与之抗衡。可以说，如果没有 3Q 大战，就没有后来的腾讯，腾讯在移动互联网之争中，就很有可能与百度一样被阿里甩到后面。所以说，遇到危机，如果能从吸取教训，那么在下次机会到来时就有可能抓住机会。</p>
<p>还有一点要说的是，腾讯在发展的过程中，有两点非常值得学习：</p>
<ol>
<li>产品的打磨：腾讯应该第一个对产品这么重视的公司，毕竟腾讯的产品都是直接与用户打交道的，腾讯的产品文化，很值得学习；</li>
<li>公司内部的赛马机制：这个机制本来是为了鼓励一些中层领导的团队之间相互竞争，它最成功的产品就是微信，现在微信可以说是已经彻底融入到我们的生活中了。</li>
</ol>
<p>腾讯的成功，有很多的原因，最大的原因应该就是机遇 —— 合适的时间做了合适的事情，在一个激情澎湃的时代，与一群志同道合的人，做了一件不甘于平凡的事情。</p>
<hr>
<p>读书中记录的笔记</p>
<blockquote>
<p>中国互联网发生过三次“圈地运动”。第一次是在1999年前后，以新闻门户为基本业态，出现了新浪、搜狐和网易“三巨头”。2007年之后，出现了以应用平台为基本业态的大洗牌，门户们陷入“模式困境”，出现了成长乏力的态势，而百度、阿里巴巴和腾讯则分别从搜索、电子商务和即时通信工具三个方向出发，到2010年前后完成了反向超越，成为“新三巨头”，它们被合称为BAT。而从2012年开始，智能手机异军突起，互联网的用户重心从电脑端向移动端快速平移，由此发生了第三次“圈地运动”。—— Kindle Edition. loc. 151-156.</p>
</blockquote>
<p>Notes: 1) 互联网的三个重要时期,现在理论上应该处于第四个时期—人工智能。</p>
<blockquote>
<p>马化腾的七种武器”，它们包括： 第一种武器：产品极简主义。—— Kindle Edition. loc. 183-183.</p>
</blockquote>
<p>Notes: 1) 简单是美</p>
<blockquote>
<p>第二种武器：用户驱动战略。—— Kindle Edition. loc. 188-188.</p>
</blockquote>
<p>Notes: 1) 用户为核心。</p>
<blockquote>
<p>第三种武器：内部赛马机制。—— Kindle Edition. loc. 192-192.</p>
</blockquote>
<p>Notes: 1) 中层通过创新的产品可以实现超越。</p>
<blockquote>
<p>第四种武器：试错迭代策略。—— Kindle Edition. loc. 196-196.</p>
</blockquote>
<p>Notes: 1) 就如同小米提出的“快,极致,专注口碑”。</p>
<blockquote>
<p>第五种武器：生态养成模式。—— Kindle Edition. loc. 199-200.</p>
</blockquote>
<p>Notes: 1) 管理。</p>
<blockquote>
<p>第六种武器：资本整合能力。—— Kindle Edition. loc. 204-204.</p>
</blockquote>
<p>Notes: 1) 资本为公司生态服务。</p>
<blockquote>
<p>第七种武器：专注创业初心。—— Kindle Edition. loc. 207-207.</p>
</blockquote>
<p>Notes: 1) 勿忘初心</p>
<blockquote>
<p>在中国乃至全球的互联网史上，从1998年到1999年的两年间，是一个神秘的时期，错过了这一段，也就错过了一个世代。—— Kindle Edition. loc. 621-622.</p>
</blockquote>
<p>Notes: 1) 正好与前两天雄安新区设立形成对比,当年人创业激情非常饱满,对成功很渴望,而现在的人则 2) 正好与前两天雄安新区设立形成对比,当年人创业激情非常饱满,对成功很渴望,而现在的人则变了很多。</p>
<blockquote>
<p>OICQ在日后被业界评价为一个不可多得的“天才产品”，宣称其系统架构在用户发展至亿级时仍然能够支撑。唯有张志东清楚其中的艰辛，所谓的“天才”都是靠徐钢武、吴宵光以及后来无数工程师不断“重写”和优化的结果。“用户快速增长，性能瓶颈不断出现，为了不让用户失望，逼得团队不断优化性能，不断克服瓶颈。说到底，都是逼出来的结果。”张志东日后回忆至此，无限感喟。——<br> Kindle Edition. loc. 814-818.</p>
</blockquote>
<p>Notes: 1) 传言并不准确,系统后来还是zuole 很多优化的,技术是为业务而服务的。</p>
<blockquote>
<p>这就是创业到第20个月的腾讯：在走了一段弯路之后，它找到了核心产品，拥有了一支志同道合的团队和一个可爱的品牌形象，它还不知道该如何盈利，不过已经有人愿意为它的未来买单。—— Kindle Edition. loc. 1121-1122.</p>
</blockquote>
<p>Notes: 1) 腾讯的发展着实曲折,没有盈利模式的互联网企业在融资过程中只是会面对资金匮乏的过程情况,可是那么牛逼的互联网公司在初创时期又有几个能直接就找到盈利模式的。</p>
<blockquote>
<p>市场在不停地变化，企业所在行业的利润来源区也不停在变，企业必须随着利润区的变化而变换自己的企业设计和盈利模式。（亚德里安·斯莱沃斯基（美国管理学家），《发现利润区》）—— Kindle Edition. loc. 1125-1126.</p>
</blockquote>
<p>Notes: 1) 多观察其他领域的盈利模式,说不定就会找到一些借鉴之处。</p>
<blockquote>
<p>在腾讯的历史，乃至中国互联网史上，QQ秀都堪称一款革命性的收费产品，它可以被视为全球互联网产业的一次“东方式应用创新”。腾讯不是这一创新的发起者，可是它却凭借这一创新获得真正商业上的成功。而比商业利益更有价值的是，QQ秀让腾讯与它的亿级用户建立了情感上的归属关系。—— Kindle Edition. loc. 1422-1424.</p>
</blockquote>
<p>Notes: 1) 没想到qq 秀启到的作用竟然这么大,虽然不是腾讯首先提出的,但腾讯却将它利用得淋漓尽致。</p>
<blockquote>
<p>围绕“QQ人”，为他们提供各种服务是腾讯商业模式的本质。—— Kindle Edition. loc. 1461-1462.</p>
</blockquote>
<p>Notes: 1) 人们需要的聊天工具并不是只有聊天的功能。</p>
<blockquote>
<p>程苓峰敏锐地窥视出了腾讯多元化战略中的一个特征：紧盯市场动态，以最快的方式复制成功者模式，利用QQ用户优势进行后发超越。—— Kindle Edition. loc. 2030-2031.</p>
</blockquote>
<p>Notes: 1) 腾讯在开始形成的一个传统,这个传统也给腾讯未来带来了很多的负面问题。</p>
<blockquote>
<p>“模仿而不创新”“以天下为敌”和“拒绝开放”便成为腾讯的“三宗罪”。—— Kindle Edition. loc. 2043-2043.</p>
</blockquote>
<p>Notes: 1) 腾讯在最开始时,不断寻找自己的商业模式,一直在盈利而发愁,直到qq 秀的出现让腾讯意识到原来自己是可以通过用户导流量、从用户身上获取利润的。qq 秀也是腾讯借鉴的商业模式,让腾讯开始尝到了甜头,在后来腾讯慢慢形成了后发制人,由于自己强大的用户规模,明目张胆抄袭他人的商业模式,近而在一段时间甚至成了全民公敌。</p>
<blockquote>
<p>腾讯在此次事件中所遭遇到的舆论攻击更让马化腾一度意兴阑珊，在访谈中，我能够非常清楚地感受到他的困惑与郁闷，甚至在某些时刻，他的价值观都有点动摇。正如黑格尔所言，获得认可的欲望是人类生存最基本的愿望，马化腾一向自诩为产品经理，日夜所思皆是用户体验及得到他们的认可，然而，就是在这个层面上，他遭遇了致命的质疑。—— Kindle Edition. loc. 3676-3679.</p>
</blockquote>
<p>Notes: 1) 3q 大战之后,腾讯开始改变了自己的策略,从一个封闭、向全行业开战的平台变成了一个开放的平台,这也使得腾讯能够在下一波互联网战争中(移动互联网时代),没有失去自己的先机,反观百度,已经落后了很多。</p>
<blockquote>
<p>过去，我们总在思考什么是对的。但是现在，我们要更多地想一想什么是能被认同的。 （马化腾，《给全体员工的邮件》）—— Kindle Edition. loc. 3683-3684.<br>Notes: 1) 换句话说,对的东西并不一代被认同。</p>
<p>无论是年轻化方向、娱乐社交战略，还是场景化通信的打法，QQ在移动互联网时代的玩法渐渐清晰，与微信之间的关系也更加明朗。通过完善两大社交平台的生态，腾讯用两条腿走路的整体布局成为可能。—— Kindle Edition. loc. 4245-4247.</p>
</blockquote>
<p>Notes: 1) qq 是偏年轻化的一款产品,功能太多,对于成年人来说甚至有些臃肿,但微信就会简单很多,遵循互联网的极简主义。</p>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[欧洲简史]]></title>
      <url>http://matt33.com/2017/04/04/read/</url>
      <content type="html"><![CDATA[<p>最近几周把这本<a href="https://book.douban.com/subject/5366248/" target="_blank" rel="external">你一定爱读的极简欧洲史</a>读完了，在阅读的过程中，感觉真的是很爽，不愧是豆瓣的8+分图书。读完本书，可以对欧洲的历史有一个大概的了解，即便是最后很多的细节记不清楚，但是整个历史过程还是会有一定的印象，能建立一个大概的时间线。读完本书，如果再有人问你<code>为什么现代科学、政治制度会诞生在西方，而不是一直领先的中国？</code>你应该也能说几个理由的。</p>
<p>全本主要分为两个部分，第一部分整体介绍了一下欧洲的大概历史进程，第二部分选取了其中的六个比较重要的方面进行介绍。纵观欧洲整个历史，大题可分为三个时代：古典时期、中世纪和近代，如下图所示。古典时期主要是古希腊和古罗马时代，而中世纪又称黑暗的中世纪，直到公元十五世纪开始文艺复兴之后，欧洲才逐渐从中世纪中走出来，进入到近代。</p>
<p><img src="http://upload-images.jianshu.io/upload_images/573840-8f214b350ec6cd08.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="欧洲历史年表"></p>
<p><img src="http://upload-images.jianshu.io/upload_images/573840-07a2b5d47fe3f014.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="宗教与西方"></p>
<p>从最开始看这本书，到这本书看完，大概花了三周时间，看书的时间依然在上下班的途中，都是利用一些零碎的时间去看的，到了现在书中能记住的东西已经不是很多，这里根据脑海中残留的大概印象对以上三个时代做一下总结：</p>
<ul>
<li>古典时期：那是个百花齐放的时代，科技、文化、政治都能达到了很大的高度，在西方人民的心中（特别是中世纪人民），那个时代简直可望而不可即，所以那个时期被称为古典时期。那个时代出现了苏格拉底、柏拉图、亚里士多德（古希腊三贤）等人，在天文上也提出了“地心说”的理论，古希腊在几何的贡献也是我们现代数学的基础，当年雅典也出现了很多的民主制度，后来的古罗马基本继承了古希腊的制度，进一步发扬了古希腊文化。在古罗马时代，出现了很多的宗教，可以说百家争鸣，后来的基督教在当时还是很小众的一个教派，直到后来古罗马帝国的君士坦丁堡大帝开始信奉基督教，导致了基督教开始走进古罗马的权力中心，开始影响欧洲历史之路。</li>
<li>中世纪：中世纪之所以被称为<strong>黑暗中世纪</strong>，完全是因为在那个时代，人们没有宗教信仰自由，只能信奉基督教，也就是天主教，其他的教派（新教、伊斯兰教等）都被称为异教；也没有读书自由（暂且这样说吧），很多古罗马时代书都被教皇保留下来，但教皇是为了通过这些著作也印证基督教的真实正确；也没有民主等等。当年人们为了死后进入天堂也是煞费苦心，教皇发放救赎劵，教众们就会去买，也不管教皇拿着这些钱作何用途（事实上是为了十字军东征）。说起这个时代的开始，就离不开日耳曼民族，当然现在的日尔曼民族已经不是当年的日尔曼民族，现在欧洲大部分的人应该都是当年日尔曼民族的后代，那个时代的日尔曼民族又叫做<strong>日尔曼蛮族</strong>，它们类似于现在的非洲部落，虽说都是日尔曼蛮族，但是却有多方的势力，并没有形成一个统一的组织，但就是这样一批人，把当年不可一世的古罗马帝国灭掉了（确切说应该是西罗马帝国），西罗马帝国被灭掉当然也有其自身衰落的原因。日尔曼蛮族虽然灭掉了西罗马帝国，但他们只是来抢东西，并没有统治这片土地的意思，而且他们最后居然保留了基督教，甚至很多人都开始慢慢信奉基督教。当时的西方虽然被很多封主、国王统治，但基督教却是一个非常统一的组织。可以说在当时君权和教皇各是一个权力终端，它们相互制约、相互牵制、相互斗争，有时候甚至是相互利用。有句话叫做有压迫就由反抗，后来马丁路德建立起新教学说就是对现任教皇的一个反抗，新教从个人的自由出发，很快就吸引了很多的民众，新教和天主教只是对《圣经》的不同解读。</li>
<li>近代：近代应该是从文艺复兴开始，文艺复兴实际上就是对古希腊罗马学术的发现和再发现，他们不希望一直接受一个被教会阉割的古典。在以前，教会虽然保留了很多古希腊罗马的学术，但是都是为了用来印证《圣经》、为教会而服务，但是现在，大家突然发现原来古希腊罗马的学术不是这样的，原来古典时期的学术、制度是那么发达，令当代人敬仰。不过随着文艺复兴的影响进一步加深，当代的思想得到很大的解放，一批如哥白尼、伽利略、牛顿等人的出现，让当时的人民觉得原来我们一点也不比古希腊罗马人笨、甚至还比他们更聪明，他们也发现原来古希腊罗马的学术并不一定全是正确的，于是各种科学开始迅速发展，为现代文明奠定基础。</li>
</ul>
<p>在本书的第二部分，重点从以下六个小的方面开始讲述欧洲历史的发展，这六个方面可以说是欧洲文明的重点组成，甚至可以说是现代欧洲文明的基石：</p>
<ol>
<li>争战一千年。从最开始的日尔曼蛮族入侵，欧洲在之后的一千年里，几乎是纷争不断，后来的穆斯林入侵、维京人入侵、十字军东征，不过这也激发了欧洲人爱冒险的血性，对后来的大航海时代也有一定的作用。</li>
<li>民主意识，这样开始的。欧洲文明给人类带来的一个重大财富就是——民主，民主最开始是诞生在古希腊，后来随着中世纪的到来，欧洲人民并没有实质意义上的民主，但也因为欧洲在罗马帝国之后就再也没有出现过一个统一的帝国，这才幸运地阻止了欧洲陷入东亚帝王专制的世界里。</li>
<li>有国王的民主，没国王的极权。这部分主要是指英国与欧洲大陆，英帝国有国王，但是因为新教（崇尚个人自由）和国会（对国王的选择起很大的作用）的缘故，使得英帝国率先走向君主立宪制，建立了民主的英帝国。反观欧洲大陆，有的地方却很极权，比如法国，最后导致了法国大革命，不过民主终究胜于极权。</li>
<li>皇帝和教皇到底谁大？欧洲有一个很特殊的现象，那就是它有两个很强大的权力系统，一个是教会，一个是政府，这两个冤家相互争斗、相互利用，都是为了各自的利益。只要皇帝并没有建立一个统一的帝国，皇帝终究是摆脱了教会的束缚，而教会也会为了自己的利益利用手中的权力来约束皇帝的权利，反而给民主提供了很好的土壤。</li>
<li>语言：从两种变几十种。欧洲的主要语言体系应该是两种：日尔曼语系和罗曼语系（拉丁语系）。</li>
<li>平民百姓的生活面貌。在工业革命之前，一千多年，欧洲85%以上的人口就是从事农业相关，这也是西方人见面经常会问天气的原因，因为天气会影响到大部分人的生活。</li>
</ol>
<p>读完本书，确实会对欧洲大概的历史有一个认识，但毕竟是欧洲简史，如果想了解欧洲历史的细节，这本书是远远不够的，但这本书会给你打开一个欧洲文明史的大门，非常推荐。</p>
<hr>
<p>下面是在读书过程中对一些自认为比较重要的内容，做的一些笔记。</p>
<blockquote>
<p>第二次的大侵略来自穆斯林，时为7世纪到8世纪，距离日耳曼蛮族入侵仅仅两百年。伊斯兰教始祖穆罕默德原为阿拉伯商人，得到神的天启后创立该教。他这支借由神助发展出来的宗教，与犹太教和基督教有紧密联系；穆斯林也承认耶稣和耶稣之前的先知们确实是先知，但深信穆罕默德是世上最后一位先知，能指引大家走向唯一真神安拉的怀抱。伊斯兰教比起基督教来说简单许多。—— 约翰•赫斯特, 你一定爱读的极简欧洲史, loc. 800-804</p>
</blockquote>
<p>Notes: 1) 伊斯兰教发源</p>
<blockquote>
<p>国王，也就是先前的日耳曼战士首领，他将土地分发给自己的子弟兵，而这些下属必须提供国王打仗所需的战力作为回报，一个国家就建基于这样的关系上。—— 约翰•赫斯特, 你一定爱读的极简欧洲史, loc. 1112-1113</p>
</blockquote>
<p>Notes: 1) 君主处于弱势的开始,君主对于土地、税收不再直接掌控,而这些权力尽数被封主拿去。</p>
<blockquote>
<p>由于立足点薄弱，封建制度的君主必须征询国内权势人士的建言。他们没有一支自己能够全权控制的军队，也没有常态的征税制度或行政部门，因此，在做决定之前，他们会邀集重要人士，听取这些人的意见并征得同意才能拍板定案。—— 约翰•赫斯特, 你一定爱读的极简欧洲史, loc. 1143-1145</p>
</blockquote>
<p>Notes: 1) 间接地限制了国王的权力,这也是西方没有形成封建专制的原因。</p>
<blockquote>
<p>英国国会让自己成了宪政体制的一个常设单位。整个过程没有流一滴血，史称“光荣革命”。—— 约翰•赫斯特, 你一定爱读的极简欧洲史， loc. 1265-1266</p>
</blockquote>
<p>Notes: 1) 欧洲大陆在走向专制的过程中,英国并没有步入后尘,宗教在这过程中起到了很大的作用,英国此时已是新教的天下,国王想通过天主教达到自己的目的反而适得其反。</p>
<blockquote>
<p>新教教义从一开始便是以保障个人自由为出发点，因为它干犯教皇和主教的权威，提升了个人的意识和地位。在英国，它与自由的关系更是密不可分，因为英国的敌人——法国和西班牙的专制君主都是天主教徒，而那些试图架空议会的英国国王不是信奉天主教就是对天主教手软之辈。保存国会与保存新教信仰合而为一，成了殊途同归的新教志业。—— 约翰•赫斯特, 你一定爱读的极简欧洲史, loc. 1281-1285</p>
</blockquote>
<p>Notes: 1) 在西方,自从罗马帝国之后,宗教与政治就变得密不可分,而天主教更侧重于上层人的利益,甚至是专制,新教则是从个人出发,更侧重于个人的自由,限制了君主的权力,比较符合国会的利益,因此,英国甚至把新教写进权力法案,以保护国会的权力。(当然国会最开始代表的并不是普通民众的利益)。</p>
<blockquote>
<p>查理大帝建立的帝国消失了，教皇也失去了保护他的强人。有一段时间教皇得过且过，哪个地方王侯支持他，他就把谁加冕为王。—— 约翰•赫斯特, 你一定爱读的极简欧洲史, loc. 1435-1436</p>
</blockquote>
<p>Notes: 1) 教皇也逐渐成了政治的一部分,教皇也只是为了寻找一个保护伞。</p>
<blockquote>
<p>双方（皇帝和教皇）都承认对方的存在有其必要，争的只是彼此的相对权力。这是西罗马帝国一个非常重要的特色，也是它和东罗马帝国的分野所在。—— 约翰•赫斯特, 你一定爱读的极简欧洲史, loc. 1495-1496</p>
</blockquote>
<p>Notes: 1) 东罗马帝国的教皇则完全由皇帝指定。</p>
<blockquote>
<p>拉丁语，跟罗马帝国的概念一样，已经气若游丝很久了。—— 约翰•赫斯特, 你一定爱读的极简欧洲史, loc. 1748-1749</p>
</blockquote>
<p>Notes: 1) 拉丁语跟罗马帝国一样,可以说是一直存在着,对后世影响深远。</p>
<blockquote>
<p>所有的人都老是为收成担心害怕。谈天气不是为了没话找话说，而是一群人在忧心自己的命运。—— 约翰•赫斯特, 你一定爱读的极简欧洲史, loc. 1810-1811</p>
</blockquote>
<p>Notes: 1) 西方见面聊天气原来是这个原因,有很多的历史背景,在工业革命之前西方基本上85%以上从事农业相关,所以大部分人都对天气非常重视。</p>
<blockquote>
<p>在欧洲，当国王的总是强敌环伺，而中国皇帝的君权无人能比，这是他们拥有的优势——或者说是陷阱。欧洲国家之间相互为敌，是它们向海外扩张的一股推动力量。—— 约翰•赫斯特, 你一定爱读的极简欧洲史, loc. 1949-1950</p>
</blockquote>
<p>Notes: 1) 中国皇帝权力过大,而西方的国王从未有如此之强权。</p>
<blockquote>
<p>欧洲的历史演进泰半从奠基的这一刻起便已注定。政府对人民毫无掌控能力，它们必须殚思竭虑，才可能争取到人民的服从。它们若想扩张势力，就得提供良好的政府——也就是维护治安作为回报，它们不能像亚洲和中东不计其数的帝国及王国那样，光靠收税机制和进贡就能运转。 数百年来，这些国王最大的威胁是他们最有权势的下属——土地贵族阶级。这些权臣最后终于俯首，但因为已在自己的领土上雄霸够久，早就为自己也为他们土地上的人民争取到私有财产的保障。“不是所有的东西都属于国王”，这是欧洲自由和繁荣的基石。—— 约翰•赫斯特, 你一定爱读的极简欧洲史, loc. 1956-1962</p>
</blockquote>
<p>Notes: 1) 这是西方与东方政府的主要区别,没有东方这种“普天之下,莫非王臣,普天之地,莫非王土”思想,政府对人民并没有绝对的控制力,人民有自己的私有财产,这也是公民限制政府权力的基础。</p>
<blockquote>
<p>在中国，权力是极其明确地集中在皇帝手里，以儒家为尊的精英文化对君权统治也支持有加。无论是个人修为或待人处世，中国人莫不以儒家思想为圭臬，它已深深扎根于整个社会和国家。统治者不管有没有合法性都得熟读四书五经，而你得通过儒家经典考试才能当上国家官员。 反观欧洲，权力不但分散，精英文化也是个大拼盘，与君权统治之间的系带并不牢固。中国人非常聪明，可是他们的聪明从来不会脱轨失控，纵有奇思异想，基本上都不曾造成纷扰。欧洲社会的开放则是源远流长。<br>近代欧洲在经济上爆发力十足，智识生活百家争鸣，皆是基于一个事实：不管是好是坏，从来没有一个单一强权掌控过它、形塑过它。它多元的历史遗产因此能被充分发掘、延伸；希腊的数学观念在科学革命时期得到实现，从而建立起科技创新的一个新基础。—— 约翰•赫斯特, 你一定爱读的极简欧洲史, loc. 1991-1997</p>
</blockquote>
<p>Notes: 1) 分析了欧洲与中国的一个巨大区别</p>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[Storm 对 0.10.x 版 Kafka 支持解析]]></title>
      <url>http://matt33.com/2017/03/17/storm-kafka-0-10-1/</url>
      <content type="html"><![CDATA[<p>由于 0.10.x 版 Kafka 与 0.8.x 版有很大的变化，这种变化对下游 Storm 有非常大的影响，0.10.x 版的 Kafka 不但增加了权限管理的功能，而且还将 simple 和 high consumer 的 offsets 进行统一管理，也就意味着在 0.8.x 中 Storm 需要去负责管理 offsets，而在 0.10.x 中，Storm 不需要关心 consumer 的 offsets 的问题，这对 KafkaSpout 的设计有很大的影响，本文就是对 <code>Storm 对 0.10.x 版 Kafka 支持的实现</code>部分的解析。</p>
<h1 id="0-10-x-版-KafkaSpout-的实现"><a href="#0-10-x-版-KafkaSpout-的实现" class="headerlink" title="0.10.x 版 KafkaSpout 的实现"></a>0.10.x 版 KafkaSpout 的实现</h1><p>社区对新版 Kafka 的支持，总体分为两种情况：</p>
<ol>
<li>一种是选择自动 commit 机制；</li>
<li>另一种是非自动 commit，就是将 commit 的权利交与 Storm 来控制。</li>
</ol>
<p>下面分别对这两种情况进行分析。</p>
<p>Kafka Consumer 的一些配置会对 Storm 的性能很大影响，下面的三个参数的设置对其性能的影响最大（默认值是根据<a href="https://hortonworks.com/blog/microbenchmarking-storm-1-0-performance/" target="_blank" rel="external">MICROBENCHMARKING APACHE STORM 1.0 PERFORMANCE</a>测试得到）：</p>
<ul>
<li><code>fetch.min.bytes</code>：默认值 200；</li>
<li><code>fetch.max.wait.ms</code>：默认值 30000（30s）；</li>
<li><code>Kafka Consumer instance poll timeout</code>, 它可以在通过 <a href="https://github.com/apache/storm/blob/1.0.x-branch/external/storm-kafka-client/src/main/java/org/apache/storm/kafka/spout/KafkaSpoutConfig.java" target="_blank" rel="external">KafkaSpoutConfig</a> 的方法 <a href="https://github.com/apache/storm/blob/1.0.x-branch/external/storm-kafka-client/src/main/java/org/apache/storm/kafka/spout/KafkaSpoutConfig.java#L180-L184" target="_blank" rel="external">setPollTimeoutMs</a> 来配置，默认值是 10000000；</li>
</ul>
<h2 id="自动-commit-模式"><a href="#自动-commit-模式" class="headerlink" title="自动 commit 模式"></a>自动 commit 模式</h2><p>自动 commit 模式就是 commit 的时机由 Consumer 来控制，本质上是异步 commit，当定时达到时，就进行 commit。而 Storm 端并没有进行任何记录，也就是这部分的容错完全由 Consumer 端来控制，而 Consumer 并不会关心数据的处理成功与否，只关心数据是否 commit，如果未 commit，就会重新发送数据，那么就有可能导致下面这个后果：</p>
<h3 id="造成那些已经-commit、但-Storm-端处理失败的数据丢失"><a href="#造成那些已经-commit、但-Storm-端处理失败的数据丢失" class="headerlink" title="造成那些已经 commit、但 Storm 端处理失败的数据丢失"></a>造成那些已经 commit、但 Storm 端处理失败的数据丢失</h3><p><strong>丢失的原因</strong></p>
<p>一些数据发送到 Spout 之后，恰好 commit 的定时到达，进行了 commit，但是这中间有某条或者几条数据处理失败，这就是说，这几条处理失败的数据已经进行 commit 了，Kafka 端也就不会重新进行发送。</p>
<p>可能出现的这种后果也确定了自动 commit 模式不能满足我们的需求，为了保证数据不丢，需要数据在 Storm 中 ack 之后才能被 commit，因此，commit 还是应该由 Storm 端来进行控制，才能保证数据被正确处理。</p>
<h2 id="非自动-commit-模式"><a href="#非自动-commit-模式" class="headerlink" title="非自动 commit 模式"></a>非自动 commit 模式</h2><p>当选用非自动的 commit 机制（实际上就是使用 Consumer 的同步 commit 机制）时，需要手动去设置 commit 的参数，有以下两项需要设置：</p>
<ul>
<li><code>offset.commit.period.ms</code>：设置 spout 多久向 Kafka commit一次，在 KafkaSpoutConfig 的 <a href="https://github.com/apache/storm/blob/1.0.x-branch/external/storm-kafka-client/src/main/java/org/apache/storm/kafka/spout/KafkaSpoutConfig.java#L189-L193" target="_blank" rel="external">setOffsetCommitPeriodMs</a> 中配置；</li>
<li><code>max.uncommitted.offsets</code>：控制在下一次拉取数据之前最多可以有多少数据在等待 commit，在 KafkaSpoutConfig 的 <a href="https://github.com/apache/storm/blob/1.0.x-branch/external/storm-kafka-client/src/main/java/org/apache/storm/kafka/spout/KafkaSpoutConfig.java#L211-L217" target="_blank" rel="external">setMaxUncommittedOffsets</a> 中配置；</li>
</ul>
<h3 id="spout-的处理过程"><a href="#spout-的处理过程" class="headerlink" title="spout 的处理过程"></a>spout 的处理过程</h3><p>关于 Kafka 的几个 offset 的概念，可以参考<a href="http://matt33.com/2017/01/16/kafka-group/#offset-那些事"> offset的一些相关概念</a></p>
<p>KafkaSpout 的处理过程主要是在 <code>nextTuple()</code> 方法，其处理过程如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">nextTuple</span><span class="params">()</span> </span>&#123;</div><div class="line">    <span class="keyword">if</span> (initialized) &#123;</div><div class="line">        <span class="keyword">if</span> (commit()) &#123;<span class="comment">// Step1 非自动 commit,并且定时达到</span></div><div class="line">            commitOffsetsForAckedTuples();<span class="comment">// 对所有已经 ack 的 msgs 进行 commit</span></div><div class="line">        &#125;</div><div class="line"></div><div class="line">        <span class="keyword">if</span> (poll()) &#123;<span class="comment">//Step2 拉取的数据都已经发送,并且未 commit 的消息数小于设置的最大 uncommit 数</span></div><div class="line">            setWaitingToEmit(pollKafkaBroker());</div><div class="line">            <span class="comment">//将拉取的所有 record 都放到 waitingToEmit 集合中,可能会重复拉取数据（由于一些 msg 需要重试，通过修改 Last Committed Offset 的值来实现的）</span></div><div class="line">        &#125;</div><div class="line"></div><div class="line">        <span class="keyword">if</span> (waitingToEmit()) &#123;<span class="comment">//Step3 waitingToEmit 中还有数据</span></div><div class="line">            emit();<span class="comment">//发送数据,但会跳过已经 ack 或者已经发送的消息</span></div><div class="line">        &#125;</div><div class="line">    &#125; <span class="keyword">else</span> &#123;</div><div class="line">        LOG.debug(<span class="string">"Spout not initialized. Not sending tuples until initialization completes"</span>);</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>上面主要分为三步：</p>
<ol>
<li>如果是非自动 commit，并且 commit 定时达到，那么就将所有已经 ack 的数据（<strong>这些数据的 offset 必须是连续的</strong>，不连续的数据不会进行 commit）进行 commit；</li>
<li>如果拉取的数据都已经发送，并且未 commit 的消息数（记录在 <code>numUncommittedOffsets</code> 中）小于设置的最大 uncommit 数，那么就根据更新后的 offset （将 offset 重置到需要重试的 msg 的最小 offset，这样该 offset 后面的 msg 还是会被重新拉取）拉取数据，并将拉取到的数据存储到 <code>waitingToEmit</code> 集合中；</li>
<li>如果 <code>waitingToEmit</code> 集合中还有数据，就发送数据，但在发送数据的过程中，会进行判断，只发送没有 ack 的数据。</li>
</ol>
<h3 id="KafkaSpout-如何进行容错"><a href="#KafkaSpout-如何进行容错" class="headerlink" title="KafkaSpout 如何进行容错"></a>KafkaSpout 如何进行容错</h3><p>举个示例，如下图所示</p>
<p><img src="/images/kafka/KafkaSpout-error.png" alt="consumer offset"></p>
<ol>
<li>图1表示一个 <code>nextTuple()</code> 循环结束之后，offset 为14那条数据处理失败，而offset 为15-18的数据处理成功；</li>
<li>图2表示在下次循环 Step 1 结束之后、Step 2 开始之前，Consumer 会将 the last committed offset 重置到 offset 为14的位置。</li>
</ol>
<p>也就是说从 offset 为14开始，后面的数据会重新发送。</p>
<p><strong>有人可能会问，那样的话会不会造成数据重复发送？</strong></p>
<p>Storm 是如何解决这个问题的呢？答案就是 Storm 会用一个 map 记录已经 ack 的数据（<code>acked</code>），Storm 在进行 commit 的时候也是根据这个 map 的数据进行 commit 的，不过 commit 数据的 offset 必须是连续的，如上图所示，只能将 offset 为11-13的数据 commit，而15-18的数据由于 offset 为14的数据未处理成功而不能 commit。offset 为11-13的数据在 commit 成功后会从 map 中移除，而 offset 为15-18的数据依然在 map 中，Storm 在将从 Kafka 拉取的数据加入到 <code>waitingToEmit</code> 集合时后，进行 emit 数据时，会先检测该数据是否存在 <code>acked</code> 中，如果存在的话，就证明该条数据已经处理过了，不会在进行发送。</p>
<p>这里有几点需要注意的：</p>
<ol>
<li>对已经 ack 的 msg 进行 commit 时，所 commit 的 msg 的 offset 必须是<strong>连续</strong>的（该 msg 存储在一个 TreeMap 中，按 offset 排序），断续的数据会暂时接着保存在集合中，不会进行 commit，如果出现断续，那就证明中间有数据处理失败，需要重新处理；</li>
<li>storm 处理 failed 的 msg，会保存到一个专门的集合中，在每次拉取数据时（是拉取数据，不是发送数据，发送数据时会检测该数据是否已经成功处理），会遍历该集合中包含的所有 TopicPartiion，获取该 partition 的 Last Committed Offset；</li>
</ol>
<p>这样设计有一个副作用就是：如果有一个 msg 一直不成功，就会导致 KafkaSpout 因为这一条数据的影响而不断地重复拉取这批数据，造成整个拓扑卡在这里。</p>
<h3 id="Kafka-Rebalance-的影响"><a href="#Kafka-Rebalance-的影响" class="headerlink" title="Kafka Rebalance 的影响"></a>Kafka Rebalance 的影响</h3><p>Kafka Rebalance 可以参考<a href="http://matt33.com/2017/01/16/kafka-group/#Consumer-Rebalance">Consumer Rebalance</a>.</p>
<p>KafkaSpout 实现了一个内部类用来监控 Group Rebalance 的情况，实现了两个回调函数，一旦发现 group 的状态变为 <code>preparingRabalance</code> 之后</p>
<ol>
<li><code>onPartitionsRevoked</code> 这个方法会在 Consumer 停止拉取数据之后、group 进行 rebalance 操作之前调用，作用是对已经 ack 的 msg 进行 commit；</li>
<li><code>onPartitionsAssigned</code> 这个方法 group 已经进行 reassignment 之后，开始拉取数据之前调用，作用是清理内存中不属于这个线程的 msg、获取 partition 的 last committed offset。</li>
</ol>
<h3 id="潜在的风险点"><a href="#潜在的风险点" class="headerlink" title="潜在的风险点"></a>潜在的风险点</h3><p>这部分还是有可能导致数据重复发送的，设想下面一种情况：</p>
<p>如果之前由于一个条消息处理失败（Partition 1），造成部分数据没有 commit 成功，在进行 rebalance 后，恰好 Partition 1 被分配到其他 spout 线程时，那么当前的 spout 就会关于 Partition 1 的相关数据删除掉，导致部分已经 commit 成功的数据（记录在 acked 中）被删除，而另外的 spout 就会重新拉取这部分数据进行处理，那么就会导致这部分已经成功处理的数据<strong>重复处理</strong>。</p>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[Kafka 之 Group 状态变化分析及 Rebalance 过程]]></title>
      <url>http://matt33.com/2017/01/16/kafka-group/</url>
      <content type="html"><![CDATA[<p>前段时间看一下 Kafka 的部分源码（0.10.1.0 版），对一些地方做了一些相应的总结。本文主要就 Kafka Group 方面的内容做一下详细的讲述，重点讲述 Consumer Client 如何进行初始化、Server 端对应的 Consumer Group 状态如何进行变化以及对一些 Kafka 的新设计（与旧版不同之处）简单介绍一下。</p>
<h1 id="Group-状态机"><a href="#Group-状态机" class="headerlink" title="Group 状态机"></a>Group 状态机</h1><p>在 0.9.0.0 之后的 Kafka，出现了几个新变动，一个是在 Server 端增加了 GroupCoordinator 这个角色，另一个较大的变动是将 topic 的 offset 信息由之前存储在 zookeeper 上改为存储到一个特殊的 topic 中（<code>__consumer_offsets</code>）。</p>
<h2 id="offset-那些事"><a href="#offset-那些事" class="headerlink" title="offset 那些事"></a>offset 那些事</h2><p>在 Kafka 中，无论是写入 topic，还是从 topic 读取数据，都免不了与 offset 打交道，关于 Kafka 的 offset 主要有以下几个概念，如下图。</p>
<p><img src="/images/kafka/consumer-figure2.png" alt="consumer offset"></p>
<p>其中，Last Committed Offset 和 Current Position 是与 Consumer Client 有关，High Watermark 和 Log End Offset 与 Producer Client 数据写入和 replica 之间的数据同步有关。</p>
<ul>
<li>Last Committed Offset：这是 group 最新一次 commit 的 offset，表示这个 group 已经把 Last Committed Offset 之前的数据都消费成功了；</li>
<li>Current Position：group 当前消费数据的 offset，也就是说，Last Committed Offset 到 Current Position 之间的数据已经拉取成功，可能正在处理，但是还未 commit；</li>
<li>Log End Offset：Producer 写入到 Kafka 中的最新一条数据的 offset；</li>
<li>High Watermark：已经成功备份到其他 replicas 中的最新一条数据的 offset，也就是说 Log End Offset 与 High Watermark 之间的数据已经写入到该 partition 的 leader 中，但是还未成功备份到其他的 replicas 中，这部分数据被认为是不安全的，是不允许 Consumer 消费的（这里说得不是很准确，可以参考：<a href="http://www.cnblogs.com/huxi2b/p/7453543.html" target="_blank" rel="external">Kafka水位(high watermark)与leader epoch的讨论</a> 这篇文章）。</li>
</ul>
<h2 id="Topic-consumer-offsets"><a href="#Topic-consumer-offsets" class="headerlink" title="Topic __consumer_offsets"></a>Topic <code>__consumer_offsets</code></h2><p><code>__consumer_offsets</code> 是 Kafka 内部使用的一个 topic，专门用来存储 group 消费的情况，默认情况下有50个 partition，每个 partition 三副本，而具体 group 的消费情况要存储到哪一个 partition 上，是根据 <code>abs(GroupId.hashCode()) % NumPartitions</code> 来计算（其中，<code>NumPartitions</code> 是<code>__consumer_offsets</code> 的 partition 数，默认是50个）的。</p>
<h2 id="GroupCoordinator"><a href="#GroupCoordinator" class="headerlink" title="GroupCoordinator"></a>GroupCoordinator</h2><p>根据上面所述，一个具体的 group，是根据其 group 名进行 hash 并计算得到其具对应的 partition 值，该 partition leader 所在 Broker 即为该 Group 所对应的 GroupCoordinator，GroupCoordinator 会存储与该 group 相关的所有的 Meta 信息。</p>
<p>在 Broker 启动时，每个 Broker 都会启动一个 GroupCoordinator 服务，但只有 <code>__consumer_offsets</code> 的 partition 的 leader 才会直接与 Consumer Client 进行交互，也就是其 group 的 GroupCoordinator，其他的 GroupCoordinator 只是作为备份，一旦作为 leader 的 Broker 挂掉之后及时进行替代。</p>
<h2 id="状态转移图"><a href="#状态转移图" class="headerlink" title="状态转移图"></a>状态转移图</h2><p>Server 端，Consumer 的 Group 共定义了五个状态</p>
<ul>
<li>Empty：Group 没有任何成员，如果所有的 offsets 都过期的话就会变成 Dead，一般当 Group 新创建时是这个状态，也有可能这个 Group 仅仅用于 offset commits 并没有任何成员（Group has no more members, but lingers until all offsets have expired. This state also represents groups which use Kafka only for offset commits and have no members.）；</li>
<li>PreparingRebalance：Group 正在准备进行 Rebalance（Group is preparing to rebalance）；</li>
<li>AwaitingSync：Group 正在等待来 group leader 的 assignment（Group is awaiting state assignment from the leader）；</li>
<li>Stable：稳定的状态（Group is stable）；</li>
<li>Dead：Group 内已经没有成员，并且它的 Meta 已经被移除（Group has no more members and its metadata is being removed）。</li>
</ul>
<p>其各个状态的定义及转换都在 <a href="https://github.com/apache/kafka/blob/0.10.1/core/src/main/scala/kafka/coordinator/GroupMetadata.scala" target="_blank" rel="external">GroupMetadata</a> 中定义，根据状态转移的条件和转移的结果做一个状态转移图如下所示</p>
<p><img src="/images/kafka/group.png" alt="group-state"></p>
<p>各个状态转化的情况，只有有对应箭头才能进行转移，比如 Empty 到 PreparingRebalance 是可以转移的，而 Dead 到 PreparingRebalance 是不可以的。后面会根据一个 Consumer Client 启动的过程，讲述一下其 Group 状态变化情况。</p>
<h1 id="Consumer-初始化"><a href="#Consumer-初始化" class="headerlink" title="Consumer 初始化"></a>Consumer 初始化</h1><p>Server 端 Group 状态的变化，其实更多的时候是由 Client 端触发的，一个 group 在最初初始化的过程总其实就是该 Group 第一个 Consumer Client 初始化的过程。</p>
<h2 id="Consumer-poll-过程解析"><a href="#Consumer-poll-过程解析" class="headerlink" title="Consumer poll 过程解析"></a>Consumer poll 过程解析</h2><p>对 Consumer 的初始化，正如 <a href="http://matt33.com/2016/07/21/kafka-new-consumer/">Apache Kafka 0.9 Consumer Client 介绍</a> 这篇文章所述，Consumer 的核心逻辑部分主要在其 poll 模型。而其源码的实现上，主要的逻辑实现也是在 <code>pollOnce</code> 方法，如下所示。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//<span class="doctag">NOTE:</span> 一次 poll 过程</span></div><div class="line"><span class="keyword">private</span> Map&lt;TopicPartition, List&lt;ConsumerRecord&lt;K, V&gt;&gt;&gt; pollOnce(<span class="keyword">long</span> timeout) &#123;</div><div class="line">    coordinator.poll(time.milliseconds());<span class="comment">//NOTE： 获取 GroupCoordinator 并连接、加入 Group、Group 进行 rebalance 并获取 assignment</span></div><div class="line"></div><div class="line">    <span class="comment">// fetch positions if we have partitions we're subscribed to that we</span></div><div class="line">    <span class="comment">// don't know the offset for</span></div><div class="line">    <span class="keyword">if</span> (!subscriptions.hasAllFetchPositions())<span class="comment">//<span class="doctag">NOTE:</span> 更新 offset</span></div><div class="line">        updateFetchPositions(<span class="keyword">this</span>.subscriptions.missingFetchPositions());</div><div class="line"></div><div class="line">    <span class="comment">// if data is available already, return it immediately</span></div><div class="line">    Map&lt;TopicPartition, List&lt;ConsumerRecord&lt;K, V&gt;&gt;&gt; records = fetcher.fetchedRecords();</div><div class="line">    <span class="comment">//NOTE： 根据最大限制拉取数据（按 partition 拉取,这个 partition 数据拉取完之后,拉取下一个 partition）</span></div><div class="line">    <span class="keyword">if</span> (!records.isEmpty())</div><div class="line">        <span class="keyword">return</span> records;</div><div class="line">    <span class="comment">//<span class="doctag">NOTE:</span> 说明上次 fetch 到是的数据已经全部拉取了,需要再次发送 fetch 请求,从 broker 拉取数据</span></div><div class="line"></div><div class="line">    <span class="comment">// send any new fetches (won't resend pending fetches)</span></div><div class="line">    fetcher.sendFetches();<span class="comment">//<span class="doctag">NOTE:</span> 向订阅的所有 partition 发送 fetch 请求,会从多个 partition 拉取数据</span></div><div class="line"></div><div class="line">    <span class="keyword">long</span> now = time.milliseconds();</div><div class="line">    <span class="keyword">long</span> pollTimeout = Math.min(coordinator.timeToNextPoll(now), timeout);</div><div class="line"></div><div class="line">    client.poll(pollTimeout, now, <span class="keyword">new</span> PollCondition() &#123;</div><div class="line">        <span class="meta">@Override</span></div><div class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">shouldBlock</span><span class="params">()</span> </span>&#123;</div><div class="line">            <span class="comment">// since a fetch might be completed by the background thread, we need this poll condition</span></div><div class="line">            <span class="comment">// to ensure that we do not block unnecessarily in poll()</span></div><div class="line">            <span class="keyword">return</span> !fetcher.hasCompletedFetches();</div><div class="line">        &#125;</div><div class="line">    &#125;);</div><div class="line"></div><div class="line">    <span class="comment">// after the long poll, we should check whether the group needs to rebalance</span></div><div class="line">    <span class="comment">// prior to returning data so that the group can stabilize faster</span></div><div class="line">    <span class="keyword">if</span> (coordinator.needRejoin())</div><div class="line">        <span class="keyword">return</span> Collections.emptyMap();</div><div class="line"></div><div class="line">    <span class="keyword">return</span> fetcher.fetchedRecords();</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>与 Server 进行交互，尤其初始化 Group 这一部分，主要是在 <code>coordinator.poll()</code> 方法，源码如下</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">poll</span><span class="params">(<span class="keyword">long</span> now)</span> </span>&#123;</div><div class="line">    invokeCompletedOffsetCommitCallbacks();<span class="comment">//<span class="doctag">NOTE:</span> 触发回调函数</span></div><div class="line"></div><div class="line">    <span class="keyword">if</span> (subscriptions.partitionsAutoAssigned() &amp;&amp; coordinatorUnknown()) &#123;</div><div class="line">        <span class="comment">//<span class="doctag">NOTE:</span> 通过 subscribe() 方法订阅 topic,并且 coordinator 未知</span></div><div class="line">        ensureCoordinatorReady();<span class="comment">//<span class="doctag">NOTE:</span> 获取 GroupCoordinator 地址,并且建立连接</span></div><div class="line">        now = time.milliseconds();</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="keyword">if</span> (needRejoin()) &#123;<span class="comment">//<span class="doctag">NOTE:</span> 判断是否需要重新加入 group,如果订阅的 partition 变化或则分配的 partition 变化时,需要 rejoin</span></div><div class="line">        <span class="comment">// due to a race condition between the initial metadata fetch and the initial rebalance,</span></div><div class="line">        <span class="comment">// we need to ensure that the metadata is fresh before joining initially. This ensures</span></div><div class="line">        <span class="comment">// that we have matched the pattern against the cluster's topics at least once before joining.</span></div><div class="line">        <span class="keyword">if</span> (subscriptions.hasPatternSubscription())</div><div class="line">            client.ensureFreshMetadata();</div><div class="line"></div><div class="line">        ensureActiveGroup();</div><div class="line">        <span class="comment">//<span class="doctag">NOTE:</span> 确保 group 是 active;加入 group;分配订阅的 partition</span></div><div class="line">        now = time.milliseconds();</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    pollHeartbeat(now);<span class="comment">//<span class="doctag">NOTE:</span> 检查心跳线程运行是否正常,如果心跳线程失败,则抛出异常,反之更新 poll 调用的时间</span></div><div class="line">    maybeAutoCommitOffsetsAsync(now);<span class="comment">//<span class="doctag">NOTE:</span> 自动 commit 时,当定时达到时,进行自动 commit</span></div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p><code>ensureCoordinatorReady()</code> 方法是获取该 group 对应的 GroupCoordinator 地址，并建立连接，然后再进行判断，如果当前的这个 Consumer Client 需要加入一个 group，将进行以下操作（向 Server 端发送 join-group 请求以加入 group，然后再发送 sync-group 请求，获取 client 的 assignment）</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//<span class="doctag">NOTE:</span> 确保 Group 是 active,并且加入该 group</span></div><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">ensureActiveGroup</span><span class="params">()</span> </span>&#123;</div><div class="line">    <span class="comment">// always ensure that the coordinator is ready because we may have been disconnected</span></div><div class="line">    <span class="comment">// when sending heartbeats and does not necessarily require us to rejoin the group.</span></div><div class="line">    ensureCoordinatorReady();<span class="comment">//<span class="doctag">NOTE:</span> 确保 GroupCoordinator 已经连接</span></div><div class="line">    startHeartbeatThreadIfNeeded();<span class="comment">//<span class="doctag">NOTE:</span> 启动心跳发送线程（并不一定发送心跳,满足条件后才会发送心跳）</span></div><div class="line">    joinGroupIfNeeded();<span class="comment">//<span class="doctag">NOTE:</span> 发送 JoinGroup 请求,并对返回的信息进行处理，还包括了发送 sync-group 请求并进行相应处理</span></div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h2 id="Consumer-初始化时-group-状态变化"><a href="#Consumer-初始化时-group-状态变化" class="headerlink" title="Consumer 初始化时 group 状态变化"></a>Consumer 初始化时 group 状态变化</h2><p>这里详述一下 Client 进行以上操作时，Server 端 Group 状态的变化情况。当 Consumer Client 首次进行拉取数据，如果该其所属 Group 并不存在时，Group 的状态变化过程如下：</p>
<ol>
<li>Consumer Client 发送 join-group 请求，如果 Group 不存在，创建该 Group，Group 的状态为 <strong>Empty</strong>；</li>
<li>由于 Group 的 member 为空，将该 member 加入到 Group 中，并将当前 member （client）设置为 Group 的 leader，进行 rebalance 操作，Group 的状态变为 <strong>preparingRebalance</strong>，等待 <code>rebalance.timeout.ms</code> 之后（为了等待其他 member 重新发送 join-group，如果 Group 的状态变为 <code>preparingRebalance</code>，Consumer Client 在进行 poll 操作时，<code>needRejoin()</code> 方法结果就会返回 true，也就意味着当前 Consumer Client 需要重新加入 Group），Group 的 member 更新已经完成，此时 Group 的状态变为 <strong>AwaitingSync</strong>，并向 Group 的所有 member 返回 join-group 响应；</li>
<li>client 在收到 join-group 结果之后，如果发现自己的角色是 Group 的 leader，就进行 assignment，该 leader 将 assignment 的结果通过 sync-group 请求发送给 GroupCoordinator，而 follower 也会向 GroupCoordinator 发送一个 sync-group 请求（只不过对应的字段为空）；</li>
<li>当 GroupCoordinator 收到这个 Group leader 的请求之后，获取 assignment 的结果，将各个 member 对应的 assignment 发送给各个 member，而如果该 Client 是 follower 的话就不做任何处理，此时 group 的状态变为 <strong>Stable</strong>（也就是说，只有当收到的 Leader 的请求之后，才会向所有 member 返回 sync-group 的结果，这个是只发送一次的，由 leader 请求来触发）。</li>
</ol>
<h2 id="Consumer-Rebalance"><a href="#Consumer-Rebalance" class="headerlink" title="Consumer Rebalance"></a>Consumer Rebalance</h2><p>根据上图，当 group 在 Empty、AwaitSync 或 Stable 状态时，group 可能会进行 rebalance；<br>rebalance 的过程就是：等待所有 member 发送 join-group（上述过程的第2步），然后设置 Group 的 leader，进行 reassignment，各个 client 发送 sync-group 来同步 server 的 assignment 结果。</p>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[别人向上，我们却在向下]]></title>
      <url>http://matt33.com/2017/01/08/book/</url>
      <content type="html"><![CDATA[<p>花了两周多的时间把钱穆老先生这部神作读完了，读完之后的感觉是，书中有太多的观点让我有醍醐灌顶之感，钱老读史思考的深度远非常人所及，这本书非常值得拜读，豆瓣上也同样给出了9分以上评价，真的名不虚传（<a href="https://book.douban.com/subject/11229072/" target="_blank" rel="external">《中国历代政治得失》</a>）。因为这本书并不是一气看完，大部分是在上下班的班车上看的，每天看一部分，持续半个月之后才看完，所以书中一些感觉很不错的观点到现在可能已经忘了一部分，现在回忆起整本书，大概有三点让我印象非常深刻，下面也会就这三点讲述一下。</p>
<p>第一点印象最深的地方当然是<strong>制度</strong>这一部分了，全文几乎都是在围绕着历代的政治制度而讲述。好的制度可以让这个国家更简单、更高效地运转，中国自古有句俗话，叫做”打天下容易，坐天下难”，在打天下的时候，少则几年、多则十几年就能打下天下。但随着队伍、领地的扩大，很多问题会暴露出来，由于之前是战时，这些问题可以暂时不管，而一旦国家归于统一、社会稳定下来之后，这些问题就不能不管了，如何为政府选取人才、如何指定合理的徒土地政策、赋役政策以及军队政策等，这些问题哪一个处理不好，都可能会导致功亏一篑，所以说坐天下难。但是难也得干下去，正所谓在其位谋其政，历代政府都使出自己的浑身解数，制定了一套政策，让这个庞大的国家开始缓慢地运转，而有些政策因其非常重要可能会以明文记载作为制度来保证政策高效地运行，制度一旦形成，甚至就如信仰一般，无人敢违逆。每个朝代在开始时期，都会指定一套保证政府运转的制度（而有的朝代却攻于权术，想着各种手段维护自己的统治，而不是尽一个政府的职责），而这些制度一旦形成，随着发展，到后期可能会变得漏洞百出而成为一些利息集团的保护伞，正所谓此一时彼一时，时代在发展，历史上也没有一套制度可以高效地运作几千年或者几百年而不离其初心。而且一旦利息集团形成，后世的知识分子又如何去改变呢？有的知识分子虽然看到这些弊端，如王安石，他同样也身居高危开始变法，也有了皇帝的支持，可是最后依然没有成功，中国人老是讲一句”祖宗之法不能改”。这种观念反而束缚了后世，如果制度不用变，后世还要政治家干什么？这也导致一个朝代兴起之后，后来因慌于人事而逐渐走向下坡路。朝代初兴之时，一般会出现很多人才，也会有圣明的皇帝，这种情况下，一些制度是可以按照其初心正常运作，而几十年或者百年之后，如果人事不给力，谁来保证？多少朝代由于这而毁，这也就突出一个好制度的重要性。制度，名义上一种规章制度，是大家共同遵守的信仰，也是约束大家的法则，但制度又不能一成不变，中国有时候就非常认死理，制度竟然可以原封不动运行几百年，这到后面怎么可能不出问题？这时候如果说中国没有法制观念反而不合适，我们反观一下西方人，他们的制度或法律其实是不在不断变化的、或者是进入了一个不断完善的轨道，西方的一些政府人员是是由人民选举出来，所以必然会代表多数人的利益，要不然下次肯定会被选下去，所以他们的制度或者法律也是会必然代表多数人的利益，而多数人的利益在发展的过程中是在不断变化的、而不是一成不变的，这也是它们制度能够自我完善的一个原因。而历史中的我们，就很难做到这一点，如果皇帝大臣是圣人君子还好，如果不是，受苦的只能是老百姓，这就说明，我们虽然有制度，但是并没有好的制度来保证这个国家的长久运转。</p>
<p>第二点说一下利益集团，或者是权力集团，钱老提出的这点观点还是很令我感到新奇的。西方社会刚开始的权力是把握在教会手中，后来又到了贵族手中，从来没有开放给全社会，这也是西方民众对主权、对权力的非常看重的原因，而我们则不一样，可以说从秦朝开始权力就已经开放给全社会或者很大一部分开放给全社会了，除了皇室，其他的职位到后来已经没有世袭，只要你有能力有才华而且又能证明自己，即使你出身低贱也能走向巅峰，如商鞅、韩信等。后来到了唐朝之后，就开始形成了科举制度，读书人科举成功即可入朝为官，可以说从此之后，中国社会的权力集团就是这些知识分子，他们才是保证这个国家运转的核心。虽说中国是皇权社会，但是皇帝只是一个人，不可能管理整个国家，皇帝的背后必然会有一群体支持着皇帝，帮着皇帝去管理整个国家。有了科举制度之后，整个国家的运转就靠着这些选举出来的人才来管理，而那些朝廷大员又非世袭，很多丞相或者内个大学士都出身贫苦，国家靠着这些读书人管理着整个国家，所以可以说中国是一个”仕人社会”，只不过到了元朝和清朝就变成了”部族社会”，这就另说了。</p>
<p>第三点读完之后的感受就是在两千年的历史（从汉到清）中，能明确感受到以下几点：1.中央政府在不断地集权、而地方政府的权力在衰落，地方政府的地位也在降低，尤其是那些真正管理百姓的县长，到后来职位是越来越低，甚至与中央通话都要隔着三四级，他们上要讨好上级，下要管理百姓，其实也是着实为难；2.政府为了防止百姓造反采取了很多的政策，比如在内部分裂知识分子以及普通民众，这也导致国人越发得不团结，不团结也就没有力量，甚至国人开始慢慢变得异常窝里斗，我们民族的这些糟粕都是有其缘由的；3.中国官本位也是有其原因的，自古以来优秀人才都被引入到了仕途，读书人心中也形成了一种观点——“学而优则仕”，而且政府到后来反而在不断地抑商，一是人才不断涌向政府，政府又用不了这么人，造成政府人事不断臃肿，二是其他行业需要人才反而又得不到人才，导致发展缓慢；4.民众的自由程度在不断压缩，甚至到了清朝为了防止汉人反清还实行了一些政策，取消了言论自由、结社自由和出版自由，这些在清朝之前都是很正常的东西，后来就慢慢给禁止了，而随后大家竟然慢慢习惯了，这也是因为个人力量非常薄弱，而大家又很难团结一起。这些不断形成的东西，站在民族长远的角度来看，对我们中华民族是非常有害的、不利的。</p>
<p>读完之后，尤其是与西方的历史对比，心中总是少不了些许疼痛，曾经引领世界的、有着全世界最优秀制度的民族，到最后竟然轮到没有自由的部族政治，清朝之害，远重于崖山。</p>
<hr>
<blockquote>
<p>汉光武自身是一好皇帝，明帝，章帝都好，然而只是人事好，没有立下好制度。因此皇帝好，事情也做得好。皇帝坏了，而政治上并不曾有管束皇帝的制度，这是东汉政治制度上的一个大问题。也是将来中国政治制度史上一个大问题。——钱穆, 中国历代政治得失, loc. 414-416</p>
</blockquote>
<p>Notes: 1) 缺少一种好的制度来防止其他情况的出现。</p>
<blockquote>
<p>但日子久了，那制度就变坏了。这不只是汉代选举制度如是，我们可以说，古今中外一切制度，都必如是。否则一项好制度，若能永远好下去，便将使政治窒息，再不需后代人来努力政治了。——钱穆, 中国历代政治得失, loc. 448-450</p>
</blockquote>
<p>Notes: 1) 任何政策都有其漏洞,时间越久,漏洞也就越多</p>
<blockquote>
<p>《唐六典》的，仍不应仅当它是一部历史书，为记载唐代现实制度的书，而应同时当它是一部理论和思想的书看。因唐代人对政治上的种种理论和思想，都已在此书中大部具体化制度化了。制度的背后，都应有理论和思想。一切制度，决不会凭空无端地产生。若我们忽略了中国以往现实的政治制度，而来空谈中国人以往的政治思想，也决无是处。——钱穆, 中国历代政治得失, loc. 568-571</p>
</blockquote>
<p>Notes: 1) 唐代的巨大进步</p>
<blockquote>
<p>总之中国是一个广土众民的大国家，必需得统一，而实不宜于过分的中央集权。这在中国的政治课题上，是一道值得谨慎应付的大题目。现在专说唐代，似乎其中央行政比汉进步，而地方行政则不如汉。中央的监察官变成了地方行政官，这是一大缺点。而由军队首领来充地方行政首长，则更是大毛病。唐室之崩溃，也可说即崩溃在此一制度上。——钱穆, 中国历代政治得失, loc. 609-612</p>
</blockquote>
<p>Notes: 1) 节度使既掌握军事又掌管地方事务,很危险</p>
<blockquote>
<p>从此可知，政治制度是现实的，每一制度，必须针对现实，时时刻刻求其能变动适应。任何制度，断无二三十年而不变的，更无二三百年而不变的。但无论如何变，一项制度背后的本原精神所在，即此制度之用意的主要处则仍可不变。于是每一项制度，便可循其正常轨道而发展。此即是此一项制度之自然生长。——钱穆, 中国历代政治得失, loc. 639-642</p>
</blockquote>
<p>Notes: 1) 制度因时因地而异.</p>
<blockquote>
<p>理论是此制度之精神生命，现实是此制度之血液营养，二者缺一不可。——钱穆, 中国历代政治得失, loc. 643-644</p>
</blockquote>
<p>Notes: 1) 理论是理想的,现实是不断完善理论,两则相辅相成。</p>
<blockquote>
<p>其实革命的本质，应该是推翻制度来迁就现实的，绝非是推翻现实来迁就制度的。我们此刻，一面既否定了传统制度背后的一切理论根据，一面又忽略了现实环境里面的一切真实要求。——钱穆, 中国历代政治得失, loc. 646-648</p>
</blockquote>
<p>Notes: 1) 制度为解决现实问题而生。</p>
<blockquote>
<p>当知任何一种制度之建立，傥是仅由一二人之私意便能实现了，这便无制度可讲。若谓此乃皇帝欺骗民众，而且凭此欺骗，便能专制几百年，古今中外，绝无此理。若民众如此易欺易骗，我们也无理由再来提倡民主政治。凭事实讲，科举制度显然在开放政权，这始是科举制度之内在意义与精神生命。汉代的选举，是由封建贵族中开放政权的一条路。唐代的公开竞选，是由门第特殊阶级中开放政权的一条路。——钱穆, 中国历代政治得失, loc. 673-677</p>
</blockquote>
<p>Notes: 1) 制度产生之历史背景,有其合理的地方,不能一言以蔽之。</p>
<blockquote>
<p>而中国则自唐以下，便已犯了政权开放之流毒。以水救水，以火救火，不仅是药不对病，而且会症上加症。若要解决中国社会之积弊，则当使知识分子不再集中到政治一途，便该奖励工商业，使聪明才智转趋此道。然结果又很易变成资本主义。在西方是先有了中产社会，先有了新兴工商资本，然后再来打开仕途，预闻政治。而中国则不然，可说自两汉以来，早已把政权开放给全国各地，不断奖励知识分子加入仕途，而同时又压抑工商资本。只鼓舞人为大学者，当大官，却不奖励人为大商人，发大财。节制资本，平均地权，大体上是中国历史上的传统政策。政治措施，存心在引导民间聪明才智，不许其为私家财力打算无限制的发展。——钱穆, 中国历代政治得失, loc. 683-689</p>
</blockquote>
<p>Notes: 1) 知识分子都涌入政治,造成官员庸肿不堪,直到今天依然如此,一个局长会有近十个副局长。 政治无法消化所有的优秀人才,应该将人才引入其他该需要的地方,以发挥最大的价值。</p>
<blockquote>
<p>即就账籍制度言，可见每一项制度之推行与继续，也必待有一种与之相当的道德意志与服务忠诚之贯注。否则徒法不能以自行，纵然法良意美，终是徒然。而且任何一制度，也必与其他制度发生交互影响。故凡一制度之成立，也绝非此制度可以单独成立的。——钱穆, 中国历代政治得失, loc. 717-720</p>
</blockquote>
<p>Notes: 1) 并不完全依靠法治,对道德水准有一定要求。</p>
<blockquote>
<p>好像汉代是在社会上层节制资本，而下层则没有力量管；唐代注意社会下层，由国家来计划分配，而让上层的富民能自由发展。这一情形，似乎唐代人更要高明些。他可以许你过富，却不让你过穷。——钱穆, 中国历代政治得失, loc. 774-776</p>
</blockquote>
<p>Notes: 1) 汉唐经济思想之精髓</p>
<blockquote>
<p>不过事情隔久了，这事情演变之本原意义忘失了，后人便只见得皇帝之尊严与宰相之卑微了。——钱穆, 中国历代政治得失, loc. 893-893</p>
</blockquote>
<p>Notes: 1) 一个制度的确立有其原因,但随着时间其原意慢慢被抛到脑后,久而久之也就为人所不知了。</p>
<blockquote>
<p>宋代制度之缺点，在散，在弱，不在专与暴。直到南宋宁宗时，已快亡国，皇帝时时下手条，当时称为御札，还激起朝臣愤慨，说事不出中书，是为乱政。可见宋代相权，还有它传统客观的地位。我们此刻只根据历史来说宋不如唐，所谓宋代宰相失职，一切仍是制度问题。并不是只有皇帝专制，更不要制度。——钱穆, 中国历代政治得失, loc. 916-919</p>
</blockquote>
<p>Notes: 1) 制度中的问题看似只是一条命令,实则影响巨大,制度要有自我完善机制</p>
<blockquote>
<p>无制度的政府，哪能有好施为，哪能有好结——钱穆, 中国历代政治得失, loc. 964-964</p>
</blockquote>
<p>Notes: 1) 制度的确立是有其缘由的,要明白背后的原因才能更好地让制度用在正途。</p>
<blockquote>
<p>宋代则把财富兵力都集中到中央，不留一点在地方上，所以中央一失败，全国土崩瓦解，再也没办法。——钱穆, 中国历代政治得失, loc. 985-986</p>
</blockquote>
<p>Notes: 1) 越往后,君权越大,中央集权越严重。</p>
<blockquote>
<p>任何一省都如此。给你这一半，割去你那一半。好使全国各省，都成支离破碎。既不能统一反抗，而任何一区域也很难单独反抗。这是行省制的内在精神。——钱穆, 中国历代政治得失, loc. 1321-1322</p>
</blockquote>
<p>Notes: 1) 背后的原因</p>
<blockquote>
<p>举人以下就没有做大官的份，如是则科举场中也分了流品。进士及第是清流，浮在上面直向前，秀才举人则变成了浊流，沉淀在下面，永远不超升。鼎——钱穆, 中国历代政治得失, loc. 1428-1430</p>
</blockquote>
<p>Notes: 1) 此思想毒害后代</p>
<blockquote>
<p>而且纵使存心公正善良的人，其所创制度，也可有偏弊，有流害。我们必如是想，才能对政治制度有深一层之研讨与警惕。——钱穆, 中国历代政治得失, loc. 1459-1460</p>
</blockquote>
<p>Notes: 1) 制度逐渐演化,已经在慢慢背离初衷。</p>
<blockquote>
<p>制度指政而言，法术只是些事情或手段；不好说是政治。大抵制度是出之于公的，在公的用心下形成的一些度量分寸是制度。而法术则出之于私，因此没有一定恰好的节限。所谓方法与权术，二者之间，当然又不能仔细分。——钱穆, 中国历代政治得失, loc. 1548-1550</p>
</blockquote>
<p>Notes: 1) 一个有度,一个没有</p>
<blockquote>
<p>论汉代，西汉可说是制度，东汉则多半出于光武的私心。论唐代，确实可说在建立制度，而宋代则有许多只算是一种法术。明代，有许多只能说它是一些事，不能说它是一些制。尤其是清代，可说全没有制度。它所有的制度，都是根据着明代，而在明代的制度里，再加上他们许多的私心。这种私心，可说是一种“部族政权”的私心。一切有满洲部族的私心处罚，所以全只有法术，更不见制度。——钱穆, 中国历代政治得失, loc. 1553-1557</p>
</blockquote>
<p>Notes: 1) 崖山之后无中国。并不准确。</p>
<blockquote>
<p>可是我们中国历史从汉代起，就不能叫皇权，因皇帝一个人不可能掌握一个国家的大权。也不能说它是贵族政权，因自汉代起，已没有显然的贵族。说是军人政权吗？我们也看不出汉政府以下，是由军人掌握的。说是资产阶级的政权吗？中国一向没有资产阶级。所以若说政权，则中国应该是一种士人政权，政府大权都掌握在士——读书人手里，从汉到明都如此。——钱穆, 中国历代政治得失, loc. 1569-1573</p>
</blockquote>
<p>Notes: 1) 这点分析得很好,利益总是被这些少数群体把握着。</p>
<blockquote>
<p>美国人尽管看重东方的商业，但他只可想旁的方法，不能派一总督来管理菲律宾，而把他们开国以来全部历史精神推翻了。所以今天苏维埃说美国帝国主义，其实是名实不相符。但若说英国对香港是一种帝国主义，这是百辩难逃的。因他把全国家分成了两部分，一部是本国，一部是征服地。这才始得叫帝国。清代有所谓本部十八省，外边又有藩属，故说它像西方的帝国，但细辩又不同。因清人待蒙古，比待中国本部的人还要好，蒙古人得封亲王，中国人是没有的。英国人断不能待香港人比待他本国的人好，可见就算清代也是帝国，还是东西巧妙不同的。——钱穆, 中国历代政治得失, loc. 1765-1770</p>
</blockquote>
<p>Notes: 1) 如果这样来看,确实如此,清朝也可以认为与英国一样。</p>
<blockquote>
<p>我们现在的毛病，就在喜欢随便使用别人家的现成名词，而这些名词的确实解释，我们又多不了解。——钱穆, 中国历代政治得失, loc. 1770-1771</p>
</blockquote>
<p>Notes: 1) 不明缘由</p>
<blockquote>
<p>当时的洪杨，并不是推不翻满清，但他们同时又要推翻中国全部历史，所以他们只可有失败。——钱穆, 中国历代政治得失, loc. 1811-1811</p>
</blockquote>
<p>Notes: 1) 缺少刘伯闻这样的谋士,这种谋士要上通天文,下知地理,也就是熟悉中国历史。</p>
<blockquote>
<p>但康有为只知道皇帝无害于立宪，却不知道满清皇帝的后面是一个部族政权在撑腰。部族政权是决不容有所谓立宪的。孙中山先生主张革命，一定要推翻皇帝，康有为的变法就变成了保皇，似乎又像非要皇帝不可了。康有为实在没有看清楚，他以为只要光绪皇帝听他话，变法就变得成，这是他的大错误。这个错误也就是错误在他没有像西洋人般懂得政治上的所谓主权的观念。他不懂得当时的中国政治，是满洲部族主权的政治。掌握主权的是满洲人，哪里是像他所谓的皇帝专制呢？他误认为中国传统政治只是皇帝专制，故而以为只要皇帝听我话，便可由皇帝专制一变而为皇帝立宪。——钱穆, 中国历代政治得失, loc. 1817-1822</p>
</blockquote>
<p>Notes: 1) 争论到最后变成了是否要保皇,已经失其初心。而且清帝国并非只是皇帝一人专制,后面利益何其复杂。</p>
<blockquote>
<p>至于中国历史上的传统政权，无论汉、唐、宋、明，却并无私权力，私立场，私背景，它的立场背景便是全国人民，便是全社会。所以遇到政治腐败，只要换一批人，把制度腐败了的略略修改，就仍可继续下。——钱穆, 中国历代政治得失, loc. 1828-1830</p>
</blockquote>
<p>Notes: 1) 两千年历史没有革命。 2) 两千年历史没有革命,变得很少。</p>
<blockquote>
<p>中国政治，实在一向是偏重于法治的，即制度化的，而西方近代政治，则比较偏重在人治在事实化。何以呢？因为他们一切政制，均决定于选举，选举出来的多数党，就可决定一切了。法制随多数意见而决定，而变动，故说它重人、重事实。我们的传统政治，往往一个制度经历几百年老不变，这当然只说是法治，是制度化。法治之下，人才就受束缚了。所以明末的黄梨洲要慨然说：“有治人，无治法。”这因一向制度太繁密，故使他太不看重法，太看重人，而要提出此主张。——钱穆, 中国历代政治得失, loc. 1905-1909</p>
</blockquote>
<p>Notes: 1) 这样的解释醍醐灌顶之感,我们一般认为中国缺少法治基因,而实际并非如此。</p>
<blockquote>
<p>孙先生不是读死书的人，他这几句话，并不由任何西方抄袭来，他真是深识远虑，确有他所见。政府是该属于民众的，但不是，也不能，定要全体民众直接来掌握此政权。理论上，国家政权当然在民众，该以民众大家的意见为意见。但民众意见，终是句空话。如何来表达出此民众的意见呢？今天中国多数民众，尚依赖政府来注意教和领导，他们哪有办法来过问政治？然而一个国家总要有一个不可动摇的中心，即如目前的日本，他们把历史上的传统中心皇帝尊严摇动了，急切间社会也会发生摇动的，他们拿什么东西来填补，来维系？这在他们也将成为一问题。中国也会碰到这问题的，而且早已碰到了。——钱穆, 中国历代政治得失, loc. 1924-1929</p>
</blockquote>
<p>Notes: 1) 孙中山先生有其擅长的地方,也有其不擅长的地方。</p>
<blockquote>
<p>历史终是客观事实，历史没有不对的，不对的是在我们不注重历史，不把历史作参考。至少我们讲人文科学方面的一切，是不该不懂历史的。政治也是人文科学中一门，我们回头把以前历史经过，再看一道，总还不是要不得。——钱穆, 中国历代政治得失, loc. 1948-1950</p>
</blockquote>
<p>Notes: 1) 历史是宝贵的财富,也是文化传统,焉能一笔抹杀</p>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[2016年终总结]]></title>
      <url>http://matt33.com/2016/12/31/2016-summary/</url>
      <content type="html"><![CDATA[<p>今天凌晨2点吃完饭回来之后，真是辗转反侧，不知为何，一直难以入眠，或许因为过了睡点，又或许因为昨晚的年会玩得太嗨，也可能是感觉对过去的一年有些许遗憾……</p>
<p>昨晚参加了最后一次实验室的年会，前两年中的都是三等奖（100块钱），没想到昨晚运气大爆发了，中了特等奖（Kindle Voyage），也算是2016年一个比较好的收官。然而，晚上睡觉时内心却是如何也无法平静下来，脑海中一直不断闪烁着过去一年、甚至过去两三年发生的一些事，不管怎样，时间就是这样，过去的就是过去了，并不以我们的意志为转移。</p>
<p>孟子说“吾日三省吾身”，这句话我们上小学时都学过，可是大多数人并没有去认真践行过，可能是现在这个社会给人压力大得已经很少有时间去思考、去反思。但是很多人却都有年终总结的习惯，总结一下过去一年做了什么事，是否完成了去年年终总结定的计划，再做一下未来一年的计划。有计划的人生总是会好一点，至少会给未来一年指引方向，甚至可以通过一些量化的指标来屏蔽一些重要的问题：我要想什么样的人生，我想要什么样的生活。这两个问题真的很难去回答，其实我们每个人也只是在不断地去摸索，因为我们原本就没有一个很清晰的目标。即使有了清晰的目标也很难在未来一年的时间里去完成，而我们又都是如此地急功近利，如果一件事情要花费自己三五年的时间、甚至十年时间的话，很多人可能都会选择放弃，去选择一些易于在短期内实现的目标。如果一个人没有一个清晰的长远目标，或者没有这个概念的话，那么年度目标其实也就是督促自己做点事而已。对于我们这种即将毕业或者刚步入职场的人来说，虽然并不一定有一个非常清晰的长远目标，但是至少是要有一个这样的概念。选取一个或者多个对你非常重要、或者能给你带来很大的提高、而短期无法实现的长远目标，把这个分割到每一年里慢慢去实现，但有一点要明确的是长远目标的制定依然是为了那两个问题而设置的，那两个问题肯定会在未来十年甚至二十年的时间不断地困扰我们，我们能做的，也只是不断地尝试，不断地去追寻内心（以上只是个人感慨，下面开始流水账）。</p>
<h1 id="工作"><a href="#工作" class="headerlink" title="工作"></a>工作</h1><p>从今年开始也算是正式迈入了职场，毕竟也在公司实习了半年多了，今年最重要的事情就是找工作这件事了，人生的第一份工作，好在最后去的部门、做的事情是自己想要的（找工作的感想可以参考<a href="http://matt33.com/2016/11/15/job-summary/">校招找工作小记</a>）。</p>
<p>除了正式工作，另一件非常重要的事就是毕业这件事了。记得去年下半年一直在绞尽脑汁，憋了好久才写了一篇小论文的大概，没写出多少，今年年初来了之后就边找实习边写小论文，最后也很幸运地成功水了一个会议。小论文之后又是大论文，纸老虎打了一个总是还会再出现一个，在实习前火急火燎地完成了初稿，后来又花了半个多月改了一下，到目前为止还没出现什么问题，祈祷盲审不中，明年顺利毕业。</p>
<p>关于明年，希望自己在工作上能有所建树，自己在公司未来的方向就是 Kafka 平台的开发和运维，希望自己能实现以下几个小目标：</p>
<ol>
<li>经过这半年对 Kafka 源码的学习和理解，希望明年把源码方面的东西都总结一下，对源码的核心设计了然于胸，多向社区提交一些 pr，成为 Kafka 领域较有权威的 contributor；</li>
<li>同事在公司经常会说<code>三分技术，七分做事</code>，虽然并不完全认同，但至少也得四分或五分做事，明年好好制定和完成自己的 KPI，认认真真做事，答应的事情要能按时按质搞定，做一个技术上靠谱的人，养成这样的习惯；</li>
<li>希望明年下半年晋升到P2.1，对小组、部门和公司业务有更深入的了解；</li>
<li>多与同事、业界交流技术经验，希望自己明年的 Github Contribute 更饱满；</li>
<li>好好运营自己的博客网站，每个月保持两篇技术文章输出（一篇 Kafka 相关）；</li>
<li>明年也应该补充一下自己的计算机基础知识，希望能够把《算法 第4版》、《深入理解计算机系统》和《计算机程序语言的构造与解释》这三本好好深入学习一下，前两本看了两年了才各自看了一半，真是惭愧，希望明年执行力强一些，把这三本坚持啃下来，并做一些相关的笔记；</li>
<li>对于其他的技术，要达到会用的效果，能够实现自己想要的功能，利用幂次法则用20%的时间达到80%的效果，选择三个方面：前端（Django、Boostrap使用）、spark（使用以及内部框架有较深入的了解）、机器学习（把周志华《机器学习》学习一下，找几个小项目做一下）；</li>
<li>每个月看一篇大数据方向的领域的相关论文，今年计划看12篇；</li>
<li>还有一个明年要做的也是很重要的是英语，先从听力开始，通过老友记去学习，要听到听懂每个句子未知，然后可以借鉴《技巧》里的不断加强难度练习的方式进行练习，一定要坚持下去，英语对于未来的发展还是至关重要的。</li>
</ol>
<p>上面的小目标也都不是很难，希望自己能够完成。</p>
<h1 id="生活"><a href="#生活" class="headerlink" title="生活"></a>生活</h1><p>今年貌似生活很平平淡淡，没有太大变化，只有几个微小的变化：</p>
<ul>
<li>之前和女朋友说了几年的云南自由行终于实现了，云南也确如网上所言，风景很好，我们整个旅途总体玩得也很开心，唯一不好的地方就是在香格里拉遇到了那些借着宗教、善意骗人的当地藏民，影响自己的心情，对那些地区多了一些偏见；</li>
<li>今年总共回家了三次，过春节一次，年中表弟结婚一次，十一回去一次，8月的时候老妈跟老弟来北京，带着他们在北京玩了三四天，老爸老妈随着年龄的增大，皱纹白发已经开始增多，自己纵有太多心酸也无可奈，只希望自己能早些立住脚，让父母过得舒适一些，年初春节的时候跟老爸老妈商量为了老弟的学习，就在学校附近租了房子专门让老妈去做饭，可是投入这么多，却没有任何收获，老弟反而更加肆无忌惮、更加贪玩，成绩也成了倒数，唉，少年不知愁滋味，只希望老弟早些长大；</li>
<li>今年自己开始买了一些装备玩户外，不过都是一些很成熟的入门级路线，不过开始总是好的，发现自己还是挺喜欢这些运动的；</li>
<li>年中的时候买了单反，开始玩起了摄影，不过目前技术依然很渣，虽然把 Lightroom 学得差不多了，但是却发现自己的硬伤是审美，并不很清楚什么样的照片才是美的照片，也并不知道在拍照时如何告诉拍照人摆 pose 以拍出最好的效果；</li>
<li>一个月前买了一个 Kindle，今年抽空确实看了不少书（<a href="https://github.com/wangzzu/awesome/blob/master/book-list.md" target="_blank" rel="external">2016个人书单</a>），大概有11本左右，因为之前看的书少，所以看的都是一些评分较高的书，其中也发现了几本好书，有两本准备寒假回去再看一遍，写几篇读书笔记，在以后的工作生活中按照书中介绍一些方法论去实验一下；</li>
<li>今年也算是坚持锻炼了身体，估计跑步跑了三百公里左右，上半年也经常去游泳，到公司实习后，回学校游泳不太方便，就经常去参加一些羽毛球活动，虽然没有把腹肌撕裂者坚持下去练出几块肌肉，但总体体重跟去年一样，并没有走样；</li>
<li>其他的都是一些琐碎之事，见了一些老朋友，很多都是几年未见的，在中学的时候感觉这些好哥们应该会一直在一起玩耍，现在却发现一年见上一面都很难，也由于各自在不同的环境下、不同的行业里大家慢慢渐行渐远，总之，感慨良多，要好好珍惜身边的好哥们，真如大土豆所言，能一直深交的好哥们人生有二三可能就已足矣。</li>
</ul>
<p>人生的时间，可能除了工作，其他基本上就属于生活了吧。中国讲<code>日子要越过越红火</code>，生活也是应该计划计划，未来一年希望能把下面的几件事搞定：</p>
<ul>
<li>走了近六年的爱情长跑，也总该有个结果了，希望明年能搞一个难忘的求婚仪式，结婚是明年还是后年可以再定，准备明年领证；</li>
<li>谈到了求婚，就不得不说到买房，希望明年户口迁杭州顺利，并把房子搞定，这个是明年重中之重，明年估计有一个月的工资就要交给铁总了；</li>
<li>希望老弟明年能进步，要不然在河南这样的高考大省，可能连上高中的机会都没有了，跟爸妈春节好好交交心，让他们少干点活，有些事情能不做的就不做了，到了这个年龄，健健康康才是最重要的；</li>
<li>坚持锻炼身体，在公司健身房多跑步（明年保持300km 以上），学习一下标准的羽毛球动作，提高球技（希望能在公司的高手场过上几招），冬天的时候跟公司的俱乐部学习一下滑雪，特别是单板（学会单板的滑行、刹车拐弯，冲一次高级场），也准备参加一些户外活动（爬山、穿越明年还是不能少），希望明年能体验一下蹦极，明年年初的毕业旅行计划去东南亚玩一趟，明年年终的时候，希望有时间和机会跟女友去日本或台湾一趟；</li>
<li>多读些书，非技术类的书籍明年计划读20本，好的书要做一下读书笔记；</li>
<li>明年就要出去租房子住了，希望合租的人能够好相处一些，明年打算练一下自己的厨艺，自己做饭还是要比外面干净很多，外面的东西越来越不放心了。</li>
<li>还有就是单反，学习审美，多拍多练习。</li>
</ul>
<h1 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h1><p>人是越长大越孤单，小的时候每当我们做错事、有什么需要改正的缺点，父母都会去提醒我们，而长大之后，如果影响不到别人，别人可能根本不会搭理你，这也有可能是因为长大之后，大家性格思维都在固化，很难去纠正，别人也就懒得去管了。而对于我们个人的发展来说，这是非常不利的，找不到或发现不了自己的缺点，那提升自己就变得很难。所以，作为一个人，还是要有自知之明，正视自己的缺点，有的时候可能是从别人身上看到我们自己的影子（通过看别人来反思自己），有的时候可能朋友会对我们一些善意的提醒，对于这样的朋友，我们应该去珍惜。记得今年去华为面试的时候在公交上遇到了一个基督徒，人挺不错，他帮助我准备面试，并帮我指出一些问题，他指出的一个问题是我说话时语速太快，之前关于这个问题我真是一点都没有意识到，后来我刻意听了一下给别人发的微信语音，确实有这个问题，如果是平时聊天还好，而如果是做一些技术交流的话，就会出问题，对于一个问题因为自己比较熟悉、快速说出来并没有问题，而别人对这个问题如果不熟悉，自己的语句就应该放慢一些给别人足够的思考时间，这才是一种有效的交流方式，希望明年在这方面能有所改进。还有一个问题，发现身边有些同学，平时交流、出去玩都还可以，但是为人却很不大气，可能会需要一些成本才能感受出来，不过这个成本也值得，能够让自己对别人了解更深入些，以后交往有所顾忌，从这件事情上，其实也能够看出自己的一些影子，对于自己来说，需要做的是，与比较豪爽的人交往自己也应该豪爽，而与一些不大气或者小气的人交往时，就应该有所注意，当然也不能让被人的缺点阻挡自己的眼睛，还是要多发现别人的优点，毕竟人无完人。也希望自己明年能对一些事情看开一下，努力学习苏公<code>一蓑烟雨任平生</code>的人生态度。</p>
<p>总之，希望明年事事顺心，家人身体健康。</p>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[Java 的 Checked 和 Unchecked Exception【译】]]></title>
      <url>http://matt33.com/2016/12/13/java-exception/</url>
      <content type="html"><![CDATA[<p>如果在 Java 应用中对 Exception 能够正确处理，那么将会使你的程序更具有健壮性。但是很多人对 Exception 中的 <strong>Checked Exception</strong> 和 <strong>Unchecked Exception</strong> 并不理解，并且 Exception 又常常被被分为 JVM Exception 和程序 Exception，这就让一些开发者显得更加困惑了，本文就这几个概念详细讲述一下。（本文翻译自<a href="http://www.hacktrix.com/checked-and-unchecked-exceptions-in-java" target="_blank" rel="external">Checked and Unchecked Exceptions in Java</a>）</p>
<h1 id="Checked-Exception"><a href="#Checked-Exception" class="headerlink" title="Checked Exception"></a>Checked Exception</h1><p>Checked Exception 是必须在代码中进行恰当处理的 Exception，而且编译器会强制开发者对其进行处理，否则编译会不通过。你可以使用 <code>catch</code> 语句捕获这些 Exception 或者在方法声明处使用 <code>throws</code> 语句抛出该异常。</p>
<p>一般来说，Checked Exception 的发生主要是由于一些特殊情况没有考虑到，比如如果网络连接失败会抛出 IOException，但是我们的程序应该能够提前预料到这些可能发生的异常，并对其进行处理，这样程序在运行过程中才不会崩掉，这也是编译器强制开发者对 Checked Exception 进行处理的原因。假设在文件传输的过程中网络出现中断，这时候程序应该能够捕获到这种异常并进行处理（重新尝试传输文件）。</p>
<h1 id="Unchecked-Exception"><a href="#Unchecked-Exception" class="headerlink" title="Unchecked Exception"></a>Unchecked Exception</h1><p>Unchecked Exception 的发生有一些是由于开发者代码逻辑错误造成的，比如：NullPointerException 这种异常可以通过检查一个引用是否为 null 来进行避免。</p>
<p>但是也有一些 Unchecked Exception 出现并不是因为开发者程序的问题，这些 Exception 是 <code>java.lang.Error</code> 的子类。就像 OutOfMemoryError 可能发生在任意一个示例对象创建时，但我们不可能在每个对象实例创建时都使用 <code>catch</code> 块去捕获异常。因此，我们也就不可能预料这些异常的发生，编译器在编译时也无法检测到这些异常。</p>
<h1 id="例子"><a href="#例子" class="headerlink" title="例子"></a>例子</h1><p>下面这个例子，由于没有对 Checked Exception 进行处理而导致编译失败。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">UnhandledException</span> </span>&#123;</div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</div><div class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> Exception();</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>为了使上面的代码可以正确编译，我们可以在 <code>try/catch</code> 块中捕获相应的异常或者是使用 <code>throws</code> 在 main 方法声明处抛出异常。</p>
<p>但是如果在 main 方法<strong>内部</strong>抛出一个 Unchecked Exception，依然可以正常编译，下面的例子就可以正确编译。正如前面所述，Unchecked Exception 在编译期间是无法提前检测，因此，不对其进行处理也不会影响到正常编译。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">UnhandledException</span> </span>&#123;</div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</div><div class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> NullPointerException();</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h1 id="Exception-类层次结构"><a href="#Exception-类层次结构" class="headerlink" title="Exception 类层次结构"></a>Exception 类层次结构</h1><p><code>java.lang.Throwable</code> 类是一个 Checked Exception，Java 的 API 定义了 Throwable 的两个子类——<code>java.lang.Exception</code> 和 <code>java.lang.Error</code>， Error 类是 Unchecked Exception 类，而 Exception 则是 Checked Exception类。</p>
<p>Exception 类有一个 Unchecked Exception 子类——<code>java.lang.RuntimeException</code>，NullPointerException 和 ClassCastException 都是 RuntimeException 的子类。RuntimeException 和 Error 的所有子类都是 Unchecked Exception，其他的  Exception 则都是 Checked Exception，如下图所示。</p>
<p><img src="/images/java/Checked-and-Unchecked-Exceptions-in-Java.png" alt="Exception Hierarchy"></p>
<p>如果创建一个自定义的异常类，它是 Checked Exception 还是 Unchecked Exception 则依赖其父类的类型。如果它继承于一个 Unchecked Exception 类，那么它就是一个 Unchecked Exception，反之依然。</p>
<p>在对 Checked Exception 进行 <code>catch</code> 操作时，也需要遵循一定的规则：在 catch 块中捕获的异常，必须在 try 块中有出现这种异常的可能性。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">try</span> &#123;</div><div class="line">    System.out.println(<span class="string">"..."</span>);</div><div class="line">&#125; <span class="keyword">catch</span>(java.io.IOException e) &#123;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>上面的例子就不能成功编译，因为在 try 块中永远都不会抛出 IOException，所以你也不能去捕获这种异常。但是如果你捕获的是一个 Unchecked Exception，那么就不会有这种问题。</p>
<p>Exception 和 Throwable 这两个类有些特殊，虽然它们都是 Checked Exception 类，但你依然可以捕获它们即使在 try 块中没有抛出该异常的可能性，因此，下面的代码的就可以正确编译。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">try</span> &#123;</div><div class="line">    System.out.println(<span class="string">"..."</span>);</div><div class="line">&#125; <span class="keyword">catch</span>(Exception ex) &#123;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>前面所说的规则对于 Exception 和 Throwable 这两个类并不是完全适用，这是因为对 Exception 和 Throwable 这两个类都有 Unchecked Exception 类型的子类，所以编译器允许你捕获它们（编译器认为你是在捕获一个 Unchecked Exception）。要清楚一点，<strong>编译器并不会检查 Unchecked Exception</strong>，RuntimeException 是 Exception 的子类，Error 是 Throwable的子类, 而 RuntimeException 和 Error 都是 Unchecked Exception 类。因此，上面的代码是可以正确编译的，编译允许这样做的原因就是因为这种方式是可以捕获到 Unchecked Exception 的。</p>
<h1 id="JVM-和程序异常"><a href="#JVM-和程序异常" class="headerlink" title="JVM 和程序异常"></a>JVM 和程序异常</h1><p>JVM Exception 是由 JVM 自己抛出的异常，比如：如果调用的方法使用一个 null 引用，然后 JVM 就会抛出 NullPointerException，或者如果在程序中出现10除以0的情况，JVM 会抛出一个 ArithmeticException。这些异常都是自动地由 JVM 抛出。</p>
<p>除了 JVM Exception 外，其他所有的异常都是由程序引起的异常。程序中，我们可以显式地使用 <code>throw</code> 语句抛出异常，这里以 NumberFormatException 为例。NumberFormatException 可能被方法 <code>Integer.parseInt</code> 或 <code>Float.parseFloat</code> 抛出，都是程序中可能出现的异常。在 <code>Integer</code> 类方法 <code>parseInt</code> 的实现中，可以找到如下的声明：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">if</span> (s == <span class="keyword">null</span>) &#123;</div><div class="line">      <span class="keyword">throw</span> <span class="keyword">new</span> NumberFormatException(<span class="string">"null"</span>);</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>而 JVM 不会抛出这种类型的异常，这些异常是使用 <code>throw</code> 语句显式地程序中抛出。当然也可以如下所示在程序中抛出 JVM Exception。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">if</span> (s == <span class="keyword">null</span>) &#123;</div><div class="line">      <span class="keyword">throw</span> <span class="keyword">new</span> NullPointerException(<span class="string">"I told you s shouldn't be null"</span>);</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>但是一般情况下，JVM Exception 是不会被开发者抛出的（JVM 自己抛出的），所有的 JVM Exception 都是 unchecked，而程序中的异常则可能是 checked 的或者 unchecked 的。</p>
<hr>
<p>参考：</p>
<ul>
<li><a href="http://docs.oracle.com/javase/specs/#44121" target="_blank" rel="external">Chapter11 Exception</a></li>
<li><a href="http://www.hacktrix.com/checked-and-unchecked-exceptions-in-java" target="_blank" rel="external">Checked and Unchecked Exceptions in Java</a></li>
</ul>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[Vim 快捷键总结]]></title>
      <url>http://matt33.com/2016/12/06/vim-basic/</url>
      <content type="html"><![CDATA[<p>Vim 到目前位置也用了将近两年，但是很多的快捷键每次要用到的时候还是会 Google 一下，只能记住很少的命令，查的过程其实还是会浪费很多时间，这里总结一下一些常用的 Vim 命令，以便以后查看。</p>
<h1 id="光标移动"><a href="#光标移动" class="headerlink" title="光标移动"></a>光标移动</h1><table>
<thead>
<tr>
<th>命令</th>
<th>作用（解释）</th>
</tr>
</thead>
<tbody>
<tr>
<td>h,j,k,l</td>
<td>h表示往左，j表示往下，k表示往上，l表示往右</td>
</tr>
<tr>
<td>Ctrl+f</td>
<td>上一页</td>
</tr>
<tr>
<td>Ctrl+b</td>
<td>下一页</td>
</tr>
<tr>
<td>w, e, W, E</td>
<td>跳到单词的后面，小写包括标点</td>
</tr>
<tr>
<td>b, B</td>
<td>以单词为单位往前跳动光标，小写包含标点</td>
</tr>
<tr>
<td>0</td>
<td>跳到本行的头部</td>
</tr>
<tr>
<td>O</td>
<td>开启新的一行</td>
</tr>
<tr>
<td>^</td>
<td>一行的开始</td>
</tr>
<tr>
<td>$</td>
<td>一行的结尾</td>
</tr>
<tr>
<td>gg</td>
<td>文档的第一行</td>
</tr>
<tr>
<td>[N]G</td>
<td>文档的第N行（G 是最后一行），如：27+shift+g</td>
</tr>
</tbody>
</table>
<h1 id="插入"><a href="#插入" class="headerlink" title="插入"></a>插入</h1><table>
<thead>
<tr>
<th>命令</th>
<th>作用（解释）</th>
</tr>
</thead>
<tbody>
<tr>
<td>i</td>
<td>插入到光标前面</td>
</tr>
<tr>
<td>I</td>
<td>插入到行的开始位置</td>
</tr>
<tr>
<td>a</td>
<td>插入到光标的后面</td>
</tr>
<tr>
<td>A</td>
<td>插入到行的最后位置</td>
</tr>
<tr>
<td>o</td>
<td>在当前光标的下方插入新一行</td>
</tr>
<tr>
<td>O(Shift+o)</td>
<td>在当前光标的上方插入新一行</td>
</tr>
<tr>
<td>Esc</td>
<td>关闭插入模式</td>
</tr>
</tbody>
</table>
<h1 id="编辑"><a href="#编辑" class="headerlink" title="编辑"></a>编辑</h1><table>
<thead>
<tr>
<th>命令</th>
<th>作用（解释）</th>
</tr>
</thead>
<tbody>
<tr>
<td>r</td>
<td>在插入模式替换光标所在的一个字符</td>
</tr>
<tr>
<td>J</td>
<td>合并下一行到上一行</td>
</tr>
<tr>
<td>s</td>
<td>删除光标所在的一个字符, 光标还在当行</td>
</tr>
<tr>
<td>S</td>
<td>删除光标所在的一行，光标还在当行，不同于dd</td>
</tr>
<tr>
<td>u</td>
<td>撤销上一步操作</td>
</tr>
<tr>
<td>ctrl+r</td>
<td>恢复上一步操作</td>
</tr>
<tr>
<td>.</td>
<td>重复最后一个命令</td>
</tr>
<tr>
<td>~</td>
<td>变换为大写</td>
</tr>
<tr>
<td>[N]&gt;&gt;</td>
<td>一行或N行往右移动一个tab</td>
</tr>
<tr>
<td>[N]&lt;&lt;</td>
<td>一行或N行往左移动一个tab</td>
</tr>
</tbody>
</table>
<h1 id="退出"><a href="#退出" class="headerlink" title="退出"></a>退出</h1><table>
<thead>
<tr>
<th>命令</th>
<th>作用（解释）</th>
</tr>
</thead>
<tbody>
<tr>
<td>:w</td>
<td>保存</td>
</tr>
<tr>
<td>:wq,:x</td>
<td>保存并关闭</td>
</tr>
<tr>
<td>:q</td>
<td>关闭（已保存）</td>
</tr>
<tr>
<td>:q!</td>
<td>强制关，不保存</td>
</tr>
</tbody>
</table>
<h1 id="查找和搜索"><a href="#查找和搜索" class="headerlink" title="查找和搜索"></a>查找和搜索</h1><table>
<thead>
<tr>
<th>命令</th>
<th>作用（解释）</th>
</tr>
</thead>
<tbody>
<tr>
<td>/pattern</td>
<td>搜索（非插入模式) ，支持正则</td>
</tr>
<tr>
<td>?pattern</td>
<td>往后搜索</td>
</tr>
<tr>
<td>n</td>
<td>光标到达搜索结果的前一个目标</td>
</tr>
<tr>
<td>N</td>
<td>光标到达搜索结果的后一个目标</td>
</tr>
<tr>
<td>r+p</td>
<td>将光标之后的字符替换为字母p</td>
</tr>
<tr>
<td>:s/word/replace</td>
<td>光标所在行的第一个 word 替换为replace。</td>
</tr>
<tr>
<td>:%s/word/replace/</td>
<td>全文查找 word 并替换为 replace</td>
</tr>
<tr>
<td>:1,50s/word/replace/</td>
<td>在第1行和第50行之间（含）进行搜索和替换</td>
</tr>
<tr>
<td>:45s/word/replace/</td>
<td>表示仅仅在第45行进行搜索和替换。而 1,$ 行号范围和 % 是等价的</td>
</tr>
<tr>
<td>%s/^/要插入的字符串</td>
<td>每行开头插入字符串</td>
</tr>
<tr>
<td>%s/$/要插入的字符串</td>
<td>每行结尾插入字符串</td>
</tr>
</tbody>
</table>
<h1 id="剪切、复制与粘贴"><a href="#剪切、复制与粘贴" class="headerlink" title="剪切、复制与粘贴"></a>剪切、复制与粘贴</h1><table>
<thead>
<tr>
<th>命令</th>
<th>作用（解释）</th>
</tr>
</thead>
<tbody>
<tr>
<td>dd</td>
<td>删除一行，同时被删除内容存于剪贴板上</td>
</tr>
<tr>
<td>de</td>
<td>删除光标后的单词内容，同时被删除内容存于剪贴板上</td>
</tr>
<tr>
<td>dw</td>
<td>删除光标后的单词内容以及之后的空格，同时被删除内容存于剪贴板上</td>
</tr>
<tr>
<td>dw</td>
<td>删除一个单词</td>
</tr>
<tr>
<td>[N]dd</td>
<td>删除以当前行开始的n行</td>
</tr>
<tr>
<td>x</td>
<td>删除后一个字符</td>
</tr>
<tr>
<td>X</td>
<td>删除前一个字符</td>
</tr>
<tr>
<td>D</td>
<td>删除一行最后一个字符</td>
</tr>
<tr>
<td>[N]yy</td>
<td>复制一行或者N行</td>
</tr>
<tr>
<td>yw</td>
<td>复制一个单词</td>
</tr>
<tr>
<td>p</td>
<td>粘贴</td>
</tr>
</tbody>
</table>
<h1 id="窗口操作"><a href="#窗口操作" class="headerlink" title="窗口操作"></a>窗口操作</h1><table>
<thead>
<tr>
<th>命令</th>
<th>作用（解释）</th>
</tr>
</thead>
<tbody>
<tr>
<td>:split</td>
<td>水平方向分割出一个窗口</td>
</tr>
<tr>
<td>:vsplit</td>
<td>垂直方向分割出一个窗口</td>
</tr>
<tr>
<td>:close</td>
<td>关闭窗口</td>
</tr>
<tr>
<td>Ctrl+W</td>
<td>切换窗口, h到左边窗口，j到下方窗口，k到上方窗口，l到右边窗口</td>
</tr>
</tbody>
</table>
<h1 id="文字版"><a href="#文字版" class="headerlink" title="文字版"></a>文字版</h1><p>这里有一个别人总结的文字版<a href="http://tnerual.eriogerg.free.fr/vimqrc.pdf" target="_blank" rel="external">图片链接</a>。</p>
<p><img src="/images/linux/vim-text.png" alt="vim-text"></p>
<hr>
<p>参考：</p>
<ul>
<li><a href="http://www.cnblogs.com/jiqingwu/archive/2012/06/14/vim_notes.html" target="_blank" rel="external">Vim 使用笔记</a></li>
<li><a href="http://cenalulu.github.io/linux/all-vim-cheatsheat/" target="_blank" rel="external">史上最全Vim快捷键键位图 – 入门到进阶</a></li>
<li><a href="http://coolshell.cn/articles/5426.html" target="_blank" rel="external">简明 Vim 练级攻略</a></li>
<li><a href="http://www.jianshu.com/p/c23136f68d2f" target="_blank" rel="external">Vim快捷键整理</a></li>
<li><a href="http://lxs647.iteye.com/blog/1245948" target="_blank" rel="external">vi/vim 删除以及其它命令</a></li>
<li><a href="http://pizn.github.io/2012/03/03/vim-commonly-used-command.html" target="_blank" rel="external">Vim 命令总结</a></li>
</ul>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[技巧，其实并没有什么技巧，只不过多了些毅力罢了]]></title>
      <url>http://matt33.com/2016/11/29/book/</url>
      <content type="html"><![CDATA[<p>本文是关于<a href="https://book.douban.com/subject/26874593/" target="_blank" rel="external">技巧</a>这本书的读书笔记。这本书是作者根据自己的生活学习经历悟出的一些方法论，满满的正能力，但有不同于一般的鸡汤文，书中提到的那些<strong>技巧</strong>，其实每个人都可以做到，但实际上却很少有人做到，正如作者所说<code>因为别人都睡着，你醒着那么你就是杰出的</code>。方法其实还是那种最简单的方法，简要来说就是<strong>行动+坚持</strong>，这也是最难的方法，因为坚持是最难的。用这种方法达到自己想要效果的人就认为这种方法非常有用，就如作者学习英语一样，而对于大多数那些坚持不下去的人来说，他们感觉这就是在扯犊子，正所谓方法因人而异。如果一味地去追求 XX 天精通 XX，其实最后的结果只会是<strong>从入门到放弃</strong>。</p>
<p>写着写着突然想讨论一下关于<strong>读书</strong>这个问题，在自己的印象中，自己第一次真正意义上、主动去读书应该是在中考结束的那个暑假，我现在已经忘了当时是什么原因让自己在那个暑假里读了好几本书，记得当时读了《三国演义》，在读完《三国演义》时觉得这本书应该是四大名著里写得最好的了，搞不懂为啥是《红楼梦》。而《红楼梦》这本书当时是强迫自己看下去的，这点还是有印象的，但当看到三十回之后，就被深深吸引住了，一发不可收拾，当时基本上晚上睡觉前都在读。当然，现在对于其中很多的细节都已经想不起来了，书中很多的故事也忘得差不多了，当年背了很久的《葬花词》也记不起几句了。我现在唯一有印象的，可能就是当时那段时光每天都在看书的场景（虽然是小说 :joy:），回忆起来还是很怀念的。再后来，上了高中之后，基本上就没有自己自主支配的时间，也就再也没有怎么看过书（非学科类的书）了。这就是在大学之前我与书的故事，很简单，但事实上，对于那个时候的我，并不知道怎么去读书，也不知道读这些书对自己有什么用，只是被书中的故事吸引而已，当然也就没有像红学研究者那样去思考这本书后面的故事。</p>
<p>到了大学之后，自己看的书也不是很多，其实是很少，这是我关于大学的遗憾之一，并没有在看书上花太多时间，大学四年自己看的书应该不会超过二十本。忘了是大二还是大三的时候，当时室友买了一本<a href="https://book.douban.com/subject/1013208/" target="_blank" rel="external">《如何阅读一本书》</a>，当时我在看到这本书的名字，对他不屑一顾地嘲笑了一番，当时感觉看书还需要学习、还需要让一本书来教你？看书不是每个人都会的吗？当时还没有开始接触豆瓣，并不知道在豆瓣上评分8.5的书意味着什么。</p>
<p>再后来，到研究生之后，记得在研一的时候，因为看了陈志武的《金融的逻辑》，对书中提出的观点感觉感觉很新颖，就把陈老师其他的几本书都看了一下，之后又看了一些小说以及吴军老师的书。前段时间在微博上看到有两本书突然很火，一本就是本文所说的《技巧》，另一本是《精进》。自己也就买了这两本书开始看，刚开始看的是《精进》，但是由于精进太偏方法论，理论更多些，感觉是需要在很安静的环境下看才比较好，所以到现在也就只看了一半，而《技巧》这本书都是以小故事的形式呈现，在宿舍或者公司读起来都很适合，所以虽然先看的《精进》，结果还是先把《技巧》看完了。《技巧》的作者 Tinyfool 是一个看过很多书的人，在书中也讲了很多看书的方法，而恰巧《精进》这本书的作者也讲了很多关于读书这一块的内容，告诉我们应该如何去读书、如何读懂一本书，在这一块，这两本书是解决了我的一些困惑。之前，我曾经想过，每看一本书，就做一个思维导图，到最后发现我做的思维导图压根没有别人做得那么好看，自己反而花了太多时间在思维导图的表达和形式上，开始觉得这并不是看书的一个好方式。</p>
<p>现在慢慢觉得关于读书这件事，第一步应该是选书，并不是评分高的书我们就应该去读，选书应该因人而异，读一本书我们是需要知道这本书解决我们哪方面的困惑，带着问题去读书，比如一些哲学类的东西在现实中可能无法找到解决方法，我们只有去借鉴前人的经验，但是也要明白一点：任何一个作者也是有其时代和历史局限性的，书中的答案并不定是正确的答案、并不一定可以解决自己的困惑。在选书上要选对自己有帮助的书，读书肯定是为了让自己收获一些东西，有些书可以解答自己的心理困惑，有些书可以讲述一些技术，也有一些书可以教给我们一些方法。但最关键的是自己要去思考和应用，对于提供书经验方法的书，我们可以学以致用；对于能解决一些困惑的书，我们要去思考这本书如何解决这个问题、从哪个角度出发以及中间论证的逻辑性等，这样才是真正的读书。现在回想起来，大学那时候的想法其实是很幼稚的，其实现在也不敢说自己就已经明白了读书的真谛，很多东西还是需要慢慢体会、慢慢积累、不断完善。</p>
<p>下面是《精进》作者采铜发的一段微博。</p>
<blockquote>
<p>很多人读完一本书的时候，喜欢画一个思维导图还原书中的主要观点。还有人会写一个书评，去分析和评价作者的观点对还是错。可是，作者的体系是他的体系，你无法直接受用；而观点的对错，对，是他对了，错，也是他错了，跟你什么关系呢？为什么一定要评个所以然出来呢？读书时，你更应着眼的是，这本书对你自己的意义。具体来讲，就是从“我”的需要出发，像一个探险家／考古学家／盗墓者／松鼠一样从各种书里探测、挖掘三种东西：原则、方法、素材。原则：书里有什么做事的原则是我可以借鉴的。方法：书里提供了什么做某事的方法。素材：书里提供了什么故事案例可以用来填充我的框架。这三样东西有些是在字面上，作者写明的，更多的，是深埋在文本之下，需要由你用你的洞察力去找出来。你读到的书是一整体，而你需要把它打散，找出你所需要的碎片，或原则，或方法，或素材，然后在你脑中拼接成型。——采铜微博。</p>
</blockquote>
<hr>
<p>下面的内容是自己在看书时，做的一些笔记，主要摘抄的书作者的观点以及个人的一些读后感。</p>
<h1 id="希望"><a href="#希望" class="headerlink" title="希望"></a>希望</h1><p>让人恐惧的不是死亡，而是希望。</p>
<ul>
<li>前妻的故事<ol>
<li>虽然学历低、家庭背景差，但是却有着一颗改变命令的心（这点很多人都有）；</li>
<li>她之所以从一个理发学徒变成一个年薪40w 的程序员（这个工资目前在程序员中并不算很高），但却很努力，而且不怕嘲笑，不懂的东西会虚心请教，最重要的是她能一直坚持下去了；</li>
<li>改变命运的心大部分人都有，但是一直把努力和不懂就问的品行坚持下去的人却很少。</li>
</ol>
</li>
<li>Sycx 的故事<br>-在互联网大潮之下潜行的成功创业者<ol>
<li>有一些互联网企业并不直接服务于用户，而是服务于产业，让互联网与一些具体的实体产业结合，这种商业模式可能不太好理解，但确实是互联网创业比较容易成功的地方。</li>
</ol>
</li>
<li>冯大辉的故事<ol>
<li>我不想做一辈子咸鱼，我构建我的个人品牌是希望积蓄力量，帮助我未来做事情；</li>
<li>无论加入的平台多么牛逼，只有自己踏踏实实做事情才能获得真正的成长。</li>
</ol>
</li>
<li>机会总是留给哪些不精明的人<ol>
<li>作者用一个身边人的例子（一位腾讯的早期员工）告诉读者一个道理：有时候人太过于精明，反而会忽略一些其他东西，从长远来看并不见得对自己有益（当然这个人的经历有很大运气的成分，但有一点可以确定的是，这个人并不甘于平庸，而且可以为了自己喜欢的东西放弃稳定的工作）。</li>
<li>作为一名普普通通的人，应该少一些浮想和幻想，多关注关注自己真正关注的东西，改变自己的心态。</li>
</ol>
</li>
<li>每个人都不完美<ol>
<li>对他人要宽容：要用发展的眼光看他人，人无完人；</li>
<li>对自己宽容：不要急躁，先承认现状，然后慢慢改进，才能平静地追求持续稳定的改进。</li>
</ol>
</li>
<li>我们能给世界留下什么<ol>
<li>作者简述乔布斯的故事，根据自己的经历做了一些思考，每个人在人生中都会经历各种起落，任何人都有烦恼，关键在于自己有没有 faith，有没有 calling，遇到困难时，有没有选择 fight。</li>
</ol>
</li>
<li>年轻是什么<ol>
<li>年轻是永远的积极向上、挑战自己、对世界继续充满好奇，希望每一天都过得有意义、充实，同时充满新鲜感，而老则相反，我们自己永远有选择的权利；</li>
<li>学习任何一个东西哪怕需要3-5年，但因为我们至少有几十年的时间可以去学习，所以去学习任何一个我们有兴趣的点都是完全可以的。</li>
</ol>
</li>
<li>身上的赘肉和自己的困境一样<ol>
<li>困境同样也不是一天之内降临的，也是慢慢积累的，找到解决办法，沿着一个既定的方向，慢慢来；</li>
<li>对于每个人来说，也许你们不胖，但是人生本是逆水行舟，当你停止前进的时候，你就老了，你就死了。</li>
</ol>
</li>
<li>疼痛有时候也是一种成长<ol>
<li>《异类》中谈论的一万个小时理论，并不是普普通通的一万个小时，而是不断冲破舒适区的一万个小时；</li>
<li>成长是由疼痛感的，就像爬楼梯，如果你可以轻轻松松爬5层，那么爬6层楼也许你会开始喘粗气，7层楼也许就会累了。那么5层就是你的舒适区，你每天都爬5层楼的话，就是坚持，而每天都试图<strong>多爬一层，这就是成长</strong>；</li>
<li>爱上成长，就是爱上那种疼痛的感觉，爱上那种感觉，就觉得自己一往无前、不可阻挡…..</li>
</ol>
</li>
<li>坚持本心，但不要拒绝任何改变<ol>
<li>我们在成长的过程中，都是一边追寻着改变而一边又畏惧着改变的；</li>
<li>这个时代变化太快，我觉得更幸福的模式不是找到一个好工作安稳一生，而是学会不停地改善自己，挑战自己的方法，然后用前进迎接这个世界一切的改变，永远站在风口浪尖上，直面前行。</li>
</ol>
</li>
<li>劫后<ol>
<li>有些东西无法预料，重要的是活好每一天。</li>
</ol>
</li>
<li>尽可能活成你想要的样子<ol>
<li>如果你发现自己不会背单词、不会游泳，那就是自己得到的欲望不够强烈；</li>
<li>The world is a playground. You know that when you are a kid but somewhere along the way, everyone forget it.</li>
</ol>
</li>
</ul>
<ol>
<li>这个世界对每个人都一样，但有些人活得很快乐，而有些人却很疼苦。</li>
</ol>
<h1 id="我们的伟业，是次序不断地改变自己"><a href="#我们的伟业，是次序不断地改变自己" class="headerlink" title="我们的伟业，是次序不断地改变自己"></a>我们的伟业，是次序不断地改变自己</h1><ul>
<li>作者学习英语的历程，很有借鉴意义<ol>
<li>作者并不是一个语言天赋很好的人，英文底子也不是很好，但最后却可以在两年内达到听说读写与外国人交流都没问题，这是很值得我们学习的，作者的技巧也就两点：循环渐进+坚持（过程很痛苦，但是回忆起来却很快乐），中间最喜欢作者说的一句话：<strong>当你感觉痛苦时，这时候就是成长</strong>；</li>
<li>虽然作者使用的是<strong>硬学</strong>，但要注意循环渐进，要由浅入深，而且不要急躁，作者看美剧突破无字幕用了半年，听 Postcast 突破也用了一个月；</li>
<li>在学习的时候，要给自己定下目标，然后去努力达到这个目标，这样才有方向性；</li>
<li>一切痛苦都不是痛苦，一切辛苦也都是快乐。</li>
</ol>
</li>
<li>掌握”学习曲线”，终身学习<ol>
<li>在任何环境中，我们都可以观察到，即使是一个不断变化的环境中，终身学习者也只占很少一部分，如果你是终身学习者，你可以秒杀一个领域里的你的同侪，终身学习是没有极限的；</li>
<li>学习曲线，当开始比较平，但是当你对一个东西了解以后，后面就是一个加速度过程，在开始的学习中，要设定合适的基准，不要控制太狠。</li>
</ol>
</li>
<li>锻炼你的大脑<ol>
<li>人有两个大脑，一个深思熟虑、功能非常强大；另一个比较像远古的动物，不太懂事，但它非常快，有点像反射，我们应该远离远古的大脑；</li>
<li>当你觉得难受时，你的大脑就在进化，无论在任何时候你觉得轻松，你都在使用你的习惯；</li>
</ol>
</li>
<li>二手知识的问题<ol>
<li>对于二手的知识的建议：一定要自己去看书，去看一手的东西，因为信息在传播的过程中会出现失真；</li>
<li>书读多了，读傻了，这是因为根本没有读懂书；</li>
<li>读一本书是要了解它的精髓，明白作者的心思，明白为什么这么写，学会一些思维方式、方法论或者一种思想感情，而不是会背几个段落。在读书的时候，如果你加入了自己的一些思考，用思维或者实践践行了书里面的理念，那么这本书，你就真的读懂了。</li>
</ol>
</li>
<li>学思关系<ol>
<li>学习的过程中，最重要的是要进行<strong>思考</strong>，比如，在看经济学的书的时候，学着利用学到的理论去分析现实生活中遇到的问题，去旅行去见世面，去了解不同的风土人情，跟书上的描写做对照，这也是思考；</li>
<li>看一本书，去吸收消化它，将它变成自己的理论，去验证它。</li>
</ol>
</li>
<li>阅读中的模型和数据<ol>
<li>一般来说，读书会给我们两种情形的收获：一是改造我们的思维方式，给我们展现一个新的思维模型，另一个是在现有的思维模型下，给我们数据，让我们对现有模型更精通、更确信。</li>
</ol>
</li>
<li>理性地设定目标<ol>
<li>再设定目标时，要设定一个长期目标，这个目标要有一定难度，让它指引着自己前进，当达到之后，再设定一个更大的目标；但近期目标一定要是可以达到的，每次完成一件事，成功了然后就会获得成就感，这会激励我们努力去做下一件事，这样才会进入一个<strong>正向循环</strong>之中；</li>
<li>人的学习曲线是一个二次函数，刚开始设置的短期目标比较低，然后慢慢提高，慢慢提高，追求在整个提升过程中，始终保持每一个短期目标都可达成，从而进入长效的正向循环之中，追求”乐学”和先慢后快的加速度运动过程之中。</li>
</ol>
</li>
<li>追求积累的力量<ol>
<li>我一直思考为什么需要终身学习、自主学习，以及我们应该怎么终身学习和自主学习。但是，扔需要强调的是，这里不会有任何捷径，我不知道任何捷径，我也不相信任何捷径；</li>
<li>年轻的时候，我以为成功是一个结果，是一个我们可以用毕生追求的目标。然而，这几年，我才慢慢明白，成功只是完善自己道路上的一个过程，没有尽头，爬上了一座高山，还有另外一座高山在等你。每一次你获得成功之前，都无不重要，获得之后，无非就是一个廉价的会议而已，你要追求的是自己的不断完善，这才是无尽的旅程。</li>
</ol>
</li>
<li>读书的时候我们在读什么<ol>
<li>人和动物的一个最大区别就是，人会思考，会将知识进行传承；</li>
<li>应试教育只是学习一种方式而已，并不是学校教育学习的东西就够我们使用了，毕业了之后就不需要学习了，实际上，在学校教育结束，我们还应该更加努力地去学习和看书，因为，在这个时代，大学毕业，竞争才刚刚开始；</li>
<li>对于任何一本好书，它的价值都远远大于它账面上的价格，在这样的情况下，迅速获取一本好书，获取其中的知识，从而提升自己的价值，这才是更合理的决策；</li>
<li>在书读太少的前提下谈优劣是一个笑话，在读得太少的前提下谈选择又是另外一个笑话，我们需要在阅读中不断的认识自己。</li>
</ol>
</li>
<li>时间和节奏的力量<ol>
<li>每个人的时间都很紧张，但是核心的问题不是时间本身，而是你能不能把握到节约时间的工作方法，简单来说，就是做事有规律有计划；</li>
<li>你可以试一下，学会每天都花固定的时间做一点点改进自己的事情，一年时间，你的改进就非常惊人，而你同时也会明白这样的人生才不会荒废。</li>
</ol>
</li>
<li>不要被你受的教育束缚<ol>
<li>不要相信某某东西很难，只有研究生博士才能学会这样的鬼话。实践才是学习的最好方法，我们要摆脱应试教育对自己的影响，从自身出发，从终身学习出发，仔细思考，自己的人该怎么渡过。</li>
</ol>
</li>
</ul>
<h1 id="前行的力量"><a href="#前行的力量" class="headerlink" title="前行的力量"></a>前行的力量</h1><p>我可以接收我自己沉沦一天、两天、三天，我决不能接收自己一直沉沦，我还没有死，所以，我不会停止前进，你们呢？</p>
<ul>
<li>比你聪明的人大多数也比你勤奋，你看不到的东西不代表没有发生过<ol>
<li>个人发展上，虽然个人的出身、家世背景对个人有一定影响，但是如果你足够努力，不断地去提高自己，在这个社会上，你完全可以过得很好。</li>
</ol>
</li>
<li>工作如何和个人成长相协调，写到刚毕业的大学生和毕业不足五年的朋友们<ol>
<li>工作无聊，不是个人无聊的原因，有些人是可以把无聊的工作，做的有声有色，甚至脱颖而出的；</li>
<li>对于校招的学生，当你在找到一个满意的工作之后，你必须要明白，你学历的价值在慢慢消退，慢慢地大家就会用一个对社会人的要求来要求你。</li>
</ol>
</li>
<li>工作方法篇：任务分解<ol>
<li>任务分解，尤其对于复杂问题，非常重要；</li>
<li>任务分解的过程，其实也就是对这个复杂问题思考的过程，只要经过深入的思考，你才能对这个任务进行分解。</li>
</ol>
</li>
<li>为什么有些人用一年时间获得了你十年的工作经验？<ol>
<li>优秀的人不但有极强的学习能力，而且他们的学习方法和对待事情的认真态度是不可阻挡的；</li>
<li>你是有十年工作经验？还是把一年工作经验用了十年？《异类》的理论是只有当你刻意去学习，不停地从自己舒适区跳出来，忍受一种痛苦和煎熬，改变自己之后，这样你付出的时间才算数；</li>
<li>如果当你在工作处理工作时，感觉很轻松，其实这时更应该有种危机感，因为这个时候其实你并没有在成长，只是在利用自己过去的经验而已。这个时候有两个办法可以去提高自己：一是找一份更有挑战性的工作，二是做一个副项目提高自己。</li>
</ol>
</li>
<li>改进自己从学会如何正确认识自己开始<ol>
<li>总之一句话，吾日三省吾身；</li>
<li>并不是所有人都可以做到，也并不是每个人都可以一直坚持下去，更应该通过外力的辅助让自己坚持一下。</li>
</ol>
</li>
<li>这是一个协作的世界<ol>
<li>在协作的世界里，很多你想做的事情更容易完成。</li>
</ol>
</li>
<li>字是一个一个写出的，路是一步一步走的<ol>
<li>走到天竺，分三步。第一步，开始走；第二步，走；第三步，到了；</li>
<li>实现自己计划的路上有多少辛苦。有多少磨难，你如果不上路，恐怕永远无法知道。</li>
</ol>
</li>
<li>急与快的区别<ol>
<li>欲速则不达，最好的方法，就不疾不徐，认真回到内心去思考，自己想要什么，自己可以做什么，什么是自己可以一步一个脚印解决问题的方法。</li>
</ol>
</li>
<li>什么是沟通？沟通的目的是什么？<ol>
<li>沟通是因为我们不同的人有不同的价值观，对事物有不同的看法，有不同的利益、不同的想法，但是我们要生活在一起，要在一起做事情，所以我们要相互交换意见；</li>
<li>沟通的目的并不是要战胜别人、说服别人，而是要说出自己的想法、自己的观点，就事论事，大家再一起寻找其中的平衡点。</li>
</ol>
</li>
<li>接触微博你节约了时间，然而并没有什么卵用<ol>
<li>耽误不耽误时间关键个人的计划，一定要保证事情优先，娱乐在后的原则，在保证自己计划、事情完成的情况，娱乐并不是坏的影响。</li>
</ol>
</li>
<li>理清头绪，找到节奏<ol>
<li>很多时候，当我们面对很多问题，很多压力，有时候甚至解决一个问题，又接着出现更多的问题，陷入一个恶性循环。当出现这种情况的时候，我们是需要思考、反思的，因为我们可能一直都没有直面真正的问题，做事情没有头绪，没有节奏，没有方法，当我们认为自己在辛苦工作，但却有从不思考为什么会一直做不好？</li>
<li>我们不应该在泥潭里坚持，而应该去积累，积累改进，积累思考跳出泥潭，去掌控自己的工作和生活。</li>
</ol>
</li>
<li>哪里真有什么信息过剩，你过省吸收的是垃圾，你需要的信息你根本没有获取够<ol>
<li>明白一点，信息从来没有过剩，我们只是沉迷在噪声里；</li>
<li>在合适的时间掌握稀缺的信息，是非常重要的，比如，当微信的小程序刚刚出来，在第一时间去学习、去应用，顺便写一些文章、做一些实用的东西；</li>
<li>深度挖掘信息的价值，如比看一本书，应该从中学会新的思维方法，将书中的方法论应用到自己的学习生活中，这样才是读懂了这本书；</li>
<li>什么信息才是自己需要的信息，要根据自己的需求出发，从自己<strong>成长的角度</strong>去考虑。</li>
</ol>
</li>
</ul>
<h1 id="我们都生活在生活之中"><a href="#我们都生活在生活之中" class="headerlink" title="我们都生活在生活之中"></a>我们都生活在生活之中</h1><ul>
<li>这世界上有无数的路，你走你的好了，别人怎么走跟你无关<ol>
<li>看完这篇文章，想起了一句话，在人生的过程中，每个人只能陪你走过一段距离。确实是这样，初中、高中时要好的朋友，等到工作了还有多少依然保持不错的联系？每个人的选择都不一样，最后的结果也只能是大家会渐行渐远；</li>
<li>这个世界上有无数条路，有很多路可以通向成功、幸福和快乐，关键是要找到自己的路，别人走什么路，其实跟我们关系并不大。</li>
</ol>
</li>
<li>自信心要如何培养？<ol>
<li>第一，要相信一点，其实大家都一样，我并不比大多数人聪明，同时也不比大多数人傻；第二，一次次的正反馈会增大我们的自信心；</li>
<li>要平时所有优秀的人，不要认为他们有什么天赋，学习优秀的人的做事方法，让自己也变得优秀，这才是进步。</li>
</ol>
</li>
<li>所有人都伤害不了你，伤害你的总是你自己<ol>
<li>这个世界有各种各样的人，有各种各样的评价标准，不管你多厉害，你也不可能取悦所有的人。关键在于找到自己真正在乎的人，找到自己真正在乎的标准。</li>
</ol>
</li>
<li>这世间并没有一种东西叫做拖延症<ol>
<li>拖延症这个概念确实是有害的，我们每个人的拖延都有无数的原因，如果我们不去分析拖延的具体原因，只是以拖延症来自我安慰，那么拖延症永远都无法得到解决。</li>
<li>拖延症，有一些情况是因为心理原因，有一些情况是因为自己把计划定得太死太严，不太合理。</li>
</ol>
</li>
<li>笨鸟先飞，但聪明的鸟飞得更快怎么办？<ol>
<li>笨鸟先飞，只是为了比自己昨天早到，要注意这里比较的对象是昨天的自己，而不是别人，如果选错了比较对象，只是自寻烦恼而已；</li>
<li>人活着，只是为了吃饱穿暖吗？如果只是这样，会不会太容易了？其实动物园里的猴子也可以吃饱穿暖，但是，这有什么意思？人活着总要有点念想，有点目标，要不人生岂不太无聊。</li>
</ol>
</li>
<li>梦想总是那么美好的，奈何你总是死在路口<ol>
<li>不去出发、不去努力，你怎么知道梦想不会实现。</li>
</ol>
</li>
<li>到底有没有寒门上升的阶梯？我们有没有希望？<ol>
<li>社会发展到现在，阶级在一定程度上确实在固化，但是这并不能否定个人努力的重要性，我们需要做的，其实就是一步一步地提升自己。</li>
</ol>
</li>
<li>成功并非只有一个标准<ol>
<li>对于人生来说，对于个人的成功来说，作者认为持续成长和内心平静。持续成长就是不断地去提升自己、越过一个又一个的高峰。内心平静就是 follow your heart，寻找内心的快乐。</li>
</ol>
</li>
<li>环境和你个人的关系，君子反求诸己<ol>
<li>环境对人的影响，其实也是非常重要的，这一点是毋庸置疑的，但是从另一角度想，如果一个和马云有同样生活经历的人，是不是也能有马云一样的成就呢？恐怕正常人都会觉得不太可能，同样也可以看出在人生中个人的影响力。对于我们大多数人来说，自己的之前的生活环境已经是无法改变了，现在能改变的只是自己了。如果只与自己做比较，影响自己发展的，只有自己个人；</li>
<li>对于我们很多人来说，由于我们的起点都不是很高，我们稍微努力一些成果就会很惊人，就跟在学校里提高学习成绩一样，差生稍微努力一下，效果会非常惊人的；</li>
<li>在现在这个社会里，能真正沉下心去做事的人并不多，只要稍微努力努力，我们就可以脱颖而出。换句话说，大多数在睡觉，你醒着你就是杰出的。</li>
</ol>
</li>
<li>《细节决定成败》的贡献和流毒<ol>
<li>与其一味地追求细节，更重要的是应该分清主次。</li>
</ol>
</li>
<li>改变不会在一夜降临，有耐心的人才能看到花开<ol>
<li>这世界上所有的变化和成长都是非常缓慢的，也只有这些缓慢的变化和成长才能慢慢积累，慢慢积累成翻天覆地的变化。</li>
</ol>
</li>
<li>外部条件解决后，你会发现最大的阻碍永远是你的内心<ol>
<li>如果外部条件解决之后，其实到最后你发现你没成功的原因并不是外部的条件，而是自己的内心。举个例子，在以前，如果你考不上耶鲁那你就上不了耶鲁的课，但是后来 MOOC 出现之后，你可以免费地去学很多名校的课，但是你最后发现你并没有坚持下去，这是因为你并没有那么想去上。记得在大二的时候，我第一次听说公开课这个概念，第一个看的是那个哲学课《死亡》，很明显我并没有坚持下去，直到现在，已经到研三了，也没有一门公开课坚持看完过。But now，我发现再不能这样下去了，那些对自己很有帮助的课，需要给自己定了一个计划，督促自己坚持下去。</li>
</ol>
</li>
<li>寻找和突破心障<ol>
<li>当你想做一件事，当时并没有去做，而且阻挡你的并不是金钱这些外部条件，那这是什么？可以称之为心障；</li>
<li>很多东西都可以算作是一种心障，比如学习成本的问题、不追求美好的生活。关于学习成本的问题，假如说学习一门语言或技术需要花费2年，但是我们可以用五年，甚至十年，那这合算吗？聪明人都知道，这怎么算都是合算的，更何况如果一门外语，尤其是英语，是可以用一辈子的，那这就更划算了，或者更详细算一下，英语熟练之后给你带来的好处，这就可以成为你学习的动力。</li>
</ol>
</li>
</ul>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[观念在变化、在成长]]></title>
      <url>http://matt33.com/2016/11/25/book/</url>
      <content type="html"><![CDATA[<p>之前公司推送了一位大神的推荐书单，当中推荐了这本<a href="https://book.douban.com/subject/20463108/" target="_blank" rel="external">《观念的水位》</a>，那是第一次看到这本书，记得当时看到这本书的名字，瞬间就吸引了我的兴趣，然后就在豆瓣上搜索了一下，看到评价还不错，就加到了自己的书单里。再后来，回到学校就在网上找到这本书的电子版，下载到手机里就开始看了起来，中间大概花了半个月的时间把这本书看完，那段时间基本上每天在公司上下班的班车和地铁上都在看这本书。在看的过程中，根据每篇文章看后的感想，做了一部分的笔记，在文章的后面会列出来。</p>
<p>在刚开始读的时候，就感觉这本书写得很深刻，披露得也很现实，甚至有点怀疑这本书是不是在大陆出版的。从书的整体上来看，感觉这本书，可以分为三大部分，第一部分是作者根据身边的实事写的一些思考和感悟，主要是以作者在英国的生活经历为主；第二部分，确切的是说应该是作者对于一些名著（或小说）的读后感；第三部分，是作者对电影的一些感悟。因为作者主要是研究历史、政治经济学（确切应该是政治学）这一块，当然其中也有关于人性和心理学的内容，作者根据身边的实事、电影以及小说，对宪政、人性进入了很多深入的分析，其中很多的地方都是我从来没想过的点（书读得少，没办法）。最令自己的敬佩的是，作者每读一本书，都会写一篇文章，看一些好电影也是这样，作者都会去深入地思考，这些都是自己应该去学习的地方。</p>
<p>当然，这本书在豆瓣能达到8分以上，证明书的内容也不会差到哪去。在读这本书的过程中，有种当时读《野火集》的感觉，感觉我们国家相比于欧美发达国家而言，政治文明、法制文明、宪政制度真的相差很远，而且我们国家在发展的过程中，还出现了各种各样的问题，这些问题都影响着我们每一个人。我们都知道法制的重要性，可是一个没有独立司法环境的社会，如何保障法制社会的建立、如何保障公民权利，一个人既当球员又当裁判，该如何保障另一球队的公平性？</p>
<p>但是，这本书给我带来的希望的地方是，随着我们国家经济的发展，当人们吃饱肚子、衣食住行得到保证之后，人们就会有一些其他更高的追求（精神上），随着这部分人的人数在增加，也推动了全民观念的水位在上升。当然由于最近一年房价的疯涨，一线城市及强二线城市基本上都已经翻倍了，这种情况的发生，突然将中国中产阶级迅速打压下去，也导致了中国中产阶级都成了名副其实的负翁。</p>
<p>就在写的时候，突然想到一点，想到了宋朝，记得历史课上学过，在宋朝，由于经济非常发达（宋朝是一个并不是由于农民起义而灭掉的王朝），在当时诞生了资产阶级的萌芽，假设，如果历史可以假设，那么如果当时蒙古没有崛起，宋朝的经济肯定还会接着发展，宋朝当时的科技好像也在世界处于领先地位，如果能这样一直发展下去，中国会不会诞生现代文明？现在我们已经无法推断，我们知道的结果是，由于蒙古的崛起，宋朝灭亡了，中国资本主义的萌芽被消灭掉了，蒙古打到地中海，其实也是间接地促使欧洲的文艺复兴（这一点暂不讨论）。中国最初的资本主义萌芽被消灭掉之后，后来再也没有恢复起来，之后明朝也没有达到宋朝当时的经济水平，中国也就慢慢沦落为二流国家。在现代，西方人经常说一句话，一个国家的中产阶级是这个国家最宝贵的财富。反看我们国家，在房价暴涨之前，随着经济的发展，中国的中产阶级人数是在慢慢扩大的，但是后来由于房价暴涨，带动了生活成本的迅速上升，我们国家的中产阶级被房价压得喘不过气，不知道是不是与一千年前的宋朝有些相似之处。本来看到的希望，突然又被现实击破。</p>
<p>当然，在历史的发展过程中，即使对于那些老牌发达国家来说，他们也是慢慢地一步一步走到现在的，而且也不能说他们现在的制度就是最好制度。尤其是近段欧洲的难民问题、美国当选的新总统特朗普感觉像是由于美国民粹主义被煽动而当选的。世界变化实在是太快，我们也不知道未来会怎样发展，我们国家是不是能走出中等收入国家陷进，尤其在出现：由于房价上涨导致制造业成本上涨，很多制造业开始外流，向东南亚发展这情况下，我们知道，制造业和服务业目前是最能解决就业的，我们国家如果在服务业还没有发展到一定程度时制造业就开始下滑，那么结果可想而知，有多少人会失业？这些问题应该怎么去解决，我现在其实是有一些悲观的，我并不知道出路在哪，感觉祖国任重道远。</p>
<hr>
<p>对书中一些小节的读后感</p>
<blockquote>
<p>认定自由、民主“只适合西方”的看法是一种变相的种族主义，而种族主义是一种过于懒惰的世界观。——自序：春天里</p>
</blockquote>
<p>近百年来，中华民族都在为了自由、民主而努力，虽然现在我们国家的经济、政治、法制相比与以前已经进步很多了，可依然跟马克思描述的社会主义有很大距离，甚至有些地方离西方发达国家也有很多的差距，而我们却总是各种借口去推卸责任。</p>
<blockquote>
<p>追求快乐的本性使每个人都成为潜在的革命者，而一个远离快乐的制度也许可以依靠信息控制维持很久，但在信息控制越来越不可能的世界，一条缝会渐渐变成一扇门。</p>
</blockquote>
<p>人性到底是善还是恶，不同的人、不同的宗教会有不同的理解，但是人追求幸福、快乐的本性是一样的，由此可见，有些人去追求财富、一些人选择移民，这都是在追求自己认为的那种快乐生活，有些人会感觉金钱会让自己有安全感、可以为自己的快乐提供基础，有些人认为移民到发达国家，享受更好的医疗制度、教育制度，会让自己更快乐。</p>
<blockquote>
<p>经济基础、社会结构和国际环境的变化已经为新的制度变迁创造基础，这种看法用学术语言来说叫“结构主义”</p>
</blockquote>
<p>说到经济，不得不让人想到邓小平，这里其他的不谈，小平提出的发展才是硬道理，对大陆确实带来了很大的贡献。经济的发展，首先会让人民生活条件提高，当大部分的人经济水平上去之后，人们才会有时间、有精力去思考、追逐自己的内心所求。一旦当有一些东西阻挡了大部分追求自己想要东西的时候，这些人都会成为一个潜在的革命者。</p>
<blockquote>
<p>我当然不相信制度的改革可以一夜之间改变文化，但是制度的变革至少可以打开一个公共生活的空间，而公民素养的培养首先需要一个公共空间，就象学会跑步需要首先解开脚镣。——素什么质</p>
</blockquote>
<p>罗马不是一天建成的，同样，欧美现在的政治、法制、精神等文明也不是突然就冒出来的，美国也曾经有过一段非常腐败的时期，美国也是这样一步步过来的。同样，中国要想崛起也需要时间，但中国崛起的前提是制度不能成为发展的绊脚石，改革需要深入、需要彻底、需要适应我们国家的发展。</p>
<blockquote>
<p>鉴定民意的真伪，标准不在于民众选择的那一刻是不是真诚，而在于他们在形成意见时讨论是否自由、观念可否多元、信息是否充分。——民意与伪民意</p>
</blockquote>
<p>如果人民一直被洗脑，没有独立思考精神，民主很多时候会成为被民粹主义利用的工具，这也是为什么一直说中产阶级是一个国家宝贵的财富的原因，当然这里中产阶级指的是有独立思考意识的中产阶级。</p>
<blockquote>
<p>制度也许可以一夜之间改写，但是企业家精神、商业头脑、市场意识，只有通过漫长的学习才能形成。——给理想一点时间</p>
</blockquote>
<p>再次证明了时间、过程的重要性，对于个人也是如此，没有人可以在一夜之间学会这学会那，只有持续不断的学习、不断地去积累才会达到自己想要的效果。</p>
<blockquote>
<p>一个人“看到”一个事物并不等于他能“看见”它，人们往往需要穿过重重意识形态才能看见自己所看到的东西。——不知道与宁可不知道</p>
</blockquote>
<p>看到不等于看见，对于大多数人，都会不自觉地选择性地过滤掉一些信息，因为不知道这些信息反而让他感觉到一切都很美好，而知道这些信息，会让他看到自己的无知。</p>
<blockquote>
<p>斯坦福大学心理学家津巴多曾经做过一个著名的“斯坦福监狱实验”。24名学生随机抽签，一半当“狱卒”，一半当“犯人”。结果在一周的角色扮演过程中，演狱卒的学生越来越残暴，演犯人的则越来越卑怯。短短一星期，哪怕是一个实验的环境，角色感就可以改造人性，这事想想真叫人不寒而栗：现实中，有多少人经年累月地藏身于各种制度化的角色中，而其人性又在角色不断内化的过程中被劫持到了哪一个星球？——恶之平庸</p>
</blockquote>
<p>环境对人的影响非常大，这个让我深有感触，就像这次香格里拉之行，以导游为例，他是一个藏族人，同时也是藏传佛教的信徒，按理说，应该是很虔诚的，待人应该以善为本，可是他入了导游这一行，这个行业有太多的潜规则，强制游客购物，甚至不惜用道德绑架、人身威胁来强迫购物，很明显这些东西他都会拿提成的，难道他不知道这是不对的吗？但是在那些藏民眼中，他却是带动当地经济发展的好人，这个导游还资助当地藏区的贫困学生，难道他是坏人吗？明显也不是，他甚至在家人、藏民眼中还是善良的佛教徒。那这是什么原因？我现在能想到的只能是环境因素，或许他会用这个行业就是这样、大家都这样来安慰自己，来减少或消除内心的不安。</p>
<blockquote>
<p>愤怒之所以令人上瘾，大约是因为愤怒是通向正义感的捷径。——迷人的愤怒</p>
</blockquote>
<p>愤怒并没有错，但是要理性愤怒，要独立思考，不能人云亦云。</p>
<blockquote>
<p>中国近当代知识分子里我最爱的还是胡适和顾准，因为在一个几千年陶醉于“意境美”的文化里，他俩一个讲实证精神，一个讲经验主义。——告别印象主义</p>
</blockquote>
<p>实证精神确实是中国人欠缺的一种精神，实事求是的口号我们也喊了几十年了，但是依然没有成为我们的民族精神，反而假大空依然横行，就比如学术这一领域，无论是教授还是学生都以这个东西能不能写成论文发表为目的，而不是这个东西能不能用或者能不能改进现有的一些技术环境。</p>
<blockquote>
<p>试图绕过程序正义，依靠“宣传”“维稳”来寻求民众合作，在一个民众理性能力和权利意识逐渐强大的时代，只会越来越捉襟见肘，甚至会陷入政府“怎么做都是错”的可悲境地。——怎样推销糖果</p>
</blockquote>
<p>依靠强权让别人去接受一些想法或事实的做法已经满足不了现在的实际情况，应该邀请对方一起商讨、共同做一个决定，包括对孩子的教育也是这样。</p>
<blockquote>
<p>在非黑即白之外还有很多思想的灰色地带，而这个地带往往最考验思想的精细，通过将他人的观点极端 化取消其意义，恰恰是公共讨论中的避重就轻。——标签战</p>
</blockquote>
<p>在与人争论中，应该用事实和逻辑分析说话，而不是简单的片面的理解，就给人贴一个标签。很多东西并不能简单地说对与错。</p>
<blockquote>
<p>除非你意识到中国不仅仅存在于都市的“五环”。在海水的深处，阳光未曾照耀之处，还有韩颖雷金模们，并且每一个已知的韩颖雷金模们，很可能还对应无数我们尚未知晓也无从知晓的韩颖雷金模们。在苍苍莽莽的雪地里，要保持对那个被遮蔽世界的知觉，你得不断提醒自己不要睡着不要睡着不要睡着。——没来的请举手</p>
</blockquote>
<p>作为国人，对这个问题比较痛心，这个社会中有太多无助的人，他们是为了大多数人利益而牺牲的少数人。尤其是近几年，房价的暴涨，导致大陆的贫富差距迅速扩大，贫富差距之大，令人咋舌，这实际上是对中下层人民财富的一次间接剥削，是一次很不公平的财富转移。</p>
<blockquote>
<p>社会跟政府讲道理，政府就跟社会耍流氓；社会跟政府耍流氓，政府就跟社会讲道理。——法治何以可能</p>
</blockquote>
<p>民主对于法制的维护着实重要，民主实际上就是对权利者权利的制衡，它可以在普通公民利益与权利者利息之间达到一个平衡。</p>
<blockquote>
<p>当然博爱的起点是自爱。自爱加上同理心，才成为博爱。——他也可以是我</p>
</blockquote>
<p>权利的重要与权力的可怕，大家都深有体会，把权力关进笼子，赋予公民应有的权利，这样这个社会才能健康的发展，这也是近百年来，国人一直的追求，虽然我们离这个理想还有很远的距离，但不能阻挡我们追求的脚步。</p>
<blockquote>
<p>西谚云：不要让“最好”成为“更好”的敌人。意思是80分不完美，60分也不完美，但不要因为80分不是100分而否认从60分进步到80分的意义。不过中谚却说：五十步怎么可以笑百步?要我说，五十步怎么不可以笑百步，九十九步都可以笑百步。人类文明的进步靠的就是点点滴滴的努力，大的进步值得大的肯定，小进步值得小肯定。——合同异</p>
</blockquote>
<p>一味的合同异就否认了变量之间的差异，也就否认了这些点滴的进步，而不急会不无以至千里，人类的进步就是靠着这些点滴实现的。</p>
<blockquote>
<p>纯洁固然美好，但是它对世界丰富性和复杂性的敌视，它天然的非黑即白世界观，本身就为专制提供了最好的精神土壤。——权力的道德捆绑</p>
</blockquote>
<p>这就好比人不能说是绝对的好与坏，而中国从古至今都是依靠人治，法制观念淡薄，依靠人治的最明显的就是民间对包青天和海瑞的推崇，人治对于国家来说是危险的，法制才是把权力关进笼子，这样公民的权利才有保障。</p>
<blockquote>
<p>我心中理想的社会变革应是一个“水涨船高”的过程：政治制度的变革源于公众政治观念的变化，而政治观念的变化又植根于人们生活观念的变化。——观念的水位</p>
</blockquote>
<p>社会观念确实在变化，尤其是当越来越多的中产阶级走出国门，看到欧美国家人民的生活时，公民的权利意识在觉醒，但是有一点要注意的是中国中产阶级毕竟是少数，中国还有基数很大的农民阶级，他们的经济条件和公民意识还需要慢慢提高，所以感觉这也是中国深度改革还需要一点火候的原因。</p>
<blockquote>
<p>英国的报销门事件得以解决，政府信息公开是一个关键因素，但是信息公开本身，又依赖媒体自由、政党角逐、权力制衡等机制。仅仅依靠领导人的“决心”，信息公开很可能流于形式，甚至成为政治作秀。一般来说，谁也不会搬起石头砸自己的脚，要想根治浪费公款，只有把“搬起石头”的权力交给别人。——倒霉的英国议员</p>
</blockquote>
<p>一个人既当裁判又当球员显然是不合理，这样只会导致很多政策流于形式。</p>
<blockquote>
<p>其实诚恳地反思过去，核心意义并不是“秋后算账”，而恰恰是在直面历史的基础上实现真正的和解与稳定。——过去的怎样让它过去</p>
</blockquote>
<p>人需要反思，需要思考，国家同样也一样，如果不反思，悲剧只会不断重演。</p>
<blockquote>
<p>政府作为公共服务机构，其不作为和胡作非为一样可怕。——沉默罪</p>
</blockquote>
<p>政府作为唯一的合法暴力机构，如果默认他人胡作非为跟自己胡作非为没什么区别。</p>
<blockquote>
<p>对具体清晰的逃避也就是对批评的封闭。——大家一起来算账</p>
</blockquote>
<p>讲述问题或辩论时应该实事求是，而不是一味地扣高帽子，说一些比较虚的事情，更多地应该讲述具体的实事，做人做事都该如此。</p>
<blockquote>
<p>俾斯麦说“政治是一种可能性的艺术”，那么我们能敲开人性中哪种可能性，说到底还是取决于我们在缔造什么样的政治。——敲开最好的可能</p>
</blockquote>
<p>人性都是一样，如果哪个国家人民的素质有高低，那也只是后天环境影响的。一个好的政治制度应该激发公民心中的善、保护公民心中的善。</p>
<blockquote>
<p>政府本质上不过是个公共服务机构，而不是什么高高在上的官府。——让政治变得家常</p>
</blockquote>
<p>一个国家的政治制度和政府性质，对于一个民族的影响很大，好的制度会估计民族向善的方向发展，不好的反之。</p>
<blockquote>
<p>在一定意义上，与其说浩浩荡荡的游行队伍体现了人们对经济危机的一团怒火，不如说体现了欧美高度发达公民社 会的组织资源。——绞死银行家</p>
</blockquote>
<p>公民有言论自由、有充分表达自己意愿的渠道，这种制度才会让一个国家更稳定、人民生活更幸福。</p>
<blockquote>
<p>在言论自由和政治平等之间，如何实现平衡？——民主的裤衩</p>
</blockquote>
<p>自由与平等是人类一直在追逐的东西，但两者在某些情况下也会有冲突，如何进行平衡，这种事情一般由最高法院来裁决，美国的司法充分保证了司法的裁决不受政治的影响，</p>
<blockquote>
<p>多元的观点带来充分的政策辩论，而充分的辩论不但给民众一个从不同角度理解这个法案的机会，也督促辩论两党给其主张提供坚实的论据基础。——吵吵更健康</p>
</blockquote>
<p>美帝的很多政策就是多方互相妥协的结果，美帝充斥各种利益集团，国家要想稳定要想发展，必须平衡各方利益，谈判妥协几乎可以说是美帝的基因所在。相反，我们民族，从古至今都是忍受，再忍受，直至没有活路，然后革命，接着再进入循环。我们民族一直都在想突破这个兴亡迭代的循环，能不能突破还要看我们这几代人的努力。</p>
<blockquote>
<p>分析各国改革速度和改革成效关系的话，反而发现改得快的未必发展慢，改得慢的发展未必快。结论很可能是，相比改革公正性、法治化、政策合理性，变革速度可能本来就不是个核心问题。——苏东巨变：20年之后</p>
</blockquote>
<p>这种感觉可以归结于具体的国情，估计作者又该说了应该拿出具体事实，而不是简单的国情了事，什么是国情，国情这种东西很模糊，天天说国情的人都不一定能搞明白啥是国情。我个人的理解是：政治、法制的改革如果能走在经济发展的前面，那么就能快速促进经济的发展，一旦落后于经济，就会抑制经济的发展。</p>
<blockquote>
<p>人类花了28年等待有形柏林墙的倒塌，无形柏林墙的消除，也许要更漫长地等待。——俄罗斯的徘徊</p>
</blockquote>
<p>自由、民主是需要时间、需要代价的。</p>
<blockquote>
<p>民主制度并不是选民投下一张选票然后翘起二郎腿等待政治家给我们端茶倒水的“懒人”体制，而需要民众对政治经年累月地“巡逻”促成点滴改良及至水滴石穿。——当“革命”成为家常便饭</p>
</blockquote>
<p>罗马不是一日建成的，一个自由、民主的社会也是如此。并不是说有了选举制度，就可以实现民主，俄罗斯可是不单单有选举制度，还是多党制，但我们并不认为俄罗斯是民主国家。自由、民主需要时间、需要代价，观念的上升才能更好地促使社会的变更。</p>
<blockquote>
<p>制度大于出身，这才是民主的要义。——“亚洲特色”的民主</p>
</blockquote>
<p>记得大陆官方当时发表声明嘲笑日本是政治世袭，国内当时可真是一片骂声，原因很清晰，日本还是世袭？那中国、朝鲜是什么？简直呵呵了。看一个社会、一个国家、一个民族，不去学习别人好的部分，老是揪住人家一些小污点不放，感觉很没有大国的胸襟。</p>
<blockquote>
<p>我认为，在经济政策上要允许试错，但藐视程序正义则是破坏现代政治的根基。——当民主缺失中产阶级</p>
</blockquote>
<p>最典型的例子就是美帝当面禁酒令，虽然执行禁酒令的时间只有13年，但确使美国经济倒退了不止20年，但是，这也丝毫没有成为阻挡美国后来崛起的绊脚石。美国现在的文明就是这样一点一点试错中成长的，什么东西都不是一蹴而就的。</p>
<blockquote>
<p>百万人涌现街头，其实并不突然。追求更多自由、更真实民主的暗流一直在伊朗“螺旋型”前进。——历史螺旋式终结</p>
</blockquote>
<p>自由民主可以说是这个世界的普世价值，每个国家和民族都在不余遗力地追求，正如前面所言，这并不是一触而就的，每个国家在走向这的过程都是曲折的，就像我们中华民族，虽然已经努力了一百多年，但与我们的理想还相差甚远。</p>
<blockquote>
<p>能够有制度性制衡来推动不同机构和利益集团之间的协商互动。一个只注重垂直呼应民意而忽视水平制衡的政府，也许合法性很高，但是合理性很低。——选举式独裁</p>
</blockquote>
<p>从美国的经验来看，权力之间的制衡以及利益集团间的相互妥协（在美国，各个协会组织或公会组织都是代表其协会成员的利息的利息集团）才是西方民主的真谛</p>
<blockquote>
<p>面对全球化，值得思考的不是它是否带来挑战，而是挑战与机遇是否对称。——我们在输出什么</p>
</blockquote>
<p>经济全球化确实带了很多问题，但是肯定是机遇与挑战并存的，问题当然很复杂，也不能一概而论。</p>
<blockquote>
<p>虽然美国收入差距在拉大，但社会仍具有相当的流动性。——有多少资本主义可以重来</p>
</blockquote>
<p>这也是美国价值观风靡全球的原因之一，一个相信个人奋斗的国家，是更容易吸引全球的人才，尤其是那些出身并不是很优秀的家庭。</p>
<blockquote>
<p>根据奥尔森集体行动的逻辑，当一个政策的受益或者受损对象比较集中，他们组织起来行动的可能性也更大。——从更人道的到更霸道的</p>
</blockquote>
<p>他们之间有明确的公共利息，不但利息明确，而且很少有分歧。</p>
<blockquote>
<p>量入为出本是最朴素的道理，但是将福利视为集体权利而不是个体责任的文化已使很多人失去了这种朴实。对于这些人来说，胖子的问题不是暴饮暴食，而是医生的减肥食谱。</p>
</blockquote>
<p>高额的福利必须会有高额的税收，福利不是从天上掉下来的，可惜的是我们国家欧洲的税收非洲的福利。</p>
<blockquote>
<p>一想到在那样无望的时代，曾国藩还奋发图强，对他的钦佩不禁如滔滔江水。转而又想到，即使是以他的奋发图强，也只能哀叹“天命”之不可违，却从未抬头观望天窗外的璀璨星空，又觉得个人面对历史，还真是胳膊拧不过大腿。——成圣又如何</p>
</blockquote>
<p>方向是错的，再努力又有何用？可是应该如何分辨自己的方向是否正确呢？曾国藩当时是没有这个条件去感受西方政治制度，自然也无法看到天窗外的星空。西方政治制度最大的特点就是不相信人性，他们用制度、用规则去管理，而不是人治、德治。</p>
<blockquote>
<p>这也是戈尔巴乔夫始料不及之处。他以为他可以放开管制同时强化专政，但多元社会和权力垄断不相容。他必须做出选择，是继续支撑这个空心帝国，还是捅破那层纸。最后他说，如果不是我们，是谁？如果不在此刻，又待何时？——那个搬起石头砸自己脚的人</p>
</blockquote>
<p>戈尔巴乔夫在来临的这个时刻做出了他应该做的决定，他选择戳破这个纸老虎，选择放弃专制，但历史并没有按照他预期的想象发展，现在俄罗斯也并不是自由民主的代表，改革的道路一片艰辛。</p>
<blockquote>
<p>摘下有色眼镜观察他国并不容易，因为我们脑子里充满了各种“想当然”。也许问题的关键并不在于我们怎么看待他国，而是怎么看待自己。——超越那些“想当然”</p>
</blockquote>
<p>在改革时，当然不能完全照抄某种经济改革，但也不能因为某些经济政策导致了一些不好后果，就把把它全盘否定。突然感觉我对这本书的一些见解好像都是在某些课上学到了，看来有些课有些书至少理论上还是很不错的，只是执行的过程中出了一些偏差。</p>
<blockquote>
<p>正是这种矛盾使其从一开始就不可能是一个逻辑上自洽的帝国：你不可能一边宣扬天赋人权，一边心安理得地铐住黑人送到加勒比海的甘蔗地。——当自由遭遇一丝微风</p>
<p>获得民众的信任并非一劳永逸之事。如果最高法院在其判决中背叛了美国宪法的最基本价值观，没有对这些价值观进行与时俱进的适应性诠释，或者在宪法所追求的不同价值观之间没有实现微妙的平衡，民众的信任和服从很可能随风而去。这大约是美国法官们工作的艰难之处：他们永远在如履薄冰，永远在风口浪尖。——法治的“秘密”</p>
</blockquote>
<p>美国法院的主要是目的就是维护宪法赋予公民的个人权利神圣不可侵犯，在历次判决中，都是以这个作为原则，这也是高等法院受公民信任的原因。</p>
<blockquote>
<p>从这个意义上来说，王彩玲这个角色比Howard更有意义：如果对个体意志的赞叹并不依赖于它是否引向“成功”，那么兰德分配给Howard的最后成功命运就是个多余的情节。不但多余，甚至是误导性的，它给人造成“功夫不负有心人”的错觉：不，功夫常常是会负有心人的；功夫负不负有心人本该没有那么重要的；“有心”的价值是不能用“负与不负”来衡量的。——你比你想象得更自由</p>
</blockquote>
<p>如果坚持初心，坚持个人的信念，成不成功又有什么不同，都只是外界的看法而已。</p>
<blockquote>
<p>犹豫不是为了逃避选择，但是它令选择之后的制度设计更加审慎和包容。——诸善之间</p>
</blockquote>
<p>当面临选择时，每一种选择都有其合理性，其实都是一种对哲学的思考，人类更多的时候是在多种选择中达成一种妥协。</p>
<blockquote>
<p>今天，权力的巩固仍然借助于对历史的改写与屏蔽。历史一层层被擦掉，或者被涂抹，失忆的人群也因此成为价值的木偶。——像一滴水一样</p>
</blockquote>
<p>正如驴得水中所说，过去的如果就让它过去，未来只会更糟。东亚民族自古以来都有改写历史的习惯，直到今天也是这样，花了那么多代价、交了那么多学费，就这样为了“政治正确”而被改写，我们可能又不得不重新去探索，这只会让未来变得更糟糕。</p>
<blockquote>
<p>所以我现在读书并不指望醍醐灌顶，更不觉得书架上会有什么“神明”，仅仅希望每一本书能推进一小点知识或者带来一个小启发。正如政治上不存在什么“救世主”，智识上也不存在什么“救世主”。真正的好书，都向证伪敞开，而不是给你一个一劳永逸的启示录让你枕着它睡大觉。振聋发聩的东西，我一向觉得可疑。——从经典到经验</p>
</blockquote>
<p>读书并不一定要去读那些深奥的经典之作，更多的应该根据自己的问题，这本书能给自己一些启发、带来一些思考、解决一些困惑，更能体现这本书的价值。</p>
<blockquote>
<p>真的，他们是怎么说服自己的？这事首先令人困惑，其次才令人沮丧。他们怎么能够在窃听骚扰跟踪袭击迫害诚实正直的人之后，一转身，对自己的孩子说：孩子，你要做一个好人。——没有你们就没有他们</p>
</blockquote>
<p>这种事情就像我们对一个幼女强奸犯说，你怎么能这样对待这个小姑娘，这个小姑娘也是别人的女儿，如果别人这样对待你的女儿你会怎么样？有时候我也搞不懂他们是怎么说服自己的，这个可能需要对人性进行更深层次的深挖。</p>
<blockquote>
<p>一切专制者都试图控制人的思想，但警察无法进驻人的大脑，于是只能控制思想的表达。语言因此必须被消毒、被驯化。一些词被妖魔化，另一些词被扎上蝴蝶结，一些词被灌入硫酸，另一些词则被喷上了香水。多年的教育之后，一提起“农民起义”，我就想起了“可歌可泣”，一说到“国民党”，就想起“三座大山”……成年以后我知道历史并非如此非黑即白，但这些被“加工”过的词汇在意识深处留下的情绪反射却经久不去。以条件反射代替思考，使每一个词语在展开其内容之前散发出某种“气味”，正是此类教育的成功之处。——语言的贫困</p>
</blockquote>
<p>这是多么的真实啊，记得小时候不知从何时开始，脑海里一出现欧美资本主义国家，就会想到万恶的资本主义、剥削压迫无产阶级，可是长大之后，我慢慢知道这个世界实际上很复杂，好与坏都是相伴而生的，而我们因为意识形态的问题边只看到某些国家好的地方或者坏的地方，又因为媒体是被完全限制的，所以我们接受的只是他们想让我们接受的，不过互联网确实是在慢慢打破这种限制，让我知道了做一个人是应该独立思考的，而不是等着别人去喂食，这也是我现在对外面的世界充满很大的好奇心，也是现在努力的原因，因为我想要自己去探索一些东西，而不是被强行灌输。作者后面这十几篇文章都是通过电影慢慢感受的，而自己在看电影时只是简单地看一下剧情，并没有深入思考，这也是我应该向作者学习的地方之一。</p>
<blockquote>
<p>影片最后，中年迈克问老年汉娜是否会想起那些犹太人，汉娜冷冷地答：“我怎么想无关紧要，反正死的人都死了。”“我以为你学到了更多的东西。”“我学到了，我学会了阅读。”汉娜学会了阅读，也仅仅是阅读而已。——爱是</p>
</blockquote>
<p>感觉已经超出了我理解范围，我也很难明白为什么人会这么复杂，有那么多面，即使这很多面实际上是有矛盾的。</p>
<blockquote>
<p>说到底，谁都终将被扔回时间的海底，在那里与其它鱼虾贝壳一同聆听无边寂静，而在这之前，我们能指望的，大约只是心灵成长，祈祷生的优雅可以抚慰它的渺小。——记得当年草上飞</p>
</blockquote>
<p>成长的道路各有不同，个人的环境、遭遇各有不同，最后每个人的最后每个人的结果当然也并不会按照自己所想的那样发展。但在命运的手上也有漏网之鱼，虽然并不多，但还是有的，这也是这个世界的美妙之处。</p>
<blockquote>
<p>抑与解放，但是刘天昭不。她写一个小女孩擦玻璃的神情，写帆布椅子上坐着的一个无所事事的老太太，写窗外三三两两的人群，写前任房客掉到床底下的储蓄本，写一只灰喜鹊在天空中划过的轨迹，写夜半大街的光线……总之她写一切貌似轻微、无关和混沌的时刻和人物。她简直是故意通过描写这些“无关紧要”的事物来暗暗颠覆这个世界的权力结构和等级秩序。谁说政治局委员的命运就比远亲里某个“破鞋”的命运更惊心动魄？又或者，凭什么一个“破鞋”的命运一定比窗前一只乌鸦起落的声音更值得书写？在被时间击败、被时间席卷、被时间吞噬方面，万物皆平等，因而都值得在颤抖中被文字拥抱。——诗的世界在每一个角落等待</p>
</blockquote>
<p>她那本书的厉害在于与别人切入点的不同吧。</p>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[从《驴得水》到《我不是潘金莲》的一些思考]]></title>
      <url>http://matt33.com/2016/11/20/movie-think/</url>
      <content type="html"><![CDATA[<p>今年好久没去电影院看过电影了，今天趁着周末去看场电影，选了最近比较火的<a href="https://movie.douban.com/subject/26630781/?from=showing" target="_blank" rel="external">《我不是潘金莲》</a>，据说这部电影跟《驴得水》有些相似之处，比较贴近现实，并那么做作。看完之后确实感慨很多，相比于以前的那些烂电影真的要好很多。</p>
<p>今年上映的国产电影，不得不说有几部确实还是挺不错的，虽然还是烂片居多。关于电影，其实我一直都是有个疑问，之前看过很多的韩国电影，看完真心感觉很多韩国电影拍得很不错，尤其是近几年，韩国的犯罪系列电影拍得很精彩，韩国也拍了很多反应社会现实的电影，如《熔炉》、《金福南杀人事件》，这些电影其实都可以归结于人性系列。那么问题来了，为什么韩国的电影近几年能够异军突起，甚至有成为亚洲电影骄傲的趋势，而我们大陆拍得电影，几乎每年都被在吐槽烂、简直扶不上墙，更别提走出国门了，一年上映几百部的电影，而豆瓣评分过7分也只有个位数，原因何在？是我们的导演不如韩国？编剧不如韩国？或者说文化氛围不如韩国？貌似这些理由都没有说服力，毕竟我们曾经拍出《让子弹飞》、《霸王别姬》、《大话西游》等这些优秀的电影，而且我们国家也出了诺贝尔文学奖获得者莫言，那么原因在哪里？很多人说是广电总局的问题，说我们国家的电影审核太严，我同样也认为这是其重要的原因之一，电影的剧本要符合主流价值观，这也使得很多好的题材并不能过审。而近段上映的两部电影——《驴得水》和《我不是潘金莲》，多多少少让我们感觉到影中的情景就是赤赤裸裸的现实，让我们明显感觉到中国电影的环境在慢慢变得健康，而不像以前那样的畸形，这两部电影的大热也不是没有原因的。</p>
<p>电影是艺术的一种，关于这一点，是我们不可否认的，一部好的艺术作品，是能够启发每个人的思考，而不仅仅是嘻嘻哈哈就过去了，对于电影作品也是如此。</p>
<p>在《驴得水》中，首先是基层人员为了能够获得更多的利益，谎报在编正式人员数，甚至不惜伪造；其次，中层领队对上级拨下来的教育扶贫资金克扣，影中克扣了70%，剩下的30%在基层人员手里大家再分一点，最后真正落到实处的都不足两成、甚至不足一成；最后，为了应付上级领导的检查，中层领导和基层人员为了各自的利益一起糊弄上级领导。这种现象在现实中大家都应该深有体会，尤其对那些三四五线的小城市，恐怕更为严重，这也是年轻人毕业 之后纷纷选择竞争更为公平的一线强二线的城市去打拼的原因（当然并不是说一线强二线就是绝对公平的，相比于三四五线还是要好很多的）。记得当时看过驴得水之后，为影中的剧情拍手叫好，当时看完电影甚至感觉有些诧异，这种电影竟然过审了？</p>
<p>今天看了《我不是潘金莲》，女主李雪莲因为一件离婚案去县里、市里告，在去市里喊冤的时候，为了不影响市里的精神文明检查她还在省委领导视察期间被关进派出所，最后幸运的是她去北京告状的时候遇到了中央的首长，更幸运的是遇到了一个比较好的中央首长，当然故事还在继续，就是因为她这一告从法院院长、县长、市长都一并被处置了，但唯独没有处置她的前夫秦玉河，这里先不讨论李雪莲是否有理（其实这个并不重要，李雪莲确实是个法盲，这部电影给人的思考更应该关注这些人民公仆的表现），在这个过程中我们看到了从下到上、从县到省是如何对待普通公民李雪莲的。首先判官李公道对这个案子判决根据我们已有的法律知识是没有问题的，但是后面的各个官员对于普通公民的态度呢？影片中也出现了法院院长喝酒应酬的情景，李雪莲前去告状，他们连深入了解这个案件的耐心都没有，甚至还生怕李雪莲在前任院长面前说了什么不该说的话，他们直接告诉李雪莲你要是对法院判决不服那就去市里告、检举法院厅长的话去检察院，这跟我们没关系，然后李雪莲就问：你们难道就不管了吗？那人说：我们什么时候说不管了，关键是我们管不了。</p>
<p>这些说的这听起来确实也没有错，当李雪莲在法院院长应酬的饭店外面蹲点，去拦截法院院长的车告状，这里看一下当时影中的情景是怎样的？</p>
<ul>
<li>李雪莲前去告状，法院中另一人直接抱住李雪莲，不让李雪莲在前任院长面前说话，生怕李雪莲说了什么队他们的不利的东西，当时前任院长有心想问一下，这时候他老婆说了一句：你已经退休了，这些事情你管不了了。这个场景我想我们大家都有深有体会的，因为很真实、很现实；</li>
<li>那些法院公职人员对待公民的态度问题，其中那个抱住李雪莲的人还一把把李雪莲推倒在地上，反而自己还大吼道：你想干嘛，真是巨大的讽刺。</li>
<li>影中还出现了两次（记得是两次）打扮颇为靓丽的年轻女子，一次在与两人法院院长吃饭的饭局上，另一次在市长与县长谈话的那个小桥边，同样也有讽刺意味十足。</li>
</ul>
<p>影片也丝毫没有遮掩下级干部是如何欺瞒、甚至糊弄上级，影中连省长向中央首长汇报都是这样，省长都向人代表明确暗示在首长面前不要多说话、讨论仅限昨天会议问题、绝对不能扯远，由此可见，别说民意上达中央了，估计省里都懒得去管。个人认为《我不是潘金莲》这部影片最牛逼的地方在于它直接就映照现实，这些东西以前可都是忌口，就连《驴得水》还用了民国做背景，而它倒好，故事背景直接就发生在近二十年，故事的最后也提高了计划生育政策，普通公民为了多生一个孩子甚至不惜以离婚作掩护，而现在的现实是很多夫妻为了多买套房、享受优惠不惜假离婚，当然也出现了一些假的变成了真的场景，在新闻上是屡见不鲜，可见一切都在改变，而似乎有些东西又丝毫没变，不知道那些这样做的人，过了二十年之后再回忆会是什么感想。</p>
<p>从《驴得水》到《我不是潘金莲》这两部电影，其实我感慨最多还是中国的电影环境在变化，大家都知道2015年和2016年这两年其中一个处在风口的行业是什么？是内容，广大普通民众对于那些套用各大明星的烂电影简直是深恶痛绝，也对那些省级卫视里那些无聊的电视剧和娱乐节目感到厌烦。记得前段时间看新闻，还说今年的票房相比去年下降了很多，我想这更多就是民众再对烂电影的一次共同抗议吧。但这也成了很多用心做内容公司一次机遇，就以电影行业为例，心迷宫、夏洛特烦恼、大圣回来等小投资的电影大热，口碑和票房双丰收，可见市场这只无形的手确实在发挥它应用的作用。</p>
<p>内容行业的人估计也在意识到现在的一些年轻人喜好正在发生改变，假大空、没有任何深入的电影，真的让人无法接受，浪费钱就不说了，更重要的是浪费了我们宝贵的时间。这种结果也是互联网对这个行业冲击的影响，首先，互联网对电影口碑的传播几乎起着决定性的作用，之前是豆瓣评分，现在朋友圈好友推荐，口碑传播的方式在慢慢变化，一部作品的口碑对其最后的成功与否也起着越来越大的作用；再者，互联网的发展，让普通民众接收到了不同信息，民众也不再像以前那样，给什么信息我们就只能接收什么信息，信息的接收渠道十分有限，但是现在我们可以接收到更多的信息，这也在潜移默化影响我们的生活，其实，我就是想说一句话，随着经济的发展，公民观念的水位在慢慢上升。举一个例子，之前那段时间我们一直都在看美国的总统大选，看得好不热闹，然后这两天也刚我们国家的人大代表换届选举，搞笑的场景就出现了，新闻上有一个地方川普的得票率达到了10%，而这个地方总投票率却不到半数，最后选举只好重新举行。对于在大城市生活的人来说，我们还是能明确感受普通公民权利意识的觉醒，这也是我们国家正在进步的表现。</p>
<p>最后，一部好的电影作品是应该引人思考、深入人性的，希望我们国家拍得电影越来越好。</p>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[校招找工作小记]]></title>
      <url>http://matt33.com/2016/11/15/job-summary/</url>
      <content type="html"><![CDATA[<p>2016年，是一个很重要的年份，不但是自己的本命年，还是自己要踏出校园、走向工作的一年。从今年过完年回到学校，记得大概是2月底，这期间经历刷题、找实习、校招，直到前两天把三方交上，今天公司盖完章拿到回执信，工作也算终于确定了下来。在这过程中，经历过失落、兴奋、伤心等等，中间的喜悲，也只有自己最清楚了，趁着这几天晚上有点时间，回想一下过去几个月的心理路程写一篇校招的小记，也算是对这几个月的酸甜苦辣做一下总结。</p>
<blockquote>
<p>莎士比亚：不要因为一次失败，就放弃你原来决心想达到的目标。</p>
</blockquote>
<h1 id="慌慌张张找实习"><a href="#慌慌张张找实习" class="headerlink" title="慌慌张张找实习"></a>慌慌张张找实习</h1><p>记得当时二月底回到实验室，刚来没几天，网易的实习招聘就开始了，当时还没到三月，丫的网易直接把实习的战线拉到了二月底。当时感觉真是日了狗了，啥都没准备，所以也就没有内推网易。然后就开始慌慌张张地准备找实习了（<strong>提醒：找实习就是找工作，一定要认真对待</strong>），先是写简历，把自己在实验室做的那些项目总结一下，重点是把项目给整理一下，根据面试的经验，对于简历中的项目一般会问以下这几个问题（这几个问题有的难度大有的小，看个人人品了，不过最后都准备一下）：</p>
<ol>
<li>项目的目的是什么？要解决什么问题？</li>
<li>为了解决这个问题或完成这个项目，设计方案是什么？以及为什么要使用这个设计方案？</li>
<li>项目中遇到了哪些难点，如何解决？</li>
<li>你再回头看这个设计方案，有什么哪些地方可以再优化？</li>
<li>如果现在让你重新设计方案来解决这个问题，你会怎么设计？（这种问题一般是之前的设计方案有漏洞或者有可以改进的地方时，面试官才会问到）。</li>
</ol>
<p>整理完自己的项目之后，就开始看一些计算机的基础知识，因为自己是做大数据方向，所以当时也就选定了 Java 开发工程师或者是大数据开发工程师的职位，其他的职位就不再考虑了。在准备 Java 基础的时候，主要就是看一下一些常见的 Java 面试题，这个网上有很多，个人的经验，觉得面的最多的就是：容器（hash 很重要）、多线程、并发等了，这个还是比较容易准备的，但当时由于自己准备的太晚，而且很多大公司的实习生开始得也比较早，所以当时就感觉时间很紧张。</p>
<p>如果想投开发岗的话，算法是必须要准备的，《<strong>剑指 Offer</strong>》这本书是肯定要刷一遍的，记得当时自己花了四五天时间急急忙忙把这本书看完，但只是看了算法过程，并没有手写代码，后来在面试中也就吃了亏，手写算法还是要好好准备的，准备一些常见的算法即可。对于 Java 开发，除了算法，JVM 的一些内容也要重点掌握，这个就是看《<strong>深入理解 Java 虚拟机</strong>》这本书了。反正对于我，记得当时刚开始面试时，遇到这种问题基本上都是一脸懵逼，不过面的多了，就知道往哪方面准备了。记得当时先投了阿里云那边，是室友的一个同学内推的，室友的这个同学先对我进行了预面试，问得也是 Java 和大数据方面的基础知识，面试完就感觉自己前几天准备的东西白准备了，都没怎么记住，当时瞬间感觉自己要完了、感觉要完全找不到实习了。</p>
<p>即使当时预面试的结果不是很理想，但是也得投简历，要不然连面试的机会都没了，所以就先投了阿里云。然后紧接着第二天中午就收到了面试电话，聊的内容当时感觉还是很深的，但从现在的角度看，其实也就那样（校招的时候很多公司问得会更深）。这是人生中第一次正式工作面试，中间聊得还挺不错的，面试官对我还比较满意，还让我推荐实验室的同学。我当时也是很幸喜，谁知道好景不长，第二天傍晚就收到了阿里的二面电话，先问了一个问题：介绍一下 Hadoop 生态圈的技术，当时就开始从 MapReudce、hdfs、HBase 开始讲起了，讲了有足足五分钟，电话那边连个音都没有（当时都怀疑那边是不是还有人在听），当时面的时候还是很紧张的，在介绍 hdfs 的时候，面试官突然问到：secondNameNode 的作用是什么？然后就回答错了，之后面试官又开始问了 spark、linux、flink 等相关的问题，自己全程是不会来结束讨论的，然后就没有然后了，这个面试只持续了15分钟就结束了，到了第二天，官网上状态就显示自己的面试结果是已回绝。第一次应聘就这样结束了，当时分析失败的原因认为主要是个人基础准备不足，还有一个是缺乏面试经验，一方面是自己准备的确实不好，另一方面是面试的时候没有把面试官领到自己熟悉的领域上来，而且前面在讨论 hadoop 的时候，并没有与面试官进行一些互动，总之，面的第一家公司就这样挂了。</p>
<p>自己当初找工作时候的目标，其实很明确，就是想去阿里的中间件做 Java 开发工程师。可惜天公不作美，阿里是我面试的第一家公司，也是第一个拒掉我的公司。经历这次面试之后，自己又把相关的基础准备了一下，接着又面了XX街、XX之家，这两家都属于比较小的公司，当时想的是积累一下面试经验，XX之家实在是太耿直了，面了一面就给了 offer，面试官人还挺好，说实话自己到现在还挺愧疚的，去那边面试了，人家给了 offer，结果自己又没去，感觉这样确实不太好。</p>
<p>其实当时自己想的也很清楚，也就准备重点投一下这6家公司：BAT、某滴、某米、某团，其他的投的话只是积累一下面试经验。当然，虽然想得很好，但现实却很骨感，T 家从头到尾都没给面试机会，感觉老是投不对岗，实习的时候投的后台，发现大都是招 C++，听人说大数据应该投基础研究，然后校招投的基础研究，笔试的时候发现题目全特么都是机器学习相关的，当时心中真是一万只草泥马奔腾而过啊，注定无缘。对于 B 家，实习的时候师兄帮忙内推的，面的是一个比较对口的部门，不过因为准备的不充分、基础也回答得不好，虽然一面面了一个半小时，结果还是挂了，不过面试官真的很 nice，面完的时候还对我的面试情况做了一下总结，说我哪地方不好，哪地方还可以，唉，最终还是挂了，校招内推的时候也没敢投，因为这次面我的这个面试官是百度负责 Kafka 技术的小组 leader，当时感觉如果校招再投简历的话简历还是会到他那里，所以就没敢再投。虽然后面百度正式校招的时候也参加了笔试，自我感觉做得还可以，不过最后还是没有面试的机会，也是无缘了。关于 A 家，因为之前实习的时候没过，后来校招的时候也找了内推，但是今年 A 家基本上没怎么校招，今年的校招基本上都是实习生转正，还有一些是内推。因为自己一直想去 A 家的中间件团队，校招的时候就找到了<a href="http://weibo.com/u/2176287895?topnav=1&amp;wvr=6&amp;topsug=1" target="_blank" rel="external">黑桃夹克</a>师兄帮忙内推，师兄很热心，但是今年 A 家的 hc 实在太少，记得当时简历投了一个月都没人理，最后直接变成了校招，让参加笔试，真心感觉 A 家今年没怎么招人，当然这跟具体部门、职位有关。</p>
<p>慢慢的就过了五一，当时实验室好多人的实习基本上已经确定了，大家基本上都拿到了一个比较好的 offer，那段时间自己心里还是能明显感觉到找实习的压力，记得那期间还失眠了一段时间。既然没找到心仪的实习 offer，只能对面试经验再做总结，自己不会的再好好准备。随后，某米和美团的实习也开始了，然后就让师兄师姐帮忙内推，关于某米的面试经历印象还是很深刻的，去面某米之前，其实还是挺想去某米的，自己对某米的商业模式是一直比较看好，但是面试结果真的是大跌眼镜了。当时的一面面试官感觉是一个刚毕业一两年的工程师，随便问了一些大数据和 java 相关的基础知识，然后就开始写算法了，写了一道算法和一个 mr，然后就进入到二面，二面面试官让我设计一个系统，用一个朋友圈来举例，全程聊了将近一个半小时，感觉最后的结果是面试官不理解我说的，而我也没完全理解面试官说的问题，总之，中间聊的时候我都想直接甩袖子走人。面完某米，记得当时我都开始怀疑自己是不是理解能力有问题，不过也深刻地明白了一个道理：<strong>一定要跟面试官确定好问题</strong>，如果你默认是这样，很有可能就中了面试官的套。</p>
<p>面完某米之后，没过几天就收到了美团的面试通知，然后就去美团面试，面美团之前想的是面面再说，反正最后也不一定去，当时约的是两点，我去的比较早，一点半就到了，然后到了一个会议室开始面试，记得当时跟一面面试官聊了一个半小时，关于 Kafka 相关的聊了近 40 min，聊的还比较深，然后又聊了很多基础知识，还写了两道算法。当时面完一面之后，当时感觉自己拿这个 offer 应该还是很稳的，因为自己在实验室做的跟这边做的完全对口。过了一会就开始了二面，刚好跟二面面试官是老乡，二面面试官是做实时的，聊了很多 storm 相关的，因为美团要求前二面必须手写算法，所以又做了一道算法，基本上就结束了，大概也聊了六七十分钟。最后又跟三面面试官聊了半个小时，三面聊了一点点技术，其他的基本上就是聊聊兴趣、聊聊人生什么的。当时从下午两点开始面，面完基本上快六点了，当时面完的感觉是美团这边招人还是挺严格的，纯技术面一口气面了三面。不过美团真的很给力，面完的第二天就给了 offer，因为我当时7月份才能实习，面试官也愿意等我到七月份入职，当时考虑一周之后，就把 offer 签了，决定去美团这边实习，当然最主要的原因是跟我的之前做的很对口，还有就是感觉那边面试还是挺严格的，所以觉得技术应该也不会差到哪去。</p>
<h1 id="实习篇"><a href="#实习篇" class="headerlink" title="实习篇"></a>实习篇</h1><p>到了七月之后，准时到公司报到，去的时候第一周就领到了全新的 Mac pro，之前没用过 mac，各种不顺手，不过用了一周之后，就觉得 Mac 用着真特么爽。去了之后，才知道，当时我的一面面试官，就是之后带我的 Mentor，他已经工作五年了，之前在阿里工作过4年，技术还是很不错的，当时觉得自己还是很幸运的，能有这位师兄带我，之前二面面试官是我们小组的 leader，三面面试官是我们大部门的 leader，被称为百度的 Metrcis 之父，还真没想到这边居然还卧虎藏龙。所以，在刚开始那段时间对自己的工作特别满意，自己在这边确实也能学到东西，被 Mator 逼着看 Kafka 的源码（感谢）。</p>
<p>这里，顺便说一下关于大公司与小公司的选择问题吧。下面纯属个人想法，关于这个选择，如果由能力能去清华的计算机，那不用考虑去就行了，毕竟那里牛人更多、氛围也更好，但是如果去不了清华的计算机，而只能去清华的XX（就是就业很不好的那种小众专业），那完全可以选择去北航的计算机或北邮的计算机。也就是说，如果有能力拿到 BAT 的核心部门的 offer，那就去；但如果只能拿到边缘部门的 offer，那完全可以选择其他公司（某滴、某米、某团）的核心部门。毕竟选择一家公司，不能只看公司的名气、薪酬，还要看当你哪天离开这家公司的时候，你自己成长了多少，个人感觉，这个才是最重要的，在大公司当螺丝钉，也只有在大公司这个环境下你才有价值，一旦离开这个大环境，你能选择的就很少了，所以，应该把个人能力的提升放在一个比较重要的位置。这里，对于应届生，我是比较推荐这六家公司（国外的公司暂不讨论），一些较小或者偏初期的创业公司，对于应届生来说，还是要谨慎一些好。还有就是哪些处在风口的企业，也要慎重，哪些公司估值泡沫很大，而且明显让人感觉的是：哇塞，今年这家公司开的好高，但是明年开高公司又变成了另外一家，所以还是要慎重，在找工作的时候，一定要有一个清晰的目标。</p>
<h1 id="急急忙忙校招"><a href="#急急忙忙校招" class="headerlink" title="急急忙忙校招"></a>急急忙忙校招</h1><p>在美团实习了两个月之后，这时候就已经到了九月份，帝都的互联网校招基本上也开始了，记得当时在论坛随便找了一个师兄内推了 X 狐，然后就通知周末去面试，去之前心里是一点都没普，毕竟算法好久没看了，很多东西长时间不看是会忘的，算法就是这样，当时就随便准备了一下就去面试了，结果很出乎意料，在面试之前，看了一些关于 Java 并发、多线程的内容，当时还做了一下总结，写了一篇博客——<a href="http://matt33.com/2016/08/21/java-concurrency/">Java 并发学习(一)</a>，没想到的是面试官问了很多这方面的内容，虽然二面的时候有一些关于 OOM 调试的问题答的不怎么好，但没过几天 X 狐还是给发了 offer，当时可以说我拿到第一个校招，虽然最后没怎么去，还是很感觉 X 狐能给我这次机会的。</p>
<p>面完 X 狐之后又陆陆续续投一批简历，参加了一批笔试，前面已经说了 BAT 的经历，除了 BAT 之外，其他能投的公司并没有多少，之后参加了某滴的内推笔试，笔试挂，某滴今年招了很多的社招的人，B 家听说有很多人跳到了某滴，阿里正明也去滴滴了，某滴今年真是大热，不过由于发展过快，外面也爆出了很多关于某滴内部管理混乱的问题，最近 zf 又出了一系列政策，导致某滴的日子其实也不好过，今年也能明确感受到某滴校招力度较小，总之，没拿到某滴的面试机会。接着又投了某米，参加了某米的笔试，感觉笔试题做的还是不错的，后来通知去面试，面了某米的互娱事业部，一面聊的还挺好，二面问了一些很基础、平且一般接触不到的问题，比如：Java 泛型的设计有什么不好的地方？问的问题有种说不出来的感觉，当时感觉某米应该是可以过的，结果很尴尬，没有收到 offer。之后由于实习拿过XX街的 offer，所以直接参加了XX街的终面，大神华黎亲自面的（不知道华黎是谁，可以看看这本书<a href="http://item.jd.com/11449803.html" target="_blank" rel="external">《大型网站系统与Java中间件实践》</a>，华黎可是当年阿里中间件核心人物之一），后来顺利拿到了 offer，不过因为其他的一些个人原因，没有选择去，很是抱歉。十月底又顺便水了一把华为的面试，也算是见到了华为的壮观面试场景，三点半的面试，等到了6点才面，一面20min 就结束了，而且面试官跟我做的完全不对口，甚至连 CentOS 都没听说过，接着又等到了七点半开始二面，二面还是一对二同时面（一个面试官同时面两个人），面试问的问题基本上就是 hr 问得那些，后来虽然也收到 offer，但总感觉心里没谱，所以就没去，毕竟华为的声名在外啊，对华为的感觉就是，重点看学校、看学习成绩，按学校级别给工资，基本上一看是好学校差不多的话都会要，进去之后估计是再统一培训，有些人比较喜欢这种，我是不太喜欢这种文化，这也是没选择华为的原因之一。</p>
<p>接着说一下，对今年校招的感觉吧，今年的校招的工资整体要比全年高一个档次，但就业其实并没有去年好，只不过是前面那批人把校招工资拉开了一个档次，当然主要的原因还是今年互联网被华为搅得天翻地覆，谁让华为有钱，而且一招招几千甚至上万人。虽然去年也有一些公司工资开得很高，但招的人太少，影响不了互联网大局。华为就不一样了，招人多，还只招好学校的，还就完全不一样了。在之前，华为都是捡漏的，今年不但薪资高，而且校招还特别早，身边真的有很多人选择了华为放弃了 BAT。听说，当初有人拿到 BAT 其中某家的 offer，因为批发价太低，想谈一下工资，结果人家不给谈，他拿到华为 offer 之后直接就放弃了这家，再后来，这家公司开始给之前放弃 offer 的人打电话，表示工资可以谈，而且还开始补招，真是呵里个呵啊（前面的”他”实际上代表的是他们，泛指很多人）。从今年的情况来看华为的影响力还是相当大的，带动了整个互联网的薪酬水平。如果单纯讨论互联网公司，个人感觉今年首先 A 家招人很少，除了实习生转正和内推，基本上没有校招；B 家招人挺多，可能因为这家公司人员流动性比较大，每年招的人都挺多；T 家不太清楚，感觉跟那边不太对口；美团今年招人还是挺多的，比往年招的力度都要大，公司对于技术还是很重视的；某滴招人也不多，可能是社招人太多还有公司业务发展受限的原因；某米，感觉招人也不少吧，记得某米去年只招了100+人，今年发出的 offer 肯定是比这个高的。互联网公司整体校招力度跟去年比可能稍微差一些，不过由于华为今年突然发力，对于好的学校而言，整体的就业形式并不去年差。</p>
<h1 id="最后"><a href="#最后" class="headerlink" title="最后"></a>最后</h1><p>这里，推荐一篇文章，黑桃夹克师兄当时找工作的时候写的：<a href="http://wuchong.me/blog/2014/09/30/looking-for-a-job-summary/" target="_blank" rel="external">找工作小记——善待挫折</a>，在拿到美团 offer 之前，我也经历一段很不自信、很沮丧的时段，这篇文章在这段时间给我了很大的鼓励，很感谢师兄分享自己的经历。毕竟像师兄这种能到阿里中间件 offer 的牛人，在找工作的时候也并不是一帆风顺的。</p>
<p>最后，说一下个人的感想，我因为一开始就决定了选择走技术这条路，所以基本上也就没有考虑其他行业、其他职位，这个要看个人的选择和职业规划，技术这条路有它的好处，其坏处也很明显，很容易达到职业瓶颈，这个暂时不是我考虑的问题，实际上做技术的人大都在后来慢慢转到管理、产品、运营，甚至去创业去了，能一直在技术上坚持走下去的人并不多，这也说明了技术这条路充满着艰险，并不如想象中的那么好走，这个完全就看个人后期的职业发展了。</p>
<p>在前行的道路上，我们也应该时常停下来多思考思考，想一下自己想要的是什么、想要的生活是什么样的等，下面一句<a href="http://cnbible.com/hosea/4-6.htm" target="_blank" rel="external">圣经：何西阿书 4章6节</a>中一句话作为结束，也希望所有面临校招的童鞋们都拿到适合自己的 offer。</p>
<blockquote>
<p>我的民因无知识而灭亡。你弃掉知识，我也必弃掉你，使你不再给我作祭司。你既忘了你　神的律法，我也必忘记你的儿女。</p>
</blockquote>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[人类简史，一段不知走向何处的简史]]></title>
      <url>http://matt33.com/2016/10/23/brief-history-of-humankind/</url>
      <content type="html"><![CDATA[<p>陆陆续续从7月份开始读这本书，直到昨天（10月底）才把这本书，拖这么久之后，发现，书中讲的很多东西已忘记的差不多了，也没有刚开始看前几章时那种爱不释手的感觉。只能根据自己一些浅显的记忆以及当时在书中记录的一些笔记来述说一下自己的感悟。</p>
<p><img src="/images/book/brief-history.jpg" alt="人类简史"></p>
<p>当初想要看这本书，是因为这本书被很多大牛们推荐，而且豆瓣也给出了<a href="https://book.douban.com/subject/25985021/" target="_blank" rel="external">人类简史-豆瓣</a> 9.3分的高分，好评如潮，感觉不得不看看这部神作。关于读书这个问题，这段时间也在同时看<a href="https://book.douban.com/subject/26874593/" target="_blank" rel="external">《技巧》</a>和<a href="https://book.douban.com/subject/26761696/" target="_blank" rel="external">《精进》</a>这两本书，这两本书都提到了学习方法、读书的方法论，作者根据自己的实践经验进行的一些总结。我个人的大概的理解是：如果是读过某本书，并没有去仔细思考， 那就是读死书，效率很低，如果能能够尝试着去理解作者的思维逻辑，然后去思考自己有哪些东西可以学习、借鉴或者是可以丰富自己的知识体系，这才是读书的真谛，想着去学习作者的经验，而不是简简单单地把书读完，等把这两本书读完，到时候会详细记录一下自己的感悟。</p>
<p>关于《人类简史》这本书，在阅读时，作者有很多非常新奇的观点，这些观点至少我之前是没有遇到过的（可能书读的少的原因），下面举几个书中的例子</p>
<blockquote>
<p>然而历史的铁则告诉我们，每一种由想象建构出来的秩序，都绝不会承认自己出于想象和虚构，而会大谈自己是自然、必然的结果。——第八章，历史从无正义</p>
<p>一次又一次，人类要让社会有秩序的方法，就是会将成员分成各种想象出来的阶级，像是上等人、平民和奴隶；白人和黑人；贵族和平民；婆罗门和首陀罗；又或是富人和穷人。所有这些阶级，就是要让某些人在法律上、政治上或社会上高人一等，从而规范了数百万人的关系。——第八章，历史从无正义</p>
</blockquote>
<p>历史上很多出现的东西都只是智人的想象而已，比如古代的皇帝、律法等，现代的金钱、经济制度等，只不过都是我们的想象，但是我们所有人都出在和生活在这个想象之中，要是有一个人否定了这个想象，立马就会人神共愤。而且人类总是不断地去完善这个所谓的自然、必然的结果，当资本主义出现问题的时候，智人开始考虑社会主义，它向智人描述了一种乌托邦的生活愿景，但是终究抵不过人性的恶，社会主义也并没有按照智人原来的意愿去发展，反而束缚了智人。</p>
<blockquote>
<p>人类历史在过去一直是由两大周期来主导：植物的生长周期，以及太阳能的变化周期（白天和黑夜，夏季和冬季）。 ——第十七章 工业的巨轮<br>在水煮沸的那一刻，水壶或锅的盖子会开始跳上跳下。这时热能转换为动能，但是我们过去都只觉得这样乱跳有点烦人，至于一时忘记而让水煮干就更麻烦了。没人注意到这件事的真正潜力。<br>蒸汽机种类繁多，但有一个共同的原则：燃烧某种燃料（例如煤），再用产生的热将水煮沸，产生蒸汽。<br>工业革命的核心，其实就是能源转换的革命。<br>学习如何有效驾驭和转换能量之后，也解决了另一个阻碍经济成长的问题：原料短缺。 ——第十七章 工业的巨轮</p>
</blockquote>
<p>对于作者的这种想法，我当时是感到很震惊的，感觉很能刷新我的认知，工业革命对人类可以是具有划时代的重要历史事件，在作者看来，其本质就是能量的转变，之前的能量变化过程是：植物吸收太阳能，将太阳能转换为食物的能量，人类或者牛拿到这部分能量之后，再来干别的事情（人类的活动、牛耕地等活动），进行能量转换。而工业革命之后的过程是：煤（动植物存储的能量）的能量转换动能（蒸汽机），动能再进行转换，这极大地提高了智人利用能源的方式，在这个基础上，智人开始利用蒸汽机技术进行航海、火车、工厂等活动。关于最后一句，可以这样理解，人类可以利用的能源暂时可以说无穷尽的，现在还有很多已知的能量我们还不能高效地利用，更别提还有很多未知的、潜在的能量了，在不同的阶段人类利用能量的方式也不一样。举个例子：人类现在每年消耗的能量总和，地球只需要短短90分钟就可以从太阳接收这么多能量，所以对于人类来说，能量是无穷尽的，只是我们暂时还不能高效地去获取或利用这些能量。</p>
<p>文章中有很多类似的观点，包括后来金钱的由来、宗教的发展等，作者站在一个更高的地方去看待整个历史进程，而不是单纯地从历史、文化等角度，向读者展示了一个不同的视角。下面引用一段豆瓣中的内容简介</p>
<blockquote>
<p>十万年前，地球上至少有六种不同的人<br>但今日，世界舞台为什么只剩下了我们自己？<br>从只能啃食虎狼吃剩的残骨的猿人，到跃居食物链顶端的智人，<br>从雪维洞穴壁上的原始人手印，到阿姆斯壮踩上月球的脚印，<br>从认知革命、农业革命，到科学革命、生物科技革命，<br>我们如何登上世界舞台成为万物之灵的？<br>从公元前1776年的《汉摩拉比法典》，到1776年的美国独立宣言，<br>从帝国主义、资本主义，到自由主义、消费主义，<br>从兽欲，到物欲，从兽性、人性，到神性，<br>我们了解自己吗？我们过得更快乐吗？<br>我们究竟希望自己得到什么、变成什么？</p>
</blockquote>
<p>可以说，《人类简史》这本书就是围绕着上述问题来讲述的，作者使用很多假设、推断去思考这些问题，虽然并不一定完全准确，但对很多的问题的分析表达的逻辑都很清晰，这是这本书的牛X 之处。</p>
<p>在人类历史之初，这个世界应该是有很多的人种，但到最后只剩下智人一种，其他的人类种族都已经从这个世界上消失，这是什么原因，如果说这是自然灾害或是其他的原因，肯定不能使人信服。而且这些种族的灭绝都是在智人到达他们的居住地之后发生的，这就不得不使人相信：因为食物的争夺，智人消灭了他们或者是同化了他们，在那个时代，争夺食物实际上就是让自己或自己族群活下去的唯一办法，也只有达尔文的进化论能够解释通这种现象——适者生存，但是这到底是正确的还是错误的？到现在我们依然没有答案，当然如果说这个理论是合理的或是合法的，智人现在就可以肆无忌惮杀害其他物种，甚至可以可以杀害不适的智人，所以，有一点是确定的，现代达尔文主义是错误的，甚至比纳粹还要可怕，这不是人类想要的结果。</p>
<p>智人从一开始消灭其他人种，爬上食物链顶端，可以说认知革命的结果，认知革命让智人开始拥有智慧，智人可以以族群进行生活，建立社群，为了生活大家一起合作。虽然智人人口的增加了，时间一长，又发生了农业革命，智人不再经常去迁徙，而是在一个地方固定居住下来，开始种植植物、训练动物，逐步出现了村落、城市、国家，而随着这些概念的出现，又开始出现了法律、制度以及非农业人员，到最后出现国王等，现在看起来很容易理解过程，但是智人走了近十万年。从十万年前智人开始出现，到5000年前世界上第一个国家开始出现，这中间足足有十万年。</p>
<p>再看一下制度的发展，从公元前1776年的《汉摩拉比法典》，到1776年的美国独立宣言，这中间又走了三千多年。这三千年，智人从最初的一个国家雏形到最后建立一个真正意义的现代国家。在最初的农业社会，智人都是以家庭或者社群为单位生活，甚至金融、养老、处罚等都是以家庭为单位进行，几千年来都是这样，甚至中国现在一些落后的农村仍然是这样（指的是金融和养老这部分，关于这方面，可以参考陈志武老师的书）。但后来自从国家、市场的概念出来以后，就不断冲击着传统的以家庭为社会单位的地位，当然这是工业革命为整个人类带来的巨大变化。工业革命的发展，更加强化了国家、市场这些概念，甚至也驱使了后来的大航海时代、一战、二战等。似乎这几千年来，智人取得了非常巨大的成就，甚至随着现代科技的发展，尤其是现代基因工程，智人开始干预造物主的工作。但是，从开始的社群主义、帝国主义、资本主义到自由主义和消费主义，以及智人从兽欲，到物欲，从兽性、人性，到神性，智人是否了解自己？智人过得到底快乐吗？</p>
<p>关于这点，我们先看一下佛教是如何解释的</p>
<blockquote>
<p>人想要离苦得乐，就必须了解自己所有的主观感受都只是一瞬间的波动，而且别再追求某种感受。如此一来，虽然感受疼痛，但不再感到悲惨；虽然愉悦，但不再干扰心灵的平静。于是，心灵变得一片澄明、自在。这样产生的心灵平静力量强大，那些穷极一生疯狂追求愉悦心情的人完全难以想象。</p>
</blockquote>
<p>佛教与现代生物学和新世纪运动的相同点，在于都认定快乐不在于外在条件。但佛教更重要也更深刻的见解在于，真正的快乐也不在于我们的主观感受。我们如果越强调主观感受，反而就越感到苦。佛教给我们的建议是，除了别再追求外在成就之外，同时也别再追求那些感觉良好的心里感受了。但现代的自由主义则劝我们去追求内心想要的东西，但我们内心到底想要什么？恐怕智人到现在也不清楚自己自己到底想要什么？</p>
<p>最后引用本书的后记作为结尾。</p>
<blockquote>
<p>变成神的这种动物</p>
<p>在7万年前，智人还不过是一种微不足道的动物，在非洲的角落自顾自地生活。但就在接下来的几千年间，智人就成了整个地球的主人、生态系统的梦魇。时至今日，智人似乎只要再跨一步就能进入神的境界，不仅有望获得永恒的青春，更拥有创造和毁灭一切的神力。</p>
<p>但遗憾的是，智人在地球上的所作所为，实在没有太多令人自豪。虽然我们主宰了环境、增加了粮食产量、盖起城市、建立帝国，还创造了无远弗届的贸易网络，但全球的痛苦减少了吗？一次又一次，虽然整体人类的能力大幅提升，但却不一定能改善个别人类的福祉，而且常常还让其他动物深受其害。</p>
<p>在过去的几十年间，至少就人类的生存条件而言有了确实的进步，饥荒、瘟疫和战争都已减少。然而，其他动物的生存条件却是以前所未有的速度急遽恶化，而且就算是人类相关的改进，也还需要再长时间观察才能判断是否利大于弊，是否能够延续。</p>
<p>此外，虽然现在人类已经拥有许多令人赞叹的能力，但我们仍然对目标感到茫然，而且似乎也仍然总是感到不满。我们的交通工具已经从独木舟变成帆船、变成汽船、变成飞机，再变成航天飞机，但我们还是不知道自己该前往的目的地。我们拥有的力量比以往任何时候都更强大，但几乎不知道该怎么使用这些力量。更糟糕的是，人类似乎也比以往任何时候更不负责。我们让自己变成了神，而唯一剩下的只有物理法则，我们也不用对任何人负责。正因如此，我们对周遭的动物和生态系统掀起一场灾难，只为了寻求自己的舒适和娱乐，但从来无法得到真正的满足。</p>
<p>拥有神的能力，但是不负责任、贪得无厌，而且连想要什么都不知道。天下危险，恐怕莫过于如此了。</p>
</blockquote>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[json 对象添加 double 型数值遇到的问题]]></title>
      <url>http://matt33.com/2016/10/15/json-kafka-bug/</url>
      <content type="html"><![CDATA[<p>这是一个关于修改 Kafka 源码时遇到的一个 bug，以及后续引起的一些思考。</p>
<h1 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a>问题描述</h1><p>我们的目标是将 Kafka 中的 <code>Producer</code> 和 <code>Consumer</code> 客户端提供的 metrics，写入到一个 Json 对象中，然后再将这个 Json 对象通过 Http 请求发送到一个 service 服务上。</p>
<p>Kafka 原生提供的 metrics 信息非常多，这些 metrics 信息的大概内容如下图所示。</p>
<p><img src="/images/kafka/kafka-metrics.png" alt="Client Metrics"></p>
<p>在使用下面代码将 metrics 写入到 json 对象</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">for</span> (Map.Entry&lt;MetricName, ? extends Metric&gt; metricEntry : metrics.entrySet()) &#123;</div><div class="line">	jsonObject.put(metricEntry.getKey().toString(),metricEntry.getValue().value();</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>因为这部分是直接添加到 <code>kafka-client</code> 中的，将 <code>kafka-client</code> 打包后，再依赖这个 jar 包，client 在启动时就报了错误，但是并没有退出。</p>
<h1 id="原因查找"><a href="#原因查找" class="headerlink" title="原因查找"></a>原因查找</h1><p>刚开始以为json 对象的大小超出了 Http 协议中的长度限制，因为重写了 <code>MetricName</code> 类的 <code>toString()</code> 方法，如下</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">public</span> String <span class="title">toFlitString</span><span class="params">()</span> </span>&#123;</div><div class="line">        <span class="keyword">return</span> <span class="string">"MetricName [name="</span> + name + <span class="string">", group="</span> + group + <span class="string">", tags="</span> + tags + <span class="string">"]"</span>;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>将长度过长而且用途不大的 <code>description</code> 字段去掉，但是结果依然，并没有解决问题。</p>
<p>接下来为了想知道是往 json 对象添加 metrics 这部分是否执行，因此在 <code>for</code> 循环内添加了一行输出，最后发现输出十行后程序就不再输出，这一行的内容如下所示</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">Key: MetricName [name=request-latency-max, group=consumer-node-metrics, description=, tags=&#123;client-id=consumer-1, node-id=node-2&#125;]	Value: -Infinity</div></pre></td></tr></table></figure>
<p>这时候发现了 <code>-Infinity</code> 这个值，参考这篇文章 <a href="http://www.cnblogs.com/zhisuoyu/archive/2016/03/24/5314541.html" target="_blank" rel="external">java中的NAN和INFINITY</a>，才知道这是一个特殊的值，所以就怀疑是这个问题，因此，写了一个小测试用例</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">package</span> com.meituan.kafka.json;</div><div class="line"></div><div class="line"><span class="keyword">import</span> org.json.JSONObject;</div><div class="line"></div><div class="line"><span class="comment">/**</span></div><div class="line"> * Created by wangmeng on 15/10/2016.</div><div class="line"> */</div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">JsonTest</span> </span>&#123;</div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</div><div class="line">        JSONObject jsonObject=<span class="keyword">new</span> JSONObject();</div><div class="line">        jsonObject.put(<span class="string">"name"</span>,<span class="string">"matt"</span>);</div><div class="line">        jsonObject.put(<span class="string">"age"</span>,<span class="number">24</span>);</div><div class="line">        jsonObject.put(<span class="string">"double"</span>,<span class="number">10</span>/<span class="number">0.0</span>);</div><div class="line">        System.out.println(jsonObject.toString());</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>程序结果真是报错，报错内容如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">Exception in thread &quot;main&quot; org.json.JSONException: JSON does not allow non-finite numbers.</div><div class="line">	at org.json.JSONObject.testValidity(JSONObject.java:1578)</div><div class="line">	at org.json.JSONObject.put(JSONObject.java:1291)</div><div class="line">	at org.json.JSONObject.put(JSONObject.java:1220)</div><div class="line">	at com.meituan.kafka.json.JsonTest.main(JsonTest.java:13)</div><div class="line">	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)</div><div class="line">	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)</div><div class="line">	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)</div><div class="line">	at java.lang.reflect.Method.invoke(Method.java:606)</div><div class="line">	at com.intellij.rt.execution.application.AppMain.main(AppMain.java:144)</div></pre></td></tr></table></figure>
<p>因此，查看了一下 <code>org.json.JSONObject.testValidity</code> 源码，内容如下</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/**</span></div><div class="line"> * Put a key/value pair in the JSONObject. If the value is null, then the</div><div class="line"> * key will be removed from the JSONObject if it is present.</div><div class="line"> *</div><div class="line"> * <span class="doctag">@param</span> key</div><div class="line"> *            A key string.</div><div class="line"> * <span class="doctag">@param</span> value</div><div class="line"> *            An object which is the value. It should be of one of these</div><div class="line"> *            types: Boolean, Double, Integer, JSONArray, JSONObject, Long,</div><div class="line"> *            String, or the JSONObject.NULL object.</div><div class="line"> * <span class="doctag">@return</span> this.</div><div class="line"> * <span class="doctag">@throws</span> JSONException</div><div class="line"> *             If the value is non-finite number or if the key is null.</div><div class="line"> */</div><div class="line"><span class="function"><span class="keyword">public</span> JSONObject <span class="title">put</span><span class="params">(String key, Object value)</span> <span class="keyword">throws</span> JSONException </span>&#123;</div><div class="line">    <span class="keyword">if</span> (key == <span class="keyword">null</span>) &#123;</div><div class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> NullPointerException(<span class="string">"Null key."</span>);</div><div class="line">    &#125;</div><div class="line">    <span class="keyword">if</span> (value != <span class="keyword">null</span>) &#123;</div><div class="line">        testValidity(value);</div><div class="line">        <span class="keyword">this</span>.map.put(key, value);</div><div class="line">    &#125; <span class="keyword">else</span> &#123;</div><div class="line">        <span class="keyword">this</span>.remove(key);</div><div class="line">    &#125;</div><div class="line">    <span class="keyword">return</span> <span class="keyword">this</span>;</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="comment">/**</span></div><div class="line"> * Throw an exception if the object is a NaN or infinite number.</div><div class="line"> *</div><div class="line"> * <span class="doctag">@param</span> o</div><div class="line"> *            The object to test.</div><div class="line"> * <span class="doctag">@throws</span> JSONException</div><div class="line"> *             If o is a non-finite number.</div><div class="line"> */</div><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">testValidity</span><span class="params">(Object o)</span> <span class="keyword">throws</span> JSONException </span>&#123;</div><div class="line">    <span class="keyword">if</span> (o != <span class="keyword">null</span>) &#123;</div><div class="line">        <span class="keyword">if</span> (o <span class="keyword">instanceof</span> Double) &#123;</div><div class="line">            <span class="keyword">if</span> (((Double) o).isInfinite() || ((Double) o).isNaN()) &#123;</div><div class="line">                <span class="keyword">throw</span> <span class="keyword">new</span> JSONException(</div><div class="line">                        <span class="string">"JSON does not allow non-finite numbers."</span>);</div><div class="line">            &#125;</div><div class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> (o <span class="keyword">instanceof</span> Float) &#123;</div><div class="line">            <span class="keyword">if</span> (((Float) o).isInfinite() || ((Float) o).isNaN()) &#123;</div><div class="line">                <span class="keyword">throw</span> <span class="keyword">new</span> JSONException(</div><div class="line">                        <span class="string">"JSON does not allow non-finite numbers."</span>);</div><div class="line">            &#125;</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>查到这里，找到了具体的原因，对 <code>Double</code> 类型的对象，其值不能为 <code>NAN</code> 和 <code>INFINITY</code>，下面再看一下这个两个值在 java 中是如何定义的，对于 double 型的变量</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">public</span> <span class="keyword">final</span> <span class="class"><span class="keyword">class</span> <span class="title">Double</span> <span class="keyword">extends</span> <span class="title">Number</span> <span class="keyword">implements</span> <span class="title">Comparable</span>&lt;<span class="title">Double</span>&gt; </span>&#123;</div><div class="line">    <span class="comment">/**</span></div><div class="line">     * A constant holding the positive infinity of type</div><div class="line">     * &#123;<span class="doctag">@code</span> double&#125;. It is equal to the value returned by</div><div class="line">     * &#123;<span class="doctag">@code</span> Double.longBitsToDouble(0x7ff0000000000000L)&#125;.</div><div class="line">     */</div><div class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">double</span> POSITIVE_INFINITY = <span class="number">1.0</span> / <span class="number">0.0</span>;</div><div class="line"></div><div class="line">    <span class="comment">/**</span></div><div class="line">     * A constant holding the negative infinity of type</div><div class="line">     * &#123;<span class="doctag">@code</span> double&#125;. It is equal to the value returned by</div><div class="line">     * &#123;<span class="doctag">@code</span> Double.longBitsToDouble(0xfff0000000000000L)&#125;.</div><div class="line">     */</div><div class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">double</span> NEGATIVE_INFINITY = -<span class="number">1.0</span> / <span class="number">0.0</span>;</div><div class="line"></div><div class="line">    <span class="comment">/**</span></div><div class="line">     * A constant holding a Not-a-Number (NaN) value of type</div><div class="line">     * &#123;<span class="doctag">@code</span> double&#125;. It is equivalent to the value returned by</div><div class="line">     * &#123;<span class="doctag">@code</span> Double.longBitsToDouble(0x7ff8000000000000L)&#125;.</div><div class="line">     */</div><div class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">double</span> NaN = <span class="number">0.0</span>d / <span class="number">0.0</span>;</div><div class="line">    .....</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>至此，对于这个问题，我们已经完整地解决了，并且也查找到了最终的原因。</p>
<h1 id="写在最后"><a href="#写在最后" class="headerlink" title="写在最后"></a>写在最后</h1><p>之前的文章，总是会写<code>写在前面</code>这一章，本文写了一章<code>写在最后</code>。</p>
<p>这本是一个 bug，实际上并没必要写成一篇文章进行分析，而我这样做的原因是：告诉自己，或者是提醒自己，遇到问题，不但要想着解决问题，还要深入理解这个问题产生的原因。</p>
<p>以前自己在开发中，遇到过很多的坑，很多坑，找到解决办法之后就过去了，后来好久之后再遇到这个问题时，结果还需要花一些时间去查找，一个是自己的记性确实不是太好，另一个当时并没有对遇到的问题深入剖析，把问题的内部原因详细记录下来，希望这篇文章是一个起点，以后博客中，不但要有总结性的文章、思考性的文章，还要有一些详细剖析 bug 的文章。</p>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[JVM 学习——垃圾收集器与内存分配策略]]></title>
      <url>http://matt33.com/2016/09/18/jvm-basic2/</url>
      <content type="html"><![CDATA[<p>本文主要是对《深入理解java虚拟机 第二版》第三章部分做的总结，文章中大部分内容都来自这章内容，也是博客 JVM 学习的第二部分。</p>
<h1 id="简述"><a href="#简述" class="headerlink" title="简述"></a>简述</h1><p>说到垃圾收集（Garbage Collection，GC），很多人可能会认为这是 Java 自有的特性，曾经我也一度这样想，后来才知道 GC 的历史要远远长于 Java，它第一次真正使用是在 Lisp 中，现在，像 python、go 等都有自己的垃圾收集器。在 GC 最开始设计时，人们在思考 GC 时就需要完成三件事情：</p>
<ol>
<li>哪些内存需要进行回收？</li>
<li>什么时候对这些内存进行回收？</li>
<li>如何进行回收？</li>
</ol>
<p>经过将近半个多世纪的发展，内存的动态分配与垃圾回收技术现在已经非常成熟，看起来是进入半自动化时代，但是我们依然需要去学习 GC 和内存分配，因为，当需要排查各种内存溢出、内存泄露问题时，当垃圾收集成为系统达到更高并发量的瓶颈时，我们就需要对这一块进行必要的监控和调节。</p>
<p>回到 Java 语言，在前面介绍的 Java 内存运行时区域的各个部分，其中程序计数器、虚拟机栈、本地方法栈3个区域随线程而生，随线程而灭。栈中的栈帧随着方法的进入和退出而有条不絮地执行着出栈和入栈操作，每一个栈帧中分配多少内存基本上是在类结构确定下来时就已知的，因此，这几块区域的内存分配和回收都具备确定性，在这几个区域内就不需要过多考虑回收的问题，因为方法结束或者线程结束时，内存自然就跟着回收了。而 Java 堆和方法区则不一样，一个接口中的多个实现类需要的内存可能不一样，一个方法中的多个分支需要的内存也可能不一样，我们只有在程序处于运行期间时才能知道会创建哪些对象，这部分的内存和回收都是动态的，垃圾回收器主要关注的也是这部分的内存。</p>
<h1 id="判断对象是否已死"><a href="#判断对象是否已死" class="headerlink" title="判断对象是否已死"></a>判断对象是否已死</h1><p>Java 的堆里存放的几乎所有的对象实例，在进行垃圾回收前，第一件事情就是要确定哪些对象还”存活”着、哪些对象已经”死去”（即不可能再被任何途径使用的对象）。</p>
<h2 id="判断的方法"><a href="#判断的方法" class="headerlink" title="判断的方法"></a>判断的方法</h2><h3 id="引用计数算法（Reference-Counting）"><a href="#引用计数算法（Reference-Counting）" class="headerlink" title="引用计数算法（Reference Counting）"></a>引用计数算法（Reference Counting）</h3><p>给对象中添加一个引用计数器，每当有一个地方引用它时，计数器就加1；当引用失效时，计数器值就减1；任何时刻计数器为0的对象就是不可能再被使用的。
  </p>
<h3 id="可达性分析算法"><a href="#可达性分析算法" class="headerlink" title="可达性分析算法"></a>可达性分析算法</h3><p>基本思想：通过一系列的称为 <strong>GC Roots</strong> 的对象作为起始点，从这些节点开始向下搜索，搜索所走过的路径称为引用链（Reference Chain)，当一个对象到GC Roots没有任何引用链时，则证明此对象是不可用的。</p>
<p>在 Java 中，可作为 GC Roots 的对象包括下面几种：</p>
<ol>
<li>虚拟机栈（栈帧中的本地变量表）中引用的对象。</li>
<li>方法区中类静态属性引用的对象。</li>
<li>方法区中常量引用的对象。</li>
<li>本地方法栈中 JNI（即一般说的 Native 方法）引用的对象。</li>
</ol>
<h3 id="两种方法对比"><a href="#两种方法对比" class="headerlink" title="两种方法对比"></a>两种方法对比</h3><table>
<thead>
<tr>
<th></th>
<th>引用计数法</th>
<th>可达性分析</th>
</tr>
</thead>
<tbody>
<tr>
<td>优点</td>
<td>实现简单，效率高（很少使用这种方法）</td>
<td>在主流的商业程序语言（Java、C#等）的主流实现中，都使用这种方法</td>
</tr>
<tr>
<td>缺点</td>
<td>无法解决对象之间相互循环引用问题（主流的 JVM 都没有使用这种方法）</td>
<td>实现稍微有些复杂</td>
</tr>
</tbody>
</table>
<h2 id="对象的四种引用"><a href="#对象的四种引用" class="headerlink" title="对象的四种引用"></a>对象的四种引用</h2><p>在 Java 中，如果仅仅把对象分为引用和没有被引用这两种状态，那么在一些场景下就无能为力了，比如：我们希望有这样一类对象，当内存空间充足时，则能保留在内存之中，而如果内存空间在进行垃圾回收后还是非常紧张，则可以抛弃这些对象。因此，在 JDK1.2 之后，Java 就对引用的概念进行了扩充，将引用非为一下四种：</p>
<table>
<thead>
<tr>
<th>引用类型</th>
<th>定义</th>
<th>声明方式</th>
<th>回收条件</th>
</tr>
</thead>
<tbody>
<tr>
<td>强引用（ Strong Reference）</td>
<td>强引用就是指在程序代码之中普遍存在的</td>
<td>类似于<code>Object obj= new Object()</code> 这类的引用</td>
<td>只要强引用还在，永不会回收</td>
</tr>
<tr>
<td>软引用（ Soft Reference）</td>
<td>软引用是用来描述一些还有用但并非必需的对象</td>
<td>使用<code>SoftReference</code> 类来声明</td>
<td>系统将要发生内存溢出异常之前，将会把这些对象列入回收范围，进行第二次回收。如果这次回收还没有足够的内存，才会抛出内存溢出异常。</td>
</tr>
<tr>
<td>弱引用（ Weak Reference）</td>
<td>弱引用也是用来描述非必需对象的，但是它的强度比软引用更弱一些</td>
<td>使用 <code>WeakReference</code> 类实现弱引用</td>
<td>被弱引用关联的对象只能生存到下一次垃圾收集发生之前。当垃圾回收器工作时，无论当前内存是否足够，都会回收掉只被弱引用关联的对象</td>
</tr>
<tr>
<td>虚引用（WeakReference）</td>
<td>它是最弱的一种引用关系，一个引用是否有虚引用的存在，完全不会对其生存时间构成影响，也无法通过虚引用来取得一个对象实例。</td>
<td>使用<code>PhantomReference</code> 类来实现虚引用</td>
<td>为一个对象设置虚引用关联的唯一目的就是能在这个对象被收集器回收时收到一个系统通知</td>
</tr>
</tbody>
</table>
<h2 id="生存还是死亡"><a href="#生存还是死亡" class="headerlink" title="生存还是死亡"></a>生存还是死亡</h2><p>要真正宣告一个对象死亡，至少要经历两次标记过程：</p>
<ol>
<li>如果对象在进行可达性分析后发现没有与 GC Roots 相连接的引用链，那它将会被第一次标记并且进行一次筛选，筛选的条件是此对象是否有必要执行 <code>finalize()</code> 方法；</li>
<li>当对象没有覆盖 <code>finalize()</code> 方法，或者 <code>finalize()</code> 方法已经被虚拟机调用过，虚拟机将这两种情况都视为<strong>没有必要执行</strong>；</li>
<li>如果对象要在 <code>finalize()</code> 中成功拯救自己——只要重新与引用链上的任何一个对象建立关联即可。 任何一个对象的 <code>finalize()</code> 方法都只会被系统自动调用一次。</li>
</ol>
<p>这里有两点要注意：</p>
<ol>
<li>如果一个对象被判定有必要执行 <code>finalize()</code> 方法，那这个对象会先被放置在一个叫做 <code>F-Queue</code> 的队列中，并由虚拟机自动建立的、低优先级的 <code>Finalizer</code> 线程去执行它。这里的 “执行” 指的是虚拟机会触发这个方法，但不会承诺等待它运行结束，原因是：如果一个对象在执行 <code>finalize()</code> 时运行缓慢，或者发生死循环，将很有可能导致 <code>F-Queue</code> 队列中其他对象永久处于等待，甚至整个内存回收系统崩溃。</li>
<li>不鼓励大家使用这种方法来拯救对象。相反，建议大家尽量避免使用它，因为它不是 C/ C++ 中的析构函数，而是 Java 刚诞生时为了使 C/ C++ 程序员更容易接受它所做出的一个妥协。它的运行代价高昂，不确定性大，无法保证各个对象的调用顺序。 关闭外部资源，使用 <code>try- finally</code> 或者其他方式都可以做得更好、更及时，所以笔者大家完全可以忘掉 Java 语言中有这个方法的存在。</li>
</ol>
<h2 id="回收方法区"><a href="#回收方法区" class="headerlink" title="回收方法区"></a>回收方法区</h2><p>很多人认为方法区（或者 HotSpot 的永久代）是没有垃圾收集的，Java 虚拟机规范中确实说过可以不要求虚拟机在方法区实现垃圾收集，而且在方法区中进行垃圾收集的 “性价” 一般比较低。</p>
<p>永久代的垃圾收集主要回收两部分内容：废弃常量和无用的类。</p>
<p>判断一个常量是否是 “废弃常量” 比较简单，而要判定一个类是否是 “无用的类” 的条件则相对苛刻很多。类需要同时满足下面 3 个条件才能算是“无用的类”：</p>
<ol>
<li>该类所有的实例都已经被回收；</li>
<li>加载该类的 <code>ClassLoader</code> 已经被回收；</li>
<li>该类对应的 <code>java. lang. Class</code> 对象没有在任何地方被引用，无法在任何地方通过反射访问该类的方法。</li>
</ol>
<p>是否对类进行回收， HotSpot 虚拟机提供了 <code>-Xnoclassgc</code> 参数进行控制，还可以使用 <code>-verbose: class</code> 以及 <code>-XX:+ TraceClassLoading</code>、<code>- XX:+ TraceClassUnLoading</code> 查看类加载和卸载信息。</p>
<p>在大量使用反射、动态代理、 CGLib 等 ByteCode 框架、动态生成 JSP 以及 OSGi 这类频繁自定义 ClassLoader 的场景都需要虚拟机具备类卸载的功能，以保证永久代不会溢出。</p>
<h1 id="垃圾收集算法"><a href="#垃圾收集算法" class="headerlink" title="垃圾收集算法"></a>垃圾收集算法</h1><p>本节主要是介绍一下垃圾收集算法的思想，并不涉及具体的实现。</p>
<h2 id="标记-清除算法"><a href="#标记-清除算法" class="headerlink" title="标记-清除算法"></a>标记-清除算法</h2><p>标记-清除（Mark-Sweep）算法，有两个阶段</p>
<ol>
<li>首先标记所有需要回收的对象；</li>
<li>在标记完成后统一进行回收。</li>
</ol>
<p>执行过程如下图所示。</p>
<p><img src="/images/java/jvm/mark-sweep.png" alt="mark-sweep"></p>
<h2 id="复制算法"><a href="#复制算法" class="headerlink" title="复制算法"></a>复制算法</h2><p>它将可用内存按容量划分为大小相等的两块，每次只使用其中的一块。当这一块的内存用完了，就将还存活着的对象复制到另外一块上面，然后再把已使用过的内存空间一次清理掉。 这种算法的代价是将内存缩小为了原来的一半，未免太高了一点。</p>
<p>算法执行过程如下图所示</p>
<p><img src="/images/java/jvm/copy.png" alt="copy"></p>
<p>现在的商业虚拟机都采用这种收集算法来回收新生代。将内存分为一块较大的 Eden 空间和两块较小的 Survivor 空间，每次使用 Eden 和其中一块 Survivor[ 1]。 当回收时，将 Eden 和 Survivor 中还存活着的对象一次性地复制到另外一块 Survivor 空间上，最后清理掉 Eden 和刚才用过的 Survivor 空间。</p>
<p>HotSpot 虚拟机默认 Eden 和 Survivor 的大小比例是 8: 1。 当 Survivor 空间不够用时，需要依赖其他内存（这里指老年代）进行分配担保（ Handle Promotion）。 如果另外一块 Survivor 空间没有足够空间存放上一次新生代收集下来的存活对象时，这些对象将直接通过分配担保机制进入老年代。</p>
<h2 id="标记-整理算法"><a href="#标记-整理算法" class="headerlink" title="标记-整理算法"></a>标记-整理算法</h2><p>标记-整理算法让所有存活的对象都向一端移动，然后直接清理掉端边界以外的内存。</p>
<p>算法执行过程如下图所示</p>
<p><img src="/images/java/jvm/mark-compact.png" alt="mark-compact"></p>
<h2 id="分代收集算法"><a href="#分代收集算法" class="headerlink" title="分代收集算法"></a>分代收集算法</h2><p>当前商业虚拟机的垃圾收集都采用分代收集（ Generational Collection） 算法。</p>
<p>一般是把 Java 堆分为新生代和老年代，这样就可以根据各个年代的特点采用最适当的收集算法。</p>
<ul>
<li>在新生代中，每次垃圾收集时都发现有大批对象死去，只有少量存活，那就选用复制算法，只需要付出少量存活对象的复制成本就可以完成收集。</li>
<li>而老年代中因为对象存活率高、没有额外空间对它进行分配担保，就必须使用“标记—清理”或者“标记—整理”算法来进行回收。</li>
</ul>
<h2 id="算法对比"><a href="#算法对比" class="headerlink" title="算法对比"></a>算法对比</h2><table>
<thead>
<tr>
<th>算法</th>
<th>优点</th>
<th>缺点</th>
</tr>
</thead>
<tbody>
<tr>
<td>标记-清除</td>
<td>最基础的算法，不是一般的简单</td>
<td>一个是效率问题，标记和清除两个过程的效率都不高；另一个是空间问题，标记清除之后会产生大量不连续的内存碎片</td>
</tr>
<tr>
<td>复制</td>
<td>实现简单，运行高效</td>
<td>减少了内存使用空间；而且在对象存活率较高时需要进行较多的复制操作（不适合老年代）</td>
</tr>
<tr>
<td>标记-整理</td>
<td>根据老年代的特点提出的一种算法，适合老年代</td>
<td>只适合于某些特定情况</td>
</tr>
<tr>
<td>分代收集</td>
<td>使用多种收集算法，根据各自的特点选用不同的收集算法</td>
<td>在具体的实现上比前面的更加复杂</td>
</tr>
</tbody>
</table>
<h1 id="HotSpot-的算法实现"><a href="#HotSpot-的算法实现" class="headerlink" title="HotSpot 的算法实现"></a>HotSpot 的算法实现</h1><p>上面介绍的基础的理论，这一节讲述一下 HotSpot 虚拟机如何实现这些算法的。</p>
<h2 id="枚举根节点"><a href="#枚举根节点" class="headerlink" title="枚举根节点"></a>枚举根节点</h2><p>当执行系统停顿下来后，并不需要一个不漏地检查完所有执行上下文和全局的引用位置，虚拟机应当是有办法直接得知哪些地方存放着对象引用。在 HotSpot 的实现中，是使用一组称为 OopMap 的数据结构来达到这个目的的。</p>
<h2 id="安全点"><a href="#安全点" class="headerlink" title="安全点"></a>安全点</h2><p>在 OopMap 的协助下， HotSpot 可以快速且准确地完成 GC Roots 枚举，但一个很现实的问题随之而来：可能导致引用关系变化，或者说 OopMap 内容变化的指令非常多，如果为每一条指令都生成对应的 OopMap，那将会需要大量的额外空间，这样 GC 的空间成本将会变得更高。</p>
<p>实际上，HotSpot 并没有为每条指令都生成 OopMap，而只是在 “特定的位置” 记录了这些信息，这些位置称为<strong>安全点（Safepoint）</strong>，即程序执行时并非在所有地方都能停顿下来开始 GC，只有在达到安全点时才能暂停。</p>
<p>Safepoint 的选定既不能太少以至于让 GC 等待时间太长，也不能多余频繁以至于过分增大运行时的负载。所以，安全点的选定基本上是以 “是否具有让程序长时间执行的特征” 为标准进行选定的——因为每条指令执行的时间非常短暂，程序不太可能因为指令流长度太长这个原因而过长时间运行，”长时间执行” 的最明显特征就是指令序列复用，例如方法调用、循环跳转、异常跳转等，所以具有这些功能的指令才会产生 Safepoint。</p>
<p>对于 Safepoint， 另一个需要考虑的问题是如何在 GC 发生时让所有线程（这里不包括执行 JNI 调用的线程）都“跑”到最近的安全点上再停顿下来： 抢先式中断（ Preemptive Suspension） 和主动式中断（ Voluntary Suspension）</p>
<ol>
<li>抢占式中断：它不需要线程的执行代码主动去配合，在 GC 发生时，首先把所有线程全部中断，如果有线程中断的地方不在安全点上，就恢复线程，让它 “跑” 到安全点上。</li>
<li>主动式中断：当 GC 需要中断线程的时候，不直接对线程操作，仅仅简单地设置一个标志，各个线程执行时主动去轮询这个标志，发现中断标志为真时就自己中断挂起。轮询标志的地方和安全点是重合的，另外再加上创建对象需要分配内存的地方。</li>
</ol>
<p>现在<strong>几乎没有虚拟机采用抢占式中断来暂停线程从而响应 GC 事件</strong>。</p>
<h2 id="安全区域"><a href="#安全区域" class="headerlink" title="安全区域"></a>安全区域</h2><p>在使用 Safepoint 似乎已经完美地解决了如何进入 GC 的问题，但实际上情况却并不一定。Safepoint 机制保证了程序执行时，在不太长的时间内就会遇到可进入 GC 的 Safepoint。但如果程序在 “不执行” 的时候呢？所谓程序不执行就是没有分配 CPU 时间，典型的例子就是处于 Sleep 状态或者 Blocked 状态，这时候线程无法响应 JVM 的中断请求，JVM 也显然不太可能等待线程重新分配 CPU 时间。对于这种情况，就需要<strong>安全区域（Safe Regin）</strong>来解决了。</p>
<p>在线程执行到 Safe Region 中的代码时，首先标识自己已经进入了 Safe Region，那样，当在这段时间里 JVM 要发起 GC 时，就不用管标识自己为 Safe Region 状态的线程了。在线程要离开 Safe Region 时，它要检查系统是否已经完成了根节点枚举（或者是整个 GC 过程），如果完成了，那线程就继续执行，否则它就必须等待直到收到可以安全离开 Safe Region 的信号为止。</p>
<h1 id="垃圾收集器"><a href="#垃圾收集器" class="headerlink" title="垃圾收集器"></a>垃圾收集器</h1><p>垃圾收集器是内存回收的具体实现，这里讨论的收集器是 JDK 1.7 Update 14 之后的 HotSpot 虚拟机（目前 G1 仍然处于实验状态），这个虚拟机包含的所有收集器如下图所示。</p>
<p><img src="/images/java/jvm/hotspot.png" alt="hotspot"></p>
<p>下面会介绍一下这几种收集器的特性、基本原理和使用场景，并重点分析 CMS 和 G1 这两个相对复杂的收集器，了解它们的部分运作细节。</p>
<blockquote>
<p>注：这里只是介绍这些收集器，进行一下比较，但并非是挑选一个最好的收集器，目前到现在为止还没有最好的收集器出现，更没有万能的收集器，我们只是选择对具体应用最合适的收集器。</p>
</blockquote>
<h2 id="Serial-收集器"><a href="#Serial-收集器" class="headerlink" title="Serial 收集器"></a>Serial 收集器</h2><p>它曾是最基本、发展历史最悠久的收集器，它是一个单线程的收集器，但它的单线程的意义并不仅仅说明它只会是使用一个 CPU 或一条收集线程去完成垃圾收集工作，更重要的是在它进行垃圾收集时，必须暂停其他所有的工作线程，直到它收集结束。<strong>Stop The World</strong> 这个名字也许听起来很酷，但这项工作实际上是由虚拟机在后台自动发起和自动完成的，在用户不可见的情况下把用户正常工作的线程全部停掉，这对很多应用来说都是难以接受的。下图展示了 Serial/Serial old 收集器的运行过程。</p>
<p><img src="/images/java/jvm/serial.png" alt="serial"></p>
<h2 id="ParNew-收集器"><a href="#ParNew-收集器" class="headerlink" title="ParNew 收集器"></a>ParNew 收集器</h2><p>ParNew 收集器其实就是 Serial 收集器的多线程版本。ParNew/Serial old 收集器的运行过程如下图所示</p>
<p><img src="/images/java/jvm/parnew.png" alt="ParNew"></p>
<p>ParNew 收集器除了多线程收集之外，其他与 Serial 收集器相比并没有太多创新之处，但它却是许多运行在 Server 模式下的虚拟机中首选的新生代收集器，其中有一个与性能无关但很重要的原因是，除了 Serial 收集器外，目前只有它能与 CMS 收集器配合工作。（CMS收集器第一次实现了让垃圾收集线程与用户线程（基本上）同时工作。）</p>
<p>CMS 作为老年代的收集器，却无法与 JDK 1. 4. 0 中已经存在的新生代收集器 Parallel Scavenge 配合工作，只能选择ParNew或者Serial收集器中的一个。ParNew 收集器也是使用 <code>-XX:+UseConcMarkSweepGC</code> 选项后的默认新生代收集器，也可以使用 <code>-XX:+UseParNewGC</code> 选项来强制指定它。</p>
<p>由于存在线程交互的开销，该收集器在通过超线程技术实现的两个 CPU 的环境中都不能百分之百地保证可以超越 Serial 收集器。但是，当 CPU 的数量增加时，它对于 GC 时系统资源的有效利用还是很有好处的，它默认开启的收集线程数与 CPU 的数量相同，在 CPU 非常多（使用超线程时）的环境下，可以使用 <code>-XX:ParallelGCThreads</code> 参数来限制垃圾收集的线程数。</p>
<h2 id="Parallel-Scavenge-收集器"><a href="#Parallel-Scavenge-收集器" class="headerlink" title="Parallel Scavenge 收集器"></a>Parallel Scavenge 收集器</h2><p>Parallel Scavenge 收集器是一个新生代收集器，它也是使用复制算法的收集器，又是并行的多线程收集器。</p>
<p>它与其他收集器的不同之处在于：它的关注点与其他收集器不同。CMS 等收集器的关注点是尽可能地缩短垃圾收集时用户线程的停顿时间，而 Parallel Scavenge 收集器的目标则是达到一个可控制的吞吐量（ Throughput）。</p>
<blockquote>
<p>所谓吞吐量就是 CPU 用于运行用户代码的时间与 CPU 总消耗时间的比值，即吞吐量 = 运行用户代码时间 / (运行用户代码时间 + 垃圾收集时间)，虚拟机总共运行了 100 分钟，其中垃圾收集花掉 1 分钟，那吞吐量就是 99%。</p>
</blockquote>
<p>停顿时间越短就越适合需要与用户交互的程序，良好的响应速度能提升用户体验，而高吞吐量则可以高效率地利用 CPU 时间，尽快完成程序的运算任务，主要适合在后台运算而不需要太多交互的任务。</p>
<p>Parallel Scavenge 收集器提供了两个参数用于精确控制吞吐量：</p>
<ol>
<li>控制最大垃圾收集停顿时间， <code>-XX:MaxGCPauseMillis</code>，设置时间小一点并不能使用系统的收集速度更快，因为 GC 停顿时间缩短是以牺牲吞吐量和新生代空间来换取的；</li>
<li>直接设置吞吐量大小， <code>-XX:GCTimeRatio GC</code>，CTimeRatio是指垃圾收集时间占总时间的比率。</li>
</ol>
<p>Parallel Scavenge 收集器经常称为 “吞吐量优先” 收集器。Parallel Scavenge 收集器还提供一个参数 <code>-XX:+ UseAdaptiveSizePolicy</code>，当这个参数打开后，就不需要收工指定一些细节参数了（如：新生代的大小等），虚拟机会动态调整这些参数以提供最合适的停顿时间或者最大的吞吐量，这种调节方式称为<strong>GC 自适应的调解策略（GC Ergonomics）</strong>。自适应调节策略也是 Parallel Scavenge 收集器与 ParNew 收集器的一个重要区别。</p>
<h2 id="Serial-Old-收集器"><a href="#Serial-Old-收集器" class="headerlink" title="Serial Old 收集器"></a>Serial Old 收集器</h2><p>Serial Old 是 Serial 收集器的老年代版本，它同样是一个单线程收集器，使用 “标记-整理” 算法。</p>
<p>这个收集器的主要意义在于给 Client 模式下的虚拟机使用，如果在 Server 模式下，那么它主要还有两大用途：</p>
<ol>
<li>在 JDK1.5 以及之前的版本中与 Parallel Scavenge 收集器搭配使用；</li>
<li>作为 CMS 收集器的后备预案，在并发收集发生 Concurrent Mode Failure 时使用。</li>
</ol>
<p>Serial Old 收集器的工作过程如下图所示</p>
<p><img src="/images/java/jvm/serial.png" alt="serial"></p>
<h2 id="Parallel-old-收集器"><a href="#Parallel-old-收集器" class="headerlink" title="Parallel old 收集器"></a>Parallel old 收集器</h2><p>Parallel Old 是 Parallel Scavenge 收集器的老年代版本，使用多线程和 “标记-整理” 算法。 这个收集器是在 JDK 1. 6 中才开始提供的。在此之前，如果新生代选择了 Parallel Scavenge 收集器，老年代除了 Serial Old（ PS MarkSweep） 收集器外别无选择（还记得上面说过 Parallel Scavenge 收集器无法与 CMS 收集器配合工作吗？）。由于老年代 Serial Old 收集器在服务端应用性能上的拖累，这种组合的吞吐量甚至还不一定有 ParNew 加 CMS 的组合“给力”。</p>
<p>知道 Parallel old 收集器出现后，”吞吐量优先”收集器终于有了比较名副其实的应用组合，在注重吞吐量以及 CPU 资源敏感的场合，都可以优先考虑 Parallel Scavenge 加 Parallel old 收集器，Parallel old 收集器的工作过程如下图所示</p>
<p><img src="/images/java/jvm/parallelold.png" alt="Parallel Old"></p>
<h2 id="CMS-收集器"><a href="#CMS-收集器" class="headerlink" title="CMS 收集器"></a>CMS 收集器</h2><p>CMS（Concurrent Mark Sweep）收集器，以获取最短回收停顿时间为目标，多数应用于互联网站或者B/S系统的服务器端上。</p>
<p>CMS 是基于 “标记—清除” 算法实现的，整个过程分为4个步骤：</p>
<ol>
<li>初始标记（CMS initial mark）</li>
<li>并发标记（CMS concurrent mark）</li>
<li>重新标记（CMS remark）</li>
<li>并发清除（CMS concurrent sweep）</li>
</ol>
<p>有以下几个特点：</p>
<ul>
<li>其中，初试标记、重新标记这两个步骤仍然需要 “Stop The World”；</li>
<li>初始标记只是标记一下 GC Roots 能直接关联到的对象，速度很快；</li>
<li>并发标记阶段就是进行 GC Roots Tracing 的过程；</li>
<li>重新标记阶段则是为了修正并发标记期间因用户程序继续运作而导致标记产生变动的那一部分对象的标记记录，这个阶段的停顿时间一般会比初试标记阶段稍长一些，但远比并发标记的时间短。</li>
</ul>
<p>CMS 收集器的运作步骤如下图所示，在整个过程中耗时最长的并发标记和并发清除过程收集器线程都可以与用户线程一起工作，因此，从总体上看，CMS 收集器的内存回收过程是与用户线程一起并发执行的。</p>
<p><img src="/images/java/jvm/cms.png" alt="cms"></p>
<ul>
<li>优点<ol>
<li>并发收集、低停顿， Sun 公司的一些官方文档中也称之为并发低停顿收集器（ Concurrent Low Pause Collector）。</li>
</ol>
</li>
<li>缺点<ol>
<li>CMS 收集器对 CPU 资源非常敏感。</li>
<li>CMS 收集器无法处理浮动垃圾（ Floating Garbage），可能出现 “Concurrnet Mode Failure” 失败而导致另一次 Full GC 的产生。如果在应用中老年代增长不是太快，可以适当调高参数 <code>-XX: CMSInitiatingOccupancyFraction</code> 的值来提高触发百分比，以便降低内存回收次数从而获取更好的性能。要是 CMS 运行期间预留的内存无法满足程序需要时，虚拟机将启动后备预案：临时启用 Serial Old 收集器来重新进行老年代的垃圾收集，这样停顿时间就很长了。所以说参数 <code>-XX: CM SInitiatingOccupancyFraction</code> 设置得太高很容易导致大量” Concurrent Mode Failure” 失败，性能反而降低。</li>
<li>收集结束时会有大量空间碎片产生，空间碎片过多时，将会给大对象分配带来很大麻烦，往往出现老年代还有很大空间剩余，但是无法找到足够大的连续空间来分配当前对象，不得不提前进行一次 Full GC。CMS 收集器提供了一个 <code>-XX:+UseCMSCompactAtFullCollection</code> 开关参数（默认就是开启的），用于在 CMS 收集器顶不住要进行 Full GC 时开启内存碎片的合并整理过程，内存整理的过程是无法并发的，空间碎片问题没有了，但停顿时间不得不变长。</li>
</ol>
</li>
</ul>
<h2 id="G1-收集器"><a href="#G1-收集器" class="headerlink" title="G1 收集器"></a>G1 收集器</h2><p>  G1 是一款面向服务器应用垃圾收集器，与其他GC收集器想必，G1具备以下特点：</p>
<ol>
<li>并行与并发：G1能充分利用多CPU、多核环境下的硬件优势，使用多个CPU来缩短 Stop The World 停顿的时间，部分其他收集器原本需要停顿Java线程执行的GC动作，G1 收集器仍然可以通过并发的方式让Java程序继续执行；</li>
<li>分代收集：与其他收集器一样，分代概念在G1中依然得以保留。虽然G1可以不要其他收集器配合就能独立管理整个GC堆，但它能够采用不同的方式去处理新创建的对象和已经存活了一半时间、熬过多次GC的旧对象以获取更好的收集效果。</li>
<li>空间整合：与CMS的 “标记-清理” 算法不同，G1从整体上看是基于“标记-整理”算法实现的收集器，从局部（两个Region之间)上来看是基于“复制”算法实现，无论如何，这两种算法都意味着G1运行期间不会产生内存空间碎片，收集后能提供规整的可用内存。</li>
<li>可预测的停顿：这是G1相对于CMS的另一个大优势，降低停顿时间是G1和CMS共同的关注点，但G1除了追求低停顿外，还能建立可预测的停顿时间模型，能让使用者明确指定在一个长度为M毫秒的时间片段内，小号在垃圾收集上的时间不能超过N毫秒，这几乎已经是实时Java(RTSJ）的垃圾收集器的特征了。<br>  <br>下图展示 G1 收集器的运行步骤</li>
</ol>
<p><img src="/images/java/jvm/g1.png" alt="G1"></p>
<p>G1收集器的运作大致可划分为以下几个步骤：</p>
<ol>
<li>初始标记（Initial Marking）：仅仅只是标记一下 GC Roots 能直接关联到的对象，并且修改 TAMS（Next Top at Mark Start）的值，让下一阶段用户程序并发运行时，能在正确可用的 Region 中创建新对象，这阶段需要停顿线程，但耗时很短；</li>
<li>并发标记（Concurrent Marking）：从 GC Roots 开始对堆中对象进行可达性分析，找出存活的对象，这阶段耗时较长，但可与用户程序并发执行；</li>
<li>最终标记（Final Marking）：最终标记则是为了修正在并发标记期间因用户程序继续运行而导致标记产生变动的那一部分标记记录，虚拟机将这段时间对象变化记录在线程 Remembered Set Logs 里面，最终标记需要把 Remembered Set Logs 的数据合并到 Remembered Set 中，这阶段需要停顿线程，但是可并行执行；</li>
<li>筛选回收（Live Data Counting and Evacuation）：筛选回收阶段首先对各个 Region 的回收价值和成本进行排序，根据用户所期望的 GC 停顿时间来指定回收计划，根据 Sun 公司透露的信息来看，这个阶段是可以做到与用户程序并发执行。</li>
</ol>
<h2 id="垃圾收集器对比"><a href="#垃圾收集器对比" class="headerlink" title="垃圾收集器对比"></a>垃圾收集器对比</h2><table>
<thead>
<tr>
<th>垃圾收集器</th>
<th>特性</th>
<th>使用场景</th>
</tr>
</thead>
<tbody>
<tr>
<td>Serial 收集器</td>
<td>复制算法；单线程；新生代；简单而高效；需要进行 stop the world。</td>
<td>它是虚拟机运行在 Client 模式下的默认新生代收集器</td>
</tr>
<tr>
<td>ParNew 收集器</td>
<td>复制算法；Serial 的多线程版本；新生代；默认的线程数与 CPU 数一致</td>
<td>它是许多运行在 Server 模式下的虚拟机中首选的新生代收集器，其中有一个与性能无关但很重要的原因是，除了 Serial 收集器外，目前只有它能与 CMS 收集器配合工作。</td>
</tr>
<tr>
<td>Parallel Scavenge 收集器</td>
<td>复制算法；并行多线程；新生代；吞吐量优先原则；有自适应调节策略</td>
<td>适合后台运算而不需要太多交互的任务</td>
</tr>
<tr>
<td>Serial Old 收集器</td>
<td>标记-整理算法；老年代；单线程；</td>
<td>这个收集器的主要意义在于给 Client 模式下的虚拟机使用</td>
</tr>
<tr>
<td>Parallel Old 收集器</td>
<td>标记-整理；老年代；多线程；与 parallel scavenge 收集器结合实现吞吐量优先</td>
<td>与 Parallel Scavenge 结合使用，适用那些注重吞吐量以及对 CPU 资源敏感的场合</td>
</tr>
<tr>
<td>CMS 收集器</td>
<td>标记-清除；老年代；并发收集、低停顿；有三个缺点（参见上面）</td>
<td>非常适合那些重视响应速度，希望系统停顿时间最短的应用</td>
</tr>
<tr>
<td>G1 收集器</td>
<td>分代收集；空间整合；可预测的停顿</td>
<td>面向服务器应用垃圾收集器</td>
</tr>
</tbody>
</table>
<h2 id="垃圾收集器参数总结"><a href="#垃圾收集器参数总结" class="headerlink" title="垃圾收集器参数总结"></a>垃圾收集器参数总结</h2><table>
<thead>
<tr>
<th>参数</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td>-XX:+UseSerialGC</td>
<td>Jvm运行在Client模式下的默认值，打开此开关后，使用Serial + Serial Old的收集器组合进行内存回收</td>
</tr>
<tr>
<td>-XX:+UseParNewGC</td>
<td>打开此开关后，使用ParNew + Serial Old的收集器进行垃圾回收</td>
</tr>
<tr>
<td>-XX:+UseConcMarkSweepGC</td>
<td>使用ParNew + CMS + Serial Old的收集器组合进行内存回收，Serial Old作为CMS出现“Concurrent Mode Failure”失败后的后备收集器使用。</td>
</tr>
<tr>
<td>-XX:+UseParallelGC</td>
<td>Jvm运行在Server模式下的默认值，打开此开关后，使用Parallel Scavenge + Serial Old的收集器组合进行回收</td>
</tr>
<tr>
<td>-XX:+UseParallelOldGC</td>
<td>使用Parallel Scavenge + Parallel Old的收集器组合进行回收</td>
</tr>
<tr>
<td>-XX:SurvivorRatio</td>
<td>新生代中Eden区域与Survivor区域的容量比值，默认为8，代表Eden:Subrvivor = 8:1</td>
</tr>
<tr>
<td>-XX:PretenureSizeThreshold</td>
<td>直接晋升到老年代对象的大小，设置这个参数后，大于这个参数的对象将直接在老年代分配</td>
</tr>
<tr>
<td>-XX:MaxTenuringThreshold</td>
<td>晋升到老年代的对象年龄，每次Minor GC之后，年龄就加1，当超过这个参数的值时进入老年代</td>
</tr>
<tr>
<td>-XX:UseAdaptiveSizePolicy</td>
<td>动态调整java堆中各个区域的大小以及进入老年代的年龄</td>
</tr>
<tr>
<td>-XX:+HandlePromotionFailure</td>
<td>是否允许新生代收集担保，进行一次minor gc后, 另一块Survivor空间不足时，将直接会在老年代中保留</td>
</tr>
<tr>
<td>-XX:ParallelGCThreads</td>
<td>设置并行GC进行内存回收的线程数</td>
</tr>
<tr>
<td>-XX:GCTimeRatio GC</td>
<td>时间占总时间的比列，默认值为99，即允许1%的GC时间，仅在使用Parallel Scavenge 收集器时有效</td>
</tr>
<tr>
<td>-XX:MaxGCPauseMillis</td>
<td>设置GC的最大停顿时间，在Parallel Scavenge 收集器下有效</td>
</tr>
<tr>
<td>-XX:CMSInitiatingOccupancyFraction</td>
<td>设置CMS收集器在老年代空间被使用多少后出发垃圾收集，默认值为68%，仅在CMS收集器时有效，-XX:CMSInitiatingOccupancyFraction=70</td>
</tr>
<tr>
<td>-XX:+UseCMSCompactAtFullCollection</td>
<td>由于CMS收集器会产生碎片，此参数设置在垃圾收集器后是否需要一次内存碎片整理过程，仅在CMS收集器时有效</td>
</tr>
<tr>
<td>-XX:+CMSFullGCBeforeCompaction</td>
<td>设置CMS收集器在进行若干次垃圾收集后再进行一次内存碎片整理过程，通常与UseCMSCompactAtFullCollection参数一起使用</td>
</tr>
<tr>
<td>-XX:+UseFastAccessorMethods</td>
<td>原始类型优化</td>
</tr>
<tr>
<td>-XX:+DisableExplicitGC</td>
<td>是否关闭手动System.gc</td>
</tr>
<tr>
<td>-XX:+CMSParallelRemarkEnabled</td>
<td>降低标记停顿</td>
</tr>
<tr>
<td>-XX:LargePageSizeInBytes</td>
<td>内存页的大小不可设置过大，会影响Perm的大小，-XX:LargePageSizeInBytes=128m</td>
</tr>
<tr>
<td>-XX:+PrintGCDetails</td>
<td>告诉虚拟机在发送垃圾收集行为时打印内存回收日志，并在进程退出的时候输出当前的内存各区域分配情况</td>
</tr>
</tbody>
</table>
<h1 id="内存分配与回收策略"><a href="#内存分配与回收策略" class="headerlink" title="内存分配与回收策略"></a>内存分配与回收策略</h1><p>本节主要探讨给对象分配内存的部分，对象主要分配在新生代的 Eden 区上，少数情况下也可能会直接分配在老年代中，分配的规则并不是百分之百固定的，取决于使用的哪种垃圾收集器组合以及 jvm 的参数设置。下面会介绍几条最普遍的内存分配规则。</p>
<h2 id="对象优先在Eden分配"><a href="#对象优先在Eden分配" class="headerlink" title="对象优先在Eden分配"></a>对象优先在Eden分配</h2><p>大多数情况下，对象在新生代 Eden 区中分配。当 Eden 区没有足够空间进行分配时，虚拟机将发起一次 <code>Minor GC</code>。</p>
<ol>
<li>新生代 GC（ Minor GC）： 指发生在新生代的垃圾收集动作，因为 Java 对象大多都具备朝生夕灭的特性，所以 Minor GC 非常频繁，一般回收速度也比较快。</li>
<li>老年代 GC（ Major GC/ Full GC）： 指发生在老年代的 GC， 出现了 Major GC， 经常会伴随至少一次的 Minor GC（ 但非绝对的，在 Parallel Scavenge 收集器的收集策略里就有直接进行 Major GC 的策略选择过程）。 Major GC 的速度一般会比 Minor GC 慢 10 倍以上。</li>
</ol>
<p>堆空间分配例子：</p>
<p><code>-verbose: gc-Xms20M-Xmx20M-Xmn10M-XX:+PrintGCDetails -XX:SurvivorRatio=8</code></p>
<p>在运行时通过 <code>-Xms20M</code>、<code>-Xmx20M</code>、<code>-Xmn10M</code> 这 3 个参数限制了 Java 堆大小为 20MB， 不可扩展，其中 10MB 分配给新生代，剩下的 10MB 分配给老年代。<code>-XX:SurvivorRatio=8</code> 决定了新生代中 Eden 区与一个 Survivor 区的空间比例是 8: 1</p>
<h2 id="大对象直接进入老年代"><a href="#大对象直接进入老年代" class="headerlink" title="大对象直接进入老年代"></a>大对象直接进入老年代</h2><p>所谓的大对象是指：需要大量连续内存空间的 Java 对象，最典型的大对象就是那种很长的字符串以及数组。</p>
<p>大对象对虚拟机的内存分配来说是一个坏消息（）遇到一个大对象更加坏的消息就是遇到一群“朝生夕灭”的“短命大对象”，写程序的时候应当避免），经常出现大对象容易导致内存还有不少空间时就提前触发垃圾收集以获取足够的连续空间来”安置”它们。</p>
<p><code>-XX:PretenureSizeThreshold</code> 参数，令大于这个设置值的对象直接在老年代分配（避免了在 Eden 以及两个 Survivor 区之间发送大量的内存复制）。 <code>PretenureSizeThreshold</code> 参数只对 Serial 和 ParNew 两款收集器有效， Parallel Scavenge 收集器不认识这个参数。</p>
<h2 id="长期存活的对象将进入老年代"><a href="#长期存活的对象将进入老年代" class="headerlink" title="长期存活的对象将进入老年代"></a>长期存活的对象将进入老年代</h2><p>如果对象在 Eden 出生并经过第一次 Minor GC 后仍然存活，并且能被 Survivor 容纳的话，将被移动到 Survivor 空间中，并且对象年龄设为 1。 对象在 Survivor 区中每熬过一次 Minor GC， 年龄就增加 1 岁，当它的年龄增加到一定程度（默认为 15 岁），就将会被晋升到老年代中。对象晋升老年代的年龄阈值，可以通过参数 <code>-XX: MaxTenuringThreshold</code> 设置。</p>
<h2 id="动态对象年龄判断"><a href="#动态对象年龄判断" class="headerlink" title="动态对象年龄判断"></a>动态对象年龄判断</h2><p>为了适应不同程序的内存状况，虚拟机并不是永远地要求对象的年龄必须达到了 <code>MaxTenuringThreshold</code> 才能晋升老年代。如果在 Survivor 空间中相同年龄所有对象大小的总和大于 Survivor 空间的一半，年龄大于或等于该年龄的对象就可以直接进入老年代，无须等到 <code>MaxTenuringThreshold</code> 中要求的年龄。</p>
<h2 id="空间分配担保"><a href="#空间分配担保" class="headerlink" title="空间分配担保"></a>空间分配担保</h2><p>在发生 Minor GC 之前，虚拟机会先检查老年代最大可用的连续空间是否大于新生代所有对象总空间，如果这个条件成立，那么 Minor GC 可以确保是安全的。当大量对象在 Minor GC 后仍绕存活，就需要老年代进行空间分配担保，把 Survivor 无法容纳的对象直接进入老年代。如果老年代的判断到剩余空间不足（根据以往每一次回收晋升到老年代对象容量的平均值作为经验值），则进行一次 Full GC。</p>
<hr>
<h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><ul>
<li><a href="https://www.amazon.cn/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3Java%E8%99%9A%E6%8B%9F%E6%9C%BA-JVM%E9%AB%98%E7%BA%A7%E7%89%B9%E6%80%A7%E4%B8%8E%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5-%E5%91%A8%E5%BF%97%E6%98%8E/dp/B00D2ID4PK/ref=sr_1_1?s=books&amp;ie=UTF8&amp;qid=1472975542&amp;sr=1-1&amp;keywords=%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3java%E8%99%9A%E6%8B%9F%E6%9C%BA" target="_blank" rel="external">深入理解java虚拟机</a></li>
</ul>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[JVM学习——java 内存区域与内存溢出分析]]></title>
      <url>http://matt33.com/2016/09/07/jvm-basic1/</url>
      <content type="html"><![CDATA[<p>本文主要是对《深入理解java虚拟机 第二版》第二章部分做的总结，文章中大部分内容都来自这章内容，之所以记录到博客，是想通过这个过程加深自己的理解，并且方便以后遇到相关问题之后进行查阅。</p>
<h1 id="JVM"><a href="#JVM" class="headerlink" title="JVM"></a>JVM</h1><p>Java 虚拟机屏蔽了与具体操作系统平台相关的信息，使得 Java 语言编译程序只需生成在 Java 虚拟机上运行的目标代码(字节码)，就可以在多种平台上不加修改地运行。Java 虚拟机在执行字节码时，实际上最终还是把字节码解释成具体平台上的机器指令执行。</p>
<h1 id="运行时数据区"><a href="#运行时数据区" class="headerlink" title="运行时数据区"></a>运行时数据区</h1><p>Java 虚拟机在执行 Java 程序的过程中会把它所管理的内存划分为若干个不同的数据区域。这些区域都有各自的用途，以及创建和销毁的时间，有的区域随着虚拟机进程的启动而存在，有些区域则依赖用户线程的启动和结束而建立和销毁。</p>
<p>Java 虚拟机所管理的内存包括以下几个运行时数据区域，如下图所示。</p>
<p><img src="/images/java/jvm/jvm.png" alt="jvm"></p>
<ul>
<li>线程间共享区域：方法区和堆；</li>
<li>线程间私有区域：虚拟机栈、本地方法栈和程序计数器。</li>
</ul>
<h2 id="程序计数器"><a href="#程序计数器" class="headerlink" title="程序计数器"></a>程序计数器</h2><p>特点：</p>
<ol>
<li>它是一块较小的内存空间，可以看出当前线程所执行的字节码的行号指示器；</li>
<li>字节码解释器的工作就是通过改变这个计数器的值来选取下一条需要执行的字节码指令，分支、循环、跳转、异常处理、线程恢复都要靠它完成；</li>
<li>每个线程都有一个自己的计数器，线程之间的计数器互不影响；</li>
<li>JVM多线程是通过线程轮流切换并分配处理器执行时间的方式来实现的；</li>
<li>执行Native方法时，计数器不起作用，职位空缺（null）；</li>
<li>此区域是唯一没有规定OOM的区域。</li>
</ol>
<h2 id="Java虚拟机栈"><a href="#Java虚拟机栈" class="headerlink" title="Java虚拟机栈"></a>Java虚拟机栈</h2><p>与程序计数器一样，Java 虚拟机栈（Java Virtual Machine Stacks）也是线程私有的，它的生命周期与线程相同。</p>
<p>虚拟机栈描述的是 Java 方法执行的内存模型：每个方法在执行的同时都会创建一个栈帧（Stack Frmae）用于存储局部变量表、操作数栈、动态链接、方法出口等信息。每个方法从调用直至执行完成的过程，就对应着一个栈帧在虚拟机栈中从入栈到出栈的过程。</p>
<h3 id="局部变量表"><a href="#局部变量表" class="headerlink" title="局部变量表"></a>局部变量表</h3><p>局部变量表存放了编译期可知的基本数据类型（boolean、byte、char、shot、int、float、long、double）、对象引用（reference 类型，他不等同于对象本身，可能是一个指向对象起始地址的引用指针，也可能是指向一个代表对象的句柄或其他与此对象相关的位置）和 returnAddress 类型（指向了一条字节码指令的地址）。</p>
<p>其中，long、double因为长度为64bit，会占用两个Slot，其余的数据类型只占用一个。由此可知局部变量表所需的内存空间在编译期间完成分配，当进入一个方法时，这个方法需要在帧中分配多大的局部变量空间是完全确定的，在方法运行期间不会改变局部变量表的大小。</p>
<h3 id="异常情况"><a href="#异常情况" class="headerlink" title="异常情况"></a>异常情况</h3><p>虚拟机栈中可能会出现两种异常情况：</p>
<ol>
<li><code>StackOverflowError</code>：线程请求的栈深度大于虚拟机所允许的深度.</li>
<li><code>OutOfMemoryError</code>：虚拟机栈动态扩展内存时，无法申请到足够的内存.</li>
</ol>
<h2 id="本地方法栈"><a href="#本地方法栈" class="headerlink" title="本地方法栈"></a>本地方法栈</h2><p>与虚拟机栈作用很相似，区别是虚拟机栈为虚拟机执行 Java 方法服务，而本地方法栈则为虚拟机使用到的 Native 方法服务。</p>
<p>与虚拟机栈一样，本地方法栈区域也会抛出 <code>StackOverflowError</code> 和 <code>OutOfMemoryError</code> 异常。</p>
<h2 id="Java堆"><a href="#Java堆" class="headerlink" title="Java堆"></a>Java堆</h2><p>Java Heap 是 jvm 所管理的内存中最大的区域。Java Heap 是被所有线程共享的一块内存区域，在虚拟机启动时创建。此内存区域的唯一目的就是存放<strong>对象实例</strong>，几乎所有的对象实例和数组都在这里分配内存。</p>
<p>Java Heap 是垃圾收集器管理的主要区域，也叫做 GC 堆。其可细分为新生代和老年代，而新生代又可分为Eden 空间、From Survivor 空间和 To Survivor 空间。</p>
<p>根据 Java 虚拟机规范的规定，Java 堆可以处于物理上不连续的内存空间中，只要逻辑是连续的即可。在实现时，既可以实现成固定大小的，也可以是可扩展的，不过当前主流的虚拟机都是按照可扩展来实现的（通过<code>-Xmx</code> 和<code>-Xms</code>控制）。但如果在堆中没有内存完成实例分配，并且也无法再扩展时，会抛出 <code>OutOfMemoryError</code> 异常。</p>
<p>其中，<code>-Xmn</code> 用来控制新生代内存的大小。</p>
<h2 id="方法区"><a href="#方法区" class="headerlink" title="方法区"></a>方法区</h2><p>特点</p>
<ol>
<li>线程间共享的内存区域；</li>
<li>用于存储已被虚拟机加载的类信息、常量、静态变量、即时编译器编译后的代码等数据；</li>
<li>当方法区无法满足内存的分配需求时，将抛出 <code>OutOfMemoryError</code> 异常；</li>
</ol>
<h2 id="运行时常量池-Runtime-Constant-Pool"><a href="#运行时常量池-Runtime-Constant-Pool" class="headerlink" title="运行时常量池 Runtime Constant Pool"></a>运行时常量池 Runtime Constant Pool</h2><p>特点</p>
<ol>
<li>属于方法区的一部分，</li>
<li>保存Class文件中描述的符号引用和各种字面量.</li>
<li>因为是方法区的一部分，所以会受到方法区内存的限制，当常量池无法再申请到内存时，抛出 <code>OutOfMemoryError</code> 异常。</li>
</ol>
<h2 id="直接内存-Direct-Memory"><a href="#直接内存-Direct-Memory" class="headerlink" title="直接内存 Direct Memory"></a>直接内存 Direct Memory</h2><ol>
<li>直接内存不是 JVM 运行时数据区的一部分，也不是 JVM 规范中定义的内存区域，但是这部分内存也可能会出现 <code>OutOfMemoryError</code> 异常；</li>
<li>在 JDK 1.4 中新加入了 NIO（<code>New Input/Output</code>），引入 <code>Channel</code> 和 <code>Buffer</code> 的 I/O 方式，它可以用 <code>native</code> 方法申请堆外内存，然后通过 JVM 堆中的 <code>DirectByteBuffer</code> 对象操作这块内存，在一些场景下可以显著提高性能（零拷贝）；</li>
<li>虽然本机直接内存的分配不会受到 Java 堆大小的限制，但是，既然是内存，肯定还是会受到本机总内存（包括 RAM 以及 SWAP 区或者分页文件）大小以及处理器寻址空间的限制。开发者在配置虚拟机参数时，会根据实际内存设置 <code>-Xmx</code> 等参数信息，但经常忽略直接内存，使得各个区域总和大于物理内存限制，从而导致动态扩展时出现 <code>OutOfMemoryError</code> 异常。</li>
</ol>
<h1 id="HotSpot虚拟机对象解密"><a href="#HotSpot虚拟机对象解密" class="headerlink" title="HotSpot虚拟机对象解密"></a>HotSpot虚拟机对象解密</h1><p>在了解了JVM 内存的概况之后，这里再介绍一下这些虚拟机内存中的数据的其它细节，譬如它们是如何创建、如何布局以及如何访问的。对于这样设计细节的问题，必须把讨论范围限定在具体的虚拟机和集中在某一个内存区域上才有意义。这里我们以常用的虚拟机 HotSpot 和常用的内存区域 Java 堆为例，深入学习 HotSpot 虚拟机在 Java 堆中对象分配、布局和访问的全过程。</p>
<h2 id="对象的创建"><a href="#对象的创建" class="headerlink" title="对象的创建"></a>对象的创建</h2><p>Java 是一门面向对象的编程语言，在 Java 中无时无刻都有对象被创建出来。在语言层次上，创建对象（例如克隆、反序列化）通常只是一个 <code>new</code> 关键字而已，本小节主要讨论一下对与一个普通的 Java 对象（不包括数组和 Class 对象等）创建的过程是怎样的？</p>
<h3 id="创建过程"><a href="#创建过程" class="headerlink" title="创建过程"></a>创建过程</h3><p>当虚拟机遇到一条 <code>new</code> 指令时，虚拟机会进行以下步骤创建对象。</p>
<ol>
<li>将先去检查这个指令的参数是否能够在常量池中定位到一个类的符号引用，并且检查这个符号引用代表的类是否已被加载、解析和初始化过，如果没有，那必须先执行响应的类加载过程（这部分本文暂时不涉及）；</li>
<li>在类加载检查通过后，接下来虚拟机将为新生对象分配内存。对象所需内存的大小在类加载完成后便可完全确定，为对象分配空间的任务等同于把一块确定大小的内存从 Java 堆中划分出来；</li>
<li>内存分配完成后，虚拟机需要将分配到的内存空间都初始化为零值（这步操作保证了对象的实例字段在 Java 代码中可以不赋初值就可以直接使用）；</li>
<li>接下来，虚拟机要对对象进行必要的设置，例如这个对象是哪个类的实例、如何才能找到类的元数据信息、对象的哈希码、对象的 GC 分代年龄等信息，这些信息存放在对象的对象头（Object Header）之中。</li>
</ol>
<p>这些步骤结束之后，对于虚拟机来说，一个新的对象已经产生了，但是从 Java 角度来看，对象创建才刚刚开始，还没有对对象进行初始化操作。</p>
<h3 id="堆内存分配方法"><a href="#堆内存分配方法" class="headerlink" title="堆内存分配方法"></a>堆内存分配方法</h3><p>从上节的第二步中可以看到，虚拟机为新生对象分配内存，相当于把一块固定大小的内存从 Java 堆中划分出来。</p>
<ol>
<li>我们假设 Java 堆中内存是绝对规整的，所有用过的内存都放在一边，空闲的内存放在另一边，中间放着一个指针作为分界点的指示器，那所分配内存就仅仅把那个指针向空闲空间那边挪动一段与对象大小相等的距离，这种分配方式叫做<strong>指针碰撞</strong>（Bump the Pointer）；</li>
<li>如果 Java 堆中的内存不是完整的，已使用的内存和空闲的内存相互交错，那就没有办法简单地进行指针碰撞了，虚拟机就必须维护一个列表，记录上哪些内存块是可用的，在分配的时候从列表中找到一块足够大的空间划分给对象实例，并更新列表上的记录，这种分配方式称为<strong>空闲列表</strong>（Free List）。</li>
</ol>
<p>选择哪种分配方式由 Java 堆是否完整决定，而 Java 堆是否完整又由所采用的垃圾收集器是否带有<strong>压缩整理</strong>功能决定。</p>
<ul>
<li>在使用 Serial、ParNew 等带有 Compact 过程的收集器时，系统采用的分配算法是指针碰撞；</li>
<li>而使用 CMS 这种基于 Mark-Sweep 算法的收集器时，通常采用的是空闲列表。</li>
</ul>
<h3 id="线程安全"><a href="#线程安全" class="headerlink" title="线程安全"></a>线程安全</h3><p>在JVM 中，对象创建是非常频繁的行为，即使是仅仅修改一个指针所指向的位置，在并发情况下也并不是线程安全的，可能出现在给对象 A 分配内存时，指针还没来得及修改，对象 B 又同时使用原来的指针分配内存的情况。对于这个问题，有两种解决方案：</p>
<ol>
<li>对分配内存空间的动作进行同步处理——实际上虚拟机采用 <strong>CAS</strong> 配上失败重试的方式更新操作的原子性；</li>
<li>把内存分配的动作按照线程划分在不同的空间之中进行，即每个线程在 Java 堆中预先分配一块内存，称为<strong>本地线程分配缓冲</strong>（Thread Local Allocation Buffer，TLAB），哪个线程要分配内存就在哪个线程的 TLAB 上分配，只有 TLAB 用完并分配新的 TLAB 时，才需要同步锁定。虚拟机是否使用 TLAB，可以通过 <code>-XX:+/-UseTLAB</code> 参数来设定。</li>
</ol>
<h2 id="对象的内存布局"><a href="#对象的内存布局" class="headerlink" title="对象的内存布局"></a>对象的内存布局</h2><p>在 HotSpot 虚拟机中，对象在内存中存储的布局可以分为三块区域：对象头（Header）、实例数据（Instance Data）和对齐填充（Padding）。</p>
<h3 id="对象头"><a href="#对象头" class="headerlink" title="对象头"></a>对象头</h3><p>HotSpot 虚拟机的对象头包括两部分信息，第一部分用于存储对象自身的运行时数据，如：哈希码、GC 分代年龄、锁状态标志、线程持有的锁、偏向线程 ID、偏向时间戳等，这部分数据的长度在32位和64位的虚拟机中分别是32bit 和64bit，官方称为”Mark Word”。</p>
<blockquote>
<p>注：对象需要存储的运行时数据很多，其实已经超出了32位、64位 Bitmap 结构所能记录的限度，但是对象头信息是与对象自身定义的数据无关的额外存储成本，因此，考虑到虚拟机的空间效率，Mark Word 被设计成一个非固定的数据结构以便在极小的空间内存储尽量多的信息，它会根据对象的状态复用自己的存储空间。</p>
</blockquote>
<p>对象头的另一部分是类型指针，即对象指向它的类元数据的指针，虚拟机通过这个指针来确定对象是哪个类的实例。另外，如果对象是一个 Java 数组，那在对象头中还必须有一块用于记录数组长度的数据，因为虚拟机可以通过普通的 Java 对象的元数据信息确定 Java 对象的大小，但是从数组的元数据中却无法确定数组的大小。</p>
<h3 id="实例数据"><a href="#实例数据" class="headerlink" title="实例数据"></a>实例数据</h3><p>实例数据才是对象真正存储的有效信息，也是在程序代码中所定义的各种类型的字段内容。无论从父类继承下来的，还是在子类中定义的，都需要记录起来。这部分的存储顺序会受到虚拟机分配策略和字段在 Java 源码中定义顺序的影响。HotSpot 虚拟机默认的分配策略为 longs/doubles、ints、shorts/chars、bytes/booleans、oops（Ordinary Object Pointers），从分配策略中可以看出，相同宽度的字段总是被分配到一起。在满足这个前提条件的情况下，在父类中定义的变量会出现在子类之前。如果 CompactFilds 参数值为 true（默认为 true），那么子类之中较窄的变量也可能会插入到父类变量的空隙之中。</p>
<h3 id="对齐填充"><a href="#对齐填充" class="headerlink" title="对齐填充"></a>对齐填充</h3><p>对齐填充仅仅起着占位符的作用，由于 HotSpot VM 的自动内存管理系统要求对象起始地址必须是8字节的整数倍，换句话说，就是对象的大小必须是8字节的整数倍，而对象头部分正好是8字节的倍数（1倍或者2倍），因此，当对象实例数据部分没有对齐时，就需要通过对齐填充来补充。</p>
<h2 id="对象的访问定位"><a href="#对象的访问定位" class="headerlink" title="对象的访问定位"></a>对象的访问定位</h2><p>建立对象是为了使用对象，我们的 Java 程序需要通过栈上的 reference 数据来操作堆上的具体对象。由于 reference 类型在 Java 虚拟机规范中只规定了一个指向对象的引用，并没有定义这个引用应该通过何种方式去定位、访问堆中的对象的具体位置，所以对象访问方式也是取决于虚拟机实现而定的。目前主流的访问方式有使用句柄和直接指针两种。</p>
<h3 id="句柄访问"><a href="#句柄访问" class="headerlink" title="句柄访问"></a>句柄访问</h3><p>Java 堆会先划分出一块内存作为句柄池，reference 中存储的就是对象的句柄地址，而句柄中包含了对象实例数据与类型数据各自的具体地址信息。</p>
<p><img src="/images/java/jvm/getobject1.png" alt="getobject1"></p>
<p>通过句柄访问的最大好处 reference 中存储的是稳定的句柄地址，在对象被移动（gc 时移动对象非常普遍）时只会改变句柄中的实例数据指针，而 reference 本身不需要修改。</p>
<h3 id="直接地址访问"><a href="#直接地址访问" class="headerlink" title="直接地址访问"></a>直接地址访问</h3><p>使用直接地址访问时，Java 堆对象的布局中就必须考虑如何放置访问类型数据的相关信息，而 reference 中存储的直接就是对象地址。</p>
<p><img src="/images/java/jvm/getobject2.png" alt="getobject2"></p>
<p>使用直接指针访问方式的最大好处就是速度更快，节省了一次指针定位的开销，HotSpot 也是这是使用这种方式实现的。</p>
<h1 id="OOM-调试"><a href="#OOM-调试" class="headerlink" title="OOM 调试"></a>OOM 调试</h1><p>根据前面的介绍，我们知道在 JVM 中，除了程序计数器之后，虚拟机内存的其他几个区域都有发生 OOM 异常的可能，本节会通过一些示例来验证异常发生的场景以及讲述一下如何进行调试。</p>
<h2 id="Java-堆溢出"><a href="#Java-堆溢出" class="headerlink" title="Java 堆溢出"></a>Java 堆溢出</h2><p>Java 堆用于存储对象实例，只要不断地创建对象，并且保证 GC Roots 到对象之间有可达路径来避免垃圾回收机制清除这些对象，那么在对象数量达到最大堆的容量限制后就会产生内存溢出异常。</p>
<h3 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h3><p>下面的例子中，我们限制 Java 堆的大小为5MB，不可扩展（将堆的最小值 <code>-Xms</code> 参数与最大值 <code>-Xmx</code> 参数设置为一样即可）。JVM 参数设置为 <code>-Xms5m -Xmx5m -XX:+HeapDumpOnOutOfMemoryError</code>，程序代码如下（<a href="https://github.com/wangzzu/java_learn/blob/master/jvm/src/main/java/heap/HeapOOMTest.java" target="_blank" rel="external">HeapOOMTest</a>）。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">HeapOOMTest</span> </span>&#123;</div><div class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">Person</span> </span>&#123;</div><div class="line">        <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">static</span> String DEFAULT_NAME = <span class="string">"matt"</span>;</div><div class="line">        <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">static</span> <span class="keyword">int</span> DEFAULT_AGE = <span class="number">18</span>;</div><div class="line">        <span class="keyword">private</span> String name;</div><div class="line">        <span class="keyword">private</span> <span class="keyword">int</span> age;</div><div class="line"></div><div class="line">        <span class="function"><span class="keyword">public</span> <span class="title">Person</span><span class="params">()</span> </span>&#123;</div><div class="line">            <span class="keyword">this</span>.name = DEFAULT_NAME;</div><div class="line">            <span class="keyword">this</span>.age = DEFAULT_AGE;</div><div class="line">        &#125;</div><div class="line"></div><div class="line">        <span class="function"><span class="keyword">public</span> <span class="title">Person</span><span class="params">(String name, <span class="keyword">int</span> age)</span> </span>&#123;</div><div class="line">            <span class="keyword">this</span>.name = name;</div><div class="line">            <span class="keyword">this</span>.age = age;</div><div class="line">        &#125;</div><div class="line"></div><div class="line">        <span class="function"><span class="keyword">public</span> String <span class="title">getName</span><span class="params">()</span> </span>&#123;</div><div class="line">            <span class="keyword">return</span> name;</div><div class="line">        &#125;</div><div class="line"></div><div class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setName</span><span class="params">(String name)</span> </span>&#123;</div><div class="line">            <span class="keyword">this</span>.name = name;</div><div class="line">        &#125;</div><div class="line"></div><div class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">getAge</span><span class="params">()</span> </span>&#123;</div><div class="line">            <span class="keyword">return</span> age;</div><div class="line">        &#125;</div><div class="line"></div><div class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setAge</span><span class="params">(<span class="keyword">int</span> age)</span> </span>&#123;</div><div class="line">            <span class="keyword">this</span>.age = age;</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</div><div class="line">        List&lt;Person&gt; persons = <span class="keyword">new</span> ArrayList&lt;Person&gt;();</div><div class="line">        <span class="keyword">while</span> (<span class="keyword">true</span>) &#123;</div><div class="line">            persons.add(<span class="keyword">new</span> Person());</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>运行结果</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line">java.lang.OutOfMemoryError: Java heap space</div><div class="line">Dumping heap to java_pid9479.hprof ...</div><div class="line">Heap dump file created [11824236 bytes <span class="keyword">in</span> 0.092 secs]</div><div class="line">Exception <span class="keyword">in</span> thread <span class="string">"main"</span> java.lang.OutOfMemoryError: Java heap space</div><div class="line">	at java.util.Arrays.copyOf(Arrays.java:2245)</div><div class="line">	at java.util.Arrays.copyOf(Arrays.java:2219)</div><div class="line">	at java.util.ArrayList.grow(ArrayList.java:242)</div><div class="line">	at java.util.ArrayList.ensureExplicitCapacity(ArrayList.java:216)</div><div class="line">	at java.util.ArrayList.ensureCapacityInternal(ArrayList.java:208)</div><div class="line">	at java.util.ArrayList.add(ArrayList.java:440)</div><div class="line">	at heap.HeapOOMTest.main(HeapOOMTest.java:47)</div><div class="line">	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)</div><div class="line">	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)</div><div class="line">	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)</div><div class="line">	at java.lang.reflect.Method.invoke(Method.java:606)</div><div class="line">	at com.intellij.rt.execution.application.AppMain.main(AppMain.java:144)</div></pre></td></tr></table></figure>
<h3 id="示例异常分析"><a href="#示例异常分析" class="headerlink" title="示例异常分析"></a>示例异常分析</h3><p>Java 堆内存的 OOM 异常是实际应用中常见的内存异常情况。当出现 Java 堆内存溢出时，会报错误信息 <code>java.lang.OutOfMemoryError</code>，会跟着进一步提示 <code>Java heap space</code>。</p>
<p>出现这个异常之后，首先需要确定内存中的数据是否是必要，也就是要先分清楚是出现了内存泄露（Memory Leak）还是内存溢出（Memory Overflow）。</p>
<ol>
<li>如果是内存泄露，可进一步通过工具查看泄露对象到 GC Roots 的引用链。于是就能找到对象是通过怎样的路径与 GC Roots 相关联并导致垃圾收集器无法自动回收它们的，这样就就可以定位出泄露代码的位置；</li>
<li>如果不是内存泄露，需要检查一下虚拟机的参数（<code>-Xmx</code> 与 <code>-Xms</code>），与物理机内存对比看是否还可以调大，然后再检查一下代码，是否存在某些对象生命周期过长、持有状态时间过长的情况，尝试减少程序运行期的内存消耗。</li>
</ol>
<h2 id="虚拟机栈和本地方法栈溢出"><a href="#虚拟机栈和本地方法栈溢出" class="headerlink" title="虚拟机栈和本地方法栈溢出"></a>虚拟机栈和本地方法栈溢出</h2><p>由于在 HotSpot 虚拟机中并不区分虚拟机栈而本地方法栈。因此，对于 HotSpot 来说，虽然 <code>-Xoss</code> 参数（设置本地方法栈大小）存在，但实际上无效的，栈容量只由 <code>-Xss</code> 参数设定。对于虚拟机栈和本地方法栈，在 Java 虚拟机中描述了两种异常：</p>
<ol>
<li>如果线程请求的栈深度大于虚拟机所允许的最大深度，将抛出 <code>StackOverflowError</code> 异常；</li>
<li>如果虚拟机在扩展栈时无法申请到足够的内存空间，则将抛出 <code>OutOfMemoryError</code> 异常。</li>
</ol>
<blockquote>
<p>注：这里有一个问题，当栈空间无法继续分配时，到底是内存太小，还是已使用的栈空间太大，其本质上只是针对同一件事情两种描述。</p>
</blockquote>
<h3 id="示例-1"><a href="#示例-1" class="headerlink" title="示例"></a>示例</h3><p>对单线程的情况，尝试一下两种方法都是获得 <code>StackOverflowError</code> 异常（<a href="https://github.com/wangzzu/java_learn/blob/master/jvm/src/main/java/stack/StackTest1.java" target="_blank" rel="external">StackTest1</a>）</p>
<ul>
<li>使用<code>-Xss</code>参数减少栈内存容量。结果：抛出 <code>StackOverflowError</code> 异常，异常出现时输出的栈深度相应减少；</li>
<li>定义了大量的本地变量，增大此方法帧中本地变量表的长度。结果：抛出 <code>StackOverflowError</code> 异常时输出的堆栈深度相应减少。</li>
</ul>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/**</span></div><div class="line"> * VM Args: -Xss256k</div><div class="line"> */</div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">StackTest1</span> </span>&#123;</div><div class="line">    <span class="keyword">private</span> <span class="keyword">int</span> stackLength=<span class="number">1</span>;</div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">stackLeak</span><span class="params">()</span></span>&#123;</div><div class="line">        stackLength++;</div><div class="line">        stackLeak();</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Throwable</span>&#123;</div><div class="line">        StackTest1 stackTest1=<span class="keyword">new</span> StackTest1();</div><div class="line">        <span class="keyword">try</span> &#123;</div><div class="line">            stackTest1.stackLeak();</div><div class="line">        &#125;<span class="keyword">catch</span> (Throwable e)&#123;</div><div class="line">            System.out.println(<span class="string">"stack length: "</span>+stackTest1.stackLength);</div><div class="line">            <span class="keyword">throw</span> e;</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>输出结果</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">Exception <span class="keyword">in</span> thread <span class="string">"main"</span> java.lang.StackOverflowError</div><div class="line">	at stack.StackTest1.stackLeak(StackTest1.java:9)</div><div class="line">stack length: 1868</div><div class="line">	at stack.StackTest1.stackLeak(StackTest1.java:10)</div><div class="line">	at stack.StackTest1.stackLeak(StackTest1.java:10)</div><div class="line">	....</div></pre></td></tr></table></figure>
<h3 id="示例分析"><a href="#示例分析" class="headerlink" title="示例分析"></a>示例分析</h3><p>根据上面的测试结果表明：在单个线程下，无论是由于栈帧太大还是虚拟机栈容量太小，当内存无法分配的时候，虚拟机抛出的都是  <code>StackOverflowError</code> 异常。</p>
<h2 id="方法区和运行时常量池异常"><a href="#方法区和运行时常量池异常" class="headerlink" title="方法区和运行时常量池异常"></a>方法区和运行时常量池异常</h2><p>运行时常量池是方法区的一部分。可以通过 <code>-XX:PermSize</code> 和 <code>-XX:MaxPermSize</code> 来限制方法区的大小，从而间接限制其中常量池的容量。下面的例子主要讲述一下方法区异常的示例。</p>
<h3 id="示例-2"><a href="#示例-2" class="headerlink" title="示例"></a>示例</h3><p>方法区用于存放 Class 的相关信息，如类名、访问修饰符、常量池、字段描述、方法描述等。对于这些区域的测试，我们的思路是运行时产生大量的类去填满方法区，知道溢出。在我们的示例中，我们借助 CGLib 直接操作字节码运行时生成了大量的动态类（<a href="https://github.com/wangzzu/java_learn/blob/master/jvm/src/main/java/methodarea/JavaMethodAreaOOM.java" target="_blank" rel="external">JavaMethodAreaOOM</a>）。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/**</span></div><div class="line"> * VM Args: -XX:PermSize=10M -XX:MaxPermSize=10M -XX:+HeapDumpOnOutOfMemoryError</div><div class="line"> */</div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">JavaMethodAreaOOM</span> </span>&#123;</div><div class="line">    <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">OOMObject</span> </span>&#123;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(<span class="keyword">final</span> String[] args)</span> </span>&#123;</div><div class="line">        <span class="keyword">while</span> (<span class="keyword">true</span>) &#123;</div><div class="line">            Enhancer enhancer = <span class="keyword">new</span> Enhancer();</div><div class="line">            enhancer.setSuperclass(OOMObject.class);</div><div class="line">            enhancer.setUseCache(<span class="keyword">false</span>);</div><div class="line">            enhancer.setCallback(<span class="keyword">new</span> MethodInterceptor() &#123;</div><div class="line">                <span class="function"><span class="keyword">public</span> Object <span class="title">intercept</span><span class="params">(Object o, Method method, Object[] objects, MethodProxy methodProxy)</span> <span class="keyword">throws</span> Throwable </span>&#123;</div><div class="line">                    <span class="keyword">return</span> methodProxy.invokeSuper(o, args);</div><div class="line">                &#125;</div><div class="line">            &#125;);</div><div class="line">            enhancer.create();</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>运行结果</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">java.lang.OutOfMemoryError: PermGen space</div><div class="line">    Dumping heap to java_pid10480.hprof ...</div><div class="line">    Heap dump file created [10685765 bytes <span class="keyword">in</span> 0.086 secs]</div><div class="line">    Exception <span class="keyword">in</span> thread <span class="string">"main"</span></div><div class="line">    Exception: java.lang.OutOfMemoryError thrown from the UncaughtExceptionHandler <span class="keyword">in</span> thread <span class="string">"main"</span></div></pre></td></tr></table></figure>
<p>方法区溢出</p>
<ul>
<li>方法区存储类信息，当类过多时，就会导致方法区溢出.</li>
<li>实际应用中，主流框架如Spring、Hibernate（CGLIB）、JSP、OSGi等会动态生成大量Class；而类被回收的判定条件是非常苛刻的.</li>
</ul>
<hr>
<h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><ul>
<li><a href="https://www.amazon.cn/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3Java%E8%99%9A%E6%8B%9F%E6%9C%BA-JVM%E9%AB%98%E7%BA%A7%E7%89%B9%E6%80%A7%E4%B8%8E%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5-%E5%91%A8%E5%BF%97%E6%98%8E/dp/B00D2ID4PK/ref=sr_1_1?s=books&amp;ie=UTF8&amp;qid=1472975542&amp;sr=1-1&amp;keywords=%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3java%E8%99%9A%E6%8B%9F%E6%9C%BA" target="_blank" rel="external">深入理解java虚拟机</a></li>
<li><a href="http://wiki.jikexueyuan.com/project/java-vm/" target="_blank" rel="external">深入理解java虚拟机 | 极客学院</a></li>
</ul>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[数据库事务性（MySQL 存储引擎及索引结构）]]></title>
      <url>http://matt33.com/2016/08/31/database-transaction/</url>
      <content type="html"><![CDATA[<h1 id="数据库事务性"><a href="#数据库事务性" class="headerlink" title="数据库事务性"></a>数据库事务性</h1><p>并非任意的对数据库的操作序列都是数据库事务。事务应该具有4个属性：原子性、一致性、隔离性、持久性。这四个属性通常称为ACID特性。</p>
<ol>
<li>原子性（Atomicity）：事务作为一个整体被执行，包含在其中的对数据库的操作要么全部被执行，要么都不执行。</li>
<li>一致性（Consistency）：事务应确保数据库的状态从一个一致状态转变为另一个一致状态。一致状态的含义是数据库中的数据应满足完整性约束。</li>
<li>隔离性（Isolation）：多个事务并发执行时，一个事务的执行不应影响其他事务的执行。事务查看数据时数据所处的状态，要么是另一并发事务修改它之前的状态，要么是另一事务修改它之后的状态，事务不会查看中间状态的数据。换句话说，一个事务的影响在该事务提交前对其他事务都不可见。</li>
<li>持久性（Durability）：一个事务一旦提交，他对数据库的修改应该永久保存在数据库中。</li>
</ol>
<h2 id="数据库的并发控制"><a href="#数据库的并发控制" class="headerlink" title="数据库的并发控制"></a>数据库的并发控制</h2><p>数据库管理系统（DBMS）中的并发控制的任务是确保在多个事务同时存取数据库中同一数据时不破坏事务的隔离性和统一性以及数据库的统一性。</p>
<p>封锁、时间戳、乐观并发控制(乐观锁)和悲观并发控制（悲观锁）是并发控制主要采用的技术手段。</p>
<h3 id="锁的分类-oracle"><a href="#锁的分类-oracle" class="headerlink" title="锁的分类(oracle)"></a>锁的分类(oracle)</h3><ol>
<li>按操作划分，可分为DML锁、DDL锁</li>
<li>按锁的粒度划分，可分为表级锁、行级锁、页级锁（mysql）</li>
<li>按锁级别划分，可分为共享锁、排他锁</li>
<li>按加锁方式划分，可分为自动锁、显示锁</li>
<li>按使用方式划分，可分为乐观锁、悲观锁</li>
</ol>
<ul>
<li>DML锁（data locks，数据锁），用于保护数据的完整性，其中包括行级锁(Row Locks (TX锁))、表级锁(table lock(TM锁));</li>
<li>DDL锁（dictionary locks，数据字典锁），用于保护数据库对象的结构，如表、索引等的结构定义.</li>
<li>其中包排他DDL锁（Exclusive DDL lock）、共享DDL锁（Share DDL lock）、可中断解析锁（Breakable parse locks）</li>
</ul>
<h1 id="数据隔离级别"><a href="#数据隔离级别" class="headerlink" title="数据隔离级别"></a>数据隔离级别</h1><p>如果不对数据库进行并发控制，可能会产生异常情况：</p>
<ol>
<li>脏读(Dirty Read)<ul>
<li>当一个事务读取另一个事务尚未提交的修改时，产生脏读。</li>
<li>同一事务内不是脏读。 一个事务开始读取了某行数据，但是另外一个事务已经更新了此数据但没有能够及时提交。这是相当危险的，因为很可能所有的操作都被回滚，也就是说读取出的数据其实是错误的。</li>
</ul>
</li>
<li>非重复读(Nonrepeatable Read)：一个事务对同一行数据重复读取两次，但是却得到了不同的结果。同一查询在同一事务中多次进行，由于其他提交事务所做的修改或删除，每次返回不同的结果集，此时发生非重复读。</li>
<li>幻像读(Phantom Reads)：事务在操作过程中进行两次查询，第二次查询的结果包含了第一次查询中未出现的数据（这里并不要求两次查询的SQL语句相同）。这是因为在两次查询过程中有另外一个事务插入数据造成的。<ul>
<li>当对某行执行插入或删除操作，而该行属于某个事务正在读取的行的范围时，会发生幻像读问题。</li>
</ul>
</li>
<li>丢失修改(Lost Update)<ul>
<li>第一类：当两个事务更新相同的数据源，如果第一个事务被提交，第二个却被撤销，那么连同第一个事务做的更新也被撤销。</li>
<li>第二类：有两个并发事务同时读取同一行数据，然后其中一个对它进行修改提交，而另一个也进行了修改提交。这就会造成第一次写操作失效。</li>
</ul>
</li>
</ol>
<p>为了兼顾并发效率和异常控制，在标准SQL规范中，定义了4个事务隔离级别，（ Oracle 和 SQL Server 对标准隔离级别有不同的实现 ）</p>
<ol>
<li>未提交读(Read Uncommitted)<ul>
<li>直译就是”读未提交”，意思就是即使一个更新语句没有提交，但是别的事务可以读到这个改变。</li>
<li>Read Uncommitted允许脏读。</li>
</ul>
</li>
<li>已提交读(Read Committed)<ul>
<li>直译就是”读提交”，意思就是语句提交以后，即执行了 Commit 以后别的事务就能读到这个改变，只能读取到已经提交的数据。Oracle等多数数据库默认都是该级别。</li>
<li>Read Commited 不允许脏读，但会出现非重复读。</li>
</ul>
</li>
<li>可重复读(Repeatable Read)<ul>
<li>直译就是”可以重复读”，这是说在同一个事务里面先后执行同一个查询语句的时候，得到的结果是一样的。</li>
<li>Repeatable Read 不允许脏读，不允许非重复读，但是会出现幻象读。</li>
</ul>
</li>
<li>串行读(Serializable)<ul>
<li>直译就是”序列化”，意思是说这个事务执行的时候不允许别的事务并发执行。完全串行化的读，每次读都需要获得表级共享锁，读写相互都会阻塞。</li>
<li>Serializable 不允许不一致现象的出现。</li>
</ul>
</li>
</ol>
<h2 id="事务隔离的实现——锁"><a href="#事务隔离的实现——锁" class="headerlink" title="事务隔离的实现——锁"></a>事务隔离的实现——锁</h2><ol>
<li>共享锁(S锁)<ul>
<li>用于只读操作(<code>SELECT</code>)，锁定共享的资源。共享锁不会阻止其他用户读，但是阻止其他的用户写和修改。</li>
</ul>
</li>
<li>更新锁(U锁)<ul>
<li>用于可更新的资源中。防止当多个会话在读取、锁定以及随后可能进行的资源更新时发生常见形式的死锁。</li>
</ul>
</li>
<li>独占锁(X锁，也叫排他锁)<ul>
<li>一次只能有一个独占锁用在一个资源上，并且阻止其他所有的锁包括共享缩。写是独占锁，可以有效的防止“脏读”。</li>
</ul>
</li>
</ol>
<p>隔离级别如何实现，这部分的详细内容可以参考<a href="http://www.hollischuang.com/archives/943" target="_blank" rel="external">深入分析事务的隔离级别</a>一文，下表是进行的总结。</p>
<table>
<thead>
<tr>
<th>隔离级别</th>
<th>实现原理</th>
</tr>
</thead>
<tbody>
<tr>
<td>未提交读(Read uncommitted)</td>
<td>事务在读数据的时候并未对数据加锁；事务在修改数据的时候只对数据增加行级共享锁。</td>
</tr>
<tr>
<td>提交读(Read committed)</td>
<td>事务对当前被读取的数据加 行级共享锁（当读到时才加锁），一旦读完该行，立即释放该行级共享锁；事务在更新某数据的瞬间（就是发生更新的瞬间），必须先对其加行级排他锁，直到事务结束才释放。</td>
</tr>
<tr>
<td>可重复读(Repeatable reads)</td>
<td>事务在读取某数据的瞬间（就是开始读取的瞬间），必须先对其加 行级共享锁，直到事务结束才释放；事务在更新某数据的瞬间（就是发生更新的瞬间），必须先对其加 行级排他锁，直到事务结束才释放。</td>
</tr>
<tr>
<td>可序列化(Serializable)</td>
<td>事务在读取数据时，必须先对其加 表级共享锁 ，直到事务结束才释放；事务在更新数据时，必须先对其加 表级排他锁 ，直到事务结束才释放。</td>
</tr>
</tbody>
</table>
<h1 id="MySQL-的存储引擎"><a href="#MySQL-的存储引擎" class="headerlink" title="MySQL 的存储引擎"></a>MySQL 的存储引擎</h1><p>关系数据库表是用于存储和组织信息的数据结构，可以将表理解为由行和列组成的表格，类似于Excel的电子表格的形式。有的表简单，有的表复杂，有的表根本不用来存储任何长期的数据，有的表读取时非常快，但是插入数据时去很差；而我们在实际开发过程中，就可能需要各种各样的表，不同的表，就意味着存储不同类型的数据，数据的处理上也会存在着差异。</p>
<p>对于MySQL来说，它提供了很多种类型的存储引擎，我们可以根据对数据处理的需求，选择不同的存储引擎，从而最大限度的利用MySQL强大的功能。本节将总结和分析各个引擎的特点，以及适用场合，这里先不会纠结于更深层次的东西，下面就对MySQL支持的存储引擎进行简单的介绍。（本节主要参考<a href="http://www.jellythink.com/archives/640" target="_blank" rel="external">MySQL存储引擎介绍</a>一文）</p>
<p>在mysql客户端中，使用以下命令可以查看MySQL支持的引擎。</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">show</span> <span class="keyword">engines</span>;</div></pre></td></tr></table></figure>
<h2 id="MyISAM"><a href="#MyISAM" class="headerlink" title="MyISAM"></a>MyISAM</h2><p><code>MyISAM</code> 表是独立于操作系统的，这说明可以轻松地将其从 Windows 服务器移植到 Linux 服务器；每当我们建立一个 <code>MyISAM</code> 引擎的表时，就会在本地磁盘上建立三个文件，文件名就是表名。例如，我建立了一个 <code>MyISAM</code> 引擎的 <code>tb_Demo</code> 表，那么就会生成以下三个文件：</p>
<ul>
<li><code>tb_demo.frm</code>：存储表定义；</li>
<li><code>tb_demo.MYD</code>：存储数据；</li>
<li><code>tb_demo.MYI</code>：存储索引。</li>
</ul>
<p>有以下特点：</p>
<ul>
<li>不支持事务：MyISAM存储引擎不支持事务，所以对事务有要求的业务场景不能使用</li>
<li>表级锁定：其锁定机制是表级锁定，这虽然可以让锁定的实现成本很小但是也同时大大降低了其并发性能</li>
<li>读写互相阻塞：不仅会在写入的时候阻塞读取，MyISAM还会在读取的时候阻塞写入，但读本身并不会阻塞另外的读</li>
<li>只会缓存索引：MyISAM可以通过key_buffer缓存以大大提高访问性能减少磁盘IO，但是这个缓存区只会缓存索引，而不会缓存数据</li>
</ul>
<p><code>MyISAM</code> 表无法处理事务，这就意味着有事务处理需求的表，不能使用 <code>MyISAM</code> 存储引擎。<code>MyISAM</code> 存储引擎特别适合在以下几种情况下使用：</p>
<ul>
<li>选择密集型的表。MyISAM存储引擎在筛选大量数据时非常迅速，这是它最突出的优点。</li>
<li>插入密集型的表。MyISAM的并发插入特性允许同时选择和插入数据。例如：MyISAM存储引擎很适合管理邮件或Web服务器日志数据。</li>
</ul>
<h2 id="InnoDB"><a href="#InnoDB" class="headerlink" title="InnoDB"></a>InnoDB</h2><p><code>InnoDB</code> 是一个健壮的事务型存储引擎，这种存储引擎已经被很多互联网公司使用，为用户操作非常大的数据存储提供了一个强大的解决方案。<code>InnoDB</code> 是默认的存储引擎，<code>InnoDB</code> 还引入了行级锁定和外键约束。</p>
<p>有以下几点特点：</p>
<ol>
<li>具有较好的事务支持：支持4个事务隔离级别，支持多版本读</li>
<li>行级锁定：通过索引实现，全表扫描仍然会是表锁，注意间隙锁的影响</li>
<li>读写阻塞与事务隔离级别相关</li>
<li>具有非常高效的缓存特性：能缓存索引，也能缓存数据</li>
<li>整个表和主键以Cluster方式存储，组成一颗平衡树</li>
<li>所有Secondary Index都会保存主键信息</li>
</ol>
<p>在以下场合下，使用 <code>InnoDB</code> 是最理想的选择：</p>
<ol>
<li>更新密集的表。<code>InnoDB</code> 存储引擎特别适合处理多重并发的更新请求。</li>
<li>事务。<code>InnoDB</code> 存储引擎是支持事务的标准 MySQL 存储引擎。</li>
<li>自动灾难恢复。与其它存储引擎不同，<code>InnoDB</code> 表能够自动从灾难中恢复。</li>
<li>外键约束。MySQL支持外键的存储引擎只有 <code>InnoDB</code>。</li>
<li>支持自动增加列<code>AUTO_INCREMENT</code>属性。</li>
</ol>
<p>一般来说，如果需要事务支持，并且有较高的并发读取频率，<code>InnoDB</code> 是不错的选择。</p>
<h2 id="MEMORY"><a href="#MEMORY" class="headerlink" title="MEMORY"></a>MEMORY</h2><p>使用 MySQL <code>Memory</code> 存储引擎的出发点是速度。为得到最快的响应时间，采用的逻辑存储介质是系统<strong>内存</strong>。虽然在内存中存储表数据确实会提供很高的性能，但当 mysqid 守护进程崩溃时，所有的 <code>Memory</code> 数据都会丢失。获得速度的同时也带来了一些缺陷。它要求存储在 <code>Memory</code> 数据表里的数据使用的是长度不变的格式，这意味着不能使用 <code>BLOB</code> 和 <code>TEXT</code> 这样的长度可变的数据类型，<code>VARCHAR</code> 是一种长度可变的类型，但因为它在 MySQL 内部当做长度固定不变的 <code>CHAR</code> 类型，所以可以使用。</p>
<p>一般在以下几种情况下适用 <code>Memory</code> 存储引擎：</p>
<ol>
<li>目标数据较小，而且被非常频繁地访问。在内存中存放数据，所以会造成内存的使用，可以通过参数 <code>max_heap_table_size</code> 控制 <code>Memory</code> 表的大小，设置此参数，就可以限制 <code>Memory</code> 表的最大大小；</li>
<li>如果数据是临时的，而且要求必须立即可用，那么就可以存放在内存表中。</li>
<li>存储在 <code>Memory</code> 表中的数据如果突然丢失，不会对应用服务产生实质的负面影响。</li>
</ol>
<p><code>Memory</code> 同时支持散列索引和B树索引。B树索引的优于散列索引的是，可以使用部分查询和通配查询，也可以使用<code>&lt;</code>、<code>&gt;</code>和<code>&gt;=</code>等操作符方便数据挖掘。散列索引进行“相等比较”非常快，但是对“范围比较”的速度就慢多了，因此散列索引值适合使用在<code>=</code>和<code>&lt;&gt;</code>的操作符中，不适合在<code>&lt;</code>或<code>&gt;</code>操作符中，也同样不适合用在 <code>order by</code> 子句中。</p>
<p>可以在表创建时利用 <code>USING</code> 子句指定要使用的版本。</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">create</span> <span class="keyword">table</span> <span class="keyword">users</span></div><div class="line">(</div><div class="line">    <span class="keyword">id</span> <span class="built_in">smallint</span> <span class="keyword">unsigned</span> <span class="keyword">not</span> <span class="literal">null</span> auto_increment,</div><div class="line">    username <span class="built_in">varchar</span>(<span class="number">15</span>) <span class="keyword">not</span> <span class="literal">null</span>,</div><div class="line">    pwd <span class="built_in">varchar</span>(<span class="number">15</span>) <span class="keyword">not</span> <span class="literal">null</span>,</div><div class="line">    <span class="keyword">index</span> <span class="keyword">using</span> <span class="keyword">hash</span> (username),</div><div class="line">    primary <span class="keyword">key</span> (<span class="keyword">id</span>)</div><div class="line">)<span class="keyword">engine</span>=<span class="keyword">memory</span>;</div></pre></td></tr></table></figure>
<p>上述代码创建了一个表，在 <code>username</code> 字段上使用了 <code>HASH</code> 散列索引。下面的代码就创建一个表，使用 <code>BTREE</code> 索引。</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">create</span> <span class="keyword">table</span> <span class="keyword">users</span></div><div class="line">(</div><div class="line">    <span class="keyword">id</span> <span class="built_in">smallint</span> <span class="keyword">unsigned</span> <span class="keyword">not</span> <span class="literal">null</span> auto_increment,</div><div class="line">    username <span class="built_in">varchar</span>(<span class="number">15</span>) <span class="keyword">not</span> <span class="literal">null</span>,</div><div class="line">    pwd <span class="built_in">varchar</span>(<span class="number">15</span>) <span class="keyword">not</span> <span class="literal">null</span>,</div><div class="line">    <span class="keyword">index</span> <span class="keyword">using</span> btree (username),</div><div class="line">    primary <span class="keyword">key</span> (<span class="keyword">id</span>)</div><div class="line">)<span class="keyword">engine</span>=<span class="keyword">memory</span>;</div></pre></td></tr></table></figure>
<h2 id="MERGE"><a href="#MERGE" class="headerlink" title="MERGE"></a>MERGE</h2><p><code>MERGE</code> 存储引擎是一组 <code>MyISAM</code> 表的组合，这些 <code>MyISAM</code> 表结构必须完全相同，尽管其使用不如其它引擎突出，但是在某些情况下非常有用。说白了，<code>Merge</code> 表就是几个相同 <code>MyISAM</code> 表的聚合器；<code>Merge</code> 表中并没有数据，对 <code>Merge</code> 类型的表可以进行查询、更新、删除操作，这些操作实际上是对内部的 <code>MyISAM</code> 表进行操作。</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><table>
<thead>
<tr>
<th></th>
<th>特点</th>
<th>适用情况</th>
</tr>
</thead>
<tbody>
<tr>
<td>MyISAM</td>
<td>独立于操作系统的；不支持事务；表级锁定；</td>
<td>不需要事务支持；并发相对较低；  数据修改相对较少，以读为主；数据一致性要求不是非常高</td>
</tr>
<tr>
<td>InnoDB</td>
<td>事务性；行级锁定；外键约束；</td>
<td>需要事务支持；数据更新较为频繁；   数据一致性要求较高；行级锁定对高并发有很好的适应能力</td>
</tr>
<tr>
<td>MEMORY</td>
<td>存储内存里，数据容易丢失；性能高；存储的数据表要求数据类型长度不可变</td>
<td>数据小，但是可能会被频繁访问；数据是临时，并且立即可用；  可靠性不高的数据</td>
</tr>
</tbody>
</table>
<h1 id="数据库的索引结构"><a href="#数据库的索引结构" class="headerlink" title="数据库的索引结构"></a>数据库的索引结构</h1><p>在 MySQL 官方定义中，索引（ Index ）是帮助 MySQL 高效获取数据的数据结构。提取句子主干，就可以得到索引的本质：索引是数据结构。</p>
<p>在 MySQL 中，主要有四种类型的索引，分别为： B-Tree 索引， Hash 索引， Fulltext （全文）索引和 R-Tree 索引。</p>
<p>具体可以参考<a href="http://blog.codinglabs.org/articles/theory-of-mysql-index.html" target="_blank" rel="external">MySQL索引背后的数据结构及算法原理-张洋</a>一文，本文以后会把这部分给补充上。</p>
<p>关于数据库的索引结构还有一下几篇文章推荐：</p>
<ul>
<li><a href="http://database.51cto.com/art/201504/473322_all.htm" target="_blank" rel="external">为什么要用B+树结构——MySQL索引结构的实现</a></li>
<li><a href="http://ju.outofmemory.cn/entry/29124" target="_blank" rel="external">mysql索引原理之B+/-Tree</a></li>
<li><a href="http://blog.csdn.net/hguisu/article/details/7786014" target="_blank" rel="external">B-树和B+树的应用：数据搜索和数据库索引</a></li>
<li><a href="http://www.2cto.com/database/201404/295109.html" target="_blank" rel="external">2014阿里实习生面试题——mysql如何实现索引的</a></li>
</ul>
<hr>
<p>参考</p>
<ul>
<li><a href="http://2627lounuo.blog.51cto.com/10696599/1787812" target="_blank" rel="external">数据库之——索引、触发器、事务（存储引擎）</a></li>
<li><a href="http://www.jellythink.com/archives/640" target="_blank" rel="external">MySQL存储引擎介绍</a></li>
<li><a href="http://blog.codinglabs.org/articles/theory-of-mysql-index.html" target="_blank" rel="external">MySQL索引背后的数据结构及算法原理-张洋</a></li>
<li><a href="http://www.hollischuang.com/archives/943" target="_blank" rel="external">深入分析事务的隔离级别</a></li>
</ul>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[TCP的三次握手和四次挥手]]></title>
      <url>http://matt33.com/2016/08/30/http-protocol/</url>
      <content type="html"><![CDATA[<p>TCP/IP 协议在计算机网络中是非常重要的部分，本文主要是简单介绍其中的 TCP 协议和 IP 协议，也会涉及一些在面试中经常遇到的问题。</p>
<h1 id="TCP-IP-协议"><a href="#TCP-IP-协议" class="headerlink" title="TCP/IP 协议"></a>TCP/IP 协议</h1><p>在最项目开发中，经常会遇到各种协议，互联网基础通信框架就是 TCP/IP。TCP/IP 是个协议族，可分为四个层次：网络接口层（连接层）、网络层、传输层和应用层。</p>
<p>可以这样理解它们的作用：</p>
<ol>
<li>连接层负责建立电路连接，是整个网络的物理基础，典型的协议包括以太网、Wi-Fi、MPLS 等；</li>
<li>网络层负责分配地址和传送二进制数据，主要协议是IP协议，也有 ICMP 协议、ARP 协议、RARP 协议和 BOOTP 协议；</li>
<li>传输层负责传送文本数据，主要协议是 TCP 协议与 UDP 协议；</li>
<li>应用层负责传送各种最终形态的数据，是直接与用户打交道的层，典型协议是 FTP、HTTP、TELNET、SMTP、DNS 等。</li>
</ol>
<h1 id="TCP协议"><a href="#TCP协议" class="headerlink" title="TCP协议"></a>TCP协议</h1><h2 id="特点"><a href="#特点" class="headerlink" title="特点"></a>特点</h2><ul>
<li>TCP提供一种面向连接的、可靠的字节流服务</li>
<li>在一个TCP连接中，仅有两方进行彼此通信。广播和多播不能用于TCP</li>
<li>TCP使用校验和，确认和重传机制来保证可靠传输</li>
<li>TCP使用累积确认</li>
<li>TCP使用滑动窗口机制来实现流量控制，通过动态改变窗口的大小进行拥塞控制</li>
</ul>
<h2 id="三次握手"><a href="#三次握手" class="headerlink" title="三次握手"></a>三次握手</h2><p>所谓三次握手(Three-way Handshake)，是指建立一个 TCP 连接时，需要客户端和服务器总共发送3个包。三次握手的目的是连接服务器指定端口，建立 TCP 连接，并同步连接双方的序列号和确认号，交换 TCP 窗口大小信息。</p>
<p>TCP 连接三次握手四次挥手（下小节介绍）如下图所示（图片来自<a href="http://www.jellythink.com/archives/705" target="_blank" rel="external">简析TCP的三次握手与四次分手</a>）</p>
<p><img src="/images/computebase/tcp.jpg" alt="tcp"></p>
<ol>
<li>第一次握手：建立连接<ul>
<li>客户端发送连接请求报文段，将 <code>SYN</code> 位置为1，<code>Sequence Number</code> 为 <code>x</code>；</li>
<li>然后，客户端进入 <code>SYN_SEND</code>状态，等待服务器的确认；</li>
</ul>
</li>
<li>第二次握手：服务器收到 <code>SYN</code> 报文段<ul>
<li>服务器收到客户端的 <code>SYN</code> 报文段，需要对这个 <code>SYN</code> 报文段进行确认，设置 <code>Acknowledgment Number</code> 为 <code>x+1</code> (<code>Sequence Number+1</code>)；</li>
<li>同时，自己自己还要发送 <code>SYN</code> 请求信息，将 <code>SYN</code> 位置为1，<code>Sequence Number</code> 为<code>y</code>；服务器端将上述所有信息放到一个报文段（即 <code>SYN+ACK</code> 报文段）中，一并发送给客户端，此时服务器进入 <code>SYN_RECV</code> 状态；</li>
</ul>
</li>
<li>第三次握手：客户端收到服务器的 <code>SYN+ACK</code> 报文段<ul>
<li>将 <code>Acknowledgment Number</code> 设置为<code>y+1</code>，向服务器发送 <code>ACK</code> 报文段，这个报文段发送完毕以后，客户端和服务器端都进入 <code>ESTABLISHED</code> 状态，完成 TCP 三次握手。</li>
</ul>
</li>
</ol>
<p>完成了三次握手，客户端和服务器端就可以开始传送数据。</p>
<h3 id="为什么需要三次握手"><a href="#为什么需要三次握手" class="headerlink" title="为什么需要三次握手"></a>为什么需要三次握手</h3><p>既然总结了TCP的三次握手，那为什么非要三次呢？怎么觉得两次就可以完成了。那TCP为什么非要进行三次连接呢？在谢希仁的《计算机网络》中是这样说的：</p>
<blockquote>
<p>为了防止已失效的连接请求报文段突然又传送到了服务端，因而产生错误。</p>
</blockquote>
<p>在书中同时举了一个例子，如下：</p>
<blockquote>
<p>“已失效的连接请求报文段”的产生在这样一种情况下：client发出的第一个连接请求报文段并没有丢失，而是在某个网络结点长时间的滞留了，以致延误到连接释放以后的某个时间才到达server。本来这是一个早已失效的报文段。但server收到此失效的连接请求报文段后，就误认为是client再次发出的一个新的连接请求。于是就向client发出确认报文段，同意建立连接。假设不采用“三次握手”，那么只要server发出确认，新的连接就建立了。由于现在client并没有发出建立连接的请求，因此不会理睬server的确认，也不会向server发送数据。但server却以为新的运输连接已经建立，并一直等待client发来数据。这样，server的很多资源就白白浪费掉了。采用“三次握手”的办法可以防止上述现象发生。例如刚才那种情况，client不会向server的确认发出确认。server由于收不到确认，就知道client并没有要求建立连接。”</p>
</blockquote>
<p>这就很明白了，防止了服务器端的一直等待而浪费资源。</p>
<h2 id="四次挥手"><a href="#四次挥手" class="headerlink" title="四次挥手"></a>四次挥手</h2><p>示意图如上图所示。</p>
<p>当客户端和服务器通过三次握手建立了 TCP 连接以后，当数据传送完毕，肯定是要断开 TCP 连接的，这时候 TCP 采用的是四次挥手。</p>
<ol>
<li>第一次挥手<ul>
<li>主机1（可以使客户端，也可以是服务器端），设置 <code>Sequence Number</code> 和 <code>Acknowledgment Number</code>，向主机2发送一个 <code>FIN</code> 报文段；</li>
<li>此时，主机1进入 <code>FIN_WAIT_1</code> 状态；这表示主机1没有数据要发送给主机2了；</li>
</ul>
</li>
<li>第二次挥手<ul>
<li>主机2收到了主机1发送的 <code>FIN</code> 报文段，向主机1回一个 <code>ACK</code> 报文段，<code>Acknowledgment Number</code> 为 <code>Sequence Number</code> 加1；</li>
<li>主机1进入 <code>FIN_WAIT_2</code> 状态；</li>
<li>主机2告诉主机1，我“同意”你的关闭请求；</li>
</ul>
</li>
<li>第三次挥手<ul>
<li>主机2向主机1发送 <code>FIN</code> 报文段，请求关闭连接;</li>
<li>同时主机2进入 <code>LAST_ACK</code> 状态；</li>
</ul>
</li>
<li>第四次挥手<ul>
<li>主机1收到主机2发送的 <code>FIN</code> 报文段，向主机2发送 <code>ACK</code> 报文段，然后主机1进入 <code>TIME_WAIT</code> 状态；</li>
<li>主机2收到主机1的 <code>ACK</code> 报文段以后，就关闭连接；</li>
<li>此时，主机1等待 2MSL 后依然没有收到回复，则证明 Server 端已正常关闭，那好，主机1也可以关闭连接了。</li>
</ul>
</li>
</ol>
<h3 id="为什么需要四次挥手"><a href="#为什么需要四次挥手" class="headerlink" title="为什么需要四次挥手"></a>为什么需要四次挥手</h3><p>那四次分手又是为何呢？TCP 协议是一种面向连接的、可靠的、基于字节流的运输层通信协议。TCP 是全双工模式，这就意味着，当主机1发出 <code>FIN</code> 报文段时，只是表示主机1已经没有数据要发送了，主机1告诉主机2，它的数据已经全部发送完毕了；但是，这个时候主机1还是可以接受来自主机2的数据；当主机2返回 <code>ACK</code> 报文段时，表示它已经知道主机1没有数据发送了，但是主机2还是可以发送数据到主机1的；当主机2也发送了 <code>FIN</code> 报文段时，这个时候就表示主机2也没有数据要发送了，就会告诉主机1，我也没有数据要发送了，之后彼此就会愉快的中断这次 TCP 连接。如果要正确的理解四次分手的原理，就需要了解四次分手过程中的状态变化。</p>
<ol>
<li><code>FIN_WAIT_1</code>: 这个状态要好好解释一下，其实 <code>FIN_WAIT_1</code> 和 <code>FIN_WAIT_2</code> 状态的真正含义都是表示等待对方的 <code>FIN</code> 报文。而这两种状态的区别是：<code>FIN_WAIT_1</code> 状态实际上是当 SOCKET 在 <code>ESTABLISHED</code> 状态时，它想主动关闭连接，向对方发送了 <code>FIN</code> 报文，此时该 SOCKET 即进入到 <code>FIN_WAIT_1</code> 状态。而当对方回应 <code>ACK</code> 报文后，则进入到 <code>FIN_WAIT_2</code> 状态，当然在实际的正常情况下，无论对方何种情况下，都应该马上回应 <code>ACK</code> 报文，所以 <code>FIN_WAIT_1</code> 状态一般是比较难见到的，而 <code>FIN_WAIT_2</code> 状态还有时常常可以用 <code>netstat</code>看到。（主动方）</li>
<li><code>FIN_WAIT_2</code>：上面已经详细解释了这种状态，实际上 <code>FIN_WAIT_2</code> 状态下的 SOCKET，表示<strong>半连接</strong>，也即有一方要求 close 连接，但另外还告诉对方，我暂时还有点数据需要传送给你( <code>ACK</code> 信息)，稍后再关闭连接。（主动方）</li>
<li><code>CLOSE_WAIT</code>：这种状态的含义其实是表示在等待关闭。怎么理解呢？当对方 close 一个 SOCKET 后发送 <code>FIN</code> 报文给自己，你系统毫无疑问地会回应一个 <code>ACK</code> 报文给对方，此时则进入到 <code>CLOSE_WAIT</code> 状态。接下来呢，实际上你真正需要考虑的事情是察看你是否还有数据发送给对方，如果没有的话，那么你也就可以 close 这个 SOCKET，发送 <code>FIN</code> 报文给对方，也即关闭连接。所以你在 <code>CLOSE_WAIT</code> 状态下，需要完成的事情是等待你去关闭连接。（被动方）</li>
<li><code>LAST_ACK</code>: 这个状态还是比较容易好理解的，它是被动关闭一方在发送 <code>FIN</code> 报文后，最后等待对方的 ACK 报文。当收到 ACK 报文后，也即可以进入到 <code>CLOSED</code> 可用状态了。（被动方）</li>
<li><code>TIME_WAIT</code>: 表示收到了对方的 <code>FIN</code> 报文，并发送出了 ACK 报文，就等 2MSL 后即可回到 <code>CLOSED</code> 可用状态了。如果 <code>FINWAIT1</code> 状态下，收到了对方同时带 <code>FIN</code> 标志和 ACK 标志的报文时，可以直接进入到 <code>TIME_WAIT</code> 状态，而无须经过 <code>FIN_WAIT_2</code> 状态。（主动方）</li>
<li><code>CLOSED</code>: 表示连接中断。</li>
</ol>
<h2 id="TCP-重传机制"><a href="#TCP-重传机制" class="headerlink" title="TCP 重传机制"></a>TCP 重传机制</h2><p>这部分可以参考<a href="http://coolshell.cn/articles/11609.html" target="_blank" rel="external">TCP 的那些事儿（下）</a>一文。</p>
<h2 id="SYN攻击"><a href="#SYN攻击" class="headerlink" title="SYN攻击"></a>SYN攻击</h2><h3 id="什么是-SYN-攻击（SYN-Flood）？"><a href="#什么是-SYN-攻击（SYN-Flood）？" class="headerlink" title="什么是 SYN 攻击（SYN Flood）？"></a>什么是 SYN 攻击（SYN Flood）？</h3><p>在三次握手过程中，服务器发送 <code>SYN-ACK</code> 之后，收到客户端的 <code>ACK</code> 之前的 TCP 连接称为半连接(half-open connect)。此时服务器处于 <code>SYN_RCVD</code> 状态。当收到 ACK 后，服务器才能转入 <code>ESTABLISHED</code> 状态.</p>
<p>SYN 攻击指的是，攻击客户端在短时间内伪造大量不存在的IP地址，向服务器不断地发送 <code>SYN</code> 包，服务器回复确认包，并等待客户的确认。由于源地址是不存在的，服务器需要不断的重发直至超时，这些伪造的 <code>SYN</code> 包将长时间占用未连接队列，正常的 <code>SYN</code> 请求被丢弃，导致目标系统运行缓慢，严重者会引起网络堵塞甚至系统瘫痪。</p>
<p><code>SYN</code> 攻击是一种典型的 <code>DoS/DDoS</code> 攻击。</p>
<h3 id="如何检测-SYN-攻击？"><a href="#如何检测-SYN-攻击？" class="headerlink" title="如何检测 SYN 攻击？"></a>如何检测 SYN 攻击？</h3><p>检测 <code>SYN</code> 攻击非常的方便，当你在服务器上看到大量的半连接状态时，特别是源IP地址是随机的，基本上可以断定这是一次 <code>SYN</code> 攻击。在 Linux/Unix 上可以使用系统自带的 <code>netstats</code> 命令来检测 <code>SYN</code> 攻击。</p>
<h3 id="如何防御-SYN-攻击？"><a href="#如何防御-SYN-攻击？" class="headerlink" title="如何防御 SYN 攻击？"></a>如何防御 SYN 攻击？</h3><p><code>SYN</code> 攻击不能完全被阻止，除非将 TCP 协议重新设计。我们所做的是尽可能的减轻 <code>SYN</code> 攻击的危害，常见的防御 <code>SYN</code> 攻击的方法有如下几种：</p>
<ul>
<li>缩短超时（SYN Timeout）时间</li>
<li>增加最大半连接数</li>
<li>过滤网关防护</li>
<li>SYN cookies技术</li>
</ul>
<h2 id="常见面试题"><a href="#常见面试题" class="headerlink" title="常见面试题"></a>常见面试题</h2><h3 id="TCP-与-UDP-的区别？"><a href="#TCP-与-UDP-的区别？" class="headerlink" title="TCP 与 UDP 的区别？"></a>TCP 与 UDP 的区别？</h3><ol>
<li>TCP是面向连接的、可靠的、有序的、速度慢的协议；UDP是无连接的、不可靠的、无序的、速度快的协议。</li>
<li>TCP开销比UDP大，TCP头部需要20字节，UDP头部只要8个字节。</li>
<li>TCP无界有拥塞控制，TCP有界无拥塞控制。</li>
</ol>
<p>补充：</p>
<ul>
<li>基于TCP的协议有：HTTP/HTTPS，Telnet，FTP，SMTP。</li>
<li>基于UDP的协议有：DHCP，DNS，SNMP，TFTP，BOOTP。</li>
</ul>
<table>
<thead>
<tr>
<th></th>
<th>TCP</th>
<th>UDP</th>
</tr>
</thead>
<tbody>
<tr>
<td>特点</td>
<td>面向连接；可靠；开销大</td>
<td>无连接；不可靠；效率高；可靠性由应用层负责</td>
</tr>
</tbody>
</table>
<h3 id="三次握手过程及其原因"><a href="#三次握手过程及其原因" class="headerlink" title="三次握手过程及其原因"></a>三次握手过程及其原因</h3><p>如上面所述</p>
<h3 id="四次挥手及其原因"><a href="#四次挥手及其原因" class="headerlink" title="四次挥手及其原因"></a>四次挥手及其原因</h3><p>如上面所述</p>
<h1 id="TCP-拥塞控制"><a href="#TCP-拥塞控制" class="headerlink" title="TCP 拥塞控制"></a>TCP 拥塞控制</h1><p>这部分可以参考<a href="http://coolshell.cn/articles/11609.html" target="_blank" rel="external">TCP 的那些事儿（下）</a>一文。</p>
<hr>
<p>参考：</p>
<ul>
<li><a href="http://www.ruanyifeng.com/blog/2009/03/tcp-ip_model.html" target="_blank" rel="external">TCP/IP模型的一个简单解释</a></li>
<li><a href="http://www.jellythink.com/archives/705" target="_blank" rel="external">简析TCP的三次握手与四次分手</a></li>
<li><a href="https://hit-alibaba.github.io/interview/basic/network/TCP.html" target="_blank" rel="external">TCP 协议</a></li>
<li><a href="http://coolshell.cn/articles/11564.html" target="_blank" rel="external">TCP 的那些事儿（上）</a></li>
<li><a href="http://coolshell.cn/articles/11609.html" target="_blank" rel="external">TCP 的那些事儿（下）</a></li>
</ul>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[Java 并发学习（一）]]></title>
      <url>http://matt33.com/2016/08/21/java-concurrency/</url>
      <content type="html"><![CDATA[<p>本文主要是根据华黎的《大型网站系统与Java中间件实践》和 <a href="http://www.jasongj.com/categories/java/" target="_blank" rel="external">Jason</a> 的几篇博客，对 Java 并发方面的内容做的一些总结，会着重讲述并发方面一些常见的类、接口和方法。</p>
<h1 id="多线程编程"><a href="#多线程编程" class="headerlink" title="多线程编程"></a>多线程编程</h1><p>对于多线程编程，线程安全是我们首先要考虑的问题，关于线程安全有三个核心概念：原子性、可见性和顺序性，这三个概念需要先理解清楚。</p>
<h2 id="三个核心概念"><a href="#三个核心概念" class="headerlink" title="三个核心概念"></a>三个核心概念</h2><h3 id="原子性"><a href="#原子性" class="headerlink" title="原子性"></a>原子性</h3><p>与数据库中事务的原子性概念相似，即对于一个操作（有可能包含有多个子操作）要么全部执行，要么全部都不执行。</p>
<p>关于原子性，最经典的例子就是银行转账问题：比如A和B同时向C转账10万元。如果转账操作不具有原子性，A在向C转账时，读取了C的余额为20万，然后加上转账的10万，计算出此时应该有30万，但还未来及将30万写回C的账户，此时B的转账请求过来了，B发现C的余额为20万，然后将其加10万并写回。然后A的转账操作技术——将30万写回C的余额。这种情况下C的最终余额为30万，而非预期的40万。</p>
<h3 id="可见性"><a href="#可见性" class="headerlink" title="可见性"></a>可见性</h3><p>可见性是指，当多个线程并发访问共享变量时，一个线程对共享变量的修改，其它线程能够立即看到。可见性问题是好多人忽略或者理解错误的一点。</p>
<p>CPU从主内存中读数据的效率相对来说不高，现在主流的计算机中，都有几级缓存。每个线程读取共享变量时，都会将该变量加载进其对应CPU的高速缓存里，修改该变量后，CPU会立即更新该缓存，但并不一定会立即将其写回主内存（实际上写回主内存的时间不可预期）。此时其它线程（尤其是不在同一个CPU上执行的线程）访问该变量时，从主内存中读到的就是旧的数据，而非第一个线程更新后的数据。</p>
<p>这一点是操作系统或者说是硬件层面的机制，所以很多应用开发人员经常会忽略。</p>
<h3 id="顺序性"><a href="#顺序性" class="headerlink" title="顺序性"></a>顺序性</h3><p>顺序性指的是，程序执行的顺序按照代码的先后顺序执行。</p>
<p>以下面这段代码为例</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">boolean</span> started = <span class="keyword">false</span>; <span class="comment">// 语句1</span></div><div class="line"><span class="keyword">long</span> counter = <span class="number">0L</span>; <span class="comment">// 语句2</span></div><div class="line">counter = <span class="number">1</span>; <span class="comment">// 语句3</span></div><div class="line">started = <span class="keyword">true</span>; <span class="comment">// 语句4</span></div></pre></td></tr></table></figure>
<p>从代码顺序上看，上面四条语句应该依次执行，但实际上JVM真正在执行这段代码时，并不保证它们一定完全按照此顺序执行。</p>
<p>处理器为了提高程序整体的执行效率，可能会对代码进行优化，其中的一项优化方式就是调整代码顺序，按照更高效的顺序执行代码。</p>
<p>讲到这里，有人要着急了——什么，CPU不按照我的代码顺序执行代码，那怎么保证得到我们想要的效果呢？实际上，大家大可放心，CPU虽然并不保证完全按照代码顺序执行，但它会保证程序最终的执行结果和代码顺序执行时的结果一致。</p>
<h2 id="Java如何解决多线程并发问题"><a href="#Java如何解决多线程并发问题" class="headerlink" title="Java如何解决多线程并发问题"></a>Java如何解决多线程并发问题</h2><p>上面已经提出了这三个核心的概念，在 Java 多线程中，我们会经常遇到这三个概念引发的多线程并发问题，下面讲述一下 Java 如果解决这些问题。</p>
<h3 id="Java如何保证原子性"><a href="#Java如何保证原子性" class="headerlink" title="Java如何保证原子性"></a>Java如何保证原子性</h3><h4 id="锁和同步"><a href="#锁和同步" class="headerlink" title="锁和同步"></a>锁和同步</h4><p>常用的保证Java操作原子性的工具是<strong>锁</strong>和<strong>同步方法</strong>（或者同步代码块）。使用锁，可以保证同一时间只有一个线程能拿到锁，也就保证了同一时间只有一个线程能执行申请锁和释放锁之间的代码。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">testLock</span> <span class="params">()</span> </span>&#123;</div><div class="line">  lock.lock();</div><div class="line">  <span class="keyword">try</span>&#123;</div><div class="line">    <span class="keyword">int</span> j = i;</div><div class="line">    i = j + <span class="number">1</span>;</div><div class="line">  &#125; <span class="keyword">finally</span> &#123;</div><div class="line">    lock.unlock();</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>与锁类似的是同步方法或者同步代码块。使用非静态同步方法时，锁住的是当前实例；使用静态同步方法时，锁住的是该类的Class对象；使用静态代码块时，锁住的是synchronized关键字后面括号内的对象。下面是同步代码块示例</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">testLock</span> <span class="params">()</span> </span>&#123;</div><div class="line">  <span class="keyword">synchronized</span> (anyObject)&#123;</div><div class="line">    <span class="keyword">int</span> j = i;</div><div class="line">    i = j + <span class="number">1</span>;</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>无论使用锁还是synchronized，本质都是一样，通过锁来实现资源的排它性，从而实际目标代码段同一时间只会被一个线程执行，进而保证了目标代码段的原子性。这是一种以牺牲性能为代价的方法。（这一部分会后面详细讲述）</p>
<h4 id="CAS（compare-and-swap）"><a href="#CAS（compare-and-swap）" class="headerlink" title="CAS（compare and swap）"></a>CAS（compare and swap）</h4><p>基础类型变量自增（i++）是一种常被新手误以为是原子操作而实际不是的操作。Java中提供了对应的原子操作类来实现该操作，并保证原子性，其本质是利用了CPU级别的CAS指令。由于是CPU级别的指令，其开销比需要操作系统参与的锁的开销小。<code>AtomicInteger</code>使用方法如下。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">AtomicInteger atomicInteger = <span class="keyword">new</span> AtomicInteger();</div><div class="line"><span class="keyword">for</span>(<span class="keyword">int</span> b = <span class="number">0</span>; b &lt; numThreads; b++) &#123;</div><div class="line">  <span class="keyword">new</span> Thread(() -&gt; &#123;</div><div class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> a = <span class="number">0</span>; a &lt; iteration; a++) &#123;</div><div class="line">      atomicInteger.incrementAndGet();</div><div class="line">    &#125;</div><div class="line">  &#125;).start();</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h3 id="Java如何保证可见性"><a href="#Java如何保证可见性" class="headerlink" title="Java如何保证可见性"></a>Java如何保证可见性</h3><p>Java提供了<code>volatile</code>关键字来保证可见性。当使用volatile修饰某个变量时，它会保证对该变量的修改会立即被更新到内存中，并且将其它缓存中对该变量的缓存设置成无效，因此其它线程需要读取该值时必须从主内存中读取，从而得到最新的值。</p>
<h3 id="Java如何保证顺序性"><a href="#Java如何保证顺序性" class="headerlink" title="Java如何保证顺序性"></a>Java如何保证顺序性</h3><p>上文讲过编译器和处理器对指令进行重新排序时，会保证重新排序后的执行结果和代码顺序执行的结果一致，所以重新排序过程并不会影响单线程程序的执行，却可能影响多线程程序并发执行的正确性。</p>
<p>Java中可通过<code>volatile</code>在一定程序上保证顺序性，另外还可以通过<code>synchronized</code>和锁来保证顺序性。</p>
<p>synchronized和锁保证顺序性的原理和保证原子性一样，都是通过保证同一时间只会有一个线程执行目标代码段来实现的。</p>
<p>除了从应用层面保证目标代码段执行的顺序性外，JVM还通过被称为<strong>happens-before原则</strong>隐式的保证顺序性。两个操作的执行顺序只要可以通过happens-before推导出来，则JVM会保证其顺序性，反之JVM对其顺序性不作任何保证，可对其进行任意必要的重新排序以获取高效率。</p>
<h3 id="happens-before原则（先行发生原则）"><a href="#happens-before原则（先行发生原则）" class="headerlink" title="happens-before原则（先行发生原则）"></a>happens-before原则（先行发生原则）</h3><ul>
<li>传递规则：如果操作1在操作2前面，而操作2在操作3前面，则操作1肯定会在操作3前发生。该规则说明了happens-before原则具有传递性</li>
<li>锁定规则：一个unlock操作肯定会在后面对同一个锁的lock操作前发生。这个很好理解，锁只有被释放了才会被再次获取</li>
<li>volatile变量规则：对一个被volatile修饰的写操作先发生于后面对该变量的读操作</li>
<li>程序次序规则：一个线程内，按照代码顺序执行</li>
<li>线程启动规则：Thread对象的start()方法先发生于此线程的其它动作</li>
<li>线程终结原则：线程的终止检测后发生于线程中其它的所有操作</li>
<li>线程中断规则： 对线程interrupt()方法的调用先发生于对该中断异常的获取</li>
<li>对象终结规则：一个对象构造先于它的finalize发生</li>
</ul>
<h1 id="线程池"><a href="#线程池" class="headerlink" title="线程池"></a>线程池</h1><p>多核时代，面向多核编程就非常重要了，基于 java 的并发和多线程开发非常重要。与其每次需要时都创建线程相比，线程池可以降低创建线程的开销，线程池在线程执行结束后进行的是回收操作，而不是真正的销毁线程。</p>
<p>线程池的好处：</p>
<ol>
<li>降低资源消耗，通过重复利用已创建的线程降低线程创建和销毁造成的消耗；</li>
<li>提高响应速度，当任务到达时，任务可以不需要等到线程创建就能立即执行；</li>
<li>提高线程的可管理性，线程是稀缺资源，如果无限制的创建，不仅会消耗系统资源，还会降低系统的稳定性，使用线程池可以进行统一的分配，调优和监控。</li>
</ol>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> java.util.LinkedList;</div><div class="line"><span class="keyword">import</span> java.util.List;</div><div class="line"><span class="keyword">import</span> java.util.Random;</div><div class="line"><span class="keyword">import</span> java.util.concurrent.LinkedBlockingQueue;</div><div class="line"><span class="keyword">import</span> java.util.concurrent.ThreadPoolExecutor;</div><div class="line"><span class="keyword">import</span> java.util.concurrent.TimeUnit;</div><div class="line"></div><div class="line"><span class="comment">/**</span></div><div class="line"> * Created by matt on 16/8/8.</div><div class="line"> */</div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ThreadPoolExecutorDemo</span> </span>&#123;</div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">threadPoolTest</span><span class="params">(<span class="keyword">int</span> count)</span> </span>&#123;</div><div class="line">        <span class="keyword">long</span> startTime = System.currentTimeMillis();</div><div class="line">        <span class="keyword">final</span> List&lt;Integer&gt; list = <span class="keyword">new</span> LinkedList&lt;Integer&gt;();</div><div class="line">        ThreadPoolExecutor threadPoolExecutor = <span class="keyword">new</span> ThreadPoolExecutor(<span class="number">1</span>, <span class="number">1</span>, <span class="number">60</span>, TimeUnit.SECONDS, <span class="keyword">new</span> LinkedBlockingQueue&lt;Runnable&gt;(count));</div><div class="line">        <span class="keyword">final</span> Random random = <span class="keyword">new</span> Random();</div><div class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; count; i++) &#123;</div><div class="line">            threadPoolExecutor.execute(<span class="keyword">new</span> Runnable() &#123;</div><div class="line">                <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</div><div class="line">                    list.add(random.nextInt());</div><div class="line">                &#125;</div><div class="line">            &#125;);</div><div class="line">        &#125;</div><div class="line">        threadPoolExecutor.shutdown();</div><div class="line">        <span class="keyword">try</span> &#123;</div><div class="line">            threadPoolExecutor.awaitTermination(<span class="number">1</span>,TimeUnit.DAYS);</div><div class="line">        &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</div><div class="line">            e.printStackTrace();</div><div class="line">        &#125;</div><div class="line"></div><div class="line">        System.out.println(<span class="string">"ThreadPool demo runs "</span>+count+ <span class="string">" times, the total time of spending is: "</span>+(System.currentTimeMillis()-startTime));</div><div class="line">        System.out.println(list.size());</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">threadTest</span><span class="params">(<span class="keyword">int</span> count)</span> </span>&#123;</div><div class="line">        <span class="keyword">long</span> startTime = System.currentTimeMillis();</div><div class="line">        <span class="keyword">final</span> List&lt;Integer&gt; list = <span class="keyword">new</span> LinkedList&lt;Integer&gt;();</div><div class="line">        <span class="keyword">final</span> Random random = <span class="keyword">new</span> Random();</div><div class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; count; i++) &#123;</div><div class="line">            Thread thread=<span class="keyword">new</span> Thread()&#123;</div><div class="line">                <span class="meta">@Override</span></div><div class="line">                <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span></span>&#123;</div><div class="line">                    list.add(random.nextInt());</div><div class="line">                &#125;</div><div class="line">            &#125;;</div><div class="line">            thread.start();</div><div class="line">            <span class="keyword">try</span> &#123;</div><div class="line">                thread.join();</div><div class="line">            &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</div><div class="line">                e.printStackTrace();</div><div class="line">            &#125;</div><div class="line">        &#125;</div><div class="line">        System.out.println(<span class="string">"Thread demo runs "</span>+count+ <span class="string">" times, the total time of spending is: "</span>+(System.currentTimeMillis()-startTime));</div><div class="line">        System.out.println(list.size());</div><div class="line">    &#125;</div><div class="line"></div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</div><div class="line">        <span class="keyword">int</span> count=<span class="number">10000</span>;</div><div class="line">        threadPoolTest(count);</div><div class="line">        threadTest(count);</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>输出结果：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">ThreadPool demo runs 10000 <span class="built_in">times</span>, the total time of spending is: 66</div><div class="line">10000</div><div class="line">Thread demo runs 10000 <span class="built_in">times</span>, the total time of spending is: 1333</div><div class="line">10000</div></pre></td></tr></table></figure>
<p>从例子中，可以直接地看到，使用线程池能极大地提高程序的运行速度。</p>
<p>两种方式差别在于，使用线程池的方式是复用线程的，而不使用线程池的方式是每次都要创建线程的。不使用线程时消耗时间过多，主要是由于创建线程的开销占整个时间的比例比较大。还有另外两种线程池：</p>
<ul>
<li>newFixedThreadPool创建一个指定工作线程数量的线程池（固定数量的线程 ）。每当提交一个任务就创建一个工作线程，如果工作线程数量达到线程池初始的最大数，则将提交的任务存入到池队列中。</li>
<li>newCachedThreadPool创建一个可缓存的线程池（线程数量根据任务数量动态变化 ）。这种类型的线程池特点是：<ul>
<li>工作线程的创建数量几乎没有限制(其实也有限制的,数目为Interger. MAX_VALUE), 这样可灵活的往线程池中添加线程。</li>
<li>如果长时间没有往线程池中提交任务，即如果工作线程空闲了指定的时间(默认为1分钟)，则该工作线程将自动终止。终止后，如果你又提交了新的任务，则线程池重新创建一个工作线程。</li>
<li>该方法返回的线程池是没有线程上限的，因为没有办法去控制总体的线程数量，而每个线程都是消耗内存的，这可能会导致过多的内存被占用。</li>
</ul>
</li>
<li>newSingleThreadExecutor创建一个单线程化的Executor，即只创建唯一的工作者线程来执行任务，如果这个线程异常结束，会有另一个取代它，保证顺序执行(我觉得这点是它的特色)。单工作线程最大的特点是可保证顺序地执行各个任务，并且在任意给定的时间不会有多个线程是活动的 。</li>
<li>newScheduleThreadPool创建一个定长的线程池，而且支持定时的以及周期性的任务执行，类似于Timer。(这种线程池原理暂还没完全了解透彻)</li>
</ul>
<p>关于线程池内部原理部门可以看一下这两篇文章，未来也会把主要内容总结到博客里面</p>
<ul>
<li><a href="http://blog.csdn.net/mazhimazh/article/details/19243889" target="_blank" rel="external">Java 7之多线程线程池 - 线程池原理（1）</a></li>
<li><a href="http://blog.csdn.net/mazhimazh/article/details/19283171" target="_blank" rel="external">Java 7之多线程线程池 - 线程池原理（2）</a></li>
</ul>
<h1 id="synchronized"><a href="#synchronized" class="headerlink" title="synchronized"></a>synchronized</h1><p>每个Java对象都可以用做一个实现同步的互斥锁，这些锁被称为内置锁。线程进入同步代码块或方法时自动获得内置锁，退出同步代码块或方法时自动释放该内置锁。进入同步代码块或者同步方法是获得内置锁的唯一途径。</p>
<h2 id="实例同步方法"><a href="#实例同步方法" class="headerlink" title="实例同步方法"></a>实例同步方法</h2><p>synchronized用于修饰实例方法（非静态方法）时，执行该方法需要获得的是该类实例对象的内置锁（同一个类的不同实例拥有不同的内置锁）。如果多个实例方法都被synchronized修饰，则当多个线程调用同一实例的不同同步方法（或者同一方法）时，需要竞争锁。但当调用的是不同实例的方法时，并不需要竞争锁。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">SynchronizedDemo1</span></span>&#123;</div><div class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">synchronized</span> <span class="keyword">void</span> <span class="title">foo1</span><span class="params">()</span></span>&#123;</div><div class="line">	&#125;</div><div class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">synchronized</span> <span class="keyword">void</span> <span class="title">foo2</span><span class="params">()</span></span>&#123;</div><div class="line">	&#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p><code>foo1()</code> 和 <code>foo2()</code>是 <code>SynchronizedDemo1</code> 的两个成员方法，在多线程编程中，调用同一个对象的 <code>foo1()</code> 或者 <code>foo2()</code>是互斥的，这是针对同一个对象的多线程方法调用互斥。</p>
<h2 id="静态同步方法"><a href="#静态同步方法" class="headerlink" title="静态同步方法"></a>静态同步方法</h2><p>synchronized用于修饰静态方法时，执行该方法需要获得的是该类的class对象的内置锁（一个类只有唯一一个class对象）。调用同一个类的不同静态同步方法时会产生锁竞争。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">SynchronizedDemo2</span></span>&#123;</div><div class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">synchronized</span> <span class="keyword">void</span> <span class="title">foo3</span><span class="params">()</span></span>&#123;</div><div class="line">	&#125;</div><div class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">synchronized</span> <span class="keyword">void</span> <span class="title">foo4</span><span class="params">()</span></span>&#123;</div><div class="line">	&#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p><code>foo3()</code> 和 <code>foo4()</code>是 <code>SynchronizedDemo2</code> 类的两个静态方法。在不同的线程中，这两个方法的调用是互斥的，不仅它们之间，任何两个不同线程之间的调用也是互斥的。</p>
<h2 id="同步代码块"><a href="#同步代码块" class="headerlink" title="同步代码块"></a>同步代码块</h2><p>synchronized用于修饰代码块时，进入同步代码块需要获得synchronized关键字后面括号内的对象（可以是实例对象也可以是class对象）的内置锁。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">SynchronizedDemo3</span></span>&#123;</div><div class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">foo5</span><span class="params">()</span></span>&#123;</div><div class="line">		<span class="keyword">synchronized</span>(<span class="keyword">this</span>)&#123;</div><div class="line">		&#125;</div><div class="line">	&#125;</div><div class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">foo6</span><span class="params">()</span></span>&#123;</div><div class="line">		<span class="keyword">synchronized</span>(SynchronizedDemo3.class)&#123;</div><div class="line">		&#125;</div><div class="line">	&#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>在这个例子中，<code>synchronized(this)</code>与<code>SynchronizedDemo3</code>中加<code>synchronized</code>的成员方法是互斥的，而<code>synchronized(SynchronizedDemo3.class)</code>与<code>SynchronizedDemo3</code>加<code>synchronized</code>的静态方法是互斥的。</p>
<p><code>synchronized</code>用于修饰代码块会更加灵活，因为其后的参数可以是任意对象。</p>
<h2 id="synchronized使用总结"><a href="#synchronized使用总结" class="headerlink" title="synchronized使用总结"></a>synchronized使用总结</h2><p>锁的使用是为了操作临界资源的正确性，而往往一个方法中并非所有的代码都操作临界资源。换句话说，方法中的代码往往并不都需要同步。此时建议不使用同步方法，而使用同步代码块，只对操作临界资源的代码，也即需要同步的代码加锁。这样做的好处是，当一个线程在执行同步代码块时，其它线程仍然可以执行该方法内同步代码块以外的部分，充分发挥多线程并发的优势，从而相较于同步整个方法而言提升性能。</p>
<p>释放Java内置锁的唯一方式是synchronized方法或者代码块执行结束。若某一线程在synchronized方法或代码块内发生死锁，则对应的内置锁无法释放，其它线程也无法获取该内置锁（即进入跟该内置锁相关的synchronized方法或者代码块）。</p>
<h1 id="ReentrantLock"><a href="#ReentrantLock" class="headerlink" title="ReentrantLock"></a>ReentrantLock</h1><p>ReentrantLock是<code>java.util.concurrent.locks</code>中的一个类，是从 JDK5开始加入的，与 synchronized 用法类似，不过它需要显式地进行 unlock。Java中的重入锁（即ReentrantLock）与Java内置锁一样，是一种排它锁。使用synchronized的地方一定可以用ReentrantLock代替。</p>
<p>重入锁需要显示请求获取锁，并显示释放锁。为了避免获得锁后，没有释放锁，而造成其它线程无法获得锁而造成死锁，一般建议将释放锁操作放在finally块里，如下所示。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">try</span>&#123;</div><div class="line">  renentrantLock.lock();</div><div class="line">  <span class="comment">// 用户操作</span></div><div class="line">&#125; <span class="keyword">finally</span> &#123;</div><div class="line">  renentrantLock.unlock();</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>如果重入锁已经被其它线程持有，则当前线程的lock操作会被阻塞。除了lock()方法之外，重入锁（或者说锁接口）还提供了其它获取锁的方法以实现不同的效果。</p>
<ol>
<li><code>lockInterruptibly()</code>：该方法尝试获取锁，若获取成功立即返回；若获取不成功则阻塞等待。与lock方法不同的是，在阻塞期间，如果当前线程被打断（interrupt）则该方法抛出<code>InterruptedException</code>。该方法提供了一种解除死锁的途径。</li>
<li><code>tryLock()</code>：该方法试图获取锁，若该锁当前可用，则该方法立即获得锁并立即返回true；若锁当前不可用，则立即返回false。该方法不会阻塞，并提供给用户对于成功获利锁与获取锁失败进行不同操作的可能性。</li>
<li><code>tryLock(long time, TimeUnit unit)</code>：该方法试图获得锁，若该锁当前可用，则立即获得锁并立即返回true。若锁当前不可用，则等待相应的时间（由该方法的两个参数决定）：1）若该时间内锁可用，则获得锁，并返回true；2）若等待期间当前线程被打断，则抛出InterruptedException；3）若等待时间结束仍未获得锁，则返回false。</li>
</ol>
<p>重入锁可定义为公平锁或非公平锁，默认实现为非公平锁。</p>
<ol>
<li>公平锁是指多个线程获取锁被阻塞的情况下，锁变为可用时，最新申请锁的线程获得锁。可通过在重入锁（RenentrantLock）的构造方法中传入true构建公平锁，如<code>Lock lock = new RenentrantLock(true)</code>；</li>
<li>非公平锁是指多个线程等待锁的情况下，锁变为可用状态时，哪个线程获得锁是随机的。synchonized相当于非公平锁。可通过在重入锁的构造方法中传入false或者使用无参构造方法构建非公平锁。效率相对高一点。</li>
</ol>
<h2 id="ReentrantReadWriteLock-读写锁"><a href="#ReentrantReadWriteLock-读写锁" class="headerlink" title="ReentrantReadWriteLock 读写锁"></a>ReentrantReadWriteLock 读写锁</h2><p>这个主要用于读多写少并且读不需要互斥的场景，这样场景使用读写锁会比使用全部互斥的锁性能高出很多，<code>ReentrantReadWriteLock</code>通过<code>readLock()</code>和<code>writeLock()</code>两个方法获取读锁和写锁。</p>
<p>实际上，<code>ReadWriteLock</code>接口并非继承自Lock接口，<code>ReentrantReadWriteLock</code>也只实现了<code>ReadWriteLock</code>接口而未实现Lock接口。<code>ReadLock()</code>和<code>WriteLock()</code>，是<code>ReentrantReadWriteLock</code>类的静态内部类，它们实现了Lock接口。</p>
<p>一个<code>ReentrantReadWriteLock</code>实例包含一个<code>ReentrantReadWriteLock.ReadLock</code>实例和一个<code>ReentrantReadWriteLock.WriteLock</code>实例。通过<code>readLock()</code>和<code>writeLock()</code>方法可分别获得读锁实例和写锁实例，并通过Lock接口提供的获取锁方法获得对应的锁。</p>
<p>读写锁的锁定规则如下：</p>
<ul>
<li>获得读锁后，其它线程可获得读锁而不能获取写锁</li>
<li>获得写锁后，其它线程既不能获得读锁也不能获得写锁</li>
</ul>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">package</span> com.test.thread;</div><div class="line"></div><div class="line"><span class="keyword">import</span> java.util.Date;</div><div class="line"><span class="keyword">import</span> java.util.concurrent.locks.Lock;</div><div class="line"><span class="keyword">import</span> java.util.concurrent.locks.ReadWriteLock;</div><div class="line"><span class="keyword">import</span> java.util.concurrent.locks.ReentrantReadWriteLock;</div><div class="line"></div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ReadWriteLockDemo</span> </span>&#123;</div><div class="line"></div><div class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</div><div class="line">    ReadWriteLock readWriteLock = <span class="keyword">new</span> ReentrantReadWriteLock();</div><div class="line"></div><div class="line">    <span class="keyword">new</span> Thread(() -&gt; &#123;</div><div class="line">      readWriteLock.readLock().lock();</div><div class="line">      <span class="keyword">try</span> &#123;</div><div class="line">        System.out.println(<span class="keyword">new</span> Date() + <span class="string">"\tThread 1 started with read lock"</span>);</div><div class="line">        <span class="keyword">try</span> &#123;</div><div class="line">          Thread.sleep(<span class="number">2000</span>);</div><div class="line">        &#125; <span class="keyword">catch</span> (Exception ex) &#123;</div><div class="line">        &#125;</div><div class="line">        System.out.println(<span class="keyword">new</span> Date() + <span class="string">"\tThread 1 ended"</span>);</div><div class="line">      &#125; <span class="keyword">finally</span> &#123;</div><div class="line">        readWriteLock.readLock().unlock();</div><div class="line">      &#125;</div><div class="line">    &#125;).start();</div><div class="line"></div><div class="line">    <span class="keyword">new</span> Thread(() -&gt; &#123;</div><div class="line">      readWriteLock.readLock().lock();</div><div class="line">      <span class="keyword">try</span> &#123;</div><div class="line">        System.out.println(<span class="keyword">new</span> Date() + <span class="string">"\tThread 2 started with read lock"</span>);</div><div class="line">        <span class="keyword">try</span> &#123;</div><div class="line">          Thread.sleep(<span class="number">2000</span>);</div><div class="line">        &#125; <span class="keyword">catch</span> (Exception ex) &#123;</div><div class="line">        &#125;</div><div class="line">        System.out.println(<span class="keyword">new</span> Date() + <span class="string">"\tThread 2 ended"</span>);</div><div class="line">      &#125; <span class="keyword">finally</span> &#123;</div><div class="line">        readWriteLock.readLock().unlock();</div><div class="line">      &#125;</div><div class="line">    &#125;).start();</div><div class="line"></div><div class="line">    <span class="keyword">new</span> Thread(() -&gt; &#123;</div><div class="line">      Lock lock = readWriteLock.writeLock();</div><div class="line">      lock.lock();</div><div class="line">      <span class="keyword">try</span> &#123;</div><div class="line">        System.out.println(<span class="keyword">new</span> Date() + <span class="string">"\tThread 3 started with write lock"</span>);</div><div class="line">        <span class="keyword">try</span> &#123;</div><div class="line">          Thread.sleep(<span class="number">2000</span>);</div><div class="line">        &#125; <span class="keyword">catch</span> (Exception ex) &#123;</div><div class="line">          ex.printStackTrace();</div><div class="line">        &#125;</div><div class="line">        System.out.println(<span class="keyword">new</span> Date() + <span class="string">"\tThread 3 ended"</span>);</div><div class="line">      &#125; <span class="keyword">finally</span> &#123;</div><div class="line">        lock.unlock();</div><div class="line">      &#125;</div><div class="line">    &#125;).start();</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>输出：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">Sat Jun 18 21:33:46 CST 2016  Thread 1 started with <span class="built_in">read</span> lock</div><div class="line">Sat Jun 18 21:33:46 CST 2016  Thread 2 started with <span class="built_in">read</span> lock</div><div class="line">Sat Jun 18 21:33:48 CST 2016  Thread 2 ended</div><div class="line">Sat Jun 18 21:33:48 CST 2016  Thread 1 ended</div><div class="line">Sat Jun 18 21:33:48 CST 2016  Thread 3 started with write lock</div><div class="line">Sat Jun 18 21:33:50 CST 2016  Thread 3 ended</div></pre></td></tr></table></figure>
<p>从上面的执行结果可见，thread 1和thread 2都只需获得读锁，因此它们可以并行执行。而thread 3因为需要获取写锁，必须等到thread 1和thread 2释放锁后才能获得锁。</p>
<h1 id="volatitle"><a href="#volatitle" class="headerlink" title="volatitle"></a>volatitle</h1><p><code>synchronized</code>保证了一个线程中变量的可见性，而<code>volatile</code>则是保证了所修饰变量的可见性（可见性可以参考前面所述）。<code>volatile</code>是轻量级的实现变量可见性的方法，其具体使用也很简单。</p>
<p>对于同一个变量线程间的可见性与多个线程中操作互斥是两件事情，操作互斥是提供了操作整体的原子性，下面通过一个例子来看。</p>
<h2 id="读"><a href="#读" class="headerlink" title="读"></a>读</h2><p>对于读操作来说，示例如下</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">int</span> i1;</div><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">getI1</span><span class="params">()</span></span>&#123;</div><div class="line">    <span class="keyword">return</span> i1;</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="keyword">volatile</span> <span class="keyword">int</span> i2;</div><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">getI2</span><span class="params">()</span></span>&#123;</div><div class="line">    <span class="keyword">return</span> i2;</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="keyword">int</span> i3;</div><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">synchronized</span> <span class="keyword">int</span> <span class="title">getI3</span><span class="params">()</span></span>&#123;</div><div class="line">    <span class="keyword">return</span> i3;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>分析一下这三种情况：</p>
<ol>
<li><code>getI1()</code>：该方法调用获取的是当前线程中的副本，这个值不一定是最新的值；</li>
<li><code>getI2()</code>：因为 i2 是被<code>volatile</code>修饰，因此对于 JVM 来说，这个变量不会又线程的本地副本，只会放在主存中，所以得到的值一定是最新的；</li>
<li><code>getI3()</code>：因为有<code>synchronized</code>关键字修饰，保证了线程的本地副本与主存的同步，所以也会得到最新的值。</li>
</ol>
<h2 id="写"><a href="#写" class="headerlink" title="写"></a>写</h2><p>再对比一下它们的写操作</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">int</span> i1;</div><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setI1</span><span class="params">(<span class="keyword">int</span> i)</span> </span>&#123;</div><div class="line">    i1 = i;</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="keyword">volatile</span> <span class="keyword">int</span> i2;</div><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setI2</span><span class="params">(<span class="keyword">int</span> i)</span> </span>&#123;</div><div class="line">    i2 = i;</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="keyword">int</span> i3;</div><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">synchronized</span> <span class="keyword">void</span> <span class="title">setI3</span><span class="params">(<span class="keyword">int</span> i)</span> </span>&#123;</div><div class="line">    i3 = <span class="number">1</span>;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>分析一下这三种情况：</p>
<ol>
<li><code>setI1()</code>：当前线程调用之后会得到最新的 i1 值，而另外的线程获取不一定可以立刻看到最新而值；</li>
<li><code>setI2()</code>：可以立刻在其他线程看到新的值，因为<code>volatile</code>保证了只有一份主存中的数据；</li>
<li><code>setI3()</code>：调用后必须在<code>synchronized</code>修饰的方法或代码中读取 i3 的值才可以看到最新值，因为<code>synchronized</code>不仅会把当前线程修改的本地副本同步给主存，还会从主存读取数据更新本地副本。</li>
</ol>
<h2 id="volatile适用场景"><a href="#volatile适用场景" class="headerlink" title="volatile适用场景"></a>volatile适用场景</h2><p>因为<code>volatile</code>只是保证了同一个变量在多线程中的可见性，所以它更多是用于修饰作为开关状态的变量。</p>
<p>volatile适用于不需要保证原子性，但却需要保证可见性的场景。一种典型的使用场景是用它修饰用于停止线程的状态标记。如下所示</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">boolean</span> isRunning = <span class="keyword">true</span>;</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">start</span> <span class="params">()</span> </span>&#123;</div><div class="line">  <span class="keyword">new</span> Thread( () -&gt; &#123;</div><div class="line">    <span class="keyword">while</span>(isRunning) &#123;</div><div class="line">      someOperation();</div><div class="line">    &#125;</div><div class="line">  &#125;).start();</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">stop</span> <span class="params">()</span> </span>&#123;</div><div class="line">  isRunning = <span class="keyword">false</span>;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>在这种实现方式下，即使其它线程通过调用<code>stop()</code>方法将<code>isRunning</code>设置为<code>false</code>，循环也不一定会立即结束。可以通过<code>volatile</code>关键字，保证<code>while</code>循环及时得到<code>isRunning</code>最新的状态从而及时停止循环，结束线程。</p>
<h1 id="Atomics"><a href="#Atomics" class="headerlink" title="Atomics"></a>Atomics</h1><p>在 JDK5 中增加了<code>java.util.concurrent.atomic</code>包，这个包是一些以<code>Atomic</code>开头的类，这些类主要提供一些相关的原子操作。</p>
<p>以<code>AtomicInteger</code>为例来看一个多线程计数器的场景，场景很简单，就是让多个线程都对计数器进行加1操作。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Counter1</span> </span>&#123;</div><div class="line">    <span class="keyword">private</span> <span class="keyword">int</span> counter = <span class="number">0</span>;</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">increase</span><span class="params">()</span> </span>&#123;</div><div class="line">        <span class="keyword">synchronized</span> (<span class="keyword">this</span>) &#123;</div><div class="line">            counter = counter + <span class="number">1</span>;</div><div class="line">            <span class="keyword">return</span> counter;</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">decrease</span><span class="params">()</span> </span>&#123;</div><div class="line">        <span class="keyword">synchronized</span> (<span class="keyword">this</span>) &#123;</div><div class="line">            counter = counter - <span class="number">1</span>;</div><div class="line">            <span class="keyword">return</span> counter;</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>在采用了<code>AtomicInteger</code>之后，代码就会变成下面这个样子：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Counter2</span> </span>&#123;</div><div class="line">    <span class="keyword">private</span> AtomicInteger counter = <span class="keyword">new</span> AtomicInteger();</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">increase</span><span class="params">()</span> </span>&#123;</div><div class="line">        <span class="keyword">return</span> counter.incrementAndGet();</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">decrease</span><span class="params">()</span> </span>&#123;</div><div class="line">        <span class="keyword">return</span> counter.decrementAndGet();</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>采用<code>AtomicInteger</code>之后代码变得简洁了，更重要的是性能得到了提升，而且还比较明显的提升，原因是<code>AtomicInteger</code>内部通过 JNI 的方式使用了硬件支持的 CAS 指令。</p>
<h1 id="wait、notify-和-notifyAll"><a href="#wait、notify-和-notifyAll" class="headerlink" title="wait、notify 和 notifyAll"></a>wait、notify 和 notifyAll</h1><p>wait、notify 和 notifyAll 是 java Object 对象上的三个方法，也就是所有的Java类都可以调用这三个方法。</p>
<p>在多线程情况下，可以把某个对象作为事件对象，通过这个对象的 wait、notify 和 notifyAll方法来完成线程间的状态通知，三个方法的作用如下：</p>
<ul>
<li>wait：是当前线程进行等待；</li>
<li>notify：是唤醒同一个对象 wait 方法的线程，但是只是唤醒一个等待线程；</li>
<li>notifyAll：是唤醒同一个对象 wait 方法的线程，唤醒所有的等待线程。</li>
</ul>
<p>注意：</p>
<p>wait方法需要释放锁，前提条件是它已经持有锁。所以wait和notify（或者<code>notifyAll</code>）方法都必须被包裹在<code>synchronized</code>语句块中，并且<code>synchronized</code>后锁的对象应该与调用<code>wait</code>方法的对象一样。否则抛出<code>IllegalMonitorStateException</code>.</p>
<p>wait 与 sleep 的区别</p>
<ul>
<li>wait：它是在当前线程持有 wait 对象锁的情况下，暂时放弃锁，并让出 CPU 资源，并积极等待其它线程调用同一对象的 notify 或者 notifyAll 方法。换言之，即使notify被调用，但只要锁没有被释放，原等待线程因为未获得锁仍然无法继续执行。</li>
<li>sleep：它告诉操作系统至少指定时间内不需为线程调度器为该线程分配执行时间片，并不释放锁（如果当前已经持有锁）。</li>
</ul>
<h1 id="线程间通信"><a href="#线程间通信" class="headerlink" title="线程间通信"></a>线程间通信</h1><h2 id="CountDownLatch"><a href="#CountDownLatch" class="headerlink" title="CountDownLatch"></a>CountDownLatch</h2><p><code>CountDownLatch</code>是<code>java.util.concurrent</code>包中的一个类，<code>CountDownLatch</code>主要提供的机制是当多个线程达到了预期状态或完成预期工作时触发事件，其他线程可以等待这个事件来触发自己后续的工作。需要注意的是，等待线程可以是多个，即 CountDownLatch 是可以唤醒多个等待的线程的。达到自己预期状态的线程会调用<code>CountDownLatch</code>的<code>countDown</code>方法，而等待线程会调用<code>CountDownLatch</code>的<code>wait</code>方法。</p>
<p>如果<code>CountDownLatch</code>初始化的 count 值为1，那么这就变成了单一事件了，即由一个线程来通知其他线程，效果等同于对象的<code>wait</code>和<code>notifyAll</code>。count 值大于1是常用的方式，目的是让多个线程达到各自的预期状态，变为一个事件进行通知，线程则继续自己的行为。</p>
<h3 id="CountDownLatch适用场景"><a href="#CountDownLatch适用场景" class="headerlink" title="CountDownLatch适用场景"></a>CountDownLatch适用场景</h3><p>Java多线程编程中经常会碰到这样一种场景——某个线程需要等待一个或多个线程操作结束（或达到某种状态）才开始执行。比如开发一个并发测试工具时，主线程需要等到所有测试线程均执行完成再开始统计总共耗费的时间，此时可以通过<code>CountDownLatch</code>轻松实现。</p>
<h3 id="CountDownLatch实例"><a href="#CountDownLatch实例" class="headerlink" title="CountDownLatch实例"></a>CountDownLatch实例</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">package</span> countdownlatch;</div><div class="line"></div><div class="line"><span class="keyword">import</span> java.util.Date;</div><div class="line"><span class="keyword">import</span> java.util.concurrent.CountDownLatch;</div><div class="line"></div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">CountDownLatchDemo</span> </span>&#123;</div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> InterruptedException </span>&#123;</div><div class="line">        <span class="keyword">int</span> totalThread = <span class="number">3</span>;</div><div class="line">        <span class="keyword">long</span> start = System.currentTimeMillis();</div><div class="line">        <span class="keyword">final</span> CountDownLatch countDown = <span class="keyword">new</span> CountDownLatch(totalThread);</div><div class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; totalThread; i++) &#123;</div><div class="line">            <span class="keyword">final</span> String threadName = <span class="string">"Thread "</span> + i;</div><div class="line">            Thread thread=<span class="keyword">new</span> Thread() &#123;</div><div class="line">                    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</div><div class="line">                        System.out.println(String.format(<span class="string">"%s\t%s %s"</span>, <span class="keyword">new</span> Date(), threadName, <span class="string">"started"</span>));</div><div class="line">                        <span class="keyword">try</span> &#123;</div><div class="line">                            Thread.sleep(<span class="number">1000</span>);</div><div class="line">                        &#125; <span class="keyword">catch</span> (Exception ex) &#123;</div><div class="line">                            ex.printStackTrace();</div><div class="line">                        &#125;</div><div class="line">                        countDown.countDown();</div><div class="line">                        System.out.println(String.format(<span class="string">"%s\t%s %s"</span>, <span class="keyword">new</span> Date(), threadName, <span class="string">"ended"</span>));</div><div class="line">                    &#125;</div><div class="line">            &#125;;</div><div class="line">            thread.start();</div><div class="line">        &#125;</div><div class="line">        countDown.await();</div><div class="line">        <span class="keyword">long</span> stop = System.currentTimeMillis();</div><div class="line">        System.out.println(String.format(<span class="string">"Total time : %sms"</span>, (stop - start)));</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>执行结果</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">Tue Aug 09 14:44:19 CST 2016	Thread 0 started</div><div class="line">Tue Aug 09 14:44:19 CST 2016	Thread 2 started</div><div class="line">Tue Aug 09 14:44:19 CST 2016	Thread 1 started</div><div class="line">Tue Aug 09 14:44:20 CST 2016	Thread 2 ended</div><div class="line">Tue Aug 09 14:44:20 CST 2016	Thread 1 ended</div><div class="line">Tue Aug 09 14:44:20 CST 2016	Thread 0 ended</div><div class="line">Total time : 1029ms</div></pre></td></tr></table></figure>
<p>可以看到，主线程等待所有3个线程都执行结束后才开始执行。</p>
<h3 id="CountDownLatch主要接口分析"><a href="#CountDownLatch主要接口分析" class="headerlink" title="CountDownLatch主要接口分析"></a>CountDownLatch主要接口分析</h3><p>CountDownLatch工作原理相对简单，可以简单看成一个倒计时器，在构造方法中指定初始值，每次调用countDown()方法时讲计数器减1，而await()会等待计数器变为0。CountDownLatch关键接口如下</p>
<ul>
<li>countDown() 如果当前计数器的值大于1，则将其减1；若当前值为1，则将其置为0并唤醒所有通过await等待的线程；若当前值为0，则什么也不做直接返回。</li>
<li>await() 等待计数器的值为0，若计数器的值为0则该方法返回；若等待期间该线程被中断，则抛出InterruptedException并清除该线程的中断状态。</li>
<li>await(long timeout, TimeUnit unit) 在指定的时间内等待计数器的值为0，若在指定时间内计数器的值变为0，则该方法返回true；若指定时间内计数器的值仍未变为0，则返回false；若指定时间内计数器的值变为0之前当前线程被中断，则抛出InterruptedException并清除该线程的中断状态。</li>
<li>getCount() 读取当前计数器的值，一般用于调试或者测试。</li>
</ul>
<h2 id="CyclicBarrier"><a href="#CyclicBarrier" class="headerlink" title="CyclicBarrier"></a>CyclicBarrier</h2><h3 id="CyclicBarrier适用场景"><a href="#CyclicBarrier适用场景" class="headerlink" title="CyclicBarrier适用场景"></a>CyclicBarrier适用场景</h3><p>CyclicBarrier，从字面理解是指循环屏障，CyclicBarrier可以在构造时指定需要在屏障前执行await的个数，所有对await的调用都会等待，只到调用await的次数达到预定指，所有等待都会立即被唤醒。</p>
<p>从使用场景上来说，CyclicBarrier是让多个线程互相等待某一事件的发生，然后同时被唤醒。而上文讲的CountDownLatch是让某一线程等待多个线程的状态，然后该线程被唤醒。</p>
<h3 id="CyclicBarrier实例"><a href="#CyclicBarrier实例" class="headerlink" title="CyclicBarrier实例"></a>CyclicBarrier实例</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">package</span> cyclicbarrier;</div><div class="line"></div><div class="line"><span class="keyword">import</span> java.util.Date;</div><div class="line"><span class="keyword">import</span> java.util.concurrent.CyclicBarrier;</div><div class="line"></div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">CyclicBarrierDemo</span> </span>&#123;</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</div><div class="line">        <span class="keyword">int</span> totalThread = <span class="number">5</span>;</div><div class="line">        <span class="keyword">final</span> CyclicBarrier barrier = <span class="keyword">new</span> CyclicBarrier(totalThread);</div><div class="line"></div><div class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; totalThread; i++) &#123;</div><div class="line">            <span class="keyword">final</span> String threadName = <span class="string">"Thread "</span> + i;</div><div class="line">            Thread thread=<span class="keyword">new</span> Thread()&#123;</div><div class="line">                <span class="meta">@Override</span></div><div class="line">                <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</div><div class="line">                    System.out.println(String.format(<span class="string">"%s\t%s %s"</span>, <span class="keyword">new</span> Date(), threadName, <span class="string">" is waiting"</span>));</div><div class="line">                    <span class="keyword">try</span> &#123;</div><div class="line">                        barrier.await();</div><div class="line">                    &#125; <span class="keyword">catch</span> (Exception ex) &#123;</div><div class="line">                        ex.printStackTrace();</div><div class="line">                    &#125;</div><div class="line">                    System.out.println(String.format(<span class="string">"%s\t%s %s"</span>, <span class="keyword">new</span> Date(), threadName, <span class="string">"ended"</span>));</div><div class="line">                &#125;</div><div class="line">            &#125;;</div><div class="line">            thread.start();</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>执行结果如下<br><figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">Tue Aug 09 18:54:39 CST 2016	Thread 4  is waiting</div><div class="line">Tue Aug 09 18:54:39 CST 2016	Thread 0  is waiting</div><div class="line">Tue Aug 09 18:54:39 CST 2016	Thread 3  is waiting</div><div class="line">Tue Aug 09 18:54:39 CST 2016	Thread 2  is waiting</div><div class="line">Tue Aug 09 18:54:39 CST 2016	Thread 1  is waiting</div><div class="line">Tue Aug 09 18:54:39 CST 2016	Thread 4 ended</div><div class="line">Tue Aug 09 18:54:39 CST 2016	Thread 1 ended</div><div class="line">Tue Aug 09 18:54:39 CST 2016	Thread 2 ended</div><div class="line">Tue Aug 09 18:54:39 CST 2016	Thread 0 ended</div><div class="line">Tue Aug 09 18:54:39 CST 2016	Thread 3 ended</div></pre></td></tr></table></figure></p>
<p>从执行结果可以看到，每个线程都不会在其它所有线程执行<code>await()</code>方法前继续执行，而等所有线程都执行<code>await()</code>方法后所有线程的等待都被唤醒从而继续执行。</p>
<h3 id="CyclicBarrier主要接口分析"><a href="#CyclicBarrier主要接口分析" class="headerlink" title="CyclicBarrier主要接口分析"></a>CyclicBarrier主要接口分析</h3><p>CyclicBarrier提供的关键方法如下</p>
<ul>
<li>await()：等待其它参与方的到来（调用await()）。如果当前调用是最后一个调用，则唤醒所有其它的线程的等待并且如果在构造CyclicBarrier时指定了action，当前线程会去执行该action，然后该方法返回该线程调用await的次序（getParties()-1说明该线程是第一个调用await的，0说明该线程是最后一个执行await的），接着该线程继续执行await后的代码；如果该调用不是最后一个调用，则阻塞等待；如果等待过程中，当前线程被中断，则抛出InterruptedException；如果等待过程中，其它等待的线程被中断，或者其它线程等待超时，或者该barrier被reset，或者当前线程在执行barrier构造时注册的action时因为抛出异常而失败，则抛出BrokenBarrierException。</li>
<li>await(long timeout, TimeUnit unit)：与await()唯一的不同点在于设置了等待超时时间，等待超时时会抛出TimeoutException。</li>
<li>reset()：该方法会将该barrier重置为它的初始状态，并使得所有对该barrier的await调用抛出BrokenBarrierException。</li>
</ul>
<h3 id="CountDownLatch-与-CyclicBarrier"><a href="#CountDownLatch-与-CyclicBarrier" class="headerlink" title="CountDownLatch 与 CyclicBarrier"></a>CountDownLatch 与 CyclicBarrier</h3><p><code>CountDownLatch</code> 与 <code>CyclicBarrier</code> 都是用于多个线程间的协调，二者的一个差别是：</p>
<ol>
<li><code>CountDownLatch</code>：它是在多个线程都进行了<code>latch.countDown</code>后才会触发事件，唤醒<code>await</code>在 latch 上的线程，而执行<code>countDown</code>的线程，执行完<code>countDown</code>后继续进行自己的工作，也就是说，<code>countDown</code>的线程会继续执行，而唤醒的是<code>await</code>的线程；</li>
<li><code>CyclicBarrier</code>：它是一个栅栏，用于同步所有调用<code>await</code>方法的线程，并且等待所有线程都到了<code>await</code>方法时，这些线程才一起返回继续各自的工作，因为使用<code>CyclicBarrier</code>的线程都会阻塞在<code>await</code>方法上，所以在线程池中使用<code>CyclicBarrier</code>时要特别小心，如果线程池的线程数过少，那么很容易发生死锁。</li>
</ol>
<h2 id="Phaser"><a href="#Phaser" class="headerlink" title="Phaser"></a>Phaser</h2><h3 id="Phaser适用场景"><a href="#Phaser适用场景" class="headerlink" title="Phaser适用场景"></a>Phaser适用场景</h3><p><code>CountDownLatch</code>和<code>CyclicBarrier</code>都是JDK 1.5引入的，而<code>Phaser</code>是JDK 1.7引入的。<code>Phaser</code>的功能与<code>CountDownLatch</code>和<code>CyclicBarrier</code>有部分重叠，同时也提供了更丰富的语义和更灵活的用法。</p>
<p><code>Phaser</code>顾名思义，与<strong>阶段</strong>相关。<code>Phaser</code>比较适合这样一种场景，一种任务可以分为多个阶段，现希望多个线程去处理该批任务，对于每个阶段，多个线程可以并发进行，但是希望保证只有前面一个阶段的任务完成之后才能开始后面的任务。这种场景可以使用多个CyclicBarrier来实现，每个CyclicBarrier负责等待一个阶段的任务全部完成。但是使用CyclicBarrier的缺点在于，需要明确知道总共有多少个阶段，同时并行的任务数需要提前预定义好，且无法动态修改。而Phaser可同时解决这两个问题。</p>
<h3 id="Phaser实例"><a href="#Phaser实例" class="headerlink" title="Phaser实例"></a>Phaser实例</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">package</span> phaser;</div><div class="line"></div><div class="line"><span class="keyword">import</span> java.io.IOException;</div><div class="line"><span class="keyword">import</span> java.util.concurrent.Phaser;</div><div class="line"></div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">PhaserDemo</span> </span>&#123;</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> IOException </span>&#123;</div><div class="line">        <span class="keyword">int</span> parties = <span class="number">3</span>;</div><div class="line">        <span class="keyword">final</span> <span class="keyword">int</span> phases = <span class="number">4</span>;</div><div class="line">        <span class="keyword">final</span> Phaser phaser = <span class="keyword">new</span> Phaser(parties) &#123;</div><div class="line">            <span class="meta">@Override</span></div><div class="line">            <span class="function"><span class="keyword">protected</span> <span class="keyword">boolean</span> <span class="title">onAdvance</span><span class="params">(<span class="keyword">int</span> phase, <span class="keyword">int</span> registeredParties)</span> </span>&#123;</div><div class="line">                System.out.println(<span class="string">"====== Phase : "</span> + phase + <span class="string">" ======"</span>);</div><div class="line">                <span class="keyword">return</span> registeredParties == <span class="number">0</span>;</div><div class="line">            &#125;</div><div class="line">        &#125;;</div><div class="line"></div><div class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; parties; i++) &#123;</div><div class="line">            <span class="keyword">final</span> <span class="keyword">int</span> threadId = i;</div><div class="line">            <span class="keyword">final</span> Thread thread = <span class="keyword">new</span> Thread() &#123;</div><div class="line">                <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</div><div class="line">                    <span class="keyword">for</span> (<span class="keyword">int</span> phase = <span class="number">0</span>; phase &lt; phases; phase++) &#123;</div><div class="line">                        System.out.println(String.format(<span class="string">"Thread %s, phase %s"</span>, threadId, phase));</div><div class="line">                        phaser.arriveAndAwaitAdvance();</div><div class="line">                    &#125;</div><div class="line">                &#125;</div><div class="line"></div><div class="line">            &#125;;</div><div class="line">            thread.start();</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>执行结果如下</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line">Thread 1, phase 0</div><div class="line">Thread 2, phase 0</div><div class="line">Thread 0, phase 0</div><div class="line">====== Phase : 0 ======</div><div class="line">Thread 0, phase 1</div><div class="line">Thread 2, phase 1</div><div class="line">Thread 1, phase 1</div><div class="line">====== Phase : 1 ======</div><div class="line">Thread 1, phase 2</div><div class="line">Thread 2, phase 2</div><div class="line">Thread 0, phase 2</div><div class="line">====== Phase : 2 ======</div><div class="line">Thread 1, phase 3</div><div class="line">Thread 2, phase 3</div><div class="line">Thread 0, phase 3</div><div class="line">====== Phase : 3 ======</div></pre></td></tr></table></figure>
<p>从上面的结果可以看到，多个线程必须等到其它线程的同一阶段的任务全部完成才能进行到下一个阶段，并且每当完成某一阶段任务时，Phaser都会执行其onAdvance方法。</p>
<h3 id="Phaser主要接口分析"><a href="#Phaser主要接口分析" class="headerlink" title="Phaser主要接口分析"></a>Phaser主要接口分析</h3><p>Phaser主要接口如下</p>
<ul>
<li>arriveAndAwaitAdvance()：当前线程当前阶段执行完毕，等待其它线程完成当前阶段。如果当前线程是该阶段最后一个未到达的，则该方法直接返回下一个阶段的序号（阶段序号从0开始），同时其它线程的该方法也返回下一个阶段的序号。</li>
<li>arriveAndDeregister()：该方法立即返回下一阶段的序号，并且其它线程需要等待的个数减一，并且把当前线程从之后需要等待的成员中移除。如果该Phaser是另外一个Phaser的子Phaser（层次化Phaser会在后文中讲到），并且该操作导致当前Phaser的成员数为0，则该操作也会将当前Phaser从其父Phaser中移除。</li>
<li>arrive()：该方法不作任何等待，直接返回下一阶段的序号。</li>
<li>awaitAdvance(int phase)：该方法等待某一阶段执行完毕。如果当前阶段不等于指定的阶段或者该Phaser已经被终止，则立即返回。该阶段数一般由arrive()方法或者arriveAndDeregister()方法返回。返回下一阶段的序号，或者返回参数指定的值（如果该参数为负数），或者直接返回当前阶段序号（如果当前Phaser已经被终止）。</li>
<li>awaitAdvanceInterruptibly(int phase)：效果与awaitAdvance(int phase)相当，唯一的不同在于若该线程在该方法等待时被中断，则该方法抛出InterruptedException。</li>
<li>awaitAdvanceInterruptibly(int phase, long timeout, TimeUnit unit)：效果与awaitAdvanceInterruptibly(int phase)相当，区别在于如果超时则抛出TimeoutException。</li>
<li>bulkRegister(int parties)：注册多个party。如果当前phaser已经被终止，则该方法无效，并返回负数。如果调用该方法时，onAdvance方法正在执行，则该方法等待其执行完毕。如果该Phaser有父Phaser则指定的party数大于0，且之前该Phaser的party数为0，那么该Phaser会被注册到其父Phaser中。</li>
<li>forceTermination()：强制让该Phaser进入终止状态。已经注册的party数不受影响。如果该Phaser有子Phaser，则其所有的子Phaser均进入终止状态。如果该Phaser已经处于终止状态，该方法调用不造成任何影响。</li>
</ul>
<h1 id="信号量-Semaphore"><a href="#信号量-Semaphore" class="headerlink" title="信号量 Semaphore"></a>信号量 Semaphore</h1><p>信号量维护一个许可集，构造时需要传入参数，总数就是控制并发的数量，在执行可通过<code>acquire()</code>获取许可（如果acquire 成功返回，Semaphore 可用的信号量就会减少一个，若无可用许可acquire 就会阻塞，等待有 release 释放信号后，acquire 才会得到信号并返回），通过<code>release()</code>释放许可，从而可能唤醒一个阻塞等待许可的线程。</p>
<p>与互斥锁类似，信号量限制了同一时间访问临界资源的线程的个数，并且信号量也分<strong>公平信号量</strong>与<strong>非公平信号量</strong>。而不同的是，互斥锁保证同一时间只会有一个线程访问临界资源，而信号量可以允许同一时间多个线程访问特定资源。所以信号量并不能保证原子性。</p>
<p>信号量的一个典型使用场景是限制系统访问量。每个请求进来后，处理之前都通过<code>acquire</code>获取许可，若获取许可成功则处理该请求，若获取失败则等待处理或者直接不处理该请求。</p>
<h2 id="信号量的使用方法"><a href="#信号量的使用方法" class="headerlink" title="信号量的使用方法"></a>信号量的使用方法</h2><ul>
<li>acquire(int permits)：申请permits（必须为非负数）个许可，若获取成功，则该方法返回并且当前可用许可数减permits；若当前可用许可数少于permits指定的个数，则继续等待可用许可数大于等于permits；若等待过程中当前线程被中断，则抛出InterruptedException；</li>
<li>acquire()：等价于acquire(1)；</li>
<li>acquireUninterruptibly(int permits)：申请permits（必须为非负数）个许可，若获取成功，则该方法返回并且当前可用许可数减permits；若当前许可数少于permits，则继续等待可用许可数大于等于permits；若等待过程中当前线程被中断，继续等待可用许可数大于等于permits，并且获取成功后设置线程中断状态；</li>
<li>acquireUninterruptibly()：等价于acquireUninterruptibly(1)；</li>
<li>drainPermits()：获取所有可用许可，并返回获取到的许可个数，该方法不阻塞；</li>
<li>tryAcquire(int permits)：尝试获取permits个可用许可，如果当前许可个数大于等于permits，则返回true并且可用许可数减permits；否则返回false并且可用许可数不变；</li>
<li>tryAcquire()：等价于tryAcquire(1)；</li>
<li>tryAcquire(int permits, long timeout, TimeUnit unit)：尝试获取permits（必须为非负数）个许可，若在指定时间内获取成功则返回true并且可用许可数减permits；若指定时间内当前线程被中断，则抛出InterruptedException；若指定时间内可用许可数均小于permits，则返回false；</li>
<li>tryAcquire(long timeout, TimeUnit unit)：等价于tryAcquire(1, long timeout, TimeUnit unit)；</li>
<li>release(int permits)：释放permits个许可，该方法不阻塞并且某线程调用release方法前并不需要先调用acquire方法；</li>
<li>release()：等价于release(1)。</li>
</ul>
<blockquote>
<p>注意：与<code>wait/notify</code>和<code>await/signal</code>不同，<code>acquire/release</code>完全与锁无关，因此<code>acquire</code>等待过程中，可用许可满足要求时<code>acquire</code>可立即返回，而不用像锁的<code>wait</code>和条件变量的<code>await</code>那样重新获取锁才能返回。或者可以理解成，只要可用许可满足需求，就已经获得了锁。</p>
</blockquote>
<p>如果<code>Semaphore</code>管理的信号量只有1个，那么就是互斥锁了；如果多于1个信号量，则主要用于控制并发数。</p>
<h1 id="Exchanger"><a href="#Exchanger" class="headerlink" title="Exchanger"></a>Exchanger</h1><p><code>Exchanger</code>从名字上来看，就是交换的意思，<code>Exchanger</code>用于在两个线程之间进行数据交换，线程会阻塞在Exchanger的<code>exchange</code>方法上，直到另外一个线程也到了同一个Exchanger的<code>exchange</code>方法时，二者进行交换，然后两个线程会继续执行自身相关的代码。</p>
<h2 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">package</span> exchanger;</div><div class="line"></div><div class="line"><span class="keyword">import</span> java.util.ArrayList;</div><div class="line"><span class="keyword">import</span> java.util.List;</div><div class="line"><span class="keyword">import</span> java.util.concurrent.Exchanger;</div><div class="line"></div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ExchangerDemo</span> </span>&#123;</div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</div><div class="line">        <span class="keyword">final</span> Exchanger&lt;List&lt;Integer&gt;&gt; exchanger = <span class="keyword">new</span> Exchanger&lt;List&lt;Integer&gt;&gt;();</div><div class="line">        <span class="keyword">new</span> Thread() &#123;</div><div class="line">            <span class="meta">@Override</span></div><div class="line">            <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</div><div class="line">                List&lt;Integer&gt; list = <span class="keyword">new</span> ArrayList&lt;Integer&gt;(<span class="number">2</span>);</div><div class="line">                list.add(<span class="number">1</span>);</div><div class="line">                list.add(<span class="number">2</span>);</div><div class="line">                <span class="keyword">try</span> &#123;</div><div class="line">                    list = exchanger.exchange(list);</div><div class="line">                &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</div><div class="line">                    e.printStackTrace();</div><div class="line">                &#125;</div><div class="line">                System.out.println(<span class="string">"Thread1"</span> + list);</div><div class="line">            &#125;</div><div class="line">        &#125;.start();</div><div class="line">        <span class="keyword">new</span> Thread()&#123;</div><div class="line">            <span class="meta">@Override</span></div><div class="line">            <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span></span>&#123;</div><div class="line">                List&lt;Integer&gt; list=<span class="keyword">new</span> ArrayList&lt;Integer&gt;(<span class="number">2</span>);</div><div class="line">                list.add(<span class="number">4</span>);</div><div class="line">                list.add(<span class="number">5</span>);</div><div class="line">                <span class="keyword">try</span> &#123;</div><div class="line">                    list=exchanger.exchange(list);</div><div class="line">                &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</div><div class="line">                    e.printStackTrace();</div><div class="line">                &#125;</div><div class="line">                System.out.println(<span class="string">"Thread2"</span> + list);</div><div class="line">            &#125;</div><div class="line">        &#125;.start();</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>运行结果</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">Thread2[1, 2]</div><div class="line">Thread1[4, 5]</div></pre></td></tr></table></figure>
<h1 id="Future-和-Future-Task"><a href="#Future-和-Future-Task" class="headerlink" title="Future 和 Future Task"></a>Future 和 Future Task</h1><p><code>Future</code>是一个接口，<code>Future Task</code>是一个具体实现类。</p>
<p>在实际开发的环境中，我们经常会遇到这样一种场景中，在一个函数中我们调用了一个函数，正常情况下，程序会在理阻塞，知道调用函数返回结果，而很多情况下返回的结果我们并不会马上使用，这样的话就浪费很多时间。我们期待的情况是：调用函数后马上返回，然后继续向下执行，等需要用数据时再来用，或者说再来等待这个数据，具体的实现方式有两种方式，一个是用<code>Future</code>，一个是用回调函数。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">Future&lt;HashMap&gt; future = getDataFromRemote2();</div><div class="line"><span class="comment">// do something</span></div><div class="line">HashMap data = (HashMap) future.get();</div></pre></td></tr></table></figure>
<p>可以看到，我们调用的方式返回的是一个 Future 对象，然后接着进行自己的处理，后面通过<code>future.get()</code>来获得真正的返回值。也就说，在调用了<code>getDataFromRemote2</code>后，就已经启动了对远程计算结果的获取，同时自己的线程还在继续处理，直到需要时再获取数据。我们先看一下<code>getDataFromRemote2</code>的实现：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">private</span> Future&lt;HashMap&gt; <span class="title">getDataFromRemote2</span><span class="params">()</span></span>&#123;</div><div class="line">	<span class="keyword">return</span> threadPool.submit(<span class="keyword">new</span> Callback&lt;HashMap&gt;()&#123;</div><div class="line">		<span class="function"><span class="keyword">public</span> HashMap <span class="title">call</span><span class="params">()</span> <span class="keyword">throws</span> Exception</span>&#123;</div><div class="line">			returngetDataFromRemote();</div><div class="line">		&#125;</div><div class="line">	&#125;);</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p><code>getDataFromRemote()</code>方法是从远程获取一些计算结果</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="function">HashMap <span class="title">getDataFromRemote</span><span class="params">()</span></span>;</div></pre></td></tr></table></figure>
<p><code>getDataFromRemote2</code>中使用了<code>getDataFromRemote</code>来完成具体操作，并且使用到了线程池，把任务添加到线程池中，把 Future 对象返回出去。我们调用了<code>getDataFromRemote2</code>的线程，然后回来继续下面的执行，而背后是另外的线程在进行远程调用及等待的工作。</p>
<h1 id="回调函数"><a href="#回调函数" class="headerlink" title="回调函数"></a>回调函数</h1><p>参考<a href="https://www.zhihu.com/question/19801131" target="_blank" rel="external">回调函数（callback）是什么?</a>。调用回调函数的函数这里称作中间函数，而调用中间函数的函数我们成为起始函数。回调函数是作为函数的参数传入到中间函数中，中间函数在运行时，在需要调用这个函数的地方就调用回调函数，并将结果返回给中间函数，中间函数再把处理后的结果返回给起始函数。</p>
<p>回调实际上有两种：阻塞式回调和延迟式回调。</p>
<ul>
<li>阻塞式回调里，回调函数的调用一定发生在起始函数返回之前；</li>
<li>延迟式回调里，回调函数的调用有可能是在起始函数返回之后。</li>
</ul>
<p>一般使用的回调函数都是阻塞式回调，而延迟式回调通常牵扯到多线程。</p>
<hr>
<p>参考：</p>
<ul>
<li><a href="http://item.jd.com/11449803.html" target="_blank" rel="external">大型网站系统与 Java 中间件实践</a></li>
<li><a href="http://www.jasongj.com/categories/java/" target="_blank" rel="external">Jason的博客：java 并发部分</a></li>
<li><a href="https://www.zhihu.com/question/19801131" target="_blank" rel="external">回调函数（callback）是什么?</a></li>
</ul>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[Kafka 0.10.0 SASL/PLAIN身份认证及权限实现]]></title>
      <url>http://matt33.com/2016/07/29/sasl-plain-kafka/</url>
      <content type="html"><![CDATA[<p>本文主要介绍一下使用官方发布的 Kafka 0.10.0 版如何实现 SASL/PLAIN 认证机制以及权限控制。</p>
<h1 id="Kafka-安全机制"><a href="#Kafka-安全机制" class="headerlink" title="Kafka 安全机制"></a>Kafka 安全机制</h1><p> Kafka 的安全机制主要分为两部分：</p>
<ul>
<li>身份认证（Authentication）：对client 与服务器的连接进行身份认证。</li>
<li>权限控制（Authorization）：实现对于消息级别的权限控制</li>
</ul>
<blockquote>
<p>In release 0.9.0.0, the Kafka community added a number of features that, used either separately or together, increases security in a Kafka cluster.<br>These features are considered to be of beta quality. The following security measures are currently supported:</p>
<ol>
<li>Authentication of connections to brokers from clients (producers and consumers), other brokers and tools, using either SSL or SASL (Kerberos). SASL/PLAIN can also be used from release 0.10.0.0 onwards.</li>
<li>Authentication of connections from brokers to ZooKeeper</li>
<li>Encryption of data transferred between brokers and clients, between brokers, or between brokers and tools using SSL (Note that there is a performance degradation when SSL is enabled, the magnitude of which depends on the CPU type and the JVM implementation.)</li>
<li>Authorization of read / write operations by clients</li>
<li>Authorization is pluggable and integration with external authorization services is supported</li>
</ol>
</blockquote>
<p>这段话的中文意思也就是说</p>
<ol>
<li>可以使用 SSL 或者 SASL 进行客户端（producer 和 consumer）、其他 brokers、tools与 brokers 之间连接的认证，SASL/PLAIN将在0.10.0中得到支持；</li>
<li>对brokers和zookeeper之间的连接进行Authentication；</li>
<li>数据传输用SSL加密，性能会下降；</li>
<li>对clients的读写操作进行Authorization；</li>
<li>Authorization 是pluggable，与外部的authorization services结合进行支持。</li>
</ol>
<h1 id="Kafka身份认证"><a href="#Kafka身份认证" class="headerlink" title="Kafka身份认证"></a>Kafka身份认证</h1><p>Kafka 目前支持SSL、SASL/Kerberos、SASL/PLAIN三种认证机制，关于这些认证机制的介绍可以参考一下三篇文章。</p>
<ul>
<li><a href="http://www.cnblogs.com/JeffreySun/archive/2010/06/24/1627247.html" target="_blank" rel="external">数字证书原理</a>;</li>
<li><a href="http://www.cnblogs.com/mailingfeng/archive/2012/07/18/2597392.html" target="_blank" rel="external">数字证书, 数字签名, SSL(TLS) , SASL</a>;</li>
<li><a href="http://www.ruanyifeng.com/blog/2014/09/ssl-latency.html" target="_blank" rel="external">SSL的延迟</a></li>
</ul>
<h2 id="SASL-PLAIN-认证"><a href="#SASL-PLAIN-认证" class="headerlink" title="SASL/PLAIN 认证"></a>SASL/PLAIN 认证</h2><p>可以参考<a href="http://orchome.com/270" target="_blank" rel="external">kafka使用SASL验证</a>，这个官方文档的中文版。</p>
<h3 id="Kafka-Server-端配置"><a href="#Kafka-Server-端配置" class="headerlink" title="Kafka Server 端配置"></a>Kafka Server 端配置</h3><p>需要在 Kafka 安装目录下的 <code>config/server.properties</code> 文件中配置以下信息</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">listeners=SASL_PLAINTEXT://ip:pot</div><div class="line">security.inter.broker.protocol=SASL_PLAINTEXT</div><div class="line">sasl.mechanism.inter.broker.protocol=PLAIN</div><div class="line">sasl.enabled.mechanisms=PLAIN</div><div class="line">authorizer.class.name = kafka.security.auth.SimpleAclAuthorizer</div><div class="line">super.users=User:admin</div></pre></td></tr></table></figure>
<p>如果要配置多个超级账户，可以按如下配置：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">super.users=User:admin;User:alice</div></pre></td></tr></table></figure>
<p>还需要配置一个名 <code>kafka_server_jaas.conf</code> 的配置文件，将配置文件放置在<code>conf</code>目录下。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">KafkaServer &#123;</div><div class="line">    org.apache.kafka.common.security.plain.PlainLoginModule required</div><div class="line">    username=&quot;admin&quot;</div><div class="line">    password=&quot;admin&quot;</div><div class="line">    user_admin=&quot;admin&quot;</div><div class="line">    user_alice=&quot;alice&quot;;</div><div class="line">&#125;;</div></pre></td></tr></table></figure>
<p>这里，我们配置了两个用户：admin 和 alice，密码分别为 admin 和 alice。<br>最后需要为 Kafka 添加 <code>java.security.auth.login.config</code> 环境变量。在 <code>bin/kafka-run-class.sh</code> 中添加以下内容</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">KAFKA_SASL_OPTS=<span class="string">'-Djava.security.auth.login.config=/opt/meituan/kafka_2.10-0.10.0.0/config/kafka_server_jaas.conf'</span></div><div class="line"><span class="comment"># Launch mode</span></div><div class="line"><span class="keyword">if</span> [ <span class="string">"x<span class="variable">$DAEMON_MODE</span>"</span> = <span class="string">"xtrue"</span> ]; <span class="keyword">then</span></div><div class="line">  nohup <span class="variable">$JAVA</span> <span class="variable">$KAFKA_HEAP_OPTS</span> <span class="variable">$KAFKA_JVM_PERFORMANCE_OPTS</span> <span class="variable">$KAFKA_GC_LOG_OPTS</span> <span class="variable">$KAFKA_SASL_OPTS</span> <span class="variable">$KAFKA_JMX_OPTS</span> <span class="variable">$KAFKA_LOG4J_OPTS</span> -cp <span class="variable">$CLASSPATH</span> <span class="variable">$KAFKA_OPTS</span> <span class="string">"<span class="variable">$@</span>"</span> &gt; <span class="string">"<span class="variable">$CONSOLE_OUTPUT_FILE</span>"</span> 2&gt;&amp;1 &lt; /dev/null &amp;</div><div class="line"><span class="keyword">else</span></div><div class="line">  <span class="built_in">exec</span> <span class="variable">$JAVA</span> <span class="variable">$KAFKA_HEAP_OPTS</span> <span class="variable">$KAFKA_JVM_PERFORMANCE_OPTS</span> <span class="variable">$KAFKA_GC_LOG_OPTS</span> <span class="variable">$KAFKA_SASL_OPTS</span> <span class="variable">$KAFKA_JMX_OPTS</span> <span class="variable">$KAFKA_LOG4J_OPTS</span> -cp <span class="variable">$CLASSPATH</span> <span class="variable">$KAFKA_OPTS</span> <span class="string">"<span class="variable">$@</span>"</span></div><div class="line"><span class="keyword">fi</span></div></pre></td></tr></table></figure>
<blockquote>
<p>注：实际上，我们只是添加了第一行，并在第4和第6行中添加了 $KAFKA_SASL_OPTS 这个环境变量。</p>
</blockquote>
<h3 id="KafkaClient-配置"><a href="#KafkaClient-配置" class="headerlink" title="KafkaClient 配置"></a>KafkaClient 配置</h3><p>首先需要在客户端配置 <code>kafka_client_jaas.conf</code> 文件</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">KafkaClient &#123;</div><div class="line">  org.apache.kafka.common.security.plain.PlainLoginModule required</div><div class="line">  username=&quot;alice&quot;</div><div class="line">  password=&quot;alice&quot;;</div><div class="line">&#125;;</div></pre></td></tr></table></figure>
<p>然后在（producer 和 consumer）程序中添加环境变量和配置，如下所示</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">System.setProperty(<span class="string">"java.security.auth.login.config"</span>, <span class="string">".../kafka_client_jaas.conf"</span>); <span class="comment">// 环境变量添加，需要输入配置文件的路径</span></div><div class="line">props.put(<span class="string">"security.protocol"</span>, <span class="string">"SASL_PLAINTEXT"</span>);</div><div class="line">props.put(<span class="string">"sasl.mechanism"</span>, <span class="string">"PLAIN"</span>);</div></pre></td></tr></table></figure>
<p>配置完以上内容后，就可以正常运行 producer 和 consumer 程序，如果账户密码错误的话，程序就不能正常进行，但是不会有任何提示，这方面后面会进行一些改进。</p>
<h1 id="Kafka权限控制"><a href="#Kafka权限控制" class="headerlink" title="Kafka权限控制"></a>Kafka权限控制</h1><p>这个小节介绍一下 Kafka 的 ACL 。</p>
<h2 id="权限的内容"><a href="#权限的内容" class="headerlink" title="权限的内容"></a>权限的内容</h2><table>
<thead>
<tr>
<th>权限</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>READ</td>
<td>读取topic</td>
</tr>
<tr>
<td>WRITE</td>
<td>写入topic</td>
</tr>
<tr>
<td>DELETE</td>
<td>删除topic</td>
</tr>
<tr>
<td>CREATE</td>
<td>创建topic</td>
</tr>
<tr>
<td>ALTER</td>
<td>修改topic</td>
</tr>
<tr>
<td>DESCRIBE</td>
<td>获取topic的信息</td>
</tr>
<tr>
<td>ClusterAction</td>
<td></td>
</tr>
<tr>
<td>ALL</td>
<td>所有权限</td>
</tr>
</tbody>
</table>
<p>访问控制列表ACL存储在zk上，路径为<code>/kafka-acl</code>。</p>
<h2 id="权限配置"><a href="#权限配置" class="headerlink" title="权限配置"></a>权限配置</h2><p>Kafka 提供的命令如下表所示</p>
<table>
<thead>
<tr>
<th>Option</th>
<th>Description</th>
<th>Default</th>
<th>Option type</th>
</tr>
</thead>
<tbody>
<tr>
<td>–add</td>
<td>Indicates to the script that user is trying to add an acl.</td>
<td></td>
<td>Action</td>
</tr>
<tr>
<td>–remove</td>
<td>Indicates to the script that user is trying to remove an acl.</td>
<td></td>
<td>Action</td>
</tr>
<tr>
<td>–list</td>
<td>Indicates to the script that user is trying to list acts.</td>
<td></td>
<td>Action</td>
</tr>
<tr>
<td>–authorizer</td>
<td>Fully qualified class name of the authorizer.</td>
<td>kafka.security.auth.SimpleAclAuthorizer</td>
<td>Configuration</td>
</tr>
<tr>
<td>–authorizer-properties</td>
<td>key=val pairs that will be passed to authorizer for initialization. For the default authorizer the example values are: zookeeper.connect=localhost:2181</td>
<td></td>
<td>Configuration</td>
</tr>
<tr>
<td>–cluster</td>
<td>Specifies cluster as resource.</td>
<td></td>
<td>Resource</td>
</tr>
<tr>
<td>–topic [topic-name]</td>
<td>Specifies the topic as resource.</td>
<td></td>
<td>Resource</td>
</tr>
<tr>
<td>–group [group-name]</td>
<td>Specifies the consumer-group as resource.</td>
<td></td>
<td>Resource</td>
</tr>
<tr>
<td>–allow-principal</td>
<td>Principal is in PrincipalType:name format that will be added to ACL with <strong>Allow</strong> permission. You can specify multiple –allow-principal in a single command.</td>
<td></td>
<td>Principal</td>
</tr>
<tr>
<td>–deny-principal</td>
<td>Principal is in PrincipalType:name format that will be added to ACL with <strong>Deny</strong> permission. You can specify multiple –deny-principal in a single command.</td>
<td></td>
<td>Principal</td>
</tr>
<tr>
<td>–allow-host</td>
<td>IP address from which principals listed in –allow-principal will have access.</td>
<td>if –allow-principal is specified defaults to * which translates to “all hosts”</td>
<td>Host</td>
</tr>
<tr>
<td>–deny-host</td>
<td>IP address from which principals listed in –deny-principal will be denied access.</td>
<td>if –deny-principal is specified defaults to * which translates to “all hosts”</td>
<td>Host</td>
</tr>
<tr>
<td>–operation</td>
<td>Operation that will be allowed or denied. Valid values are : Read, Write, Create, Delete, Alter, Describe, ClusterAction, All</td>
<td>All</td>
<td>Operation</td>
</tr>
<tr>
<td>–producer</td>
<td>Convenience option to add/remove acls for producer role. This will generate acls that allows WRITE, DESCRIBE on topic and CREATE on cluster.</td>
<td></td>
<td>Convenience</td>
</tr>
<tr>
<td>–consumer</td>
<td>Convenience option to add/remove acls for consumer role. This will generate acls that allows READ, DESCRIBE on topic and READ on consumer-group.</td>
<td></td>
<td>Convenience</td>
</tr>
</tbody>
</table>
<h2 id="权限设置"><a href="#权限设置" class="headerlink" title="权限设置"></a>权限设置</h2><p>通过几个例子介绍一下如何进行权限设置。</p>
<h3 id="add-操作"><a href="#add-操作" class="headerlink" title="add 操作"></a>add 操作</h3><figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 为用户 alice 在 test（topic）上添加读写的权限</span></div><div class="line">bin/kafka-acls.sh --authorizer-properties zookeeper.connect=data-rt-dev02:2181/kafka_test10 --add --allow-principal User:alice --operation Read --operation Write --topic <span class="built_in">test</span></div><div class="line"><span class="comment"># 对于 topic 为 test 的消息队列，拒绝来自 ip 为198.51.100.3账户为 BadBob  进行 read 操作，其他用户都允许</span></div><div class="line">bin/kafka-acls.sh --authorizer-properties zookeeper.connect=data-rt-dev02:2181/kafka_test10 --add --allow-principal User:* --allow-host * --deny-principal User:BadBob --deny-host 198.51.100.3 --operation Read --topic <span class="built_in">test</span></div><div class="line"><span class="comment"># 为bob 和 alice 添加all，以允许来自 ip 为198.51.100.0或者198.51.100.1的读写请求</span></div><div class="line">bin/kafka-acls.sh --authorizer-properties zookeeper.connect=data-rt-dev02:2181/kafka_test10 --add --allow-principal User:bob --allow-principal User:alice --allow-host 198.51.100.0 --allow-host 198.51.100.1 --operation Read --operation Write --topic <span class="built_in">test</span></div></pre></td></tr></table></figure>
<h3 id="list-操作"><a href="#list-操作" class="headerlink" title="list 操作"></a>list 操作</h3><figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 列出 topic 为 test 的所有权限账户</span></div><div class="line">bin/kafka-acls.sh --authorizer-properties zookeeper.connect=data-rt-dev02:2181/kafka_test10 --list --topic <span class="built_in">test</span></div></pre></td></tr></table></figure>
<p>输出信息为：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">Current ACLs <span class="keyword">for</span> resource `Topic:<span class="built_in">test</span>`:</div><div class="line">    User:alice has Allow permission <span class="keyword">for</span> operations: Describe from hosts: *</div><div class="line">    User:alice has Allow permission <span class="keyword">for</span> operations: Read from hosts: *</div><div class="line">    User:alice has Allow permission <span class="keyword">for</span> operations: Write from hosts: *</div></pre></td></tr></table></figure>
<h3 id="remove-操作"><a href="#remove-操作" class="headerlink" title="remove 操作"></a>remove 操作</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"># 移除 acl</div><div class="line">bin/kafka-acls.sh --authorizer-properties zookeeper.connect=data-rt-dev02:2181/kafka_test10 --remove --allow-principal User:Bob --allow-principal User:Alice --allow-host 198.51.100.0 --allow-host 198.51.100.1 --operation Read --operation Write --topic test</div></pre></td></tr></table></figure>
<h3 id="producer-和-consumer-的操作"><a href="#producer-和-consumer-的操作" class="headerlink" title="producer 和 consumer 的操作"></a>producer 和 consumer 的操作</h3><figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># producer</span></div><div class="line">bin/kafka-acls.sh --authorizer-properties zookeeper.connect=data-rt-dev02:2181/kafka_test10 --add --allow-principal User:alice --producer --topic <span class="built_in">test</span></div><div class="line"></div><div class="line"><span class="comment">#consumer</span></div><div class="line">bin/kafka-acls.sh --authorizer-properties zookeeper.connect=data-rt-dev02:2181/kafka_test10 --add --allow-principal User:alice --consumer --topic <span class="built_in">test</span> —group <span class="built_in">test</span>-group</div></pre></td></tr></table></figure>
<h1 id="填坑"><a href="#填坑" class="headerlink" title="填坑"></a>填坑</h1><p>本小节记录了在使用 SASL/PLAIN 时遇到的一些坑。</p>
<h2 id="Controller连接broker失败"><a href="#Controller连接broker失败" class="headerlink" title="Controller连接broker失败"></a>Controller连接broker失败</h2><p>错误信息如下：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div></pre></td><td class="code"><pre><div class="line">[2016-07-27 17:45:46,047] WARN [Controller-1-to-broker-1-send-thread], Controller 1<span class="string">'s connection to broker XXXX:9092 (id: 1 rack: null) was unsuccessful (kafka.controller.RequestSendThread)</span></div><div class="line">java.io.IOException: Connection to XXXX:9092 (id: 1 rack: null) failed</div><div class="line">    at kafka.utils.NetworkClientBlockingOps$$anonfun$blockingReady$extension$2.apply(NetworkClientBlockingOps.scala:63)</div><div class="line">    at kafka.utils.NetworkClientBlockingOps$$anonfun$blockingReady$extension$2.apply(NetworkClientBlockingOps.scala:59)</div><div class="line">    at kafka.utils.NetworkClientBlockingOps$.recursivePoll$1(NetworkClientBlockingOps.scala:112)</div><div class="line">    at kafka.utils.NetworkClientBlockingOps$.kafka$utils$NetworkClientBlockingOps$$pollUntil$extension(NetworkClientBlockingOps.scala:120)</div><div class="line">    at kafka.utils.NetworkClientBlockingOps$.blockingReady$extension(NetworkClientBlockingOps.scala:59)</div><div class="line">    at kafka.controller.RequestSendThread.brokerReady(ControllerChannelManager.scala:232)</div><div class="line">    at kafka.controller.RequestSendThread.liftedTree1$1(ControllerChannelManager.scala:181)</div><div class="line">    at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:180)</div><div class="line">    at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:63)</div><div class="line">[2016-07-27 17:45:46,056] INFO [delete-topics-thread-1], Starting  (kafka.controller.TopicDeletionManager$DeleteTopicsThread)</div><div class="line">[2016-07-27 17:45:46,057] DEBUG [Topic Deletion Manager 1], Waiting for signal to start or continue topic deletion (kafka.controller.TopicDeletionManager)</div><div class="line">[2016-07-27 17:45:46,351] WARN [Controller-1-to-broker-1-send-thread], Controller 1's connection to broker XXXX:9092 (id: 1 rack: null) was unsuccessful (kafka.controller.RequestSendThread)</div><div class="line">java.io.IOException: Connection to XXXX:9092 (id: 1 rack: null) failed</div><div class="line">    at kafka.utils.NetworkClientBlockingOps$<span class="variable">$anonfun</span><span class="variable">$blockingReady</span><span class="variable">$extension</span><span class="variable">$2</span>.apply(NetworkClientBlockingOps.scala:63)</div><div class="line">    at kafka.utils.NetworkClientBlockingOps$<span class="variable">$anonfun</span><span class="variable">$blockingReady</span><span class="variable">$extension</span><span class="variable">$2</span>.apply(NetworkClientBlockingOps.scala:59)</div><div class="line">    at kafka.utils.NetworkClientBlockingOps$.recursivePoll<span class="variable">$1</span>(NetworkClientBlockingOps.scala:112)</div><div class="line">    at kafka.utils.NetworkClientBlockingOps$.kafka<span class="variable">$utils</span><span class="variable">$NetworkClientBlockingOps</span>$<span class="variable">$pollUntil</span><span class="variable">$extension</span>(NetworkClientBlockingOps.scala:120)</div><div class="line">    at kafka.utils.NetworkClientBlockingOps$.blockingReady<span class="variable">$extension</span>(NetworkClientBlockingOps.scala:59)</div><div class="line">    at kafka.controller.RequestSendThread.brokerReady(ControllerChannelManager.scala:232)</div><div class="line">    at kafka.controller.RequestSendThread.liftedTree1<span class="variable">$1</span>(ControllerChannelManager.scala:181)</div><div class="line">    at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:180)</div><div class="line">    at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:63)</div></pre></td></tr></table></figure>
<p>查找原因查找了半天，之前以为是<code>kafka_server_jaas.conf</code>文件的格式有问题，改了之后发现 Kafka 有时启动正常，有时不能正常启动，修改之前 conf 文件为：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">KafkaServer &#123;</div><div class="line">    org.apache.kafka.common.security.plain.PlainLoginModule required</div><div class="line">    username=&quot;admin&quot;</div><div class="line">    password=&quot;admin&quot;</div><div class="line">    user_matt=“33&quot;</div><div class="line">    user_alice=&quot;alice&quot;;</div><div class="line">&#125;;</div></pre></td></tr></table></figure>
<p>最后分析可能是因为没有在 user 中配置 admin 账户，因为 broker 之间也开启了身份认证，修改之后的配置文件如下。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">KafkaServer &#123;</div><div class="line">    org.apache.kafka.common.security.plain.PlainLoginModule required</div><div class="line">    username=&quot;admin&quot;</div><div class="line">    password=&quot;admin&quot;</div><div class="line">    user_admin=&quot;admin&quot;</div><div class="line">    user_alice=&quot;alice&quot;;</div><div class="line">&#125;;</div></pre></td></tr></table></figure>
<p>修改完之后，Kafka 就可以正常运行了。</p>
<hr>
<p>参考：</p>
<ul>
<li>confluent的官网博客：<a href="http://www.confluent.io/blog/apache-kafka-security-authorization-authentication-encryption" target="_blank" rel="external">Apache Kafka Security 101</a></li>
<li>Kafka 官网：<a href="https://cwiki.apache.org/confluence/pages/viewpage.action?pageId=51809888" target="_blank" rel="external">KIP-12 - Kafka Sasl/Kerberos and SSL implementation</a></li>
<li><a href="https://cwiki.apache.org/confluence/display/KAFKA/Security" target="_blank" rel="external">Kafka Security</a></li>
<li>Kafka 官网：<a href="http://kafka.apache.org/documentation.html#security" target="_blank" rel="external">Kafka security</a></li>
<li>Kafka 官网中文翻译<a href="http://orchome.com/270" target="_blank" rel="external">kafka使用SASL验证</a></li>
</ul>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[Apache Kafka 0.10.0 new Consumer使用]]></title>
      <url>http://matt33.com/2016/07/22/kafak-new-consumer-use/</url>
      <content type="html"><![CDATA[<p>本文主要介绍一下Kafka new Consumer的使用，关于new Consumer的基本概念可以参考上一篇博文<a href="http://matt33.com/2016/07/21/kafka-new-consumer/">Apache Kafka 0.9 Consumer Client 介绍【译】</a>，这篇对于Kafka的new Consumer介绍得比较清楚。本文的一部分内容也来自上一篇文章。</p>
<h1 id="Consumer-Client"><a href="#Consumer-Client" class="headerlink" title="Consumer Client"></a>Consumer Client</h1><p>本节主要介绍Kafka从一些topic消费数据的示例。</p>
<h2 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h2><p>使用新版的Consumer，需要先在工程中添加kafka-clients依赖，添加的配置信息如下：</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.kafka<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>kafka-clients<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>0.10.0.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></div><div class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></div></pre></td></tr></table></figure>
<h2 id="初始化与配置"><a href="#初始化与配置" class="headerlink" title="初始化与配置"></a>初始化与配置</h2><p>Consumer的创建过程与之前旧的API创建方法一样，一个Consumer必备的最小配置项如下所示：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">Properties props = <span class="keyword">new</span> Properties();</div><div class="line">props.put(<span class="string">"bootstrap.servers"</span>, <span class="string">"localhost:9092"</span>); <span class="comment">// 通过其中的一台broker来找到group的coordinator，并不需要列出所有的broker</span></div><div class="line">props.put(<span class="string">"group.id"</span>, <span class="string">"consumer-tutorial"</span>);</div><div class="line">props.put(<span class="string">"key.deserializer"</span>, StringDeserializer.class.getName());</div><div class="line">props.put(<span class="string">"value.deserializer"</span>, StringDeserializer.class.getName());</div><div class="line">KafkaConsumer&lt;String, String&gt; consumer = <span class="keyword">new</span> KafkaConsumer&lt;&gt;(props); <span class="comment">// consumer实例</span></div></pre></td></tr></table></figure>
<p>Consumer的其他配置项可以参考<a href="http://kafka.apache.org/documentation.html#newconsumerconfigs" target="_blank" rel="external">New Consumer Configs</a>，除了上面的这几个配置之外，其他的几个比较常用的配置信息如下表所示</p>
<table>
<thead>
<tr>
<th>参数</th>
<th>默认值</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>heartbeat.interval.ms</td>
<td>3000</td>
<td>当使用Kafka的group管理机制时，consumer向coordinator发送心跳的间隔，这个值要比session.timeout.ms小，最好不要超过session.timeout.ms的\frac{1}{3}</td>
</tr>
<tr>
<td>session.timeout.ms</td>
<td>30000</td>
<td>当使用Kafka的group管理机制时用于检测到consumer失败的时长，如果在这个时间内没有收到consumer的心跳信息，就认为Consumer失败了</td>
</tr>
<tr>
<td>auto.offset.reset</td>
<td>latest</td>
<td>group首次开始消费数据时的offset，有以下几个值可以选择：earliest、latest、none、anything else.</td>
</tr>
<tr>
<td>enable.auto.commit</td>
<td>true</td>
<td>设置为true时，Consumer的offset将会被周期性地自动commit</td>
</tr>
<tr>
<td>auto.commit.interval.ms</td>
<td>5000</td>
<td>Consumer的offset自动commit时的周期</td>
</tr>
</tbody>
</table>
<h2 id="Consumer-Auto-Offset-Commit"><a href="#Consumer-Auto-Offset-Commit" class="headerlink" title="Consumer Auto Offset Commit"></a>Consumer Auto Offset Commit</h2><p>本例使用Kafka的自动commit机制，每隔一段时间（可通过<code>auto.commit.interval.ms</code>来设置）就会自动进行commit offset。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div></pre></td><td class="code"><pre><div class="line">Properties props = <span class="keyword">new</span> Properties();</div><div class="line">props.put(<span class="string">"bootstrap.servers"</span>, <span class="string">"localhost:9092"</span>);</div><div class="line">props.put(<span class="string">"group.id"</span>, <span class="string">"group"</span>);</div><div class="line">props.put(<span class="string">"auto.offset.reset"</span>, <span class="string">"earliest"</span>);</div><div class="line">props.put(<span class="string">"enable.auto.commit"</span>, <span class="string">"true"</span>); <span class="comment">// 自动commit</span></div><div class="line">props.put(<span class="string">"auto.commit.interval.ms"</span>, <span class="string">"1000"</span>); <span class="comment">// 自动commit的间隔</span></div><div class="line">props.put(<span class="string">"session.timeout.ms"</span>, <span class="string">"30000"</span>);</div><div class="line">props.put(<span class="string">"key.deserializer"</span>, <span class="string">"org.apache.kafka.common.serialization.StringDeserializer"</span>);</div><div class="line">props.put(<span class="string">"value.deserializer"</span>, <span class="string">"org.apache.kafka.common.serialization.StringDeserializer"</span>);</div><div class="line">KafkaConsumer&lt;String, String&gt; consumer = <span class="keyword">new</span> KafkaConsumer&lt;&gt;(props);</div><div class="line">consumer.subscribe(Arrays.asList(<span class="string">"test1"</span>, <span class="string">"test2"</span>)); <span class="comment">// 可消费多个topic,组成一个list</span></div><div class="line"><span class="keyword">while</span> (<span class="keyword">true</span>) &#123;</div><div class="line">    ConsumerRecords&lt;String, String&gt; records = consumer.poll(<span class="number">100</span>);</div><div class="line">    <span class="keyword">for</span> (ConsumerRecord&lt;String, String&gt; record : records) &#123;</div><div class="line">        System.out.printf(<span class="string">"offset = %d, key = %s, value = %s \n"</span>, record.offset(), record.key(), record.value());</div><div class="line">        <span class="keyword">try</span> &#123;</div><div class="line">            Thread.sleep(<span class="number">1000</span>);</div><div class="line">        &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</div><div class="line">            e.printStackTrace();</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>这里有几点需要注意：</p>
<ol>
<li>在使用自动commit时，系统是保证at least once，因为offset是在这些messages被应用处理成功后才进行commit的；</li>
<li>subscribe方法需要传入所有topic的列表，一个group所消费的topic是不能动态增加的，但是可以在任何时间改变这个列表，它会把前面的设置覆盖掉；</li>
<li>poll中的参数就是设置一个时长，Consumer在进行拉取数据进行block的最大时间限制；</li>
</ol>
<h2 id="Consumer-Manual-Offset-Control"><a href="#Consumer-Manual-Offset-Control" class="headerlink" title="Consumer Manual Offset Control"></a>Consumer Manual Offset Control</h2><p>要进行手动commit，需要在配置文件中将enable.auto.commit设置为false，来禁止自动commit，本例以手动同步commit为例</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div></pre></td><td class="code"><pre><div class="line">Properties props = <span class="keyword">new</span> Properties();</div><div class="line">props.put(<span class="string">"bootstrap.servers"</span>, <span class="string">"localhost:9092"</span>);</div><div class="line">props.put(<span class="string">"group.id"</span>, <span class="string">"group"</span>);</div><div class="line">props.put(<span class="string">"enable.auto.commit"</span>, <span class="string">"false"</span>); <span class="comment">//关闭自动commit</span></div><div class="line">props.put(<span class="string">"session.timeout.ms"</span>, <span class="string">"30000"</span>);</div><div class="line">props.put(<span class="string">"auto.offset.reset"</span>, <span class="string">"earliest"</span>);</div><div class="line">props.put(<span class="string">"key.deserializer"</span>, <span class="string">"org.apache.kafka.common.serialization.StringDeserializer"</span>);</div><div class="line">props.put(<span class="string">"value.deserializer"</span>, <span class="string">"org.apache.kafka.common.serialization.StringDeserializer"</span>);</div><div class="line">KafkaConsumer&lt;String, String&gt; consumer = <span class="keyword">new</span> KafkaConsumer&lt;&gt;(props);</div><div class="line">consumer.subscribe(Arrays.asList(<span class="string">"test1"</span>, <span class="string">"test2"</span>));</div><div class="line"><span class="keyword">final</span> <span class="keyword">int</span> minBatchSize = <span class="number">10</span>;</div><div class="line"><span class="keyword">while</span> (<span class="keyword">true</span>) &#123;</div><div class="line">    ConsumerRecords&lt;String, String&gt; records = consumer.poll(<span class="number">100</span>);</div><div class="line">    <span class="keyword">int</span> i = <span class="number">0</span>;</div><div class="line">    <span class="keyword">for</span> (ConsumerRecord&lt;String, String&gt; record : records) &#123;</div><div class="line">        System.out.printf(<span class="string">"offset = %d, key = %s, value = %s \n"</span>, record.offset(), record.key(), record.value());</div><div class="line">        i++;</div><div class="line">    &#125;</div><div class="line">    <span class="keyword">if</span> (i &gt;= minBatchSize) &#123;</div><div class="line">        consumer.commitSync(); <span class="comment">//批量完成写入后，手工同步commit offset</span></div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<ol>
<li>在本例中，我们调用了commitSync方法，这是同步commit的方式，同时Kafka还提供了commitAsync方法，它们的区别是：使用同步提交时，consumer会进行block知道commit的结果返回，这样的话如果commit失败就可以今早地发现错误，而当使用异步commit时，commit的结果还未返回，Consumer就会开始拉取下一批的数据，但是使用异步commit可以系统的吞吐量，具体使用哪种方式需要开发者自己权衡；</li>
<li>本例中的实现依然是保证at least once，但是如果每次拉取到数据之后，就进行commit，最后再处理数据，就可以保证at last once。</li>
</ol>
<h2 id="Consumer-Manual-Partition-Assign"><a href="#Consumer-Manual-Partition-Assign" class="headerlink" title="Consumer Manual Partition Assign"></a>Consumer Manual Partition Assign</h2><p>Kafka在进行消费数据时，可以指定消费某个topic的某个partition，这种使用情况比较特殊，并不需要coordinator进行rebalance，也就意味着这种模式虽然需要设置group id，但是它跟前面的group的机制并不一样，它与旧的Consumer中的Simple Consumer相似，这是Kafka在新的Consumer API中对这种情况的支持。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div></pre></td><td class="code"><pre><div class="line">Properties props = <span class="keyword">new</span> Properties();</div><div class="line">props.put(<span class="string">"bootstrap.servers"</span>, <span class="string">"localhost:9092"</span>);</div><div class="line">props.put(<span class="string">"group.id"</span>, <span class="string">"group"</span>);</div><div class="line">props.put(<span class="string">"enable.auto.commit"</span>, <span class="string">"false"</span>); <span class="comment">//关闭自动commit</span></div><div class="line">props.put(<span class="string">"session.timeout.ms"</span>, <span class="string">"30000"</span>);</div><div class="line">props.put(<span class="string">"auto.offset.reset"</span>, <span class="string">"earliest"</span>);</div><div class="line">props.put(<span class="string">"key.deserializer"</span>, <span class="string">"org.apache.kafka.common.serialization.StringDeserializer"</span>);</div><div class="line">props.put(<span class="string">"value.deserializer"</span>, <span class="string">"org.apache.kafka.common.serialization.StringDeserializer"</span>);</div><div class="line">KafkaConsumer consumer = <span class="keyword">new</span> KafkaConsumer(props);</div><div class="line">TopicPartition partition0 = <span class="keyword">new</span> TopicPartition(<span class="string">"test"</span>, <span class="number">0</span>);</div><div class="line">TopicPartition partition1 = <span class="keyword">new</span> TopicPartition(<span class="string">"test"</span>, <span class="number">2</span>);</div><div class="line">consumer.assign(Arrays.asList(partition0, partition1));</div><div class="line"></div><div class="line"><span class="keyword">final</span> <span class="keyword">int</span> minBatchSize = <span class="number">10</span>;</div><div class="line"><span class="keyword">while</span> (<span class="keyword">true</span>) &#123;</div><div class="line">    ConsumerRecords&lt;String, String&gt; records = consumer.poll(<span class="number">100</span>);</div><div class="line">    <span class="keyword">int</span> i = <span class="number">0</span>;</div><div class="line">    <span class="keyword">for</span> (ConsumerRecord&lt;String, String&gt; record : records) &#123;</div><div class="line">        System.out.printf(<span class="string">"offset = %d, key = %s, value = %s \n"</span>, record.offset(), record.key(), record.value());</div><div class="line">        i++;</div><div class="line">    &#125;</div><div class="line">    <span class="keyword">if</span> (i &gt;= minBatchSize) &#123;</div><div class="line">        consumer.commitSync(); <span class="comment">//批量完成写入后，手工sync offset</span></div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>注意：</p>
<ol>
<li>与前面的subscribe方法一样，在调用assign方法时，需要传入这个Consumer要消费的所有TopicPartition的列表；</li>
<li>不管对于simple consumer还是consumer group，所有offset的commit都必须经过group coordinator；</li>
<li>在进行commit时，必须设置一个合适的group.id，避免与其他的group产生冲突。如果一个simple consumer试图使用一个与一个active group相同的id进行commit offset，coordinator将会拒绝这个commit请求，会返回一个CommitFailedException异常，但是，如果一个simple consumer与另一个simple consumer使用同一个id，系统就不会报任何错误。</li>
</ol>
<h1 id="KafkaStream使用"><a href="#KafkaStream使用" class="headerlink" title="KafkaStream使用"></a>KafkaStream使用</h1><p>KafkaStream是在Kafka 0.10.0版中新提出的内容，Kafka官方也说了设计这个feature的原因——为了简单，之前在流处理方面，一般情况下都会使用Kafka作为消息队列，然后再搭建一个流处理环境做流处理，而现在我们可以直接在Kafka中进行流处理，不需要再搭建另外一个环境（加了这个feature之后会使得Kafka变得更加复杂，不过官网说，在使用时我们只需要在工程中添加一个外部依赖包即可使用这个功能）。</p>
<h2 id="配置-1"><a href="#配置-1" class="headerlink" title="配置"></a>配置</h2><p>需要在pom文件中添加如下依赖，KafkaStream在实际运行时也是依赖这个外部的jar包运行。</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.kafka<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>kafka-streams<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>0.10.0.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></div><div class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></div></pre></td></tr></table></figure>
<h2 id="初始化与配置-1"><a href="#初始化与配置-1" class="headerlink" title="初始化与配置"></a>初始化与配置</h2><p>KafkaStream使用的一个基本初始化部分如下所示（代码来自<a href="http://kafka.apache.org/0100/javadoc/index.html?org/apache/kafka/streams/KafkaStreams.html" target="_blank" rel="external">Javadoc</a>）</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line">Map&lt;String, Object&gt; props = <span class="keyword">new</span> HashMap&lt;&gt;();</div><div class="line">props.put(StreamsConfig.APPLICATION_ID_CONFIG, <span class="string">"my-stream-processing-application"</span>);</div><div class="line">props.put(StreamsConfig.BOOTSTRAP_SERVERS_CONFIG, <span class="string">"localhost:9092"</span>);</div><div class="line">props.put(StreamsConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class);</div><div class="line">props.put(StreamsConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class);</div><div class="line">props.put(StreamsConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class);</div><div class="line">props.put(StreamsConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class);</div><div class="line">StreamsConfig config = <span class="keyword">new</span> StreamsConfig(props);</div><div class="line"></div><div class="line">KStreamBuilder builder = <span class="keyword">new</span> KStreamBuilder();</div><div class="line">builder.from(<span class="string">"my-input-topic"</span>).mapValue(value -&gt; value.length().toString()).to(<span class="string">"my-output-topic"</span>);</div><div class="line"></div><div class="line">KafkaStreams streams = <span class="keyword">new</span> KafkaStreams(builder, config);</div><div class="line">streams.start();</div></pre></td></tr></table></figure>
<p>完整的配置选项如下表所示，也可以参考<a href="http://kafka.apache.org/documentation.html#streamsconfigs" target="_blank" rel="external">Streams Configs</a></p>
<table>
<thead>
<tr>
<th>名称</th>
<th>描述</th>
<th>类型</th>
<th>默认值</th>
</tr>
</thead>
<tbody>
<tr>
<td>application.id</td>
<td>流处理应用的标识，对同一个应用需要一致，因为它是作为消费的group_id的</td>
<td>string</td>
<td></td>
</tr>
<tr>
<td>bootstrap.servers</td>
<td>host1:port1,host2:port2 这样的列表，是用来发现所有Kafka节点的种子，因此不需要配上所有的Kafka节点</td>
<td>list</td>
<td></td>
</tr>
<tr>
<td>client.id</td>
<td>应用的一个客户端的逻辑名称，设定后可以区分是哪个客户端在请求</td>
<td>string</td>
<td>“”</td>
</tr>
<tr>
<td>zookeeper.connect</td>
<td>zookeeper</td>
<td>string</td>
<td>“”</td>
</tr>
<tr>
<td>key.serde</td>
<td>键的序列化/反序列化类</td>
<td>class</td>
<td>org.apache.kafka.common.serialization.Serdes$ByteArraySerde</td>
</tr>
<tr>
<td>partition.grouper</td>
<td>用于分区组织的类，需要实现PartitionGrouper接口</td>
<td>class</td>
<td>org.apache.kafka.streams.processor.DefaultPartitionGrouper</td>
</tr>
<tr>
<td>replication.factor</td>
<td>流处理应用会创建change log topic和repartition topic用于管理内部状态，这个参数设定这些topic的副本数</td>
<td>int</td>
<td>1</td>
</tr>
<tr>
<td>state.dir</td>
<td>状态仓库的存储路径</td>
<td>string</td>
<td>/tmp/kafka-streams</td>
</tr>
<tr>
<td>timestamp.extractor</td>
<td>时间戳抽取类，需要实现TimestampExtractor接口</td>
<td>class</td>
<td>org.apache.kafka.streams.processor.ConsumerRecordTimestampExtractor</td>
</tr>
<tr>
<td>value.serde</td>
<td>值的序列化/反序列化类</td>
<td>class</td>
<td>org.apache.kafka.common.serialization.Serdes$ByteArraySerde</td>
</tr>
<tr>
<td>buffered.records.per.partition</td>
<td>每个分区缓存的最大记录数</td>
<td>int</td>
<td>1000</td>
</tr>
<tr>
<td>commit.interval.ms</td>
<td>存储处理器当前位置的间隔毫秒数</td>
<td>long</td>
<td>30000</td>
</tr>
<tr>
<td>metric.reporters</td>
<td>用于性能报告的类列表。需要实现MetricReporter接口。JmxReporter会永远开启不需要指定</td>
<td>list</td>
<td>[]</td>
</tr>
<tr>
<td>metric.num.samples</td>
<td>计算性能需要的采样数</td>
<td>int</td>
<td>2</td>
</tr>
<tr>
<td>metric.sample.window.ms</td>
<td>性能采样的时间间隔</td>
<td>long</td>
<td>30000</td>
</tr>
<tr>
<td>num.standby.replicas</td>
<td>每个任务的后备副本数</td>
<td>int</td>
<td>0</td>
</tr>
<tr>
<td>num.stream.threads</td>
<td>执行流处理的线程数</td>
<td>int</td>
<td>1</td>
</tr>
<tr>
<td>poll.ms</td>
<td>等待输入的毫秒数</td>
<td>long</td>
<td>100</td>
</tr>
<tr>
<td>state.cleanup.delay.ms</td>
<td>一个分区迁移后，在删除状态前等待的毫秒数</td>
<td>long</td>
<td>60000</td>
</tr>
</tbody>
</table>
<h2 id="小示例"><a href="#小示例" class="headerlink" title="小示例"></a>小示例</h2><p>这是个将一个topic的事件进行过滤的示例，处理很简单，下面给出了这个例子的完整代码。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> org.apache.kafka.clients.consumer.ConsumerConfig;</div><div class="line"><span class="keyword">import</span> org.apache.kafka.common.serialization.Serdes;</div><div class="line"><span class="keyword">import</span> org.apache.kafka.streams.kstream.KStream;</div><div class="line"><span class="keyword">import</span> org.apache.kafka.streams.kstream.KStreamBuilder;</div><div class="line"><span class="keyword">import</span> org.apache.kafka.streams.KafkaStreams;</div><div class="line"><span class="keyword">import</span> org.apache.kafka.streams.StreamsConfig;</div><div class="line"><span class="keyword">import</span> org.apache.kafka.streams.kstream.Predicate;</div><div class="line"></div><div class="line"><span class="keyword">import</span> java.util.Properties;</div><div class="line"></div><div class="line"><span class="comment">/**</span></div><div class="line"> * Created by matt on 16/7/22.</div><div class="line"> */</div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">EventFilter</span> </span>&#123;</div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</div><div class="line">        Properties props = <span class="keyword">new</span> Properties();</div><div class="line">        props.put(StreamsConfig.APPLICATION_ID_CONFIG, <span class="string">"test-filter"</span>);</div><div class="line">        props.put(StreamsConfig.BOOTSTRAP_SERVERS_CONFIG, <span class="string">"10.4.232.70:9091,10.4.232.77:2181"</span>);</div><div class="line">        props.put(StreamsConfig.KEY_SERDE_CLASS_CONFIG, Serdes.String().getClass());</div><div class="line">        props.put(StreamsConfig.VALUE_SERDE_CLASS_CONFIG, Serdes.String().getClass());</div><div class="line"></div><div class="line">        <span class="comment">// setting offset reset to earliest so that we can re-run the demo code with the same pre-loaded data</span></div><div class="line">        props.put(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, <span class="string">"earliest"</span>);</div><div class="line"></div><div class="line">        KStreamBuilder builder = <span class="keyword">new</span> KStreamBuilder();</div><div class="line"></div><div class="line">        KStream&lt;String, String&gt; source = builder.stream(<span class="string">"test"</span>);</div><div class="line"></div><div class="line">        source.filter(<span class="keyword">new</span> Predicate&lt;String, String&gt;() &#123;</div><div class="line">            <span class="meta">@Override</span></div><div class="line">            <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">test</span><span class="params">(String key, String value)</span> </span>&#123;</div><div class="line">                <span class="keyword">return</span> (value.split(<span class="string">","</span>)[<span class="number">3</span>]).equals(<span class="string">"food"</span>);</div><div class="line">            &#125;</div><div class="line">        &#125;).to(<span class="string">"food"</span>);</div><div class="line"></div><div class="line">        KafkaStreams streams = <span class="keyword">new</span> KafkaStreams(builder, props);</div><div class="line">        streams.start();</div><div class="line"></div><div class="line">        <span class="comment">// usually the stream application would be running forever,</span></div><div class="line">        <span class="comment">// in this example we just let it run for some time and stop since the input data is finite.</span></div><div class="line">        Thread.sleep(<span class="number">5000L</span>);</div><div class="line"></div><div class="line">        streams.close();</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<hr>
<p>本文只是介绍这两个重要feature的使用方法，而KafkaStream并没有深入去讨论，后面会对本文再进行更新，并且还会增加Producer和Consumer使用安全机制的方法。</p>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[Apache Kafka 0.9 Consumer Client 介绍【译】]]></title>
      <url>http://matt33.com/2016/07/21/kafka-new-consumer/</url>
      <content type="html"><![CDATA[<p>近段时间在公司实习，有一项任务就是负责对Kafka新版本的一些feature做一下调研，主要是调研的内容是Kafka在0.9.0版本中提供的两个新特性：New Consumer API和安全认证机制，本文是在研究Kafka的新consumer API时看过的一篇文章，对于理解新API的设计理念以及应用，有很多的帮助，因此就打算翻译一下，帮助自己更好理解的同时也为开源做一些贡献。本文译自<a href="http://www.confluent.io/blog/tutorial-getting-started-with-the-new-apache-kafka-0.9-consumer-client" target="_blank" rel="external">Introducing the Kafka Consumer: Getting Started with the New Apache Kafka 0.9 Consumer Client</a>一文，是Confluent官方出的一篇关于Kafka新Consumer客户端介绍的文章。</p>
<blockquote>
<p>注：个人的英文及写作水平有限，虽然有些地方能够理解作者的意思，但是可能自己会表达不准确，读者遇到难以理解的地方，可以对照英文原文进行阅读。另外，有些在Kafka中经常出现专有英文名词，本文会尽量还用英文表示，本来直接看这些英文名词就非常简洁，翻译成中文反而难以理解。</p>
</blockquote>
<p>Kafka最初被设计时，它原生地提供了一个Scala版本的producer和Consumer客户端。但是随着Kafka的应用更加广泛，我们意识到这些API有很多的缺陷。比如，Kafka提供了一个<strong>high-level</strong>的Consumer API，它可以实现consumer group和自动容错，但是不能支持一些更复杂的使用场景，同时我们也提供了一套<strong>simple</strong>的Consumer API以提供更全面、更细粒度的控制，但是这种Consumer需要开发者自己设计容错机制。因此，我们重新设计和开发了客户端，以适应哪些旧的客户端很难或者无法适用的应用场景，并且建立了一套可以支持长久发展的API。</p>
<p>开始的第一阶段，在0.8.1的版本中，我们重写设计了Producer的API。最近的0.9.0版本完成了第二阶段，引入了新的Consumer API。在Kafka本身提供的一套新的<strong>group coordination protocol</strong>的基础上，新的Consumer有以下这些优势：</p>
<ul>
<li>Clean Consolidated API：新的Consumer结合了旧的”simple”和”high-level”Consumer客户端，同时提供了group协调机制和更细粒度的消费机制；</li>
<li>Reduced Dependencies：新的Consumer完全是用Java编写的，它在运行过程中没有依赖Scala或者Zookeeper，这使得我们的工程的依赖包更加轻量化；</li>
<li>Better Security：Kafka 0.9.0提供的<a href="https://cwiki.apache.org/confluence/pages/viewpage.action?pageId=51809888" target="_blank" rel="external">security extensions</a>只被新的Consumer所支持；</li>
<li>新的Consumer同样也增加一系列用于管理消费过程中group容错的协议。之前这部分的设计是使用Java客户端实现的，它需要频繁地与Zookeeper进行交互，这个实现逻辑上的复杂性使得这些它很难推广到其他语言的客户端上。而随着新协议的提出，实现变得更加简单，实际上<a href="https://github.com/edenhill/librdkafka" target="_blank" rel="external">C Client</a>已经开始应用这个协议了。</li>
</ul>
<p>尽管新的Consumer使用了重新设计的API和一个新的coordination protocol，但是Kafka的那些基础的概念并没有任何变化。因此，对旧的Consumer非常熟悉的开发者在理解新Consumer客户端的设计时并不会遇到太大困难。然而，却有一些不易察觉细节需要额外的关注，特别是在理解<strong>group management</strong>和<strong>thread model</strong>上时。本文的目的就是讲述一下新Consumer的使用以及解释一下这些细节问题。</p>
<blockquote>
<p>有一点需要注意：在本文还在写的时候，新的Consumer在稳定性方面仍然被认为是”beta”。</p>
</blockquote>
<p>我们已经解决了几个在0.9.0版中遇到的重要bug，如果你在使用0.9.0版时遇到任何问题，我们建议你先对这个分支进行一下测试。如果依然遇到问题，可以通过<a href="https://kafka.apache.org/contact.html" target="_blank" rel="external">mail lists</a>或者<a href="https://issues.apache.org/jira/secure/Dashboard.jspa" target="_blank" rel="external">JIRA</a>提出。</p>
<h1 id="Getting-Started：开始"><a href="#Getting-Started：开始" class="headerlink" title="Getting Started：开始"></a>Getting Started：开始</h1><p>开始讲述代码之前，我们先回顾一下Kafka的基本概念。在Kafka中，每一个topic都被分为一系列消息的集合，这些集合被称为partition，Producer会在这些消息集合的尾部追加数据，Consumer从给定的位置读取数据。Kafka通过consumer group实现规模化地消费topic数据，group是一系列Consumers共享一个共同的标识符。下图展示了一个有3个partition的topic被一个有2个成员的group消费的情况，topic的每个partition被安排到group中的一个cosumer上。</p>
<p><img src="/images/kafka/consumer-figure1.png" alt="consumer group"></p>
<p>旧的Consumer依赖ZK进行group管理，而新的Consumer则使用了一个Kafka自身提供的group coordination protocol实现。对于每一个group，都会从所有的broker中选取一个作为<strong>group coordinator</strong>，这个coordinator是负责维护和管理这个group的状态，它的主要工作是当一个consumer加入、一个consumer离开（挂掉或者手动停止等）或者topic的partition改变时重新进行partition分配，这个过程就是group的<strong>rebalance</strong>。</p>
<blockquote>
<p>这里有一个问题需要思考，每个topic的元数据信息（具体的指的是，这个topic有多少个partition，每个partition的leader在哪台broker上）是不是也有coordinator保存的？还是这些元数据信息直接保存在broker上？</p>
</blockquote>
<p>当一个group刚开始被初始化时，group中consumer可以选择从每个partition的最小或者最大的offset开始消费数据，然后每个partition中的message会按顺序依次进行消费。随着Consumer的处理，它会对已经成功处理的msg进行commit（提交的是msg的offset）。例如，如下图所示，Consumer当前消费的msg的offset（<code>Current Position</code>）是6，上一次已经提交的msg的offset（<code>Last Committed Offset</code>）是1.</p>
<p><img src="/images/kafka/consumer-figure2.png" alt="consumer offset"></p>
<p>当一个partition被分配到group中的另外一个consumer时，初始化的位置是<code>Last Committed Offset</code>。如果本例中的consumer突然挂掉，这个group中的consumer将不得不从1（<code>Last Committed Offset</code>）开始消费数据，在这种情况下，offset为1~6的message将被重新处理。</p>
<p>图中也展示了在log中其他两个比较重要的位置信息，<code>Log End Offset</code>是写入log中的最新一条message的offset，而<code>High Watermark</code>是log中已经成功备份到其他replicas中的最新一条message的offset，也就是说<code>Log End Offset</code>与<code>High Watermark</code>之间的数据已经写入到log中，但是还未成功备份到其他的replicas中。从consuemr端来看，<code>High Watermark</code>是consumer可以消费的最后一条message的offset，这种机制会阻止Consumer读取那些未备份的message，因为这些message在后面可能会丢失。</p>
<h1 id="Configuration-and-Initialization：配置与初始化"><a href="#Configuration-and-Initialization：配置与初始化" class="headerlink" title="Configuration and Initialization：配置与初始化"></a>Configuration and Initialization：配置与初始化</h1><p>使用新版的Consumer，需要先在工程中添加kafka-clients依赖，添加的配置信息如下：</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></div><div class="line"> <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.kafka<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></div><div class="line"> <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>kafka-clients<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></div><div class="line"> <span class="tag">&lt;<span class="name">version</span>&gt;</span>0.9.0.0-cp1<span class="tag">&lt;/<span class="name">version</span>&gt;</span></div><div class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></div></pre></td></tr></table></figure>
<p>与其他的Kafka客户端一样，新版的Consumer也需要使用一个<code>Properties</code>文件来创建。下面例子中的配置，是对于一个Consumer group来说的几个必备的配置项</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">Properties props = <span class="keyword">new</span> Properties();</div><div class="line">props.put(<span class="string">"bootstrap.servers"</span>, <span class="string">"localhost:9092"</span>);</div><div class="line">props.put(<span class="string">"group.id"</span>, <span class="string">"consumer-tutorial"</span>);</div><div class="line">props.put(<span class="string">"key.deserializer"</span>, StringDeserializer.class.getName());</div><div class="line">props.put(<span class="string">"value.deserializer"</span>, StringDeserializer.class.getName());</div><div class="line">KafkaConsumer&lt;String, String&gt; consumer = <span class="keyword">new</span> KafkaConsumer&lt;&gt;(props);</div></pre></td></tr></table></figure>
<p>与旧的Consumer和Producer一样， 我们需要先配置一个brokers的初始列表，以便Consumer能够找到集群中其他的节点，这并不需要列出集群中的所有节点，客户端从列表中的broker中来找到全部的alive brokers，本例我们假设这台broker是运行在本地上的。Consumer也需要设置key和value反序列化的方式。最后，为了加入一个Consumer Group，也需要设置group id，它是group的一个标识符。在本文的下面，我们会介绍更多的配置选项。</p>
<blockquote>
<p>这里也有一个问题需要思考，Kafka是如何通过初始的broker列表来找到Kafka集群所有的节点信息？</p>
</blockquote>
<h1 id="Topic-Subscription：订阅Topic"><a href="#Topic-Subscription：订阅Topic" class="headerlink" title="Topic Subscription：订阅Topic"></a>Topic Subscription：订阅Topic</h1><p>开始消费前，必须首先配置出应用需要订阅的topic信息，下面的例子中，我们订阅了来自Topic为”foo”和”bar”的数据</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">consumer.subscribe(Arrays.asList(<span class="string">"foo"</span>, <span class="string">"bar"</span>));</div></pre></td></tr></table></figure>
<p>开始订阅之后，Consumer可以与group的其他Consumer进行协调，来得到自己的partition分配，这个过程是在Consumer开始消费数据时自动进行的。下面，我们会展示如何使用<strong>assign</strong> API来手动进行partition分配，但是需要注意的是，Consumer中同时使用自动管理和手动管理是没有必要的。</p>
<p><code>subscribe</code>方法是不能增加的：程序中必须包含想要消费的所有topic列表，你可以在任何时间改变你订阅的topic的集合，但是之前订阅的这些topic会被你使用<code>subscribe</code>方法调用的新的列表所取代。</p>
<h1 id="Basic-Poll-Loop：基本的poll循环模型"><a href="#Basic-Poll-Loop：基本的poll循环模型" class="headerlink" title="Basic Poll Loop：基本的poll循环模型"></a>Basic Poll Loop：基本的poll循环模型</h1><p>Consumer需要支持并行地拉取数据，常见的情况就是从分布在不同broker上的多个topic的多个partition上拉取数据。为了实现这种情况，Kafka使用了一套类似于Unix中的<code>poll</code>或者<code>select</code>调用的API风格：一旦topic进行注册，未来所有的coordination、rebalance和数据拉取都是在一个event loop中通过一个单一的poll调用来触发的。这种实现方式是简单有效的，它可以处理来自单线程的所有IO。</p>
<blockquote>
<p>思考：Consumer在调用<code>poll</code>方法时处理逻辑是怎么样？</p>
</blockquote>
<p>在订阅了一个topic之后，你需要启动一个<code>event loop</code>来获得partition分配并开始开始拉取数据，这听起来很复杂，但是你需要做的就是在一个循环中调用<code>poll</code>方法，然后Consumer会自动处理其他的所有的事情。每一次对于<code>poll</code>方法的调用都会返回一个从其所分配的partition上拉取的message集合（集合可能会空）。下面的例子展示了在一个基本的poll循环模型中打印Consumer拉取的mmessage的offset和value。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">try</span> &#123;</div><div class="line">  <span class="keyword">while</span> (running) &#123;</div><div class="line">    ConsumerRecords&lt;String, String&gt; records = consumer.poll(<span class="number">1000</span>);</div><div class="line">    <span class="keyword">for</span> (ConsumerRecord&lt;String, String&gt; record : records)</div><div class="line">      System.out.println(record.offset() + <span class="string">": "</span> + record.value());</div><div class="line">  &#125;</div><div class="line">&#125; <span class="keyword">finally</span> &#123;</div><div class="line">  consumer.close();</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>这个<code>poll</code>API返回了根据<code>Current Position</code>拉取到的record。当group第一次创建时，这个位置是根据配置来进行设置的，可以被设置每个partition的最早或者最新的offset。但是一旦这个Consumer开始commit offset，之后的每次rebalance都会把position重置到<code>Last Committed Offset</code>位置。<code>poll</code>的这个参数是用来控制当Consumer在<code>Current Position</code>等待数据时block的最大时间，只要有任何record是可用的，Consumer就会立马返回，但是如果没有任何record是可用，Consumer将会等待一定的时长（被设置的时间）。</p>
<blockquote>
<p>思考：新API中的record与旧API中的message有什么区别与联系？</p>
</blockquote>
<p>Consumer最初被设计时就是运行在它自己的线程上，在多线程情况下使用时如果没有额外的同步机制它并不是线程安全的，而且也不推荐去尝试。在这个例子中，我们使用了一个flag（<code>runnning</code>），当应用关掉时它用于从poll循环中中断。当这个flag被其他线程（例如：关闭进程的线程）设置为false时，当poll返回时循环就会结束，而且无论是否返回record应用都会结束进程。</p>
<p>当Consumer进程结束时，你应该显式地关闭Consumer进程，这样不仅可以清除使用的socket，而且可以确保Consumer会向Coordinator发送它离开group的信息。</p>
<p>在上面的例子中，我们使用了较小的定时来确保在关闭Consumer时没有太多的延迟，或者，你也可以设置一个较长的定时，通过使用<code>weakup</code>API来从循环中中断。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">try</span> &#123;</div><div class="line">  <span class="keyword">while</span> (<span class="keyword">true</span>) &#123;</div><div class="line">    ConsumerRecords&lt;String, String&gt; records = consumer.poll(Long.MAX_VALUE);</div><div class="line">    <span class="keyword">for</span> (ConsumerRecord&lt;String, String&gt; record : records)</div><div class="line">      System.out.println(record.offset() + “: ” + record.value());</div><div class="line">  &#125;</div><div class="line">&#125; <span class="keyword">catch</span> (WakeupException e) &#123;</div><div class="line">  <span class="comment">// ignore for shutdown</span></div><div class="line">&#125; <span class="keyword">finally</span> &#123;</div><div class="line">  consumer.close();</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>在这个例子中，我们将时长设置为了<code>Long.MAX_VALUE</code>，它意味着Consumer将会一直bolck直到下一批records返回。相比于前面例子中使用的flag，本例中线程通过调用<code>consumer.wakeup()</code>来中断poll循环，同时进程抛出一个<code>WakeupException</code>异常。这个API被其他线程调用是安全的，但值得注意的是：如果进程当前没有调用poll，这个异常会在下次调用时被抛出。在这个例子中，我们可以捕捉这个异常来阻止它继续传播。</p>
<blockquote>
<p>思考：1.只要有数据，poll就立马返回吗？还是poll会等待一段时间或者一定消息量后返回？2.poll中设置的time参数在什么情况下起作用？如果拉取的消息为空，而时间又超出的话会出现什么情况？</p>
</blockquote>
<h1 id="Putting-in-all-Together：一个完整的例子"><a href="#Putting-in-all-Together：一个完整的例子" class="headerlink" title="Putting in all Together：一个完整的例子"></a>Putting in all Together：一个完整的例子</h1><p>在下面的例子中，我们创建一个简单的<code>Runnable</code>任务，它初始化这个Consumer、订阅一个topic的列表，并且一直执行poll循环除非遇到外部触发结束进程。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ConsumerLoop</span> <span class="keyword">implements</span> <span class="title">Runnable</span> </span>&#123;</div><div class="line">  <span class="keyword">private</span> <span class="keyword">final</span> KafkaConsumer&lt;String, String&gt; consumer;</div><div class="line">  <span class="keyword">private</span> <span class="keyword">final</span> List&lt;String&gt; topics;</div><div class="line">  <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">int</span> id;</div><div class="line"></div><div class="line">  <span class="function"><span class="keyword">public</span> <span class="title">ConsumerLoop</span><span class="params">(<span class="keyword">int</span> id,</span></span></div><div class="line">                      String groupId,</div><div class="line">                      List&lt;String&gt; topics) &#123;</div><div class="line">    <span class="keyword">this</span>.id = id;</div><div class="line">    <span class="keyword">this</span>.topics = topics;</div><div class="line">    Properties props = <span class="keyword">new</span> Properties();</div><div class="line">    props.put(<span class="string">"bootstrap.servers"</span>, <span class="string">"localhost:9092"</span>);</div><div class="line">    props.put(“group.id”, groupId);</div><div class="line">    props.put(“key.deserializer”, StringDeserializer.class.getName());</div><div class="line">    props.put(“value.deserializer”, StringDeserializer.class.getName());</div><div class="line">    <span class="keyword">this</span>.consumer = <span class="keyword">new</span> KafkaConsumer&lt;&gt;(props);</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  <span class="meta">@Override</span></div><div class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</div><div class="line">    <span class="keyword">try</span> &#123;</div><div class="line">      consumer.subscribe(topics);</div><div class="line"></div><div class="line">      <span class="keyword">while</span> (<span class="keyword">true</span>) &#123;</div><div class="line">        ConsumerRecords&lt;String, String&gt; records = consumer.poll(Long.MAX_VALUE);</div><div class="line">        <span class="keyword">for</span> (ConsumerRecord&lt;String, String&gt; record : records) &#123;</div><div class="line">          Map&lt;String, Object&gt; data = <span class="keyword">new</span> HashMap&lt;&gt;();</div><div class="line">          data.put(<span class="string">"partition"</span>, record.partition());</div><div class="line">          data.put(<span class="string">"offset"</span>, record.offset());</div><div class="line">          data.put(<span class="string">"value"</span>, record.value());</div><div class="line">          System.out.println(<span class="keyword">this</span>.id + <span class="string">": "</span> + data);</div><div class="line">        &#125;</div><div class="line">      &#125;</div><div class="line">    &#125; <span class="keyword">catch</span> (WakeupException e) &#123;</div><div class="line">      <span class="comment">// ignore for shutdown</span></div><div class="line">    &#125; <span class="keyword">finally</span> &#123;</div><div class="line">      consumer.close();</div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">shutdown</span><span class="params">()</span> </span>&#123;</div><div class="line">    consumer.wakeup();</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>为了测试这个示例，需要有一个运行0.9.0版Kafka的broker，并且需要一个有一些待消费数据的topic，向一个topic写入数据的最简单的办法是使用<code>kafka-verifiable-producer.sh</code>脚本。为了确保实验更有趣，我们将topic设置为多个partition，这样的话就不用使一个parition去做所有的工作了。在本例中，Kafka的broker和Zookeeper都运行在本地，你可以在一个Kafka根目录下键入以下命令进行设置topic和partiion。</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># bin/kafka-topics.sh --create --topic consumer-tutorial --replication-factor 1 --partitions 3 --zookeeper localhost:2181</span></div><div class="line"></div><div class="line"><span class="comment"># bin/kafka-verifiable-producer.sh --topic consumer-tutorial --max-messages 200000 --broker-list localhost:9092</span></div></pre></td></tr></table></figure>
<p>然后我们创建了一个有三个成员的consumer group，这个group来订阅我们刚才创建的那个topic</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</div><div class="line">  <span class="keyword">int</span> numConsumers = <span class="number">3</span>;</div><div class="line">  String groupId = <span class="string">"consumer-tutorial-group"</span></div><div class="line">  List&lt;String&gt; topics = Arrays.asList(<span class="string">"consumer-tutorial"</span>);</div><div class="line">  ExecutorService executor = Executors.newFixedThreadPool(numConsumers);</div><div class="line"></div><div class="line">  <span class="keyword">final</span> List&lt;ConsumerLoop&gt; consumers = <span class="keyword">new</span> ArrayList&lt;&gt;();</div><div class="line">  <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; numConsumers; i++) &#123;</div><div class="line">    ConsumerLoop consumer = <span class="keyword">new</span> ConsumerLoop(i, groupId, topics);</div><div class="line">    consumers.add(consumer);</div><div class="line">    executor.submit(consumer);</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  Runtime.getRuntime().addShutdownHook(<span class="keyword">new</span> Thread() &#123;</div><div class="line">    <span class="meta">@Override</span></div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</div><div class="line">      <span class="keyword">for</span> (ConsumerLoop consumer : consumers) &#123;</div><div class="line">        consumer.shutdown();</div><div class="line">      &#125;</div><div class="line">      executor.shutdown();</div><div class="line">      <span class="keyword">try</span> &#123;</div><div class="line">        executor.awaitTermination(<span class="number">5000</span>, TimeUnit.MILLISECONDS);</div><div class="line">      &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</div><div class="line">        e.printStackTrace;</div><div class="line">      &#125;</div><div class="line">    &#125;</div><div class="line">  &#125;);</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>这个例子向一个executor提交三个consumer，每一个线程都分配了一个唯一的id，便于我们清楚是哪个线程在接收数据。当进程停止时，shutdown的Hook将被触发，它将使用<code>weakup</code>中断这三个线程，并且等待它们关闭。如果你运行这个程序，你将会看到所有这些线程接收到数据，下面是运行之后的输出例子：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div></pre></td><td class="code"><pre><div class="line">2: &#123;partition=0, offset=928, value=2786&#125;</div><div class="line">2: &#123;partition=0, offset=929, value=2789&#125;</div><div class="line">1: &#123;partition=2, offset=297, value=891&#125;</div><div class="line">2: &#123;partition=0, offset=930, value=2792&#125;</div><div class="line">1: &#123;partition=2, offset=298, value=894&#125;</div><div class="line">2: &#123;partition=0, offset=931, value=2795&#125;</div><div class="line">0: &#123;partition=1, offset=278, value=835&#125;</div><div class="line">2: &#123;partition=0, offset=932, value=2798&#125;</div><div class="line">0: &#123;partition=1, offset=279, value=838&#125;</div><div class="line">1: &#123;partition=2, offset=299, value=897&#125;</div><div class="line">1: &#123;partition=2, offset=300, value=900&#125;</div><div class="line">1: &#123;partition=2, offset=301, value=903&#125;</div><div class="line">1: &#123;partition=2, offset=302, value=906&#125;</div><div class="line">1: &#123;partition=2, offset=303, value=909&#125;</div><div class="line">1: &#123;partition=2, offset=304, value=912&#125;</div><div class="line">0: &#123;partition=1, offset=280, value=841&#125;</div><div class="line">2: &#123;partition=0, offset=933, value=2801&#125;</div></pre></td></tr></table></figure>
<p>这个输出展示三个partition的消费情况，每一个partition都被安排到其中的一个线程上。在每个partition中，你都会看到offset如期望中的一样在不断增加，你可以使用命令行或者IDE中的<code>Ctrl+C</code>关闭这个进程。</p>
<h1 id="Consumer-Liveness：Consumer存活"><a href="#Consumer-Liveness：Consumer存活" class="headerlink" title="Consumer Liveness：Consumer存活"></a>Consumer Liveness：Consumer存活</h1><p>Group中每一个Consumer都被安排它订阅topic的partitions的一个子集，group会使用一个group锁在这些partition上。只要这些锁还被持有，其他的Consumer成员就不能从这些partition上读取数据。如果这些Consumer运行正常，这种情况就是我们想要的结果，这也是避免重复读消费数据的唯一办法。但是如果由于节点或者程序故障造成Consumer异常退出时，你需要能够释放这些锁，以便这些partition可以被安排到其他健康的Consumer上。</p>
<p>Kafka的group coordination protocol通过心跳机制来解决这个问题（Consumer通过心跳机制来实现持有锁和释放锁），在每一次rebalance之后，当前group中的所有Consumer都会定期向group的coordinator发送心跳信息，如果可以收到这个Consumer的心跳信息，就证明这个Consumer是正常的。一旦收到心跳信息，这个coordinator会重新开始计时。如果定时到了而还没有收到心跳信息，coordinator将会把这个consumer标记为dead，并且会向group的其他成员发送信号，这样就会进行rebalance操作，从而重新对这些partition进行分配。定时的时长就是session 时长，它可以通过客户端的<code>session.timeout.ms</code>这个参数来设置</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">props.put(<span class="string">"session.timeout.ms"</span>, <span class="string">"60000"</span>);</div></pre></td></tr></table></figure>
<p>session时长机制可以确保如果遇到节点或者应用崩亏、或者网络把consumer从group中隔离的情况，锁会被释放。但是，通常应用失败的情况处理起来有点麻烦，因为即使Consumer仍然向coordinator发送心跳信息也不能证明应用是正常运行的。</p>
<p>Consumer的poll循环是被设置为解决这个问题，当你调用<code>poll</code>方法或者其他的阻塞的API时所有的网络IO就已经完成。而且Consumer并不会在后台调用任何其他线程，这就意味着心跳信息只是在调用<code>poll</code>方法时发送给coordinator的。如果因为处理代码的逻辑部分抛出异常或者下游系统崩溃而造成应用停止<code>poll</code>方法调用，那么也会造成没有任何心跳被发送，然后session定时就会超时，这个group就会进行rebalance操作。</p>
<p>如果一个consumer在给定的时间内没有发送心跳信息，这种机制就会被触发一个虚假的rebalance操作。当然可以通过将定时设置足够大来避免这种情况的发生，它默认的时长是30s，但是它没有必要的将时长设置高达几分钟。设置为更长时长的一个问题就是它需要花费更多的时间来发现失败的Consumer。</p>
<h1 id="Delivery-Semantics：可靠的消息传递"><a href="#Delivery-Semantics：可靠的消息传递" class="headerlink" title="Delivery Semantics：可靠的消息传递"></a>Delivery Semantics：可靠的消息传递</h1><p>当一个consumer group刚开始被创建的时候，最初的offset是通过<code>auto.offset.reset</code>配置项来进行设置的。一旦Consumer开始处理数据，它根据应用的需要来定期地对offset进行commit。在每一次的rebalance之后，group会将这个offset将被设置为<code>Last Committed Offset</code>。但如果consumer在对已经处理过的message进行commit之前挂掉了，另外一个Consumer最终会重复处理这些已经处理但未commit的数据。应用中对offset进行commit越频繁，在一次崩溃后你重复消费的数据就会越少。</p>
<p>在前面的例子中，我们都已经设置了自动提交机制，当把<code>enable.auto.commit</code>设置为<code>true</code>（default）时，Consumer会周期性地自动触发的offset commit机制，这个时长可以通过<code>auto.commit.interval.ms</code>来进行配置。通过减少这个间隔，我们可以限制当崩溃发生时Consumer重新处理的数据量。</p>
<p>如果要使用consumer的commit API，首先需要在配置文件中将<code>enable.auto.commit</code>设置为false，来禁止自动commit</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">props.put(<span class="string">"enable.auto.commit"</span>, <span class="string">"false"</span>);</div></pre></td></tr></table></figure>
<p>这个commit API使用起来非常简单，难点在于如何与poll循环配合使用。下面的例子，主体中包含了commit细节实现的完整的poll循环。调用同步commit的API是处理手动提交的最简单的方法。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">try</span> &#123;</div><div class="line">  <span class="keyword">while</span> (running) &#123;</div><div class="line">    ConsumerRecords&lt;String, String&gt; records = consumer.poll(<span class="number">1000</span>);</div><div class="line">    <span class="keyword">for</span> (ConsumerRecord&lt;String, String&gt; record : records)</div><div class="line">      System.out.println(record.offset() + <span class="string">": "</span> + record.value());</div><div class="line"></div><div class="line">    <span class="keyword">try</span> &#123;</div><div class="line">      consumer.commitSync();</div><div class="line">    &#125; <span class="keyword">catch</span> (CommitFailedException e) &#123;</div><div class="line">      <span class="comment">// application specific failure handling</span></div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line">&#125; <span class="keyword">finally</span> &#123;</div><div class="line">  consumer.close();</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>使用无参的<code>commitSync</code>API进行commit的offset是在调用<code>poll</code>后返回的，因为是同步commit，所以这个调用将会被一直block直到commit成功或者因为不可恢复的错误而失败。处理过程中，需要特别注意的是message处理的时间大于session时长的这种情况，如果这种情况发生，coordinator就会把这个consumer踢出这个group，它会导致抛出<code>CommitFailedException</code>异常。应用程序应该能够处理这种错误，并对由于消费自从上一次成功提交后的message造成的变化进行回滚操作。</p>
<p>一般情况下，你应该确保message被成功处理后，这个offset被commit了。但是如果在commit被发送之前consumer挂掉了，然后这些messages就会被重复处理。如果这个commit机制保证<code>Last Committed Offset</code>不会超过<code>Current Position</code>（如图2所示，上图，非下图），然后系统就会保证<strong>at least once</strong>消息传递机制。</p>
<p><img src="/images/kafka/consumer-figure3.png" alt="consumer commit offset"></p>
<p>通过改变commit机制来保证<code>Current Position</code>不会超过<code>Last Committed Offset</code>，如上图所示，你将会得到<strong>at most once</strong>消息传递保证。如果在<code>Current Position</code>赶上<code>Last Committed Offset</code>之前consumer挂掉了，这段时间内的所有messages都会丢失，但是可以确定是没有消息会处理超过一次。为了实现这个机制，我们只需要改变commit和消息处理的顺序。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">try</span> &#123;</div><div class="line">  <span class="keyword">while</span> (running) &#123;</div><div class="line">  ConsumerRecords&lt;String, String&gt; records = consumer.poll(<span class="number">1000</span>);</div><div class="line"></div><div class="line">  <span class="keyword">try</span> &#123;</div><div class="line">    consumer.commitSync();</div><div class="line">    <span class="keyword">for</span> (ConsumerRecord&lt;String, String&gt; record : records)</div><div class="line">      System.out.println(record.offset() + <span class="string">": "</span> + record.value());</div><div class="line">    &#125; <span class="keyword">catch</span> (CommitFailedException e) &#123;</div><div class="line">      <span class="comment">// application specific failure handling</span></div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line">&#125; <span class="keyword">finally</span> &#123;</div><div class="line">  consumer.close();</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>要注意的是，如果使用<strong>默认的自动commit机制，系统是保证<code>at least once</code>消息处理</strong>，因为offset是在这些messages被应用处理后才进行commit的。在最糟糕的情况下，系统不得不重新处理的消息数量是由自动commit的间隔决定的（可以通过<code>auto.commit.interval.ms</code>设置）。</p>
<blockquote>
<p>思考：为什么kafka不能保证exactly once？</p>
</blockquote>
<p>通过应用commit API，你可以对重复处理的消息量进行更细的控制，在更极端的情况下，你甚至可以在每一条消息被处理后都进行commit，如下面的例子所示</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">try</span> &#123;</div><div class="line">  <span class="keyword">while</span> (running) &#123;</div><div class="line">    ConsumerRecords&lt;String, String&gt; records = consumer.poll(<span class="number">1000</span>);</div><div class="line"></div><div class="line">    <span class="keyword">try</span> &#123;</div><div class="line">      <span class="keyword">for</span> (ConsumerRecord&lt;String, String&gt; record : records) &#123;</div><div class="line">        System.out.println(record.offset() + <span class="string">": "</span> + record.value());</div><div class="line">        consumer.commitSync(Collections.singletonMap(record.partition(), <span class="keyword">new</span> OffsetAndMetadata(record.offset() + <span class="number">1</span>)));</div><div class="line">      &#125;</div><div class="line">    &#125; <span class="keyword">catch</span> (CommitFailedException e) &#123;</div><div class="line">      <span class="comment">// application specific failure handling</span></div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line">&#125; <span class="keyword">finally</span> &#123;</div><div class="line">  consumer.close();</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>在这个例子中，我们调用<code>commitSync</code>方法通过对明确的offset进行commit，要注意的是，要进行commit的offset应该是应用将要读取的下一条消息的offset。当<code>commitSync</code>方法被无参调用时，这个consumer对应用返回的<code>Last Offset（+1）</code>进行commit，但是在这里并不能使用，因为我们不允许<code>The Committed Position</code>超过我们实际的处理位置（<code>Current Position</code>）。</p>
<p>由于处理线程在每次进行commit请求并等待服务器返回这个过程中需要进行加锁，很明显对于大多数的应用场景，这种设计并不适用，这种设计会严重影响到consumer的吞吐量。更合理的设计是每接收N条消息后再进行commit，为了更高的吞吐量N的值可以进行调整。</p>
<p>本例中<code>commitSync</code>方法的参数是一个map的数据结构，key为topic partition，value为<code>OffsetAndMetadata</code>的实例。Commit API允许在每次commit时包含一些额外的元数据信息，这些数据信息可以是record进行commit的时间、要发送的host、或者应用程序中需要的任何其他信息，在本例中，我们并没有添加这个额外信息。</p>
<p>相比于对每接收一条message就进行commit，一个更加合理的机制是当你处理完每个partition的数据后进行commit offset。<code>ConsumerRecords</code>集合类提供了获取它内部每个partition集合以及每个partition内数据的方法。下面的例子详细描述这种机制：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">try</span> &#123;</div><div class="line">  <span class="keyword">while</span> (running) &#123;</div><div class="line">    ConsumerRecords&lt;String, String&gt; records = consumer.poll(Long.MAX_VALUE);</div><div class="line">    <span class="keyword">for</span> (TopicPartition partition : records.partitions()) &#123;</div><div class="line">      List&lt;ConsumerRecord&lt;String, String&gt;&gt; partitionRecords = records.records(partition);</div><div class="line">      <span class="keyword">for</span> (ConsumerRecord&lt;String, String&gt; record : partitionRecords)</div><div class="line">        System.out.println(record.offset() + <span class="string">": "</span> + record.value());</div><div class="line"></div><div class="line">      <span class="keyword">long</span> lastoffset = partitionRecords.get(partitionRecords.size() - <span class="number">1</span>).offset();</div><div class="line">      consumer.commitSync(Collections.singletonMap(partition, <span class="keyword">new</span> OffsetAndMetadata(lastoffset + <span class="number">1</span>)));</div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line">&#125; <span class="keyword">finally</span> &#123;</div><div class="line">  consumer.close();</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>截止到目前为止，我们主要研究的是同步commit的API，但是consumer也提供了异步提交的API——<code>commitAsync</code>。使用异步commit一般情况下会提高系统的吞吐量，因为应用可以在commit结果还未返回时就能开始处理下一批的message。但是你可能在之后才会发现commit失败了，这是需要开发者进行权衡。下面的例子是异步commit的基本用法。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">try</span> &#123;</div><div class="line">  <span class="keyword">while</span> (running) &#123;</div><div class="line">    ConsumerRecords&lt;String, String&gt; records = consumer.poll(<span class="number">1000</span>);</div><div class="line">    <span class="keyword">for</span> (ConsumerRecord&lt;String, String&gt; record : records)</div><div class="line">      System.out.println(record.offset() + <span class="string">": "</span> + record.value());</div><div class="line"></div><div class="line">    consumer.commitAsync(<span class="keyword">new</span> OffsetCommitCallback() &#123;</div><div class="line">      <span class="meta">@Override</span></div><div class="line">      <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onComplete</span><span class="params">(Map&lt;TopicPartition, OffsetAndMetadata&gt; offsets, Exception exception)</span> </span>&#123;</div><div class="line">        <span class="keyword">if</span> (exception != <span class="keyword">null</span>) &#123;</div><div class="line">          <span class="comment">// application specific failure handling</span></div><div class="line">        &#125;</div><div class="line">      &#125;</div><div class="line">    &#125;);</div><div class="line">  &#125;</div><div class="line">&#125; <span class="keyword">finally</span> &#123;</div><div class="line">  consumer.close();</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>在本例中，在<code>commitAsync</code>中我们提供了回调方法，这个方法只会在commit完成后（不管成功还是失败）才会被consumer触发。如果你不需要这个设置，你也可以使用无参的<code>commitAsync</code>API。</p>
<blockquote>
<p>思考：在进行commit时，如果commit失败，consumer会怎么处理，同步与异步的处理过程是一样的吗？</p>
</blockquote>
<h1 id="Consumer-Group-Inspection：consumer-group查看"><a href="#Consumer-Group-Inspection：consumer-group查看" class="headerlink" title="Consumer Group Inspection：consumer group查看"></a>Consumer Group Inspection：consumer group查看</h1><p>当一个consuemr group是active，你可以通过在命令行运行<code>consumer-groups.sh</code>脚本来查看partition assignment和group消费情况，这个脚本存放在Kafka的<code>bin</code>目录下</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># bin/kafka-consumer-groups.sh --new-consumer --describe --group consumer-tutorial-group --bootstrap-server localhost:9092</span></div></pre></td></tr></table></figure>
<p>输出的结果如下所示</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">GROUP, TOPIC, PARTITION, CURRENT OFFSET, LOG END OFFSET, LAG, OWNER</div><div class="line">consumer-tutorial-group, consumer-tutorial, 0, 6667, 6667, 0, consumer-1_/127.0.0.1</div><div class="line">consumer-tutorial-group, consumer-tutorial, 1, 6667, 6667, 0, consumer-2_/127.0.0.1</div><div class="line">consumer-tutorial-group, consumer-tutorial, 2, 6666, 6666, 0, consumer-3_/127.0.0.1</div></pre></td></tr></table></figure>
<p>上面的结果展示了这个consumer group的partition分配以及哪个consumer实例消费这个partition，还有<code>Last Committed Offset</code>（这里也可以认为是<code>Current Offset</code>）。每个partition的lag就是这个partition的最后offset与<code>Last Committed Offset</code>的差值。Administrators会一直进行监控以确保consuemr group能跟得上producers。</p>
<h1 id="Using-Manual-Assignment：使用手动的assign"><a href="#Using-Manual-Assignment：使用手动的assign" class="headerlink" title="Using Manual Assignment：使用手动的assign"></a>Using Manual Assignment：使用手动的assign</h1><p>正如本文开始所述的一样，新的Consumer实现了对那些不需要group的场景进行更细粒度的控制，对这种场景的支持是建议使用新Consumer API的重要原因之一。旧的<code>simple consumer</code>虽然也提供这样的设计，但是却需要你自己做很多的容错处理。而新的Consumer API，你只需要提供了你需要读取的topic的partition，然后就可以开始读取数据，其他的东西Consumer会帮你处理。</p>
<p>下面的例子展示了如何使用<code>partitionsFor</code> API来分配安排一个topic的所有partition</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">List&lt;TopicPartition&gt; partitions = <span class="keyword">new</span> ArrayList&lt;&gt;();</div><div class="line"><span class="keyword">for</span> (PartitionInfo partition : consumer.partitionsFor(topic))</div><div class="line">  partitions.add(<span class="keyword">new</span> TopicPartition(topic, partition.partition()));</div><div class="line">consumer.assign(partitions);</div></pre></td></tr></table></figure>
<p>和<code>subscribe</code>方法相似，调用<code>assign</code>方法时必须传入consuemr要读取的所有parition的集合，一旦partition被分配了，poll循环部分就与前面的过程基本一样。</p>
<p>有一点需要的注意的是，不管是一个simple consumer还是一个consumer group，所有offset的commit都必须经过<strong>group coordinator</strong>。因此，如果你需要进行commit，你必须设置一个合适的<code>group.id</code>，避免与其他的group产生冲突。如果一个simple consumer试图使用一个与一个active group相同的id进行commit offset，coordinator将会拒绝这个commit请求，会返回一个<code>CommitFailedException</code>异常。但是，如果一个simple consumer与另一个simple consumer使用同一个id，系统就不会报任何错误。</p>
<h1 id="Conclusion：结论"><a href="#Conclusion：结论" class="headerlink" title="Conclusion：结论"></a>Conclusion：结论</h1><p>新的Consumer给Kafka社区带了很多的好处，比如，简洁的API、更好的安全性和对ZK更少的依赖。本文介绍了new consumer的基本用法，并注重于poll循环模型以及使用commit API来控制传递机制。虽然还有很多需要讨论的地方，但是本文对于基本的使用是足够了。尽管新的comsumer还在开发中，但是我们仍然鼓励你去尝试使用。使用中如果遇到什么问题，欢迎通过邮件告诉我们.</p>
<hr>
<p>参考</p>
<ul>
<li><a href="http://www.confluent.io/blog/tutorial-getting-started-with-the-new-apache-kafka-0.9-consumer-client" target="_blank" rel="external">Introducing the Kafka Consumer: Getting Started with the New Apache Kafka 0.9 Consumer Client</a></li>
</ul>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[Mac常用软件及环境配置]]></title>
      <url>http://matt33.com/2016/07/09/mac-software/</url>
      <content type="html"><![CDATA[<p>近段时间因为在公司实习，公司提供的电脑都是Mac，还给发了一台全新的Mac pro，刚开始用的时候有很多不习惯的地方，但是用了几天之后就感觉Mac真的爽到爆啊，本篇文章就记录一下自己感觉在Mac上用到的一些不错的软件，以及Mac下一些常用编程工具的配置安装方法，这样也方便自己以后查看，本篇文章会一直保持更新。</p>
<h1 id="Mac基本配置"><a href="#Mac基本配置" class="headerlink" title="Mac基本配置"></a>Mac基本配置</h1><p>推荐一些Mac下常用的软件</p>
<ul>
<li>笔记：<a href="https://www.yinxiang.com/download/?offer=www_menu" target="_blank" rel="external">Evernote</a>，<a href="http://www.jianshu.com/p/a26fffc3c746" target="_blank" rel="external">Evernote（印象笔记）用户如何使用Markdown</a>；</li>
<li>MarkDown：<a href="http://zh.mweb.im/" target="_blank" rel="external">MWeb</a>、<a href="http://25.io/mou/" target="_blank" rel="external">Mou</a>、Ulysses、<a href="http://macdown.uranusjr.com/" target="_blank" rel="external">MacDown</a>；</li>
<li>编辑器：<a href="https://atom.io/" target="_blank" rel="external">Atom</a>；</li>
<li>思维导图：<a href="http://www.xmindchina.net/" target="_blank" rel="external">XMid</a>、SimpleMind；</li>
<li>NTFS挂载：<a href="http://www.tuxera.com/products/tuxera-ntfs-for-mac/" target="_blank" rel="external">Tuxera NTFS</a>（<a href="http://www.orsoon.com/Mac/129966.html" target="_blank" rel="external">序列号</a>，建议买正版）；</li>
<li>播放器：MPV（mpv安装及快捷键操作参考<a href="https://intxt.net/meet-mpv/" target="_blank" rel="external">mpv安装</a>一文，<a href="https://mpv.io/installation/" target="_blank" rel="external">mpv安装地址</a>）；</li>
<li>浏览器：chrome，必须是chrome；</li>
<li>上网：<a href="https://github.com/shadowsocks/shadowsocks-iOS/releases/" target="_blank" rel="external">shadowsocks</a>；</li>
<li>英文写作检查的软件：1Checker;</li>
<li><a href="http://www.jianshu.com/p/c98c73704ff6" target="_blank" rel="external">Mac vim高亮设置</a>;</li>
</ul>
<p>博文推荐</p>
<ul>
<li><a href="http://www.jianshu.com/p/19e8ffd91576" target="_blank" rel="external">Mac下开发常用的必备软件</a>，这里有office、ps等工具的安装；</li>
<li><a href="http://www.iphoneba.net/231.html" target="_blank" rel="external">Adobe After Effects CC 2015 Mac</a>，推荐使用正版；</li>
<li><a href="http://www.waitsun.com/lightroom-cc-6-0.html" target="_blank" rel="external">Adobe Photoshop Lightroom CC for Mac 6.0 优秀的图像后期处理软件</a>，推荐使用正版；</li>
</ul>
<h2 id="mpv-的一些常用快捷键"><a href="#mpv-的一些常用快捷键" class="headerlink" title="mpv 的一些常用快捷键"></a>mpv 的一些常用快捷键</h2><p>mpv 是 mac 下使用非常舒服的一款视频播放器，下面是一些常用的快捷键</p>
<table>
<thead>
<tr>
<th>快捷键</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>SPACE</td>
<td>暂停/播放切换</td>
</tr>
<tr>
<td>UP</td>
<td>快进 60 秒</td>
</tr>
<tr>
<td>DOWN</td>
<td>回退 60 秒</td>
</tr>
<tr>
<td>LEFT</td>
<td>回退 5 秒</td>
</tr>
<tr>
<td>RIGHT</td>
<td>快进 5 秒</td>
</tr>
<tr>
<td><code>]</code></td>
<td>加速播放</td>
</tr>
<tr>
<td><code>[</code></td>
<td>减速播放</td>
</tr>
<tr>
<td>j</td>
<td>循环选择字幕</td>
</tr>
<tr>
<td>J</td>
<td>反向循环选择字幕</td>
</tr>
<tr>
<td>#</td>
<td>循环切换音轨</td>
</tr>
<tr>
<td>f</td>
<td>切换全屏状态</td>
</tr>
<tr>
<td>T</td>
<td>切换视频窗口是否总在最前</td>
</tr>
<tr>
<td>s</td>
<td>视频截图，包含字幕</td>
</tr>
<tr>
<td>S</td>
<td>视频截图，不带字幕</td>
</tr>
<tr>
<td>Alt+s</td>
<td>自动逐帧视频截图，再按一次停止截图</td>
</tr>
</tbody>
</table>
<h2 id="chrome常用配置"><a href="#chrome常用配置" class="headerlink" title="chrome常用配置"></a>chrome常用配置</h2><p>chrome既方便又强大，于是乎，不得不单独弄出一小章来介绍。</p>
<h3 id="常用小插件"><a href="#常用小插件" class="headerlink" title="常用小插件"></a>常用小插件</h3><p>对工程师来说，可以参考这篇文章<a href="https://mp.weixin.qq.com/s?__biz=MzA4NTQwNDcyMA==&amp;mid=402064553&amp;idx=1&amp;sn=4bc95ed03916f87cc8dfd17baed54f24" target="_blank" rel="external">吐血推荐珍藏的Chrome插件</a>。</p>
<ul>
<li>代理：<a href="https://chrome.google.com/webstore/detail/proxy-switchyomega/padekgcemlokbadohgkifijomclgjgif" target="_blank" rel="external">switchyomega</a>；</li>
<li>流程图：<a href="https://chrome.google.com/webstore/detail/gliffy-diagrams/bhmicilclplefnflapjmnngmkkkkpfad" target="_blank" rel="external">gliffy</a>;</li>
<li>MarkDown：<a href="chrome-extension://elifhakcjgalahccnjkneoccemfahfoa/common/options.html" target="_blank" rel="external">MarkDown Here</a>;</li>
<li>词典：<a href="https://chrome.google.com/webstore/detail/%E7%BF%B0%E6%9E%97%E8%8B%B1%E6%B1%89%E5%8F%8C%E8%A7%A3%E8%AF%8D%E5%85%B8/fidicgekecdkdmkjghdgadgdmcfodfid" target="_blank" rel="external">翰林英汉双解词典</a>;</li>
<li>Momentum：使用这个插件每次打开一个 Tab 时，不再是一个空白页面，而是一副精美的图片；</li>
<li>Alexa Traffic Rank：Alexa排名是指网站的世界排名，非常有权威。直接主流网站或博客绝对是有Alexa排名的，我们在浏览博客或者网站的时候就可以通过Alexa排名知晓该网站的流行程度，适用于经常看博客的人，装了这个插件一键查看网站排名；</li>
<li>Isometric Contributions：一个小玩意，可以让在 GitHub 上的 commit 像盖楼一样的展示，很有趣；</li>
<li>Avatars for Github：顾名思义，默认我们在 GitHub 主页动态只能看到 id 的，而安装了这个插件就可以看到 GitHub 头像了，让你一眼就能知道是谁；</li>
</ul>
<h1 id="Mac下常用快捷键"><a href="#Mac下常用快捷键" class="headerlink" title="Mac下常用快捷键"></a>Mac下常用快捷键</h1><table>
<thead>
<tr>
<th>说明</th>
<th>快捷键</th>
</tr>
</thead>
<tbody>
<tr>
<td>网页刷新</td>
<td>command+r</td>
</tr>
<tr>
<td>自定义截图，保存到桌面</td>
<td>command+shfit+4</td>
</tr>
<tr>
<td>全屏截图，保存到桌面</td>
<td>command＋shift＋3</td>
</tr>
<tr>
<td>自定义截图，保存到剪贴板</td>
<td>command+shfit+4+ctrl</td>
</tr>
<tr>
<td>显示器</td>
<td>control+shift+电源键</td>
</tr>
<tr>
<td>将文本编辑器由带格式变为存文本</td>
<td>command+shfit+t</td>
</tr>
<tr>
<td>EverNote无格式粘贴</td>
<td>command+shift+option+v</td>
</tr>
<tr>
<td>文件/文件夹重命名</td>
<td>选中该文件/文件夹，点击回车键</td>
</tr>
</tbody>
</table>
<p>快捷键可以参考<a href="https://support.apple.com/zh-cn/HT201236" target="_blank" rel="external">Mac键盘快捷键</a>一文.</p>
<p>这里有一篇Bash下的快捷键的wiki，<a href="https://github.com/hokein/Wiki/wiki/Bash-Shell%E5%B8%B8%E7%94%A8%E5%BF%AB%E6%8D%B7%E9%94%AE" target="_blank" rel="external">Bash Shell常用快捷键</a>，可以方便查找bash下的常用快捷键。</p>
<p>其他博文推荐：</p>
<ol>
<li><a href="http://wuchong.me/blog/2014/06/29/the-first-experience-of-mac/" target="_blank" rel="external">Mac上手体验</a></li>
<li><a href="http://www.macx.cn/thread-2133104-1-1.html" target="_blank" rel="external">Mac快速锁屏</a></li>
<li><a href="https://support.apple.com/kb/PH18669?locale=zh_CN&amp;viewlocale=zh_CN" target="_blank" rel="external">Mac锁屏后设置需要输密码</a></li>
<li><a href="http://www.hangge.com/blog/cache/detail_540.html" target="_blank" rel="external">Mac下文本编辑器</a></li>
<li><a href="http://popozhu.github.io/2013/09/24/mac%E5%85%89%E6%A0%87%E9%80%9F%E5%BA%A6%E8%B0%83%E6%95%B4/" target="_blank" rel="external">Mac光标速度调整</a></li>
</ol>
<h1 id="Mac终端iTerm2配置"><a href="#Mac终端iTerm2配置" class="headerlink" title="Mac终端iTerm2配置"></a>Mac终端iTerm2配置</h1><p>Mac下的iTerm2用着真的超爽</p>
<h2 id="iTerm2下载安装"><a href="#iTerm2下载安装" class="headerlink" title="iTerm2下载安装"></a>iTerm2下载安装</h2><p><a href="http://www.iterm2.com/" target="_blank" rel="external">iTerm2下载</a></p>
<p>下载完直接安装即可。</p>
<h2 id="安装oh-my-zsh"><a href="#安装oh-my-zsh" class="headerlink" title="安装oh-my-zsh"></a>安装oh-my-zsh</h2><figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">curl -L https://raw.github.com/robbyrussell/oh-my-zsh/master/tools/install.sh | sh</div></pre></td></tr></table></figure>
<p>安装成功后的效果如下图所示</p>
<p><img src="/images/mac/iterm-1.png" alt="zsh"></p>
<h2 id="安装powerline"><a href="#安装powerline" class="headerlink" title="安装powerline"></a>安装powerline</h2><p>关于powerline的介绍可以参考<a href="http://cenalulu.github.io/linux/mac-powerline/" target="_blank" rel="external">为Bash和VIM配置一个美观奢华的状态提示栏</a>这篇文章，powerline就是一个全局的状态提示栏，安装方法如下：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 先安装pip指令</span></div><div class="line">sudo easy_install pip</div><div class="line"><span class="comment"># 安装管道</span></div><div class="line">pip install powerline-status</div></pre></td></tr></table></figure>
<p>在第二步安装时，出现了这个错误，<code>error: [Errno 1] Operation not permitted: u&#39;/System/Library/Frameworks/Python.framework/Versions/2.7/bin/powerline&#39;</code>，如下图所示</p>
<p><img src="/images/mac/iterm-2.png" alt="error"></p>
<p>这个问题出现的原因，因为没有安装python，解决办法如下</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 1.安装Homebrew</span></div><div class="line">/usr/bin/ruby <span class="_">-e</span> <span class="string">"<span class="variable">$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)</span>"</span></div><div class="line"><span class="comment"># 2.配置python</span></div><div class="line">brew install python</div><div class="line"><span class="comment"># 3.安装管道</span></div><div class="line">pip install --user powerline-status</div></pre></td></tr></table></figure>
<p>powerline的安装可以参考：</p>
<ol>
<li>brew安装参考<a href="http://brew.sh/" target="_blank" rel="external">官网</a></li>
<li>PowerLine安装参考<a href="http://powerline.readthedocs.io/en/latest/installation/osx.html" target="_blank" rel="external">官网</a></li>
</ol>
<h2 id="安装字体库"><a href="#安装字体库" class="headerlink" title="安装字体库"></a>安装字体库</h2><figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 下载字体库</span></div><div class="line">git <span class="built_in">clone</span> https://github.com/powerline/fonts.git</div><div class="line"><span class="comment"># 安装所有字体</span></div><div class="line"><span class="built_in">cd</span> fonts</div><div class="line">./install.sh</div></pre></td></tr></table></figure>
<p>安装成功后，如下图所示</p>
<p><img src="/images/mac/iterm-3.png" alt="font"></p>
<p>安装完成后会提示所有的字体均已下载到<code>/Users/superdanny/Library/Fonts</code>路径。</p>
<h2 id="字体设置、配色方案设置及主题设置"><a href="#字体设置、配色方案设置及主题设置" class="headerlink" title="字体设置、配色方案设置及主题设置"></a>字体设置、配色方案设置及主题设置</h2><h3 id="字体配置"><a href="#字体配置" class="headerlink" title="字体配置"></a>字体配置</h3><p>安装完字体库之后，把iTerm 2的设置里的Profile中的Text 选项卡中里的<code>Regular Font</code>和<code>Non-ASCII Font</code>的字体都设置成powerline的字体，我这里设置的字体是<code>14pt Meslo LG S DZ Regular for Powerline</code>.</p>
<p><img src="/images/mac/iterm-4.png" alt="font-setting"></p>
<h3 id="配色方案"><a href="#配色方案" class="headerlink" title="配色方案"></a>配色方案</h3><h4 id="安装配色方案"><a href="#安装配色方案" class="headerlink" title="安装配色方案"></a>安装配色方案</h4><p>需要先在github下下载solarized工程，<a href="https://github.com/altercation/solarized" target="_blank" rel="external">solarized github地址</a></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">git clone https://github.com/altercation/solarized</div></pre></td></tr></table></figure>
<p>然后进入刚刚下载的工程的<code>solarized/iterm2-colors-solarized</code> 下双击 <code>Solarized Dark.itermcolors</code> 和 <code>Solarized Light.itermcolors</code> 两个文件就可以把配置文件导入到 iTerm2 里.</p>
<h4 id="配置配色方案"><a href="#配置配色方案" class="headerlink" title="配置配色方案"></a>配置配色方案</h4><p>通过load presets选择刚刚安装的配色主题即可</p>
<p><img src="/images/mac/iterm-5.png" alt="color"></p>
<h3 id="主题设置"><a href="#主题设置" class="headerlink" title="主题设置"></a>主题设置</h3><p>这里使用的是agnoster主题，<a href="https://github.com/fcamblor/oh-my-zsh-agnoster-fcamblor" target="_blank" rel="external">oh-my-zsh-agnoster-fcamblor Github地址</a></p>
<h4 id="下载安装"><a href="#下载安装" class="headerlink" title="下载安装"></a>下载安装</h4><figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 1.下载主题</span></div><div class="line">git <span class="built_in">clone</span> https://github.com/fcamblor/oh-my-zsh-agnoster-fcamblor</div><div class="line"><span class="comment"># 2.安装主题</span></div><div class="line"><span class="built_in">cd</span> oh-my-zsh-agnoster-fcamblor</div><div class="line">./install</div></pre></td></tr></table></figure>
<h4 id="设置该主题"><a href="#设置该主题" class="headerlink" title="设置该主题"></a>设置该主题</h4><p>编辑<code>~/.zshrc</code>文件，然后将<code>ZSH_THEME</code>后面的字段改为<code>agnoster</code>。<code>ZSH_THEME=&quot;agnoster&quot;</code>（agnoster即为要设置的主题）.</p>
<h4 id="增加指令高亮效果"><a href="#增加指令高亮效果" class="headerlink" title="增加指令高亮效果"></a>增加指令高亮效果</h4><p>指令高亮效果作用是当用户输入正确命令时指令会绿色高亮，错误时命令红色高亮，这里需要先下载<code>zsh-syntax-highlighting</code></p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 1.下载工程项目</span></div><div class="line">git <span class="built_in">clone</span> git://github.com/zsh-users/zsh-syntax-highlighting.git</div><div class="line"><span class="comment"># 2.打开.zshrc文件，在最后添加下面内容</span></div><div class="line"><span class="built_in">source</span> /Users/matt/git//zsh-syntax-highlighting/zsh-syntax-highlighting.zsh</div><div class="line"><span class="comment"># 3.打开.zshrc文件，在最后面添加下面内容</span></div><div class="line">plugins=(zsh-syntax-highlighting)</div></pre></td></tr></table></figure>
<p>配置完之后效果如下图所示</p>
<p><img src="/images/mac/iterm-6.png" alt="end"></p>
<h2 id="iTerm2快捷键"><a href="#iTerm2快捷键" class="headerlink" title="iTerm2快捷键"></a>iTerm2快捷键</h2><p>iTerm2快捷键的使用可以参考<a href="http://cnbin.github.io/blog/2015/06/20/iterm2-kuai-jie-jian-da-quan/" target="_blank" rel="external">Iterm2快捷键</a>这篇文章，这里给出一些常用的命令</p>
<table>
<thead>
<tr>
<th>说明</th>
<th>快捷键</th>
</tr>
</thead>
<tbody>
<tr>
<td>新建标签</td>
<td>command + t</td>
</tr>
<tr>
<td>关闭标签</td>
<td>command + w</td>
</tr>
<tr>
<td>切换标签</td>
<td>command + 数字 command + 左右方向键</td>
</tr>
<tr>
<td>切换全屏</td>
<td>command + enter</td>
</tr>
<tr>
<td>查找</td>
<td>command +f</td>
</tr>
<tr>
<td>垂直分屏</td>
<td>command + d</td>
</tr>
<tr>
<td>水平分屏</td>
<td>command + shift + d</td>
</tr>
<tr>
<td>切换屏幕</td>
<td>command + option + 方向键 command + [ 或 command + ]</td>
</tr>
<tr>
<td>查看历史命令</td>
<td>command + ;</td>
</tr>
<tr>
<td>查看剪贴板历史</td>
<td>command + shift + h</td>
</tr>
<tr>
<td>清除当前行</td>
<td>ctrl + u</td>
</tr>
<tr>
<td>到行首</td>
<td>ctrl + a</td>
</tr>
<tr>
<td>到行尾</td>
<td>ctrl + e</td>
</tr>
<tr>
<td>前进后退</td>
<td>ctrl + f/b (相当于左右方向键)</td>
</tr>
<tr>
<td>上一条命令</td>
<td>ctrl + p</td>
</tr>
<tr>
<td>搜索命令历史</td>
<td>ctrl + r</td>
</tr>
<tr>
<td>删除当前光标的字符</td>
<td>ctrl + d</td>
</tr>
<tr>
<td>删除光标之前的字符</td>
<td>ctrl + h</td>
</tr>
<tr>
<td>删除光标之前的单词</td>
<td>ctrl + w</td>
</tr>
<tr>
<td>删除到文本末尾</td>
<td>ctrl + k</td>
</tr>
<tr>
<td>交换光标处文本</td>
<td>ctrl + t</td>
</tr>
<tr>
<td>清屏1</td>
<td>command + r</td>
</tr>
<tr>
<td>清屏2</td>
<td>ctrl + l</td>
</tr>
</tbody>
</table>
<h1 id="编程环境配置"><a href="#编程环境配置" class="headerlink" title="编程环境配置"></a>编程环境配置</h1><h2 id="Java"><a href="#Java" class="headerlink" title="Java"></a>Java</h2><p>一般情况下，可能需要安装多个版本的JDK，具体各个版本的下载，JDK7和JDK8可以在官网上直接下载，而JDK6的下载资源就比较难找了，可以参考<a href="http://www.codecate.com/code/archives/16" target="_blank" rel="external">Mac安装jdk1.6 1.7 1.8</a>这篇文章</p>
<p>下载安装完这三个版本的JDK之后，需要进行以下配置</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># bash下是~/.bashrc文件</span></div><div class="line"><span class="built_in">export</span> JAVA_6_HOME=/Library/Java/JavaVirtualMachines/1.6.0.jdk/Contents/Home/</div><div class="line"><span class="built_in">export</span> JAVA_7_HOME=/Library/Java/JavaVirtualMachines/jdk1.7.0_76.jdk/Contents/Home/</div><div class="line"><span class="built_in">export</span> JAVA_8_HOME=/Library/Java/JavaVirtualMachines/jdk1.8.0_91.jdk/Contents/Home/</div><div class="line"><span class="built_in">export</span> JAVA_HOME=<span class="variable">$JAVA_7_HOME</span></div><div class="line"><span class="built_in">alias</span> jdk8=<span class="string">'export JAVA_HOME=$JAVA_8_HOME'</span></div><div class="line"><span class="built_in">alias</span> jdk7=<span class="string">'export JAVA_HOME=$JAVA_7_HOME'</span></div><div class="line"><span class="built_in">alias</span> jdk6=<span class="string">'export JAVA_HOME=$JAVA_6_HOME'</span></div><div class="line"><span class="built_in">export</span> PATH=<span class="variable">$PATH</span>:<span class="variable">$JAVA_HOME</span>/bin</div></pre></td></tr></table></figure>
<h2 id="IntelliJ-IDEA"><a href="#IntelliJ-IDEA" class="headerlink" title="IntelliJ IDEA"></a>IntelliJ IDEA</h2><h3 id="idea安装"><a href="#idea安装" class="headerlink" title="idea安装"></a>idea安装</h3><p><a href="https://www.jetbrains.com/idea/download/" target="_blank" rel="external">idea下载地址</a></p>
<p>如果下载的版本是2016.1版，这里有一个<a href="http://aiyougege.com/articles/022711.html" target="_blank" rel="external">激活码</a>，不过推荐购买正版，免费版推荐社区版，一般的开发也就够用了。</p>
<h3 id="Google-Java编程规范配置"><a href="#Google-Java编程规范配置" class="headerlink" title="Google Java编程规范配置"></a>Google Java编程规范配置</h3><p>参考<a href="http://zacard.net/2016/04/11/idea-google-code-style/" target="_blank" rel="external">Idea直接导入xml文件</a>一文。</p>
<p>idea可以支持自定义的code style，并且google code style也提供了对idea的xml配置，直接导入就可以在idea中使用google提倡的code style了。</p>
<p>使用方法：</p>
<ol>
<li>从github上clone <a href="https://github.com/google/styleguide" target="_blank" rel="external">Google Style GitHub</a>；</li>
<li>复制对应的xml配置（如intellij-java-google-style.xml）到“~/Library/Preferences/IDEA/codestyles/”下</li>
<li>重启idea在Prefrence-&gt;Editor—&gt;Code Stytle-&gt;Java,选择GoogleStyle即可</li>
</ol>
<p>mac下格式化代码的快捷键： <code>command+alt+L</code></p>
<h3 id="简单配置"><a href="#简单配置" class="headerlink" title="简单配置"></a>简单配置</h3><p>需要配置的内容主要有以下几项：</p>
<ol>
<li>自动行号显示</li>
<li>字体</li>
<li>SDK设置（就是jdk，scala等设置）</li>
<li>maven设置</li>
<li>快捷键</li>
</ol>
<h3 id="快捷键"><a href="#快捷键" class="headerlink" title="快捷键"></a>快捷键</h3><p>常用的快捷键如下表所示</p>
<table>
<thead>
<tr>
<th>说明</th>
<th>快捷键</th>
</tr>
</thead>
<tbody>
<tr>
<td>查看所选代码的源码</td>
<td>cmd + ↓</td>
</tr>
<tr>
<td>查看maven依赖</td>
<td>opt+shift+cmd+U</td>
</tr>
<tr>
<td>智能补齐代码</td>
<td>opt + enter</td>
</tr>
<tr>
<td>生成一些常用方法，如：toString、get 等</td>
<td>control + enter</td>
</tr>
</tbody>
</table>
<p>关于快捷键可以参考<a href="http://wiki.jikexueyuan.com/project/intellij-idea-tutorial/keymap-mac-introduce.html" target="_blank" rel="external">Mac下idea快捷键</a>一文。</p>
<ul>
<li><a href="http://baowp.iteye.com/blog/1989575" target="_blank" rel="external">Mac下Idea打开Maven的jar包依赖图</a></li>
</ul>
<h2 id="PyCharm"><a href="#PyCharm" class="headerlink" title="PyCharm"></a>PyCharm</h2><h3 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h3><p><a href="https://www.jetbrains.com/pycharm/download/" target="_blank" rel="external">PyCharm下载地址</a></p>
<p>2016版的可以使用<a href="http://blog.csdn.net/jiang314/article/details/51680072" target="_blank" rel="external">注册码</a>进行破解，不过推荐购买正版。</p>
<h1 id="其他常用命令安装"><a href="#其他常用命令安装" class="headerlink" title="其他常用命令安装"></a>其他常用命令安装</h1><h2 id="tree命令安装"><a href="#tree命令安装" class="headerlink" title="tree命令安装"></a>tree命令安装</h2><figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 需要先安装HomeBrew</span></div><div class="line">brew install tree</div></pre></td></tr></table></figure>
<h2 id="Sublime-Text-3"><a href="#Sublime-Text-3" class="headerlink" title="Sublime Text 3"></a>Sublime Text 3</h2><p>参考下面的文章：</p>
<ol>
<li><a href="https://blog.csdn.net/javaexploreroooo/article/details/77989993" target="_blank" rel="external">最新版本sublime text3注册码</a>；</li>
<li><a href="https://jingyan.baidu.com/article/4f7d5712d707161a21192773.html" target="_blank" rel="external">Sublime Text 3 Mac版怎么安装插件</a>；</li>
<li><a href="https://www.jianshu.com/p/aa30cc25c91b" target="_blank" rel="external">Sublime插件：Markdown篇</a>，文章下面有Sublime的其他使用的系列文章；</li>
</ol>
<h1 id="Mac下遇到的其他问题"><a href="#Mac下遇到的其他问题" class="headerlink" title="Mac下遇到的其他问题"></a>Mac下遇到的其他问题</h1><h2 id="bashrc每次打开iterm都要重新加载"><a href="#bashrc每次打开iterm都要重新加载" class="headerlink" title="~/.bashrc每次打开iterm都要重新加载"></a>~/.bashrc每次打开iterm都要重新加载</h2><p>参考<a href="http://www.zhihu.com/question/29653438" target="_blank" rel="external">文章</a></p>
<p>原因：使用的zsh，而不是bash，所以zsh没有义务去加载<code>~/.bashrc</code>文件，zsh下别名一般放置到<code>~/.zshrc</code>文件中。</p>
<p>解决办法：在<code>~/.zshrc</code>文件的最后添加<code>source ~/.bashrc</code>.</p>
<h2 id="修改电脑名的方法"><a href="#修改电脑名的方法" class="headerlink" title="修改电脑名的方法"></a>修改电脑名的方法</h2><p>有人可能感觉跟我一样有强迫症，看到电脑名太长影响终端的显示，就想着怎么修改一下。</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 执行下面命令“mac”是你想要改的电脑名称</span></div><div class="line">sudo scutil --set HostName mac</div></pre></td></tr></table></figure>
<blockquote>
<p>注：关闭终端之后，重新打开终端就会生效。</p>
</blockquote>
<h2 id="修改电脑名导致的错误"><a href="#修改电脑名导致的错误" class="headerlink" title="修改电脑名导致的错误"></a>修改电脑名导致的错误</h2><p>使用上面的方法修改电脑名，可能会导致一个这样的错误.</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 其中 mac 为自己设置的电脑名，不同的电脑名显示不一样</span></div><div class="line">java.net.UnknownHostException: mac: mac: nodename nor servname provided, or not known</div></pre></td></tr></table></figure>
<p>这个问题和路由映射有关系，处理方法就是对 mac 做个DNS解析指向127.0.0.1.</p>
<p>修改文件 <code>/etc/hosts</code>，在里面增加对 127.0.0.1 的解析.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">127.0.0.1    mac    localhost</div></pre></td></tr></table></figure>
<p>保存生效后，就没有问题了。</p>
<hr>
<p>参考：</p>
<ul>
<li><a href="http://www.jianshu.com/p/7de00c73a2bb" target="_blank" rel="external">iTerm 2 &amp;&amp; Oh My Zsh</a></li>
<li><a href="http://cnbin.github.io/blog/2015/06/20/iterm2-kuai-jie-jian-da-quan/" target="_blank" rel="external">Iterm2快捷键</a></li>
<li><a href="http://www.zhihu.com/question/29653438" target="_blank" rel="external">为什么我的Mac不加载/etc/bashrc文件呢？</a></li>
</ul>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[Redis简单介绍]]></title>
      <url>http://matt33.com/2016/06/06/redis-introduce/</url>
      <content type="html"><![CDATA[<p>本文是根据我在<a href="https://www.shiyanlou.com/courses/106" target="_blank" rel="external">实验楼-Redis基础教程</a>中学习的总结，简单讲述了一下Redis的安装和使用。</p>
<h1 id="Redis简介"><a href="#Redis简介" class="headerlink" title="Redis简介"></a>Redis简介</h1><h2 id="什么是Redis"><a href="#什么是Redis" class="headerlink" title="什么是Redis"></a>什么是Redis</h2><p>REmote DIctionary Server(Redis) 是一个由Salvatore Sanfilippo写的key-value存储系统。Redis提供了一些丰富的数据结构，包括 <code>lists</code>, <code>sets</code>, <code>ordered sets</code> 以及 <code>hashes</code> ，当然还有和<code>Memcached</code>一样的 strings结构。Redis当然还包括了对这些数据结构的丰富操作。</p>
<p>Redis常被称作是一款数据结构服务器（<code>data structure server</code>）。Redis的键值可以包括字符串（strings）类型，同时它还包括哈希（hashes）、列表（lists）、集合（sets）和 有序集合（sorted sets）等数据类型。 对于这些数据类型，你可以执行原子操作。例如：对字符串进行附加操作（<code>append</code>）；递增哈希中的值；向列表中增加元素；计算集合的交集、并集与差集等。</p>
<h2 id="Redis的优点"><a href="#Redis的优点" class="headerlink" title="Redis的优点"></a>Redis的优点</h2><ul>
<li>性能极高：Redis能支持超过 100K+ 每秒的读写频率。</li>
<li>丰富的数据类型：Redis支持二进制案例的 <code>Strings</code>, <code>Lists</code>, <code>Hashes</code>, <code>Sets</code> 及 <code>Ordered Sets</code> 数据类型操作。</li>
<li>原子：Redis的所有操作都是原子性的，同时Redis还支持对几个操作全并后的原子性执行。</li>
<li>丰富的特性：Redis还支持 <code>publish/subscribe</code>, 通知, key 过期等等特性。</li>
</ul>
<h1 id="Redis安装"><a href="#Redis安装" class="headerlink" title="Redis安装"></a>Redis安装</h1><p>在<a href="http://redis.io/" target="_blank" rel="external">Redis官网</a>中下载最新的稳定版，这里我选用的是<code>3.2.0</code>稳定版。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"># 解压按照包</div><div class="line">$ tar xvfz redis-3.2.0.tar.gz</div><div class="line"></div><div class="line"># 编译</div><div class="line">$ cd redis-3.2.0</div><div class="line">$ sudo make</div><div class="line">$ sudo make install</div><div class="line"></div><div class="line"># 测试</div><div class="line">$ make test</div></pre></td></tr></table></figure>
<p>测试成功的结果如下图所示：</p>
<p><img src="/images/redis/test.png" alt="test"></p>
<h1 id="Redis启动"><a href="#Redis启动" class="headerlink" title="Redis启动"></a>Redis启动</h1><h2 id="启动与配置"><a href="#启动与配置" class="headerlink" title="启动与配置"></a>启动与配置</h2><p>在 Redis 安装完成后，注意一些重要的文件，可用 ls 命令查看。</p>
<ul>
<li>服务端的启动脚本：<code>src/redis-server</code>；</li>
<li>客户端的启动脚本：<code>src/redis-cls</code>；</li>
<li>默认配置文件：<code>redis.conf</code></li>
</ul>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 启动redis服务器</span></div><div class="line">$ ./src/redis-server</div></pre></td></tr></table></figure>
<p>启动成功结果如下图：</p>
<p><img src="/images/redis/start.png" alt="start"></p>
<blockquote>
<p>说明： 从上图中，可以发现启动的端口为缺省的<strong>6379</strong>. 用户可以在启动的时候，指定具体的配置文件，并在其中指定启动的端口。</p>
</blockquote>
<h2 id="配置-PATH"><a href="#配置-PATH" class="headerlink" title="配置$PATH"></a>配置$PATH</h2><p>然后将可执行文件放置在$PATH环境目录下，便于以后使用</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">$ sudo　cp src/redis-server /usr/<span class="built_in">local</span>/bin/</div><div class="line">$　sudo cp src/redis-cli /usr/<span class="built_in">local</span>/bin/</div></pre></td></tr></table></figure>
<h2 id="查看Redis"><a href="#查看Redis" class="headerlink" title="查看Redis"></a>查看Redis</h2><p>再启动玩Redis服务器之后，可以通过以下命令来查看Redis运行情况：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">$ ps -ef | grep redis</div><div class="line"><span class="comment"># 通过启动命令检查Redis服务器状态</span></div><div class="line">$ netstat -nlt|grep 6379</div></pre></td></tr></table></figure>
<p><img src="/images/redis/state.png" alt="state"></p>
<h2 id="启动Redis-client"><a href="#启动Redis-client" class="headerlink" title="启动Redis-client"></a>启动Redis-client</h2><figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ redis-cli</div></pre></td></tr></table></figure>
<h1 id="Redis数据类型"><a href="#Redis数据类型" class="headerlink" title="Redis数据类型"></a>Redis数据类型</h1><p>Redis不仅仅是简单的<code>key-value</code> 存储器，正如本文开头所述Redis同时也是一种<code>data structures server</code>。传统的<code>key-value</code>是指支持使用一个<code>key</code>字符串来索引<code>value</code>字符串的存储，而Redis中，<code>value</code>不仅仅支持字符串，还支持更多的复杂结构，包括列表，集合，哈希表等。</p>
<p>在本小节中，我们一一讲解：Redis keys是采用<strong>二进制安全</strong>（这里的二进制安全可以理解为：只关心二进制化的字符串，不关心具体格式，只会严格的按照二进制的数据存取，并不会按照某种具体格式去解析，杜绝了出乱码的问题），这就意味着你可以使用任何二进制序列作为重点，从像”foo”可以联系一个 JPEG 文件。空字符串也是一个有效的密钥。</p>
<h2 id="Redis-strings"><a href="#Redis-strings" class="headerlink" title="Redis strings"></a>Redis strings</h2><p>字符串是一种最基本的Redis值类型。Redis字符串是二进制安全的，这意味着一个Redis字符串能包含任意类型的数据，例如： 一张JPEG格式的图片或者一个序列化的Ruby对象。一个字符串类型的值最多能存储512M字节的内容。</p>
<p>这里启动<code>redis-cli</code>来看看Redis strings数据类型。</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 启动服务器与客户端</span></div><div class="line">$ sudo service redis-server start</div><div class="line">$ redis-cli</div></pre></td></tr></table></figure>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># redis客户端下</span></div><div class="line">&gt; <span class="built_in">set</span> mykey somevalue</div><div class="line">&gt; get mykey</div></pre></td></tr></table></figure>
<p>如上例所示，可以<code>SET</code>和<code>GET</code>命令来创建和检索strings。注意,<code>set</code>命令将取代现有的任何已经存在的key。</p>
<p><code>SET</code>命令还有一个提供附加参数的选项,我们能够让<code>SET</code>命令只有在没有相同key的情况下成功，反之亦然，可以让<code>SET</code>命令在有相同key值得情况下成功。</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">&gt; <span class="built_in">set</span> mykey newval nx</div><div class="line">&gt; <span class="built_in">set</span> mykey newval xx</div></pre></td></tr></table></figure>
<p>即使string是Redis的基本类型，也可以对其进行一些有趣的操作，例如加法器：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">&gt; <span class="built_in">set</span> counter 100</div><div class="line">&gt; incr counter</div><div class="line">&gt; incr counter</div><div class="line">&gt; incrby counter 50</div></pre></td></tr></table></figure>
<p><code>INCR</code>命令让the value 成为一个整数，运行一次<code>INCR</code>便+1。<code>INCRBY</code>命令便是一个加法运算。类似的命令如减法运算为： <code>DECR and DECRBY</code>。</p>
<p>Redis可以运用<code>MSET and MGET</code> 命令完成一次性的完成多个key-value的对应关系，使用<code>MGET</code>命令，Redis返回一个value数组。</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">&gt; mset a 10 b 20 c 30</div><div class="line">&gt; mget a b c</div></pre></td></tr></table></figure>
<p>以上操作的结果如下图所示：</p>
<p><img src="/images/redis/strings.png" alt="string"></p>
<h2 id="Redis-Lists"><a href="#Redis-Lists" class="headerlink" title="Redis Lists"></a>Redis Lists</h2><p>Redis列表是简单的字符串列表，按照插入顺序排序。你可以添加一个元素导列表的头部（左边）或者尾部（右边）。</p>
<ul>
<li><code>LPUSH</code> 命令插入一个新的元素导头部；</li>
<li><code>RPUSH</code>插入一个新元素导尾部.</li>
</ul>
<p>当一个这两个操作在一个空的Key上被执行的时候一个新的列表被创建。相似的，如果一个列表操作清空一个列表那么对应的key将被从key空间中删除。</p>
<p><code>PUSH</code>一类的命令的返回值为list的长度。一些类表操作和结果的例子：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">&gt; rpush mylist A</div><div class="line">&gt; rpush mylist B</div><div class="line">&gt; lpush mylist first</div><div class="line">&gt; lrange mylist 0 -1</div></pre></td></tr></table></figure>
<blockquote>
<p>注意：<code>LRANGE</code> 利用了两个检索值，0表示list的开头第一个，-1表示list的倒数第一个，即最后一个。-2则便是list的倒数第二个，以此类推。</p>
</blockquote>
<p>这些命令都是可变的命令，也就是说你可以一次加入多个元素放入list。</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">&gt; rpush mylist 1 2 3 4 5 <span class="string">"foo bar"</span></div><div class="line">&gt; lrange mylist 0 -1</div></pre></td></tr></table></figure>
<p>在Redis的命令操作中，还有一类重要的操作：<code>POP</code>，取出list元素。和<code>PUSH</code>操作类似，<code>POP</code>命令可以选择不同的方向取出元素.<code>POP</code>命令返回值为取出的元素。</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">&gt; del mylist</div><div class="line">&gt; rpush mylist a b c</div><div class="line">&gt; rpop mylist</div><div class="line">&gt; lrange mylist 0 -1</div><div class="line">&gt; lpop mylist</div><div class="line">&gt; lrange mylist 0 -1</div></pre></td></tr></table></figure>
<p>以上操作的结果如下图所示：</p>
<p><img src="/images/redis/list.png" alt="list"></p>
<h2 id="Redis-Hashes"><a href="#Redis-Hashes" class="headerlink" title="Redis Hashes"></a>Redis Hashes</h2><p>Redis Hashes是字符串字段和字符串值之间的映射，因此他们是展现对象的完美数据类型。 (例如:一个有名，姓，年龄等等属性的用户)：一个带有一些字段的<code>hash</code>仅仅需要一块很小的空间存储，因此你可以存储数以百万计的对象在一个小的Redis实例中。 哈希主要用来表现对象，他们有能力存储很多对象，因此你可以将哈希用于许多其他的任务。</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">&gt; hmset user:1000 username antirez birthyear 1977 verified 1</div><div class="line">&gt; hget user:1000 username</div><div class="line">&gt; hget user:1000 birthyear</div><div class="line">&gt; hgetall user:1000</div></pre></td></tr></table></figure>
<ul>
<li><code>HMSET</code>命令设置一个多域的hash表；</li>
<li><code>HGET</code>命令获取指定的单域；</li>
<li><code>HGETALL</code>命令获取指定key的所有信息；</li>
<li><code>HMGET</code>类似于<code>HGET</code>，只是返回一个value数组。</li>
</ul>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">&gt; hmget user:1000 username birthyear no-such-field</div></pre></td></tr></table></figure>
<p>同样可以根据需要对hash表的表项进行单独的操作，例如 <code>HINCRBY</code>， （原本birthyear 为1977，见上一图）</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">&gt; hincrby user:1000 birthyear 10</div><div class="line">&gt; hincrby user:1000 birthyear 10</div></pre></td></tr></table></figure>
<p>以上操作的结果如下图所示：</p>
<p><img src="/images/redis/hash.png" alt="hash"></p>
<h2 id="Redis-无序集合"><a href="#Redis-无序集合" class="headerlink" title="Redis 无序集合"></a>Redis 无序集合</h2><p>Redis 集合（Set）是一个<strong>无序的字符串集合</strong>. 你可以以$O(1)$的时间复杂度 (无论集合中有多少元素时间复杂度都是常量）完成添加、删除，以及测试元素是否存在。 Redis 集合拥有令人满意的不允许包含相同成员的属性。多次添加相同的元素，最终在集合里只会有一个元素。 实际上说这些就是意味着在添加元素的时候无须检测元素是否存在。 一个Redis集合的非常有趣的事情是他支持一些服务端的命令从现有的集合出发去进行集合运算，因此你可以在非常短的时间内进行合并（<code>unions</code>）, 求交集（<code>intersections</code>），找出不同的元素（<code>differences of sets</code>）。</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">&gt; sadd myset 1 2 3</div><div class="line">&gt; smembers myset</div></pre></td></tr></table></figure>
<ul>
<li><code>SADD</code>命令产生一个无序集合，并返回集合的元素个数；</li>
<li><code>SMEMBER</code>用于查看集合；</li>
<li><code>SISMEMBER</code>用于查看集合是否存在，匹配项包括集合名和元素个数，匹配成功返回1，匹配失败返回0。</li>
</ul>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">&gt; sismember myset 3</div><div class="line">&gt; sismember myset 30</div><div class="line">&gt; sismember mys 3</div></pre></td></tr></table></figure>
<p>以上操作的结果如下图所示：</p>
<p><img src="/images/redis/set1.png" alt="set1"></p>
<h2 id="Redis有序集合"><a href="#Redis有序集合" class="headerlink" title="Redis有序集合"></a>Redis有序集合</h2><p>Redis有序集合与普通集合非常相似，是一个<strong>没有重复元素的字符串集合</strong>。不同之处是有序集合的没有成员都关联了一个<strong>评分</strong>，这个评分被用来按照从最低分到最高分的方式排序集合中的成员。集合的成员是唯一的，但是评分可以是重复了。 使用有序集合你可以以非常快的速度（$O\log{N}$）添加，删除和更新元素。因为元素是有序的, 所以你也可以很快的根据评分（<code>score</code>）或者次序（<code>position</code>）来获取一个范围的元素。访问有序集合的中间元素也是非常快的,因此你能够使用有序集合作为一个没有重复成员的智能列表。在有序集合中，你可以很快捷的访问一切你需要的东西：有序的元素，快速的存在性测试，快速访问集合的中间元素！ 简而言之使用有序集合你可以做完成许多对性能有极端要求的任务，而那些任务使用其他类型的数据库真的是很难完成的。</p>
<p><code>ZADD</code>与<code>SADD</code>类似，但是在元素之前多了一个参数，这个参数便是用于排序的。形成一个有序的集合。</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">&gt; zadd hackers 1940 <span class="string">"Alan Kay"</span></div><div class="line">&gt; zadd hackers 1957 <span class="string">"Sophie Wilson"</span></div><div class="line">&gt; zadd hackers 1953 <span class="string">"Richard Stallman"</span></div><div class="line">&gt; zadd hackers 1949 <span class="string">"Anita Borg"</span></div><div class="line">&gt; zadd hackers 1965 <span class="string">"Yukihiro Matsumoto"</span></div><div class="line">&gt; zadd hackers 1914 <span class="string">"Hedy Lamarr"</span></div><div class="line">&gt; zadd hackers 1916 <span class="string">"Claude Shannon"</span></div><div class="line">&gt; zadd hackers 1969 <span class="string">"Linus Torvalds"</span></div><div class="line">&gt; zadd hackers 1912 <span class="string">"Alan Turing"</span></div></pre></td></tr></table></figure>
<ul>
<li><code>ZRANGE</code>是查看正序的集合;</li>
<li><code>ZREVRANGE</code>是查看反序的集合。0表示集合第一个元素，-1表示集合的倒数第一个元素。</li>
</ul>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">&gt; zrange hackers 0 -1</div><div class="line">&gt; zrevrange hackers 0 -1</div></pre></td></tr></table></figure>
<p>使用<code>WITHSCORES</code> 参数返回记录值。</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">&gt; zrange hackers 0 -1 withscores</div></pre></td></tr></table></figure>
<p>以上操作的结果如下图所示：</p>
<p><img src="/images/redis/set2.png" alt="set2"></p>
<h1 id="Redis系统管理"><a href="#Redis系统管理" class="headerlink" title="Redis系统管理"></a>Redis系统管理</h1><p>在Redis中，命令大小写不敏感。</p>
<h2 id="适合全体类型的常用命令"><a href="#适合全体类型的常用命令" class="headerlink" title="适合全体类型的常用命令"></a>适合全体类型的常用命令</h2><figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 启动服务器与客户端</span></div><div class="line">$ redis-server</div><div class="line">$ redis-cli</div></pre></td></tr></table></figure>
<h3 id="EXISTS-and-DEL"><a href="#EXISTS-and-DEL" class="headerlink" title="EXISTS and DEL"></a>EXISTS and DEL</h3><ul>
<li><code>EXISTS key</code> 判断一个key是否存在，存在返回 1;否则返回0;</li>
<li><code>DEL key</code> 删除某个key，或是一系列key，<code>DEL key1 key2 key3 key4</code>。成功返回1，失败返回0（key值不存在）。</li>
</ul>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">&gt; <span class="built_in">set</span> mykey hello</div><div class="line">&gt; exists mykey</div><div class="line"></div><div class="line">&gt; del mykey</div><div class="line">&gt; exists mykey</div></pre></td></tr></table></figure>
<p><img src="/images/redis/exist.png" alt="exist"></p>
<h3 id="TYPE-and-KEYS"><a href="#TYPE-and-KEYS" class="headerlink" title="TYPE and KEYS"></a>TYPE and KEYS</h3><ul>
<li><code>TYPE key</code>：返回某个key元素的数据类型 ( none:不存在,string:字符,list,set,zset,hash)，key不存在返回空。</li>
<li><code>KEYS key—pattern</code> ：返回匹配的key列表 (<code>KEYS foo*</code>:查找foo开头的keys)</li>
</ul>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">&gt; <span class="built_in">set</span> mykey x</div><div class="line">&gt; <span class="built_in">type</span> mykey</div><div class="line">&gt; keys my*</div><div class="line">&gt; del mykey</div><div class="line">&gt; keys my*</div><div class="line">&gt; <span class="built_in">type</span> mykey</div></pre></td></tr></table></figure>
<p><img src="/images/redis/type.png" alt="type"></p>
<h3 id="RANDOMKEY-and-CLEAR"><a href="#RANDOMKEY-and-CLEAR" class="headerlink" title="RANDOMKEY and CLEAR"></a>RANDOMKEY and CLEAR</h3><ul>
<li><code>RANDOMKEY</code> ： 随机获得一个已经存在的key，如果当前数据库为空，则返回空字符串</li>
<li><code>CLEAR</code> ：清除界面。</li>
</ul>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">&gt; randomkey</div><div class="line">&gt; clear</div></pre></td></tr></table></figure>
<h3 id="RENAME-and-RENAMENX"><a href="#RENAME-and-RENAMENX" class="headerlink" title="RENAME and RENAMENX"></a>RENAME and RENAMENX</h3><ul>
<li><code>RENAME oldname newname</code>：改key的名字，新键如果存在将被覆盖;</li>
<li><code>RENAMENX oldname newname</code>：更改key的名字，如果名字存在则更改失败.</li>
</ul>
<p>笔者randomkey结果为mylist，将此key值更名为newlist。</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">&gt; randomkey</div><div class="line">&gt; rename mylist newlist</div><div class="line">&gt; exists mylist</div><div class="line">&gt; exists newlist</div></pre></td></tr></table></figure>
<p><img src="/images/redis/rename.png" alt="rename"></p>
<h3 id="DBSIZE"><a href="#DBSIZE" class="headerlink" title="DBSIZE"></a>DBSIZE</h3><p><code>DBSIZE</code> ：返回当前数据库的key的总数</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">&gt; dbsize</div></pre></td></tr></table></figure>
<h2 id="Redis-时间相关命令"><a href="#Redis-时间相关命令" class="headerlink" title="Redis 时间相关命令"></a>Redis 时间相关命令</h2><h3 id="限定key生存时间"><a href="#限定key生存时间" class="headerlink" title="限定key生存时间"></a>限定key生存时间</h3><p>这同样是一个无视数据类型的命令，对于临时存储很有用处。避免进行大量的DEL操作。</p>
<ul>
<li><code>EXPIRE</code>：设置某个key的过期时间（秒）,(<code>EXPIRE bruce 1000</code>：设置<code>bruce</code>这个key1000秒后系统自动删除)</li>
</ul>
<blockquote>
<p>注意：如果在还没有过期的时候，对值进行了改变，那么那个值会被清除。</p>
</blockquote>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">&gt; <span class="built_in">set</span> key some-value</div><div class="line">&gt; expire key 10</div><div class="line"><span class="comment"># 马上执行此命令</span></div><div class="line">&gt; get key</div><div class="line"><span class="comment"># 10s后执行此命令</span></div><div class="line">&gt; get key</div></pre></td></tr></table></figure>
<p>结果显示，执行EXPIRE命令后，马上GET，显示key存在。10秒后再GET时，key 已经被自动删除。</p>
<p><img src="/images/redis/ttl.png" alt="ttl"></p>
<h3 id="查询key剩余生存时间"><a href="#查询key剩余生存时间" class="headerlink" title="查询key剩余生存时间"></a>查询key剩余生存时间</h3><p>限时操作可以再<code>SET</code>命令中实现，并且可用<code>TTL</code>命令查询key剩余生存时间。</p>
<p><code>TTL</code>：查找某个key还有多长时间过期,返回时间秒</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">&gt; <span class="built_in">set</span> key 100 ex 30</div><div class="line">&gt; ttl key</div><div class="line">&gt; ttl key</div></pre></td></tr></table></figure>
<h3 id="清除key"><a href="#清除key" class="headerlink" title="清除key"></a>清除key</h3><ul>
<li><code>FLUSHDB</code>：清空当前数据库中的所有键;</li>
<li><code>FLUSHALL</code>：清空所有数据库中的所有键.</li>
</ul>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">&gt; flushdb</div><div class="line">&gt; flushall</div></pre></td></tr></table></figure>
<h2 id="Redis设置相关命令"><a href="#Redis设置相关命令" class="headerlink" title="Redis设置相关命令"></a>Redis设置相关命令</h2><p>Redis有其配置文件，可以通过client-command窗口查看或者更改相关配置。相关命令介绍如下：</p>
<h3 id="CONFIG-GET-and-CONFIG-SET"><a href="#CONFIG-GET-and-CONFIG-SET" class="headerlink" title="CONFIG GET and CONFIG SET"></a>CONFIG GET and CONFIG SET</h3><ul>
<li><code>CONFIG GET</code>：用来读取运行Redis服务器的配置参数。</li>
<li><code>CONFIG SET</code>：用于更改运行Redis服务器的配置参数。</li>
<li><code>AUTH</code> : 认证密码，下面针对Redis密码的示例：</li>
</ul>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">&gt; config get requirepass （查看密码）</div><div class="line">&gt; config <span class="built_in">set</span> requirepass <span class="built_in">test</span>123 （设置密码为<span class="built_in">test</span>123 ）</div><div class="line">&gt; config get requirepass  （报错，没有认证）</div><div class="line">&gt; auth <span class="built_in">test</span>123</div><div class="line">&gt; config get requirepass</div></pre></td></tr></table></figure>
<p>由结果可知，刚开始时Reids并未设置密码，密码查询结果为空。然后设置密码为test123，再次查询报错。经过auth命令认证后，可正常查询。</p>
<p>可以经过修改Redis的配置文件redis.conf修改密码。</p>
<p><code>CONFIG GET</code>命令是以list的key-value对显示的，如查询数据类型的最大条目：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">&gt; config get *max-*-entries*</div></pre></td></tr></table></figure>
<p><img src="/images/redis/pass.png" alt="pass"></p>
<h3 id="重置报告"><a href="#重置报告" class="headerlink" title="重置报告"></a>重置报告</h3><p><code>CONFIG RESETSTAT</code>：重置数据统计报告，通常返回值为’OK”。</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">&gt; CONFIG RESETSTAT</div></pre></td></tr></table></figure>
<h2 id="查询信息"><a href="#查询信息" class="headerlink" title="查询信息"></a>查询信息</h2><p><code>INFO [section]</code> ：查询Redis相关信息。 INFO命令可以查询Redis几乎所有的信息，其命令选项有如下：</p>
<ul>
<li><code>server</code> : Redis server的常规信息</li>
<li><code>clients</code> : Client的连接选项</li>
<li><code>memory</code> : 存储占用相关信息</li>
<li><code>persistence</code> : RDB and AOF 相关信息</li>
<li><code>stats</code> : 常规统计</li>
<li><code>replication</code> : Master/slave请求信息</li>
<li><code>cpu</code> : CPU 占用信息统计</li>
<li><code>cluster</code> : Redis 集群信息</li>
<li><code>keyspace</code> : 数据库信息统计</li>
<li><code>all</code> : 返回所有信息</li>
<li><code>default</code> : 返回常规设置信息</li>
</ul>
<p>若命令参数为空，info命令返回所有信息。</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">&gt; info keyspace</div><div class="line">&gt; info server</div></pre></td></tr></table></figure>
<h1 id="Redis的高级应用"><a href="#Redis的高级应用" class="headerlink" title="Redis的高级应用"></a>Redis的高级应用</h1><p>本节来讲述Redis的高级应用，包括：安全性设置，主从复制，事务处理， 持久化机制， 虚拟内存的使用。</p>
<h2 id="安全性"><a href="#安全性" class="headerlink" title="安全性"></a>安全性</h2><p>设置在客户端连接是需要指定的密码（由于redis速度相当的快，一秒钟可以150K次的密码尝试，所以需要设置一个密码强度很大的密码）。</p>
<p>设置密码的方式有两种：</p>
<ol>
<li>使用<code>config set</code> 命令的<code>requirepass</code> 参数，具体格式为<code>config set requirepass “password”</code>;</li>
<li>配置<code>redis.conf</code> 中设置<code>requirepass</code>属性，后面为密码。</li>
</ol>
<p>输入认证的方式也有两种：</p>
<ol>
<li>登录时可以 <code>redis-cli -a password</code>;</li>
<li>登录后使用 <code>auth password</code>.</li>
</ol>
<h3 id="设置密码"><a href="#设置密码" class="headerlink" title="设置密码"></a>设置密码</h3><p>第一种密码设置方式在上面已经提到，（在<code>CONFIG SET</code>命令讲解的实例），此处我们来看看第二种方式设置密码。</p>
<p>首先需要进入Redis的安装目录，然后修改配置文件<code>redis.conf</code>。根据<code>grep</code>命令的结果，使用vi编辑器修改<code># requirepass foobared</code> 为<code>requirepass test123</code>，然后保存退出。</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">$ grep -n requirepass /etc/redis/redis.conf</div><div class="line">$ sudo vim /etc/redis/redis.conf</div></pre></td></tr></table></figure>
<h3 id="重启redis-server-与redis-cli"><a href="#重启redis-server-与redis-cli" class="headerlink" title="重启redis-server 与redis-cli"></a>重启redis-server 与redis-cli</h3><figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 重启redis server。</span></div><div class="line">$ sudo service redis-server restart</div></pre></td></tr></table></figure>
<p>进入到redis-cli交互界面进行验证</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">$ redis-cli</div><div class="line">&gt; info</div><div class="line">&gt; auth <span class="built_in">test</span>123</div><div class="line">&gt; info</div><div class="line">&gt; <span class="built_in">exit</span></div></pre></td></tr></table></figure>
<p>结果表明第一次<code>info</code>命令失败，在<code>auth</code>认证之后<code>info</code>命令正常返回。最后退出<code>redis-cli</code>。</p>
<p>另外一种密码认证方式：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">$ redis-cli <span class="_">-a</span> <span class="built_in">test</span>123</div><div class="line">&gt; info</div></pre></td></tr></table></figure>
<h2 id="主从复制"><a href="#主从复制" class="headerlink" title="主从复制"></a>主从复制</h2><p>Redis的主从复制配置和使用都比较简单，通过主从复制可以允许多个slave server拥有和master server相同的数据库副本。从服务器只能读，不能写。</p>
<p>Redis主从复制特点：</p>
<ol>
<li>master可以拥有多个slave;</li>
<li>多个slave可以连接同一个master外，还可以连接到其他的slave。（当master宕机后，相连的slave转变为master）;</li>
<li>主从复制不会阻塞master，再同步数据时，master可以继续处理client请求;</li>
<li>提高了系统的可伸缩性。</li>
</ol>
<p>Redis主从复制的过程：</p>
<ol>
<li>Slave与master建立连接，发送sync同步命令;</li>
<li>Master会启动一个后台进程，将数据库快照保存到文件中，同时Master主进程会开始收集新的写命令并缓存;</li>
<li>后台完成保存后，就将此文件发送给Slave;</li>
<li>Slave将此文件保存到磁盘上。</li>
</ol>
<h2 id="事务处理"><a href="#事务处理" class="headerlink" title="事务处理"></a>事务处理</h2><p>Redis的事务处理比较简单。只能保证client发起的事务中的命令可以连续的执行，而且不会插入其他的client命令，当一个client在连接中发出multi命令时，这个连接就进入一个事务的上下文，该连接后续的命令不会执行，而是存放到一个队列中，当执行exec命令时，redis会顺序的执行队列中的所有命令。如果其中执行出现错误，执行正确的不会回滚，不同于关系型数据库的事务。</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">&gt; multi</div><div class="line">&gt; <span class="built_in">set</span> name a</div><div class="line">&gt; <span class="built_in">set</span> name b</div><div class="line">&gt; <span class="built_in">exec</span></div><div class="line">&gt; get name</div></pre></td></tr></table></figure>
<p><img src="/images/redis/multi.png" alt="multi"></p>
<h2 id="持久化机制"><a href="#持久化机制" class="headerlink" title="持久化机制"></a>持久化机制</h2><p>Redis是一个支持持久化的内存数据库，Redis需要经常将内存中的数据同步到磁盘来保证持久化。</p>
<p>Redis支持两种持久化方式：</p>
<ol>
<li><code>snapshotting</code>（快照），将数据存放到文件里，默认方式。<br>是将内存中的数据已快照的方式写入到二进制文件中，默认文件<code>dump.rdb</code>，可以通过配置设置自动做快照持久化的方式。可配置Redis在n秒内如果超过m个key被修改就自动保存快照。<ul>
<li><code>save 900 1</code>: 900秒内如果超过1个key被修改，则发起快照保存;</li>
<li><code>save 300 10</code>: 300秒内如果超过10个key被修改，则快照保存.</li>
</ul>
</li>
<li><code>Append-only file</code>（缩写为<code>aof</code>），将读写操作存放到文件中。</li>
</ol>
<blockquote>
<p>Note: 由于快照方式在一定间隔时间做一次，所以如果Redis意外down掉的话，就会丢失最后一次快照后的所有修改。</p>
</blockquote>
<p><code>aof</code>比快照方式有更好的持久化性，是由于使用<code>aof</code>时，redis会将每一个收到的写命令都通过write函数写入到文件中当redis启动时会通过重新执行文件中保存的写命令来在内存中重新建立整个数据库的内容。</p>
<p>由于os会在内核中缓存write做的修改，所以可能不是立即写到磁盘上，这样aof方式的持久化也还是有可能会丢失一部分数据。可以通过配置文件告诉redis我们想要通过<code>fsync</code>函数强制os写入到磁盘的时机。</p>
<p>配置文件中的可配置参数：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">appendonly   yes     //启用aof持久化方式</div><div class="line">#appendfsync  always //收到写命令就立即写入磁盘，最慢，但是保证了数据的完整持久化</div><div class="line">appendfsync   everysec  //每秒中写入磁盘一次，在性能和持久化方面做了很好的折中</div><div class="line">#appendfsync  no     //完全依赖os，性能最好，持久化没有保证</div></pre></td></tr></table></figure>
<p>在redis-cli的命令中，SAVE命令是将数据写入磁盘中。</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">&gt; <span class="built_in">help</span> save</div><div class="line">&gt; save</div></pre></td></tr></table></figure>
<h2 id="虚拟内存的使用"><a href="#虚拟内存的使用" class="headerlink" title="虚拟内存的使用"></a>虚拟内存的使用</h2><p>虚拟内存管理在2.6及之上版本取消了，本文安装的的是3.2.0版本的redis ，所以配置文件中并没有虚拟内存管理功能的配置选项。此处仅仅是大概介绍一下。</p>
<p>Redis的虚拟内存是暂时把不经常访问的数据从内存交换到磁盘中，从而腾出内存空间用于其他的访问数据，尤其对于redis这样的内存数据库，内存总是不够用的。除了分隔到多个redis server外，提高数据库的容量的方法就是使用虚拟内存，把那些不常访问的数据交换到磁盘上。</p>
<p>通过配置vm相关的<code>redis.config</code>配置：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">vm-enable  yes                   #开启vm功能</div><div class="line">vm-swap-file    /tmp/redis.swap  #交换出来的value保存的文件路径</div><div class="line">vm-max-memory    10000000        #redis使用的最大内存上线</div><div class="line">vm-page-size   32       #每个页面的大小32字节</div><div class="line">vm-pages     123217729    #最多使用多小个页面</div><div class="line">vm-max-threads     4        #用于执行value对象换入的工作线程数量</div></pre></td></tr></table></figure>
<hr>
<p>参考</p>
<ul>
<li><a href="http://redis.io/" target="_blank" rel="external">Redis官网</a></li>
<li><a href="http://www.redis.cn/" target="_blank" rel="external">Redis中文网站</a></li>
<li><a href="http://redisdoc.com/" target="_blank" rel="external">Redis命令参考</a></li>
<li><a href="http://www.runoob.com/redis/redis-tutorial.html" target="_blank" rel="external">Redis | 菜鸟教程</a></li>
</ul>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[Java序列化学习]]></title>
      <url>http://matt33.com/2016/05/21/java-serializable/</url>
      <content type="html"><![CDATA[<h1 id="写在前面"><a href="#写在前面" class="headerlink" title="写在前面"></a>写在前面</h1><p>本文主要是对Java序列化学习的一些总结，一来是方便自己以后查阅，二来是希望通过本文能给他人带来一些帮助。</p>
<h1 id="对象序列化"><a href="#对象序列化" class="headerlink" title="对象序列化"></a>对象序列化</h1><p>Java提供了一种对象序列化的机制，在该机制中，一个对象可以被表示为一个字节序列，该字节序列包括该对象的数据、有关对象的类型的信息和存储在对象中数据的类型。将序列化对象写入文件之后，可以再从文件中读取出来，并且对它进行反序列化，也就是说，可以根据对象的类型信息、对象的数据、还有对象中的数据类型可以在内存中新建该对象。</p>
<p>在实际的应用中，我们为什么需要对象序列化机制呢？因为在一般情况下，只有当JVM进程处于运行时，JVM建立的对象才可能存在，也就是说，这些对象的生命周期不会比JVM进程的生命周期更长。但是在现实的应用中，有时需要在JVM进程停止运行之后能够保存(持久化)指定的对象，并且在将来某个时刻重新读取被保存的对象，或者我们希望将一个进程创建的对象传送到另一个JVM进程中。Java的对象序列化机制就能够帮助我们实现这些功能（这就意味着序列化机制是可以自动弥补不同操作系统之间的差异）。</p>
<p>一般来说，对象的序列化主要有两种用途：</p>
<ul>
<li>把对象的字节序列持久化到硬盘，通常保存在一个文件中；</li>
<li>在网络上传输对象的字节序列；</li>
</ul>
<p>我们在使用Java对象序列化时，会把对象的状态保存为一组字节序列，在未来，再将这些字节组装成对象。必须注意地是，对象序列化保存的是对象的<strong>状态</strong>，即它的成员变量。由此可知，对象序列化不会关注类中的静态变量，因为静态变量是类的状态。</p>
<p>这个整个过程都是Java虚拟机（JVM）独立完成的，也就是说，在一个平台上序列化的对象可以在另一个完全不同的平台上反序列化该对象。</p>
<p>但是一个类的对象如果要想序列化成功，必须满足两个条件：</p>
<ul>
<li>该类必须实现 <code>java.io.Serializable</code> 接口。</li>
<li>该类的所有属性必须是可序列化的。如果有一个属性不是可序列化的，则该属性<strong>必须注明是短暂</strong>的。</li>
</ul>
<p>如果你想知道一个Java标准类是否是可序列化的，请查看该类的文档。检验一个类的实例是否能序列化十分简单， 只需要查看该类有没有实现<code>java.io.Serializable</code>接口即可。</p>
<h1 id="序列化实现的示例"><a href="#序列化实现的示例" class="headerlink" title="序列化实现的示例"></a>序列化实现的示例</h1><ul>
<li>对象序列化时，首先要创建某个<code>OutputStream</code>对象，然后将其封装在一个<code>ObjectOutputStream</code>对象内，这时，只需要调用<code>writeObject()</code>即可将对象序列化，并将其发送给<code>OutputStream</code>（对象化序列是基于字节的，因要使用<code>InputStream</code>和<code>OutputStream</code>继承层次结构）；</li>
<li>对象反序列化时，需要将一个<code>InputStream</code>对象封装在<code>ObjectInputStream</code>内，然后调用<code>readObject()</code>方法；</li>
</ul>
<p>对象序列化时，不仅保存了对象的“全景图”，而且能追踪对象内所包含的所有引用，并保存那些对象，接着又能对对象内包含的每个这样的引用进行追踪，并保存那些对象，这种情况有时被称为“对象网”。</p>
<p>这里我们先建立一个对象<code>Person</code>，如下（<a href="https://github.com/wangzzu/java_learn/tree/master/java_thinking/src/javabasic/serialize" target="_blank" rel="external">示例参考</a>）：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// Person.java</span></div><div class="line"><span class="keyword">import</span> java.io.Serializable;</div><div class="line"><span class="keyword">import</span> java.util.Random;</div><div class="line"></div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Person</span> <span class="keyword">implements</span> <span class="title">Serializable</span></span>&#123;</div><div class="line">	<span class="keyword">private</span> String name;</div><div class="line">	<span class="keyword">private</span> <span class="keyword">int</span> age;</div><div class="line">	<span class="keyword">private</span> Gender gender;</div><div class="line">	<span class="keyword">private</span> <span class="keyword">int</span> id;</div><div class="line"></div><div class="line">	<span class="function"><span class="keyword">public</span> <span class="title">Person</span><span class="params">(String name, <span class="keyword">int</span> age, Gender gender)</span> </span>&#123;</div><div class="line">		<span class="keyword">this</span>.name = name;</div><div class="line">		<span class="keyword">this</span>.age = age;</div><div class="line">		<span class="keyword">this</span>.gender = gender;</div><div class="line">		<span class="keyword">this</span>.id = (<span class="keyword">new</span> Random()).nextInt(<span class="number">10</span>);</div><div class="line">	&#125;</div><div class="line"></div><div class="line">	<span class="function"><span class="keyword">public</span> String <span class="title">getName</span><span class="params">()</span> </span>&#123;</div><div class="line">		<span class="keyword">return</span> name;</div><div class="line">	&#125;</div><div class="line"></div><div class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setName</span><span class="params">(String name)</span> </span>&#123;</div><div class="line">		<span class="keyword">this</span>.name = name;</div><div class="line">	&#125;</div><div class="line"></div><div class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">getAge</span><span class="params">()</span> </span>&#123;</div><div class="line">		<span class="keyword">return</span> age;</div><div class="line">	&#125;</div><div class="line"></div><div class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setAge</span><span class="params">(<span class="keyword">int</span> age)</span> </span>&#123;</div><div class="line">		<span class="keyword">this</span>.age = age;</div><div class="line">	&#125;</div><div class="line"></div><div class="line">	<span class="function"><span class="keyword">public</span> Gender <span class="title">getGender</span><span class="params">()</span> </span>&#123;</div><div class="line">		<span class="keyword">return</span> gender;</div><div class="line">	&#125;</div><div class="line"></div><div class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setGender</span><span class="params">(Gender gender)</span> </span>&#123;</div><div class="line">		<span class="keyword">this</span>.gender = gender;</div><div class="line">	&#125;</div><div class="line"></div><div class="line">	<span class="meta">@Override</span></div><div class="line">	<span class="function"><span class="keyword">public</span> String <span class="title">toString</span><span class="params">()</span> </span>&#123;</div><div class="line">		<span class="keyword">return</span> <span class="string">"["</span> + name + <span class="string">", "</span> + age + <span class="string">", "</span> + gender + <span class="string">", "</span> + id + <span class="string">"]"</span>;</div><div class="line">	&#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>下面，我们在一个进程里对其进行序列化，然后再反序列化出该对象（<a href="https://github.com/wangzzu/java_learn/blob/master/java_thinking/src/javabasic/serialize/Serialize.java" target="_blank" rel="external">示例</a>）</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// Serialize.java</span></div><div class="line"><span class="keyword">import</span> java.io.ByteArrayInputStream;</div><div class="line"><span class="keyword">import</span> java.io.ByteArrayOutputStream;</div><div class="line"><span class="keyword">import</span> java.io.FileInputStream;</div><div class="line"><span class="keyword">import</span> java.io.FileOutputStream;</div><div class="line"><span class="keyword">import</span> java.io.IOException;</div><div class="line"><span class="keyword">import</span> java.io.ObjectInputStream;</div><div class="line"><span class="keyword">import</span> java.io.ObjectOutputStream;</div><div class="line"></div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Serialize</span> </span>&#123;</div><div class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</div><div class="line">		Person p1 = <span class="keyword">new</span> Person(<span class="string">"wm0"</span>, <span class="number">10</span>, Gender.MALE);</div><div class="line">		Person p2 = <span class="keyword">new</span> Person(<span class="string">"wm1"</span>, <span class="number">18</span>, Gender.MALE);</div><div class="line"></div><div class="line">		System.out.println(<span class="string">"p1 = "</span> + p1);</div><div class="line">		ObjectOutputStream out = <span class="keyword">null</span>;</div><div class="line">		<span class="keyword">try</span> &#123;</div><div class="line">			out = <span class="keyword">new</span> ObjectOutputStream(<span class="keyword">new</span> FileOutputStream(<span class="string">"/home/matt/person.out"</span>)); <span class="comment">// 写入本地文件</span></div><div class="line">			out.writeObject(<span class="string">"Person1 storage\n"</span>);</div><div class="line">			out.writeObject(p1);</div><div class="line">			out.close(); <span class="comment">// Also flushes output</span></div><div class="line">			ObjectInputStream in = <span class="keyword">new</span> ObjectInputStream(<span class="keyword">new</span> FileInputStream(<span class="string">"/home/matt/person.out"</span>)); <span class="comment">// 从本地文件读取</span></div><div class="line">			String s = <span class="keyword">null</span>;</div><div class="line">			Person p11 = <span class="keyword">null</span>;</div><div class="line">			<span class="keyword">try</span> &#123;</div><div class="line">				s = (String) in.readObject();</div><div class="line">				p11 = (Person) in.readObject();</div><div class="line">				System.out.println(<span class="string">"after Serialize: "</span> + p11);</div><div class="line">			&#125; <span class="keyword">catch</span> (ClassNotFoundException e) &#123;</div><div class="line">				e.printStackTrace();</div><div class="line">			&#125;</div><div class="line"></div><div class="line">			System.out.println(<span class="string">"\n"</span>+ <span class="string">"p2 = "</span> + p2);</div><div class="line">			ByteArrayOutputStream bout = <span class="keyword">new</span> ByteArrayOutputStream(); <span class="comment">// 将数据写入缓冲区</span></div><div class="line">			ObjectOutputStream out2 = <span class="keyword">new</span> ObjectOutputStream(bout);</div><div class="line">			out2.writeObject(<span class="string">"Person2 storage\n"</span>);</div><div class="line">			out2.writeObject(p2);</div><div class="line">			out2.flush();</div><div class="line">			ObjectInputStream in2 = <span class="keyword">new</span> ObjectInputStream(<span class="keyword">new</span> ByteArrayInputStream(bout.toByteArray())); <span class="comment">// 通过toByteArray()获取数据</span></div><div class="line">			<span class="keyword">try</span> &#123;</div><div class="line">				s = (String) in2.readObject();</div><div class="line">				Person p22 = (Person) in2.readObject();</div><div class="line">				System.out.println(<span class="string">"after Serialize: "</span> + p22);</div><div class="line">			&#125; <span class="keyword">catch</span> (ClassNotFoundException e) &#123;</div><div class="line">				e.printStackTrace();</div><div class="line">			&#125;</div><div class="line">		&#125; <span class="keyword">catch</span> (IOException e) &#123;</div><div class="line">			e.printStackTrace();</div><div class="line">		&#125;</div><div class="line">	&#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>这里有一点要注意的是：反序列化Person对象时，需要要能找到<code>Person.class</code>，否者就会抛出<code>ClassNotFoundException</code>的异常。</p>
<h1 id="序列化的控制"><a href="#序列化的控制" class="headerlink" title="序列化的控制"></a>序列化的控制</h1><p>通过上面的例子，我们可以看出序列化的使用，其实还是很简单的，但是，如果我们有特殊的需要那又该怎么办呢？下面我们介绍几种序列化的控制机制。</p>
<h2 id="Externalizable接口"><a href="#Externalizable接口" class="headerlink" title="Externalizable接口"></a>Externalizable接口</h2><p>如果我们希望对象的一部分被序列化，而另一部分不被序列化；或者一个对象被还原之后，某子对象需要重新创建，从而不必将该子对象序列化。在这种情况下，我们可以通过实现<code>Externalization</code>接口——该接口实现<code>Serializable</code>接口，同时增加两个方法：<code>writeExternal()</code>和<code>readExternal()</code>，这两个方法会在序列化和反序列化还原的过程中被自动调用以便执行一些特殊操作。</p>
<p>这与恢复<code>Serializable</code>对象不同，对于<code>Serializable</code>对象，对象完全以它存储的二进制位为基础来构造，而不调用构造器。但是对于一个<code>Externalization</code>对象，所有普通的默认构造器都会被调用（包括字段定义时的初始化），然后调用<code>readExternal()</code>。</p>
<blockquote>
<p>必须要注意这一点：所有默认的构造器都会被调用，才能使<code>Externalization</code>对象产生正确的行为。</p>
</blockquote>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// Blip3.java</span></div><div class="line"><span class="keyword">import</span> java.io.Externalizable;</div><div class="line"><span class="keyword">import</span> java.io.FileInputStream;</div><div class="line"><span class="keyword">import</span> java.io.FileOutputStream;</div><div class="line"><span class="keyword">import</span> java.io.IOException;</div><div class="line"><span class="keyword">import</span> java.io.ObjectInput;</div><div class="line"><span class="keyword">import</span> java.io.ObjectInputStream;</div><div class="line"><span class="keyword">import</span> java.io.ObjectOutput;</div><div class="line"><span class="keyword">import</span> java.io.ObjectOutputStream;</div><div class="line"></div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Blip3</span> <span class="keyword">implements</span> <span class="title">Externalizable</span> </span>&#123;</div><div class="line">	<span class="keyword">private</span> <span class="keyword">int</span> i;</div><div class="line">	<span class="keyword">private</span> String s; <span class="comment">// No initialization</span></div><div class="line"></div><div class="line">	<span class="function"><span class="keyword">public</span> <span class="title">Blip3</span><span class="params">()</span> </span>&#123;</div><div class="line">		System.out.println(<span class="string">"Blip3 Constructor"</span>);</div><div class="line">		<span class="comment">// s, i not initialized</span></div><div class="line">	&#125;</div><div class="line"></div><div class="line">	<span class="function"><span class="keyword">public</span> <span class="title">Blip3</span><span class="params">(String x, <span class="keyword">int</span> a)</span> </span>&#123;</div><div class="line">		System.out.println(<span class="string">"Blip3(String x, int a)"</span>);</div><div class="line">		s = x;</div><div class="line">		i = a;</div><div class="line">		<span class="comment">// s &amp; i initialized only in non-default constructor.</span></div><div class="line">	&#125;</div><div class="line"></div><div class="line">	<span class="function"><span class="keyword">public</span> String <span class="title">toString</span><span class="params">()</span> </span>&#123;</div><div class="line">		<span class="keyword">return</span> s + i;</div><div class="line">	&#125;</div><div class="line"></div><div class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">writeExternal</span><span class="params">(ObjectOutput out)</span> <span class="keyword">throws</span> IOException </span>&#123;</div><div class="line">		System.out.println(<span class="string">"Blip3.writeExternal"</span>);</div><div class="line">		<span class="comment">// You must do this:</span></div><div class="line">		out.writeObject(s);</div><div class="line">		out.writeInt(i);</div><div class="line">	&#125;</div><div class="line"></div><div class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">readExternal</span><span class="params">(ObjectInput in)</span> <span class="keyword">throws</span> IOException, ClassNotFoundException </span>&#123;</div><div class="line">		System.out.println(<span class="string">"Blip3.readExternal"</span>);</div><div class="line">		<span class="comment">// You must do this:</span></div><div class="line">		s = (String) in.readObject();</div><div class="line">		i = in.readInt();</div><div class="line">	&#125;</div><div class="line"></div><div class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> IOException, ClassNotFoundException </span>&#123;</div><div class="line">		System.out.println(<span class="string">"Constructing objects:"</span>);</div><div class="line">		Blip3 b3 = <span class="keyword">new</span> Blip3(<span class="string">"A String "</span>, <span class="number">47</span>);</div><div class="line">		System.out.println(b3);</div><div class="line">		ObjectOutputStream o = <span class="keyword">new</span> ObjectOutputStream(<span class="keyword">new</span> FileOutputStream(<span class="string">"/home/matt/Blip3.out"</span>));</div><div class="line">		System.out.println(<span class="string">"Saving object:"</span>);</div><div class="line">		o.writeObject(b3);</div><div class="line">		o.close();</div><div class="line">		<span class="comment">// Now get it back:</span></div><div class="line">		ObjectInputStream in = <span class="keyword">new</span> ObjectInputStream(<span class="keyword">new</span> FileInputStream(<span class="string">"/home/matt/Blip3.out"</span>));</div><div class="line">		System.out.println(<span class="string">"Recovering b3:"</span>);</div><div class="line">		b3 = (Blip3) in.readObject();</div><div class="line">		System.out.println(b3);</div><div class="line">	&#125;</div><div class="line">&#125;</div><div class="line"><span class="comment">/* Output:</span></div><div class="line">* Constructing objects:</div><div class="line">* Blip3(String x, int a)</div><div class="line">* A String 47</div><div class="line">* Saving object:</div><div class="line">* Blip3.writeExternal</div><div class="line">* Recovering b3:</div><div class="line">* Blip3 Constructor</div><div class="line">* Blip3.readExternal</div><div class="line">* A String 47</div><div class="line"> */</div></pre></td></tr></table></figure>
<p>在上面的例子中，字段<code>s</code>和<code>i</code>只会在第二个构造器中初始化，而不是在默认的构造器中初始化。这意味着假如不在<code>readExternal()</code>中初始化<code>s</code>和<code>i</code>，<code>s</code>就会为<code>null</code>，而<code>i</code>就会为零（因为在创建对象的第一步中将对象的存储空间清理为0）。如果我们把<code>writeExternal()</code>方法中两行注释掉，对象还原后，<code>s</code>是<code>null</code>，而<code>i</code>是零。</p>
<p>我们如果从一个<code>Externalization</code>对象继承，通常需要调用基类版本的<code>writeExternal()</code>和<code>readExternal()</code>来为基类组件提供恰当的存储和恢复功能。</p>
<p>因此，为了正常运行，我们不仅需要在<code>writeExternal()</code>方法（没有任何默认行为来为<code>Externalization</code>对象写入任何成员对象）中将来自对象的重要信息写入，还必须在<code>readExternal()</code>方法中恢复数据。</p>
<h2 id="Transient关键字"><a href="#Transient关键字" class="headerlink" title="Transient关键字"></a>Transient关键字</h2><p>在进行序列化控制时，可能某个特定子对象不想让Java的序列化机制自动保存和恢复。如果子对象表示的是我们不希望将其序列化的敏感信息（如密码），那么我们就会面临这种情况。即使对象中的这些信息是<code>private</code>属性，一经序列化处理，人们就可以通过读取文件或者拦截网络传输的方式来访问到它。</p>
<p>有两种方法可以实现上述要求：</p>
<ol>
<li>将类实现<code>Externalizable</code>接口，这样的话，没有任何东西是可以自动序列化，并且可以在<code>writeExternal()</code>内部只对所需部门进行显式的序列化；</li>
<li>如果在操作的是一个<code>Serializable</code>对象，那么所有序列化操作都会自动进行，为了能够进行控制，可以用<code>transient</code>关键字逐个字段地关闭序列化，这个关键字的意思就是<strong>不用麻烦你保存或者回复数据——我自己会处理的</strong>。</li>
</ol>
<p><a href="https://github.com/wangzzu/java_learn/blob/master/java_thinking/src/javabasic/serialize/Login.java" target="_blank" rel="external">示例</a></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// Login.java</span></div><div class="line"><span class="keyword">import</span> java.io.FileInputStream;</div><div class="line"><span class="keyword">import</span> java.io.FileOutputStream;</div><div class="line"><span class="keyword">import</span> java.io.ObjectInputStream;</div><div class="line"><span class="keyword">import</span> java.io.ObjectOutputStream;</div><div class="line"><span class="keyword">import</span> java.io.Serializable;</div><div class="line"><span class="keyword">import</span> java.util.Date;</div><div class="line"><span class="comment">//: io/Logon.java</span></div><div class="line"><span class="comment">//Demonstrates the "transient" keyword.</span></div><div class="line"><span class="keyword">import</span> java.util.concurrent.TimeUnit;</div><div class="line"></div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Login</span> <span class="keyword">implements</span> <span class="title">Serializable</span> </span>&#123;</div><div class="line">	<span class="keyword">private</span> Date date = <span class="keyword">new</span> Date();</div><div class="line">	<span class="keyword">private</span> String username;</div><div class="line">	<span class="keyword">private</span> <span class="keyword">transient</span> String password;</div><div class="line"></div><div class="line">	<span class="function"><span class="keyword">public</span> <span class="title">Login</span><span class="params">(String name, String pwd)</span> </span>&#123;</div><div class="line">		username = name;</div><div class="line">		password = pwd;</div><div class="line">	&#125;</div><div class="line"></div><div class="line">	<span class="function"><span class="keyword">public</span> String <span class="title">toString</span><span class="params">()</span> </span>&#123;</div><div class="line">		<span class="keyword">return</span> <span class="string">"logon info: \n   username: "</span> + username + <span class="string">"\n   date: "</span> + date + <span class="string">"\n   password: "</span> + password;</div><div class="line">	&#125;</div><div class="line"></div><div class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</div><div class="line">		Login a = <span class="keyword">new</span> Login(<span class="string">"Hulk"</span>, <span class="string">"myLittlePony"</span>);</div><div class="line">		System.out.println(<span class="string">"logon a = "</span> + a);</div><div class="line">		ObjectOutputStream o = <span class="keyword">new</span> ObjectOutputStream(<span class="keyword">new</span> FileOutputStream(<span class="string">"/home/matt/Logon.out"</span>));</div><div class="line">		o.writeObject(a);</div><div class="line">		o.close();</div><div class="line">		TimeUnit.SECONDS.sleep(<span class="number">1</span>); <span class="comment">// Delay</span></div><div class="line">		<span class="comment">// Now get them back:</span></div><div class="line">		ObjectInputStream in = <span class="keyword">new</span> ObjectInputStream(<span class="keyword">new</span> FileInputStream(<span class="string">"/home/matt/Logon.out"</span>));</div><div class="line">		System.out.println(<span class="string">"Recovering object at "</span> + <span class="keyword">new</span> Date());</div><div class="line">		a = (Login) in.readObject();</div><div class="line">		System.out.println(<span class="string">"logon a = "</span> + a);</div><div class="line">	&#125;</div><div class="line">&#125; <span class="comment">/*</span></div><div class="line">* logon a = logon info:</div><div class="line">*   username: Hulk</div><div class="line">*    date: Tue May 17 11:11:28 CST 2016</div><div class="line">*    password: myLittlePony</div><div class="line">* Recovering object at Tue May 17 11:11:29 CST 2016</div><div class="line">* logon a = logon info:</div><div class="line">*    username: Hulk</div><div class="line">*    date: Tue May 17 11:11:28 CST 2016</div><div class="line">*    password: null</div><div class="line">*/</div></pre></td></tr></table></figure>
<p>可以看到，其中的<code>date</code>和<code>username</code>域是一般的（不是<code>transient</code>的），所以它们会被自动序列化。而<code>password</code>是<code>transient</code>的，所以不会被自动保存到磁盘；另外，自动序列化机制也不会尝试去恢复它。当对象被恢复时，<code>password</code>域就会变成<code>null</code>。我们还可以发现，<code>date</code>字段也是从存储到了磁盘并从磁盘上被恢复出来，而且没有再重新生成。</p>
<blockquote>
<p>由于实现<code>Externalizable</code>接口的对象在默认情况下不保存它们的任何字段，所以<code>transient</code>关键字只能和<code>Serializable</code>对象一起使用。</p>
</blockquote>
<h2 id="重写writeObject-和readObject-方法"><a href="#重写writeObject-和readObject-方法" class="headerlink" title="重写writeObject()和readObject()方法"></a>重写writeObject()和readObject()方法</h2><p>如果不是特别坚持使用<code>Externalizable</code>接口，那么还有一种方法。我们可以实现<code>Serializable</code>接口，并添加<code>writeObject()</code>和<code>readObject()</code>方法。这样一旦对象被序列化或者被反序列化还原，就会自动地分别调用这两个方法，而不是使用默认的序列化机制。（<a href="https://github.com/wangzzu/java_learn/blob/master/java_thinking/src/javabasic/serialize/SerialCtl.java" target="_blank" rel="external">示例</a>）</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// SerialCtl.java</span></div><div class="line"></div><div class="line"><span class="keyword">import</span> java.io.ByteArrayInputStream;</div><div class="line"><span class="keyword">import</span> java.io.ByteArrayOutputStream;</div><div class="line"><span class="keyword">import</span> java.io.IOException;</div><div class="line"><span class="keyword">import</span> java.io.ObjectInputStream;</div><div class="line"><span class="keyword">import</span> java.io.ObjectOutputStream;</div><div class="line"><span class="keyword">import</span> java.io.Serializable;</div><div class="line"></div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">SerialCtl</span> <span class="keyword">implements</span> <span class="title">Serializable</span> </span>&#123;</div><div class="line">	<span class="keyword">private</span> String a;</div><div class="line">	<span class="keyword">private</span> <span class="keyword">transient</span> String b;</div><div class="line"></div><div class="line">	<span class="function"><span class="keyword">public</span> <span class="title">SerialCtl</span><span class="params">(String aa, String bb)</span> </span>&#123;</div><div class="line">		a = <span class="string">"Not Transient: "</span> + aa;</div><div class="line">		b = <span class="string">"Transient: "</span> + bb;</div><div class="line">	&#125;</div><div class="line"></div><div class="line">	<span class="function"><span class="keyword">public</span> String <span class="title">toString</span><span class="params">()</span> </span>&#123;</div><div class="line">		<span class="keyword">return</span> a + <span class="string">" "</span> + b;</div><div class="line">	&#125;</div><div class="line"></div><div class="line">	<span class="comment">/**</span></div><div class="line">	 * 自定义该方法，这里要注意方法时private</div><div class="line">	 * 在调用ObjectOutputStream.writeObject()时，会检查所传递的Serializable对象，看看是否实现了它自己的writeObject()。</div><div class="line">	 * 如果是这样，就跳过正常的序列化过程并调用它的writeObject()</div><div class="line">	 *</div><div class="line">	 * <span class="doctag">@param</span> stream</div><div class="line">	 * <span class="doctag">@throws</span> IOException</div><div class="line">	 */</div><div class="line">	<span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">writeObject</span><span class="params">(ObjectOutputStream stream)</span> <span class="keyword">throws</span> IOException </span>&#123;</div><div class="line">		stream.defaultWriteObject(); <span class="comment">// 执行默认的writeObject()</span></div><div class="line">		stream.writeObject(b); <span class="comment">// transient字段需要明确保存和</span></div><div class="line">	&#125;</div><div class="line"></div><div class="line">	<span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">readObject</span><span class="params">(ObjectInputStream stream)</span> <span class="keyword">throws</span> IOException, ClassNotFoundException </span>&#123;</div><div class="line">		stream.defaultReadObject(); <span class="comment">// 执行默认的readObject()</span></div><div class="line">		b = (String) stream.readObject(); <span class="comment">// transient字段需要明确恢复</span></div><div class="line">	&#125;</div><div class="line"></div><div class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> IOException, ClassNotFoundException </span>&#123;</div><div class="line">		SerialCtl sc = <span class="keyword">new</span> SerialCtl(<span class="string">"Test1"</span>, <span class="string">"Test2"</span>);</div><div class="line">		System.out.println(<span class="string">"Before:\n"</span> + sc);</div><div class="line">		ByteArrayOutputStream buf = <span class="keyword">new</span> ByteArrayOutputStream();</div><div class="line">		ObjectOutputStream o = <span class="keyword">new</span> ObjectOutputStream(buf);</div><div class="line">		o.writeObject(sc);</div><div class="line">		<span class="comment">// Now get it back:</span></div><div class="line">		ObjectInputStream in = <span class="keyword">new</span> ObjectInputStream(<span class="keyword">new</span> ByteArrayInputStream(buf.toByteArray()));</div><div class="line">		SerialCtl sc2 = (SerialCtl) in.readObject();</div><div class="line">		System.out.println(<span class="string">"After:\n"</span> + sc2);</div><div class="line">	&#125;</div><div class="line">&#125;</div><div class="line"><span class="comment">/*</span></div><div class="line">* Before:</div><div class="line">* Not Transient: Test1 Transient: Test2</div><div class="line">* After:</div><div class="line">* Not Transient: Test1 Transient: Test2</div><div class="line">*/</div></pre></td></tr></table></figure>
<p>上述的例子中，非transient字段由<code>defaultReadObject</code>保存，而transient字段必须在程序中明确保存和恢复。</p>
<h2 id="静态变量的序列化"><a href="#静态变量的序列化" class="headerlink" title="静态变量的序列化"></a>静态变量的序列化</h2><p>前面我们也已经提到过，静态变量是不会被序列化的，这里我们通过一个例子来看一下（<a href="https://github.com/wangzzu/java_learn/blob/master/java_thinking/src/javabasic/serialize/StaticTest.java" target="_blank" rel="external">示例</a>）</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> java.io.FileInputStream;</div><div class="line"><span class="keyword">import</span> java.io.FileOutputStream;</div><div class="line"><span class="keyword">import</span> java.io.IOException;</div><div class="line"><span class="keyword">import</span> java.io.ObjectInputStream;</div><div class="line"><span class="keyword">import</span> java.io.ObjectOutputStream;</div><div class="line"><span class="keyword">import</span> java.io.Serializable;</div><div class="line"></div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">StaticTest</span> <span class="keyword">implements</span> <span class="title">Serializable</span></span>&#123;</div><div class="line">	<span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">int</span> id=<span class="number">10</span>;</div><div class="line"></div><div class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</div><div class="line">		System.out.println(<span class="string">"Constructing objects:"</span>);</div><div class="line">		ObjectOutputStream o = <span class="keyword">null</span>;</div><div class="line">		<span class="keyword">try</span> &#123;</div><div class="line">			o = <span class="keyword">new</span> ObjectOutputStream(<span class="keyword">new</span> FileOutputStream(<span class="string">"/home/matt/static.out"</span>));</div><div class="line">			o.writeObject(<span class="keyword">new</span> StaticTest());</div><div class="line">			o.close();</div><div class="line">			StaticTest.id=<span class="number">0</span>;</div><div class="line">			ObjectInputStream in = <span class="keyword">new</span> ObjectInputStream(<span class="keyword">new</span> FileInputStream(<span class="string">"/home/matt/static.out"</span>));</div><div class="line">			StaticTest staticTest = <span class="keyword">null</span>;</div><div class="line">			<span class="keyword">try</span> &#123;</div><div class="line">				staticTest = (StaticTest) in.readObject();</div><div class="line">			&#125; <span class="keyword">catch</span> (ClassNotFoundException e) &#123;</div><div class="line">				e.printStackTrace();</div><div class="line">			&#125;</div><div class="line">			System.out.println(staticTest.id);</div><div class="line">		&#125; <span class="keyword">catch</span> (IOException e) &#123;</div><div class="line">			e.printStackTrace();</div><div class="line">		&#125;</div><div class="line">	&#125;</div><div class="line">&#125;</div><div class="line"><span class="comment">/**</span></div><div class="line">* output:</div><div class="line">* 0</div><div class="line">*/</div></pre></td></tr></table></figure>
<p>程序输出的结果为修改之后的结果，正如我们前面所述一样，对象序列化时并不会序列化静态变量，这一点可以这样理解：对象序列化是序列化对象的状态，而静态变量是类变量，也就是类的状态。因此，<strong>对象序列化并不保存静态变量</strong>。</p>
<h2 id="存储规则"><a href="#存储规则" class="headerlink" title="存储规则"></a>存储规则</h2><p>这里我们通过一个例子来看一下Java序列化机制的存储规则，主要是多次写入同一个对象的情况（<a href="https://github.com/wangzzu/java_learn/blob/master/java_thinking/src/javabasic/serialize/StoreTest.java" target="_blank" rel="external">示例</a>）</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> java.io.File;</div><div class="line"><span class="keyword">import</span> java.io.FileInputStream;</div><div class="line"><span class="keyword">import</span> java.io.FileOutputStream;</div><div class="line"><span class="keyword">import</span> java.io.IOException;</div><div class="line"><span class="keyword">import</span> java.io.ObjectInputStream;</div><div class="line"><span class="keyword">import</span> java.io.ObjectOutputStream;</div><div class="line"></div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">StoreTest</span> </span>&#123;</div><div class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</div><div class="line">		ObjectOutputStream o = <span class="keyword">null</span>;</div><div class="line">		<span class="keyword">try</span> &#123;</div><div class="line">			o = <span class="keyword">new</span> ObjectOutputStream(<span class="keyword">new</span> FileOutputStream(<span class="string">"/home/matt/store.out"</span>));</div><div class="line">			Person person=<span class="keyword">new</span> Person(<span class="string">"matt1"</span>,<span class="number">20</span>,Gender.MALE);</div><div class="line">			o.writeObject(person);</div><div class="line">			person.setAge(<span class="number">22</span>);</div><div class="line">			System.out.println(<span class="keyword">new</span> File(<span class="string">"/home/matt/store.out"</span>).length());</div><div class="line">			o.writeObject(person);</div><div class="line">			System.out.println(<span class="keyword">new</span> File(<span class="string">"/home/matt/store.out"</span>).length());</div><div class="line">			o.close();</div><div class="line">			ObjectInputStream in = <span class="keyword">new</span> ObjectInputStream(<span class="keyword">new</span> FileInputStream(<span class="string">"/home/matt/store.out"</span>));</div><div class="line">			<span class="keyword">try</span> &#123;</div><div class="line">				Person person1= (Person) in.readObject();</div><div class="line">				System.out.println(person1.getAge());</div><div class="line">				Person person2= (Person) in.readObject();</div><div class="line">				System.out.println(person2.getAge());</div><div class="line">				System.out.println(person1==person2);</div><div class="line">			&#125; <span class="keyword">catch</span> (ClassNotFoundException e) &#123;</div><div class="line">				e.printStackTrace();</div><div class="line">			&#125;</div><div class="line">		&#125; <span class="keyword">catch</span> (IOException e) &#123;</div><div class="line">			e.printStackTrace();</div><div class="line">		&#125;</div><div class="line">	&#125;</div><div class="line">&#125;</div><div class="line"><span class="comment">/**</span></div><div class="line">* Output:</div><div class="line">* 232</div><div class="line">* 237</div><div class="line">* 20</div><div class="line">* 20</div><div class="line">* true</div><div class="line">*/</div></pre></td></tr></table></figure>
<p>在上述示例中，对于同一个对象，在修改完年龄值后又重新将该实例对象序列化到文件。通过运行的结果我们可以发现：</p>
<ul>
<li>第二次将对象序列化到文件之后，文件的大小只增加了5个字节的大小；</li>
<li>第二次序列化的对象年龄值已经修改为22，但是从反序列化的结果来看，该实例对象的年龄值并未改变。</li>
</ul>
<p>大家是不是感觉到非常的奇怪，通过下面的两点解释之后，大家可能就会明白这其中的原因了：</p>
<ol>
<li>因为写入的是同一个对象，Java序列化机制为了节省磁盘空间，当写入文件的为同一个对象时，并不会将对象的内容再次进行存储，而只是再次存储一份引用，上面增加的5个字节的存储空间就是新增的引用和一些控制信息的空间，从反序列化的结果也可以看出，两个引用指向的是同一个对象；</li>
<li>虽然第二次存储时将年龄修改为22，但是因为Java序列化机制在第二次序列化同一个对象时，并保存具体的数据，只是保存了第一次的引用，所以反序列化时，得到的对象都是第一次序列化的对象。</li>
</ol>
<h2 id="序列化ID"><a href="#序列化ID" class="headerlink" title="序列化ID"></a>序列化ID</h2><p>这里可以可以参考<a href="http://ych0108.iteye.com/blog/2256640" target="_blank" rel="external">Java中序列化的serialVersionUID作用</a>一文。</p>
<p>这里我们就简单说一下序列化ID的作用：</p>
<p><code>serialVersionUID</code>用来表明类的不同版本间的兼容性。它有两种生成方式： 一个是默认的1L；另一种是根据类名、接口名、成员方法及属性等来生成一个64位的哈希字段 。</p>
<ol>
<li>在某些场合，希望类的不同版本对序列化兼容，因此需要确保类的不同版本具有相同的<code>serialVersionUID</code>；而在某些场合，不希望类的不同版本对序列化兼容，因此需要确保类的不同版本具有不同的<code>serialVersionUID</code>。</li>
<li>当你序列化了一个类实例后，希望更改一个字段或添加一个字段，不设置<code>serialVersionUID</code>，所做的任何更改都将导致无法反序化旧有实例，并在反序列化时抛出一个异常。如果你添加了<code>serialVersionUID</code>，在反序列旧有实例时，新添加或更改的字段值将设为初始化值（对象为null，基本类型为相应的初始默认值），字段被删除将不设置。</li>
</ol>
<hr>
<p>参考：</p>
<ul>
<li><a href="http://item.jd.com/10058164.html" target="_blank" rel="external">Java编程思想 第4版</a></li>
<li><a href="https://www.ibm.com/developerworks/cn/java/j-lo-serial/" target="_blank" rel="external">Java序列化的高级认识</a></li>
</ul>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[Java容器学习]]></title>
      <url>http://matt33.com/2016/05/13/java-collection/</url>
      <content type="html"><![CDATA[<p>Java的容器类，在程序中经常被用，而且也是在面试中经常被问到的部分，笔者近段就被问到过n次了，所以这里就根据网上的一些资料，并结合着openJDK的源码对这些容器类好好总结一下。</p>
<h1 id="Java中的容器"><a href="#Java中的容器" class="headerlink" title="Java中的容器"></a>Java中的容器</h1><p>在Java（以JDK1.7为例）中，如果一个程序包含固定数量的且生命周期已知的对象，那么我们可以使用数组来保存这些对象。但是一般情况下，我们在写程序时不知道需要保存多少个对象，对于这种情况，Java的实用类库中提供了一套相当完整的容器类来解决这个问题，其中基本的类型是：</p>
<ol>
<li>List</li>
<li>Set</li>
<li>Map</li>
</ol>
<p>这些容器类也称为集合类。</p>
<p>对于它们之间的联系：我是这样理解的，首先Map是一个K-V对的集合（关联数组）：</p>
<ol>
<li>key的集合组成了一个Set，因为key是不允许重复的，且Map不会保存key的插入顺序，所以key可组成一个set；</li>
<li>value的集合组成了一个List，因为value是完全可以重复的，Map会根据key的值来获取value，这些value（如果当key是int型时）就组成了一个List（当然List并不是根据Map实现的）。</li>
</ol>
<p>上面的三种集合类只是提供了三个基本的接口，实际使用的集合类主要还是在它们的子类，下面这个图比较清楚地介绍了这三种容器类的常用子类（图片来自<a href="http://stackoverflow.com/questions/3317381/what-is-the-difference-between-collection-and-list-in-java" target="_blank" rel="external">StackOverFlow</a>）</p>
<p><img src="/images/java/collection.png" alt="collection"></p>
<blockquote>
<p>注：图片并没有把所有的继承与接口实现全部表示出来，只是列出了主要的部分，比如：<code>class HashSet&lt;E&gt; extends AbstractSet&lt;E&gt; implements Set&lt;E&gt;, Cloneable, java.io.Serializable</code>，而<code>class AbstractSet&lt;E&gt; extends AbstractCollection&lt;E&gt; implements Set</code>，而<code>AbstractCollection&lt;E&gt; implements Collection</code>，全部的继承与接口实现机制比较复杂，这里只画出了它们的主要部分，这样方便我们看到这些集合类之间的联系与区别。</p>
</blockquote>
<p>对于集合类的分析，这里我们主要从以下几个部分去分析：</p>
<ol>
<li>原理：底层如何实现；</li>
<li>性能：分析这个集合类在具体操作上的复杂度<ul>
<li>插入：插入是如何实现的，性能如何；</li>
<li>删除：删除是如何实现的，性能如何；</li>
<li>读取：读取是如何实现的，性能如何；</li>
</ul>
</li>
<li>其他：比如集合类存储对象时，HashMap里需要重写<code>hash()</code>和<code>equals()</code>等性质。</li>
</ol>
<h1 id="List"><a href="#List" class="headerlink" title="List"></a>List</h1><p>首先这里先介绍一下List集合类，List集合存储的是对象的引用或者基本数据类型，而且存储都是<strong>有序</strong>的，并且<strong>可以重复</strong>。下面分别介绍三种常见的List类。</p>
<h2 id="ArrayList"><a href="#ArrayList" class="headerlink" title="ArrayList"></a>ArrayList</h2><p>源码可以参考<a href="https://github.com/fanhongtao/JDK/blob/master/src/java/util/ArrayList.java" target="_blank" rel="external">ArrayList</a>，我们这里主要摘取几块重要的部分（并非全部代码）</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ArrayList</span>&lt;<span class="title">E</span>&gt; <span class="keyword">extends</span> <span class="title">AbstractList</span>&lt;<span class="title">E</span>&gt; <span class="keyword">implements</span> <span class="title">List</span>&lt;<span class="title">E</span>&gt;, <span class="title">RandomAccess</span>, <span class="title">Cloneable</span>, <span class="title">java</span>.<span class="title">io</span>.<span class="title">Serializable</span></span>&#123;</div><div class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> DEFAULT_CAPACITY = <span class="number">10</span>; <span class="comment">// 默认的数组长度</span></div><div class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> Object[] EMPTY_ELEMENTDATA = &#123;&#125;;</div><div class="line">    <span class="keyword">private</span> <span class="keyword">transient</span> Object[] elementData; <span class="comment">// transient关键字主要是用于定制序列化方面</span></div><div class="line"></div><div class="line">    <span class="keyword">private</span> <span class="keyword">int</span> size;</div><div class="line"></div><div class="line">	<span class="comment">// 知道数组长度的情况下初始化数组</span></div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="title">ArrayList</span><span class="params">(<span class="keyword">int</span> initialCapacity)</span> </span>&#123;</div><div class="line">        <span class="keyword">super</span>();</div><div class="line">        <span class="keyword">if</span> (initialCapacity &lt; <span class="number">0</span>)</div><div class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> IllegalArgumentException(<span class="string">"Illegal Capacity: "</span>+ initialCapacity);</div><div class="line">        <span class="keyword">this</span>.elementData = <span class="keyword">new</span> Object[initialCapacity];</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="title">ArrayList</span><span class="params">()</span> </span>&#123;</div><div class="line">        <span class="keyword">super</span>();</div><div class="line">        <span class="keyword">this</span>.elementData = EMPTY_ELEMENTDATA;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">	<span class="comment">// 动态增加数组的长度，每次动态增加(oldCapacity &gt;&gt; 1)</span></div><div class="line">	<span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">grow</span><span class="params">(<span class="keyword">int</span> minCapacity)</span> </span>&#123;</div><div class="line">        <span class="comment">// overflow-conscious code</span></div><div class="line">        <span class="keyword">int</span> oldCapacity = elementData.length;</div><div class="line">        <span class="keyword">int</span> newCapacity = oldCapacity + (oldCapacity &gt;&gt; <span class="number">1</span>);</div><div class="line">        <span class="keyword">if</span> (newCapacity - minCapacity &lt; <span class="number">0</span>)</div><div class="line">            newCapacity = minCapacity;</div><div class="line">        <span class="keyword">if</span> (newCapacity - MAX_ARRAY_SIZE &gt; <span class="number">0</span>)</div><div class="line">            newCapacity = hugeCapacity(minCapacity);</div><div class="line">        <span class="comment">// minCapacity is usually close to size, so this is a win:</span></div><div class="line">        elementData = Arrays.copyOf(elementData, newCapacity);</div><div class="line">    &#125;</div><div class="line"></div><div class="line">	<span class="comment">// 获取元素，先检查index是否在范围，然后直接以数组的方式取出</span></div><div class="line">    <span class="function"><span class="keyword">public</span> E <span class="title">get</span><span class="params">(<span class="keyword">int</span> index)</span> </span>&#123;</div><div class="line">        rangeCheck(index);</div><div class="line"></div><div class="line">        <span class="keyword">return</span> elementData(index);</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="comment">// 修改给定位置的一个元素值</span></div><div class="line">    <span class="function"><span class="keyword">public</span> E <span class="title">set</span><span class="params">(<span class="keyword">int</span> index, E element)</span> </span>&#123;</div><div class="line">        rangeCheck(index);</div><div class="line"></div><div class="line">        E oldValue = elementData(index);</div><div class="line">        elementData[index] = element;</div><div class="line">        <span class="keyword">return</span> oldValue;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">   	<span class="comment">// 在list的最后添加一个元素</span></div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">add</span><span class="params">(E e)</span> </span>&#123;</div><div class="line">        ensureCapacityInternal(size + <span class="number">1</span>);  <span class="comment">// Increments modCount!!</span></div><div class="line">        elementData[size++] = e;</div><div class="line">        <span class="keyword">return</span> <span class="keyword">true</span>;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="comment">// 在给定位置添加一个元素（随机插入），这时候需要将该位置后面的所有元素移位</span></div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">add</span><span class="params">(<span class="keyword">int</span> index, E element)</span> </span>&#123;</div><div class="line">        rangeCheckForAdd(index);</div><div class="line"></div><div class="line">        ensureCapacityInternal(size + <span class="number">1</span>);  <span class="comment">// Increments modCount!!</span></div><div class="line">        System.arraycopy(elementData, index, elementData, index + <span class="number">1</span>, size - index);</div><div class="line">        elementData[index] = element;</div><div class="line">        size++;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="comment">// 移出给定位置的一个元素（随机删除），这时候也需要将该位置后面的所有元素移位</span></div><div class="line">    <span class="function"><span class="keyword">public</span> E <span class="title">remove</span><span class="params">(<span class="keyword">int</span> index)</span> </span>&#123;</div><div class="line">        rangeCheck(index);</div><div class="line"></div><div class="line">        modCount++;</div><div class="line">        E oldValue = elementData(index);</div><div class="line"></div><div class="line">        <span class="keyword">int</span> numMoved = size - index - <span class="number">1</span>;</div><div class="line">        <span class="keyword">if</span> (numMoved &gt; <span class="number">0</span>)</div><div class="line">            System.arraycopy(elementData, index+<span class="number">1</span>, elementData, index, numMoved);</div><div class="line">        elementData[--size] = <span class="keyword">null</span>; <span class="comment">// clear to let GC do its work</span></div><div class="line"></div><div class="line">        <span class="keyword">return</span> oldValue;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="comment">// 移出第一个符合要求的元素（需要从最前面开始遍历list）</span></div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">remove</span><span class="params">(Object o)</span> </span>&#123;</div><div class="line">        <span class="keyword">if</span> (o == <span class="keyword">null</span>) &#123;</div><div class="line">            <span class="keyword">for</span> (<span class="keyword">int</span> index = <span class="number">0</span>; index &lt; size; index++)</div><div class="line">                <span class="keyword">if</span> (elementData[index] == <span class="keyword">null</span>) &#123;</div><div class="line">                    fastRemove(index);</div><div class="line">                    <span class="keyword">return</span> <span class="keyword">true</span>;</div><div class="line">                &#125;</div><div class="line">        &#125; <span class="keyword">else</span> &#123;</div><div class="line">            <span class="keyword">for</span> (<span class="keyword">int</span> index = <span class="number">0</span>; index &lt; size; index++)</div><div class="line">                <span class="keyword">if</span> (o.equals(elementData[index])) &#123;</div><div class="line">                    fastRemove(index);</div><div class="line">                    <span class="keyword">return</span> <span class="keyword">true</span>;</div><div class="line">                &#125;</div><div class="line">        &#125;</div><div class="line">        <span class="keyword">return</span> <span class="keyword">false</span>;</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>通过对代码的分析，下面总结一下ArrayList（<a href="https://github.com/wangzzu/java_learn/blob/master/java_thinking/src/javabasic/collection/list/ArrayListTest.java" target="_blank" rel="external">测试代码</a>）：</p>
<ul>
<li>原理：基于<strong>数组</strong>来实现（顺序存储的线性表）</li>
<li>特点：<ol>
<li>动态数组，每次插入时都会检查数组长度是否够用，不够用时需要进行扩大，每次会将数组的长度增加$\frac{N}{2}$，也就是新建一个数组，然后将原来数组的元素拷贝进去；</li>
<li>ArrayList是List接口的可变数组的实现；</li>
<li>非同步；</li>
<li>添加、删除操作时，每次都需要把该索引右边的数组整体移动，性能较差，所以ArrayList更擅长随机访问数组，但是在数组中间进行插入或删除元素时较慢；</li>
<li>内部实现时，使用了<code>transient</code>修饰数组，这保证系统序列化ArrayList对象时不会直接序列化<code>elementData</code>数组，而是通过ArrayList提供的<code>writeObject</code>、<code>readObject</code>方法定制序列化。</li>
</ol>
</li>
</ul>
<h2 id="Vector"><a href="#Vector" class="headerlink" title="Vector"></a>Vector</h2><p>源码可以参考<a href="https://github.com/fanhongtao/JDK/blob/master/src/java/util/Vector.java" target="_blank" rel="external">Vector</a>，我们这里主要摘取几块重要的部分（并非全部代码）</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Vector</span>&lt;<span class="title">E</span>&gt; <span class="keyword">extends</span> <span class="title">AbstractList</span>&lt;<span class="title">E</span>&gt; <span class="keyword">implements</span> <span class="title">List</span>&lt;<span class="title">E</span>&gt;, <span class="title">RandomAccess</span>, <span class="title">Cloneable</span>, <span class="title">java</span>.<span class="title">io</span>.<span class="title">Serializable</span></span>&#123;</div><div class="line"></div><div class="line">    <span class="keyword">protected</span> Object[] elementData;</div><div class="line"></div><div class="line">    <span class="keyword">protected</span> <span class="keyword">int</span> elementCount;</div><div class="line"></div><div class="line">    <span class="keyword">protected</span> <span class="keyword">int</span> capacityIncrement; <span class="comment">// 数组动态增加时的步长</span></div><div class="line"></div><div class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">long</span> serialVersionUID = -<span class="number">2767605614048989439L</span>;</div><div class="line"></div><div class="line">    <span class="comment">// 初始化list，可以设置步长</span></div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="title">Vector</span><span class="params">(<span class="keyword">int</span> initialCapacity, <span class="keyword">int</span> capacityIncrement)</span> </span>&#123;</div><div class="line">        <span class="keyword">super</span>();</div><div class="line">        <span class="keyword">if</span> (initialCapacity &lt; <span class="number">0</span>)</div><div class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> IllegalArgumentException(<span class="string">"Illegal Capacity: "</span>+ initialCapacity);</div><div class="line">        <span class="keyword">this</span>.elementData = <span class="keyword">new</span> Object[initialCapacity];</div><div class="line">        <span class="keyword">this</span>.capacityIncrement = capacityIncrement;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="title">Vector</span><span class="params">(<span class="keyword">int</span> initialCapacity)</span> </span>&#123;</div><div class="line">        <span class="keyword">this</span>(initialCapacity, <span class="number">0</span>);</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="title">Vector</span><span class="params">()</span> </span>&#123;</div><div class="line">        <span class="keyword">this</span>(<span class="number">10</span>);</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="comment">// 在list最后添加元素</span></div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">synchronized</span> <span class="keyword">boolean</span> <span class="title">add</span><span class="params">(E e)</span> </span>&#123;</div><div class="line">        modCount++;</div><div class="line">        ensureCapacityHelper(elementCount + <span class="number">1</span>);</div><div class="line">        elementData[elementCount++] = e;</div><div class="line">        <span class="keyword">return</span> <span class="keyword">true</span>;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="comment">// 在给定位置添加元素</span></div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">add</span><span class="params">(<span class="keyword">int</span> index, E element)</span> </span>&#123;</div><div class="line">        insertElementAt(element, index);</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="comment">// 随机插入元素的实际操作方法，这里也需要移动整个数组</span></div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">synchronized</span> <span class="keyword">void</span> <span class="title">insertElementAt</span><span class="params">(E obj, <span class="keyword">int</span> index)</span> </span>&#123;</div><div class="line">        modCount++;</div><div class="line">        <span class="keyword">if</span> (index &gt; elementCount) &#123;</div><div class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> ArrayIndexOutOfBoundsException(index + <span class="string">" &gt; "</span> + elementCount);</div><div class="line">        &#125;</div><div class="line">        ensureCapacityHelper(elementCount + <span class="number">1</span>);</div><div class="line">        System.arraycopy(elementData, index, elementData, index + <span class="number">1</span>, elementCount - index);</div><div class="line">        elementData[index] = obj;</div><div class="line">        elementCount++;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="comment">// 删除给定位置的元素，也需要整体移动数组</span></div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">synchronized</span> E <span class="title">remove</span><span class="params">(<span class="keyword">int</span> index)</span> </span>&#123;</div><div class="line">        modCount++;</div><div class="line">        <span class="keyword">if</span> (index &gt;= elementCount)</div><div class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> ArrayIndexOutOfBoundsException(index);</div><div class="line">        E oldValue = elementData(index);</div><div class="line"></div><div class="line">        <span class="keyword">int</span> numMoved = elementCount - index - <span class="number">1</span>;</div><div class="line">        <span class="keyword">if</span> (numMoved &gt; <span class="number">0</span>)</div><div class="line">            System.arraycopy(elementData, index+<span class="number">1</span>, elementData, index, numMoved);</div><div class="line">        elementData[--elementCount] = <span class="keyword">null</span>; <span class="comment">// Let gc do its work</span></div><div class="line"></div><div class="line">        <span class="keyword">return</span> oldValue;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="comment">// 获取给定位置的元素</span></div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">synchronized</span> E <span class="title">get</span><span class="params">(<span class="keyword">int</span> index)</span> </span>&#123;</div><div class="line">        <span class="keyword">if</span> (index &gt;= elementCount)</div><div class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> ArrayIndexOutOfBoundsException(index);</div><div class="line"></div><div class="line">        <span class="keyword">return</span> elementData(index);</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="function">E <span class="title">elementData</span><span class="params">(<span class="keyword">int</span> index)</span> </span>&#123;</div><div class="line">        <span class="keyword">return</span> (E) elementData[index];</div><div class="line">    &#125;</div></pre></td></tr></table></figure>
<p>Vector与ArrayLis很相似，ArrayList与Vector的大部分方法都是相同，只是Vector添加了<code>synchronized</code>，也就是说，Vector是ArrayList的线程安全版本，但是在序列化方面，ArrayList比Vector更安全。</p>
<ul>
<li>原理：基于<strong>数组</strong>实现</li>
<li>特点：<ol>
<li>同步的（方法大都是<code>synchronized</code>的）；</li>
<li>每次扩大时可以通过参数设置扩大的步长;</li>
<li>对于Vector，没有使用<code>transient</code>修饰数组，而且Vector只提供了一个<code>writeObject</code>方法，并未完全实现定制序列化。</li>
</ol>
</li>
</ul>
<p>它有一个子类为Stack（线程安全），对于栈，不要求线程安全时，可以使用<code>ArrayDeque</code>实现。</p>
<h2 id="LinkedList"><a href="#LinkedList" class="headerlink" title="LinkedList"></a>LinkedList</h2><p>源码可以参考<a href="https://github.com/fanhongtao/JDK/blob/master/src/java/util/LinkedList.java" target="_blank" rel="external">LinkedList</a>，我们这里主要摘取几块重要的部分（并非全部代码）</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div><div class="line">113</div><div class="line">114</div><div class="line">115</div><div class="line">116</div><div class="line">117</div><div class="line">118</div><div class="line">119</div><div class="line">120</div><div class="line">121</div><div class="line">122</div><div class="line">123</div><div class="line">124</div><div class="line">125</div><div class="line">126</div><div class="line">127</div><div class="line">128</div><div class="line">129</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">LinkedList</span>&lt;<span class="title">E</span>&gt; <span class="keyword">extends</span> <span class="title">AbstractSequentialList</span>&lt;<span class="title">E</span>&gt; <span class="keyword">implements</span> <span class="title">List</span>&lt;<span class="title">E</span>&gt;, <span class="title">Deque</span>&lt;<span class="title">E</span>&gt;, <span class="title">Cloneable</span>, <span class="title">java</span>.<span class="title">io</span>.<span class="title">Serializable</span></span>&#123;</div><div class="line">    <span class="keyword">transient</span> <span class="keyword">int</span> size = <span class="number">0</span>;</div><div class="line"></div><div class="line">    <span class="keyword">transient</span> Node&lt;E&gt; first; <span class="comment">// 指向第一个节点</span></div><div class="line"></div><div class="line">    <span class="keyword">transient</span> Node&lt;E&gt; last; <span class="comment">// 指向最后一个节点</span></div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="title">LinkedList</span><span class="params">()</span> </span>&#123;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="title">LinkedList</span><span class="params">(Collection&lt;? extends E&gt; c)</span> </span>&#123;</div><div class="line">        <span class="keyword">this</span>();</div><div class="line">        addAll(c);</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">linkFirst</span><span class="params">(E e)</span> </span>&#123;&#125; <span class="comment">// 将元素e添加到list的头部</span></div><div class="line"></div><div class="line">    <span class="comment">//调用上一个私有方法</span></div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">addFirst</span><span class="params">(E e)</span> </span>&#123;</div><div class="line">        linkFirst(e);</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">void</span> <span class="title">linkLast</span><span class="params">(E e)</span> </span>&#123;&#125; <span class="comment">// 将元素添加到list的尾部</span></div><div class="line"></div><div class="line">    <span class="comment">// 在节点succ前添加一个元素e</span></div><div class="line">    <span class="function"><span class="keyword">void</span> <span class="title">linkBefore</span><span class="params">(E e, Node&lt;E&gt; succ)</span> </span>&#123;</div><div class="line">        <span class="comment">// assert succ != null;</span></div><div class="line">        <span class="keyword">final</span> Node&lt;E&gt; pred = succ.prev;</div><div class="line">        <span class="keyword">final</span> Node&lt;E&gt; newNode = <span class="keyword">new</span> Node&lt;&gt;(pred, e, succ);</div><div class="line">        succ.prev = newNode;</div><div class="line">        <span class="keyword">if</span> (pred == <span class="keyword">null</span>)</div><div class="line">            first = newNode;</div><div class="line">        <span class="keyword">else</span></div><div class="line">            pred.next = newNode;</div><div class="line">        size++;</div><div class="line">        modCount++;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="comment">// 删除头节点</span></div><div class="line">    <span class="function"><span class="keyword">private</span> E <span class="title">unlinkFirst</span><span class="params">(Node&lt;E&gt; f)</span> </span>&#123;&#125;</div><div class="line"></div><div class="line">    <span class="comment">// 删除尾节点</span></div><div class="line">    <span class="function"><span class="keyword">private</span> E <span class="title">unlinkLast</span><span class="params">(Node&lt;E&gt; l)</span> </span>&#123;&#125;</div><div class="line"></div><div class="line">    <span class="comment">// 在list尾部添加元素的实际操作</span></div><div class="line">    <span class="function"><span class="keyword">void</span> <span class="title">linkLast</span><span class="params">(E e)</span> </span>&#123;</div><div class="line">        <span class="keyword">final</span> Node&lt;E&gt; l = last;</div><div class="line">        <span class="keyword">final</span> Node&lt;E&gt; newNode = <span class="keyword">new</span> Node&lt;&gt;(l, e, <span class="keyword">null</span>);</div><div class="line">        last = newNode;</div><div class="line">        <span class="keyword">if</span> (l == <span class="keyword">null</span>)</div><div class="line">            first = newNode;</div><div class="line">        <span class="keyword">else</span></div><div class="line">            l.next = newNode;</div><div class="line">        size++;</div><div class="line">        modCount++;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="comment">// 在list最后面添加元素</span></div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">add</span><span class="params">(E e)</span> </span>&#123;</div><div class="line">        linkLast(e);</div><div class="line">        <span class="keyword">return</span> <span class="keyword">true</span>;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="comment">// 给定位置添加元素</span></div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">add</span><span class="params">(<span class="keyword">int</span> index, E element)</span> </span>&#123;</div><div class="line">        checkPositionIndex(index);</div><div class="line"></div><div class="line">        <span class="keyword">if</span> (index == size)</div><div class="line">            linkLast(element);</div><div class="line">        <span class="keyword">else</span></div><div class="line">            linkBefore(element, node(index)); <span class="comment">//调用这个方法</span></div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="comment">// 删除给定的节点</span></div><div class="line">    <span class="function">E <span class="title">unlink</span><span class="params">(Node&lt;E&gt; x)</span> </span>&#123;</div><div class="line">        <span class="comment">// assert x != null;</span></div><div class="line">        <span class="keyword">final</span> E element = x.item;</div><div class="line">        <span class="keyword">final</span> Node&lt;E&gt; next = x.next;</div><div class="line">        <span class="keyword">final</span> Node&lt;E&gt; prev = x.prev;</div><div class="line"></div><div class="line">        <span class="keyword">if</span> (prev == <span class="keyword">null</span>) &#123;</div><div class="line">            first = next;</div><div class="line">        &#125; <span class="keyword">else</span> &#123;</div><div class="line">            prev.next = next;</div><div class="line">            x.prev = <span class="keyword">null</span>;</div><div class="line">        &#125;</div><div class="line"></div><div class="line">        <span class="keyword">if</span> (next == <span class="keyword">null</span>) &#123;</div><div class="line">            last = prev;</div><div class="line">        &#125; <span class="keyword">else</span> &#123;</div><div class="line">            next.prev = prev;</div><div class="line">            x.next = <span class="keyword">null</span>;</div><div class="line">        &#125;</div><div class="line"></div><div class="line">        x.item = <span class="keyword">null</span>;</div><div class="line">        size--;</div><div class="line">        modCount++;</div><div class="line">        <span class="keyword">return</span> element;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="comment">// 根据索引返回该位置的Node（这个方法会经常调用，通过遍历的方法找到该位置）</span></div><div class="line">    <span class="function">Node&lt;E&gt; <span class="title">node</span><span class="params">(<span class="keyword">int</span> index)</span> </span>&#123;</div><div class="line">        <span class="comment">// assert isElementIndex(index);</span></div><div class="line"></div><div class="line">        <span class="keyword">if</span> (index &lt; (size &gt;&gt; <span class="number">1</span>)) &#123;</div><div class="line">            Node&lt;E&gt; x = first;</div><div class="line">            <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; index; i++)</div><div class="line">                x = x.next;</div><div class="line">            <span class="keyword">return</span> x;</div><div class="line">        &#125; <span class="keyword">else</span> &#123;</div><div class="line">            Node&lt;E&gt; x = last;</div><div class="line">            <span class="keyword">for</span> (<span class="keyword">int</span> i = size - <span class="number">1</span>; i &gt; index; i--)</div><div class="line">                x = x.prev;</div><div class="line">            <span class="keyword">return</span> x;</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="comment">// 删除指定位置的元素</span></div><div class="line">    <span class="function"><span class="keyword">public</span> E <span class="title">remove</span><span class="params">(<span class="keyword">int</span> index)</span> </span>&#123;</div><div class="line">        checkElementIndex(index);</div><div class="line">        <span class="keyword">return</span> unlink(node(index));</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="comment">// 返回指定位置的元素</span></div><div class="line">    <span class="function"><span class="keyword">public</span> E <span class="title">get</span><span class="params">(<span class="keyword">int</span> index)</span> </span>&#123;</div><div class="line">        checkElementIndex(index);</div><div class="line">        <span class="keyword">return</span> node(index).item;</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<ul>
<li>原理：基于<strong>双向链表</strong>实现的（链式存储的线性表）</li>
<li>特点：<ol>
<li>在获取元素的索引时，需要去<strong>遍历</strong>链表来获取索引（也就是<code>node()</code>方法）。</li>
<li>它的插入和删除操作比ArrayList更加高效（主要是对于List中间的删除或添加，因为ArrayList需要整体移动右边数组），也正是由于它是基于链表实现的，所以随机访问的效率要比ArrayList差。</li>
<li>非同步；</li>
<li>实现了List和Deque接口，既可以做双向链表使用，又可以做队列使用，还可以做栈使用;</li>
<li>也可以进行定制序列化。</li>
</ol>
</li>
</ul>
<blockquote>
<p>Deque接口是双端队列，既可以作为栈也可以作为队列。</p>
</blockquote>
<p>关于LinkedList，笔者做一个test，使用LinkedList分别做链表、队列和栈，参考<a href="https://github.com/wangzzu/java_learn/blob/master/java_thinking/src/javabasic/collection/list/LinkedListTest.java" target="_blank" rel="external">测试代码</a>。</p>
<blockquote>
<p>Notice: <strong>fail-fast 机制</strong>是java集合(Collection)中的一种错误机制。 当多个线程对同一个集合的内容进行操作时，就可能会产生 fail-fast 事件（<code>ConcurrentModificationException</code>）。fail-fast机制，是一种错误检测机制。它只能被用来检测错误，因为JDK并不保证fail-fast机制一定会发生。若在多线程环境下使用 fail-fast机制的集合，建议使用<code>java.util.concurrent</code>包下的类去取代<code>java.util</code>包下的类。</p>
</blockquote>
<h1 id="Map"><a href="#Map" class="headerlink" title="Map"></a>Map</h1><p>Map一种经常用的容器类型，它存储的是K-V键值对。</p>
<h2 id="HashMap"><a href="#HashMap" class="headerlink" title="HashMap"></a>HashMap</h2><p>先讲一下最常用的HashMap吧，还是看一下主要的源码，可以参考<a href="https://github.com/fanhongtao/JDK/blob/master/src/java/util/HashMap.java" target="_blank" rel="external">HashMap</a>，这里摘取几块重要的部分（并非全部代码）</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div><div class="line">113</div><div class="line">114</div><div class="line">115</div><div class="line">116</div><div class="line">117</div><div class="line">118</div><div class="line">119</div><div class="line">120</div><div class="line">121</div><div class="line">122</div><div class="line">123</div><div class="line">124</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">HashMap</span>&lt;<span class="title">K</span>,<span class="title">V</span>&gt; <span class="keyword">extends</span> <span class="title">AbstractMap</span>&lt;<span class="title">K</span>,<span class="title">V</span>&gt; <span class="keyword">implements</span> <span class="title">Map</span>&lt;<span class="title">K</span>,<span class="title">V</span>&gt;, <span class="title">Cloneable</span>, <span class="title">Serializable</span></span>&#123;</div><div class="line"></div><div class="line">    <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> DEFAULT_INITIAL_CAPACITY = <span class="number">1</span> &lt;&lt; <span class="number">4</span>; <span class="comment">// 默认的长度，这里是16，要求必须是2的次方</span></div><div class="line"></div><div class="line">    <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">float</span> DEFAULT_LOAD_FACTOR = <span class="number">0.75f</span>; <span class="comment">// 默认的负载因子</span></div><div class="line"></div><div class="line">    <span class="keyword">static</span> <span class="keyword">final</span> Entry&lt;?,?&gt;[] EMPTY_TABLE = &#123;&#125;;</div><div class="line"></div><div class="line">    <span class="keyword">transient</span> Entry&lt;K,V&gt;[] table = (Entry&lt;K,V&gt;[]) EMPTY_TABLE;</div><div class="line"></div><div class="line">    <span class="keyword">transient</span> <span class="keyword">int</span> size; <span class="comment">// map中的长度</span></div><div class="line"></div><div class="line">    <span class="keyword">final</span> <span class="keyword">float</span> loadFactor;</div><div class="line"></div><div class="line">    <span class="comment">// 根据给定大小和负载因子初始化map</span></div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="title">HashMap</span><span class="params">(<span class="keyword">int</span> initialCapacity, <span class="keyword">float</span> loadFactor)</span> </span>&#123;</div><div class="line">        <span class="keyword">if</span> (initialCapacity &lt; <span class="number">0</span>)</div><div class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> IllegalArgumentException(<span class="string">"Illegal initial capacity: "</span> + initialCapacity);</div><div class="line">        <span class="keyword">if</span> (initialCapacity &gt; MAXIMUM_CAPACITY)</div><div class="line">            initialCapacity = MAXIMUM_CAPACITY;</div><div class="line">        <span class="keyword">if</span> (loadFactor &lt;= <span class="number">0</span> || Float.isNaN(loadFactor))</div><div class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> IllegalArgumentException(<span class="string">"Illegal load factor: "</span> + loadFactor);</div><div class="line">        <span class="keyword">this</span>.loadFactor = loadFactor;</div><div class="line">        threshold = initialCapacity;</div><div class="line">        init();</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="title">HashMap</span><span class="params">(<span class="keyword">int</span> initialCapacity)</span> </span>&#123;</div><div class="line">        <span class="keyword">this</span>(initialCapacity, DEFAULT_LOAD_FACTOR);</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="title">HashMap</span><span class="params">()</span> </span>&#123;</div><div class="line">        <span class="keyword">this</span>(DEFAULT_INITIAL_CAPACITY, DEFAULT_LOAD_FACTOR);</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="comment">/// 添加KV对</span></div><div class="line">    <span class="function"><span class="keyword">public</span> V <span class="title">put</span><span class="params">(K key, V value)</span> </span>&#123;</div><div class="line">        <span class="keyword">if</span> (table == EMPTY_TABLE) &#123;</div><div class="line">            inflateTable(threshold);</div><div class="line">        &#125;</div><div class="line">        <span class="keyword">if</span> (key == <span class="keyword">null</span>)</div><div class="line">            <span class="keyword">return</span> putForNullKey(value);</div><div class="line">        <span class="keyword">int</span> hash = hash(key);</div><div class="line">        <span class="keyword">int</span> i = indexFor(hash, table.length);</div><div class="line">        <span class="keyword">for</span> (Entry&lt;K,V&gt; e = table[i]; e != <span class="keyword">null</span>; e = e.next) &#123;</div><div class="line">            Object k;</div><div class="line">            <span class="keyword">if</span> (e.hash == hash &amp;&amp; ((k = e.key) == key || key.equals(k))) &#123; <span class="comment">// key相等（hash值还有实际值相等）时，替换value</span></div><div class="line">                V oldValue = e.value;</div><div class="line">                e.value = value;</div><div class="line">                e.recordAccess(<span class="keyword">this</span>);</div><div class="line">                <span class="keyword">return</span> oldValue;</div><div class="line">            &#125;</div><div class="line">        &#125;</div><div class="line">        modCount++;</div><div class="line">        addEntry(hash, key, value, i); <span class="comment">// 将&lt;key, value&gt;添加到i索引处</span></div><div class="line">        <span class="keyword">return</span> <span class="keyword">null</span>;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="comment">// 将KV对添加到给定位置的Entry链上</span></div><div class="line">    <span class="function"><span class="keyword">void</span> <span class="title">addEntry</span><span class="params">(<span class="keyword">int</span> hash, K key, V value, <span class="keyword">int</span> bucketIndex)</span> </span>&#123;</div><div class="line">        <span class="keyword">if</span> ((size &gt;= threshold) &amp;&amp; (<span class="keyword">null</span> != table[bucketIndex])) &#123;</div><div class="line">            resize(<span class="number">2</span> * table.length);</div><div class="line">            hash = (<span class="keyword">null</span> != key) ? hash(key) : <span class="number">0</span>;</div><div class="line">            bucketIndex = indexFor(hash, table.length);</div><div class="line">        &#125;</div><div class="line">        createEntry(hash, key, value, bucketIndex);</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="comment">// 根据key获取相应的value值</span></div><div class="line">    <span class="function"><span class="keyword">public</span> V <span class="title">get</span><span class="params">(Object key)</span> </span>&#123;</div><div class="line">        <span class="keyword">if</span> (key == <span class="keyword">null</span>)</div><div class="line">            <span class="keyword">return</span> getForNullKey();</div><div class="line">        Entry&lt;K,V&gt; entry = getEntry(key);</div><div class="line">        <span class="keyword">return</span> <span class="keyword">null</span> == entry ? <span class="keyword">null</span> : entry.getValue();</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="comment">// 根据key找到给KV对象</span></div><div class="line">    <span class="function"><span class="keyword">final</span> Entry&lt;K,V&gt; <span class="title">getEntry</span><span class="params">(Object key)</span> </span>&#123;</div><div class="line">        <span class="keyword">if</span> (size == <span class="number">0</span>) &#123;</div><div class="line">            <span class="keyword">return</span> <span class="keyword">null</span>;</div><div class="line">        &#125;</div><div class="line">        <span class="keyword">int</span> hash = (key == <span class="keyword">null</span>) ? <span class="number">0</span> : hash(key);</div><div class="line">        <span class="keyword">for</span> (Entry&lt;K,V&gt; e = table[indexFor(hash, table.length)]; e != <span class="keyword">null</span>; e = e.next) &#123;</div><div class="line">            Object k;</div><div class="line">            <span class="keyword">if</span> (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != <span class="keyword">null</span> &amp;&amp; key.equals(k))))</div><div class="line">                <span class="keyword">return</span> e;</div><div class="line">        &#125;</div><div class="line">        <span class="keyword">return</span> <span class="keyword">null</span>;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="comment">// 根据key删除该元素</span></div><div class="line">    <span class="function"><span class="keyword">public</span> V <span class="title">remove</span><span class="params">(Object key)</span> </span>&#123;</div><div class="line">        Entry&lt;K,V&gt; e = removeEntryForKey(key);</div><div class="line">        <span class="keyword">return</span> (e == <span class="keyword">null</span> ? <span class="keyword">null</span> : e.value);</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="comment">// 实际删除该Entry链元素的实际操作</span></div><div class="line">    <span class="function"><span class="keyword">final</span> Entry&lt;K,V&gt; <span class="title">removeEntryForKey</span><span class="params">(Object key)</span> </span>&#123;</div><div class="line">        <span class="keyword">if</span> (size == <span class="number">0</span>) &#123;</div><div class="line">            <span class="keyword">return</span> <span class="keyword">null</span>;</div><div class="line">        &#125;</div><div class="line">        <span class="keyword">int</span> hash = (key == <span class="keyword">null</span>) ? <span class="number">0</span> : hash(key);</div><div class="line">        <span class="keyword">int</span> i = indexFor(hash, table.length);</div><div class="line">        Entry&lt;K,V&gt; prev = table[i];</div><div class="line">        Entry&lt;K,V&gt; e = prev;</div><div class="line">        <span class="keyword">while</span> (e != <span class="keyword">null</span>) &#123;</div><div class="line">            Entry&lt;K,V&gt; next = e.next;</div><div class="line">            Object k;</div><div class="line">            <span class="keyword">if</span> (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != <span class="keyword">null</span> &amp;&amp; key.equals(k)))) &#123;</div><div class="line">                modCount++;</div><div class="line">                size--;</div><div class="line">                <span class="keyword">if</span> (prev == e)</div><div class="line">                    table[i] = next;</div><div class="line">                <span class="keyword">else</span></div><div class="line">                    prev.next = next;</div><div class="line">                e.recordRemoval(<span class="keyword">this</span>);</div><div class="line">                <span class="keyword">return</span> e;</div><div class="line">            &#125;</div><div class="line">            prev = e;</div><div class="line">            e = next;</div><div class="line">        &#125;</div><div class="line">        <span class="keyword">return</span> e;</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>在Google上找到了一张关于关于HashMap数据存储图，如下所示</p>
<p><img src="/images/java/hashmap.png" alt="hashmap"></p>
<ul>
<li>原理： 基于<strong>拉链法的散列表</strong>（数组和链表的结合），数组的每个元素都是一个链表的引用，对象的存储位置跟key的hash值有关。</li>
<li>特点：<ol>
<li>允许存放null键和null值；</li>
<li>HashMap数组的长度总是2的n次方（这样才能高效地利用数组空间的存储）；</li>
<li>当key的hash值相同，而值不同时，会添加到链表里，key值相同时，就会覆盖原kv对的value值；</li>
<li><code>java.util.HashMap</code>不是线程安全的，因此如果在使用迭代器的过程中有其他线程修改了map，那么将抛出<code>ConcurrentModificationException</code>，这就是所谓fail-fast策略；</li>
<li>HashMap在底层吧K-V当成一个整体进行处理，这个整体就是一个Entry对象。</li>
</ol>
</li>
<li>缺点： Hashmap数据有可能出现分布不均匀的情况这样就会影响查询效率，这跟HashCode算法和具体数据有关系，一般需要重写HashCode算法。</li>
<li>性能<ol>
<li>负载因子loadFactor定义为：散列表的实际元素数目(n)/ 散列表的总容量(initialCapacity)，当loadFactor达到指定值或者0.75时候，HashMap的总容量自动扩展一倍，以此类推。</li>
<li>负载因子衡量的是一个散列表的空间的使用程度，负载因子越大表示散列表的装填程度越高，反之愈小。</li>
<li>负载因子是对时间和空间成本上的一种折衷。增大负载因袭可以减少Hash表所占用的内存空间，但会增加查询时间，而查询是HashMap中对频繁的操作；减少负载因子会提高数据查询的性能，但会增加Hash表所占用的内存空间。</li>
</ol>
</li>
</ul>
<h2 id="Hashtable"><a href="#Hashtable" class="headerlink" title="Hashtable"></a>Hashtable</h2><p>还是看一下主要的源码，可以参考<a href="https://github.com/fanhongtao/JDK/blob/master/src/java/util/Hashtable.java" target="_blank" rel="external">Hashtable</a>，这里摘取几块重要的部分（并非全部代码）</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div><div class="line">113</div><div class="line">114</div><div class="line">115</div><div class="line">116</div><div class="line">117</div><div class="line">118</div><div class="line">119</div><div class="line">120</div><div class="line">121</div><div class="line">122</div><div class="line">123</div><div class="line">124</div><div class="line">125</div><div class="line">126</div><div class="line">127</div><div class="line">128</div><div class="line">129</div><div class="line">130</div><div class="line">131</div><div class="line">132</div><div class="line">133</div><div class="line">134</div><div class="line">135</div><div class="line">136</div><div class="line">137</div><div class="line">138</div><div class="line">139</div><div class="line">140</div><div class="line">141</div><div class="line">142</div><div class="line">143</div><div class="line">144</div><div class="line">145</div><div class="line">146</div><div class="line">147</div><div class="line">148</div><div class="line">149</div><div class="line">150</div><div class="line">151</div><div class="line">152</div><div class="line">153</div><div class="line">154</div><div class="line">155</div><div class="line">156</div><div class="line">157</div><div class="line">158</div><div class="line">159</div><div class="line">160</div><div class="line">161</div><div class="line">162</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Hashtable</span>&lt;<span class="title">K</span>,<span class="title">V</span>&gt; <span class="keyword">extends</span> <span class="title">Dictionary</span>&lt;<span class="title">K</span>,<span class="title">V</span>&gt; <span class="keyword">implements</span> <span class="title">Map</span>&lt;<span class="title">K</span>,<span class="title">V</span>&gt;, <span class="title">Cloneable</span>, <span class="title">java</span>.<span class="title">io</span>.<span class="title">Serializable</span> </span>&#123;</div><div class="line"></div><div class="line">    <span class="keyword">private</span> <span class="keyword">transient</span> Entry&lt;K,V&gt;[] table;</div><div class="line"></div><div class="line">    <span class="keyword">private</span> <span class="keyword">transient</span> <span class="keyword">int</span> count;</div><div class="line"></div><div class="line">    <span class="keyword">private</span> <span class="keyword">int</span> threshold;</div><div class="line"></div><div class="line">    <span class="keyword">private</span> <span class="keyword">float</span> loadFactor;</div><div class="line"></div><div class="line">    <span class="keyword">private</span> <span class="keyword">transient</span> <span class="keyword">int</span> modCount = <span class="number">0</span>;</div><div class="line"></div><div class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">long</span> serialVersionUID = <span class="number">1421746759512286392L</span>;</div><div class="line"></div><div class="line">    <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> ALTERNATIVE_HASHING_THRESHOLD_DEFAULT = Integer.MAX_VALUE;</div><div class="line"></div><div class="line">    <span class="comment">// 创建Hashtable</span></div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="title">Hashtable</span><span class="params">(<span class="keyword">int</span> initialCapacity, <span class="keyword">float</span> loadFactor)</span> </span>&#123;</div><div class="line">        <span class="keyword">if</span> (initialCapacity &lt; <span class="number">0</span>)</div><div class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> IllegalArgumentException(<span class="string">"Illegal Capacity: "</span>+ initialCapacity);</div><div class="line">        <span class="keyword">if</span> (loadFactor &lt;= <span class="number">0</span> || Float.isNaN(loadFactor))</div><div class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> IllegalArgumentException(<span class="string">"Illegal Load: "</span>+loadFactor);</div><div class="line">        <span class="keyword">if</span> (initialCapacity==<span class="number">0</span>)</div><div class="line">            initialCapacity = <span class="number">1</span>;</div><div class="line">        <span class="keyword">this</span>.loadFactor = loadFactor;</div><div class="line">        table = <span class="keyword">new</span> Entry[initialCapacity];</div><div class="line">        threshold = (<span class="keyword">int</span>)Math.min(initialCapacity * loadFactor, MAX_ARRAY_SIZE + <span class="number">1</span>);</div><div class="line">        initHashSeedAsNeeded(initialCapacity);</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="title">Hashtable</span><span class="params">(<span class="keyword">int</span> initialCapacity)</span> </span>&#123;</div><div class="line">        <span class="keyword">this</span>(initialCapacity, <span class="number">0.75f</span>);</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="comment">// 默认是11，与有所HashMap不同</span></div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="title">Hashtable</span><span class="params">()</span> </span>&#123;</div><div class="line">        <span class="keyword">this</span>(<span class="number">11</span>, <span class="number">0.75f</span>);</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="comment">// 查看是否包含某个KV对</span></div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">synchronized</span> <span class="keyword">boolean</span> <span class="title">containsKey</span><span class="params">(Object key)</span> </span>&#123;</div><div class="line">        Entry tab[] = table;</div><div class="line">        <span class="keyword">int</span> hash = hash(key);</div><div class="line">        <span class="keyword">int</span> index = (hash &amp; <span class="number">0x7FFFFFFF</span>) % tab.length;</div><div class="line">        <span class="keyword">for</span> (Entry&lt;K,V&gt; e = tab[index] ; e != <span class="keyword">null</span> ; e = e.next) &#123;</div><div class="line">            <span class="keyword">if</span> ((e.hash == hash) &amp;&amp; e.key.equals(key)) &#123;</div><div class="line">                <span class="keyword">return</span> <span class="keyword">true</span>;</div><div class="line">            &#125;</div><div class="line">        &#125;</div><div class="line">        <span class="keyword">return</span> <span class="keyword">false</span>;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="comment">// 根据key查找KV对的value值</span></div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">synchronized</span> V <span class="title">get</span><span class="params">(Object key)</span> </span>&#123;</div><div class="line">        Entry tab[] = table;</div><div class="line">        <span class="keyword">int</span> hash = hash(key);</div><div class="line">        <span class="keyword">int</span> index = (hash &amp; <span class="number">0x7FFFFFFF</span>) % tab.length;</div><div class="line">        <span class="keyword">for</span> (Entry&lt;K,V&gt; e = tab[index] ; e != <span class="keyword">null</span> ; e = e.next) &#123;</div><div class="line">            <span class="keyword">if</span> ((e.hash == hash) &amp;&amp; e.key.equals(key)) &#123;</div><div class="line">                <span class="keyword">return</span> e.value;</div><div class="line">            &#125;</div><div class="line">        &#125;</div><div class="line">        <span class="keyword">return</span> <span class="keyword">null</span>;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="comment">// 能分配的最大数组长度</span></div><div class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> MAX_ARRAY_SIZE = Integer.MAX_VALUE - <span class="number">8</span>;</div><div class="line"></div><div class="line">    <span class="comment">// 增加数组的长度</span></div><div class="line">    <span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">rehash</span><span class="params">()</span> </span>&#123;</div><div class="line">        <span class="keyword">int</span> oldCapacity = table.length;</div><div class="line">        Entry&lt;K,V&gt;[] oldMap = table;</div><div class="line"></div><div class="line">        <span class="comment">// overflow-conscious code</span></div><div class="line">        <span class="keyword">int</span> newCapacity = (oldCapacity &lt;&lt; <span class="number">1</span>) + <span class="number">1</span>;</div><div class="line">        <span class="keyword">if</span> (newCapacity - MAX_ARRAY_SIZE &gt; <span class="number">0</span>) &#123;</div><div class="line">            <span class="keyword">if</span> (oldCapacity == MAX_ARRAY_SIZE)</div><div class="line">                <span class="comment">// Keep running with MAX_ARRAY_SIZE buckets</span></div><div class="line">                <span class="keyword">return</span>;</div><div class="line">            newCapacity = MAX_ARRAY_SIZE;</div><div class="line">        &#125;</div><div class="line">        Entry&lt;K,V&gt;[] newMap = <span class="keyword">new</span> Entry[newCapacity];</div><div class="line"></div><div class="line">        modCount++;</div><div class="line">        threshold = (<span class="keyword">int</span>)Math.min(newCapacity * loadFactor, MAX_ARRAY_SIZE + <span class="number">1</span>);</div><div class="line">        <span class="keyword">boolean</span> rehash = initHashSeedAsNeeded(newCapacity);</div><div class="line"></div><div class="line">        table = newMap;</div><div class="line"></div><div class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = oldCapacity ; i-- &gt; <span class="number">0</span> ;) &#123;</div><div class="line">            <span class="keyword">for</span> (Entry&lt;K,V&gt; old = oldMap[i] ; old != <span class="keyword">null</span> ; ) &#123;</div><div class="line">                Entry&lt;K,V&gt; e = old;</div><div class="line">                old = old.next;</div><div class="line"></div><div class="line">                <span class="keyword">if</span> (rehash) &#123;</div><div class="line">                    e.hash = hash(e.key);</div><div class="line">                &#125;</div><div class="line">                <span class="keyword">int</span> index = (e.hash &amp; <span class="number">0x7FFFFFFF</span>) % newCapacity;</div><div class="line">                e.next = newMap[index];</div><div class="line">                newMap[index] = e;</div><div class="line">            &#125;</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="comment">// 添加元素，与HashMap类似</span></div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">synchronized</span> V <span class="title">put</span><span class="params">(K key, V value)</span> </span>&#123;</div><div class="line">        <span class="comment">// Make sure the value is not null</span></div><div class="line">        <span class="keyword">if</span> (value == <span class="keyword">null</span>) &#123;</div><div class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> NullPointerException();</div><div class="line">        &#125;</div><div class="line"></div><div class="line">        <span class="comment">// Makes sure the key is not already in the hashtable.</span></div><div class="line">        Entry tab[] = table;</div><div class="line">        <span class="keyword">int</span> hash = hash(key);</div><div class="line">        <span class="keyword">int</span> index = (hash &amp; <span class="number">0x7FFFFFFF</span>) % tab.length;</div><div class="line">        <span class="keyword">for</span> (Entry&lt;K,V&gt; e = tab[index] ; e != <span class="keyword">null</span> ; e = e.next) &#123;</div><div class="line">            <span class="keyword">if</span> ((e.hash == hash) &amp;&amp; e.key.equals(key)) &#123;</div><div class="line">                V old = e.value;</div><div class="line">                e.value = value;</div><div class="line">                <span class="keyword">return</span> old;</div><div class="line">            &#125;</div><div class="line">        &#125;</div><div class="line"></div><div class="line">        modCount++;</div><div class="line">        <span class="keyword">if</span> (count &gt;= threshold) &#123;</div><div class="line">            <span class="comment">// Rehash the table if the threshold is exceeded</span></div><div class="line">            rehash();</div><div class="line"></div><div class="line">            tab = table;</div><div class="line">            hash = hash(key);</div><div class="line">            index = (hash &amp; <span class="number">0x7FFFFFFF</span>) % tab.length;</div><div class="line">        &#125;</div><div class="line"></div><div class="line">        <span class="comment">// Creates the new entry.</span></div><div class="line">        Entry&lt;K,V&gt; e = tab[index];</div><div class="line">        tab[index] = <span class="keyword">new</span> Entry&lt;&gt;(hash, key, value, e);</div><div class="line">        count++;</div><div class="line">        <span class="keyword">return</span> <span class="keyword">null</span>;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="comment">// 删除元素，如果该key不存在，则返回null</span></div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">synchronized</span> V <span class="title">remove</span><span class="params">(Object key)</span> </span>&#123;</div><div class="line">        Entry tab[] = table;</div><div class="line">        <span class="keyword">int</span> hash = hash(key);</div><div class="line">        <span class="keyword">int</span> index = (hash &amp; <span class="number">0x7FFFFFFF</span>) % tab.length;</div><div class="line">        <span class="keyword">for</span> (Entry&lt;K,V&gt; e = tab[index], prev = <span class="keyword">null</span> ; e != <span class="keyword">null</span> ; prev = e, e = e.next) &#123;</div><div class="line">            <span class="keyword">if</span> ((e.hash == hash) &amp;&amp; e.key.equals(key)) &#123;</div><div class="line">                modCount++;</div><div class="line">                <span class="keyword">if</span> (prev != <span class="keyword">null</span>) &#123;</div><div class="line">                    prev.next = e.next;</div><div class="line">                &#125; <span class="keyword">else</span> &#123;</div><div class="line">                    tab[index] = e.next;</div><div class="line">                &#125;</div><div class="line">                count--;</div><div class="line">                V oldValue = e.value;</div><div class="line">                e.value = <span class="keyword">null</span>;</div><div class="line">                <span class="keyword">return</span> oldValue;</div><div class="line">            &#125;</div><div class="line">        &#125;</div><div class="line">        <span class="keyword">return</span> <span class="keyword">null</span>;</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<ul>
<li>原理：数组+链表（与HashMap一样）</li>
<li>特点：<ol>
<li>和HashMap一样，Hashtable也是一个基于拉链法实现的散列表，它存储的内容是键值对；</li>
<li>Hashtable继承于Dictionary类，实现了Map, Cloneable, java.io.Serializable接口；</li>
<li>线程安全；</li>
<li>比较老的类，命名也没有遵循现在Java的驼峰法；</li>
<li>Hashtable的key和value都不允许为null；</li>
</ol>
</li>
</ul>
<h2 id="LinkedHashMap"><a href="#LinkedHashMap" class="headerlink" title="LinkedHashMap"></a>LinkedHashMap</h2><p>还是看一下主要的源码，可以参考<a href="https://github.com/fanhongtao/JDK/blob/master/src/java/util/LinkedList.java" target="_blank" rel="external">LinkedList</a>，这里摘取几块重要的部分（并非全部代码）</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">LinkedHashMap</span>&lt;<span class="title">K</span>,<span class="title">V</span>&gt; <span class="keyword">extends</span> <span class="title">HashMap</span>&lt;<span class="title">K</span>,<span class="title">V</span>&gt; <span class="keyword">implements</span> <span class="title">Map</span>&lt;<span class="title">K</span>,<span class="title">V</span>&gt;</span>&#123; <span class="comment">// 继承HashMap</span></div><div class="line"></div><div class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">long</span> serialVersionUID = <span class="number">3801124242820219131L</span>;</div><div class="line"></div><div class="line">    <span class="keyword">private</span> <span class="keyword">transient</span> Entry&lt;K,V&gt; header; <span class="comment">// 头元素</span></div><div class="line"></div><div class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">boolean</span> accessOrder; <span class="comment">// 设置迭代顺序，可以设置插入顺序（false）或者访问顺序（true）</span></div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="title">LinkedHashMap</span><span class="params">(<span class="keyword">int</span> initialCapacity, <span class="keyword">float</span> loadFactor)</span> </span>&#123;</div><div class="line">        <span class="keyword">super</span>(initialCapacity, loadFactor);</div><div class="line">        accessOrder = <span class="keyword">false</span>;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="title">LinkedHashMap</span><span class="params">(<span class="keyword">int</span> initialCapacity)</span> </span>&#123;</div><div class="line">        <span class="keyword">super</span>(initialCapacity);</div><div class="line">        accessOrder = <span class="keyword">false</span>;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="title">LinkedHashMap</span><span class="params">()</span> </span>&#123;</div><div class="line">        <span class="keyword">super</span>();</div><div class="line">        accessOrder = <span class="keyword">false</span>;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="title">LinkedHashMap</span><span class="params">(Map&lt;? extends K, ? extends V&gt; m)</span> </span>&#123;</div><div class="line">        <span class="keyword">super</span>(m);</div><div class="line">        accessOrder = <span class="keyword">false</span>;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="title">LinkedHashMap</span><span class="params">(<span class="keyword">int</span> initialCapacity, <span class="keyword">float</span> loadFactor, <span class="keyword">boolean</span> accessOrder)</span> </span>&#123;</div><div class="line">        <span class="keyword">super</span>(initialCapacity, loadFactor);</div><div class="line">        <span class="keyword">this</span>.accessOrder = accessOrder;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="meta">@Override</span></div><div class="line">    <span class="function"><span class="keyword">void</span> <span class="title">init</span><span class="params">()</span> </span>&#123;</div><div class="line">        header = <span class="keyword">new</span> Entry&lt;&gt;(-<span class="number">1</span>, <span class="keyword">null</span>, <span class="keyword">null</span>, <span class="keyword">null</span>);</div><div class="line">        header.before = header.after = header;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="comment">// 实际上调用HashMap的方法</span></div><div class="line">    <span class="function"><span class="keyword">public</span> V <span class="title">get</span><span class="params">(Object key)</span> </span>&#123;</div><div class="line">        Entry&lt;K,V&gt; e = (Entry&lt;K,V&gt;)getEntry(key);</div><div class="line">        <span class="keyword">if</span> (e == <span class="keyword">null</span>)</div><div class="line">            <span class="keyword">return</span> <span class="keyword">null</span>;</div><div class="line">        e.recordAccess(<span class="keyword">this</span>);</div><div class="line">        <span class="keyword">return</span> e.value;</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>LinkedHashMap的数据的存储方式如下图所示（图片来自<a href="http://www.cnblogs.com/leesf456/p/5248868.html" target="_blank" rel="external">LinkedHashMap</a>）：</p>
<p><img src="/images/java/linkedhashmap.png" alt="LinkedHashMap"></p>
<blockquote>
<p>Note：途中蓝色箭头的指针是<code>Entry</code>对象的<code>next</code>指针，而黑色箭头的指针是双向链表的<code>before</code>和<code>after</code>指针。</p>
</blockquote>
<ul>
<li>原理：数组+双向链表（有before、after两个指针，所以可以保留插入或访问顺序）</li>
<li>特点：<ol>
<li>LinkedHashMap是HashMap的一个子类，它<strong>保留插入的顺序</strong>， 如果需要输出的顺序和输入时的相同，那么就选用LinkedHashMap；</li>
<li>LinkedHashMap实现与HashMap的不同之处在于，LinkedHashMap维护着一个运行于所有条目的<strong>双向链接列表</strong>。此链接列表定义了迭代顺序，该迭代顺序可以是插入顺序或者是访问顺序；</li>
<li>非同步的。如果多个线程同时访问链接的哈希映射，而其中至少一个线程从结构上修改了该映射，则它必须保持外部同步；</li>
<li>根据链表中元素的顺序可以分为：按插入顺序的链表，和按访问顺序(调用get方法)的链表。默认是按插入顺序排序；</li>
<li>如果指定按访问顺序排序，那么调用get方法后，会将这次访问的元素移至链表尾部，不断访问可以形成按访问顺序排序的链表；</li>
<li>底层使用哈希表与双向链表来保存所有元素。其基本操作与父类HashMap相似，它通过重写父类相关的方法，来实现自己的链接列表特性；</li>
<li>LinkedHashMap定义了排序模式accessOrder，该属性为boolean型变量，对于访问顺序，为true；对于插入顺序，则为false。一般情况下，不必指定排序模式，其迭代顺序即为默认为插入顺序；</li>
<li>LinkedHashMap通过继承hashMap中的Entry,并添加两个属性Entry before,after,和header结合起来组成一个双向链表，来实现按插入顺序或访问顺序排序；</li>
<li>允许使用null值和null键；</li>
</ol>
</li>
</ul>
<p>关于迭代顺序可以参考<a href="https://github.com/wangzzu/java_learn/blob/master/java_thinking/src/javabasic/collection/map/LinkedHashMapTest.java" target="_blank" rel="external">测试代码</a></p>
<h2 id="ConcurrentHashMap"><a href="#ConcurrentHashMap" class="headerlink" title="ConcurrentHashMap"></a>ConcurrentHashMap</h2><p>对于线程安全的情况，在不考虑性能问题的时候，我们的解决方案有Hashtable或者Collections.synchronizedMap(hashMap)，这两种方式基本都是对整个hash表结构做锁定操作的，这样在锁表的期间，别的线程就需要等待了，无疑性能不高。 但是Java为我们提供了封装好的线程安全的集合类，这些类在<code>java.util.concurrent</code>包内，这里我们介绍一个常用的map子类——ConcurrentHashMap。</p>
<p>源码，可以参考<a href="https://github.com/fanhongtao/JDK/blob/master/src/java/util/concurrent/ConcurrentHashMap.java" target="_blank" rel="external">ConcurrentHashMap</a>，这里就不再介绍 ConcurrentHashMap的源码了。</p>
<p>先看一下ConcurrentHashMap的结构，如下图所示</p>
<p><img src="/images/java/concurrenthashmap.png" alt="concurrenthashmap"></p>
<p>在ConcurrentHashMap内有几个重要的内部类分别是：</p>
<ol>
<li><code>HashEntry</code>类：用来封装散列映射表中的键值对，HashEntry的学习可以类比着 HashMap中的Entry。我们的存储键值对的过程中，散列的时候如果发生“碰撞”，将采用<strong>拉链法</strong>来处理碰撞：把碰撞的 HashEntry 对象链接成一个链表；</li>
<li><code>Segment</code>类：Segment 的类定义为<code>static final class Segment&lt;K,V&gt; extends ReentrantLock implements Serializable</code>，其继承于 ReentrantLock类，从而使得 Segment对象可以充当锁的角色。Segment中包含HashEntry的数组，其可以守护其包含的若干个桶（HashEntry的数组）。Segment 在某些意义上有点类似于 HashMap了，都是包含了一个数组，而数组中的元素可以是一个链表。</li>
</ol>
<ul>
<li>原理：数组+链表，每个数组元素是一个类似于HashMap结构的segment，每个segment又是一个数组和链表的形式，这样在对某个segment操作时，就可以锁住该segment，不影响对其他segment的操作。</li>
<li>特点：<ol>
<li>ConcurrentHashMap的实现是依赖于Java内存模型；</li>
<li>本质也是数组和链表，ConcurrentHashMap数据结构为一个Segment数组，Segment的数据结构为HashEntry的数组，而HashEntry存的是我们的键值对，可以构成链表，默认的Segment是16个，通过key的hash值与16取余确定在哪个桶。</li>
<li>ConcurrentHashMap的结构中包含的Segment的数组，在默认的并发级别会创建包含16个Segment对象的数组。</li>
<li>执行put方法的时候，会需要<strong>加锁</strong>来完成，在put操作时锁定的是一个Segment而不是整个ConcurrentHashMap。</li>
<li>ConcurrentHashMap不允许空值。该方法首先有一个Segment的引用s，然后会通过hash()方法对key进行计算，得到哈希值；继而通过调用Segment的put(K key, int hash, V value, boolean onlyIfAbsent)方法进行存储操作。</li>
<li>在理想状态下，ConcurrentHashMap 可以支持 16 个线程执行并发写操作（如果并发级别设置为 16），及任意数量线程的读操作。</li>
</ol>
</li>
</ul>
<p>ConcurrentHashMap 的高并发性主要来自于三个方面：</p>
<ol>
<li>用分离锁实现多个线程间的更深层次的共享访问。</li>
<li>用 HashEntery 对象的不变性来降低执行读操作的线程在遍历链表期间对加锁的需求。</li>
<li>通过对同一个 Volatile 变量的写 / 读访问，协调不同线程间读 / 写操作的内存可见性。</li>
</ol>
<h2 id="TreeMap"><a href="#TreeMap" class="headerlink" title="TreeMap"></a>TreeMap</h2><p>还是看一下主要的源码，可以参考<a href="https://github.com/fanhongtao/JDK/blob/master/src/java/util/TreeMap.java" target="_blank" rel="external">TreeMap</a>，这里摘取几块重要的部分（并非全部代码）</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div><div class="line">113</div><div class="line">114</div><div class="line">115</div><div class="line">116</div><div class="line">117</div><div class="line">118</div><div class="line">119</div><div class="line">120</div><div class="line">121</div><div class="line">122</div><div class="line">123</div><div class="line">124</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">TreeMap</span>&lt;<span class="title">K</span>,<span class="title">V</span>&gt; <span class="keyword">extends</span> <span class="title">AbstractMap</span>&lt;<span class="title">K</span>,<span class="title">V</span>&gt; <span class="keyword">implements</span> <span class="title">NavigableMap</span>&lt;<span class="title">K</span>,<span class="title">V</span>&gt;, <span class="title">Cloneable</span>, <span class="title">java</span>.<span class="title">io</span>.<span class="title">Serializable</span></span>&#123;</div><div class="line"></div><div class="line">    <span class="keyword">private</span> <span class="keyword">final</span> Comparator&lt;? <span class="keyword">super</span> K&gt; comparator; <span class="comment">// 比较器，不设置时使用key的自然顺序</span></div><div class="line"></div><div class="line">    <span class="keyword">private</span> <span class="keyword">transient</span> Entry&lt;K,V&gt; root = <span class="keyword">null</span>;</div><div class="line"></div><div class="line">    <span class="keyword">private</span> <span class="keyword">transient</span> <span class="keyword">int</span> size = <span class="number">0</span>;</div><div class="line"></div><div class="line">    <span class="keyword">private</span> <span class="keyword">transient</span> <span class="keyword">int</span> modCount = <span class="number">0</span>;</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="title">TreeMap</span><span class="params">()</span> </span>&#123;</div><div class="line">        comparator = <span class="keyword">null</span>;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="comment">// 这里可以设置比较器</span></div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="title">TreeMap</span><span class="params">(Comparator&lt;? <span class="keyword">super</span> K&gt; comparator)</span> </span>&#123;</div><div class="line">        <span class="keyword">this</span>.comparator = comparator;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="title">TreeMap</span><span class="params">(Map&lt;? extends K, ? extends V&gt; m)</span> </span>&#123;</div><div class="line">        comparator = <span class="keyword">null</span>;</div><div class="line">        putAll(m);</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="title">TreeMap</span><span class="params">(SortedMap&lt;K, ? extends V&gt; m)</span> </span>&#123;</div><div class="line">        comparator = m.comparator();</div><div class="line">        <span class="keyword">try</span> &#123;</div><div class="line">            buildFromSorted(m.size(), m.entrySet().iterator(), <span class="keyword">null</span>, <span class="keyword">null</span>);</div><div class="line">        &#125; <span class="keyword">catch</span> (java.io.IOException cannotHappen) &#123;</div><div class="line">        &#125; <span class="keyword">catch</span> (ClassNotFoundException cannotHappen) &#123;</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="comment">// 插入方法，这个是红黑树中非常重要的方法，根据定制的比较器将插入的元素放在合适的位置</span></div><div class="line">    <span class="function"><span class="keyword">public</span> V <span class="title">put</span><span class="params">(K key, V value)</span> </span>&#123;</div><div class="line">        Entry&lt;K,V&gt; t = root;</div><div class="line">        <span class="keyword">if</span> (t == <span class="keyword">null</span>) &#123;</div><div class="line">            compare(key, key); <span class="comment">// type (and possibly null) check</span></div><div class="line"></div><div class="line">            root = <span class="keyword">new</span> Entry&lt;&gt;(key, value, <span class="keyword">null</span>);</div><div class="line">            size = <span class="number">1</span>;</div><div class="line">            modCount++;</div><div class="line">            <span class="keyword">return</span> <span class="keyword">null</span>;</div><div class="line">        &#125;</div><div class="line">        <span class="keyword">int</span> cmp;</div><div class="line">        Entry&lt;K,V&gt; parent;</div><div class="line">        <span class="comment">// split comparator and comparable paths</span></div><div class="line">        Comparator&lt;? <span class="keyword">super</span> K&gt; cpr = comparator;</div><div class="line">        <span class="keyword">if</span> (cpr != <span class="keyword">null</span>) &#123;</div><div class="line">            <span class="keyword">do</span> &#123;</div><div class="line">                parent = t;</div><div class="line">                cmp = cpr.compare(key, t.key);</div><div class="line">                <span class="keyword">if</span> (cmp &lt; <span class="number">0</span>)</div><div class="line">                    t = t.left;</div><div class="line">                <span class="keyword">else</span> <span class="keyword">if</span> (cmp &gt; <span class="number">0</span>)</div><div class="line">                    t = t.right;</div><div class="line">                <span class="keyword">else</span></div><div class="line">                    <span class="keyword">return</span> t.setValue(value);</div><div class="line">            &#125; <span class="keyword">while</span> (t != <span class="keyword">null</span>);</div><div class="line">        &#125;</div><div class="line">        <span class="keyword">else</span> &#123;</div><div class="line">            <span class="keyword">if</span> (key == <span class="keyword">null</span>)</div><div class="line">                <span class="keyword">throw</span> <span class="keyword">new</span> NullPointerException();</div><div class="line">            Comparable&lt;? <span class="keyword">super</span> K&gt; k = (Comparable&lt;? <span class="keyword">super</span> K&gt;) key;</div><div class="line">            <span class="keyword">do</span> &#123;</div><div class="line">                parent = t;</div><div class="line">                cmp = k.compareTo(t.key);</div><div class="line">                <span class="keyword">if</span> (cmp &lt; <span class="number">0</span>)</div><div class="line">                    t = t.left;</div><div class="line">                <span class="keyword">else</span> <span class="keyword">if</span> (cmp &gt; <span class="number">0</span>)</div><div class="line">                    t = t.right;</div><div class="line">                <span class="keyword">else</span></div><div class="line">                    <span class="keyword">return</span> t.setValue(value);</div><div class="line">            &#125; <span class="keyword">while</span> (t != <span class="keyword">null</span>);</div><div class="line">        &#125;</div><div class="line">        Entry&lt;K,V&gt; e = <span class="keyword">new</span> Entry&lt;&gt;(key, value, parent);</div><div class="line">        <span class="keyword">if</span> (cmp &lt; <span class="number">0</span>)</div><div class="line">            parent.left = e;</div><div class="line">        <span class="keyword">else</span></div><div class="line">            parent.right = e;</div><div class="line">        fixAfterInsertion(e);</div><div class="line">        size++;</div><div class="line">        modCount++;</div><div class="line">        <span class="keyword">return</span> <span class="keyword">null</span>;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="comment">// 删除KV对</span></div><div class="line">    <span class="function"><span class="keyword">public</span> V <span class="title">remove</span><span class="params">(Object key)</span> </span>&#123;</div><div class="line">        Entry&lt;K,V&gt; p = getEntry(key);</div><div class="line">        <span class="keyword">if</span> (p == <span class="keyword">null</span>)</div><div class="line">            <span class="keyword">return</span> <span class="keyword">null</span>;</div><div class="line"></div><div class="line">        V oldValue = p.value;</div><div class="line">        deleteEntry(p);</div><div class="line">        <span class="keyword">return</span> oldValue;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="comment">// 根据key找到对应的Entry对象，熟悉二叉树的人应该很熟悉这里的结构</span></div><div class="line">    <span class="function"><span class="keyword">final</span> Entry&lt;K,V&gt; <span class="title">getEntry</span><span class="params">(Object key)</span> </span>&#123;</div><div class="line">        <span class="comment">// Offload comparator-based version for sake of performance</span></div><div class="line">        <span class="keyword">if</span> (comparator != <span class="keyword">null</span>)</div><div class="line">            <span class="keyword">return</span> getEntryUsingComparator(key);</div><div class="line">        <span class="keyword">if</span> (key == <span class="keyword">null</span>)</div><div class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> NullPointerException();</div><div class="line">        Comparable&lt;? <span class="keyword">super</span> K&gt; k = (Comparable&lt;? <span class="keyword">super</span> K&gt;) key;</div><div class="line">        Entry&lt;K,V&gt; p = root;</div><div class="line">        <span class="keyword">while</span> (p != <span class="keyword">null</span>) &#123;</div><div class="line">            <span class="keyword">int</span> cmp = k.compareTo(p.key);</div><div class="line">            <span class="keyword">if</span> (cmp &lt; <span class="number">0</span>)</div><div class="line">                p = p.left;</div><div class="line">            <span class="keyword">else</span> <span class="keyword">if</span> (cmp &gt; <span class="number">0</span>)</div><div class="line">                p = p.right;</div><div class="line">            <span class="keyword">else</span></div><div class="line">                <span class="keyword">return</span> p;</div><div class="line">        &#125;</div><div class="line">        <span class="keyword">return</span> <span class="keyword">null</span>;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="comment">// 很多话方法都会调用这个比较方法（这个方法设置为了final，是不允许修改的）</span></div><div class="line">    <span class="function"><span class="keyword">final</span> <span class="keyword">int</span> <span class="title">compare</span><span class="params">(Object k1, Object k2)</span> </span>&#123;</div><div class="line">        <span class="keyword">return</span> comparator==<span class="keyword">null</span> ? ((Comparable&lt;? <span class="keyword">super</span> K&gt;)k1).compareTo((K)k2)</div><div class="line">            : comparator.compare((K)k1, (K)k2);</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<ul>
<li>原理：TreeMap基于红黑树（Red-Black tree）实现。该映射根据其键的自然顺序进行排序，或者根据创建映射时提供的 Comparator 进行排序，具体取决于使用的构造方法。</li>
<li>特点：<ol>
<li>TreeMap 是一个有序的key-value集合，它是通过红黑树实现的；</li>
<li>TreeMap 继承于AbstractMap，所以它是一个Map，即一个key-value集合；</li>
<li>TreeMap 实现了NavigableMap接口，意味着它支持一系列的导航方法。比如返回有序的key集合；</li>
<li>TreeMap 实现了Cloneable接口，意味着它能被克隆；</li>
<li>TreeMap 实现了java.io.Serializable接口，意味着它支持序列化；</li>
<li>TreeMap是非同步的。 它的iterator 方法返回的迭代器是fail-fastl的；</li>
<li>可以重写<code>comparable</code>。</li>
</ol>
</li>
<li>性能：<ol>
<li>因为底层是使用红黑树保存集合中的Entry对象，这也就意味着TreeMap对于添加元素、取出元素的性能要比HashMap低。当TreeMap添加元素时，需要通过循环找到新增Entry的插入位置，因此比较耗性能；当从TreeMap中取出元素时，需要通过循环才能找到合适的Entry，也比较耗性能；</li>
<li>TreeMap的优势在于：TreeMap中的所有Entry都是按key根据指定排序规则（可以根据重写的<code>comparable</code>定制排序规则）操持有序状态。</li>
</ol>
</li>
</ul>
<p>这里我做了一个测试，使用TreeMapTest（及其自定义排序形式）与HashMap做一下对比（<a href="https://github.com/wangzzu/java_learn/blob/master/java_thinking/src/javabasic/collection/map/TreeMapTest.java" target="_blank" rel="external">测试代码</a>）</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> java.util.Comparator;</div><div class="line"><span class="keyword">import</span> java.util.HashMap;</div><div class="line"><span class="keyword">import</span> java.util.Iterator;</div><div class="line"><span class="keyword">import</span> java.util.Map;</div><div class="line"><span class="keyword">import</span> java.util.TreeMap;</div><div class="line"></div><div class="line"><span class="comment">/**</span></div><div class="line"> * Created by matt on 5/13/16.</div><div class="line"> */</div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">TreeMapTest</span> </span>&#123;</div><div class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</div><div class="line">		TreeMap&lt;String, String&gt; treeMap = <span class="keyword">new</span> TreeMap&lt;&gt;();</div><div class="line">		HashMap&lt;String, String&gt; hashMap = <span class="keyword">new</span> HashMap&lt;&gt;();</div><div class="line"></div><div class="line">		treeMap.put(<span class="string">"a"</span>, <span class="string">"wm0"</span>);</div><div class="line">		treeMap.put(<span class="string">"b"</span>, <span class="string">"wm1"</span>);</div><div class="line">		treeMap.put(<span class="string">"c"</span>, <span class="string">"wm2"</span>);</div><div class="line">		treeMap.put(<span class="string">"d"</span>, <span class="string">"wm3"</span>);</div><div class="line">		Iterator tree = treeMap.keySet().iterator();</div><div class="line">		System.out.println(<span class="string">"TreeMap:"</span>);</div><div class="line">		<span class="keyword">while</span> (tree.hasNext()) &#123;</div><div class="line">			Object key = tree.next();</div><div class="line">			System.out.println(key.toString() + <span class="string">" "</span> + treeMap.get(key));</div><div class="line">		&#125;</div><div class="line"></div><div class="line"></div><div class="line">		TreeMap&lt;String,String&gt; treeMap1 = <span class="keyword">new</span> TreeMap&lt;String,String&gt;(<span class="keyword">new</span> Comparator()&#123;</div><div class="line">			<span class="meta">@Override</span></div><div class="line">			<span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">compare</span><span class="params">(Object o1, Object o2)</span> </span>&#123;</div><div class="line">				<span class="comment">// TODO Auto-generated method stub</span></div><div class="line">				String a = (String)o1;</div><div class="line">				String b = (String)o2;</div><div class="line">				<span class="keyword">return</span> -a.compareTo(b);</div><div class="line">			&#125;&#125;);</div><div class="line">		treeMap1.put(<span class="string">"a"</span>, <span class="string">"wm0"</span>);</div><div class="line">		treeMap1.put(<span class="string">"b"</span>, <span class="string">"wm1"</span>);</div><div class="line">		treeMap1.put(<span class="string">"c"</span>, <span class="string">"wm2"</span>);</div><div class="line">		treeMap1.put(<span class="string">"d"</span>, <span class="string">"wm3"</span>);</div><div class="line">		Iterator tree1 = treeMap1.keySet().iterator();</div><div class="line">		System.out.println(<span class="string">"\nTreeMap（根据value排序）:"</span>);</div><div class="line">		<span class="keyword">while</span> (tree1.hasNext()) &#123;</div><div class="line">			Object key = tree1.next();</div><div class="line">			System.out.println(key.toString() + <span class="string">" "</span> + treeMap1.get(key));</div><div class="line">		&#125;</div><div class="line"></div><div class="line">		hashMap.put(<span class="string">"a"</span>, <span class="string">"wm0"</span>);</div><div class="line">		hashMap.put(<span class="string">"b"</span>, <span class="string">"wm1"</span>);</div><div class="line">		hashMap.put(<span class="string">"c"</span>, <span class="string">"wm2"</span>);</div><div class="line">		hashMap.put(<span class="string">"d"</span>, <span class="string">"wm3"</span>);</div><div class="line">		Iterator hash = hashMap.keySet().iterator();</div><div class="line">		System.out.println(<span class="string">"\nHashMap:"</span>);</div><div class="line">		<span class="keyword">while</span> (hash.hasNext()) &#123;</div><div class="line">			Object key = hash.next();</div><div class="line">			System.out.println(key.toString() + <span class="string">" "</span> + hashMap.get(key));</div><div class="line">		&#125;</div><div class="line">	&#125;</div><div class="line">&#125;</div><div class="line"></div><div class="line"></div><div class="line"><span class="comment">/**</span></div><div class="line">* Output:</div><div class="line">* TreeMap:</div><div class="line">* a wm0</div><div class="line">* b wm1</div><div class="line">* c wm2</div><div class="line">* d wm3</div><div class="line">*</div><div class="line">* TreeMap（根据value排序）:</div><div class="line">* d wm3</div><div class="line">* c wm2</div><div class="line">* b wm1</div><div class="line">* a wm0</div><div class="line">*</div><div class="line">* HashMap:</div><div class="line">* d wm3</div><div class="line">* b wm1</div><div class="line">* c wm2</div><div class="line">* a wm0</div><div class="line">*/</div></pre></td></tr></table></figure>
<h1 id="Set"><a href="#Set" class="headerlink" title="Set"></a>Set</h1><p>下面开始介绍Set了，Set是不保存重复元素的集合。当保存对象引用，一般情况下，对象需要重写<code>equals()</code>和<code>hashCode()</code>方法，不重写的话，就会使用对应Map（HashMap，TreeMap）的判断方法。</p>
<p>因为Set集合类的底层实现大都与前面的类似，所以下面会介绍稍微简洁一些。</p>
<h2 id="HashSet"><a href="#HashSet" class="headerlink" title="HashSet"></a>HashSet</h2><p>先介绍一下HashSet，还是看一下主要的源码，可以参考<a href="https://github.com/fanhongtao/JDK/blob/master/src/java/util/HashSet.java" target="_blank" rel="external">HashSet</a>，这里摘取几块重要的部分（并非全部代码）</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">HashSet</span>&lt;<span class="title">E</span>&gt; <span class="keyword">extends</span> <span class="title">AbstractSet</span>&lt;<span class="title">E</span>&gt; <span class="keyword">implements</span> <span class="title">Set</span>&lt;<span class="title">E</span>&gt;, <span class="title">Cloneable</span>, <span class="title">java</span>.<span class="title">io</span>.<span class="title">Serializable</span></span>&#123;</div><div class="line"></div><div class="line">    <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">long</span> serialVersionUID = -<span class="number">5024744406713321676L</span>;</div><div class="line"></div><div class="line">    <span class="keyword">private</span> <span class="keyword">transient</span> HashMap&lt;E,Object&gt; map; <span class="comment">// 使用HashMap实现</span></div><div class="line"></div><div class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> Object PRESENT = <span class="keyword">new</span> Object(); <span class="comment">// map中默认的value值</span></div><div class="line"></div><div class="line">    <span class="comment">// 构造方法都是借助与HashMap实现</span></div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="title">HashSet</span><span class="params">()</span> </span>&#123;</div><div class="line">        map = <span class="keyword">new</span> HashMap&lt;&gt;();</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="title">HashSet</span><span class="params">(Collection&lt;? extends E&gt; c)</span> </span>&#123;</div><div class="line">        map = <span class="keyword">new</span> HashMap&lt;&gt;(Math.max((<span class="keyword">int</span>) (c.size()/.<span class="number">75f</span>) + <span class="number">1</span>, <span class="number">16</span>));</div><div class="line">        addAll(c);</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="title">HashSet</span><span class="params">(<span class="keyword">int</span> initialCapacity, <span class="keyword">float</span> loadFactor)</span> </span>&#123;</div><div class="line">        map = <span class="keyword">new</span> HashMap&lt;&gt;(initialCapacity, loadFactor);</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="title">HashSet</span><span class="params">(<span class="keyword">int</span> initialCapacity)</span> </span>&#123;</div><div class="line">        map = <span class="keyword">new</span> HashMap&lt;&gt;(initialCapacity);</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="comment">// 感觉这个应该是老方法，构造对象时是无法使用这个方法的</span></div><div class="line">    HashSet(<span class="keyword">int</span> initialCapacity, <span class="keyword">float</span> loadFactor, <span class="keyword">boolean</span> dummy) &#123;</div><div class="line">        map = <span class="keyword">new</span> LinkedHashMap&lt;&gt;(initialCapacity, loadFactor);</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="comment">// 添加元素，这个方法本质上还是调用了HashMap的方法</span></div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">add</span><span class="params">(E e)</span> </span>&#123;</div><div class="line">        <span class="keyword">return</span> map.put(e, PRESENT)==<span class="keyword">null</span>;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="comment">// 删除元素</span></div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">remove</span><span class="params">(Object o)</span> </span>&#123;</div><div class="line">        <span class="keyword">return</span> map.remove(o)==PRESENT;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">contains</span><span class="params">(Object o)</span> </span>&#123;</div><div class="line">        <span class="keyword">return</span> map.containsKey(o);</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>从上面的源码中，我们可以看到，HashSet的实现其实非常简单，他只是封装了一个HashMap对象来存储所有的集合元素。所有放入HashSet中的集合元素实际上由HashMap的key来保存，而HashMap的value则存储了一个<code>PRESENT</code>，它是一个静态的Object对象。</p>
<ul>
<li>原理：HashSet底层使用HashMap来保存所有元素（value出存储了一个静态的Object对象）。</li>
<li>特点：<ol>
<li>HashSet实现了Set接口，它不允许集合中有重复的值;</li>
<li>HashSet的随机读取和写入还是很快的，同样也会出现与HashMap一样的问题，即有可能出现数据不均匀的情况；</li>
<li>重写<code>equals()</code>和<code>hashCode()</code>方法，这样才能比较对象的值是否相等，以确保set中没有储存相等的对象;</li>
<li>当向Set添加元素时，如果与Set中的某一个元素比较时，当<code>equals()</code>比较返回true和<code>hashCode()</code>的返回值相等时，此时，元素就会添加失败（并不会覆盖Set中的元素，因为在HashMap中，遇到这种情况，只是覆盖value，不会覆盖key，而HashSet是基于HashMap实现的，所以元素也并不会被覆盖，只是会添加失败）；</li>
</ol>
</li>
</ul>
<p>下面我们看一个三个测试用例，来说明使用HashSet存储对象引用时，重写<code>equals()</code>和<code>hashCode()</code>方法的重要性。</p>
<p>Test1：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Person</span> </span>&#123;</div><div class="line">	<span class="keyword">private</span> String name;</div><div class="line">	<span class="keyword">private</span> <span class="keyword">int</span> age;</div><div class="line">	<span class="function"><span class="keyword">public</span> <span class="title">Person</span><span class="params">(String name, <span class="keyword">int</span> age)</span></span>&#123;</div><div class="line">		<span class="keyword">this</span>.name=name;</div><div class="line">		<span class="keyword">this</span>.age=age;</div><div class="line">	&#125;</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">HashSetTest</span> </span>&#123;</div><div class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</div><div class="line">		HashSet&lt;Person&gt; set=<span class="keyword">new</span> HashSet&lt;&gt;();</div><div class="line">		set.add(<span class="keyword">new</span> Person(<span class="string">"wm"</span>,<span class="number">12</span>));</div><div class="line">		System.out.println(set.contains(<span class="keyword">new</span> Person(<span class="string">"wm"</span>,<span class="number">123</span>)));</div><div class="line">	&#125;</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="comment">/**</span></div><div class="line">* Output: false</div><div class="line">*/</div></pre></td></tr></table></figure>
<p>Test2：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Person</span> </span>&#123;</div><div class="line">	<span class="keyword">private</span> String name;</div><div class="line">	<span class="keyword">private</span> <span class="keyword">int</span> age;</div><div class="line">	<span class="function"><span class="keyword">public</span> <span class="title">Person</span><span class="params">(String name, <span class="keyword">int</span> age)</span></span>&#123;</div><div class="line">		<span class="keyword">this</span>.name=name;</div><div class="line">		<span class="keyword">this</span>.age=age;</div><div class="line">	&#125;</div><div class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">equals</span><span class="params">(Object o)</span> </span>&#123;</div><div class="line">		<span class="keyword">if</span> (<span class="keyword">this</span> == o) &#123;</div><div class="line">			<span class="keyword">return</span> <span class="keyword">true</span>;</div><div class="line">		&#125;</div><div class="line">		<span class="keyword">if</span> (o.getClass() == Person.class) &#123;</div><div class="line">			Person per = (Person) o;</div><div class="line">			<span class="keyword">return</span> <span class="keyword">this</span>.age == per.age &amp;&amp; <span class="keyword">this</span>.name.equals(per.name);</div><div class="line">		&#125;</div><div class="line">		<span class="keyword">return</span> <span class="keyword">false</span>;</div><div class="line">	&#125;</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">HashSetTest</span> </span>&#123;</div><div class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</div><div class="line">		HashSet&lt;Person&gt; set=<span class="keyword">new</span> HashSet&lt;&gt;();</div><div class="line">		set.add(<span class="keyword">new</span> Person(<span class="string">"wm"</span>,<span class="number">12</span>));</div><div class="line">		System.out.println(set.contains(<span class="keyword">new</span> Person(<span class="string">"wm"</span>,<span class="number">123</span>)));</div><div class="line">	&#125;</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="comment">/**</span></div><div class="line">* 因为两个对象的hash值不同，这样就会当作两个对象来处理。</div><div class="line">* Output: false</div><div class="line">*/</div></pre></td></tr></table></figure>
<p>Test3：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Person</span> </span>&#123;</div><div class="line">	<span class="keyword">private</span> String name;</div><div class="line">	<span class="keyword">private</span> <span class="keyword">int</span> age;</div><div class="line"></div><div class="line">	<span class="function"><span class="keyword">public</span> <span class="title">Person</span><span class="params">(String name, <span class="keyword">int</span> age)</span> </span>&#123;</div><div class="line">		<span class="keyword">this</span>.name = name;</div><div class="line">		<span class="keyword">this</span>.age = age;</div><div class="line">	&#125;</div><div class="line"></div><div class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">equals</span><span class="params">(Object o)</span> </span>&#123;</div><div class="line">		<span class="keyword">if</span> (<span class="keyword">this</span> == o) &#123;</div><div class="line">			<span class="keyword">return</span> <span class="keyword">true</span>;</div><div class="line">		&#125;</div><div class="line">		<span class="keyword">if</span> (o.getClass() == Person.class) &#123;</div><div class="line">			Person per = (Person) o;</div><div class="line">			<span class="keyword">return</span> <span class="keyword">this</span>.name.equals(per.name);</div><div class="line">		&#125;</div><div class="line">		<span class="keyword">return</span> <span class="keyword">false</span>;</div><div class="line">	&#125;</div><div class="line"></div><div class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">hashCode</span><span class="params">()</span></span>&#123;</div><div class="line">		<span class="keyword">return</span> name.hashCode();</div><div class="line">	&#125;</div><div class="line">&#125;</div><div class="line"></div><div class="line"></div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">HashSetTest</span> </span>&#123;</div><div class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</div><div class="line">		HashSet&lt;Person&gt; set=<span class="keyword">new</span> HashSet&lt;&gt;();</div><div class="line">		set.add(<span class="keyword">new</span> Person(<span class="string">"wm"</span>,<span class="number">12</span>));</div><div class="line">		System.out.println(set.contains(<span class="keyword">new</span> Person(<span class="string">"wm"</span>,<span class="number">123</span>)));</div><div class="line">	&#125;</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="comment">/**</span></div><div class="line">* 重写的equals和hashCode方法的返回值必须保持一致，当两个类的hashCode()返回值相同时，</div><div class="line">* 它们通过equals()方法的比较也应该相同。</div><div class="line">* Output: true</div><div class="line">*/</div></pre></td></tr></table></figure>
<h2 id="LinkedHashSet"><a href="#LinkedHashSet" class="headerlink" title="LinkedHashSet"></a>LinkedHashSet</h2><p>还是先看一下主要的源码，可以参考<a href="https://github.com/fanhongtao/JDK/blob/master/src/java/util/LinkedHashSet.java" target="_blank" rel="external">LinkedHashSet</a>，这里摘取几块重要的部分（并非全部代码）</p>
<p>对于 LinkedHashSet 而言，它继承与 HashSet、又基于 LinkedHashMap 来实现的。</p>
<p>LinkedHashSet 底层使用 LinkedHashMap 来保存所有元素，它继承与 HashSet，其所有的方法操作上又与 HashSet 相同，因此 LinkedHashSet 的实现上非常简单，只提供了四个构造方法，并通过传递一个标识参数，调用父类的构造器，底层构造一个 LinkedHashMap 来实现，在相关操作上与父类 HashSet 的操作相同，直接调用父类 HashSet 的方法即可。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">LinkedHashSet</span>&lt;<span class="title">E</span>&gt; <span class="keyword">extends</span> <span class="title">HashSet</span>&lt;<span class="title">E</span>&gt; <span class="keyword">implements</span> <span class="title">Set</span>&lt;<span class="title">E</span>&gt;, <span class="title">Cloneable</span>, <span class="title">java</span>.<span class="title">io</span>.<span class="title">Serializable</span> </span>&#123;</div><div class="line"></div><div class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">long</span> serialVersionUID = -<span class="number">2851667679971038690L</span>;</div><div class="line"></div><div class="line">    <span class="comment">// 实际上是调用了HashSet中的default方法（该方法只能在包内或同一个文件内部调用），实际使用LinkedHashMap实现</span></div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="title">LinkedHashSet</span><span class="params">(<span class="keyword">int</span> initialCapacity, <span class="keyword">float</span> loadFactor)</span> </span>&#123;</div><div class="line">        <span class="keyword">super</span>(initialCapacity, loadFactor, <span class="keyword">true</span>);</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="title">LinkedHashSet</span><span class="params">(<span class="keyword">int</span> initialCapacity)</span> </span>&#123;</div><div class="line">        <span class="keyword">super</span>(initialCapacity, .<span class="number">75f</span>, <span class="keyword">true</span>);</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="title">LinkedHashSet</span><span class="params">()</span> </span>&#123;</div><div class="line">        <span class="keyword">super</span>(<span class="number">16</span>, .<span class="number">75f</span>, <span class="keyword">true</span>);</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="title">LinkedHashSet</span><span class="params">(Collection&lt;? extends E&gt; c)</span> </span>&#123;</div><div class="line">        <span class="keyword">super</span>(Math.max(<span class="number">2</span>*c.size(), <span class="number">11</span>), .<span class="number">75f</span>, <span class="keyword">true</span>);</div><div class="line">        addAll(c);</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<ul>
<li>原理：继承于HashSet、又基于LinkedHashMap来实现。</li>
<li>特点：<ol>
<li>是一个Set的实现，所以它其中存的肯定不是键值对，而是值；</li>
<li>与HashSet的不同之处在于，LinkedHashSet维护着一个运行于所有条目的双向链接列表。 此链接列表定义了迭代顺序，该迭代顺序可为插入顺序或是访问顺序；</li>
<li>非同步。如果多个线程同时访问链接的哈希Set，而其中至少一个线程修改了该Set，则它必须保持外部同步；</li>
<li>继承于HashSet、又基于LinkedHashMap（父类HashSet实现时专门为其提供了一个LinkedHashMap的构造方法）来实现的。</li>
</ol>
</li>
</ul>
<h2 id="TreeSet"><a href="#TreeSet" class="headerlink" title="TreeSet"></a>TreeSet</h2><p>TreeSet源码，可以参考<a href="https://github.com/fanhongtao/JDK/blob/master/src/java/util/TreeSet.java" target="_blank" rel="external">TreeSet</a></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">TreeSet</span>&lt;<span class="title">E</span>&gt; <span class="keyword">extends</span> <span class="title">AbstractSet</span>&lt;<span class="title">E</span>&gt; <span class="keyword">implements</span> <span class="title">NavigableSet</span>&lt;<span class="title">E</span>&gt;, <span class="title">Cloneable</span>, <span class="title">java</span>.<span class="title">io</span>.<span class="title">Serializable</span></span>&#123;</div><div class="line"></div><div class="line">    <span class="keyword">private</span> <span class="keyword">transient</span> NavigableMap&lt;E,Object&gt; m;</div><div class="line"></div><div class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> Object PRESENT = <span class="keyword">new</span> Object();</div><div class="line"></div><div class="line">    TreeSet(NavigableMap&lt;E,Object&gt; m) &#123;</div><div class="line">        <span class="keyword">this</span>.m = m;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="title">TreeSet</span><span class="params">()</span> </span>&#123;</div><div class="line">        <span class="keyword">this</span>(<span class="keyword">new</span> TreeMap&lt;E,Object&gt;());</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="title">TreeSet</span><span class="params">(Comparator&lt;? <span class="keyword">super</span> E&gt; comparator)</span> </span>&#123;</div><div class="line">        <span class="keyword">this</span>(<span class="keyword">new</span> TreeMap&lt;&gt;(comparator));</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="title">TreeSet</span><span class="params">(Collection&lt;? extends E&gt; c)</span> </span>&#123;</div><div class="line">        <span class="keyword">this</span>();</div><div class="line">        addAll(c);</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="title">TreeSet</span><span class="params">(SortedSet&lt;E&gt; s)</span> </span>&#123;</div><div class="line">        <span class="keyword">this</span>(s.comparator());</div><div class="line">        addAll(s);</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>由上面的源码可知，TreeSet底层采用一个<code>NavigableMap</code>来保存TreeSet集合的元素。但实际上，由于<code>NavigableMap</code>只是一个接口，因此底层依然是使用了TreeMap来包含Set集合中的所有元素。TreeSet里绝大多数方法都是直接使用TreeMap的方法来实现的，因此在上面的源码只列出简单的TreeSet的构造方法。</p>
<ul>
<li>原理：基于TreeMap实现的。</li>
<li>特点：TreeSet中的所有元素总是根据指定排序规则保存有序状态（可以自定义TreeSet的排序规则）。</li>
</ul>
<p>下面给一个例子（<a href="https://github.com/wangzzu/java_learn/blob/master/java_thinking/src/javabasic/collection/set/TreeSetTest.java" target="_blank" rel="external">测试代码</a>）</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> java.util.Comparator;</div><div class="line"><span class="keyword">import</span> java.util.Iterator;</div><div class="line"><span class="keyword">import</span> java.util.TreeSet;</div><div class="line"></div><div class="line"><span class="comment">/**</span></div><div class="line"> * Created by matt on 5/13/16.</div><div class="line"> */</div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">TreeSetTest</span> </span>&#123;</div><div class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</div><div class="line">		TreeSet&lt;String&gt; treeSet=<span class="keyword">new</span> TreeSet&lt;&gt;();</div><div class="line">		treeSet.add(<span class="string">"wm0"</span>);</div><div class="line">		treeSet.add(<span class="string">"wm1"</span>);</div><div class="line">		treeSet.add(<span class="string">"matt0"</span>);</div><div class="line">		treeSet.add(<span class="string">"matt1"</span>);</div><div class="line">		Iterator tree=treeSet.iterator();</div><div class="line">		System.out.println(<span class="string">"HashSet(默认排序规则):"</span>);</div><div class="line">		<span class="keyword">while</span> (tree.hasNext())&#123;</div><div class="line">			System.out.println(tree.next());</div><div class="line">		&#125;</div><div class="line"></div><div class="line">		TreeSet&lt;String&gt; treeSet1 = <span class="keyword">new</span> TreeSet&lt;String&gt;(<span class="keyword">new</span> Comparator()&#123;</div><div class="line">			<span class="meta">@Override</span></div><div class="line">			<span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">compare</span><span class="params">(Object o1, Object o2)</span> </span>&#123;</div><div class="line">				<span class="comment">// TODO Auto-generated method stub</span></div><div class="line">				String a = (String)o1;</div><div class="line">				String b = (String)o2;</div><div class="line">				<span class="keyword">return</span> -a.compareTo(b);</div><div class="line">			&#125;&#125;);</div><div class="line">		treeSet1.add(<span class="string">"wm0"</span>);</div><div class="line">		treeSet1.add(<span class="string">"wm1"</span>);</div><div class="line">		treeSet1.add(<span class="string">"matt0"</span>);</div><div class="line">		treeSet1.add(<span class="string">"matt1"</span>);</div><div class="line">		System.out.println(<span class="string">"\nHashSet(向反的默认排序规则):"</span>);</div><div class="line">		Iterator tree1=treeSet1.iterator();</div><div class="line">		<span class="keyword">while</span> (tree1.hasNext())&#123;</div><div class="line">			System.out.println(tree1.next());</div><div class="line">		&#125;</div><div class="line">	&#125;</div><div class="line">&#125;</div><div class="line"><span class="comment">/**</span></div><div class="line">* HashSet(默认排序规则):</div><div class="line">* matt0</div><div class="line">* matt1</div><div class="line">* wm0</div><div class="line">* wm1</div><div class="line">*</div><div class="line">* HashSet(向反的默认排序规则):</div><div class="line">* wm1</div><div class="line">* wm0</div><div class="line">* matt1</div><div class="line">* matt0</div><div class="line">* /</div></pre></td></tr></table></figure>
<h1 id="常见面试题"><a href="#常见面试题" class="headerlink" title="常见面试题"></a>常见面试题</h1><p>这里理出一些常见的面试题，大部分题并未给出准确的回答，大家可以根据前面的分析自行总结。</p>
<ol>
<li>ArrayList VS Vector</li>
<li>ArrayList VS LinkedList<ul>
<li>ArrayList和LinkedList是两个集合 类，用于存储一系列的对象引用(references)。一般大家都知道ArrayList和LinkedList的大致区别：</li>
</ul>
<ol>
<li>ArrayList是实现了基于动态数组的数据结构，LinkedList基于链表的数据结构。</li>
<li>对于随机访问get和set，ArrayList觉得优于LinkedList，因为LinkedList要进行遍历。</li>
<li>对于新增和删除操作add和remove，LinkedList比较占优势，因为ArrayList要移动部分数据。</li>
</ol>
</li>
<li>说你知道的几个Java集合类：list、set、queue、map实现类。<ul>
<li>Map接口<br>映射。主要存储一组组具有映射关系的数据，映射关系主要用key/value的键值对形式表示，一组键值对构成了Map的内部类Entry，所以可以把Map当做由Entry构成的集合。</li>
<li>List接口<br>表。这个表可以是数组实现的ArrayList，也可以是链表实现的LinkedList。比较古老的实现是Vector，现在不推荐使用，包括它的子类Stack，尽管它是线程安全的。List集合代表一个元素有序、可重复的集合，集合中每个元素都有其对应的顺序索引。List集合允许加入重复元素，因为它可以通过索引来访问指定位置的集合元素。</li>
<li>Queue接口<br>模拟”队列”这种数据结构</li>
<li>Set 接口<br>Set是只有Key值，value值为NULL的一个特殊的Map。 只能通过iterator访问元素。</li>
</ul>
</li>
<li>Java中的队列都有哪些，有什么区别。</li>
<li>Java数组和链表两种结构的操作效率，在哪些情况下(从开头开始，从结尾开始，从中间开始)，哪些操作(插入，查找，删除)的效率高？</li>
<li>HashMap与HashTable的区别？<ol>
<li>继承的父类不同，HashTable基于Dictionary类，而HashMap是基于AbstractMap，它们都实现了Map接口。Dictionary是任何可将键映射到相应值的类的抽象父类，而AbstractMap是基于Map接口的实现；</li>
<li>key和value是否允许出现null值。HashMap的key和value都允许为null，而Hashtable的key和value都不允许为null。HashMap遇到key为null的时候，调用putForNullKey方法进行处理，而对value没有处理；Hashtable遇到null，直接返回NullPointerException；</li>
<li>线程安全不同，Hashtable中的几乎所有的public的方法都是synchronized的，而有些方法也是在内部通过synchronized代码块来实现。在多线程并发的环境下，可以直接使用Hashtable，不需要自己为它的方法实现同步，但使用HashMap时就必须要自己增加同步处理；</li>
<li>是否提供contains方法，HashMap把Hashtable的contains方法去掉了，改成containsValue和containsKey，因为contains方法容易让人引起误解。Hashtable则保留了contains，containsValue和containsKey三个方法，其中contains和containsValue功能相同；</li>
<li>内部实现使用的数组初始化和扩容方式不同，HashTable中hash数组默认大小是11，增加的方式是 $old*2+1$，HashMap中hash数组的默认大小是16，而且一定是2的指数；</li>
<li>两个遍历方式的内部实现上不同，Hashtable、HashMap都使用了 Iterator，Hashtable还保留了Enumeration的方式 ；</li>
<li>hash值不同，哈希值的使用不同，HashTable直接使用对象的hashCode，而HashMap重新计算hash值。</li>
</ol>
</li>
<li>HashMap冲突很厉害，最差性能，你会怎么解决?从$O(n)$提升到$\log{n}$。</li>
<li>HashMap和Concurrent HashMap区别， Concurrent HashMap 线程安全吗， Concurrent HashMap如何保证 线程安全？</li>
<li>Hash冲突怎么办？哪些解决散列冲突的方法？<ol>
<li>基于<strong>拉链法</strong>的散列表</li>
</ol>
<ul>
<li>原理：数组+链表（HashMap的实现方式）</li>
<li>特点：</li>
</ul>
<ol>
<li>方法：一，根据散列值查找相应的链表；二，沿着链表查找相应的键；</li>
<li>性能：对于一张含有M条链表和N个键的散列表中，未命中查找和插入操所需的比较次数都为$~\frac{N}{M}$。</li>
<li>基于<strong>线性探测法</strong>的散列表</li>
</ol>
<ul>
<li>原理：用大小为M的<strong>数组</strong>保存N个键值对（$M&gt;N$）。利用空位，也称为开放地址散列表。</li>
<li>特点：当发生碰撞时，直接检查散列表的下一个位置（索引值加1），会有三种结果：</li>
</ul>
<ol>
<li>命中，该位置的键和被查找的键相同；</li>
<li>未命中，键为空；</li>
<li>继续查找，该位置的键和被查找的键不同。</li>
</ol>
<ul>
<li>缺点：进行删除操作时，删除键右边的所有键（连在一起）需要重新插入散列表。</li>
</ul>
</li>
<li>hashCode() 与 equals() 生成算法、方法怎么重写。</li>
<li>如果不让你用Java Jdk提供的工具，你自己实现一个Map，你怎么做。说了好久，说了HashMap源代码，如果我做，就会借鉴HashMap的原理，说了一通HashMap实现。</li>
<li>常用的hash算法有哪些？<ul>
<li>除法hash：求余；</li>
<li>乘法hash；</li>
</ul>
</li>
<li>什么是一致性哈希？（参考<a href="http://blog.csdn.net/cywosp/article/details/23397179" target="_blank" rel="external">五分钟理解一致性Hash算法</a>）<br>为了解决因特网中的热点(Hot spot)问题，初衷和CARP十分类似。一致性哈希修正了CARP使用的简单哈希算法带来的问题。<br>判定哈希算法好坏的四个定义：<ol>
<li>平衡性(Balance)：平衡性是指哈希的结果能够尽可能分布到所有的缓冲中去，这样可以使得所有的缓冲空间都得到利用；</li>
<li>单调性(Monotonicity)：单调性是指如果已经有一些内容通过哈希分派到了相应的缓冲中，又有新的缓冲加入到系统中。哈希的结果应能够保证原有已分配的内容可以被映射到原有的或者新的缓冲中去，而不会被映射到旧的缓冲集合中的其他缓冲区。；</li>
<li>分散性(Spread)：在分布式环境中，终端有可能看不到所有的缓冲，而是只能看到其中的一部分。好的哈希算法应能够尽量避免不一致的情况发生，也就是尽量降低分散性；</li>
<li>负载(Load)：负载问题实际上是从另一个角度看待分散性问题。既然不同的终端可能将相同的内容映射到不同的缓冲区中，那么对于一个特定的缓冲区而言，也可能被不同的用户映射为不同 的内容。与分散性一样，这种情况也是应当避免的，因此好的哈希算法应能够尽量降低缓冲的负荷；<br>在一致性哈希算法中，为了尽可能的满足平衡性，其引入了虚拟节点：<strong>虚拟节点</strong>（ virtual node ）是实际节点（机器）在 hash 空间的复制品（ replica ），一实际个节点（机器）对应了若干个“虚拟节点”，这个对应个数也成为“复制个数”，“虚拟节点”在 hash 空间中以hash值排列.</li>
</ol>
</li>
<li>ReHash<br>ReHash的过程其实是空间和时间的双重重大损失，ReHash的过程其实就是一个动态扩容的过程，而哈希表的扩容是个空间和时间消耗都非常惊人的内部操作。<ol>
<li>原来当我们对哈希结构的容器进行扩容时，散列表内部要重新new一个更大的数组，然后把原来数组的内容拷贝到新数组，并进行重新散列；</li>
<li>new出来的这个更大的新数组容量有多大也是一门学问，一般来说，新数组的大小会设置成原数组双倍大小的相近的一个素数</li>
</ol>
</li>
</ol>
<hr>
<p>参考：</p>
<ul>
<li><a href="http://wiki.jikexueyuan.com/project/java-collection/" target="_blank" rel="external">Java集合学习指南</a></li>
<li><a href="http://www.cnblogs.com/leesf456/tag/%E9%9B%86%E5%90%88%E6%A1%86%E6%9E%B6/" target="_blank" rel="external">Java集合框架学习</a></li>
<li><a href="http://item.jd.com/10064252.html" target="_blank" rel="external">突破Java程序员基本功的16课</a></li>
</ul>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[Java中对象的内存使用学习]]></title>
      <url>http://matt33.com/2016/05/07/java-object-memory/</url>
      <content type="html"><![CDATA[<p>本文的内容来自《算法 第四版》，上次看这一部分的时候应该是一年前了，不过因为昨天在面试中，被问到String对象在内存是如何存储，虽然之前看过这方面的内容，对这还有一点模糊印象，但终究没想起来，所以就想再看一下，顺便写成博客，方便以后查看。</p>
<p>本文主要介绍在Java中，对象、数组、字符串在内存是如何存储的，它们需要占用多少内存。</p>
<h1 id="对象的内存"><a href="#对象的内存" class="headerlink" title="对象的内存"></a>对象的内存</h1><p>要想知道一个对象使用的内存量，需要将所有实例变量使用的内存与对象本身的开销（一般是16个字节）相加。这些开销包括一个指向对象的类的引用、垃圾收集信息以及同步信息。另外，一般内存的使用都会被填充为8个字节（64位计算机中的机器字）的倍数。如下图所示，对于一个<code>Integer</code>对象</p>
<p><img src="/images/2016-05-07-java-object-mem/integer.png" alt="int"></p>
<p>一个<code>Integer</code>对象会使用24字节（16个字节的对象开销，4个字节用于保存它的int值以及4个填充字节）。</p>
<p>一个<code>Date</code>对象（如下图）需要使用32字节：16个字节的对象开销，3个int实例变量各需4个字节，以及4个填充字节。</p>
<p><img src="/images/2016-05-07-java-object-mem/date.png" alt="date"></p>
<p>对象的引用一般都是一个内存地址，因此会使用8个字节。</p>
<p>例如对于一个<code>Counter</code>对象</p>
<p><img src="/images/2016-05-07-java-object-mem/counter.png" alt="counter"></p>
<p>它需要32字节：16个字节的对象开销，8个字节用于它的String型实例变量（<strong>一个引用</strong>），4字节用于int实例变量，以及4个填充字节。</p>
<p>当我们说明一个引用所占的内存时，我们会单独说它所指向的对象所占用的内存，因此，这个内存使用总量并没有包含String对象所使用的内存。</p>
<h1 id="数组"><a href="#数组" class="headerlink" title="数组"></a>数组</h1><p>在java中，数组一般被实现为对象，它们一般都会因为记录长度而需要额外的内存。</p>
<p>一个原始数据类型的数组一般需要24字节的头信息（如下）和保存值所需的引用。</p>
<ol>
<li>16个字节的对象开销；</li>
<li>4个字节用于保存长度；</li>
<li>4个填充字节。</li>
</ol>
<p>下面分别介绍一下<code>int[]</code>、<code>double[]</code>、对象数组和二维数组的内存占用情况。</p>
<p><img src="/images/2016-05-07-java-object-mem/array.png" alt="array"></p>
<h2 id="int值的数组"><a href="#int值的数组" class="headerlink" title="int值的数组"></a>int值的数组</h2><p>一个含有N个int值的数组需要使用$24+4N$字节（<em>notice：最后会被填充为8的倍数</em>）。</p>
<h2 id="double值的数组"><a href="#double值的数组" class="headerlink" title="double值的数组"></a>double值的数组</h2><p>一个含有N个double值的数组需要使用$24+8N$字节（<em>notice：最后会被填充为8的倍数</em>）。</p>
<h2 id="对象的数组"><a href="#对象的数组" class="headerlink" title="对象的数组"></a>对象的数组</h2><p>一个对象的数组就是一个对象的引用的数组，所以我们应该在对象所需的内存之外再加上引用所需的内存。例如，对于一个含有N个<code>Date</code>对象的数组需要使用24字节（头信息）加上$8N$字节（所有的引用）加上每个对象的32字节，总共$24+40N$。</p>
<h2 id="二维数组"><a href="#二维数组" class="headerlink" title="二维数组"></a>二维数组</h2><p>对于二维数组而言，它就是一个数组的数组（每个数组都是一个对象）。例如：一个$M*N$的double类型的二维数组需要使用24字节（头信息）加上$8M$字节（所有元素数组的引用）加上$24M$字节（所有元素的开销）加上$8MN$字节（$M$个长度为$N$的double类型的数组），总和共$8MN+32M+24$字节。</p>
<h1 id="String"><a href="#String" class="headerlink" title="String"></a>String</h1><p>一个String对象</p>
<p><img src="/images/2016-05-07-java-object-mem/string.png" alt="string"></p>
<p>String的标准实现含有4个<strong>实例变量</strong>：</p>
<ul>
<li>一个指向字符数组的引用（8字节）；</li>
<li>三个int值（4个字节）<ol>
<li>第一个int值：字符数组中的偏移量；</li>
<li>第二个int值：一个计数器，也就是字符串的长度，以上图为例，对象所表示的字符串由<code>value[offset]</code>到<code>value[offset+count-1]</code>中的字符组成；</li>
<li>第三个int值：散列值。</li>
</ol>
</li>
</ul>
<p>因此，每个String对象都会使用40字节（16字节表示对象，三个int实例变量各需4个字节，加上数组引用的8个字节和4个填充字节）。这是除字符数组之外字符所需的内存空间，所有字符所需的内存需要另记，因为String的char数组常常是在多个字符串之间共享的。因为String对象是不可变的，这种设计使String的实现能够在多个对象都含有相同的<code>value[]</code>数组时节省内存。</p>
<h1 id="字符串的值和子字符串"><a href="#字符串的值和子字符串" class="headerlink" title="字符串的值和子字符串"></a>字符串的值和子字符串</h1><p>字符串和子字符串的例子如下所示：</p>
<p><img src="/images/2016-05-07-java-object-mem/substring.png" alt="substring"></p>
<p>一个长度为N的String对象一般需要使用40字节（String对象本身）加上$24+2N$字节（字符数组），总共$64+2N$字节。但在处理字符串时经常会和子字符串打交道，所以Java对字符串的表示希望能够避免复制字符串中的字符。</p>
<p>当调用<code>substring()</code>方法时，就创建了一个新的String对象（40字节），但它仍然重用了相同的<code>value[]</code>数组，因此该字符串的子字符串只会使用40字节的内存。含有原始字符串的字符数组的别名存在于子字符串中，字符串对象的偏移量和长度域标记了子字符串的位置。</p>
<p>这些基础机制能够有效地帮助我们估计大量程序对内存的使用情况，但是很多复杂的因素仍然会使这个任务变得困难，这就得看一下JVM方面的书籍了。</p>
<hr>
<p>参考：</p>
<ul>
<li><a href="http://item.jd.com/11098789.html" target="_blank" rel="external">算法 第四版</a></li>
</ul>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[Google Java Style]]></title>
      <url>http://matt33.com/2016/04/22/google-java-style/</url>
      <content type="html"><![CDATA[<p>这份文档是Google Java编程风格规范的定义。在平时编写代码时应该养成一个良好的习惯，按照这个标准去编写容易维护的代码。当且仅当一个Java源文件符合此文档中的规则，我们才认为它符合Google的Java编程风格。</p>
<h1 id="源文件基础"><a href="#源文件基础" class="headerlink" title="源文件基础"></a>源文件基础</h1><h2 id="源文件名"><a href="#源文件名" class="headerlink" title="源文件名"></a>源文件名</h2><p>源文件以其最顶层的类名来命名，大小写敏感，文件扩展名为<code>.java</code>。</p>
<h2 id="文件编码"><a href="#文件编码" class="headerlink" title="文件编码"></a>文件编码</h2><p>源文件编码格式为：<strong>UTF-8</strong>。</p>
<h2 id="特殊字符"><a href="#特殊字符" class="headerlink" title="特殊字符"></a>特殊字符</h2><h3 id="空白字符"><a href="#空白字符" class="headerlink" title="空白字符"></a>空白字符</h3><p>除了行结束符序列，ASCII水平空格字符(<code>0x20</code>，即空格)是源文件中唯一允许出现的空白字符，这意味着：</p>
<ol>
<li>所有其它字符串中的空白字符都要进行转义。</li>
<li>制表符不用于缩进。</li>
</ol>
<h3 id="特殊转义序列"><a href="#特殊转义序列" class="headerlink" title="特殊转义序列"></a>特殊转义序列</h3><p>对于具有特殊转义序列的任何字符(<code>\b</code>,<code>\t</code>,<code>\n</code>, <code>\f</code>, <code>\r</code>,<code>&quot;</code>,<code>&#39;</code>及<code>\</code>)，我们使用它的转义序列，而不是相应的八进制(比如<code>\012</code>)或Unicode(比如<code>\u000a</code>)转义。</p>
<h3 id="非ASCII字符"><a href="#非ASCII字符" class="headerlink" title="非ASCII字符"></a>非ASCII字符</h3><p>对于剩余的非ASCII字符，是使用实际的Unicode字符(比如<code>∞</code>)，还是使用等价的Unicode转义符(比如<code>\u221e</code>)，取决于哪个能让代码更易于阅读和理解。</p>
<blockquote>
<p>Tip: 在使用Unicode转义符或是一些实际的Unicode字符时，建议做些注释给出解释，这有助于别人阅读和理解。</p>
</blockquote>
<h1 id="源文件结构"><a href="#源文件结构" class="headerlink" title="源文件结构"></a>源文件结构</h1><p>一个源文件包含（按顺序地）：</p>
<ol>
<li>许可证版权信息（如果需要的情况下）；</li>
<li>package语句；</li>
<li>import语句；</li>
<li>一个顶级类（只有一个）；</li>
</ol>
<p><em>以上每个部分用一个空行隔开。</em></p>
<h2 id="许可证或版权信息"><a href="#许可证或版权信息" class="headerlink" title="许可证或版权信息"></a>许可证或版权信息</h2><p>如果一个文件包含许可证或版权信息，那么它应当被放在文件最前面。</p>
<h2 id="package语句"><a href="#package语句" class="headerlink" title="package语句"></a>package语句</h2><p><strong>package语句不换行</strong>，列限制并不适用于package语句。(即package语句写在一行里)</p>
<h2 id="import语句"><a href="#import语句" class="headerlink" title="import语句"></a>import语句</h2><ul>
<li>import<strong>不要使用通配符</strong>，不要出现类似这样的import语句：<code>import java.util.*</code>；</li>
<li>import语句<strong>不要换行</strong>，每个import语句独立成行；</li>
<li>顺序与间距：import语句分为以下几组，按照这个顺序，每组由一个空行分隔。<ol>
<li>所有的静态类导入独立成组；</li>
<li><code>com.google</code> imports；</li>
<li>第三的包。每个包为一组，字典序，如<code>andriod</code>，<code>com</code>，<code>junit</code>，<code>org</code>，<code>sun</code>.</li>
<li><code>java</code> imports;</li>
<li><code>javax</code> imports.</li>
</ol>
</li>
</ul>
<p>组内不空行，按字典序排序。</p>
<h2 id="类声明"><a href="#类声明" class="headerlink" title="类声明"></a>类声明</h2><h3 id="只有一个顶级类声明"><a href="#只有一个顶级类声明" class="headerlink" title="只有一个顶级类声明"></a>只有一个顶级类声明</h3><p>每个顶级类都在一个与它同名的源文件中(当然，还包含<code>.java</code>后缀)。</p>
<p>例如：<code>package-info.java</code>，该文件中可没有<code>package-info</code>类。</p>
<h3 id="类成员顺序"><a href="#类成员顺序" class="headerlink" title="类成员顺序"></a>类成员顺序</h3><p>类的成员顺序对易学性有很大的影响，但这也不存在唯一的通用法则。不同的类对成员的排序可能是不同的。 最重要的一点，每个类应该以<strong>某种逻辑</strong>去排序它的成员，维护者应该要能解释这种排序逻辑。比如， 新的方法不能总是习惯性地添加到类的结尾，因为这样就是按时间顺序而非某种逻辑来排序的。</p>
<h3 id="重载：永不分离"><a href="#重载：永不分离" class="headerlink" title="重载：永不分离"></a>重载：永不分离</h3><p>当一个类有多个构造函数，或是多个同名方法，这些函数/方法应该按顺序出现在一起，中间不要放进其它函数/方法。</p>
<h1 id="格式"><a href="#格式" class="headerlink" title="格式"></a>格式</h1><h2 id="大括号"><a href="#大括号" class="headerlink" title="大括号"></a>大括号</h2><h3 id="使用大括号"><a href="#使用大括号" class="headerlink" title="使用大括号"></a>使用大括号</h3><p>当大括号与<code>if</code>, <code>else</code>, <code>for</code>, <code>do</code>, <code>while</code>语句一起使用，即使只有一条语句（或者是空），也应该把大括号写上。</p>
<h3 id="非空块"><a href="#非空块" class="headerlink" title="非空块"></a>非空块</h3><p>对于非空块和块状结构，主要有以下几个原则：</p>
<ul>
<li>在左大括号前不换行；</li>
<li>左大括号后换行；</li>
<li>右大括号前换行；</li>
<li>如果右大括号是一个语句、函数体或类的终止，则右大括号后换行; 否则不换行。例如，如果右大括号后面是else或逗号，则不换行。</li>
</ul>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//示例</span></div><div class="line"><span class="keyword">return</span> <span class="keyword">new</span> MyClass() &#123;</div><div class="line">    <span class="meta">@Override</span> <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">method</span><span class="params">()</span> </span>&#123;</div><div class="line">        <span class="keyword">if</span> (condition()) &#123;</div><div class="line">            <span class="keyword">try</span> &#123;</div><div class="line">                something();</div><div class="line">            &#125; <span class="keyword">catch</span> (ProblemException e) &#123;</div><div class="line">                recover();</div><div class="line">            &#125;</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line">&#125;;</div></pre></td></tr></table></figure>
<h3 id="空块"><a href="#空块" class="headerlink" title="空块"></a>空块</h3><p>这里主要有两种情况：</p>
<ul>
<li>一个空的块状结构里什么也不包含，大括号可以简洁地写成<code>{}</code>，不需要换行；</li>
</ul>
<ul>
<li>但是也有例外的情况：如果它是一个多块语句的一部分(<code>if/else</code>或 <code>try/catch/finally</code>) ，即使大括号内没内容，右大括号也要换行。</li>
</ul>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//不换行</span></div><div class="line"><span class="function"><span class="keyword">void</span> <span class="title">doNothing</span><span class="params">()</span> </span>&#123;&#125;</div></pre></td></tr></table></figure>
<h2 id="块缩进：2个空格"><a href="#块缩进：2个空格" class="headerlink" title="块缩进：2个空格"></a>块缩进：2个空格</h2><p>每当开始一个新的块，缩进增加<strong>2个空格</strong>，当块结束时，缩进返回先前的缩进级别。缩进级别适用于代码和注释。（不过一般情况大家用的都是4个，这个的话看个人喜好，感觉只要统一就可以了）</p>
<h2 id="一行一个语句"><a href="#一行一个语句" class="headerlink" title="一行一个语句"></a>一行一个语句</h2><p>每个语句后要换行。</p>
<h2 id="列限制：80或100"><a href="#列限制：80或100" class="headerlink" title="列限制：80或100"></a>列限制：80或100</h2><p>一个项目可以选择一行80个字符或100个字符的列限制，除了下述例外，任何一行如果超过这个字符数限制，必须自动换行。</p>
<p>例外：</p>
<ul>
<li>不可能满足列限制的行(例如，Javadoc中的一个长URL，或是一个长的JSNI方法参考);</li>
<li><code>package</code>和<code>import</code>语句;</li>
<li>注释中那些可能被剪切并粘贴到shell中的命令行.</li>
</ul>
<h2 id="自动换行"><a href="#自动换行" class="headerlink" title="自动换行"></a>自动换行</h2><p>术语说明：一般情况下，一行长代码为了避免超出列限制(<strong>80或100</strong>个字符)而被分为多行，我们称之为<strong>自动换行</strong>(line-wrapping)。</p>
<p>我们并没有全面，确定性的准则来决定在每一种情况下如何自动换行。很多时候，对于同一段代码会有好几种有效的自动换行方式。</p>
<blockquote>
<p>Tip: 提取方法或局部变量可以在不换行的情况下解决代码过长的问题(是合理缩短命名长度吧)</p>
</blockquote>
<h3 id="从哪里断开"><a href="#从哪里断开" class="headerlink" title="从哪里断开"></a>从哪里断开</h3><p>自动换行的基本准则是：更倾向于在更高的语法级别处断开。</p>
<ul>
<li>如果在<code>非赋值运算符</code>处断开，那么在该符号前断开(比如+，它将位于下一行)。这条规则也适用于以下“类运算符”符号：点分隔符(.)，类型界限中的&amp;（<code>&lt;T extends Foo &amp; Bar&gt;</code>)，catch块中的管道符号(<code>catch (FooException | BarException e</code>)</li>
<li>如果在赋值运算符处断开，通常的做法是在该符号后断开(比如=，它与前面的内容留在同一行)。这条规则也适用于<code>foreach</code>语句中的分号。</li>
<li>方法名或构造函数名与左括号留在同一行。</li>
<li>逗号(,)与其前面的内容留在同一行。</li>
</ul>
<h3 id="自动换行时缩进至少-4个空格"><a href="#自动换行时缩进至少-4个空格" class="headerlink" title="自动换行时缩进至少+4个空格"></a>自动换行时缩进至少+4个空格</h3><p>自动换行时，第一行后的每一行至少比第一行多缩进4个空格(注意：制表符不用于缩进。见2.3.1节)。</p>
<p>当存在连续自动换行时，缩进可能会多缩进不只4个空格(语法元素存在多级时)。一般而言，两个连续行使用相同的缩进当且仅当它们开始于同级语法元素。</p>
<h2 id="空白"><a href="#空白" class="headerlink" title="空白"></a>空白</h2><h3 id="垂直空白"><a href="#垂直空白" class="headerlink" title="垂直空白"></a>垂直空白</h3><p>以下情况需要使用<strong>一个空行</strong>：</p>
<ol>
<li>类内连续的成员之间：字段，构造函数，方法，嵌套类，静态初始化块，实例初始化块。<br>例外：两个连续字段之间的空行是可选的，用于字段的空行主要用来对字段进行逻辑分组。</li>
<li>在函数体内，语句的逻辑分组间使用空行。</li>
<li>类内的第一个成员前或最后一个成员后的空行是可选的(既不鼓励也不反对这样做，视个人喜好而定)。</li>
<li>要满足本文档中其他节的空行要求(比如3.3节：import语句)</li>
</ol>
<p>多个连续的空行是允许的，但没有必要这样做(我们也不鼓励这样做)。</p>
<h3 id="水平空白"><a href="#水平空白" class="headerlink" title="水平空白"></a>水平空白</h3><p>除了语言需求和其它规则，并且除了文字，注释和<code>Javadoc</code>用到单个空格，单个ASCII空格也出现在以下几个地方：</p>
<ol>
<li>分隔任何保留字与紧随其后的左括号(<code>(</code>)(如<code>if, for catch</code>等)。</li>
<li>分隔任何保留字与其前面的右大括号(<code>}</code>)(如<code>else, catch</code>)。</li>
<li>在任何左大括号前(<code>{</code>)，两个例外：<ul>
<li><code>@SomeAnnotation({a, b})</code>(不使用空格)。</li>
<li><code>String[][] x = foo;</code>(大括号间没有空格，见下面的Note)。</li>
</ul>
</li>
<li>在任何二元或三元运算符的两侧。这也适用于以下“类运算符”符号：<ul>
<li>类型界限中的&amp;(<code>&lt;T extends Foo &amp; Bar&gt;</code>)。</li>
<li><code>catch</code>块中的管道符号(<code>catch (FooException | BarException e</code>)。</li>
<li><code>foreach</code>语句中的分号。</li>
</ul>
</li>
<li>在<code>, : ;</code>及右括号(<code>)</code>)后</li>
<li>如果在一条语句后做注释，则<strong>双斜杠(//)两边都要空格</strong>。这里可以允许多个空格，但没有必要。</li>
<li>类型和变量之间：List list。</li>
<li><p>数组初始化中，大括号内的空格是可选的，即<code>new int[] {5, 6}</code>和<code>new int[] { 5, 6 }</code>都是可以的。</p>
<blockquote>
<p>Note：这个规则并不要求或禁止一行的开关或结尾需要额外的空格，只对内部空格做要求。</p>
</blockquote>
</li>
</ol>
<h3 id="水平对齐：不做要求"><a href="#水平对齐：不做要求" class="headerlink" title="水平对齐：不做要求"></a>水平对齐：不做要求</h3><p>术语说明：水平对齐指的是通过增加可变数量的空格来使某一行的字符与上一行的相应字符对齐。</p>
<p>这是允许的(而且在不少地方可以看到这样的代码)，但Google编程风格对此不做要求。即使对于已经使用水平对齐的代码，我们也不需要去保持这种风格。</p>
<p>以下示例先展示未对齐的代码，然后是对齐的代码：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// 未对齐</span></div><div class="line"><span class="keyword">private</span> <span class="keyword">int</span> x; <span class="comment">// this is fine</span></div><div class="line"><span class="keyword">private</span> Color color; <span class="comment">// this too</span></div><div class="line"><span class="comment">// 对齐</span></div><div class="line"><span class="keyword">private</span> <span class="keyword">int</span> x; <span class="comment">// permitted, but future edits</span></div><div class="line"><span class="keyword">private</span> Color color; <span class="comment">// may leave it unaligned</span></div></pre></td></tr></table></figure>
<blockquote>
<p>Tip：对齐可增加代码可读性，但它为日后的维护带来问题。考虑未来某个时候，我们需要修改一堆对齐的代码中的一行。 这可能导致原本很漂亮的对齐代码变得错位。很可能它会提示你调整周围代码的空白来使这一堆代码重新水平对齐(比如程序员想保持这种水平对齐的风格)， 这就会让你做许多的无用功，增加了reviewer的工作并且可能导致更多的合并冲突。</p>
</blockquote>
<h2 id="用小括号来限定组：推荐"><a href="#用小括号来限定组：推荐" class="headerlink" title="用小括号来限定组：推荐"></a>用小括号来限定组：推荐</h2><p>除非作者和reviewer都认为去掉小括号也不会使代码被误解，或是去掉小括号能让代码更易于阅读，否则我们不应该去掉小括号。 我们没有理由假设读者能记住整个Java运算符优先级表。（把所有优先级表全部记下来是比较困难的）</p>
<h2 id="具体结构"><a href="#具体结构" class="headerlink" title="具体结构"></a>具体结构</h2><h3 id="枚举类"><a href="#枚举类" class="headerlink" title="枚举类"></a>枚举类</h3><p>枚举常量间用逗号隔开，换行可选。</p>
<p>没有方法和文档的枚举类可写成数组初始化的格式：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">private</span> <span class="keyword">enum</span> Suit &#123; CLUBS, HEARTS, SPADES, DIAMONDS &#125;</div></pre></td></tr></table></figure>
<p>由于枚举类也是一个类，因此所有适用于其它类的格式规则也适用于枚举类。</p>
<h3 id="变量声明"><a href="#变量声明" class="headerlink" title="变量声明"></a>变量声明</h3><h4 id="每次只声明一个变量"><a href="#每次只声明一个变量" class="headerlink" title="每次只声明一个变量"></a>每次只声明一个变量</h4><p><strong>不要使用组合声明</strong>，比如<code>int a, b</code>;。</p>
<h4 id="局部变量需要时才声明，并尽快进行初始化"><a href="#局部变量需要时才声明，并尽快进行初始化" class="headerlink" title="局部变量需要时才声明，并尽快进行初始化"></a>局部变量需要时才声明，并尽快进行初始化</h4><p>不要在一个代码块的开头把局部变量一次性都声明了(这是c语言的做法)，而是在第一次需要使用它时才声明。 局部变量在声明时最好就进行初始化，或者声明后尽快进行初始化。</p>
<h3 id="数组"><a href="#数组" class="headerlink" title="数组"></a>数组</h3><h4 id="数组初始化：可写成块状结构"><a href="#数组初始化：可写成块状结构" class="headerlink" title="数组初始化：可写成块状结构"></a>数组初始化：可写成块状结构</h4><p>数组初始化可以写成块状结构，比如，下面的写法都是OK的：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">new</span> <span class="keyword">int</span>[] &#123;</div><div class="line">     <span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span></div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="keyword">new</span> <span class="keyword">int</span>[] &#123;</div><div class="line">     <span class="number">0</span>,</div><div class="line">     <span class="number">1</span>,</div><div class="line">     <span class="number">2</span>,</div><div class="line">     <span class="number">3</span></div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="keyword">new</span> <span class="keyword">int</span>[] &#123;</div><div class="line">     <span class="number">0</span>, <span class="number">1</span>,</div><div class="line">     <span class="number">2</span>, <span class="number">3</span></div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="keyword">new</span> <span class="keyword">int</span>[]&#123;<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>&#125;</div></pre></td></tr></table></figure>
<h4 id="数组声明"><a href="#数组声明" class="headerlink" title="数组声明"></a>数组声明</h4><p>中括号是类型的一部分：<code>String[] args</code>。</p>
<h3 id="switch语句"><a href="#switch语句" class="headerlink" title="switch语句"></a>switch语句</h3><p>术语说明：switch块的大括号内是一个或多个语句组。每个语句组包含一个或多个<code>switch</code>标签(<code>case FOO:</code>或<code>default:</code>)，后面跟着一条或多条语句。</p>
<h4 id="缩进"><a href="#缩进" class="headerlink" title="缩进"></a>缩进</h4><p>与其它块状结构一致，<code>switch</code>块中的内容缩进为2个空格。</p>
<p>每个<code>switch</code>标签后新起一行，再缩进2个空格，写下一条或多条语句。</p>
<h4 id="Fall-through：注释"><a href="#Fall-through：注释" class="headerlink" title="Fall-through：注释"></a>Fall-through：注释</h4><p>在一个<code>switch</code>块内，每个语句组要么通过<code>break, continue, return</code>或抛出异常来终止，要么通过一条注释来说明程序将继续执行到下一个语句组， 任何能表达这个意思的注释都是OK的(典型的是用// fall through)。这个特殊的注释并不需要在最后一个语句组(一般是<code>default</code>)中出现。示例：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">switch</span> (input) &#123;</div><div class="line">     <span class="keyword">case</span> <span class="number">1</span>:</div><div class="line">     <span class="keyword">case</span> <span class="number">2</span>:</div><div class="line">         prepareOneOrTwo();</div><div class="line">         <span class="comment">// fall through</span></div><div class="line">     <span class="keyword">case</span> <span class="number">3</span>:</div><div class="line">         handleOneTwoOrThree();</div><div class="line">         <span class="keyword">break</span>;</div><div class="line">     <span class="keyword">default</span>:</div><div class="line">         handleLargeNumber(input);</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h4 id="default的情况要写出来"><a href="#default的情况要写出来" class="headerlink" title="default的情况要写出来"></a>default的情况要写出来</h4><p>每个switch语句都包含一个<code>default</code>语句组，即使它什么代码也不包含。</p>
<h3 id="注解-Annotations"><a href="#注解-Annotations" class="headerlink" title="注解(Annotations)"></a>注解(<code>Annotations</code>)</h3><p>注解紧跟在文档块后面，应用于类、方法和构造函数，一个注解<strong>独占一行</strong>。这些换行不属于自动换行，因此缩进级别不变。例如：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="meta">@Override</span></div><div class="line"><span class="meta">@Nullable</span></div><div class="line"><span class="function"><span class="keyword">public</span> String <span class="title">getNameIfPresent</span><span class="params">()</span> </span>&#123; ... &#125;</div></pre></td></tr></table></figure>
<p>例外：单个的注解可以和签名的第一行出现在同一行。例如：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="meta">@Override</span> <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">hashCode</span><span class="params">()</span> </span>&#123; ... &#125;</div></pre></td></tr></table></figure>
<p>应用于字段的注解紧随文档块出现，应用于字段的多个注解允许与字段出现在同一行。例如：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="meta">@Partial</span> <span class="meta">@Mock</span> DataLoader loader;</div></pre></td></tr></table></figure>
<p>参数和局部变量注解没有特定规则。</p>
<h3 id="注释"><a href="#注释" class="headerlink" title="注释"></a>注释</h3><h4 id="块注释风格"><a href="#块注释风格" class="headerlink" title="块注释风格"></a>块注释风格</h4><p>块注释与其周围的代码在同一缩进级别。它们可以是/<em> … </em>/风格，也可以是// …风格。对于多行的/<em> … </em>/注释，后续行必须从<em>开始， 并且与前一行的</em>对齐。以下示例注释都是OK的。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/*</span></div><div class="line">* This is // And so /* Or you can</div><div class="line">* okay. // is this. * even do this. */</div><div class="line">*/</div></pre></td></tr></table></figure>
<p>注释不要封闭在由星号或其它字符绘制的框架里。</p>
<p>Tip：在写多行注释时，如果你希望在必要时能重新换行(即注释像段落风格一样)，那么使用/<em> … </em>/。</p>
<h3 id="Modifiers"><a href="#Modifiers" class="headerlink" title="Modifiers"></a>Modifiers</h3><p>类和成员的<code>modifiers</code>如果存在，则按Java语言规范中推荐的顺序出现。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">public</span> <span class="keyword">protected</span> <span class="keyword">private</span> <span class="keyword">abstract</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">transient</span> <span class="keyword">volatile</span> <span class="keyword">synchronized</span> <span class="keyword">native</span> <span class="keyword">strictfp</span></div></pre></td></tr></table></figure>
<h1 id="命名约定"><a href="#命名约定" class="headerlink" title="命名约定"></a>命名约定</h1><h2 id="对所有标识符都通用的规则"><a href="#对所有标识符都通用的规则" class="headerlink" title="对所有标识符都通用的规则"></a>对所有标识符都通用的规则</h2><p>标识符只能使用ASCII字母和数字，因此每个有效的标识符名称都能匹配正则表达式<code>\w+</code>。</p>
<p>在Google其它编程语言风格中使用的特殊前缀或后缀，如<code>name_</code>,<code>mName</code>, <code>s_name</code>和<code>kName</code>，在Java编程风格中都不再使用。</p>
<h2 id="标识符类型的规则"><a href="#标识符类型的规则" class="headerlink" title="标识符类型的规则"></a>标识符类型的规则</h2><h3 id="包名"><a href="#包名" class="headerlink" title="包名"></a>包名</h3><p>包名<strong>全部小写</strong>，连续的单词只是<strong>简单地连接</strong>起来，不使用下划线。</p>
<h3 id="类名"><a href="#类名" class="headerlink" title="类名"></a>类名</h3><p>类名都以<code>UpperCamelCase</code>风格编写。</p>
<p>类名通常是名词或名词短语，接口名称有时可能是形容词或形容词短语。现在还没有特定的规则或行之有效的约定来命名注解类型。</p>
<p>测试类的命名以它要测试的类的名称开始，以Test结束。例如，<code>HashTest</code>或<code>HashIntegrationTest</code>。</p>
<h3 id="方法名"><a href="#方法名" class="headerlink" title="方法名"></a>方法名</h3><p>方法名都以<code>lowerCamelCase</code>风格编写。</p>
<p>方法名通常是动词或动词短语。</p>
<p>下划线可能出现在JUnit测试方法名称中用以分隔名称的逻辑组件。一个典型的模式是：<code>test&lt;MethodUnderTest&gt;_&lt;state&gt;</code>，例如<code>testPop_emptyStack</code>。 并不存在唯一正确的方式来命名测试方法。</p>
<h3 id="常量名"><a href="#常量名" class="headerlink" title="常量名"></a>常量名</h3><p>常量名命名模式为<code>CONSTANT_CASE</code>，<strong>全部字母大写，用下划线分隔单词</strong>。那，到底什么算是一个常量？</p>
<p>每个常量都是一个静态<code>final</code>字段，但不是所有静态<code>final</code>字段都是常量。在决定一个字段是否是一个常量时， 考虑它是否真的感觉像是一个常量。例如，如果任何一个该实例的观测状态是可变的，则它几乎肯定不会是一个常量。 只是永远不打算改变对象一般是不够的，它要真的一直不变才能将它示为常量。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// Constants</span></div><div class="line"><span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> NUMBER = <span class="number">5</span>;</div><div class="line"><span class="keyword">static</span> <span class="keyword">final</span> ImmutableList&lt;String&gt; NAMES = ImmutableList.of(<span class="string">"Ed"</span>, <span class="string">"Ann"</span>);</div><div class="line"><span class="keyword">static</span> <span class="keyword">final</span> Joiner COMMA_JOINER = Joiner.on(<span class="string">','</span>); <span class="comment">// because Joiner is immutable</span></div><div class="line"><span class="keyword">static</span> <span class="keyword">final</span> SomeMutableType[] EMPTY_ARRAY = &#123;&#125;;</div><div class="line"><span class="keyword">enum</span> SomeEnum &#123; ENUM_CONSTANT &#125;</div><div class="line"></div><div class="line"><span class="comment">// Not constants</span></div><div class="line"><span class="keyword">static</span> String nonFinal = <span class="string">"non-final"</span>;</div><div class="line"><span class="keyword">final</span> String nonStatic = <span class="string">"non-static"</span>;</div><div class="line"><span class="keyword">static</span> <span class="keyword">final</span> Set&lt;String&gt; mutableCollection = <span class="keyword">new</span> HashSet&lt;String&gt;();</div><div class="line"><span class="keyword">static</span> <span class="keyword">final</span> ImmutableSet&lt;SomeMutableType&gt; mutableElements = ImmutableSet.of(mutable);</div><div class="line"><span class="keyword">static</span> <span class="keyword">final</span> Logger logger = Logger.getLogger(MyClass.getName());</div><div class="line"><span class="keyword">static</span> <span class="keyword">final</span> String[] nonEmptyArray = &#123;<span class="string">"these"</span>, <span class="string">"can"</span>, <span class="string">"change"</span>&#125;;</div></pre></td></tr></table></figure>
<p>这些名字通常是名词或名词短语。</p>
<h3 id="非常量字段名"><a href="#非常量字段名" class="headerlink" title="非常量字段名"></a>非常量字段名</h3><p>非常量字段名以<code>lowerCamelCase</code>风格编写。</p>
<p>这些名字通常是名词或名词短语。</p>
<h3 id="参数名"><a href="#参数名" class="headerlink" title="参数名"></a>参数名</h3><p>参数名以<code>lowerCamelCase</code>风格编写。</p>
<p>参数应该避免用单个字符命名。</p>
<h3 id="局部变量名"><a href="#局部变量名" class="headerlink" title="局部变量名"></a>局部变量名</h3><p>局部变量名以<code>lowerCamelCase</code>风格编写，比起其它类型的名称，局部变量名可以有更为宽松的缩写。</p>
<p>虽然缩写更宽松，但还是要避免用单字符进行命名，除了临时变量和循环变量。</p>
<p>即使局部变量是<code>final</code>和不可改变的，也不应该把它示为常量，自然也不能用常量的规则去命名它。</p>
<h3 id="类型变量名"><a href="#类型变量名" class="headerlink" title="类型变量名"></a>类型变量名</h3><p>类型变量可用以下两种风格之一进行命名：</p>
<ul>
<li>单个的大写字母，后面可以跟一个数字(如：E, T, X, T2)。</li>
<li>以类命名方式(5.2.2节)，后面加个大写的T(如：RequestT, FooBarT)。</li>
</ul>
<h2 id="驼峰式命名法-CamelCase"><a href="#驼峰式命名法-CamelCase" class="headerlink" title="驼峰式命名法(CamelCase)"></a>驼峰式命名法(<code>CamelCase</code>)</h2><p>驼峰式命名法：</p>
<ol>
<li>大驼峰式命名法(<code>UpperCamelCase</code>);</li>
<li>小驼峰式命名法(<code>lowerCamelCase</code>)。</li>
</ol>
<p>有时，我们有不只一种合理的方式将一个英语词组转换成驼峰形式，如缩略语或不寻常的结构(例如”IPv6”或”iOS”)。Google指定了以下的转换方案。</p>
<p>名字从散文形式(prose form)开始:</p>
<ol>
<li>把短语转换为纯ASCII码，并且移除任何单引号。例如：”Müller’s algorithm”将变成”Muellers algorithm”。</li>
<li>把这个结果切分成单词，在空格或其它标点符号(通常是连字符)处分割开。<ul>
<li>推荐：如果某个单词已经有了常用的驼峰表示形式，按它的组成将它分割开(如”AdWords”将分割成”ad words”)。 需要注意的是”iOS”并不是一个真正的驼峰表示形式，因此该推荐对它并不适用。</li>
</ul>
</li>
<li>现在将所有字母都小写(包括缩写)，然后将单词的第一个字母大写：<ol>
<li>每个单词的第一个字母都大写，来得到大驼峰式命名。</li>
<li>除了第一个单词，每个单词的第一个字母都大写，来得到小驼峰式命名。</li>
</ol>
</li>
<li>最后将所有的单词连接起来得到一个标识符。</li>
</ol>
<p>示例：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">Prose form Correct Incorrect</div><div class="line">------------------------------------------------------------------</div><div class="line"><span class="string">"XML HTTP request"</span> XmlHttpRequest XMLHTTPRequest</div><div class="line"><span class="string">"new customer ID"</span> newCustomerId newCustomerID</div><div class="line"><span class="string">"inner stopwatch"</span> innerStopwatch innerStopWatch</div><div class="line"><span class="string">"supports IPv6 on iOS?"</span> supportsIpv6OnIos supportsIPv6OnIOS</div><div class="line"><span class="string">"YouTube importer"</span> YouTubeImporter</div><div class="line">YoutubeImporter*</div></pre></td></tr></table></figure>
<p>加星号处表示可以，但不推荐。</p>
<blockquote>
<p>Note：在英语中，某些带有连字符的单词形式不唯一。例如：”nonempty”和”non-empty”都是正确的，因此方法名<code>checkNonempty</code>和<code>checkNonEmpty</code>也都是正确的。</p>
</blockquote>
<h1 id="编程实践"><a href="#编程实践" class="headerlink" title="编程实践"></a>编程实践</h1><h2 id="Override：能用则用"><a href="#Override：能用则用" class="headerlink" title="@Override：能用则用"></a><code>@Override</code>：能用则用</h2><p>只要是合法的，就把<code>@Override</code>注解给用上。</p>
<h2 id="捕获的异常：不能忽视"><a href="#捕获的异常：不能忽视" class="headerlink" title="捕获的异常：不能忽视"></a>捕获的异常：不能忽视</h2><p>除了下面的例子，对捕获的异常不做响应是极少正确的。(典型的响应方式是打印日志，或者如果它被认为是不可能的，则把它当作一个<code>AssertionError</code>重新抛出。)</p>
<p>如果它确实是不需要在<code>catch</code>块中做任何响应，需要做注释加以说明(如下面的例子)。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">try</span> &#123;</div><div class="line">     <span class="keyword">int</span> i = Integer.parseInt(response);</div><div class="line">     <span class="keyword">return</span> handleNumericResponse(i);</div><div class="line">&#125; <span class="keyword">catch</span> (NumberFormatException ok) &#123;</div><div class="line">     <span class="comment">// it's not numeric; that's fine, just continue</span></div><div class="line">&#125;</div><div class="line"><span class="keyword">return</span> handleTextResponse(response);</div></pre></td></tr></table></figure>
<blockquote>
<p>例外：在测试中，如果一个捕获的异常被命名为<code>expected</code>，则它可以被不加注释地忽略。下面是一种非常常见的情形，用以确保所测试的方法会抛出一个期望中的异常， 因此在这里就没有必要加注释。</p>
</blockquote>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">try</span> &#123;</div><div class="line">     emptyStack.pop();</div><div class="line">     fail();</div><div class="line">&#125; <span class="keyword">catch</span> (NoSuchElementException expected) &#123;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h2 id="静态成员：使用类进行调用"><a href="#静态成员：使用类进行调用" class="headerlink" title="静态成员：使用类进行调用"></a>静态成员：使用类进行调用</h2><p>使用类名调用静态的类成员，而不是具体某个对象或表达式。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">Foo aFoo = ...;</div><div class="line">Foo.aStaticMethod(); <span class="comment">// good</span></div><div class="line">aFoo.aStaticMethod(); <span class="comment">// bad</span></div><div class="line">somethingThatYieldsAFoo().aStaticMethod(); <span class="comment">// very bad</span></div></pre></td></tr></table></figure>
<h2 id="Finalizers-禁用"><a href="#Finalizers-禁用" class="headerlink" title="Finalizers: 禁用"></a><code>Finalizers</code>: 禁用</h2><p>极少会去重写<code>Object.finalize</code>。</p>
<blockquote>
<p>Tip：不要使用finalize。如果你非要使用它，请先仔细阅读和理解Effective Java 第7条款：“Avoid Finalizers”，然后不要使用它。</p>
</blockquote>
<h1 id="Javadoc"><a href="#Javadoc" class="headerlink" title="Javadoc"></a>Javadoc</h1><h2 id="格式-1"><a href="#格式-1" class="headerlink" title="格式"></a>格式</h2><h3 id="一般形式"><a href="#一般形式" class="headerlink" title="一般形式"></a>一般形式</h3><p>Javadoc块的基本格式如下所示：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/**</span></div><div class="line">* Multiple lines of Javadoc text are written here,</div><div class="line">* wrapped normally...</div><div class="line">*/</div><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">method</span><span class="params">(String p1)</span> </span>&#123; ... &#125;</div></pre></td></tr></table></figure>
<p>或者是以下单行形式：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/** An especially short bit of Javadoc. */</span></div></pre></td></tr></table></figure>
<p>基本格式总是OK的。当整个Javadoc块能容纳于一行时(且没有Javadoc标记@XXX)，可以使用单行形式。</p>
<h3 id="段落"><a href="#段落" class="headerlink" title="段落"></a>段落</h3><p>空行(即，只包含最左侧星号的行)会出现在段落之间和Javadoc标记(@XXX)之前(如果有的话)。 除了第一个段落，每个段落第一个单词前都有标签</p><p>，并且它和第一个单词间没有空格。</p>
<h3 id="Javadoc标记"><a href="#Javadoc标记" class="headerlink" title="Javadoc标记"></a>Javadoc标记</h3><p>标准的Javadoc标记按以下顺序出现：<code>@param</code>, <code>@return</code>, <code>@throws</code>, <code>@deprecated</code>, 前面这4种标记如果出现，描述都不能为空。 当描述无法在一行中容纳，连续行需要至少再缩进4个空格。</p>
<h2 id="摘要片段"><a href="#摘要片段" class="headerlink" title="摘要片段"></a>摘要片段</h2><p>每个类或成员的Javadoc以一个简短的摘要片段开始。这个片段是非常重要的，在某些情况下，它是唯一出现的文本，比如在类和方法索引中。</p>
<p>这只是一个小片段，可以是一个名词短语或动词短语，但不是一个完整的句子。它不会以<code>A {@code Foo} is a...</code>或<code>This method returns...</code>开头, 它也不会是一个完整的祈使句，如<code>Save the record...</code>。然而，由于开头大写及被加了标点，它看起来就像是个完整的句子。</p>
<blockquote>
<p>Tip：一个常见的错误是把简单的Javadoc写成<code>/** @return the customer ID */</code>，这是不正确的。它应该写成<code>/** Returns the customer ID. */</code>。</p>
</blockquote>
<h2 id="哪里需要使用Javadoc"><a href="#哪里需要使用Javadoc" class="headerlink" title="哪里需要使用Javadoc"></a>哪里需要使用Javadoc</h2><p>至少在每个public类及它的每个<code>public</code>和<code>protected</code>成员处使用Javadoc，以下是一些例外：</p>
<h3 id="例外：不言自明的方法"><a href="#例外：不言自明的方法" class="headerlink" title="例外：不言自明的方法"></a>例外：不言自明的方法</h3><p>对于简单明显的方法如<code>getFoo</code>，Javadoc是可选的(即，是可以不写的)。这种情况下除了写“Returns the foo”，确实也没有什么值得写了。</p>
<p>单元测试类中的测试方法可能是不言自明的最常见例子了，我们通常可以从这些方法的描述性命名中知道它是干什么的，因此不需要额外的文档说明。</p>
<blockquote>
<p>Tip：如果有一些相关信息是需要读者了解的，那么以上的例外不应作为忽视这些信息的理由。例如，对于方法名<code>getCanonicalName</code>， 就不应该忽视文档说明，因为读者很可能不知道词语<code>canonical name</code>指的是什么。</p>
</blockquote>
<h3 id="例外：重写"><a href="#例外：重写" class="headerlink" title="例外：重写"></a>例外：重写</h3><p>如果一个方法重写了超类中的方法，那么Javadoc并非必需的。</p>
<h3 id="可选的Javadoc"><a href="#可选的Javadoc" class="headerlink" title="可选的Javadoc"></a>可选的Javadoc</h3><p>对于包外不可见的类和方法，如有需要，也是要使用Javadoc的。如果一个注释是用来定义一个类，方法，字段的整体目的或行为， 那么这个注释应该写成Javadoc，这样更统一更友好。</p>
<hr>
<p>参考：</p>
<ul>
<li><a href="https://google.github.io/styleguide/javaguide.html" target="_blank" rel="external">Google Java Style</a></li>
<li><a href="http://www.hawstein.com/posts/google-java-style.html" target="_blank" rel="external">Google Style编程指南</a></li>
</ul>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[postgres安装]]></title>
      <url>http://matt33.com/2016/04/14/postgres-install/</url>
      <content type="html"><![CDATA[<p>本文主要介绍一下在linux（CentOS7.1）下postgres的安装，后续的一篇博文会着重的介绍一下SQL操作。</p>
<p>注：</p>
<ul>
<li>#：超级用户提示符</li>
<li>$：普通用户提示符</li>
</ul>
<h1 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h1><figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">$ sudo yum install postgresql</div><div class="line">$ sudo yum install pgadmin3</div><div class="line"></div><div class="line">$ su postgres <span class="comment">#切换psql用户下</span></div><div class="line"><span class="built_in">exit</span> <span class="comment">#退出</span></div></pre></td></tr></table></figure>
<p>修改用户postgres密码</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ sudo passwd postgres <span class="comment">#重置新密码</span></div></pre></td></tr></table></figure>
<h1 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h1><h2 id="初始化数据库"><a href="#初始化数据库" class="headerlink" title="初始化数据库"></a>初始化数据库</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">$ sudo mkdir -p /var/lib/pgsql/data      #创建pgsql的数据库目录</div><div class="line"># cd /var/lib/pgsql</div><div class="line"># chown postgres.postgres data     #改变目录的所属用户用组</div><div class="line"># su postgres                     #切换到postgres，不然初始化不了</div><div class="line"></div><div class="line">initdb -E UTF-8 -D /var/lib/pgsql/data --locale=en_US.UTF-8 -U postgres -W  #在postgres下，初始化数据库(初始化过程中，需要输入root密码)</div></pre></td></tr></table></figure>
<h2 id="修改配置文件"><a href="#修改配置文件" class="headerlink" title="修改配置文件"></a>修改配置文件</h2><p>修改<code>/var/lib/pgsql/data/postgresql.conf</code>文件，修改postgresql.conf的目的是修改连接权限；</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># vim /var/lib/pgsql/data/postgresql.conf</span></div></pre></td></tr></table></figure>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">listen_addresses = <span class="string">'*'</span>     <span class="comment">#监听所有ip的连接，默认是本机 ip，当然也可以设置局域网ip</span></div><div class="line">port = 5432             <span class="comment">#这个不开也行，默认就是5432端口</span></div></pre></td></tr></table></figure>
<p>修改<code>/var/lib/pgsql/data/pg_hba.conf</code>文件，修改pg_hba.conf的目的是设置谁才可以操作数据服务器</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"># vim /var/lib/pgsql/data/pg_hba.conf</div></pre></td></tr></table></figure>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># TYPE  DATABASE    USER        CIDR-ADDRESS          METHOD</span></div><div class="line"><span class="comment"># "local" is for Unix domain socket connections only</span></div><div class="line"><span class="built_in">local</span>   all         all                               trust</div><div class="line"><span class="comment"># IPv4 local connections:</span></div><div class="line">host    all         all         127.0.0.1/32          <span class="literal">true</span></div><div class="line">host    all         all         0.0.0.0/0             <span class="literal">true</span>   <span class="comment">#这一行我加的，所有IP和用户，密码对都可以连接</span></div><div class="line"><span class="comment"># IPv6 local connections:</span></div><div class="line">host    all         all         ::1/128               <span class="literal">true</span></div></pre></td></tr></table></figure>
<h1 id="psql使用"><a href="#psql使用" class="headerlink" title="psql使用"></a>psql使用</h1><h2 id="启动"><a href="#启动" class="headerlink" title="启动"></a>启动</h2><p>命令：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"># systemctl start postgresql.service</div><div class="line"># or</div><div class="line"># service postgresql start</div></pre></td></tr></table></figure>
<p>但是出现了一个问题：</p>
<p><img src="/images/2016-04-14-postgresql/1.png" alt="startFailed"></p>
<p>使用<code>systemctl status postgresql.service</code>查看日志信息：</p>
<p><img src="/images/2016-04-14-postgresql/fail.png" alt="fail"></p>
<p>检查：</p>
<ul>
<li><p>配置防火墙，在<code>/etc/sysconfig/iptables</code>中添加</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">-A INPUT -p tcp -m state --state NEW -m tcp --dport 5432 -j ACCEPT //postgresql的端口是5432</div><div class="line">-A INPUT -p tcp -m state --state NEW -m tcp --dport 80 -j ACCEPT</div></pre></td></tr></table></figure>
</li>
<li><p>然后设置<code>systemctl enable postgresql.service</code> 来设置<code>/usr/lib/systemd/system/postgresql.service</code>文件。</p>
</li>
</ul>
<p>成功启动的psql如下所示：</p>
<p><img src="/images/2016-04-14-postgresql/status.png" alt="status"></p>
<p>通过<code>netstat -tpnl | grep 5432</code>来查看5432端口的情况。</p>
<p><img src="/images/2016-04-14-postgresql/port.png" alt="port"></p>
<h2 id="添加用户和数据库"><a href="#添加用户和数据库" class="headerlink" title="添加用户和数据库"></a>添加用户和数据库</h2><p>推荐两个学习的网站：</p>
<ul>
<li><a href="http://developer.51cto.com/art/201401/426437.htm" target="_blank" rel="external">psql学习网站</a></li>
<li><a href="http://www.yiibai.com/html/postgresql/" target="_blank" rel="external">psql教程</a></li>
</ul>
<p>首先，在linux下进入到<code>postgres</code>用户名下，然后进入到postgres的控制台：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"># su postgres</div><div class="line">psql</div></pre></td></tr></table></figure>
<p>这样就进入了<strong>数据库的控制台</strong>。</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#不要忘记每句话后的";"，建立数据库用户时，首先linux系统下要有user用户(adduser user )，然后才可以再把user用户指定为数据库的用户。</span></div><div class="line"></div><div class="line">CREATE USER matt WITH PASSWORD <span class="string">'123456'</span>;<span class="comment">#创建数据库用户matt，并设置密码</span></div><div class="line"></div><div class="line">CREATE DATABASE bank OWNER matt;<span class="comment">#创建数据库bank，并指定该数据库的所有者为matt</span></div><div class="line"></div><div class="line">GRANT ALL PRIVILEGES ON DATABASE bank to matt;<span class="comment">#将test数据库的所有权限都赋给用户matt，否则用户matt只能登陆控制台，没有任何数据库操作权限</span></div><div class="line"></div><div class="line">\q <span class="comment">#退出控制台（ctrl+D）</span></div></pre></td></tr></table></figure>
<p>控制台命令：</p>
<ul>
<li><strong>\h</strong>：查看SQL命令的解释，比如\h select。</li>
<li><strong>\?</strong>：查看psql命令列表。</li>
<li><strong>\l</strong>：列出所有数据库。</li>
<li><strong>\c [database_name]</strong>：连接其他数据库。</li>
<li><strong>\d</strong>：列出当前数据库的所有表格。</li>
<li><strong>\d [table_name]</strong>：列出某一张表格的结构。</li>
<li><strong>\du</strong>：列出所有用户。</li>
<li><strong>\e</strong>：打开文本编辑器。</li>
<li><strong>\conninfo</strong>：列出当前数据库和连接的信息</li>
</ul>
<h2 id="建立数据表"><a href="#建立数据表" class="headerlink" title="建立数据表"></a>建立数据表</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">psql -U matt <span class="_">-d</span> bank -h 127.0.0.1 -p 5432<span class="comment">#上面命令的参数含义如下：-U指定用户，-d指定数据库，-h指定服务器，-p指定端口。</span></div><div class="line"><span class="comment"># or</span></div><div class="line">psql -U matt <span class="_">-d</span> bank</div></pre></td></tr></table></figure>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="comment">-- 建立四张表，不要忘记最后面的“；”号</span></div><div class="line"><span class="keyword">create</span> <span class="keyword">table</span> customer(customer_name <span class="built_in">char</span>(<span class="number">20</span>), customer_street <span class="built_in">char</span>(<span class="number">30</span>), customer_city <span class="built_in">char</span>(<span class="number">30</span>), primary <span class="keyword">key</span>(customer_name));</div><div class="line"><span class="keyword">create</span> <span class="keyword">table</span> branch(branch_name <span class="built_in">char</span>(<span class="number">15</span>), branch_city <span class="built_in">char</span>(<span class="number">30</span>), assets <span class="built_in">numeric</span>(<span class="number">16</span>,<span class="number">2</span>), primary <span class="keyword">key</span>(branch_name));</div><div class="line"><span class="keyword">create</span> <span class="keyword">table</span> <span class="keyword">account</span>(account_number <span class="built_in">char</span>(<span class="number">10</span>), branch_name <span class="built_in">char</span>(<span class="number">15</span>), balance <span class="built_in">numeric</span>(<span class="number">12</span>,<span class="number">2</span>), primary <span class="keyword">key</span>(account_number));</div><div class="line"><span class="keyword">create</span> <span class="keyword">table</span> depositor(customer_name <span class="built_in">char</span>(<span class="number">20</span>), account_number <span class="built_in">char</span>(<span class="number">10</span>), primary <span class="keyword">key</span>(customer_name, account_number));</div></pre></td></tr></table></figure>
<p>其他的SQL命令会后续的博客中详细介绍。</p>
<h1 id="遇到的问题"><a href="#遇到的问题" class="headerlink" title="遇到的问题"></a>遇到的问题</h1><h2 id="连接数据库失败"><a href="#连接数据库失败" class="headerlink" title="连接数据库失败"></a>连接数据库失败</h2><p>错误为<code>org.postgresql.util.PSQLException: FATAL: password authentication failed for user &quot;postgres&quot;</code>。<br>打开Postgresql安装目录下的data文件夹，找到pg_hba.conf文件并打开。修改认证方式，将md5改为trust，然后保存。</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># TYPE DATABASE USER CIDR-ADDRESS METHOD</span></div><div class="line"><span class="comment"># IPv4 local connections:</span></div><div class="line">host all all 127.0.0.1/32 trust<span class="comment">#md5改为trust</span></div><div class="line">host all all 0.0.0.0/0 trust</div></pre></td></tr></table></figure>
<p>参考<a href="http://blog.chinaunix.net/uid-26149100-id-3189230.html" target="_blank" rel="external">Postgresql常见问题</a>。</p>
<h2 id="开启端口"><a href="#开启端口" class="headerlink" title="开启端口"></a>开启端口</h2><p>有可能是电脑的端口5432的TCP/IP允许没有开启。</p>
<h2 id="JAVA接口"><a href="#JAVA接口" class="headerlink" title="JAVA接口"></a>JAVA接口</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> java.sql.Connection;</div><div class="line"><span class="keyword">import</span> java.sql.DriverManager;</div><div class="line"><span class="keyword">import</span> java.sql.Statement;</div><div class="line"></div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">table_insert</span> </span>&#123;</div><div class="line">     <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String args[])</span> </span>&#123;</div><div class="line">         Connection c = <span class="keyword">null</span>;</div><div class="line">         Statement stmt = <span class="keyword">null</span>;</div><div class="line"></div><div class="line">         <span class="keyword">long</span> time= <span class="number">201503292255L</span>;</div><div class="line">         <span class="keyword">int</span> client_id=<span class="number">4</span>;</div><div class="line">         <span class="keyword">int</span> server_id=<span class="number">3</span>;</div><div class="line">         <span class="keyword">int</span> server_location=<span class="number">110000</span>;</div><div class="line">         String WebName=<span class="string">"other"</span>;</div><div class="line">         <span class="keyword">int</span> count=<span class="number">1000</span>;</div><div class="line"></div><div class="line">         <span class="keyword">try</span> &#123;</div><div class="line">             Class.forName(<span class="string">"org.postgresql.Driver"</span>);</div><div class="line">             c = DriverManager.getConnection(<span class="string">"jdbc:postgresql://192.168.81.136:5432/postgres"</span>,<span class="string">"postgres"</span>,<span class="string">"psql"</span>);</div><div class="line">             c.setAutoCommit(<span class="keyword">false</span>);</div><div class="line">             System.out.println(<span class="string">"Opened database successfully"</span>);</div><div class="line"></div><div class="line">             stmt = c.createStatement();</div><div class="line"></div><div class="line">             <span class="comment">//String sql = "INSERT INTO traffic (time, client_id, server_id, server_location, web_name, count) VALUES( 201503292255, 1, 3, 110000,'others', 2);";</span></div><div class="line"></div><div class="line">             <span class="comment">//String sql="INSERT INTO traffic (time, client_id, server_id, server_location, web_name, count) VALUES( "+time+", "+client_id+", "+server_id+", "+server_location+", '"+WebName+"'"+", "+count+");";</span></div><div class="line"></div><div class="line">             String sql=<span class="string">"UPDATE traffic SET count="</span>+count+<span class="string">" WHERE time="</span>+time+<span class="string">" AND client_id="</span>+client_id+<span class="string">" AND server_id="</span>+server_id+<span class="string">" AND server_location="</span>+server_location+<span class="string">" AND web_name= '"</span>+WebName+<span class="string">"';"</span>;</div><div class="line">             stmt.executeUpdate(sql);</div><div class="line"></div><div class="line">             stmt.close();<span class="comment">//必须从要有对应关闭数据库的操作，否则会出现问题</span></div><div class="line">             c.commit();</div><div class="line">             <span class="comment">//c.close();</span></div><div class="line">         &#125; <span class="keyword">catch</span> (Exception e) &#123;</div><div class="line">             System.err.println( e.getClass().getName()+<span class="string">": "</span>+ e.getMessage() );</div><div class="line">             System.exit(<span class="number">0</span>);</div><div class="line">         &#125;</div><div class="line">         System.out.println(<span class="string">"Records created successfully"</span>);</div><div class="line">     &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>这里必须要有数据库关闭的操作。</p>
<h2 id="连接数过多"><a href="#连接数过多" class="headerlink" title="连接数过多"></a>连接数过多</h2><p><code>So many clients alreay！</code>.<br>查看的命令：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="comment">--控制台下输入</span></div><div class="line"></div><div class="line"><span class="comment">--当前总共正在使用的连接数</span></div><div class="line"><span class="keyword">select</span> <span class="keyword">count</span>(<span class="number">1</span>) <span class="keyword">from</span> pg_stat_activity;</div><div class="line"><span class="comment">--显示系统允许的最大连接数</span></div><div class="line"><span class="keyword">show</span> max_connections;</div><div class="line"><span class="comment">--显示系统保留的用户数</span></div><div class="line"><span class="keyword">show</span> superuser_reserved_connections ;</div></pre></td></tr></table></figure>
<p>修改<code>/var/lib/pgsql/data/postgresql.conf</code>文件的<code>max_connections</code>，默认为100.但是更多的时候需要考虑的是为什么数据库的连接会那么多，一般情况下是自己的程序出错了。</p>
<hr>
<p>参考：</p>
<ul>
<li><a href="http://blog.51yip.com/pgsql/1520.html" target="_blank" rel="external">Postgres安装介绍</a></li>
</ul>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[zookeeper之学习笔记]]></title>
      <url>http://matt33.com/2016/04/13/zookeeper-learn/</url>
      <content type="html"><![CDATA[<p>Zookeeper的重要性及应用的广泛性，这里就不再叙述了，本文是学习<a href="https://www.amazon.cn/Hadoop%E6%9D%83%E5%A8%81%E6%8C%87%E5%8D%97-%E6%80%80%E7%89%B9/dp/B0055QFIA6/ref=sr_1_3?ie=UTF8&amp;qid=1460778185&amp;sr=8-3&amp;keywords=hadoop%E6%9D%83%E5%A8%81%E6%8C%87%E5%8D%97" target="_blank" rel="external">Hadoop权威指南</a>的基础上进行的总结，当然本文大部分内容来自此书，中间会穿插一些个人的理解。本文主要分以下几块进行详述。</p>
<blockquote>
<ul>
<li>ZooKeeper介绍</li>
<li>Zookeeper安装与运行</li>
<li>ZooKeeper组成员关系</li>
<li>ZooKeeper服务</li>
<li>ZooKeeper应用</li>
</ul>
</blockquote>
<h1 id="ZooKeeper介绍"><a href="#ZooKeeper介绍" class="headerlink" title="ZooKeeper介绍"></a>ZooKeeper介绍</h1><p><a href="https://zookeeper.apache.org/" target="_blank" rel="external">官网</a>对其介绍的原话如下：</p>
<blockquote>
<p>ZooKeeper is a centralized service for maintaining configuration information, naming, providing distributed synchronization, and providing group services. All of these kinds of services are used in some form or another by distributed applications. Each time they are implemented there is a lot of work that goes into fixing the bugs and race conditions that are inevitable. Because of the difficulty of implementing these kinds of services, applications initially usually skimp on them ,which make them brittle in the presence of change and difficult to manage. Even when done correctly, different implementations of these services lead to management complexity when the applications are deployed.</p>
</blockquote>
<p>总结一下就是，Zookeeper分布式服务框架是一个用来解决分布式应用中经常遇到的一些数据管理问题（如：统一命名服务、状态同步服务、集群管理、分布式应用配置项的管理等）的中央服务。</p>
<p>对于一个分布式系统最困难的事情之一就是如何处理<strong>部分失败</strong>（partial failure）。当一条message在网络中的两个节点之间传送时，如果出现了网络错误，发送者无法知道接收者是否已经接收到了这条message。接收者有可能在发生错误之前收到这个message，也有可能没有收到，还有可能接收者已经挂掉。发送者获得真实情况的一般解决方案就是：重新连接接收者，然后发起询问。这就是部分失败：即我们甚至不知道一个操作是否已经完成。</p>
<p>Zookeeper正是为了解决这个问题而应运而生的，当然Zookeeper并不能完全根除部分失败，当然它也不会隐藏这部分的失败。ZooKeeper具有以下几个特点：</p>
<ul>
<li>简单：它的核心是一个精简的文件系统，它提供一些简单的操作和一些额外的抽象操作；</li>
<li>富有表现力：ZooKeeper可以用于实现多种协议和数据结构；</li>
<li>高可用性：可避免单点故障；</li>
<li>采用耦合交互方式：在交互过程中，参与者不需要彼此了解，进程在不了解其他进程的情况下就能够彼此发现并进行交互；</li>
<li>是一个资源库：它是一个开源共享存储库，能使程序员免于编写这类通用的协议。</li>
<li>高性能：对于写操作而言，Zookeeper的基准测试吞吐量已经超过每秒10000个操作，对于常规的读操作，吞吐量更高。</li>
</ul>
<h1 id="Zookeeper的安装与运行"><a href="#Zookeeper的安装与运行" class="headerlink" title="Zookeeper的安装与运行"></a>Zookeeper的安装与运行</h1><h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><p>在<a href="http://archive.apache.org/dist/zookeeper/" target="_blank" rel="external">Zookeeper镜像上</a>下载Zookeeper安装包（这里以<code>zookeeper-3.4.6.tar.gz</code>为例）。这里给出一般Zookeeper的安装与运行的方法，很多实际生成环境中，我们都是使用CDH集成的Zookeeper，这样的话安装与运行就完全可以通过图形化界面操作了。</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 解压</span></div><div class="line">tar -zxvf zookeeper-3.4.6.tar.gz -C /opt</div><div class="line"><span class="comment"># 复制配置文件</span></div><div class="line">cp /opt/zookeeper/zoo_sample.cfg /opt/zookeeper/zoo.cfg</div></pre></td></tr></table></figure>
<p>修改配置文件<code>zoo.cfg</code>.</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">dataDir=/opt/zookeeper/data</div><div class="line">dataLogDir=/opt/zookeeper/logs</div><div class="line">clientPort=2181</div><div class="line">tickTime=2000</div><div class="line">initLimit=5</div><div class="line">syncLimit=2</div><div class="line">server.1=zookeeper1:2888:3888</div><div class="line">server.2=zookeeper2:2888:3888</div><div class="line">server.3=zookeeper3:2888:3888</div></pre></td></tr></table></figure>
<p>首先需要在<code>dataDir</code>目录下，新建一个名为<code>myid</code>的文件，这个文件的作用是指定这个服务器的ID，服务器ID在集合体中是唯一的，并且取值范围在1到255之间。下面再分别介绍一下其他几个参数的意义：</p>
<ul>
<li>dataDir：数据目录；</li>
<li>dataLogDir：日志目录；</li>
<li>clientPort：客户端连接端口；</li>
<li>tickTime：Zookeeper 服务器之间或客户端与服务器之间维持心跳的时间间隔，也就是每个 tickTime 时间就会发送一个心跳（它也是Zookeeper中的基本时间单位）；</li>
<li>initLimit：设定了允许所有follower（下面会介绍）与leader进行连接并同步的时间，它是tickTime的整数倍；</li>
<li>syncLimit：设定了一个follower与leader进行同步的时间，也是tickTime的整数倍；</li>
<li>server.n=hostname:port1:port2：n的值就是服务器的ID，port1是follower用来连接leader的端口，port2是用于leader选举。总结起来就是，2181用于客户端连接，对于leader来说，2888端口用于follower连接，3888端口用于leader选举阶段的其他服务器连接。</li>
</ul>
<h2 id="启动与停止"><a href="#启动与停止" class="headerlink" title="启动与停止"></a>启动与停止</h2><p>启动：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">/opt/zookeeper-3.4.6/bin/zkServer.sh start</div></pre></td></tr></table></figure>
<p>停止：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">/opt/zookeeper-3.4.6/bin/zkServer.sh stop</div></pre></td></tr></table></figure>
<h1 id="ZooKeeper组成员关系"><a href="#ZooKeeper组成员关系" class="headerlink" title="ZooKeeper组成员关系"></a>ZooKeeper组成员关系</h1><p>Zookeeper是一个具有高可用性的高性能协调服务。</p>
<h2 id="组成员关系"><a href="#组成员关系" class="headerlink" title="组成员关系"></a>组成员关系</h2><p>Zookeeper 会维护一个具有层次关系的数据结构，它非常类似于一个标准的文件系统，但是这个文件系统中没有文件和目录，而是统一使用节点（node）的概念，成为<strong>znode</strong>。znode既可以作为保存数据的容器（如：文件），也可以作为保存其他znode的容器（如：目录）。所有的znode构成一个层次化的命名空间。一种自然的建立组成员列表的方式就是利用这个层次结构，如下图所示，首先创建一个以组名（<code>/zk</code>）为节点的znode作为父节点，然后以组成员（<code>/zk/node1</code>、<code>/zk/node2</code>、<code>/zk/node3</code>）为节点名来创建作为子节点的znode。</p>
<p><img src="/images/2016-04-13-zookeeper-learn/group.png" alt="group"></p>
<h2 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h2><p>本例通过一个小项目来介绍Zookeeper的API使用。工程项目参见<a href="https://github.com/wangzzu/bigdata-examples/tree/master/zookeeperexample/src/main/java/groupexample" target="_blank" rel="external">ZooKeeperGroupExample</a>.</p>
<p>这里是使用maven建立的工程，pom文件中jar包的依赖内容如下：</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div></pre></td><td class="code"><pre><div class="line"><span class="tag">&lt;<span class="name">repositories</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">repository</span>&gt;</span></div><div class="line">        <span class="tag">&lt;<span class="name">id</span>&gt;</span>cloudera<span class="tag">&lt;/<span class="name">id</span>&gt;</span></div><div class="line">        <span class="tag">&lt;<span class="name">url</span>&gt;</span>https://repository.cloudera.com/artifactory/cloudera-repos/<span class="tag">&lt;/<span class="name">url</span>&gt;</span></div><div class="line">    <span class="tag">&lt;/<span class="name">repository</span>&gt;</span></div><div class="line"><span class="tag">&lt;/<span class="name">repositories</span>&gt;</span></div><div class="line"><span class="tag">&lt;<span class="name">dependencies</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></div><div class="line">        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>commons-logging<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></div><div class="line">        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>commons-logging<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></div><div class="line">        <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.2<span class="tag">&lt;/<span class="name">version</span>&gt;</span></div><div class="line">    <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></div><div class="line">        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.kafka<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></div><div class="line">        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>kafka_2.10<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></div><div class="line">        <span class="tag">&lt;<span class="name">version</span>&gt;</span>0.9.0.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></div><div class="line">    <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></div><div class="line">        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.zookeeper<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></div><div class="line">        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>zookeeper<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></div><div class="line">        <span class="tag">&lt;<span class="name">version</span>&gt;</span>3.4.5-cdh5.4.8<span class="tag">&lt;/<span class="name">version</span>&gt;</span></div><div class="line">    <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></div><div class="line"><span class="tag">&lt;/<span class="name">dependencies</span>&gt;</span></div></pre></td></tr></table></figure>
<h3 id="创建组"><a href="#创建组" class="headerlink" title="创建组"></a>创建组</h3><p>本程序是在Zookeeper中新建表示组的znode，代码如下所示：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> org.apache.zookeeper.CreateMode;</div><div class="line"><span class="keyword">import</span> org.apache.zookeeper.KeeperException;</div><div class="line"><span class="keyword">import</span> org.apache.zookeeper.WatchedEvent;</div><div class="line"><span class="keyword">import</span> org.apache.zookeeper.Watcher;</div><div class="line"><span class="keyword">import</span> org.apache.zookeeper.ZooDefs;</div><div class="line"><span class="keyword">import</span> org.apache.zookeeper.ZooKeeper;</div><div class="line"></div><div class="line"><span class="keyword">import</span> java.io.IOException;</div><div class="line"><span class="keyword">import</span> java.util.concurrent.CountDownLatch;</div><div class="line"></div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">CreateGroup</span> <span class="keyword">implements</span> <span class="title">Watcher</span> </span>&#123;</div><div class="line">	<span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> SESSION_TIMEOUT = <span class="number">5000</span>;</div><div class="line">	<span class="keyword">private</span> ZooKeeper zk;</div><div class="line">	<span class="keyword">private</span> CountDownLatch connectedSignal = <span class="keyword">new</span> CountDownLatch(<span class="number">1</span>);</div><div class="line"></div><div class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">connect</span><span class="params">(String hosts)</span> <span class="keyword">throws</span> IOException, InterruptedException </span>&#123;</div><div class="line">		zk = <span class="keyword">new</span> ZooKeeper(hosts, SESSION_TIMEOUT, <span class="keyword">this</span>);</div><div class="line">		connectedSignal.await();</div><div class="line">	&#125;</div><div class="line"></div><div class="line">	<span class="meta">@Override</span></div><div class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">process</span><span class="params">(WatchedEvent event)</span> </span>&#123;</div><div class="line">		<span class="keyword">if</span> (event.getState() == Event.KeeperState.SyncConnected) &#123;</div><div class="line">			connectedSignal.countDown();</div><div class="line">		&#125;</div><div class="line">	&#125;</div><div class="line"></div><div class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">create</span><span class="params">(String groupName)</span> <span class="keyword">throws</span> KeeperException, InterruptedException </span>&#123;</div><div class="line">		String path = <span class="string">"/"</span> + groupName;</div><div class="line">		String createdPath = zk.create(path, <span class="keyword">null</span><span class="comment">/*data*/</span>, ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT);</div><div class="line">		System.out.println(<span class="string">"CreateGroup: Created"</span> + createdPath);</div><div class="line">	&#125;</div><div class="line"></div><div class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">close</span><span class="params">()</span> <span class="keyword">throws</span> InterruptedException </span>&#123;</div><div class="line">		zk.close();</div><div class="line">	&#125;</div><div class="line"></div><div class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</div><div class="line">		CreateGroup createGroup = <span class="keyword">new</span> CreateGroup();</div><div class="line">		createGroup.connect(args[<span class="number">0</span>]);</div><div class="line">		createGroup.create(args[<span class="number">1</span>]);</div><div class="line">		createGroup.close();</div><div class="line">	&#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>程序的主要接口有：</p>
<ul>
<li><code>new ZooKeeper()</code>:实例化一个新的Zookeeper类的对象，这个类负责维护客户端和Zookeeper服务之间的联系。它有三个参数<ol>
<li>Zookeeper服务的主机地址（可指定端口，默认是2181）；</li>
<li>以毫秒为单位的会话超时参数；</li>
<li>一个<code>Watcher</code>对象的实例，<code>Watcher</code>对象接收来自Zookeeper的回调，以获得各种事件的通知。</li>
</ol>
</li>
<li><code>zk.create()</code>:创建一个新的Zookeeper的znode。它有四个参数：<ol>
<li>路径（字符串表示）；</li>
<li>znode的内容（字节数组，本例中都使用null值）；</li>
<li>ACL（访问控制列表）；</li>
<li>创建znode的类型，有短暂和持久两种。</li>
</ol>
</li>
</ul>
<p>当一个Zookeeper实例新建时，会启动一个线程连接到Zookeeper服务，它对构造函数是立即返回的，因此在新建的Zookeeper对象之前一定要等待其与Zookeeper服务之间连接成功。这里使用<code>CountDownLatch</code>来阻止使用的Zookeeper对象。当客户端与Zookeeper建立连接之后，<code>Watcher</code>的<code>process()</code>方法会被调用，参数表示一个连接的事件。在接收到一个连接事件（以<code>Watcher.Event.KeeperState</code>的枚举类型值<code>SyncConnected</code>来表示）时，我们通过调用<code>CountDownLatch</code>的<code>countDown()</code>方法来递减它的计数器。锁存器（latch）被创建时带有一个值为1的计数器，用于表示它在释放所有线程之前需要发生的事件数。在调用一次<code>countDown()</code>方法之后，计数器的值变为0，则<code>await()</code>方法返回。</p>
<p>输入以下命令运行：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">java -cp zookeeperexample.jar groupexample.CreateGroup zkIP matt</div></pre></td></tr></table></figure>
<p>输出：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">CreateGroup: Created/matt</div></pre></td></tr></table></figure>
<h3 id="创建组成员"><a href="#创建组成员" class="headerlink" title="创建组成员"></a>创建组成员</h3><p>下面我们编写一个用于注册组成员的程序，每个组成员将作为一个程序运行，并且加入到组中。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// 用于等待建立与Zookeeper连接的辅助类</span></div><div class="line"></div><div class="line"><span class="keyword">import</span> org.apache.zookeeper.WatchedEvent;</div><div class="line"><span class="keyword">import</span> org.apache.zookeeper.Watcher;</div><div class="line"><span class="keyword">import</span> org.apache.zookeeper.ZooKeeper;</div><div class="line"></div><div class="line"><span class="keyword">import</span> java.io.IOException;</div><div class="line"><span class="keyword">import</span> java.util.concurrent.CountDownLatch;</div><div class="line"></div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ConnectionWatcher</span> <span class="keyword">implements</span> <span class="title">Watcher</span></span>&#123;</div><div class="line">	<span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> SESSION_TIMEOUT=<span class="number">5000</span>;</div><div class="line">	<span class="keyword">protected</span> ZooKeeper zk;</div><div class="line">	<span class="keyword">private</span> CountDownLatch connectedSignal=<span class="keyword">new</span> CountDownLatch(<span class="number">1</span>);</div><div class="line"></div><div class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">connect</span><span class="params">(String hosts)</span> <span class="keyword">throws</span> IOException, InterruptedException</span>&#123;</div><div class="line">		zk=<span class="keyword">new</span> ZooKeeper(hosts,SESSION_TIMEOUT,<span class="keyword">this</span>);</div><div class="line">		connectedSignal.await();</div><div class="line">	&#125;</div><div class="line"></div><div class="line">	<span class="meta">@Override</span></div><div class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">process</span><span class="params">(WatchedEvent event)</span></span>&#123;</div><div class="line">		<span class="keyword">if</span>(event.getState()== Event.KeeperState.SyncConnected)&#123;</div><div class="line">			connectedSignal.countDown();</div><div class="line">		&#125;</div><div class="line">	&#125;</div><div class="line"></div><div class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">close</span><span class="params">()</span> <span class="keyword">throws</span>  InterruptedException</span>&#123;</div><div class="line">		zk.close();</div><div class="line">	&#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>上述代码与<code>CreateGroup</code>的很类似。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// 用于将组成员加入到组中</span></div><div class="line"></div><div class="line"><span class="keyword">import</span> org.apache.zookeeper.CreateMode;</div><div class="line"><span class="keyword">import</span> org.apache.zookeeper.KeeperException;</div><div class="line"><span class="keyword">import</span> org.apache.zookeeper.ZooDefs;</div><div class="line"></div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">JoinGroup</span> <span class="keyword">extends</span> <span class="title">ConnectionWatcher</span> </span>&#123;</div><div class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">join</span><span class="params">(String groupName, String memberName)</span> <span class="keyword">throws</span> KeeperException, InterruptedException </span>&#123;</div><div class="line">		String path = <span class="string">"/"</span> + groupName + <span class="string">"/"</span> + memberName;</div><div class="line">		String createdPath = zk.create(path, <span class="keyword">null</span><span class="comment">/*data*/</span>, ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT);</div><div class="line">		System.out.println(<span class="string">"Created "</span> + createdPath);</div><div class="line">	&#125;</div><div class="line"></div><div class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</div><div class="line">		JoinGroup joinGroup = <span class="keyword">new</span> JoinGroup();</div><div class="line">		joinGroup.connect(args[<span class="number">0</span>]);</div><div class="line">		joinGroup.join(args[<span class="number">1</span>], args[<span class="number">2</span>]);</div><div class="line">	&#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>这里的<code>CreateMode.PERSISTENT</code>也可以设置为<code>CreateMode.EPHEMERAL</code>，当设置为<code>EPHEMERAL</code>时，也就意味着这个znode是一个短暂的znode，一旦关闭客户端，子节点的znode就会从父节点的znode中删除。</p>
<p>输入以下命令运行：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">java -cp zookeeperexample.jar groupexample.JoinGroup 192.168.80.23 matt wm1</div><div class="line">java -cp zookeeperexample.jar groupexample.JoinGroup 192.168.80.23 matt wm2</div><div class="line">java -cp zookeeperexample.jar groupexample.JoinGroup 192.168.80.23 matt wm3</div></pre></td></tr></table></figure>
<p>输出：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">Created /matt/wm1</div><div class="line">Created /matt/wm2</div><div class="line">Created /matt/wm3</div></pre></td></tr></table></figure>
<h3 id="列出组成员"><a href="#列出组成员" class="headerlink" title="列出组成员"></a>列出组成员</h3><p>这段程序的目标是，在给出Zookeeper地址和父节点znode的情况下，列出该父节点znode的子节点znode。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> org.apache.zookeeper.KeeperException;</div><div class="line"><span class="keyword">import</span> java.util.List;</div><div class="line"></div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ListGroup</span> <span class="keyword">extends</span> <span class="title">ConnectionWatcher</span> </span>&#123;</div><div class="line"></div><div class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">list</span><span class="params">(String groupName)</span> <span class="keyword">throws</span> KeeperException, InterruptedException </span>&#123;</div><div class="line">		String path = <span class="string">"/"</span> + groupName;</div><div class="line">		<span class="keyword">try</span> &#123;</div><div class="line">			List&lt;String&gt; children = zk.getChildren(path, <span class="keyword">false</span>);</div><div class="line">			<span class="keyword">if</span> (children.isEmpty()) &#123;</div><div class="line">				System.out.printf(<span class="string">"No members in group %s\n"</span>, groupName);</div><div class="line">				System.exit(<span class="number">1</span>);</div><div class="line">			&#125;</div><div class="line">			<span class="keyword">for</span> (String child : children) &#123;</div><div class="line">				System.out.println(child);</div><div class="line">			&#125;</div><div class="line">		&#125; <span class="keyword">catch</span> (KeeperException.NoNodeException e) &#123;</div><div class="line">			System.out.printf(<span class="string">"Group %s does not exist\n"</span>, groupName);</div><div class="line">			System.exit(<span class="number">1</span>);</div><div class="line">		&#125;</div><div class="line">	&#125;</div><div class="line"></div><div class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</div><div class="line">		ListGroup listGroup = <span class="keyword">new</span> ListGroup();</div><div class="line">		listGroup.connect(args[<span class="number">0</span>]);</div><div class="line">		listGroup.list(args[<span class="number">1</span>]);</div><div class="line">		listGroup.close();</div><div class="line">	&#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>这里主要是调用了<code>zk.getChildren()</code>来打印出一个znode的子节点列表，调用参数为该znode的路径和设为false的观察标志。如果在一个znode上设置了观察标志，那么一旦该znode的状态改变，关联的观察（<code>Watcher</code>）会被触发。在这里我们没有使用观察，但是在查看一个znode的子节点时，也可以设置观察，让应用程序接收到组成员加入、退出和组被删除的有关通知。</p>
<p><code>KeeperException.NoNodeException</code>代表了组znode不存在的异常。</p>
<p>输入以下命令运行：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">java -cp zookeeperexample.jar groupexample.ListGroup 192.168.80.23 matt</div></pre></td></tr></table></figure>
<p>输出：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">wm1</div><div class="line">wm2</div><div class="line">wm3</div></pre></td></tr></table></figure>
<h3 id="删除组"><a href="#删除组" class="headerlink" title="删除组"></a>删除组</h3><p>这里给出一个删除znode的程序，它需要支持一级目录的递归删除。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> org.apache.zookeeper.KeeperException;</div><div class="line"><span class="keyword">import</span> java.util.List;</div><div class="line"></div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">DeleteGroup</span> <span class="keyword">extends</span> <span class="title">ConnectionWatcher</span></span>&#123;</div><div class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">delete</span><span class="params">(String groupName)</span> <span class="keyword">throws</span> KeeperException,InterruptedException</span>&#123;</div><div class="line">		String path=<span class="string">"/"</span>+groupName;</div><div class="line"></div><div class="line">		<span class="keyword">try</span>&#123;</div><div class="line">			List&lt;String&gt; children=zk.getChildren(path,<span class="keyword">false</span>);</div><div class="line">			<span class="keyword">for</span>(String child: children)&#123;</div><div class="line">				zk.delete(path+<span class="string">"/"</span>+child,-<span class="number">1</span>);</div><div class="line">			&#125;</div><div class="line">			zk.delete(path,-<span class="number">1</span>);</div><div class="line">		&#125;<span class="keyword">catch</span> (KeeperException.NoNodeException e)&#123;</div><div class="line">			System.out.printf(<span class="string">"Group %s does not exist\n"</span>, groupName);</div><div class="line">			System.exit(<span class="number">1</span>);</div><div class="line">		&#125;</div><div class="line">	&#125;</div><div class="line"></div><div class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception</span>&#123;</div><div class="line">		DeleteGroup deleteGroup=<span class="keyword">new</span> DeleteGroup();</div><div class="line">		deleteGroup.connect(args[<span class="number">0</span>]);</div><div class="line">		deleteGroup.delete(args[<span class="number">1</span>]);</div><div class="line">		deleteGroup.close();</div><div class="line">	&#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>zookeeper对象提供了<code>delete()</code>的方法，该方法有两个参数：</p>
<ol>
<li>路径；</li>
<li>版本号：如果所提供的版本号与znode的版本号一致，则Zookeeper会删除这个znode，这是一种乐观枷锁方式，使客户端能够检测出对znode的修改冲突，这里将版本号设置为-1，可以绕过这个版本检测机制，不管znode的版本号是什么而直接将其删除。</li>
</ol>
<p>Zookeeper不支持递归的删除操作，所以在删除父节点之前必须删除其子节点。</p>
<p>输入以下命令运行：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">java -cp zookeeperexample.jar groupexample.DeleteGroup 192.168.80.23 matt</div></pre></td></tr></table></figure>
<p>通过Zookeeper客户端看到的变化如下图（处理过之后的图）所示：</p>
<p><img src="/images/2016-04-13-zookeeper-learn/zk.png" alt="zk"></p>
<h1 id="ZooKeeper服务"><a href="#ZooKeeper服务" class="headerlink" title="ZooKeeper服务"></a>ZooKeeper服务</h1><p>这里主要通过数据模型、操作、实现、一致性、会话和状态来介绍。</p>
<h2 id="数据模型"><a href="#数据模型" class="headerlink" title="数据模型"></a>数据模型</h2><p>Zookeeper维护着一个树形层次结构，树中的节点被称为znode。znode可以用与存储数据，并且有一个与之关联的ACL。</p>
<ol>
<li>Zookeeper被设计用来协调服务（通常是小数据文件），而不是用于大容量数据存储，因此一个znode能存储的数据被限制在1MB以内；</li>
<li>znode的数据访问具有<strong>原子性</strong>：客户端在读取一个znode数据时，要么读取到所有的数据，要么读操作失败，不会只读到部分数据。同样，写操作将替换znode存储的所有数据（Zookeeper不支持添加操作）；</li>
<li>znode通过路径被引用：Zookeeper中使用的路径必须是绝对路径，而且所有的路径必须是规范的，即每条路径只有唯一的一种表示方式，不支持路径解析；</li>
<li>Zookeeper的路径与URI不同，前者在Java API中通过（<code>java.lang.String</code>）来使用，而后者通过Hadoop <code>Path</code>类（或<code>java.net.URI</code>）来使用。</li>
</ol>
<h3 id="短暂znode"><a href="#短暂znode" class="headerlink" title="短暂znode"></a>短暂znode</h3><p>znode有两种类型，znode的类型在创建时确定并且之后不能再修改。</p>
<ol>
<li>短暂的：在创建短暂znode的客户端会话结束时，Zookeeper会将该短暂znode删除（短暂的znode不能有子节点）；<br>应用：对于那些需要知道特定时刻有哪些分布式资源可用的应用来说，使用短暂znode是一种理想的选择。</li>
<li>持久的：持久znode不依赖于客户端会话，只有当客户端明确要删除该持久znode时才会被删除。</li>
</ol>
<h3 id="顺序号"><a href="#顺序号" class="headerlink" title="顺序号"></a>顺序号</h3><ul>
<li>概念<ul>
<li>顺序（sequential）znode是指名称中包含ZooKeeper指定顺序号的znode。</li>
</ul>
</li>
<li>设置<ul>
<li>如果在创建znode时设置了顺序标识，那么该znode名称之后便会附加一个值，这个值由一个单调递增的<strong>计数器</strong>（由父节点维护）所添加的。</li>
</ul>
</li>
<li>举例<ul>
<li>如果一个客户端请求创建一个名为<code>/a/b-</code>的顺序znode，则所创建znode的名字可能是<code>/a/b-3</code>。如果稍后，另外一个名为<code>/a/b-</code>的顺序znode被创建，计数器会给出一个更大的值来保证znode名称的唯一性，例如：<code>/a/b-5</code>。在 Java 的 API 中，顺序 znode 的实际路径会作为 create() 调用的返回值被传回到客户端。</li>
</ul>
</li>
<li>应用<ul>
<li>在一个分布式系统中，顺序号可以被用于为所有的时间进行全局排序，这样客户端就可以通过顺序号来推断事件的顺序。今后的共享锁就是利用该原理。</li>
</ul>
</li>
</ul>
<h3 id="观察"><a href="#观察" class="headerlink" title="观察"></a>观察</h3><p>znode以某种方式发生变化时，<strong>观察</strong>（Watch）机制可以让客户端得到通知。可以针对Zookeeper服务的操作来设置观察，该服务的其他操作可以触发观察。</p>
<p>注意：</p>
<ul>
<li>观察只触发一次，为了得到多次收到通知，客户端需要重新注册所需的观察。</li>
</ul>
<h2 id="操作"><a href="#操作" class="headerlink" title="操作"></a>操作</h2><p>如下表，Zookeeper中有9种基本操作。</p>
<table>
<thead>
<tr>
<th>操作</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td>create</td>
<td>创建一个 znode （必须要有父节点）</td>
</tr>
<tr>
<td>delete</td>
<td>删除一个 znode （该 znode不能有任何子节点）</td>
</tr>
<tr>
<td>exists</td>
<td>测试一个 znode 是否存在并且查询它的元数据</td>
</tr>
<tr>
<td>getACL,setACL</td>
<td>获取/设置一个 znode 的 ACL</td>
</tr>
<tr>
<td>getChildren</td>
<td>获取一个 znode 的子节点列表</td>
</tr>
<tr>
<td>getData，setData</td>
<td>获取/设置一个 znode 所保存的数据</td>
</tr>
<tr>
<td>sync</td>
<td>将客户端的 znode 视图与 Zookeeper 同步</td>
</tr>
</tbody>
</table>
<p>Zookeeper 中的更新操作时有条件的，在使用<code>delete</code>或<code>setData</code>操作时必须提供被更新 znode 的版本号（可以通过 exists 操作获得）。如果版本号不匹配，则更新操作会失败。更新操作时非阻塞操作，因此一个更新失败的客户端（由于其他进程同时在更新同一个 znode）可以决定是否重试，或执行其他操作，并不会因此而阻塞其他进程的执行。</p>
<p>虽然 Zookeeper 可以被看作是一个文件系统，但出于简单性的需求，有一些文件系统的基本操作被它摒弃了。由于 Zookeeper 中的文件较小并且总是被整体读写，因此没有必要提供打开、关闭或查找操作。</p>
<h3 id="API"><a href="#API" class="headerlink" title="API"></a>API</h3><p>对于 Zookeeper 客户端来说，主要由两种语言绑定 (binging) 可以使用：Java 和 C；当然也可以使用 Perl、Python 和 REST 的 contrib 绑定。对于每一种绑定语言来说，在执行操作时都可以选择同步执行或异步执行（提供两种不同的API）。</p>
<p>同步API与异步API的区别：</p>
<ul>
<li>同步API：使用同步API每个线程都会阻塞进程，知道该操作返回；</li>
<li>异步API：允许以流水线方式处理请求，这在某些情况下可以提供更好的吞吐量。</li>
</ul>
<h3 id="观察触发器"><a href="#观察触发器" class="headerlink" title="观察触发器"></a>观察触发器</h3><p>在<code>exists</code>、<code>getChildren</code>和<code>getData</code>这些读操作上可以设置观察，这些观察可以被写操作<code>create</code>、<code>delete</code>和<code>setData</code> 触发。ACL 相关的操作不参与触发任何观察。当一个观察被触发时会产生一个观察事件，这个观察和触发它的操作共同决定着观察事件的类型。</p>
<ul>
<li>当所观察的znode被创建子节点、删除或其他数据更新时，设置在<code>exists</code>操作上的观察将会被触发。</li>
<li>当所观察的znode被删除或其更新时，设置在<code>getData</code>上的观察将会被触发，创建znode不会触发<code>getData</code>上的观察，因为getData操作成功执行的前提是znode必须已经在。</li>
<li>当所观察的znode的一个子节点被创建或删除时，或观察的znode自己被删时，设置在<code>getChildren</code>操作上的观察将会被触发。</li>
</ul>
<p>设置监视器的操作及对应的触发器</p>
<p><img src="/images/2016-04-13-zookeeper-learn/watch.png" alt="watch"></p>
<ul>
<li>NodeCreated:节点创建事件；</li>
<li>NodeDeleted：代表znode被删除事件；</li>
<li>NodeDataChanged：节点数据改变事件；</li>
<li>NodeChildrenChanged：节点的子节点改变事件；</li>
</ul>
<p>注意：</p>
<ul>
<li>对于NodeCreated和NodeDeleted事件，可以通过路径来判断哪一个节点被创建或删除；</li>
<li>对于NodeChildrenChanged事件，需要重新调用<code>getChildren</code>来获取新的子节点列表来判断哪一个子节点被修改；</li>
<li>对于NodeDataChanged事件，需要调用<code>getData</code>来获取最新的数据；</li>
<li>对于上述第二、三种情况，从收到观察事件到执行操作期间，znode的状态可能会发生变化。</li>
</ul>
<h3 id="ACL-列表"><a href="#ACL-列表" class="headerlink" title="ACL 列表"></a>ACL 列表</h3><p>每个 znode 被创建时都会有一个 ACL 列表，用于决定谁可以对它执行何种操作。ACL 依赖于 Zookeeper 的客户端身份验证机制。Zookeeper 提供了一下几种身份验证方式：</p>
<ul>
<li>digest ：通过用户名和密码来识别客户端；</li>
<li>host：通过客户端的主机名（hostname）来识别客户端；</li>
<li>ip : 通过客户端的 IP 地址来识别客户端。</li>
</ul>
<p>在建议一个 Zookeeper 会话之后，客户端可以对自己进行身份验证。虽然 znode 的 ACL 列表会要求所有的客户端是经过验证的，但 Zookeeper 的身份验证过程却是可选的，客户端必须自己进行身份验证来支持对 znode 的访问。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//使用digest模式（用户和密码）进行身份验证</span></div><div class="line">zk.addAuthInfo(<span class="string">"digest"</span>,<span class="string">"tom:secret"</span>.getBytes());</div><div class="line"></div><div class="line"><span class="comment">//给域example.com下的客户端对某个znode的读权限，可以使用host模式、example.com的ID和READ权限在该znode上设置一个ACL</span></div><div class="line"><span class="keyword">new</span> ACL(Perms.READ,<span class="keyword">new</span> Id(<span class="string">"host"</span>,<span class="string">"example.com"</span>));</div></pre></td></tr></table></figure>
<p>ACL权限如下表：</p>
<table>
<thead>
<tr>
<th>ACL权限</th>
<th>允许的操作</th>
</tr>
</thead>
<tbody>
<tr>
<td>CREATE</td>
<td>create（子节点）</td>
</tr>
<tr>
<td>READ</td>
<td>getChildren/getData</td>
</tr>
<tr>
<td>WRITE</td>
<td>setData</td>
</tr>
<tr>
<td>DELETE</td>
<td>delete（子节点）</td>
</tr>
<tr>
<td>ADMIN</td>
<td>setACL</td>
</tr>
</tbody>
</table>
<h2 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h2><p>这里先介绍一下Zookeeper在实际环境中使用时两种不同的运行模式：</p>
<ol>
<li>独立模式（standalone mode）<ul>
<li>只有一个ZooKeeper服务器，这种模式比较简单，适用于测试环境，但是不能保证高可用性和恢复性；</li>
</ul>
</li>
<li>复制模式（replicated mode）<ul>
<li>运行于一个计算机集群上，这个计算机集群被称为一个”集合体“（ensemble）,ZooKeeper通过复制模式来实现高可用性，只要集合体中有半数以上的机器处于可用状态，他就可以提供服务；</li>
<li>对于一个有5个节点的集合体中，最多可以容忍两台机器出现故障，这里要注意的是对于6个节点的集合体也是只能够容忍2台机器出现故障。</li>
</ul>
</li>
</ol>
<p>ZooKeeper要做的事情就是：确保对znode树的每一个修改都会被复制到集合体中超过半数的机器上。如果少于半数的机器出现故障，则最少有一台机器会保存最新的状态，其余的副本最终也会更新到这个状态。</p>
<p>Zookeeper使用了<strong>Zab协议</strong>，该协议包括两个可以无限重复的阶段：</p>
<ol>
<li>阶段1：leader选举<ul>
<li>集合体中的所有机器通过一个选择过程来选出一台被称为“领导者”（leader）的机器，其他的机器被称为”跟随者“（follower）。一旦半数以上（或指定数量）的follower已经将其状态与leader同步，则标明这个阶段已经完成。</li>
</ul>
</li>
<li>阶段2: 原子广播<ol>
<li>所有的写请求都会被转发给leader，再由leader将更新广播给follwer；</li>
<li>当半数以上的follower已经将修改持久化之后，leader才会提交这个更新，然后客户端才会收到一个更新成功的响应。</li>
<li>这个用来打成共识的协议被设计成具有原子性，因此每个修改要么成功要么失败。</li>
</ol>
</li>
</ol>
<p>注意：</p>
<ul>
<li>如果leader出现故障，其余的机器会选出另外一个leader，并和新的leader继续提供服务。之后，如果之前的leader恢复正常，它就变成了一个follower（leader选举工程很快，根据<a href="http://zookeeper.apache.org/doc/current/zookeeperOver" target="_blank" rel="external">目前的结果</a>，大概只需要200ms）；</li>
<li>在更新内存中的znode树之前，集合体中的所有机器都会被先将更新写入磁盘。</li>
</ul>
<h2 id="一致性"><a href="#一致性" class="headerlink" title="一致性"></a>一致性</h2><p>理解 Zookeeper 的实现基础有助于理解其服务所提供的一致性保证。在集合体中所使用的术语leader和follower是恰当的，它们表名了一点，即一个follower可能滞后于leader几个更新。这也表名了一个现实情况，在一个修改被提交之前，只需要集合体中半数以上机器已经将该修改持久化即可。对 Zookeeper 来说，理想的情况就是将客户端都连接到与leader状态一致的服务器上，每个客户端都有连接到leader，但客户端对此无法控制，甚至它自己都无法知道是否连接到leader。参见下图</p>
<p><img src="/images/2016-04-13-zookeeper-learn/service.png" alt="service"></p>
<p>每一个对 znode 树的更新都被赋予一个全局唯一的 ID，称为<strong>zxid</strong> （代表 “Zookeeper Transaction ID”）。Zookeeper决定了分布式系统中的顺序，它对所有的更新进行排序，如果 zxid z1 小于 z2，则 z1 一定发生在 z2 之前。</p>
<p>在 Zookeeper 的设计中，以下几点考虑保证了数据的一致性。</p>
<ol>
<li>顺序一致性<ul>
<li>来自任意特定客户端的更新都会按其发送顺序被提交。也就是说，如果一个客户端将 znode z 的值更新为 a，在之后的操作中，它又将 z 的值更新为 b ，则没有客户端能够在看到 z 的值是 b 之后再看到值 a（如果没有其他对于 z 的更新）。</li>
</ul>
</li>
<li>原子性<ul>
<li>更新要么成功，要么失败，不会存在部分成功或失败的结果。如果失败了，则不会有客户端看到这个更新的结果。</li>
</ul>
</li>
<li>单一系统映像<ul>
<li>一个客户端无论连接到具体哪一台服务器上，它看到的都是同样的系统视图。这意味着，如果一个客户端在同一个会话中连接到一台新的服务器，它所看到的系统状态不会比在之前服务器上所看到的更老。当一台服务器出故障，导致它的一个客户端需要尝试连接集合体中其他的服务器时，所有状态滞后于故障服务器的服务器都不会接受该连接请求，除非这些服务器将状态赶上故障服务器。</li>
</ul>
</li>
<li>持久性（可靠性）<ul>
<li>一个更改一旦成功，其结果就会被持久化并且不会被撤。这表明更新不会受到服务器故障的影响。</li>
</ul>
</li>
<li>及时性<ul>
<li>任何客户端所看到的系统视图的滞后都是有限的，不会超过几十秒，这意味着与其允许一个客户端看到非常陈旧的数据，还不如将服务器关闭，强迫该客户端连接到到一个状态较新的服务器。</li>
</ul>
</li>
</ol>
<p>由于性能的原因，所有的读操作都是从 Zookeeper 服务器的内存获得数据，它们不参与写操作的全局排序。如果客户端之间通过 Zookeeper 之外的机制进行通信，则客户端可能会发现它们所看到的 Zookeeper 状态是不一致的。</p>
<p>可以使用<code>sync</code>操作，保证任何后续的操作都在服务器的<code>sync</code>操作完成之后才执行。客户端使用<code>sync</code>操作来使自己保持最新的状态。</p>
<h2 id="会话"><a href="#会话" class="headerlink" title="会话"></a>会话</h2><p>每个 Zookeeper 客户端的配置中都包括集合体中服务器的列表。在启动时，客户端会尝试连接到列表中的一台服务器。如果连接失败，它会尝试连接另一台服务器，以此类推，直到成功与一台服务器建立连接或因为所有 Zookeeper 服务器都不可用而失败。</p>
<p>一旦客户端与一台 Zookeeper 服务器建立连接，这台服务器就会为该客户端创建一个新的会话。每个会话都会有一个超时的时间设置，这个设置由创建会话的应用来设定。如果服务器在超过时间段内没有收到任何请求，则相应的会话会过期。一旦一个会话已经过期，就无法重新被打开，并且任何与该会话相关联的短暂 znode 都会丢失。会话通常会长期存在，而会话过期则是一种比较罕见的事件，但对于应用来说，如何处理会话过期仍是非常重要的。</p>
<p>只要一个会话空闲超过一定时间，都可以通过客户端发送 ping 请求（也称为心跳）来保持会话不过期。（ping 请求是由 Zookeeper 的客户端库自动发送，因此在你的代码中不需要考虑如何维护会话）。这个时间长度的设置应当足够低，以便能够检测出服务器故障（由读超时体现），并且能够在会话超时的时间段内重新连接到另外一台服务器。</p>
<p>Zookeeper 客户端可以自动地进行故障切换，切换至另一台 Zookeeper 服务器，并且关键的是，在另一台服务器接替故障服务器之后，所有的会话（和相关的短暂 znode）仍然是有效的。</p>
<p>在故障切换过程中，应用程序将收到断开连接和连接至服务的通知。当客户端断开连接时，观察通知将无法发送；但是当客户端成功恢复连接后，这些延迟的通知还会被发送。当然，在客户端重新连接至另一台服务器的过程中，如果应用程序试图执行一个操作，这个操作将会失败。这充分说明在真实的 Zookeeper 应用中处理连接丢失异常的重要性。</p>
<h3 id="时间"><a href="#时间" class="headerlink" title="时间"></a>时间</h3><p>在 Zookeeper 中有几个时间参数。<strong>滴答 (tickTime)</strong> 参数定义了 ZooKeeper 中的基本时间周期。</p>
<p>其他设置都是根据 滴答 (tickTime) 参数来定义的，或至少受它的限制。例如，会话超时 (session timeout) 参数的值不可以小于 2 个 滴答 (tickTime) 并且不可以大于 20 个 滴答 (tickTime)。如果你试图将会话超时参数设置在这个范围之外，它将会被自动修改到这个范围之内。</p>
<p>通常将 滴答 (tickTime) 参数设置为 2 秒 (2000毫秒)，对应于允许的会话超时范围是 4 到 40 秒。在选择会话超时设置时有几点需要考虑。</p>
<h2 id="状态"><a href="#状态" class="headerlink" title="状态"></a>状态</h2><p>ZooKeeper 对象在其生命周期中会经历几种不同的状态，如下图。你可以在任何时刻通过 <code>getState()</code> 方法来查询对象的状态。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">public</span> Status <span class="title">getState</span><span class="params">()</span></span></div></pre></td></tr></table></figure>
<p>Status被定义为代表Zookeeper对象在不同状态的枚举类型值（一个Zookeeper的实例在一个时刻只能处于一种状态）。</p>
<p><img src="/images/2016-04-13-zookeeper-learn/status.png" alt="status"></p>
<ul>
<li>一个新建的Zookeeper实例处于<code>CONNECTING</code>状态。</li>
<li>一旦建立连接，他就会进入<code>CONNECTED</code>状态。</li>
<li>一个对象在进入<code>CONNECTED</code>状态时，观察对象会收到一个<code>WatchedEvent</code>通知，其中<code>KeeperState</code>的值是<code>SyncConnected</code>。</li>
<li>Zookeeper实例可以断开，然后重新连接到Zookeeper服务，此时它的状态就在<code>CONNECTED</code>和<code>CONNECTING</code>之间转换。</li>
<li>如果<code>close()</code>方法被调用或出现会话超时，Zookeeper实例就会转换到第三个状态<code>CLOSED</code>。一旦处于<code>CLOSED</code>状态，Zookeeper对象就不再被认为是活跃的，并且不能再用。</li>
</ul>
<p>Zookeeper的观察对象有两个作用：</p>
<ul>
<li>它可以用来获得Zookeeper状态变化的相关通知；</li>
<li>它还可以用来获得znode变化的相关通知。</li>
</ul>
<h1 id="ZooKeeper应用"><a href="#ZooKeeper应用" class="headerlink" title="ZooKeeper应用"></a>ZooKeeper应用</h1><h2 id="配置服务示例"><a href="#配置服务示例" class="headerlink" title="配置服务示例"></a>配置服务示例</h2><p>配置服务是分布式系统应用所需要的基本服务之一，它可以使集群中的机器共享配置信息中的那些公共部分。也就是说，Zookeeper可以作为一个具有高可用性的配置服务存储器，允许分布式应用的参与者检索和更新配置文件。</p>
<p>这里我们编写这样一个应用示例（完整代码参考<a href="https://github.com/wangzzu/bigdata-examples/tree/master/zookeeperexample/src/main/java/updateexample" target="_blank" rel="external">Zookeeper Update Example</a>），这里有两个假设来简化我们的示例：</p>
<ol>
<li>所需存储的配置数据是字符串，关键字是znode的路径，因此我们在znode上存储了一个键值对；</li>
<li>在任何时候只有一个客户端会执行更新操作。</li>
</ol>
<p>首先我们在<code>ActiveKeyValueStore</code>的类中编写如下代码：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> groupexample.ConnectionWatcher;</div><div class="line"><span class="keyword">import</span> org.apache.zookeeper.CreateMode;</div><div class="line"><span class="keyword">import</span> org.apache.zookeeper.KeeperException;</div><div class="line"><span class="keyword">import</span> org.apache.zookeeper.Watcher;</div><div class="line"><span class="keyword">import</span> org.apache.zookeeper.ZooDefs;</div><div class="line"><span class="keyword">import</span> org.apache.zookeeper.data.Stat;</div><div class="line"></div><div class="line"><span class="keyword">import</span> java.nio.charset.Charset;</div><div class="line"></div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ActiveKeyValueStore</span> <span class="keyword">extends</span> <span class="title">ConnectionWatcher</span> </span>&#123;</div><div class="line">	<span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> Charset CHARSET = Charset.forName(<span class="string">"UTF-8"</span>);</div><div class="line"></div><div class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">write</span><span class="params">(String path, String value)</span> <span class="keyword">throws</span> InterruptedException, KeeperException </span>&#123;</div><div class="line">		Stat stat = zk.exists(path, <span class="keyword">false</span>);</div><div class="line"></div><div class="line">		<span class="keyword">if</span> (stat == <span class="keyword">null</span>) &#123;</div><div class="line">			zk.create(path, value.getBytes(CHARSET), ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT);</div><div class="line">		&#125; <span class="keyword">else</span> &#123;</div><div class="line">			zk.setData(path, value.getBytes(CHARSET), -<span class="number">1</span>);</div><div class="line">		&#125;</div><div class="line">	&#125;</div><div class="line"></div><div class="line">	<span class="function"><span class="keyword">public</span> String <span class="title">read</span><span class="params">(String path, Watcher watcher)</span> <span class="keyword">throws</span> InterruptedException, KeeperException </span>&#123;</div><div class="line">		<span class="keyword">byte</span>[] data = zk.getData(path, watcher, <span class="keyword">null</span><span class="comment">/*stat*/</span>);</div><div class="line">		<span class="keyword">return</span> <span class="keyword">new</span> String(data, CHARSET);</div><div class="line">	&#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>这里面有两个关键方法：</p>
<ul>
<li><code>write()</code>：将一个关键字及其值写入Zookeeper；</li>
<li><code>read()</code>：读取Zookeeper中的配置属性。</li>
</ul>
<p>Zookeeper的<code>getData()</code>方法有三个参数：</p>
<ol>
<li>路径；</li>
<li>一个观察对象；</li>
<li>一个Stat对象.</li>
</ol>
<p>其中，Stat对象由<code>getData()</code>方法返回的值填充，用来将信息传回给调用者，通过这个方法，调用者可以获得一个znode的数据和元数据，但在本例中，由于我们对元数据不感兴趣，因此将Stat参数设为null。</p>
<p>下面我们编写一个用于更新配置属性值的类<code>ConfigUpdater</code>.</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> org.apache.zookeeper.KeeperException;</div><div class="line"></div><div class="line"><span class="keyword">import</span> java.io.IOException;</div><div class="line"><span class="keyword">import</span> java.util.Random;</div><div class="line"><span class="keyword">import</span> java.util.concurrent.TimeUnit;</div><div class="line"></div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ConfigUpdater</span> </span>&#123;</div><div class="line">	<span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> String PATH = <span class="string">"/matt"</span>;</div><div class="line"></div><div class="line">	<span class="keyword">private</span> ActiveKeyValueStore store;</div><div class="line">	<span class="keyword">private</span> Random random = <span class="keyword">new</span> Random();</div><div class="line"></div><div class="line">	<span class="function"><span class="keyword">public</span> <span class="title">ConfigUpdater</span><span class="params">(String hosts)</span> <span class="keyword">throws</span> IOException, InterruptedException </span>&#123;</div><div class="line">		store = <span class="keyword">new</span> ActiveKeyValueStore();</div><div class="line">		store.connect(hosts);</div><div class="line">	&#125;</div><div class="line"></div><div class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> <span class="keyword">throws</span> InterruptedException, KeeperException </span>&#123;</div><div class="line">		<span class="keyword">while</span> (<span class="keyword">true</span>) &#123;</div><div class="line">			String value = random.nextInt(<span class="number">100</span>) + <span class="string">" "</span>;</div><div class="line">			store.write(PATH, value);</div><div class="line">			System.out.printf(<span class="string">"Set %s to %s \n"</span>, PATH, value);</div><div class="line">			TimeUnit.SECONDS.sleep(random.nextInt(<span class="number">10</span>));</div><div class="line">		&#125;</div><div class="line">	&#125;</div><div class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception</span>&#123;</div><div class="line">		ConfigUpdater configUpdater=<span class="keyword">new</span> ConfigUpdater(args[<span class="number">0</span>]);</div><div class="line">		configUpdater.run();</div><div class="line">	&#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p><code>run()</code>方法在随机时间将随机值更新到<code>/matt</code>znode中。</p>
<p>下面我们通过一个<code>ConfigWatcher</code>类初始化一个实例，然后在<code>dirplayConfig()</code>方法中调用<code>read()</code>显示它所读取到的配置信息的初始值。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> org.apache.zookeeper.KeeperException;</div><div class="line"><span class="keyword">import</span> org.apache.zookeeper.WatchedEvent;</div><div class="line"><span class="keyword">import</span> org.apache.zookeeper.Watcher;</div><div class="line"></div><div class="line"><span class="keyword">import</span> java.io.IOException;</div><div class="line"></div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ConfigWatcher</span> <span class="keyword">implements</span> <span class="title">Watcher</span> </span>&#123;</div><div class="line">	<span class="keyword">private</span> ActiveKeyValueStore store;</div><div class="line"></div><div class="line">	<span class="function"><span class="keyword">public</span> <span class="title">ConfigWatcher</span><span class="params">(String hosts)</span> <span class="keyword">throws</span> IOException, InterruptedException </span>&#123;</div><div class="line">		store = <span class="keyword">new</span> ActiveKeyValueStore();</div><div class="line">		store.connect(hosts);</div><div class="line">	&#125;</div><div class="line"></div><div class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">displayConfig</span><span class="params">()</span> <span class="keyword">throws</span> InterruptedException, KeeperException </span>&#123;</div><div class="line">		String value = store.read(ConfigUpdater.PATH, <span class="keyword">this</span>);</div><div class="line">		System.out.printf(<span class="string">"Read %s as %s.\n"</span>, ConfigUpdater.PATH, value);</div><div class="line">	&#125;</div><div class="line"></div><div class="line">	<span class="meta">@Override</span></div><div class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">process</span><span class="params">(WatchedEvent event)</span> </span>&#123;</div><div class="line">		<span class="keyword">if</span> (event.getType() == Event.EventType.NodeChildrenChanged) &#123;</div><div class="line">			<span class="keyword">try</span> &#123;</div><div class="line">				displayConfig();</div><div class="line">			&#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</div><div class="line">				System.out.println(<span class="string">"Interrupted. exiting."</span>);</div><div class="line">				Thread.currentThread().interrupt();</div><div class="line">			&#125; <span class="keyword">catch</span> (KeeperException e) &#123;</div><div class="line">				System.out.printf(<span class="string">"KeeperException: %s. Exiting.\n"</span>, e);</div><div class="line">			&#125;</div><div class="line">		&#125;</div><div class="line">	&#125;</div><div class="line"></div><div class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</div><div class="line">		ConfigWatcher configWatcher = <span class="keyword">new</span> ConfigWatcher(args[<span class="number">0</span>]);</div><div class="line">		configWatcher.displayConfig();</div><div class="line"></div><div class="line">		Thread.sleep(Long.MAX_VALUE);</div><div class="line">	&#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>运行命令：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 两个控制台分别运行以下命令</span></div><div class="line">java -cp zookeeperexample.jar updateexample.ConfigUpdater zkIP</div><div class="line">java -cp zookeeperexample.jar updateexample.ConfigWatcher zkIp</div></pre></td></tr></table></figure>
<p>这里要注意<code>ConfigWatcher</code>只能收到最近的一个更新，而不是收到所有的更新，每当<code>ConfigWatcher</code>调用时，就会收到最近的一个更新。</p>
<h2 id="异常处理"><a href="#异常处理" class="headerlink" title="异常处理"></a>异常处理</h2><p>在前面的两个例子，我们经常会看到<code>InterruptedException</code>和<code>KeeperException</code>这两种类型的异常，下面，我们就详细讲述一下。</p>
<h3 id="InterruptedException异常"><a href="#InterruptedException异常" class="headerlink" title="InterruptedException异常"></a>InterruptedException异常</h3><p>如果操作被中断，则会有一个<code>InterruptedException</code>异常。在Java中，有一个取消阻塞方法的标准机制，即针对存在阻塞方法的线程调用<code>interrupt()</code>。一个成功的取消操作将产生一个<code>InterruptedException</code>异常。Zookeeper也遵循这一机制，因此你可以使用这种方法来取消一个Zookeeper操作。使用了Zookeeper的类或者库时，通常就会传播<code>InterruptedException</code>异常，使客户端取消它们的操作。</p>
<p><code>InterruptedException</code>异常并不意味着故障，只是表明相应的操作被取消了而已。</p>
<h3 id="KeeperException异常"><a href="#KeeperException异常" class="headerlink" title="KeeperException异常"></a>KeeperException异常</h3><p>如果ZooKeeper服务器发出一个错误信号或与服务器存在通信问题，抛出的则是<code>KeeperException</code>异常。</p>
<ul>
<li>针对不同的错误情况，<code>KeeperException</code>异常存在不同的子类。<br>例如:　<code>KeeperException.NoNodeException</code>是<code>KeeperException</code>的一个子类，如果你试图针对一个不存在的znode执行操作，抛出的则是该异常。</li>
<li>每一个<code>KeeperException</code>异常的子类都对应一个关于错误类型信息的代码。<br>例如:　<code>KeeperException.NoNodeException</code>异常的代码是<code>KeeperException.Code.NONODE</code>.</li>
</ul>
<p>有两种方法被用来处理<code>KeeperException</code>异常：</p>
<ol>
<li>捕捉<code>KeeperException</code>异常，并且通过检测它的代码来决定采取何种补救措施；</li>
<li>另一种是捕捉等价的<code>KeeperException</code>子类，并且在每段捕捉代码中执行相应的操作。</li>
</ol>
<p>KeeperException异常分为三大类</p>
<h4 id="1-状态异常"><a href="#1-状态异常" class="headerlink" title="1.状态异常"></a>1.状态异常</h4><p>当一个操作因不能被应用于znode树而导致失败时，就会出现状态异常。状态异常产生的原因通常是在同一时间有另外一个进程正在修改znode。例如，如果一个znode先被另外一个进程更新了，根据版本号执行<code>setData()</code>操作的进程就会失败，并收到一个<code>KeeperException.BadVersionException</code>异常，这是因为版本号不匹配。程序员通常都知道这种冲突总是存在的，也都会编写代码来进行处理。</p>
<p>一些状态异常会指出程序中的错误，例如<code>KeeperException.NoChildrenForEphemeralsException</code>异常，试图在短暂znode下创建子节点时就会抛出该异常。</p>
<h4 id="2-可恢复异常"><a href="#2-可恢复异常" class="headerlink" title="2.可恢复异常"></a>2.可恢复异常</h4><p>可恢复的异常是指那些应用程序能够在同一个ZooKeeper会话中恢复的异常。一个可恢复的异常是通过<code>KeeperException.ConnectionLossException</code>来表示的，它意味着已经丢失了与ZooKeeper的连接。ZooKeeper会尝试重新连接，并且在大多数情况下重新连接会成功，并确保会话是完整的。</p>
<p>但是ZooKeeper不能判断与<code>KeeperException.ConnectionLossException</code>异常相关的操作是否成功执行。这种情况就是部分失败的一个例子。这时程序员有责任来解决这种不确定性，并且根据应用的情况来采取适当的操作。在这一点上，就需要对<strong>幂等(idempotent)操作</strong>和<strong>非幂等(Nonidempotent)操作</strong>进行区分。</p>
<ul>
<li>幂等操作:指那些一次或多次执行都会产生相同结果的操作，例如读请求或无条件执行的<code>setData</code>操作。对于幂等操作，只需要简单地进行重试即可。</li>
<li>非幂等操作:就不能盲目地进行重试，因为它们多次执行的结果与一次执行是完全不同的。程序可以通过在znode的路径和它的数据中编码信息来检测是否非幂等操怍的更新已经完成。</li>
</ul>
<h4 id="3-不可恢复的异常"><a href="#3-不可恢复的异常" class="headerlink" title="3.不可恢复的异常"></a>3.不可恢复的异常</h4><p>在某些情况下，ZooKeeper会话会失效——也许因为超时或因为会话被关闭，两种情况下都会收到<code>KeeperException.SessionExpiredException</code>异常，或因为身份验证失败，<code>KeeperException.AuthFailedException</code>异常。无论上述哪种情况，所有与会话相关联的短暂znode都将丢失，因此应用程序需要在重新连接到ZooKeeper之前重建它的状态。</p>
<p>到这里，对Zookeeper的主要内容已经讲述差不多了，希望对大家能有所帮助。</p>
<hr>
<p>参考：</p>
<ul>
<li><a href="https://www.amazon.cn/Hadoop%E6%9D%83%E5%A8%81%E6%8C%87%E5%8D%97-%E6%80%80%E7%89%B9/dp/B0055QFIA6/ref=sr_1_3?ie=UTF8&amp;qid=1460778185&amp;sr=8-3&amp;keywords=hadoop%E6%9D%83%E5%A8%81%E6%8C%87%E5%8D%97" target="_blank" rel="external">Hadoop权威指南第二版</a></li>
<li><a href="https://zookeeper.apache.org/" target="_blank" rel="external">Apache Zookeeper</a></li>
<li><a href="https://cwiki.apache.org/confluence/display/ZOOKEEPER/Index" target="_blank" rel="external">ZooKeeper WIKI</a></li>
<li><a href="http://zookeeper.apache.org/doc/current/index.html" target="_blank" rel="external">ZooKeeper 3.4Documentation</a></li>
</ul>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[Thrift之学习笔记]]></title>
      <url>http://matt33.com/2016/04/07/thrift-learn/</url>
      <content type="html"><![CDATA[<p>本文主要是对Thrift学习的一些总结，主要讲述了Thrift的开发、基本数据类型服务类型的介绍，然后会通过两个例子来学习如何使用Thrift进行开发，同时会介绍Thrift在大数据框架方面的应用。</p>
<h2 id="thrift-介绍"><a href="#thrift-介绍" class="headerlink" title="thrift 介绍"></a>thrift 介绍</h2><p>Apache Thrift 是由 Facebook 开发的一种远程服务调用（RPC Remote Procedure Call）的框架。下面应用官网的一句话对其进行介绍：</p>
<blockquote class="blockquote-center">The Apache Thrift software framework, for scalable cross-language services development, combines a software stack with a code generation engine to build services that work efficiently and seamlessly between C++, Java, Python, PHP, Ruby, Erlang, Perl, Haskell, C#, Cocoa, JavaScript, Node.js, Smalltalk, OCaml and Delphi and other languages.</blockquote>

<p>简而言之，Thrift是一种支持多语言的软件框架，在各个服务之间的RPC通信领域应用非常广泛。<strong>RPC</strong>（远程过程调用）是一个计算机通信协议，该协议允许运行于一台计算机的程序调用另一台计算机的子程序，而程序员无需额外地为这个交互作用编程。（参考<a href="https://zh.wikipedia.org/wiki/%E9%81%A0%E7%A8%8B%E9%81%8E%E7%A8%8B%E8%AA%BF%E7%94%A8" target="_blank" rel="external">远程过程调用</a>）。</p>
<p>Thrift通过一个中间语言(IDL, 接口定义语言)来定义RPC的接口和数据类型，然后通过一个编译器生成不同语言的代码（目前支持C++,Java, Python, PHP, Ruby, Erlang, Perl, Haskell, C#, Cocoa, Smalltalk和OCaml）,并由生成的代码负责RPC协议层和传输层的实现。</p>
<h3 id="Thrift安装"><a href="#Thrift安装" class="headerlink" title="Thrift安装"></a>Thrift安装</h3><p>安装可以参考<a href="https://thrift.apache.org/docs/install/" target="_blank" rel="external">Apache Thrift Install</a>，我使用的是CentOS7.1，直接使用yum安装即可。</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#安装</span></div><div class="line">$ sudo yum install thrift</div><div class="line"></div><div class="line"><span class="comment">#查看版本</span></div><div class="line">$ thrift -version</div><div class="line"></div><div class="line"><span class="comment"># Output： Thrift version 0.9.1</span></div></pre></td></tr></table></figure>
<h2 id="Thrift-Type"><a href="#Thrift-Type" class="headerlink" title="Thrift Type"></a>Thrift Type</h2><p>使用Thrift时，涉及到了<code>.thrift</code>文件（也就是服务）的编写，因此，需要了解一下Thrift Types，它包含了基本类型，自定义的结构体，容器，异常等。关于这部分，<a href="http://wuchong.me/blog/2015/10/07/thrift-induction/" target="_blank" rel="external">Thrift 入门</a>这篇文章，总结很不错，我这里也就直接使用了拿来主义，首稍微有些修改。</p>
<h3 id="基本类型（Base-Types）"><a href="#基本类型（Base-Types）" class="headerlink" title="基本类型（Base Types）"></a>基本类型（Base Types）</h3><ul>
<li>bool: 布尔变量（A boolean value, one byte）；</li>
<li>byte: 8位有符号整数（A signed byte）；</li>
<li>i16: 16位有符号整数（A 16-bit signed integer）；</li>
<li>i32: 32位有符号整数（A 32-bit signed integer）；</li>
<li>i64: 64位有符号整数（A 64-bit signed integer）；</li>
<li>double: 64位浮点数（A 64-bit floating point number）；</li>
<li>binary: byte数组（A byte array）；</li>
<li>string: 字符串（Encoding agnostic text or binary string）；</li>
</ul>
<p><em>Note：Thrift 不支持无符号整数，因为有些语言也不支持无符号整数，比如Java</em></p>
<h3 id="容器类型（Containers）"><a href="#容器类型（Containers）" class="headerlink" title="容器类型（Containers）"></a>容器类型（Containers）</h3><ul>
<li>list<t>: 一系列由T类型的数据组成的有序列表，元素可以重复；</t></li>
<li>set<t>: 一系列由T类型的数据组成的无序集合，元素不可重复</t></li>
<li>map<t1,t2>: 一个字典结构，key为T1类型，value为T2类型；</t1,t2></li>
</ul>
<p><em>Note：这些集合中的元素可以是除了服务的任何Thrift类型（包括结构体和异常）。</em></p>
<h3 id="结构体（Struct）"><a href="#结构体（Struct）" class="headerlink" title="结构体（Struct）"></a>结构体（Struct）</h3><p>结构体中包含一系列的强类型域，等同于无继承的class。可以看出struct写法很类似C语言的结构体。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">struct Example &#123;</div><div class="line">  1:i32 number=10,</div><div class="line">  2:i64 bigNumber,</div><div class="line">  3:list&lt;double&gt; decimals,</div><div class="line">  4:string name=&quot;thrifty&quot;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h3 id="可选与必选"><a href="#可选与必选" class="headerlink" title="可选与必选"></a>可选与必选</h3><p>Thrift提供两个关键字<code>required</code>，<code>optional</code>，分别用于表示对应的字段时必填的还是可选的。例如：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">struct People &#123;</div><div class="line">    1: required string name;</div><div class="line">    2: optional i32 age;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>表示name是必填的，age是可选的。</p>
<h3 id="联合-Union"><a href="#联合-Union" class="headerlink" title="联合(Union)"></a>联合(Union)</h3><p>在一个结构体中，如果field之间的关系是互斥的，即<strong>只能有一个field</strong>被使用被赋值。在这种情况下，我们可以使用<code>union</code>来声明这个结构体，而不是一堆堆optional的field，语意上也更明确了。例如：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">union JavaObjectArg &#123;</div><div class="line">  1: i32 int_arg;</div><div class="line">  2: i64 long_arg;</div><div class="line">  3: string string_arg;</div><div class="line">  4: bool bool_arg;</div><div class="line">  5: binary binary_arg;</div><div class="line">  6: double double_arg;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h3 id="异常-Exceptions"><a href="#异常-Exceptions" class="headerlink" title="异常(Exceptions)"></a>异常(Exceptions)</h3><p>可以自定义异常类型，所定义的异常会继承对应语言的异常基类，例如java，就会继承 <code>java.lang.Exception</code>.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">exception InvalidOperation &#123;</div><div class="line">  1: i32 what,</div><div class="line">  2: string why</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h3 id="服务-service"><a href="#服务-service" class="headerlink" title="服务(service)"></a>服务(service)</h3><p>Thrift定义服务相当于Java中创建Interface一样，创建的service经过代码生成命令之后就会生成客户端和服务端的框架代码。定义形式如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">service Hello&#123;</div><div class="line">  string helloString(1:string para)</div><div class="line">  i32 helloInt(1:i32 para)</div><div class="line">  bool helloBoolean(1:bool para)</div><div class="line">  void helloVoid()</div><div class="line">  string helloNull()</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h3 id="命名空间-namespace"><a href="#命名空间-namespace" class="headerlink" title="命名空间(namespace)"></a>命名空间(namespace)</h3><p>Thrift的命名空间相当于Java中的package的意思，主要目的是组织代码。thrift使用关键字namespace定义命名空间，如：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">namespace java service.demo</div></pre></td></tr></table></figure>
<p>注意末尾不能有分号，由此生成的代码，其包路径结构为<code>service.demo</code>.</p>
<h2 id="Thrift支持的数据传输格式、数据传输方式和服务模型"><a href="#Thrift支持的数据传输格式、数据传输方式和服务模型" class="headerlink" title="Thrift支持的数据传输格式、数据传输方式和服务模型"></a>Thrift支持的数据传输格式、数据传输方式和服务模型</h2><h3 id="协议（传输格式）"><a href="#协议（传输格式）" class="headerlink" title="协议（传输格式）"></a>协议（传输格式）</h3><ul>
<li>TBinaryProtocol： 二进制格式；</li>
<li>TCompactProtocol：高效率的、密集的二进制编码格式进行数据传输；</li>
<li>TJSONProtocol：JSON格式；</li>
<li>TSimpleJSONProtocol：提供JSON只写协议, 生成的文件很容易通过脚本语言解析；</li>
<li>TDebugProtocol：使用易懂的可读的文本格式，以便于debug。</li>
</ul>
<h3 id="传输层（数据传输方式）"><a href="#传输层（数据传输方式）" class="headerlink" title="传输层（数据传输方式）"></a>传输层（数据传输方式）</h3><ul>
<li>TSocket：阻塞式socker；</li>
<li>TFramedTransport：使用非阻塞方式，以frame为单位进行传输。</li>
<li>TFileTransport：以文件形式进行传输。</li>
<li>TMemoryTransport：将内存用于I/O. java实现时内部实际使用了简单的ByteArrayOutputStream。</li>
<li>TZlibTransport：使用zlib进行压缩， 与其他传输方式联合使用。当前无java实现。</li>
<li>TNonblockingTransport —— 使用非阻塞方式，用于构建异步客户端</li>
</ul>
<h3 id="服务模型"><a href="#服务模型" class="headerlink" title="服务模型"></a>服务模型</h3><ul>
<li>TSimpleServer：单线程服务器端使用标准的阻塞式 I/O，简单的单线程服务模型，常用于测试；</li>
<li>TThreadPoolServer：多线程服务模型，使用标准的阻塞式IO；</li>
<li>TNonblockingServer：多线程服务模型，使用非阻塞式IO（需使用TFramedTransport数据传输方式）。</li>
</ul>
<h2 id="Thrift-简单使用"><a href="#Thrift-简单使用" class="headerlink" title="Thrift 简单使用"></a>Thrift 简单使用</h2><p>这里我们使用两个Thrift的示例来讲述Thrift的使用，第一例子比较简单，类似于Hello World这种。第二例子，我们会使用阻塞单线程多线程、非阻塞、半同步半阻塞等方式。</p>
<p>这里Maven工程的<code>pom.xml</code>文件的配置为：</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.thrift<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>libthrift<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>0.9.3<span class="tag">&lt;/<span class="name">version</span>&gt;</span></div><div class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></div><div class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.slf4j<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>slf4j-log4j12<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.7.21<span class="tag">&lt;/<span class="name">version</span>&gt;</span></div><div class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></div></pre></td></tr></table></figure>
<h3 id="Thrift之Hello-World"><a href="#Thrift之Hello-World" class="headerlink" title="Thrift之Hello World"></a>Thrift之Hello World</h3><p>本例是一个简单Thrift示例，具体代码参见<a href="https://github.com/wangzzu/java_learn/tree/master/thrift/src/main/java/matt/thrift/hello" target="_blank" rel="external">thrifthello</a></p>
<h4 id="1-接口定义"><a href="#1-接口定义" class="headerlink" title="1.接口定义"></a>1.接口定义</h4><p>我们来编写一个thrift文件，定义服务端的接口定义个服务接口（<code>hello.thrift</code>）.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">namespace java hello.thrift</div><div class="line">service Hello&#123;</div><div class="line"> string helloString(1:string para)</div><div class="line"> i32 helloInt(1:i32 para)</div><div class="line"> bool helloBoolean(1:bool para)</div><div class="line"> void helloVoid()</div><div class="line"> string helloNull()</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>这里我们定义了5个不同的接口，接着使用Thrift对文件进行编译，产生对应的程序文件，以Java为例。</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">thrift —gen java hello.thrift</div></pre></td></tr></table></figure>
<p>命令执行完成后，就会在<code>gen-java/hello/thrift</code>生成一个Hello.java的文件，将这个java文件放到<code>hello/thrift</code>中。</p>
<h4 id="2-接口实现"><a href="#2-接口实现" class="headerlink" title="2.接口实现"></a>2.接口实现</h4><p>前面只是定义了接口的签名，现在我们来对接口进行实现，实现类需要实现<code>Hello.Iface</code>接口，代码如下:</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">package</span> matt.thrifthello;</div><div class="line"></div><div class="line"><span class="keyword">import</span> org.apache.thrift.TException;</div><div class="line"></div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">HelloServiceImpl</span> <span class="keyword">implements</span> <span class="title">Hello</span>.<span class="title">Iface</span> </span>&#123;</div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">helloBoolean</span><span class="params">(<span class="keyword">boolean</span> para)</span> <span class="keyword">throws</span> TException </span>&#123;</div><div class="line">        System.out.printf(<span class="string">"hello true/false"</span>);</div><div class="line">        <span class="keyword">return</span> para;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">helloInt</span><span class="params">(<span class="keyword">int</span> para)</span> <span class="keyword">throws</span> TException </span>&#123;</div><div class="line">        System.out.println(<span class="string">"hello times: "</span> + para);</div><div class="line">        <span class="keyword">return</span> para;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">helloNull</span><span class="params">()</span> <span class="keyword">throws</span> TException </span>&#123;</div><div class="line">        System.out.println(<span class="string">"hello null"</span>);</div><div class="line">        <span class="keyword">return</span> <span class="keyword">null</span>;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">helloString</span><span class="params">(String para)</span> <span class="keyword">throws</span> TException </span>&#123;</div><div class="line">        System.out.println(<span class="string">"hello "</span> + para);</div><div class="line">        <span class="keyword">return</span> para;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">helloVoid</span><span class="params">()</span> <span class="keyword">throws</span> TException </span>&#123;</div><div class="line">        System.out.println(<span class="string">"Hello World"</span>);</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h4 id="3-服务端代码的实现"><a href="#3-服务端代码的实现" class="headerlink" title="3.服务端代码的实现"></a>3.服务端代码的实现</h4><p>下面来编写服务器端的代码</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">package</span> matt.thrifthello;</div><div class="line"></div><div class="line"><span class="keyword">import</span> org.apache.thrift.TProcessor;</div><div class="line"><span class="keyword">import</span> org.apache.thrift.server.TServer;</div><div class="line"><span class="keyword">import</span> org.apache.thrift.server.TThreadPoolServer;</div><div class="line"><span class="keyword">import</span> org.apache.thrift.transport.TServerSocket;</div><div class="line"><span class="keyword">import</span> org.apache.thrift.transport.TTransportException;</div><div class="line"></div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">HelloServiceServer</span> </span>&#123;</div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</div><div class="line">        <span class="keyword">try</span> &#123;</div><div class="line">            <span class="comment">// 设置服务端口为 9527</span></div><div class="line">            TServerSocket serverTransport = <span class="keyword">new</span> TServerSocket(<span class="number">9527</span>);</div><div class="line">            <span class="comment">// 关联处理器与 Hello 服务的实现</span></div><div class="line">            TProcessor processor = <span class="keyword">new</span> Hello.Processor(<span class="keyword">new</span> HelloServiceImpl());</div><div class="line">            TServer server = <span class="keyword">new</span> TThreadPoolServer(<span class="keyword">new</span> TThreadPoolServer.Args(serverTransport).processor(processor));</div><div class="line"></div><div class="line">            System.out.println(<span class="string">"Start server on port 9527..."</span>);</div><div class="line">            server.serve();</div><div class="line">        &#125; <span class="keyword">catch</span> (TTransportException e) &#123;</div><div class="line">            e.printStackTrace();</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h4 id="4-客户端的实现"><a href="#4-客户端的实现" class="headerlink" title="4.客户端的实现"></a>4.客户端的实现</h4><p>下面来编写客户端的代码：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">package</span> matt.thrifthello;</div><div class="line"></div><div class="line"><span class="keyword">import</span> org.apache.thrift.TException;</div><div class="line"><span class="keyword">import</span> org.apache.thrift.protocol.TBinaryProtocol;</div><div class="line"><span class="keyword">import</span> org.apache.thrift.protocol.TProtocol;</div><div class="line"><span class="keyword">import</span> org.apache.thrift.transport.TSocket;</div><div class="line"><span class="keyword">import</span> org.apache.thrift.transport.TTransport;</div><div class="line"><span class="keyword">import</span> org.apache.thrift.transport.TTransportException;</div><div class="line"></div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">HelloServiceClient</span> </span>&#123;</div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</div><div class="line">        <span class="keyword">try</span> &#123;</div><div class="line">            <span class="comment">// 设置调用的服务地址为本地，端口为 9527</span></div><div class="line">            TTransport transport = <span class="keyword">new</span> TSocket(<span class="string">"localhost"</span>, <span class="number">9527</span>);</div><div class="line">            transport.open();</div><div class="line">            <span class="comment">// 设置传输协议为 TBinaryProtocol</span></div><div class="line">            TProtocol protocol = <span class="keyword">new</span> TBinaryProtocol(transport);</div><div class="line">            Hello.Client client = <span class="keyword">new</span> Hello.Client(protocol);</div><div class="line">            <span class="comment">// 调用服务的 helloVoid 方法，向server发送数据</span></div><div class="line">            client.helloVoid();</div><div class="line"></div><div class="line">            transport.close();</div><div class="line">        &#125; <span class="keyword">catch</span> (TTransportException e) &#123;</div><div class="line">            e.printStackTrace();</div><div class="line">        &#125; <span class="keyword">catch</span> (TException e) &#123;</div><div class="line">            e.printStackTrace();</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h4 id="运行"><a href="#运行" class="headerlink" title="运行"></a>运行</h4><p>代码完成后，可以先运行<code>HelloServiceServer</code>（会一直运行，需要手动关闭），然后再运行<code>HelloServiceClient</code>（调用一次<code>helloVoid()</code>方法之后，就会退出，不过可以重复运行，这样就可以在server端看到多次输出了），就可以在<code>HelloServiceServer</code>的输出结果中看到客户端打印的<code>Hello World</code>字符串。</p>
<h3 id="Thrift之Account"><a href="#Thrift之Account" class="headerlink" title="Thrift之Account"></a>Thrift之Account</h3><p>本例是关于用户帐号的示例，会涉及到用户帐号的添加登陆注册以及查询等，详细的代码参考<a href="https://github.com/wangzzu/java_learn/tree/master/thrift/src/main/java/matt/thrift/account" target="_blank" rel="external">Thrift_Account</a>.</p>
<h4 id="1-接口定义-1"><a href="#1-接口定义-1" class="headerlink" title="1.接口定义"></a>1.接口定义</h4><p>这里我们编写一个thrift文件，定义服务接口，先定义一个操作状态有两种选项登陆或者注册；然后定一个结构体User，它有四个属性；再声明一个自定义的异常类，最后定义服务接口的一些方法。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div></pre></td><td class="code"><pre><div class="line">namespace java matt.thrift.account</div><div class="line"></div><div class="line">enum Operation&#123;</div><div class="line">	LOGIN=1,</div><div class="line">	REGISTER=2</div><div class="line">&#125;</div><div class="line"></div><div class="line">struct User&#123;</div><div class="line">	1: required i32 userId,</div><div class="line">	2: required string username,</div><div class="line">	3: required string password,</div><div class="line">	4: Operation op</div><div class="line">&#125;</div><div class="line"></div><div class="line">exception InvalidOperation&#123;</div><div class="line">	1: i32 code,</div><div class="line">	2: string reason</div><div class="line">&#125;</div><div class="line"></div><div class="line">service Account&#123;</div><div class="line">	void addUser(1:User user) throws (1: InvalidOperation e)</div><div class="line">	User queryUser(1:i32 id)</div><div class="line">	list&lt;User&gt; queryUserList()</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>接着对Thrift对文件进行编译，产生对应的程序文件，以Java为例。</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">thrift —gen java Account.thrift</div></pre></td></tr></table></figure>
<p>命令执行完成后，就会在<code>gen-java/matt/thrift/account</code>生成多个java的文件，将这些java文件放到<code>matt/thrift/account</code>中。</p>
<h4 id="2-接口实现-1"><a href="#2-接口实现-1" class="headerlink" title="2.接口实现"></a>2.接口实现</h4><p>这里定义<code>AccountService</code>类来实现<code>Account.Iface</code>接口，主要实现了三个方法。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">package</span> matt.thrift.account;</div><div class="line"></div><div class="line"><span class="keyword">import</span> java.util.ArrayList;</div><div class="line"><span class="keyword">import</span> java.util.HashMap;</div><div class="line"><span class="keyword">import</span> java.util.List;</div><div class="line"><span class="keyword">import</span> java.util.Map;</div><div class="line"></div><div class="line"><span class="keyword">import</span> org.apache.thrift.TException;</div><div class="line"></div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">AccountService</span> <span class="keyword">implements</span> <span class="title">Account</span>.<span class="title">Iface</span> </span>&#123;</div><div class="line">	<span class="keyword">private</span> <span class="keyword">static</span> Map&lt;String, String&gt; namePw = <span class="keyword">new</span> HashMap&lt;&gt;();</div><div class="line">	<span class="keyword">private</span> <span class="keyword">static</span> Map&lt;String, Integer&gt; nameId = <span class="keyword">new</span> HashMap&lt;&gt;();</div><div class="line">	<span class="keyword">private</span> <span class="keyword">static</span> Map&lt;String, Operation&gt; nameOp = <span class="keyword">new</span> HashMap&lt;&gt;();</div><div class="line">	<span class="keyword">private</span> <span class="keyword">static</span> Map&lt;Integer, String&gt; idname = <span class="keyword">new</span> HashMap&lt;&gt;();</div><div class="line"></div><div class="line">	<span class="meta">@Override</span></div><div class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">addUser</span><span class="params">(User user)</span> <span class="keyword">throws</span> TException </span>&#123;</div><div class="line">		<span class="keyword">int</span> id = user.getUserId();</div><div class="line">		String name = user.getUsername();</div><div class="line">		String pass = user.getPassword();</div><div class="line">		Operation op = user.getOp();</div><div class="line"></div><div class="line">		<span class="keyword">if</span> (name == <span class="keyword">null</span> || name.length() == <span class="number">0</span>) &#123;</div><div class="line">			<span class="keyword">throw</span> <span class="keyword">new</span> InvalidOperation(<span class="number">100</span>, <span class="string">"The name should not be empty!"</span>);</div><div class="line">		&#125;</div><div class="line">		<span class="keyword">if</span> (namePw.containsKey(name)) &#123;</div><div class="line">			<span class="keyword">throw</span> <span class="keyword">new</span> InvalidOperation(<span class="number">101</span>, <span class="string">"The name has been used, please change the name!"</span>);</div><div class="line">		&#125;</div><div class="line">		<span class="keyword">if</span> (nameId.containsValue(id) || id &lt;= <span class="number">0</span>) &#123;</div><div class="line">			<span class="keyword">throw</span> <span class="keyword">new</span> InvalidOperation(<span class="number">102</span>, <span class="string">"The id has been used or the id is invalid, please change the id!"</span>);</div><div class="line">		&#125;</div><div class="line"></div><div class="line">		<span class="keyword">if</span> (op == Operation.LOGIN) &#123;</div><div class="line">			String password = namePw.get(name);</div><div class="line">			<span class="keyword">if</span> (password != <span class="keyword">null</span> &amp;&amp; password.equals(pass)) &#123;</div><div class="line">				System.out.println(<span class="string">"Login success!! Hello "</span> + name);</div><div class="line">			&#125; <span class="keyword">else</span> &#123;</div><div class="line">				System.out.println(<span class="string">"Login failed!! please check your username and password"</span>);</div><div class="line">			&#125;</div><div class="line">		&#125; <span class="keyword">else</span> <span class="keyword">if</span> (op == Operation.REGISTER) &#123;</div><div class="line">			<span class="keyword">if</span> (namePw.containsKey(name)) &#123;</div><div class="line">				System.out.println(<span class="string">"The username "</span> + name + <span class="string">" has been registered, please change one."</span>);</div><div class="line">			&#125; <span class="keyword">else</span> &#123;</div><div class="line">				namePw.put(name, pass);</div><div class="line">				nameId.put(name, id);</div><div class="line">				nameOp.put(name, op);</div><div class="line">				idname.put(id, name);</div><div class="line">				System.out.println(<span class="string">"Register success!! Hello "</span> + name);</div><div class="line">			&#125;</div><div class="line">		&#125; <span class="keyword">else</span> &#123;</div><div class="line">			<span class="keyword">throw</span> <span class="keyword">new</span> InvalidOperation(<span class="number">103</span>, <span class="string">"unknown operation: "</span> + op.getValue());</div><div class="line">		&#125;</div><div class="line">	&#125;</div><div class="line"></div><div class="line">	<span class="meta">@Override</span></div><div class="line">	<span class="function"><span class="keyword">public</span> User <span class="title">queryUser</span><span class="params">(<span class="keyword">int</span> id)</span> <span class="keyword">throws</span> TException </span>&#123;</div><div class="line">		System.out.println(id);</div><div class="line">		<span class="keyword">if</span> (idname.containsKey(id)) &#123;</div><div class="line">			User user = <span class="keyword">new</span> User();</div><div class="line">			user.userId = id;</div><div class="line">			String name = idname.get(id);</div><div class="line">			user.username = name;</div><div class="line">			user.password = namePw.get(name);</div><div class="line">			user.op = nameOp.get(name);</div><div class="line">			<span class="keyword">return</span> user;</div><div class="line">		&#125; <span class="keyword">else</span> &#123;</div><div class="line">			System.out.println(<span class="string">"The id: "</span> + id + <span class="string">" does not exist!"</span>);</div><div class="line">			User user = <span class="keyword">new</span> User();</div><div class="line">			user.userId = <span class="number">0</span>;</div><div class="line">			user.username = <span class="string">""</span>;</div><div class="line">			user.password = <span class="string">"123456"</span>;</div><div class="line">			user.op = Operation.LOGIN;</div><div class="line">			<span class="keyword">return</span> user;</div><div class="line">		&#125;</div><div class="line">	&#125;</div><div class="line"></div><div class="line">	<span class="meta">@Override</span></div><div class="line">	<span class="function"><span class="keyword">public</span> List&lt;User&gt; <span class="title">queryUserList</span><span class="params">()</span> <span class="keyword">throws</span> TException </span>&#123;</div><div class="line">		List&lt;User&gt; list = <span class="keyword">new</span> ArrayList&lt;User&gt;();</div><div class="line">		<span class="keyword">for</span> (String name : namePw.keySet()) &#123;</div><div class="line">			User user = <span class="keyword">new</span> User();</div><div class="line">			user.userId = nameId.get(name);</div><div class="line">			user.username = name;</div><div class="line">			user.password = namePw.get(name);</div><div class="line">			user.op = nameOp.get(name);</div><div class="line">			list.add(user);</div><div class="line">		&#125;</div><div class="line">		<span class="keyword">return</span> list;</div><div class="line">	&#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h4 id="3-服务端代码的实现-1"><a href="#3-服务端代码的实现-1" class="headerlink" title="3.服务端代码的实现"></a>3.服务端代码的实现</h4><p>这里是服务器端的实现，主要使用多种方式来实现，这几种方式实现的差别是使用API的不同。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div><div class="line">113</div><div class="line">114</div><div class="line">115</div><div class="line">116</div><div class="line">117</div><div class="line">118</div><div class="line">119</div><div class="line">120</div><div class="line">121</div><div class="line">122</div><div class="line">123</div><div class="line">124</div><div class="line">125</div><div class="line">126</div><div class="line">127</div><div class="line">128</div><div class="line">129</div><div class="line">130</div><div class="line">131</div><div class="line">132</div><div class="line">133</div><div class="line">134</div><div class="line">135</div><div class="line">136</div><div class="line">137</div><div class="line">138</div><div class="line">139</div><div class="line">140</div><div class="line">141</div><div class="line">142</div><div class="line">143</div><div class="line">144</div><div class="line">145</div><div class="line">146</div><div class="line">147</div><div class="line">148</div><div class="line">149</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">package</span> matt.thrift.account;</div><div class="line"></div><div class="line"><span class="keyword">import</span> org.apache.thrift.TProcessor;</div><div class="line"><span class="keyword">import</span> org.apache.thrift.protocol.TBinaryProtocol;</div><div class="line"><span class="keyword">import</span> org.apache.thrift.protocol.TCompactProtocol;</div><div class="line"><span class="keyword">import</span> org.apache.thrift.server.THsHaServer;</div><div class="line"><span class="keyword">import</span> org.apache.thrift.server.TNonblockingServer;</div><div class="line"><span class="keyword">import</span> org.apache.thrift.server.TServer;</div><div class="line"><span class="keyword">import</span> org.apache.thrift.server.TSimpleServer;</div><div class="line"><span class="keyword">import</span> org.apache.thrift.server.TThreadPoolServer;</div><div class="line"><span class="keyword">import</span> org.apache.thrift.transport.TFramedTransport;</div><div class="line"><span class="keyword">import</span> org.apache.thrift.transport.TNonblockingServerSocket;</div><div class="line"><span class="keyword">import</span> org.apache.thrift.transport.TNonblockingServerTransport;</div><div class="line"><span class="keyword">import</span> org.apache.thrift.transport.TServerSocket;</div><div class="line"><span class="keyword">import</span> org.apache.thrift.transport.TTransportException;</div><div class="line"></div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">AccountServer</span> </span>&#123;</div><div class="line">	<span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">int</span> port = <span class="number">8090</span>;</div><div class="line"></div><div class="line">	<span class="comment">/**</span></div><div class="line">	 * 简单服务器类型 阻塞单线程</div><div class="line">	 *</div><div class="line">	 * <span class="doctag">@author</span> matt</div><div class="line">	 * <span class="doctag">@since</span> Apr 7, 2016</div><div class="line">	 * <span class="doctag">@throws</span> 无</div><div class="line">	 *             void</div><div class="line">	 */</div><div class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">startSimpleServer</span><span class="params">()</span> </span>&#123;</div><div class="line">		TProcessor tprocessor = <span class="keyword">new</span> Account.Processor(<span class="keyword">new</span> AccountService());</div><div class="line">		<span class="keyword">try</span> &#123;</div><div class="line">			<span class="comment">// 创建trsnaport 阻塞通信</span></div><div class="line">			TServerSocket serverTransport = <span class="keyword">new</span> TServerSocket(port);</div><div class="line">			<span class="comment">// 创建protocol</span></div><div class="line">			TBinaryProtocol.Factory protocol = <span class="keyword">new</span> TBinaryProtocol.Factory();</div><div class="line">			<span class="comment">// 将processor transport protocol设入到服务器server中</span></div><div class="line">			TServer.Args args = <span class="keyword">new</span> TServer.Args(serverTransport);</div><div class="line">			args.processor(tprocessor);</div><div class="line">			args.protocolFactory(protocol);</div><div class="line">			<span class="comment">// 定义服务器类型 设定参数</span></div><div class="line">			TServer server = <span class="keyword">new</span> TSimpleServer(args);</div><div class="line">			<span class="comment">// 开启服务</span></div><div class="line">			System.out.println(<span class="string">"Starting the Account server..."</span>);</div><div class="line">			server.serve();</div><div class="line">		&#125; <span class="keyword">catch</span> (TTransportException e) &#123;</div><div class="line">			<span class="comment">// TODO Auto-generated catch block</span></div><div class="line">			e.printStackTrace();</div><div class="line">		&#125;</div><div class="line">	&#125;</div><div class="line"></div><div class="line">	<span class="comment">/**</span></div><div class="line">	 * 多线程服务器 阻塞多线程</div><div class="line">	 *</div><div class="line">	 * <span class="doctag">@author</span> matt</div><div class="line">	 * <span class="doctag">@since</span> Apr 7, 2016</div><div class="line">	 * <span class="doctag">@throws</span> 无</div><div class="line">	 *             void</div><div class="line">	 */</div><div class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">startThreadPoolServer</span><span class="params">()</span> </span>&#123;</div><div class="line">		<span class="comment">// 创建processor</span></div><div class="line">		TProcessor tprocessor = <span class="keyword">new</span> Account.Processor(<span class="keyword">new</span> AccountService());</div><div class="line">		<span class="keyword">try</span> &#123;</div><div class="line">			<span class="comment">// 创建transport 阻塞通信</span></div><div class="line">			TServerSocket serverTransport = <span class="keyword">new</span> TServerSocket(port);</div><div class="line">			<span class="comment">// 创建protocol 数据传输协议</span></div><div class="line">			TBinaryProtocol.Factory protocol = <span class="keyword">new</span> TBinaryProtocol.Factory();</div><div class="line">			TThreadPoolServer.Args args = <span class="keyword">new</span> TThreadPoolServer.Args(serverTransport);</div><div class="line">			args.processor(tprocessor);</div><div class="line">			args.protocolFactory(protocol);</div><div class="line">			<span class="comment">// 创建服务器类型 多线程</span></div><div class="line">			TServer server = <span class="keyword">new</span> TThreadPoolServer(args);</div><div class="line">			<span class="comment">// 开启服务</span></div><div class="line">			System.out.println(<span class="string">"Starting the Account server..."</span>);</div><div class="line">			server.serve();</div><div class="line">		&#125; <span class="keyword">catch</span> (Exception e) &#123;</div><div class="line">			e.printStackTrace();</div><div class="line">		&#125;</div><div class="line">	&#125;</div><div class="line"></div><div class="line">	<span class="comment">/**</span></div><div class="line">	 * 非阻塞I/O</div><div class="line">	 *</div><div class="line">	 * <span class="doctag">@author</span> matt</div><div class="line">	 * <span class="doctag">@since</span> Apr 7, 2016</div><div class="line">	 * <span class="doctag">@throws</span> 无</div><div class="line">	 *             void</div><div class="line">	 */</div><div class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">startTNonblockingServer</span><span class="params">()</span> </span>&#123;</div><div class="line">		<span class="comment">// 创建processor</span></div><div class="line">		TProcessor tprocessor = <span class="keyword">new</span> Account.Processor(<span class="keyword">new</span> AccountService());</div><div class="line">		<span class="keyword">try</span> &#123;</div><div class="line">			<span class="comment">// 创建transport 非阻塞 nonblocking</span></div><div class="line">			TNonblockingServerTransport serverTransport = <span class="keyword">new</span> TNonblockingServerSocket(port);</div><div class="line">			<span class="comment">// 创建protocol 数据传输协议</span></div><div class="line">			TCompactProtocol.Factory protocol = <span class="keyword">new</span> TCompactProtocol.Factory();</div><div class="line">			<span class="comment">// 创建transport 数据传输方式 非阻塞需要用这种方式传输</span></div><div class="line">			TFramedTransport.Factory transport = <span class="keyword">new</span> TFramedTransport.Factory();</div><div class="line">			TNonblockingServer.Args args = <span class="keyword">new</span> TNonblockingServer.Args(serverTransport);</div><div class="line">			args.processor(tprocessor);</div><div class="line">			args.transportFactory(transport);</div><div class="line">			args.protocolFactory(protocol);</div><div class="line">			<span class="comment">// 创建服务器 类型是非阻塞</span></div><div class="line">			TServer server = <span class="keyword">new</span> TNonblockingServer(args);</div><div class="line">			<span class="comment">// 开启服务</span></div><div class="line">			System.out.println(<span class="string">"Starting the Account server..."</span>);</div><div class="line">			server.serve();</div><div class="line">		&#125; <span class="keyword">catch</span> (Exception e) &#123;</div><div class="line">			e.printStackTrace();</div><div class="line">		&#125;</div><div class="line">	&#125;</div><div class="line"></div><div class="line">	<span class="comment">/**</span></div><div class="line">	 * 半同步半异步的非阻塞I/O</div><div class="line">	 */</div><div class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">startTHsHaServer</span><span class="params">()</span> </span>&#123;</div><div class="line">		<span class="comment">// 创建processor</span></div><div class="line">		TProcessor tprocessor = <span class="keyword">new</span> Account.Processor(<span class="keyword">new</span> AccountService());</div><div class="line">		<span class="keyword">try</span> &#123;</div><div class="line">			<span class="comment">// 创建transport 非阻塞</span></div><div class="line">			TNonblockingServerTransport serverTransport = <span class="keyword">new</span> TNonblockingServerSocket(port);</div><div class="line">			<span class="comment">// 非阻塞需要的传输方式</span></div><div class="line">			TFramedTransport.Factory transport = <span class="keyword">new</span> TFramedTransport.Factory();</div><div class="line">			<span class="comment">// 数据传输协议</span></div><div class="line">			TCompactProtocol.Factory protocol = <span class="keyword">new</span> TCompactProtocol.Factory();</div><div class="line">			<span class="comment">// 创建半同步半异步服务</span></div><div class="line">			THsHaServer.Args args = <span class="keyword">new</span> THsHaServer.Args(serverTransport);</div><div class="line">			args.processor(tprocessor);</div><div class="line">			args.transportFactory(transport);</div><div class="line">			args.protocolFactory(protocol);</div><div class="line">			<span class="comment">// 创建 服务类型</span></div><div class="line">			TServer server = <span class="keyword">new</span> THsHaServer(args);</div><div class="line">			<span class="comment">// 开启服务</span></div><div class="line">			System.out.println(<span class="string">"Starting the Account server..."</span>);</div><div class="line">			server.serve();</div><div class="line">		&#125; <span class="keyword">catch</span> (Exception e) &#123;</div><div class="line">			e.printStackTrace();</div><div class="line">		&#125;</div><div class="line">	&#125;</div><div class="line"></div><div class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String args[])</span> </span>&#123;</div><div class="line">		<span class="comment">// 开启简单服务器</span></div><div class="line">		<span class="comment">// AccountServer.startSimpleServer();</span></div><div class="line">		<span class="comment">// 开启多线程服务器</span></div><div class="line">		<span class="comment">// AccountServer.startThreadPoolServer();</span></div><div class="line">		<span class="comment">// 非阻塞I/O</span></div><div class="line">		AccountServer.startTNonblockingServer();</div><div class="line">		<span class="comment">// 半同步半异步的非阻塞I/O</span></div><div class="line">		<span class="comment">// AccountServer.startTHsHaServer();</span></div><div class="line">	&#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h4 id="4-客户端的实现-1"><a href="#4-客户端的实现-1" class="headerlink" title="4.客户端的实现"></a>4.客户端的实现</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div><div class="line">113</div><div class="line">114</div><div class="line">115</div><div class="line">116</div><div class="line">117</div><div class="line">118</div><div class="line">119</div><div class="line">120</div><div class="line">121</div><div class="line">122</div><div class="line">123</div><div class="line">124</div><div class="line">125</div><div class="line">126</div><div class="line">127</div><div class="line">128</div><div class="line">129</div><div class="line">130</div><div class="line">131</div><div class="line">132</div><div class="line">133</div><div class="line">134</div><div class="line">135</div><div class="line">136</div><div class="line">137</div><div class="line">138</div><div class="line">139</div><div class="line">140</div><div class="line">141</div><div class="line">142</div><div class="line">143</div><div class="line">144</div><div class="line">145</div><div class="line">146</div><div class="line">147</div><div class="line">148</div><div class="line">149</div><div class="line">150</div><div class="line">151</div><div class="line">152</div><div class="line">153</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">package</span> matt.thrift.account;</div><div class="line"></div><div class="line"><span class="keyword">import</span> java.util.List;</div><div class="line"></div><div class="line"><span class="keyword">import</span> org.apache.thrift.protocol.TBinaryProtocol;</div><div class="line"><span class="keyword">import</span> org.apache.thrift.protocol.TCompactProtocol;</div><div class="line"><span class="keyword">import</span> org.apache.thrift.protocol.TProtocol;</div><div class="line"><span class="keyword">import</span> org.apache.thrift.transport.TFramedTransport;</div><div class="line"><span class="keyword">import</span> org.apache.thrift.transport.TSocket;</div><div class="line"><span class="keyword">import</span> org.apache.thrift.transport.TTransport;</div><div class="line"></div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">AccountClient</span> </span>&#123;</div><div class="line">	<span class="keyword">public</span> <span class="keyword">static</span> String ip = <span class="string">"localhost"</span>;</div><div class="line">	<span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">int</span> port = <span class="number">8090</span>;</div><div class="line">	<span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">int</span> time_out = <span class="number">30000</span>;</div><div class="line"></div><div class="line">	<span class="comment">/**</span></div><div class="line">	 * 使用阻塞式socket</div><div class="line">	 *</div><div class="line">	 * <span class="doctag">@author</span> matt</div><div class="line">	 * <span class="doctag">@since</span> Apr 7, 2016</div><div class="line">	 * <span class="doctag">@throws</span> 无</div><div class="line">	 *             void</div><div class="line">	 */</div><div class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">startSimpleClient</span><span class="params">()</span> </span>&#123;</div><div class="line">		TTransport transport = <span class="keyword">null</span>;</div><div class="line">		<span class="keyword">try</span> &#123;</div><div class="line">			<span class="comment">// 创建Transport</span></div><div class="line">			transport = <span class="keyword">new</span> TSocket(ip, port, time_out);</div><div class="line">			<span class="comment">// 创建TProtocol</span></div><div class="line">			TProtocol protocol = <span class="keyword">new</span> TBinaryProtocol(transport);</div><div class="line">			<span class="comment">// 基于TTransport和TProtocol创建Client</span></div><div class="line">			Account.Client client = <span class="keyword">new</span> Account.Client(protocol);</div><div class="line">			transport.open();</div><div class="line"></div><div class="line">			<span class="comment">// 正常添加用户</span></div><div class="line">			User user1 = <span class="keyword">new</span> User(<span class="number">001</span>, <span class="string">"matt1"</span>, <span class="string">"123456"</span>, Operation.REGISTER);</div><div class="line">			client.addUser(user1);</div><div class="line">			User user2 = <span class="keyword">new</span> User(<span class="number">002</span>, <span class="string">"matt2"</span>, <span class="string">"123456"</span>, Operation.REGISTER);</div><div class="line">			client.addUser(user2);</div><div class="line">			User user3 = <span class="keyword">new</span> User(<span class="number">003</span>, <span class="string">"matt3"</span>, <span class="string">"123456"</span>, Operation.REGISTER);</div><div class="line">			client.addUser(user3);</div><div class="line">			User user4 = <span class="keyword">new</span> User(<span class="number">004</span>, <span class="string">"matt4"</span>, <span class="string">"123456"</span>, Operation.REGISTER);</div><div class="line">			client.addUser(user4);</div><div class="line">			User user5 = <span class="keyword">new</span> User(<span class="number">005</span>, <span class="string">"matt5"</span>, <span class="string">"123456"</span>, Operation.REGISTER);</div><div class="line">			client.addUser(user5);</div><div class="line"></div><div class="line">			<span class="comment">// 查看全部用户</span></div><div class="line">			List&lt;User&gt; list = client.queryUserList();</div><div class="line">			System.out.println(<span class="string">"There are "</span> + list.size() + <span class="string">" users in total."</span>);</div><div class="line">			<span class="keyword">for</span> (User user : list) &#123;</div><div class="line">				System.out.println(user.userId + <span class="string">" "</span> + user.username + <span class="string">" "</span> + user.password);</div><div class="line">			&#125;</div><div class="line">			<span class="comment">// 查询用户</span></div><div class="line">			User userq1 = client.queryUser(<span class="number">1</span>);</div><div class="line">			<span class="keyword">if</span> (userq1 != <span class="keyword">null</span>) &#123;</div><div class="line">				System.out.println(<span class="string">"Query: "</span> + userq1.userId + <span class="string">" "</span> + userq1.username + <span class="string">" "</span> + userq1.password);</div><div class="line">			&#125; <span class="keyword">else</span> &#123;</div><div class="line">				System.out.println(<span class="string">"The id: 1 does not exist!"</span>);</div><div class="line">			&#125;</div><div class="line">			User userq2 = client.queryUser(<span class="number">8</span>);</div><div class="line">			<span class="keyword">if</span> (userq2 != <span class="keyword">null</span>) &#123;</div><div class="line">				System.out.println(<span class="string">"Query: "</span> + userq2.userId + <span class="string">" "</span> + userq2.username + <span class="string">" "</span> + userq2.password);</div><div class="line">			&#125; <span class="keyword">else</span> &#123;</div><div class="line">				System.out.println(<span class="string">"The id: 8 does not exist!"</span>);</div><div class="line">			&#125;</div><div class="line"></div><div class="line">			<span class="comment">// 登陆用户</span></div><div class="line">			User users = <span class="keyword">new</span> User(<span class="number">005</span>, <span class="string">"matt5"</span>, <span class="string">"123456"</span>, Operation.LOGIN);</div><div class="line">			client.addUser(users);</div><div class="line"></div><div class="line">			<span class="comment">// 添加异常用户</span></div><div class="line">			User user6 = <span class="keyword">new</span> User(<span class="number">006</span>, <span class="string">""</span>, <span class="string">"123456"</span>, Operation.REGISTER);<span class="comment">// name=null</span></div><div class="line">			client.addUser(user6);</div><div class="line">			User user7 = <span class="keyword">new</span> User(<span class="number">006</span>, <span class="string">"matt1"</span>, <span class="string">"123456"</span>, Operation.REGISTER);<span class="comment">// name存在</span></div><div class="line">			client.addUser(user7);</div><div class="line">			User user8 = <span class="keyword">new</span> User(<span class="number">005</span>, <span class="string">"matt6"</span>, <span class="string">"123456"</span>, Operation.REGISTER);<span class="comment">// id异常</span></div><div class="line">			client.addUser(user8);</div><div class="line">		&#125; <span class="keyword">catch</span> (Exception e) &#123;</div><div class="line">			e.printStackTrace();</div><div class="line">		&#125;</div><div class="line">	&#125;</div><div class="line"></div><div class="line">	<span class="comment">/**</span></div><div class="line">	 * 非阻塞</div><div class="line">	 *</div><div class="line">	 * <span class="doctag">@author</span> matt</div><div class="line">	 * <span class="doctag">@since</span> Apr 7, 2016</div><div class="line">	 * <span class="doctag">@throws</span> 无</div><div class="line">	 *             void</div><div class="line">	 */</div><div class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">startNonblockingClient</span><span class="params">()</span> </span>&#123;</div><div class="line">		TTransport transport = <span class="keyword">null</span>;</div><div class="line">		<span class="keyword">try</span> &#123;</div><div class="line">			transport = <span class="keyword">new</span> TFramedTransport(<span class="keyword">new</span> TSocket(ip, port));</div><div class="line">			TCompactProtocol protocol = <span class="keyword">new</span> TCompactProtocol(transport);</div><div class="line">			Account.Client client = <span class="keyword">new</span> Account.Client(protocol);</div><div class="line">			transport.open();</div><div class="line"></div><div class="line">			<span class="comment">// 正常添加用户</span></div><div class="line">			User user1 = <span class="keyword">new</span> User(<span class="number">001</span>, <span class="string">"matt1"</span>, <span class="string">"123456"</span>, Operation.REGISTER);</div><div class="line">			client.addUser(user1);</div><div class="line">			User user2 = <span class="keyword">new</span> User(<span class="number">002</span>, <span class="string">"matt2"</span>, <span class="string">"123456"</span>, Operation.REGISTER);</div><div class="line">			client.addUser(user2);</div><div class="line">			User user3 = <span class="keyword">new</span> User(<span class="number">003</span>, <span class="string">"matt3"</span>, <span class="string">"123456"</span>, Operation.REGISTER);</div><div class="line">			client.addUser(user3);</div><div class="line">			User user4 = <span class="keyword">new</span> User(<span class="number">004</span>, <span class="string">"matt4"</span>, <span class="string">"123456"</span>, Operation.REGISTER);</div><div class="line">			client.addUser(user4);</div><div class="line">			User user5 = <span class="keyword">new</span> User(<span class="number">005</span>, <span class="string">"matt5"</span>, <span class="string">"123456"</span>, Operation.REGISTER);</div><div class="line">			client.addUser(user5);</div><div class="line"></div><div class="line">			<span class="comment">// 查看全部用户</span></div><div class="line">			List&lt;User&gt; list = client.queryUserList();</div><div class="line">			System.out.println(<span class="string">"There are "</span> + list.size() + <span class="string">" users in total."</span>);</div><div class="line">			<span class="keyword">for</span> (User user : list) &#123;</div><div class="line">				System.out.println(user.userId + <span class="string">" "</span> + user.username + <span class="string">" "</span> + user.password);</div><div class="line">			&#125;</div><div class="line"></div><div class="line">			<span class="comment">// 查询用户</span></div><div class="line">			User userq1 = client.queryUser(<span class="number">1</span>);</div><div class="line">			<span class="keyword">if</span> (!userq1.username.equals(<span class="string">""</span>)) &#123;</div><div class="line">				System.out.println(<span class="string">"Query: "</span> + userq1.userId + <span class="string">" "</span> + userq1.username + <span class="string">" "</span> + userq1.password);</div><div class="line">			&#125; <span class="keyword">else</span> &#123;</div><div class="line">				System.out.println(<span class="string">"The id: 1 does not exist!"</span>);</div><div class="line">			&#125;</div><div class="line">			User userq2 = client.queryUser(<span class="number">8</span>);</div><div class="line">			<span class="keyword">if</span> (!userq2.username.equals(<span class="string">""</span>)) &#123;</div><div class="line">				System.out.println(<span class="string">"Query: "</span> + userq2.userId + <span class="string">" "</span> + userq2.username + <span class="string">" "</span> + userq2.password);</div><div class="line">			&#125; <span class="keyword">else</span> &#123;</div><div class="line">				System.out.println(<span class="string">"The id: 8 does not exist!"</span>);</div><div class="line">			&#125;</div><div class="line"></div><div class="line">			<span class="comment">// 登陆用户</span></div><div class="line">			User users = <span class="keyword">new</span> User(<span class="number">005</span>, <span class="string">"matt5"</span>, <span class="string">"123456"</span>, Operation.LOGIN);</div><div class="line">			client.addUser(users);</div><div class="line"></div><div class="line">			<span class="comment">// 添加异常用户</span></div><div class="line">			User user6 = <span class="keyword">new</span> User(<span class="number">006</span>, <span class="string">""</span>, <span class="string">"123456"</span>, Operation.REGISTER);<span class="comment">// name=null</span></div><div class="line">			client.addUser(user6);</div><div class="line">			User user7 = <span class="keyword">new</span> User(<span class="number">006</span>, <span class="string">"matt1"</span>, <span class="string">"123456"</span>, Operation.REGISTER);<span class="comment">// name存在</span></div><div class="line">			client.addUser(user7);</div><div class="line">			User user8 = <span class="keyword">new</span> User(<span class="number">005</span>, <span class="string">"matt6"</span>, <span class="string">"123456"</span>, Operation.REGISTER);<span class="comment">// id异常</span></div><div class="line">			client.addUser(user8);</div><div class="line">		&#125; <span class="keyword">catch</span> (Exception e) &#123;</div><div class="line">			e.printStackTrace();</div><div class="line">		&#125;</div><div class="line">	&#125;</div><div class="line"></div><div class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</div><div class="line">		<span class="comment">// AccountClient.startSimpleClient();</span></div><div class="line">		AccountClient.startNonblockingClient();</div><div class="line">	&#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h4 id="运行-1"><a href="#运行-1" class="headerlink" title="运行"></a>运行</h4><p>代码完成后，可以先运行<code>AccountServer</code>（会一直运行，需要手动关闭），然后再运行<code>AccountClient</code>。</p>
<p>上面程序服务器端的运行的结果为：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">Starting the Account server...</div><div class="line">Register success!! Hello matt1</div><div class="line">Register success!! Hello matt2</div><div class="line">Register success!! Hello matt3</div><div class="line">Register success!! Hello matt4</div><div class="line">Register success!! Hello matt5</div><div class="line">1</div><div class="line">8</div><div class="line">The id: 8 does not exist!</div></pre></td></tr></table></figure>
<p>客户端运行的结果为：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div></pre></td><td class="code"><pre><div class="line">There are 5 users in total.</div><div class="line">1 matt1 123456</div><div class="line">3 matt3 123456</div><div class="line">2 matt2 123456</div><div class="line">5 matt5 123456</div><div class="line">4 matt4 123456</div><div class="line">Query: 1 matt1 123456</div><div class="line">The id: 8 does not exist!</div><div class="line">InvalidOperation(code:101, reason:The name has been used, please change the name!)</div><div class="line">	at matt.thrift.account.Account$addUser_result$addUser_resultStandardScheme.read(Account.java:1165)</div><div class="line">	at matt.thrift.account.Account$addUser_result$addUser_resultStandardScheme.read(Account.java:1)</div><div class="line">	at matt.thrift.account.Account$addUser_result.read(Account.java:1101)</div><div class="line">	at org.apache.thrift.TServiceClient.receiveBase(TServiceClient.java:86)</div><div class="line">	at matt.thrift.account.Account$Client.recv_addUser(Account.java:93)</div><div class="line">	at matt.thrift.account.Account$Client.addUser(Account.java:80)</div><div class="line">	at matt.thrift.account.AccountClient.startNonblockingClient(AccountClient.java:135)</div><div class="line">	at matt.thrift.account.AccountClient.main(AccountClient.java:151)</div></pre></td></tr></table></figure>
<h2 id="Thrift结构"><a href="#Thrift结构" class="headerlink" title="Thrift结构"></a>Thrift结构</h2><p>Thrift包含了一个完整的堆栈结构用于构建客户端和服务器端，下面描述了Thrift的整体的架构。</p>
<p><img src="/images/2016-04-07-thrift/thrift.png" alt="selection_sort"></p>
<ul>
<li>黄色部分：是用户实现的业务逻辑；</li>
<li>褐色部分：是根据 Thrift 定义的服务接口描述文件生成的客户端和服务器端代码框架；</li>
<li>红色部分：是根据 Thrift 文件生成代码实现数据的读写操作；</li>
<li>TProtocol：是协议层, 定义数据传输格式，可以为二进制或者XML等；</li>
<li>TTransport：是传输层，定义数据传输方式，可以为TCP/IP传输，内存共享或者文件共享等。</li>
</ul>
<hr>
<p>参考：</p>
<ul>
<li><a href="https://thrift.apache.org/" target="_blank" rel="external">Apache Thrift</a></li>
<li><a href="http://thrift-tutorial.readthedocs.org/en/latest/index.html" target="_blank" rel="external">Thrift Tutorial</a></li>
<li><a href="http://dongxicheng.org/recommend/" target="_blank" rel="external">董的博客 五.Apache Thrift</a></li>
<li><a href="https://www.ibm.com/developerworks/cn/java/j-lo-apachethrift/" target="_blank" rel="external">Apache Thrift - 可伸缩的跨语言服务开发框架</a></li>
<li><a href="https://diwakergupta.github.io/thrift-missing-guide/" target="_blank" rel="external">Thrift: The Missing Guide</a></li>
<li><a href="http://zhaozhiming.github.io/blog/2015/01/25/hello-thrift/" target="_blank" rel="external">Apache Thrift的简单代码示例</a></li>
<li><a href="http://wuchong.me/blog/2015/10/07/thrift-induction/" target="_blank" rel="external">Thrift 入门</a></li>
</ul>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[从Jekyll转向Hexo]]></title>
      <url>http://matt33.com/2016/03/30/hexo-set/</url>
      <content type="html"><![CDATA[<p>之前的博客，是使用Jekyll搭建的，因为学过一些ruby，也会一些ruby on rails，所以对Jekyll有天生的好感，看不上wordpress、hexo之类的。不过后来当我看到了hexo的next主题时，被它的简洁所吸引，因此决定转向hexo，本文记录使用hexo构建博客的方法（PS；我只是一个搬运工，针对Linux用户而言）。</p>
<h2 id="Hexo"><a href="#Hexo" class="headerlink" title="Hexo"></a>Hexo</h2><p>Hexo 是一个快速、简洁且高效的博客框架。Hexo 使用 Markdown（或其他渲染引擎）解析文章，在几秒内，即可利用靓丽的主题生成静态网页。</p>
<h3 id="Hexo安装"><a href="#Hexo安装" class="headerlink" title="Hexo安装"></a>Hexo安装</h3><p>安装Hexo需要三步，需要安装以下三个部分：</p>
<ul>
<li>Git</li>
<li>Node.js</li>
<li>Hexo</li>
</ul>
<h4 id="Git"><a href="#Git" class="headerlink" title="Git"></a>Git</h4><p><a href="https://git-scm.com/downloads" target="_blank" rel="external">下载地址</a></p>
<ul>
<li>Linux (Ubuntu, Debian)：<code>sudo apt-get install git</code>;</li>
<li>Linux (Fedora, Red Hat, CentOS)：<code>sudo yum install git</code>;</li>
</ul>
<h4 id="Node-js"><a href="#Node-js" class="headerlink" title="Node.js"></a>Node.js</h4><p>安装Node.js的最佳方式是使用<a href="https://github.com/creationix/nvm" target="_blank" rel="external">nvm</a></p>
<p>nvm安装的两种方式：</p>
<ul>
<li>cURL: <code>$ curl https://raw.github.com/creationix/nvm/master/install.sh | sh</code>;</li>
<li>Wget: <code>$ wget -qO- https://raw.github.com/creationix/nvm/master/install.sh | sh</code>;</li>
</ul>
<p>安装完成后，重启终端并执行下列命令即可安装 Node.js。（<code>$</code>代表在当前普通用户下执行命令）</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ nvm install stable</div></pre></td></tr></table></figure>
<p>当然也可以通过<a href="https://nodejs.org/en/download/" target="_blank" rel="external">下载</a>安装。</p>
<blockquote>
<p>如果遇到 node 版本问题可以参考 <a href="https://stackoverflow.com/questions/11107594/nodejs-update-leaves-old-version-as-current" target="_blank" rel="external">Nodejs Update leaves old version as current</a>，直接输入 <code>nvm</code> 可以查看相应命令方法。</p>
</blockquote>
<h4 id="Hexo-1"><a href="#Hexo-1" class="headerlink" title="Hexo"></a>Hexo</h4><p>所有必备的应用程序安装完成后，即可使用 npm 安装 Hexo。</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ npm install -g hexo-cli</div></pre></td></tr></table></figure>
<p>到这里Hexo已经安装完毕了，下面讲一下如何使用。</p>
<h3 id="Hexo使用"><a href="#Hexo使用" class="headerlink" title="Hexo使用"></a>Hexo使用</h3><p>通过下列命令，Hexo会在指定文件夹中新建所需要的文件。</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">$ hexo init /home/matt/wangzzuB<span class="built_in">log</span></div><div class="line">$ <span class="built_in">cd</span> /home/matt/wangzzuB<span class="built_in">log</span></div><div class="line">$ npm install</div></pre></td></tr></table></figure>
<p>新建完成后，指定文件夹<code>/home/matt/wangzzuBlog</code>的目录如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">.</div><div class="line">├── _config.yml</div><div class="line">├── package.json</div><div class="line">├── scaffolds</div><div class="line">├── source</div><div class="line">|   ├── _drafts</div><div class="line">|   └── _posts</div><div class="line">└── themes</div></pre></td></tr></table></figure>
<p><strong><code>_config.yml</code></strong></p>
<p>它与Jekyll中的<code>_config.yml</code>功能类似，对博客网站进行一下配置。</p>
<p><strong><code>package.json</code></strong></p>
<p>这里面是安装的应用程序的信息，EJS, Stylus 和 Markdown renderer 已默认安装，我们可以自由移除。</p>
<figure class="highlight json"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div></pre></td><td class="code"><pre><div class="line">&#123;</div><div class="line">  <span class="attr">"name"</span>: <span class="string">"hexo-site"</span>,</div><div class="line">  <span class="attr">"version"</span>: <span class="string">"0.0.0"</span>,</div><div class="line">  <span class="attr">"private"</span>: <span class="literal">true</span>,</div><div class="line">  <span class="attr">"hexo"</span>: &#123;</div><div class="line">    <span class="attr">"version"</span>: <span class="string">""</span></div><div class="line">  &#125;,</div><div class="line">  <span class="attr">"dependencies"</span>: &#123;</div><div class="line">    <span class="attr">"hexo"</span>: <span class="string">"^3.0.0"</span>,</div><div class="line">    <span class="attr">"hexo-generator-archive"</span>: <span class="string">"^0.1.0"</span>,</div><div class="line">    <span class="attr">"hexo-generator-category"</span>: <span class="string">"^0.1.0"</span>,</div><div class="line">    <span class="attr">"hexo-generator-index"</span>: <span class="string">"^0.1.0"</span>,</div><div class="line">    <span class="attr">"hexo-generator-tag"</span>: <span class="string">"^0.1.0"</span>,</div><div class="line">    <span class="attr">"hexo-renderer-ejs"</span>: <span class="string">"^0.1.0"</span>,</div><div class="line">    <span class="attr">"hexo-renderer-stylus"</span>: <span class="string">"^0.2.0"</span>,</div><div class="line">    <span class="attr">"hexo-renderer-marked"</span>: <span class="string">"^0.2.4"</span>,</div><div class="line">    <span class="attr">"hexo-server"</span>: <span class="string">"^0.1.2"</span></div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p><strong><code>source</code></strong></p>
<p>资源文件夹是存放用户资源的地方。除 <code>_posts</code>文件夹之外，开头命名为 _ (下划线)的文件 / 文件夹和隐藏的文件将会被忽略。Markdown 和 HTML 文件会被解析并放到 public 文件夹，而其他文件会被拷贝过去。</p>
<p><strong><code>themes</code></strong></p>
<p><a href="https://hexo.io/themes/" target="_blank" rel="external">主题</a>文件夹，Hexo会根据主题来生成静态页面。</p>
<h3 id="Hexo配置"><a href="#Hexo配置" class="headerlink" title="Hexo配置"></a>Hexo配置</h3><p>这里可以参考<a href="https://hexo.io/zh-cn/docs/configuration.html" target="_blank" rel="external">Hexo中文文档</a>，这里讲述的非常详细。</p>
<h3 id="Hexo命令"><a href="#Hexo命令" class="headerlink" title="Hexo命令"></a>Hexo命令</h3><p>参考<a href="https://hexo.io/zh-cn/docs/commands.html" target="_blank" rel="external">Hexo 指令</a>。</p>
<h4 id="init"><a href="#init" class="headerlink" title="init"></a>init</h4><figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ hexo init [folder]</div></pre></td></tr></table></figure>
<p>新建一个网站。如果没有设置 <code>folder</code> ，Hexo 默认在目前的文件夹建立网站。</p>
<h4 id="new"><a href="#new" class="headerlink" title="new"></a>new</h4><figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ hexo new [layout] &lt;title&gt;</div></pre></td></tr></table></figure>
<p>新建一篇文章。如果没有设置 <code>layout</code> 的话，默认使用 <code>_config.yml</code> 中的 <code>default_layout</code> 参数代替。如果标题包含空格的话，请使用引号括起来。</p>
<p>草稿的使用：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">$ hexo new draft <span class="string">"new draft"</span> <span class="comment">#新建草稿</span></div><div class="line">$ hexo publish [layout] &lt;title&gt; <span class="comment">#变成正式文章</span></div></pre></td></tr></table></figure>
<h4 id="generate"><a href="#generate" class="headerlink" title="generate"></a>generate</h4><figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">$ hexo generate</div><div class="line">$ hexo g</div></pre></td></tr></table></figure>
<p>生成静态文件。</p>
<table>
<thead>
<tr>
<th>选项</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td>-d, –deploy</td>
<td>文件生成后立即部署网站</td>
</tr>
<tr>
<td>-w, –watch</td>
<td>监视文件变动</td>
</tr>
</tbody>
</table>
<h4 id="publish"><a href="#publish" class="headerlink" title="publish"></a>publish</h4><figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ hexo publish [layout] &lt;filename&gt;</div></pre></td></tr></table></figure>
<p>发表草稿。</p>
<h4 id="server"><a href="#server" class="headerlink" title="server"></a>server</h4><figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">$ hexo server</div><div class="line">$ hexo server -p 4040</div></pre></td></tr></table></figure>
<p>启动服务器。默认情况下，访问网址为： <a href="http://localhost:4000/。" target="_blank" rel="external">http://localhost:4000/。</a></p>
<table>
<thead>
<tr>
<th>选项</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td>-p, –port</td>
<td>重设端口</td>
</tr>
<tr>
<td>-s, –static</td>
<td>只使用静态文件</td>
</tr>
<tr>
<td>-l, –log</td>
<td>启动日记记录，使用覆盖记录格式</td>
</tr>
</tbody>
</table>
<h4 id="deploy"><a href="#deploy" class="headerlink" title="deploy"></a>deploy</h4><figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ hexo deploy</div></pre></td></tr></table></figure>
<p>部署网站。</p>
<table>
<thead>
<tr>
<th>参数</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td>-g, –generate</td>
<td>部署之前预先生成静态文件</td>
</tr>
</tbody>
</table>
<h4 id="render"><a href="#render" class="headerlink" title="render"></a>render</h4><figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ hexo render &lt;file1&gt; [file2] ...</div></pre></td></tr></table></figure>
<p>渲染文件。</p>
<table>
<thead>
<tr>
<th>参数</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td>-o, –output</td>
<td>设置输出路径</td>
</tr>
</tbody>
</table>
<h4 id="migrate"><a href="#migrate" class="headerlink" title="migrate"></a>migrate</h4><figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ hexo migrate &lt;<span class="built_in">type</span>&gt;</div></pre></td></tr></table></figure>
<p>从其他博客系统 迁移内容。</p>
<h4 id="clean"><a href="#clean" class="headerlink" title="clean"></a>clean</h4><figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ hexo clean</div></pre></td></tr></table></figure>
<p>清除缓存文件 (<code>db.json</code>) 和已生成的静态文件 (<code>public</code>)。</p>
<h4 id="list"><a href="#list" class="headerlink" title="list"></a>list</h4><figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ hexo list &lt;<span class="built_in">type</span>&gt;</div></pre></td></tr></table></figure>
<p>列出网站资料。</p>
<h4 id="version"><a href="#version" class="headerlink" title="version"></a>version</h4><figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ hexo version</div></pre></td></tr></table></figure>
<p>显示 Hexo 版本。</p>
<h2 id="Next主题"><a href="#Next主题" class="headerlink" title="Next主题"></a>Next主题</h2><p>Hexo博客的主题有很多种，可以参考<a href="https://hexo.io/themes/" target="_blank" rel="external">Themes</a>，个人比较喜欢Next主题，下面给出一些Next主题配置的一些资料，本文就不再详述了。</p>
<ul>
<li>Next主题的基本配置可以参考<a href="http://theme-next.iissnan.com/getting-started.html" target="_blank" rel="external">Next WIKI</a>，这个网站基本上讲述已经非常清晰了。</li>
<li>这个博文——<a href="http://www.arao.me/2015/hexo-next-theme-optimize-base/" target="_blank" rel="external">动动手指，NexT主题与Hexo更搭哦（基础篇）</a>配着图片进行讲述如何配置使用。</li>
<li>这篇介绍如何统计阅读量<a href="http://zhiho.github.io/2015/09/29/hexo-next/" target="_blank" rel="external">Hexo搭建GitHub博客（三）- NexT主题配置使用</a>。</li>
<li>这位博主由一系列关于Hexo配置的博文，非常推荐——<a href="http://www.arao.me/2015/hexo-next-theme-optimize-duoshuo/" target="_blank" rel="external">动动手指，给你的Hexo站点添加最近访客（多说篇）</a>。</li>
</ul>
<h2 id="Jekyll迁移到Hexo"><a href="#Jekyll迁移到Hexo" class="headerlink" title="Jekyll迁移到Hexo"></a>Jekyll迁移到Hexo</h2><p>把 <code>_posts</code> 文件夹内的所有文件复制到 <code>source/_posts</code> 文件夹，并在 <code>_config.yml</code> 中修改 <code>new_post_name</code> 参数。</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">new_post_name: :year-:month-:day-:title.md</div></pre></td></tr></table></figure>
<p>然后进行生成静态文件，部署网站即可。</p>
<h1 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h1><ul>
<li><a href="http://hanhailong.com/2015/10/08/Hexo%E2%80%94%E6%AD%A3%E7%A1%AE%E6%B7%BB%E5%8A%A0RSS%E8%AE%A2%E9%98%85/" target="_blank" rel="external">Hexo 正确添加 RSS 订阅</a></li>
</ul>
<hr>
<p>参考：</p>
<ul>
<li><a href="http://theme-next.iissnan.com/getting-started.html" target="_blank" rel="external">Next WIKI</a></li>
<li><a href="https://hexo.io/zh-cn/docs/index.html" target="_blank" rel="external">文档 | Hexo</a></li>
<li><a href="http://www.arao.me/2015/hexo-next-theme-optimize-base/" target="_blank" rel="external">动动手指，NexT主题与Hexo更搭哦（基础篇）</a></li>
<li><a href="http://zhiho.github.io/2015/09/29/hexo-next/" target="_blank" rel="external">Hexo搭建GitHub博客（三）- NexT主题配置使用</a></li>
<li><a href="http://www.arao.me/2015/hexo-next-theme-optimize-duoshuo/" target="_blank" rel="external">动动手指，给你的Hexo站点添加最近访客（多说篇）</a></li>
</ul>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[排序算法总结]]></title>
      <url>http://matt33.com/2016/03/26/algorithm-sort/</url>
      <content type="html"><![CDATA[<p>排序算法是算法中基础的部分，也是面试中经常被问到的地方。因此，根据对《算法》和《算法导论》关于这部分的学习，做一下总结，以后再遇到排序方面的问题就可以直接看一下博文就行了（文中算法用java实现）。</p>
<ul>
<li>选择排序</li>
<li>插入排序</li>
<li>希尔排序</li>
<li>冒泡排序</li>
<li>归并排序</li>
<li>快速排序</li>
<li>堆排序</li>
<li>计数排序</li>
<li>基数排序</li>
<li>桶排序</li>
</ul>
<h1 id="性能评估指标"><a href="#性能评估指标" class="headerlink" title="性能评估指标"></a>性能评估指标</h1><ol>
<li>运行时间：<strong>排序的成本模型</strong>：在研究排序算法时，需要计算比较和交换的数量，对于不交换元素的算法，我们会计算访问数组的次数。</li>
<li>额外的内存使用：排序算法分为两种：除了函数调用的栈和固定数目的实例变量之外无需额外内存的<code>原地排序算法</code>，以及需要额外内存空间存储另一份数组副本的其他排序算法。</li>
</ol>
<p>代码中使用基本方法的实现如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">boolean</span> <span class="title">less</span><span class="params">(Comparable v, Comparable w)</span></span>&#123;</div><div class="line">    <span class="keyword">return</span> v.compareTo(w) &lt; <span class="number">0</span>;</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">exch</span><span class="params">(Comparable[] a, <span class="keyword">int</span> i, <span class="keyword">int</span> j)</span></span>&#123;</div><div class="line">    Comparable tmp = a[i];</div><div class="line">    a[i] = a[j];</div><div class="line">    a[j] = tmp;</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">show</span><span class="params">(Comparable[] a)</span></span>&#123;</div><div class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; a.length; i++)</div><div class="line">        System.out.print(a[i] + <span class="string">" "</span>)</div><div class="line">    System.out.println();</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="comment">//默认按升序排列</span></div><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">boolean</span> <span class="title">isSorted</span><span class="params">(Comparable[] a)</span></span>&#123;</div><div class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">1</span>; i &lt; a.length; i++)&#123;</div><div class="line">        <span class="keyword">if</span>(less(a[i],a[i-<span class="number">1</span>]))</div><div class="line">            <span class="keyword">return</span> <span class="keyword">false</span>;</div><div class="line">        <span class="keyword">return</span> <span class="keyword">true</span>;</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h1 id="选择排序"><a href="#选择排序" class="headerlink" title="选择排序"></a>选择排序</h1><h2 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h2><p>首先在未排序序列中找到最小（大）元素，存放到排序序列的起始位置，然后，再从剩余未排序元素中继续寻找最小（大）元素，然后放到已排序序列的末尾。以此类推，直到所有元素均排序完毕。</p>
<h2 id="步骤"><a href="#步骤" class="headerlink" title="步骤"></a>步骤</h2><ol>
<li>先找到数组中最小的那个元素；</li>
<li>将它和数组中第一个元素交换位置（如果第一个元素是自己，和自己交换）；</li>
<li>在剩下的数组中找到最小的元素，将它和第二个元素交换位置，以此类推。</li>
</ol>
<h2 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">sort</span><span class="params">(Comparable[] a)</span> </span>&#123;</div><div class="line">    <span class="keyword">int</span> N = a.length;</div><div class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; N; i++) &#123;</div><div class="line">        <span class="keyword">int</span> min = i;</div><div class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> j = i + <span class="number">1</span>; j &lt; N; j++) &#123;</div><div class="line">            <span class="keyword">if</span> (less(a[j], a[min]))</div><div class="line">                min = j;</div><div class="line">        &#125;</div><div class="line">        exch(a, i, min);</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>完整代码参考<a href="https://github.com/wangzzu/algorithms/blob/master/Algorithms-4th/src/main/java/sort_two/Selection.java" target="_blank" rel="external">Selection.java</a></p>
<p>排序效果如下图所示（原图来自<a href="https://zh.wikipedia.org/wiki/%E9%80%89%E6%8B%A9%E6%8E%92%E5%BA%8F" target="_blank" rel="external">维基百科之选择排序</a>）</p>
<p><img src="/images/2016-03-26-sort/Selection_sort_animation.gif" alt="selection_sort"></p>
<h2 id="性能分析"><a href="#性能分析" class="headerlink" title="性能分析"></a>性能分析</h2><ul>
<li>复杂度分析：<ol>
<li>对于长度为$N$的数组，选择排序需要大约$\frac{N^2}{2}$次比较和$N$次交换；</li>
<li>最好的情况：已经有序，交换$0$次；</li>
<li>最坏的情况：逆序，交换$N-1$次。</li>
</ol>
</li>
<li>特点：<ol>
<li>运行时间与输入无关，即使对于一个有序数组，依然需要扫描全部元素而且运行时间与随机数组一样；</li>
<li>数据移动是最少的。交换次数与数组大小成线性关系。</li>
</ol>
</li>
</ul>
<h1 id="插入排序"><a href="#插入排序" class="headerlink" title="插入排序"></a>插入排序</h1><h2 id="原理-1"><a href="#原理-1" class="headerlink" title="原理"></a>原理</h2><p>通过构建有序序列，对于未排序数据，在已排序序列中从后向前扫描，找到相应位置并插入。</p>
<h2 id="步骤-1"><a href="#步骤-1" class="headerlink" title="步骤"></a>步骤</h2><ol>
<li>从第一个元素开始，该元素可以认为已经被排序；</li>
<li>取出下一个元素，在已经排序的元素序列中从后向前扫描；</li>
<li>如果被扫描的元素（已排序）大于新元素，将该元素后移一位；</li>
<li>重复步骤3，直到找到已排序的元素小于或者等于新元素的位置；</li>
<li>将新元素插入到该位置后；</li>
<li>重复步骤2~5。</li>
</ol>
<h2 id="实现-1"><a href="#实现-1" class="headerlink" title="实现"></a>实现</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">sort</span><span class="params">(Comparable[] a)</span> </span>&#123;</div><div class="line">    <span class="keyword">int</span> N = a.length;</div><div class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">1</span>; i &lt; N; i++) &#123;</div><div class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> j = i; j &gt; <span class="number">0</span>; j--) &#123;</div><div class="line">            <span class="keyword">if</span>(less(a[j], a[j - <span class="number">1</span>]))</div><div class="line">                exch(a, j, j - <span class="number">1</span>);</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>完整代码参考<a href="https://github.com/wangzzu/algorithms/blob/master/Algorithms-4th/src/main/java/sort_two/Insertion.java" target="_blank" rel="external">Insertion.java</a></p>
<p>排序效果如下图所示（原图来自<a href="https://zh.wikipedia.org/wiki/%E6%8F%92%E5%85%A5%E6%8E%92%E5%BA%8F" target="_blank" rel="external">维基百科之插入排序</a>）</p>
<p><img src="/images/2016-03-26-sort/Insertion_sort_animation.gif" alt="Insertion_sort"></p>
<h2 id="性能分析-1"><a href="#性能分析-1" class="headerlink" title="性能分析"></a>性能分析</h2><ul>
<li>复杂度分析：<ol>
<li>平均来说，插入排序的复杂度为$O(n^2)$;</li>
<li>最好的情况：已经有序，只需要比较操作$N-1$次即可；</li>
<li>最坏的情况：逆序，需要比较$\frac{N*(N-1)}{2}$次。</li>
</ol>
</li>
<li>特点：<ol>
<li>插入排序很适合部分有序的数组和规模较小的数组；</li>
<li>插入排序不适合对于数据量比较大的排序应用.</li>
</ol>
</li>
</ul>
<h1 id="希尔排序"><a href="#希尔排序" class="headerlink" title="希尔排序"></a>希尔排序</h1><h2 id="原理-2"><a href="#原理-2" class="headerlink" title="原理"></a>原理</h2><p>也称为递减增量排序算法，它是对插入排序的一种快速算法，插入排序相当于$h=1$的情况。（希尔排序的思想是使数组中任意间隔为h的元素都是有序的）</p>
<p>希尔排序是基于插入排序的以下两点性质而提出改进方法的：</p>
<ol>
<li>插入排序在对几乎已经排好序的数据操作时， 效率高， 即可以达到线性排序的效率；</li>
<li>但插入排序一般来说是低效的， 因为插入排序每次只能将数据移动一位。</li>
</ol>
<h2 id="步骤-2"><a href="#步骤-2" class="headerlink" title="步骤"></a>步骤</h2><p>算法最重要的部分是<strong>步长</strong>，当步长为1时就是插入排序。</p>
<ol>
<li>最开始以一定的步长进行排序；</li>
<li>然后会继续以一定步长进行排序；</li>
<li>最终算法以步长为1进行排序。</li>
</ol>
<p>当步长为1时，算法变为插入排序，这就保证了数据一定会被排序。</p>
<p>步长的设置，影响着希尔排序算法的复杂度，具体可参考<a href="https://zh.wikipedia.org/wiki/%E5%B8%8C%E5%B0%94%E6%8E%92%E5%BA%8F" target="_blank" rel="external">维基百科之希尔排序</a>，这里给出一个步长序列与复杂度的关系表：</p>
<p><img src="/images/2016-03-26-sort/shell.png" alt="shell"></p>
<h2 id="实现-2"><a href="#实现-2" class="headerlink" title="实现"></a>实现</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">sort</span><span class="params">(Comparable[] a)</span> </span>&#123;</div><div class="line">    <span class="keyword">int</span> N = a.length;</div><div class="line">    <span class="keyword">int</span> h = <span class="number">1</span>;</div><div class="line">    <span class="keyword">while</span> (h &lt; N / <span class="number">3</span>)</div><div class="line">        h = <span class="number">3</span> * h + <span class="number">1</span>;</div><div class="line">    <span class="keyword">while</span> (h &gt;= <span class="number">1</span>) &#123;</div><div class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = h; i &lt; N; i++) &#123;</div><div class="line">            <span class="keyword">for</span> (<span class="keyword">int</span> j = i; j &gt;= h &amp;&amp; less(a[j], a[j - h]); j -= h) &#123;</div><div class="line">                exch(a, j, j - h);</div><div class="line">            &#125;</div><div class="line">        &#125;</div><div class="line">        h = h / <span class="number">3</span>;</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>完整代码参考<a href="https://github.com/wangzzu/algorithms/blob/master/Algorithms-4th/src/main/java/sort_two/Shell.java" target="_blank" rel="external">Shell.java</a></p>
<p>排序效果如下图所示（原图来自<a href="https://zh.wikipedia.org/wiki/%E5%B8%8C%E5%B0%94%E6%8E%92%E5%BA%8F" target="_blank" rel="external">维基百科之希尔排序</a>）</p>
<p><img src="/images/2016-03-26-sort/Sorting_shellsort_anim.gif" alt="shellsort"></p>
<h2 id="性能分析-2"><a href="#性能分析-2" class="headerlink" title="性能分析"></a>性能分析</h2><ul>
<li>复杂度分析：参见上表</li>
<li>特点：<ol>
<li>排序最重要的地方在于当用较小步长排序后，以前用的较大步长仍然是有序的。比如，如果一个数列以步长5进行了排序然后再以步长3进行排序，那么该数列不仅是以步长3有序，而且是以步长5有序。</li>
</ol>
</li>
</ul>
<h1 id="冒泡排序"><a href="#冒泡排序" class="headerlink" title="冒泡排序"></a>冒泡排序</h1><h2 id="原理-3"><a href="#原理-3" class="headerlink" title="原理"></a>原理</h2><p>冒泡排序是一种简单的排序算法。它每次去从开始去比较两个元素，如果顺序错误就交换过来，当比较到最后一个元素时，就会把最小（最大）的元素找出来；然后在重复比较，前面已经找到的就不再参与比较。元素越小（大）的元素会经过交换慢慢“浮”到数列顶端。</p>
<h2 id="步骤-3"><a href="#步骤-3" class="headerlink" title="步骤"></a>步骤</h2><ol>
<li>比较相邻的元素。如果第一个比第二个大，就交换他们两个；</li>
<li>对每一对相邻元素作同样的工作，从开始第一对到结尾的最后一对。在这一点，最后的元素应该会是最大的数；</li>
<li>针对所有的元素重复以上的步骤，除了最后一个；</li>
<li>持续每次对越来越少的元素重复上面的步骤，直到没有任何一对数字需要比较。</li>
</ol>
<h2 id="实现-3"><a href="#实现-3" class="headerlink" title="实现"></a>实现</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">sort</span><span class="params">(Comparable[] a)</span> </span>&#123;</div><div class="line">    <span class="keyword">int</span> N=a.length-<span class="number">1</span>;</div><div class="line">    <span class="keyword">while</span>(N&gt;<span class="number">0</span>)&#123;</div><div class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">1</span>;i&lt;=N;i++)&#123;</div><div class="line">            <span class="keyword">if</span>(less(a[i],a[i-<span class="number">1</span>]))</div><div class="line">                exch(a,i,i-<span class="number">1</span>);</div><div class="line">        &#125;</div><div class="line">        N--;</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>完整代码参考<a href="https://github.com/wangzzu/algorithms/blob/master/Algorithms-4th/src/main/java/sort_two/Bubble.java" target="_blank" rel="external">Bubble.java</a></p>
<p>排序效果如下图所示（原图来自<a href="https://zh.wikipedia.org/wiki/%E6%8F%92%E5%85%A5%E6%8E%92%E5%BA%8F" target="_blank" rel="external">维基百科之插入排序</a>）</p>
<p><img src="/images/2016-03-26-sort/Bubble_sort_animation.gif" alt="Bubble_sort"></p>
<h1 id="归并排序"><a href="#归并排序" class="headerlink" title="归并排序"></a>归并排序</h1><h2 id="原地归并排序"><a href="#原地归并排序" class="headerlink" title="原地归并排序"></a>原地归并排序</h2><h3 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h3><p>对两个有序数组进行归并。</p>
<h3 id="步骤-4"><a href="#步骤-4" class="headerlink" title="步骤"></a>步骤</h3><p>原地归并排序主要是对于有序数组而言，这里只需要额外申请一段数据空间，来进行合并数组即可（迭代法）。</p>
<ol>
<li>申请空间，使其大小为两个已经排序序列之和，该空间用来存放合并后的序列；</li>
<li>设定两个指针，最初位置分别为两个已经排序序列的起始位置；</li>
<li>比较两个指针所指向的元素，选择相对小的元素放入到合并空间，并移动指针到下一位置；</li>
<li>重复步骤3直到某一指针到达序列尾；</li>
<li>将另一序列剩下的所有元素直接复制到合并序列尾。</li>
</ol>
<h3 id="实现-4"><a href="#实现-4" class="headerlink" title="实现"></a>实现</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//迭代法(第一个有序数组为lo~mid，第二个有序数组为mid+1~hi)</span></div><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">merge</span><span class="params">(Comparable[] a, <span class="keyword">int</span> lo, <span class="keyword">int</span> mid, <span class="keyword">int</span> hi)</span> </span>&#123;</div><div class="line">    <span class="keyword">int</span> i = lo;</div><div class="line">    <span class="keyword">int</span> j = mid + <span class="number">1</span>;</div><div class="line">    Comparable[] aux = <span class="keyword">new</span> Comparable[a.length];</div><div class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> k = lo; k &lt;= hi; k++)</div><div class="line">        aux[k] = a[k];</div><div class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> k = lo; k &lt;= hi; k++) &#123;</div><div class="line">        <span class="keyword">if</span> (i &gt; mid)</div><div class="line">            a[k] = aux[j++];</div><div class="line">        <span class="keyword">else</span> <span class="keyword">if</span> (j &gt; hi)</div><div class="line">            a[k] = aux[i++];</div><div class="line">        <span class="keyword">else</span> <span class="keyword">if</span> (less(aux[j], aux[i]))</div><div class="line">            a[k] = aux[j++];</div><div class="line">        <span class="keyword">else</span></div><div class="line">            a[k] = aux[i++];</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h2 id="自顶向下"><a href="#自顶向下" class="headerlink" title="自顶向下"></a>自顶向下</h2><h3 id="原理-4"><a href="#原理-4" class="headerlink" title="原理"></a>原理</h3><p>首先要知道原地归并排序算法，这个是将两个有序的数组归并到一个数组中，然后使用递归算法，每次都对对并一半的数据（直到把数据间隔减少到1为止，从上往下切分）进行归并排序，这样就是递归地调用归并排序。</p>
<h3 id="步骤-5"><a href="#步骤-5" class="headerlink" title="步骤"></a>步骤</h3><ol>
<li>将序列分成两部分，然后对部分分别进行归并；</li>
<li>再将这部分分成两部分进行归并；</li>
<li>重复步骤2，直到把每部分分成为大小为1的数组。</li>
</ol>
<h3 id="实现-5"><a href="#实现-5" class="headerlink" title="实现"></a>实现</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">sort</span><span class="params">(Comparable[] a, <span class="keyword">int</span> lo, <span class="keyword">int</span> hi)</span> </span>&#123;</div><div class="line">    <span class="keyword">if</span> (hi &lt;= lo)</div><div class="line">        <span class="keyword">return</span>;</div><div class="line">    <span class="keyword">int</span> mid = lo + (hi - lo) / <span class="number">2</span>;</div><div class="line">    sort(a, lo, mid);</div><div class="line">    sort(a, mid + <span class="number">1</span>, hi);</div><div class="line">    merge(a, lo, mid, hi);<span class="comment">// 归并两个有序数组</span></div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h3 id="性能分析-3"><a href="#性能分析-3" class="headerlink" title="性能分析"></a>性能分析</h3><ol>
<li>对于长度为N的任意数组，自顶向下的归并排序需要$\frac{N\lg{N}}{2} $至$N\lg{N}$次比较；</li>
<li>对于长度为N的任意数组，自顶向下的归并排序最多需要访问数组$6NlgN$次。</li>
</ol>
<ul>
<li>缺点：其辅助数组所使用的额外空间和N的大小成正比。</li>
</ul>
<h2 id="自低向上"><a href="#自低向上" class="headerlink" title="自低向上"></a>自低向上</h2><h3 id="原理-5"><a href="#原理-5" class="headerlink" title="原理"></a>原理</h3><p>从最下面的长度为1数组开始往上进行合并，直到最后数组变成两个有序数组，再进行最后依次合并。</p>
<h3 id="步骤-6"><a href="#步骤-6" class="headerlink" title="步骤"></a>步骤</h3><ol>
<li>将序列每相邻两个数字进行归并操作，形成$ \lfloor\frac{n}{2}\rfloor$个序列，排序后每个序列包含两个元素；</li>
<li>将上述序列再次归并，形成$\lfloor\frac{n}{4}\rfloor$个序列，每个序列包含四个元素；</li>
<li>重复步骤2，直到所有元素排序完毕。</li>
</ol>
<h3 id="实现-6"><a href="#实现-6" class="headerlink" title="实现"></a>实现</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">sortBU</span><span class="params">(Comparable[] a)</span> </span>&#123;</div><div class="line">    <span class="keyword">int</span> N = a.length;</div><div class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> sz = <span class="number">1</span>; sz &lt; N; sz = sz + sz) &#123;</div><div class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> lo = <span class="number">0</span>; lo &lt; N - sz; lo += sz + sz)</div><div class="line">            merge(a, lo, lo + sz - <span class="number">1</span>, Math.min(lo + sz + sz - <span class="number">1</span>, N - <span class="number">1</span>));</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h3 id="性能分析-4"><a href="#性能分析-4" class="headerlink" title="性能分析"></a>性能分析</h3><ol>
<li>对于长度为N的任意数组，自低向上的归并排序需要$\frac{N\lg{N}}{2}$至$N\lg{N}$次比较，最多需要访问数组$6N\lg{N}$次。</li>
<li>与自顶向下是相同的，只是顺序不同而已。</li>
</ol>
<h1 id="快速排序"><a href="#快速排序" class="headerlink" title="快速排序"></a>快速排序</h1><h2 id="原理-6"><a href="#原理-6" class="headerlink" title="原理"></a>原理</h2><p>分治思想，将数组分成两个子数组，独自进行排序。最简单的递归切分：指针i从数组的最左端开始扫描直到找到一个大于等于它的元素，指针j从数组的最右端开始扫描直到找到一个小于等于它的元素，然后交换它们的位置，直到指针相遇。</p>
<p>注意：</p>
<ol>
<li>终止循环：一个常见的错误就是没有考虑到数组中可能包含和切分元素的值相同的其他元素。</li>
</ol>
<h2 id="步骤-7"><a href="#步骤-7" class="headerlink" title="步骤"></a>步骤</h2><ol>
<li>选择一个基准元素,通常选择第一个元素或者最后一个元素;</li>
<li>通过一趟排序将待排序的记录分割成独立的两部分，其中一部分记录的元素值均比基准元素值小。另一部分记录的 元素值比基准值大;</li>
<li>此时基准元素在其排好序后的正确位置;</li>
<li>然后分别对这两部分记录用同样的方法继续进行排序，直到整个序列有序。</li>
</ol>
<h2 id="实现-7"><a href="#实现-7" class="headerlink" title="实现"></a>实现</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">sort</span><span class="params">(Comparable[] a, <span class="keyword">int</span> low, <span class="keyword">int</span> high)</span> </span>&#123;</div><div class="line">    <span class="keyword">int</span> l = low;</div><div class="line">    <span class="keyword">int</span> h = high;</div><div class="line">    Comparable key = a[l];</div><div class="line">    <span class="keyword">while</span> (l &lt; h) &#123;</div><div class="line">        <span class="keyword">while</span> (l &lt; h &amp;&amp; less(key, a[h]))</div><div class="line">            h--;</div><div class="line">        <span class="keyword">if</span> (l &lt; h) &#123;</div><div class="line">            exch(a, l, h);</div><div class="line">            l++;</div><div class="line">        &#125;</div><div class="line"></div><div class="line">        <span class="keyword">while</span> (l &lt; h &amp;&amp; less(a[l], key))</div><div class="line">            l++;</div><div class="line">        <span class="keyword">if</span> (l &lt; h) &#123;</div><div class="line">            exch(a, l, h);</div><div class="line">            h--;</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line">    <span class="keyword">if</span> (l &gt; low)</div><div class="line">        sort(a, low, l - <span class="number">1</span>);</div><div class="line">    <span class="keyword">if</span> (h &lt; high)</div><div class="line">        sort(a, l + <span class="number">1</span>, high);</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>完整代码参考<a href="https://github.com/wangzzu/algorithms/blob/master/Algorithms-4th/src/main/java/sort_two/Quick.java" target="_blank" rel="external">Quick.java</a></p>
<p>排序效果如下图所示（原图来自<a href="https://zh.wikipedia.org/wiki/%E5%BF%AB%E9%80%9F%E6%8E%92%E5%BA%8F#.E9.81.B8.E6.93.87.E7.9A.84.E9.97.9C.E9.80.A3.E6.80.A7" target="_blank" rel="external">维基百科之快速排序</a>）</p>
<p><img src="/images/2016-03-26-sort/Sorting_quicksort_anim.gif" alt="quick_sort"></p>
<h2 id="性能分析-5"><a href="#性能分析-5" class="headerlink" title="性能分析"></a>性能分析</h2><ol>
<li>快速排序的内循环会用一个递增的索引将数组元素和一个定值进行比较，其他的几种排序还需要再内循环中移动元素；</li>
<li>它的比较次数较少；</li>
<li>排序的效率取决于切分的效果，而不是切分元素的值，最好的效果是每次都能将数组对半分，在切分不平衡时，程序就会变得比较低效；</li>
<li>对于长度为N的无重复数组排序，快速排序平均需要～$2N\ln{N}$次比较（以及$\frac{1}{6}$次交换）；</li>
<li>快速排序最多需要约$\frac{n^2}{2}$次比较，随机打乱数组可以预防这种情况（当切分时，每次两个子数组之一为空才会出现这种情况）；</li>
<li>三向切分：主要对于有大量元素相等的情况。</li>
</ol>
<h2 id="快排算法改进"><a href="#快排算法改进" class="headerlink" title="快排算法改进"></a>快排算法改进</h2><ol>
<li>小数组时（$h_i&lt;lo+M$），切换到插入排序。对于小数组，快排比插入排序要慢；</li>
<li>三取样切分。使用子数组的一小部分的中位数来切分数组，这样做得到切分效果更好，但是代价是需要计算中位数；</li>
<li>三向切分，主要是对于有重复元素的情况下，将数组切分为三部分，分别是小于，等于和大于切分元素的数组元素。</li>
</ol>
<h1 id="堆排序"><a href="#堆排序" class="headerlink" title="堆排序"></a>堆排序</h1><h2 id="原理-7"><a href="#原理-7" class="headerlink" title="原理"></a>原理</h2><p>先构造一个最大堆（最小堆），然后将根节点的最大值（最小值）与最后一位交换，再对第一位进行下沉（上浮）操作，依次类推（下次与倒数第二位进行交换），最后得到的数组即为有序数组。</p>
<p>最大堆的特点：</p>
<ol>
<li>一棵大小为$N$的完全二叉树的高度为不小于的$\lg{N}$最小整数；</li>
<li>当一棵二叉树的每个节点都大于等于它的两个子节点时，被称为<strong>堆有序</strong>；</li>
<li>根节点是最大的节点；</li>
<li>对于节点$i$，左移一位算出$2i$节点（即为左子节点），左移一位并在低位加1得到$2i+1$节点（右子节点），右移一位得到$\lfloor\frac{i}{2}\rfloor$（父节点）。</li>
</ol>
<h2 id="实现-8"><a href="#实现-8" class="headerlink" title="实现"></a>实现</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">sort</span><span class="params">(Comparable[] pq)</span> </span>&#123;</div><div class="line">		<span class="keyword">int</span> N = pq.length;</div><div class="line">		<span class="keyword">for</span> (<span class="keyword">int</span> k = N / <span class="number">2</span>; k &gt;= <span class="number">1</span>; k--)</div><div class="line">			sink(pq, k, N);</div><div class="line">		<span class="keyword">while</span> (N &gt; <span class="number">1</span>) &#123;</div><div class="line">			exch(pq, <span class="number">1</span>, N);</div><div class="line">			N--;</div><div class="line">			sink(pq, <span class="number">1</span>, N);</div><div class="line">		&#125;</div><div class="line">	&#125;</div><div class="line"></div><div class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">sink</span><span class="params">(Comparable[] pq, <span class="keyword">int</span> k, <span class="keyword">int</span> N)</span> </span>&#123;</div><div class="line">		<span class="keyword">while</span> (<span class="number">2</span> * k &lt;= N) &#123;</div><div class="line">			<span class="keyword">int</span> j = <span class="number">2</span> * k;</div><div class="line">			<span class="keyword">if</span> (j + <span class="number">1</span> &lt;= N) &#123;</div><div class="line">				<span class="keyword">if</span> (j &lt; N &amp;&amp; less(pq, j, j + <span class="number">1</span>))</div><div class="line">					j++;</div><div class="line">			&#125;</div><div class="line">			<span class="keyword">if</span> (!less(pq, k, j))</div><div class="line">				<span class="keyword">break</span>;</div><div class="line">			exch(pq, k, j);</div><div class="line">			k = j;</div><div class="line">		&#125;</div><div class="line">	&#125;</div><div class="line"></div><div class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">exch</span><span class="params">(Comparable[] pq, <span class="keyword">int</span> i, <span class="keyword">int</span> j)</span> </span>&#123;</div><div class="line">		Comparable swap = pq[i - <span class="number">1</span>];</div><div class="line">		pq[i - <span class="number">1</span>] = pq[j - <span class="number">1</span>];</div><div class="line">		pq[j - <span class="number">1</span>] = swap;</div><div class="line">	&#125;</div><div class="line"></div><div class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">boolean</span> <span class="title">less</span><span class="params">(Comparable[] pq, <span class="keyword">int</span> i, <span class="keyword">int</span> j)</span> </span>&#123;</div><div class="line">		<span class="keyword">return</span> pq[i - <span class="number">1</span>].compareTo(pq[j - <span class="number">1</span>]) &lt; <span class="number">0</span>;</div><div class="line">	&#125;</div></pre></td></tr></table></figure>
<p>完整代码参考<a href="https://github.com/wangzzu/algorithms/blob/master/Algorithms-4th/src/main/java/sort_two/Heap.java" target="_blank" rel="external">Heap.java</a></p>
<p>排序效果如下图所示（原图来自<a href="https://zh.wikipedia.org/wiki/%E5%A0%86%E6%8E%92%E5%BA%8F" target="_blank" rel="external">维基百科之快速排序</a>）</p>
<p><img src="/images/2016-03-26-sort/Sorting_heapsort_anim.gif" alt="heap_sort"></p>
<h2 id="性能分析-6"><a href="#性能分析-6" class="headerlink" title="性能分析"></a>性能分析</h2><ul>
<li>复杂度分析：<ol>
<li>构造堆的时间复杂度为$O(n)$；</li>
<li>堆排序的时间复杂度为$O(n\lg{n})$;</li>
</ol>
</li>
<li>特点：<ol>
<li>排序算法使用的是最大堆，最小堆通常用于优先队列（当然也可以反过来）；</li>
<li>将一个数组构造为一个最大堆时，使用递归循环通过下沉（<code>sink</code>方法）将所有有子节点的父节点下沉到给定位置，它的时间复杂度为<code>O(n)</code>；</li>
<li>最大优先队列的一个典型应用就是共享计算机系统中的作业调度。</li>
</ol>
</li>
</ul>
<h1 id="计数排序"><a href="#计数排序" class="headerlink" title="计数排序"></a>计数排序</h1><h2 id="原理-8"><a href="#原理-8" class="headerlink" title="原理"></a>原理</h2><p>对于每个输入元素x，确定小于x的元素个数，利用这个信息可以直接把x放在输出数组中的位置上了。</p>
<h2 id="步骤-8"><a href="#步骤-8" class="headerlink" title="步骤"></a>步骤</h2><p>参考<a href="https://zh.wikipedia.org/wiki/%E8%AE%A1%E6%95%B0%E6%8E%92%E5%BA%8F" target="_blank" rel="external">CountingSort</a>，其步骤为：</p>
<ol>
<li>找出待排序的数组中最大和最小的元素；</li>
<li>统计数组中每个值为i的元素出现的次数，存入数组 C 的第 i 项；</li>
<li>对所有的计数累加（从$C$中的第一个元素开始，每一项和前一项相加）；</li>
<li>反向填充目标数组：将每个元素i放在新数组的第$C(i)$项，每放一个元素就将$C(i)$减去1。</li>
</ol>
<h2 id="实现-9"><a href="#实现-9" class="headerlink" title="实现"></a>实现</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">int</span>[] sort(<span class="keyword">int</span>[] a) &#123;</div><div class="line">	<span class="keyword">int</span>[] b = <span class="keyword">new</span> <span class="keyword">int</span>[a.length];</div><div class="line">	<span class="keyword">int</span> min = a[<span class="number">0</span>];</div><div class="line">	<span class="keyword">int</span> max = a[<span class="number">0</span>];</div><div class="line">	<span class="keyword">for</span> (<span class="keyword">int</span> i : a) &#123;</div><div class="line">		<span class="keyword">if</span> (i &gt; max)</div><div class="line">			max = i;</div><div class="line">		<span class="keyword">if</span> (i &lt; min)</div><div class="line">			min = i;</div><div class="line">	&#125;</div><div class="line">	<span class="keyword">int</span> size = max - min + <span class="number">1</span>;</div><div class="line">	<span class="keyword">int</span>[] c = <span class="keyword">new</span> <span class="keyword">int</span>[size];</div><div class="line">	<span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; a.length; i++) &#123;</div><div class="line">		c[a[i] - min]++;</div><div class="line">	&#125;</div><div class="line">	<span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">1</span>; i &lt; c.length; i++) &#123;</div><div class="line">		c[i] = c[i] + c[i - <span class="number">1</span>];</div><div class="line">	&#125;</div><div class="line">	<span class="keyword">for</span> (<span class="keyword">int</span> i = a.length - <span class="number">1</span>; i &gt;= <span class="number">0</span>; i--) &#123;</div><div class="line">		b[--c[a[i] - min]] = a[i];</div><div class="line">	&#125;</div><div class="line">	<span class="keyword">return</span> b;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>完整代码参考<a href="https://github.com/wangzzu/algorithms/blob/master/Algorithms-4th/src/main/java/sort_two/CountingSort.java" target="_blank" rel="external">CountingSort.java</a></p>
<h2 id="性能分析-7"><a href="#性能分析-7" class="headerlink" title="性能分析"></a>性能分析</h2><ul>
<li>复杂度分析：<ol>
<li>时间复杂度为O(k+n).</li>
</ol>
</li>
<li>特点：<ol>
<li>用运算确定次序，而非比较来确定；</li>
<li><strong>稳定</strong>：具有相同值的元素在输出数组中的相对次序与它们在输入数组中的相对次序是相同的。</li>
</ol>
</li>
</ul>
<h1 id="基数排序（Radix-Sort）"><a href="#基数排序（Radix-Sort）" class="headerlink" title="基数排序（Radix Sort）"></a>基数排序（Radix Sort）</h1><p>将整数按位数切割成不同的数字，然后按每个位数分别比较。</p>
<h2 id="原理-9"><a href="#原理-9" class="headerlink" title="原理"></a>原理</h2><p>将所有待比较数值（正整数）统一为同样的数位长度，数位较短的数前面补零。然后，从最低位开始，依次进行一次排序。这样从最低位排序直到最高位排序完成以后，数列就变成了一个有序序列。</p>
<h2 id="步骤-9"><a href="#步骤-9" class="headerlink" title="步骤"></a>步骤</h2><p>对于$n$个$d$位数，每个数位有k个可能的取值（比如十进制数每位有10个可能的取值）。</p>
<ol>
<li>先按最低位对数进行排序（可以是计数排序）；</li>
<li>再次低位进行排序</li>
<li>重复第2步，直到最后一步按照最高位进行排序。</li>
</ol>
<p>从最低位开始排序，保证排序算法的稳定性（如果遇到该位数值相同的话，就按输入顺序）。可以参考<a href="http://baike.baidu.com/view/1170573.htm#1" target="_blank" rel="external">百度百科之基数排序</a>中例子。</p>
<h2 id="实现-10"><a href="#实现-10" class="headerlink" title="实现"></a>实现</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">sort</span><span class="params">(<span class="keyword">int</span>[] a, <span class="keyword">int</span> d)</span> </span>&#123;<span class="comment">// d最大值多少位</span></div><div class="line">	<span class="keyword">int</span> index = <span class="number">0</span>;</div><div class="line">	<span class="keyword">int</span> m = <span class="number">1</span>;</div><div class="line">	<span class="keyword">int</span> n = <span class="number">1</span>;</div><div class="line">	<span class="keyword">int</span>[][] tmp = <span class="keyword">new</span> <span class="keyword">int</span>[<span class="number">10</span>][a.length];</div><div class="line">	<span class="keyword">int</span>[] num = <span class="keyword">new</span> <span class="keyword">int</span>[<span class="number">10</span>];</div><div class="line">	<span class="keyword">while</span> (m &lt;= d) &#123;</div><div class="line">		<span class="keyword">for</span> (<span class="keyword">int</span> i : a) &#123;</div><div class="line">			<span class="keyword">int</span> lsd = (i / n) % <span class="number">10</span>;</div><div class="line">			tmp[lsd][num[lsd]] = i;</div><div class="line">			num[lsd]++;</div><div class="line">		&#125;</div><div class="line">		<span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">10</span>; i++) &#123;</div><div class="line">			<span class="keyword">if</span> (num[i] != <span class="number">0</span>) &#123;</div><div class="line">				<span class="keyword">for</span> (<span class="keyword">int</span> j = <span class="number">0</span>; j &lt; num[i]; j++) &#123;</div><div class="line">					a[index] = tmp[i][j];</div><div class="line">					index++;</div><div class="line">				&#125;</div><div class="line">				num[i] = <span class="number">0</span>;</div><div class="line">			&#125;</div><div class="line">		&#125;</div><div class="line">		n *= <span class="number">10</span>;</div><div class="line">		index = <span class="number">0</span>;</div><div class="line">		m++;</div><div class="line">	&#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>完整代码参考<a href="https://github.com/wangzzu/algorithms/blob/master/Algorithms-4th/src/main/java/sort_two/RadixSort.java" target="_blank" rel="external">RadixSort.java</a></p>
<h2 id="性能分析-8"><a href="#性能分析-8" class="headerlink" title="性能分析"></a>性能分析</h2><ul>
<li>复杂度分析：<ol>
<li>使用稳定排序方法耗时$O(k+n)$，那么就可以在$O(d*(k+n))$时间内将这些数排好序。</li>
</ol>
</li>
<li>特点：<ol>
<li>基数排序利用的计数排序不是原址排序，而快排是原址排序。</li>
</ol>
</li>
</ul>
<h1 id="桶排序"><a href="#桶排序" class="headerlink" title="桶排序"></a>桶排序</h1><p>也即是箱排序。</p>
<h2 id="原理-10"><a href="#原理-10" class="headerlink" title="原理"></a>原理</h2><p>将数组分到有限数量的桶子里。每个桶子再个别排序。</p>
<h2 id="步骤-10"><a href="#步骤-10" class="headerlink" title="步骤"></a>步骤</h2><ol>
<li>设置一个合适数量的数组作为空桶子；</li>
<li>寻访序列，并且把项目一个一个放到对应的桶子里；</li>
<li>对每个不是空桶子进行排序；</li>
<li>从不是空的桶子里把项目再放回原来的序列中。</li>
</ol>
<p>排序效果如下图所示（原图来自<a href="http://baike.baidu.com/link?url=0bNJEspxIkXRmUyeUSZPfOG5N2YcfhFT00DXysI-k0IVGq7IkaGxs1ronj3iQasuVTLrEvIY3A_POP3V8eTWma" target="_blank" rel="external">百度百科之桶排序</a>）</p>
<p><img src="/images/2016-03-26-sort/bucketSort.jpg" alt="bucket_sort"></p>
<h2 id="实现-11"><a href="#实现-11" class="headerlink" title="实现"></a>实现</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">sort</span><span class="params">(<span class="keyword">int</span> a[])</span> </span>&#123;</div><div class="line">	<span class="keyword">int</span> n = a.length;</div><div class="line">	<span class="keyword">int</span> bask[][] = <span class="keyword">new</span> <span class="keyword">int</span>[<span class="number">10</span>][n];</div><div class="line">	<span class="keyword">int</span> index[] = <span class="keyword">new</span> <span class="keyword">int</span>[<span class="number">10</span>];</div><div class="line">	<span class="keyword">int</span> max = Integer.MIN_VALUE;</div><div class="line">	<span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; n; i++) &#123;</div><div class="line">		max = max &gt; (Integer.toString(a[i]).length()) ? max : (Integer.toString(a[i]).length());</div><div class="line">	&#125;</div><div class="line">	String str;</div><div class="line">	<span class="keyword">for</span> (<span class="keyword">int</span> i = max - <span class="number">1</span>; i &gt;= <span class="number">0</span>; i--) &#123;</div><div class="line">		<span class="keyword">for</span> (<span class="keyword">int</span> j = <span class="number">0</span>; j &lt; n; j++) &#123;</div><div class="line">			str = <span class="string">""</span>;</div><div class="line">			<span class="keyword">if</span> (Integer.toString(a[j]).length() &lt; max) &#123;</div><div class="line">				<span class="keyword">for</span> (<span class="keyword">int</span> k = <span class="number">0</span>; k &lt; max - Integer.toString(a[j]).length(); k++)</div><div class="line">					str += <span class="string">"0"</span>;</div><div class="line">			&#125;</div><div class="line">			str += Integer.toString(a[j]);</div><div class="line">			bask[str.charAt(i) - <span class="string">'0'</span>][index[str.charAt(i) - <span class="string">'0'</span>]++] = a[j];</div><div class="line">		&#125;</div><div class="line">		<span class="keyword">int</span> pos = <span class="number">0</span>;</div><div class="line">		<span class="keyword">for</span> (<span class="keyword">int</span> j = <span class="number">0</span>; j &lt; <span class="number">10</span>; j++) &#123;</div><div class="line">			<span class="keyword">for</span> (<span class="keyword">int</span> k = <span class="number">0</span>; k &lt; index[j]; k++) &#123;</div><div class="line">				a[pos++] = bask[j][k];</div><div class="line">			&#125;</div><div class="line">		&#125;</div><div class="line">		<span class="keyword">for</span> (<span class="keyword">int</span> x = <span class="number">0</span>; x &lt; <span class="number">10</span>; x++)</div><div class="line">			index[x] = <span class="number">0</span>;</div><div class="line">	&#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>完整代码参考<a href="https://github.com/wangzzu/algorithms/blob/master/Algorithms-4th/src/main/java/sort_two/BucketSort.java" target="_blank" rel="external">BucketSort.java</a></p>
<h2 id="性能分析-9"><a href="#性能分析-9" class="headerlink" title="性能分析"></a>性能分析</h2><ul>
<li>复杂度分析：<ol>
<li>平均时间复杂度为 $O(k+n)$；</li>
<li>最差时间复杂度：$O(n^2)$;</li>
<li>最差空间复杂度：$O(k*n)$；</li>
</ol>
</li>
<li>特点：<ol>
<li>感觉相当于先进行hash，然后再进行排序，这种思想在海量数据排序中经常会使用到。</li>
</ol>
</li>
</ul>
<hr>
<h1 id="算法性能总结"><a href="#算法性能总结" class="headerlink" title="算法性能总结"></a>算法性能总结</h1><table>
<thead>
<tr>
<th>算法名称</th>
<th>平均时间复杂度</th>
<th>最坏情况时间复杂度</th>
<th>最好情况时间复杂度</th>
<th>辅助空间</th>
<th>稳定性</th>
</tr>
</thead>
<tbody>
<tr>
<td>选择排序</td>
<td>$O(n^2)$</td>
<td>$O(n^2)$</td>
<td>$O(n)$</td>
<td>$O(1)$</td>
<td>不稳定</td>
</tr>
<tr>
<td>插入排序</td>
<td>$O(n^2)$</td>
<td>$O(n^2)$</td>
<td>$O(n)$</td>
<td>$O(1)$</td>
<td>稳定</td>
</tr>
<tr>
<td>希尔排序</td>
<td>$O(n\lg{n})$ ~ $O(n^2)$</td>
<td>$O(n^2)$</td>
<td>$O(n^{1.3})$</td>
<td>$ O(1)$</td>
<td>不稳定</td>
</tr>
<tr>
<td>冒泡排序</td>
<td>$O(n^2)$</td>
<td>$O(n^2)$</td>
<td>$O(n)$</td>
<td>$ O(1)$</td>
<td>稳定</td>
</tr>
<tr>
<td>自底向上归并排序</td>
<td>$O(n\lg{n})$</td>
<td>$O(n\lg{n}) $</td>
<td>$ O(n) $</td>
<td>$ O(n)$</td>
<td>稳定</td>
</tr>
<tr>
<td>自顶向下归并排序</td>
<td>$O(n\lg{n})$</td>
<td>$ O(n\lg{n}) $</td>
<td>$O(n)  $</td>
<td>$ O(n)$</td>
<td>稳定</td>
</tr>
<tr>
<td>快速排序</td>
<td>$O(n\lg{n}) $</td>
<td>$O(n^2)$</td>
<td>$O(nlgn)$</td>
<td>$O(\lg{n})$ ~ $O(n)$</td>
<td>不稳定</td>
</tr>
<tr>
<td>堆排序</td>
<td>$O(n\lg{n}) $</td>
<td>$O(n\lg{n}) $</td>
<td>$O(n\lg{n}$)</td>
<td>$O(1)$</td>
<td>不稳定</td>
</tr>
<tr>
<td>计数排序</td>
<td>$ O(n+k) $</td>
<td></td>
<td></td>
<td>$O(n + k)$</td>
<td>稳定</td>
</tr>
<tr>
<td>基数排序</td>
<td>$O(k*n)$</td>
<td></td>
<td></td>
<td>$O(n)$</td>
<td>稳定</td>
</tr>
<tr>
<td>桶排序</td>
<td>$O(n^2)$</td>
<td></td>
<td></td>
<td>$ O(k)$</td>
<td>稳定</td>
</tr>
</tbody>
</table>
<hr>
<p>参考资料：</p>
<ol>
<li><a href="http://www.amazon.cn/%E5%9B%BE%E7%81%B5%E7%A8%8B%E5%BA%8F%E8%AE%BE%E8%AE%A1%E4%B8%9B%E4%B9%A6-%E7%AE%97%E6%B3%95-%E5%A1%9E%E5%A5%87%E5%A8%81%E5%85%8B/dp/B009OCFQ0O/ref=sr_1_1?ie=UTF8&amp;qid=1458988861&amp;sr=8-1&amp;keywords=%E7%AE%97%E6%B3%95" target="_blank" rel="external">《算法 第四版》</a></li>
<li><a href="http://www.amazon.cn/%E7%AE%97%E6%B3%95%E5%AF%BC%E8%AE%BA-Thomas-H-Cormen/dp/B00AK7BYJY/ref=sr_1_3?ie=UTF8&amp;qid=1458988861&amp;sr=8-3&amp;keywords=%E7%AE%97%E6%B3%95" target="_blank" rel="external">《算法导论 第三版》</a></li>
<li><a href="https://zh.wikipedia.org/wiki/%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95" target="_blank" rel="external">维基百科之排序</a></li>
</ol>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[Java工程师成神之路【转】]]></title>
      <url>http://matt33.com/2016/03/22/java-learn/</url>
      <content type="html"><![CDATA[<p>原文转自<a href="http://www.hollischuang.com/archives/489" target="_blank" rel="external">Java工程师成神之路</a>，并对原文根据自己的学习及经验做了一些修改。</p>
<h1 id="基础篇"><a href="#基础篇" class="headerlink" title="基础篇"></a>基础篇</h1><p>先推荐一个网址<a href="https://google.github.io/styleguide/javaguide.html" target="_blank" rel="external">Google Code Style for Java</a>，这是Google出的一个关于Java代码规范化的文章，代码规范化的好处及重要性这里就不再叙述了，希望大家都能按照这个要求去写代码，这样才能写出真正易读的优秀代码。</p>
<h2 id="JVM"><a href="#JVM" class="headerlink" title="JVM"></a>JVM</h2><h3 id="Java内存模型"><a href="#Java内存模型" class="headerlink" title="Java内存模型"></a>Java内存模型</h3><ul>
<li>Java内存管理;</li>
<li>Java堆和栈;</li>
<li>垃圾回收</li>
</ul>
<p>学习资料：</p>
<ul>
<li><a href="http://www.jcp.org/en/jsr/detail?id=133" target="_blank" rel="external">Java Community Process</a></li>
<li><a href="http://ifeve.com/jmm-faq/" target="_blank" rel="external">并发编程网之Java内存模型</a></li>
</ul>
<h2 id="了解JVM各种参数及调优"><a href="#了解JVM各种参数及调优" class="headerlink" title="了解JVM各种参数及调优"></a>了解JVM各种参数及调优</h2><h3 id="学习使用Java工具"><a href="#学习使用Java工具" class="headerlink" title="学习使用Java工具"></a>学习使用Java工具</h3><ul>
<li>jps；</li>
<li>jstack；</li>
<li>jmap；</li>
<li>jconsole；</li>
<li>jinfo；</li>
<li>jhat；</li>
<li>javap …</li>
</ul>
<p>学习资料：</p>
<p><a href="http://kenai.com/projects/btrace" target="_blank" rel="external">http://kenai.com/projects/btrace</a><br><a href="http://www.crashub.org/" target="_blank" rel="external">http://www.crashub.org/</a><br><a href="https://github.com/taobao/TProfiler" target="_blank" rel="external">https://github.com/taobao/TProfiler</a><br><a href="https://github.com/CSUG/HouseMD" target="_blank" rel="external">https://github.com/CSUG/HouseMD</a><br><a href="http://wiki.cyclopsgroup.org/jmxterm" target="_blank" rel="external">http://wiki.cyclopsgroup.org/jmxterm</a><br><a href="https://github.com/jlusdy/TBJMap" target="_blank" rel="external">https://github.com/jlusdy/TBJMap</a></p>
<h3 id="学习Java诊断工具"><a href="#学习Java诊断工具" class="headerlink" title="学习Java诊断工具"></a>学习Java诊断工具</h3><p><a href="http://www.eclipse.org/mat/" target="_blank" rel="external">http://www.eclipse.org/mat/</a><br><a href="http://visualvm.java.net/oqlhelp.html" target="_blank" rel="external">http://visualvm.java.net/oqlhelp.html</a></p>
<h3 id="自己编写各种outofmemory，stackoverflow程序"><a href="#自己编写各种outofmemory，stackoverflow程序" class="headerlink" title="自己编写各种outofmemory，stackoverflow程序"></a>自己编写各种outofmemory，stackoverflow程序</h3><ul>
<li>HeapOutOfMemory</li>
<li>Young OutOfMemory</li>
<li>MethodArea OutOfMemory</li>
<li>ConstantPool OutOfMemory</li>
<li>DirectMemory OutOfMemory</li>
<li>Stack OutOfMemory</li>
<li>Stack OverFlow</li>
</ul>
<h3 id="使用工具尝试解决以下问题，并写下总结当一个Java程序响应很慢时如何查找问题"><a href="#使用工具尝试解决以下问题，并写下总结当一个Java程序响应很慢时如何查找问题" class="headerlink" title="使用工具尝试解决以下问题，并写下总结当一个Java程序响应很慢时如何查找问题"></a>使用工具尝试解决以下问题，并写下总结当一个Java程序响应很慢时如何查找问题</h3><ul>
<li>当一个Java程序频繁FullGC时如何解决问题，如何查看垃圾回收日志</li>
<li>当一个Java应用发生OutOfMemory时该如何解决，年轻代、年老代、永久代解决办法不同，导致原因也不同</li>
</ul>
<h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><p><a href="http://docs.oracle.com/javase/specs/jvms/se7/html/" target="_blank" rel="external">http://docs.oracle.com/javase/specs/jvms/se7/html/</a><br><a href="http://www.cs.umd.edu/~pugh/java/memoryModel/" target="_blank" rel="external">http://www.cs.umd.edu/~pugh/java/memoryModel/</a><br><a href="http://gee.cs.oswego.edu/dl/jmm/cookbook.html" target="_blank" rel="external">http://gee.cs.oswego.edu/dl/jmm/cookbook.html</a></p>
<h2 id="Java基础知识"><a href="#Java基础知识" class="headerlink" title="Java基础知识"></a>Java基础知识</h2><h3 id="阅读源代码"><a href="#阅读源代码" class="headerlink" title="阅读源代码"></a>阅读源代码</h3><ul>
<li>java.lang.String</li>
<li>java.lang.Integer</li>
<li>java.lang.Long</li>
<li>java.lang.Enum</li>
<li>java.math.BigDecimal</li>
<li>java.lang.ThreadLocal</li>
<li>java.lang.ClassLoader &amp; java.net.URLClassLoader</li>
<li>java.util.ArrayList &amp; java.util.LinkedList</li>
<li>java.util.HashMap &amp; java.util.LinkedHashMap &amp; java.util.TreeMap</li>
<li>java.util.HashSet &amp; java.util.LinkedHashSet &amp; java.util.TreeSet</li>
</ul>
<h3 id="熟悉Java中各种变量类型"><a href="#熟悉Java中各种变量类型" class="headerlink" title="熟悉Java中各种变量类型"></a>熟悉Java中各种变量类型</h3><h3 id="熟悉Java-String的使用，熟悉String的各种函数"><a href="#熟悉Java-String的使用，熟悉String的各种函数" class="headerlink" title="熟悉Java String的使用，熟悉String的各种函数"></a>熟悉Java String的使用，熟悉String的各种函数</h3><h3 id="熟悉Java中各种关键字"><a href="#熟悉Java中各种关键字" class="headerlink" title="熟悉Java中各种关键字"></a>熟悉Java中各种关键字</h3><h3 id="学会使用List，Map，Stack，Queue，Set上述数据结构的遍历、上述数据结构的使用场景"><a href="#学会使用List，Map，Stack，Queue，Set上述数据结构的遍历、上述数据结构的使用场景" class="headerlink" title="学会使用List，Map，Stack，Queue，Set上述数据结构的遍历、上述数据结构的使用场景"></a>学会使用List，Map，Stack，Queue，Set上述数据结构的遍历、上述数据结构的使用场景</h3><ul>
<li>Java实现对Array/List排序</li>
<li>java.uti.Arrays.sort()</li>
<li>java.util.Collections.sort()</li>
<li>Java实现对List去重</li>
<li>Java实现对List去重，并且需要保留数据原始的出现顺序</li>
<li>Java实现最近最少使用cache，用LinkedHashMap</li>
</ul>
<h3 id="Java-IO"><a href="#Java-IO" class="headerlink" title="Java IO"></a>Java IO</h3><ul>
<li>Java NIO，并学会使用java.io.*</li>
<li>java.nio.*</li>
<li>nio和reactor设计模式</li>
<li>文件编码，字符集</li>
<li>几种不同I/O类型（与UNIX网络编程模式做对比）</li>
</ul>
<h3 id="Java反射与javassist反射与工厂模式"><a href="#Java反射与javassist反射与工厂模式" class="headerlink" title="Java反射与javassist反射与工厂模式"></a>Java反射与javassist反射与工厂模式</h3><ul>
<li>java.lang.reflect.*</li>
</ul>
<h3 id="Java序列化java-io-Serializable"><a href="#Java序列化java-io-Serializable" class="headerlink" title="Java序列化java.io. Serializable"></a>Java序列化<code>java.io. Serializable</code></h3><ul>
<li>什么是序列化，为什么序列化</li>
<li>序列化与单例模式</li>
<li>google序列化protobuf</li>
</ul>
<h3 id="虚引用，弱引用，软引用java-lang-ref"><a href="#虚引用，弱引用，软引用java-lang-ref" class="headerlink" title="虚引用，弱引用，软引用java.lang.ref.*"></a>虚引用，弱引用，软引用java.lang.ref.*</h3><ul>
<li>这些引用概念、区别使用；</li>
<li>实验这些引用的回收</li>
</ul>
<h3 id="熟悉Java系统属性java-util-Properties"><a href="#熟悉Java系统属性java-util-Properties" class="headerlink" title="熟悉Java系统属性java.util.Properties"></a>熟悉Java系统属性java.util.Properties</h3><h3 id="熟悉Annotation用法java-lang-annotation"><a href="#熟悉Annotation用法java-lang-annotation" class="headerlink" title="熟悉Annotation用法java.lang.annotation.*"></a>熟悉Annotation用法java.lang.annotation.*</h3><h3 id="JMSjavax-jms"><a href="#JMSjavax-jms" class="headerlink" title="JMSjavax.jms.*"></a>JMSjavax.jms.*</h3><h3 id="JMXjava-lang-management-、javax-management"><a href="#JMXjava-lang-management-、javax-management" class="headerlink" title="JMXjava.lang.management.、javax.management."></a>JMXjava.lang.management.<em>、javax.management.</em></h3><h3 id="泛型和继承，泛型和擦除"><a href="#泛型和继承，泛型和擦除" class="headerlink" title="泛型和继承，泛型和擦除"></a>泛型和继承，泛型和擦除</h3><h3 id="1-2-15-自动拆箱装箱与字节码"><a href="#1-2-15-自动拆箱装箱与字节码" class="headerlink" title="1.2.15. 自动拆箱装箱与字节码"></a>1.2.15. 自动拆箱装箱与字节码</h3><h3 id="实现Callback"><a href="#实现Callback" class="headerlink" title="实现Callback"></a>实现Callback</h3><h3 id="java-lang-Void类使用"><a href="#java-lang-Void类使用" class="headerlink" title="java.lang.Void类使用"></a>java.lang.Void类使用</h3><h3 id="Java-Agent，premain函数java-lang-instrument"><a href="#Java-Agent，premain函数java-lang-instrument" class="headerlink" title="Java Agent，premain函数java.lang.instrument"></a>Java Agent，premain函数java.lang.instrument</h3><h3 id="单元测试"><a href="#单元测试" class="headerlink" title="单元测试"></a>单元测试</h3><ul>
<li>Junit，<a href="http://junit.org/" target="_blank" rel="external">http://junit.org/</a></li>
<li>Jmockit，<a href="https://code.google.com/p/jmockit/" target="_blank" rel="external">https://code.google.com/p/jmockit/</a></li>
<li>djUnit，<a href="http://works.dgic.co.jp/djunit/" target="_blank" rel="external">http://works.dgic.co.jp/djunit/</a></li>
</ul>
<h3 id="Java实现通过正则表达式提取一段文本中的电子邮件，并将-替换为-输出java-lang-util-regex"><a href="#Java实现通过正则表达式提取一段文本中的电子邮件，并将-替换为-输出java-lang-util-regex" class="headerlink" title="Java实现通过正则表达式提取一段文本中的电子邮件，并将@替换为#输出java.lang.util.regex.*"></a>Java实现通过正则表达式提取一段文本中的电子邮件，并将@替换为#输出java.lang.util.regex.*</h3><h3 id="学习使用常用的Java工具库commons-lang-commons-…"><a href="#学习使用常用的Java工具库commons-lang-commons-…" class="headerlink" title="学习使用常用的Java工具库commons.lang, commons.*…"></a>学习使用常用的Java工具库commons.lang, commons.*…</h3><ul>
<li>guava-libraries</li>
<li>netty、jetty（storm、hadoop、spark也用到了）</li>
</ul>
<h3 id="什么是API-amp-SPI"><a href="#什么是API-amp-SPI" class="headerlink" title="什么是API&amp;SPI"></a>什么是API&amp;SPI</h3><p><a href="http://en.wikipedia.org/wiki/Application_programming_interface" target="_blank" rel="external">http://en.wikipedia.org/wiki/Application_programming_interface</a><br><a href="http://en.wikipedia.org/wiki/Service_provider_interface" target="_blank" rel="external">http://en.wikipedia.org/wiki/Service_provider_interface</a></p>
<h3 id="参考资料JDK-src-zip-源代码"><a href="#参考资料JDK-src-zip-源代码" class="headerlink" title="参考资料JDK src.zip 源代码"></a>参考资料JDK src.zip 源代码</h3><p><a href="http://openjdk.java.net/" target="_blank" rel="external">http://openjdk.java.net/</a><br><a href="http://commons.apache.org/" target="_blank" rel="external">http://commons.apache.org/</a><br><a href="https://code.google.com/p/guava-libraries/" target="_blank" rel="external">https://code.google.com/p/guava-libraries/</a><br><a href="http://netty.io/" target="_blank" rel="external">http://netty.io/</a><br><a href="http://stackoverflow.com/questions/2954372/difference-between-spi-and-api" target="_blank" rel="external">http://stackoverflow.com/questions/2954372/difference-between-spi-and-api</a><br><a href="http://stackoverflow.com/questions/11404230/how-to-implement-the-api-spi-pattern-in-java" target="_blank" rel="external">http://stackoverflow.com/questions/11404230/how-to-implement-the-api-spi-pattern-in-java</a></p>
<h2 id="Java并发编程"><a href="#Java并发编程" class="headerlink" title="Java并发编程"></a>Java并发编程</h2><h3 id="阅读源代码-1"><a href="#阅读源代码-1" class="headerlink" title="阅读源代码"></a>阅读源代码</h3><p>阅读源代码，并学会使用</p>
<ul>
<li>java.lang.Thread</li>
<li>java.lang.Runnable</li>
<li>java.util.concurrent.Callable</li>
<li>java.util.concurrent.locks.ReentrantLock</li>
<li>java.util.concurrent.locks.ReentrantReadWriteLock</li>
<li>java.util.concurrent.atomic.Atomic*</li>
<li>java.util.concurrent.Semaphore</li>
<li>java.util.concurrent.CountDownLatch</li>
<li>java.util.concurrent.CyclicBarrier</li>
<li>java.util.concurrent.ConcurrentHashMap</li>
<li>java.util.concurrent.Executors</li>
</ul>
<h3 id="学习使用线程池，自己设计线程池需要注意什么"><a href="#学习使用线程池，自己设计线程池需要注意什么" class="headerlink" title="学习使用线程池，自己设计线程池需要注意什么"></a>学习使用线程池，自己设计线程池需要注意什么</h3><h3 id="锁什么是锁，锁的种类有哪些，每种锁有什么特点，适用场景是什么，在并发编程中锁的意义是什么"><a href="#锁什么是锁，锁的种类有哪些，每种锁有什么特点，适用场景是什么，在并发编程中锁的意义是什么" class="headerlink" title="锁什么是锁，锁的种类有哪些，每种锁有什么特点，适用场景是什么，在并发编程中锁的意义是什么"></a>锁什么是锁，锁的种类有哪些，每种锁有什么特点，适用场景是什么，在并发编程中锁的意义是什么</h3><h3 id="synchronized的作用是什么，synchronized和lock"><a href="#synchronized的作用是什么，synchronized和lock" class="headerlink" title="synchronized的作用是什么，synchronized和lock"></a>synchronized的作用是什么，synchronized和lock</h3><h3 id="sleep和wait"><a href="#sleep和wait" class="headerlink" title="sleep和wait"></a>sleep和wait</h3><h3 id="wait和notify"><a href="#wait和notify" class="headerlink" title="wait和notify"></a>wait和notify</h3><h3 id="写一个死锁的程序"><a href="#写一个死锁的程序" class="headerlink" title="写一个死锁的程序"></a>写一个死锁的程序</h3><h3 id="什么是守护线程，守护线程和非守护线程的区别以及用法"><a href="#什么是守护线程，守护线程和非守护线程的区别以及用法" class="headerlink" title="什么是守护线程，守护线程和非守护线程的区别以及用法"></a>什么是守护线程，守护线程和非守护线程的区别以及用法</h3><h3 id="volatile关键字的理解C-volatile关键字和Java-volatile关键字"><a href="#volatile关键字的理解C-volatile关键字和Java-volatile关键字" class="headerlink" title="volatile关键字的理解C++ volatile关键字和Java volatile关键字"></a>volatile关键字的理解C++ volatile关键字和Java volatile关键字</h3><p>happens-before语义<br>编译器指令重排和CPU指令重排<br><a href="http://en.wikipedia.org/wiki/Memory_ordering" target="_blank" rel="external">http://en.wikipedia.org/wiki/Memory_ordering</a><br><a href="http://en.wikipedia.org/wiki/Volatile_variable" target="_blank" rel="external">http://en.wikipedia.org/wiki/Volatile_variable</a><br><a href="http://preshing.com/20130702/the-happens-before-relation/" target="_blank" rel="external">http://preshing.com/20130702/the-happens-before-relation/</a></p>
<h3 id="以下代码是不是线程安全？为什么？如果为count加上volatile修饰是否能够做到线程安全？你觉得该怎么做是线程安全的？"><a href="#以下代码是不是线程安全？为什么？如果为count加上volatile修饰是否能够做到线程安全？你觉得该怎么做是线程安全的？" class="headerlink" title="以下代码是不是线程安全？为什么？如果为count加上volatile修饰是否能够做到线程安全？你觉得该怎么做是线程安全的？"></a>以下代码是不是线程安全？为什么？如果为count加上volatile修饰是否能够做到线程安全？你觉得该怎么做是线程安全的？</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Sample</span> </span>&#123;</div><div class="line">  <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">int</span> count = <span class="number">0</span>;</div><div class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">increment</span><span class="params">()</span> </span>&#123;</div><div class="line">    count++;</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h3 id="解释一下下面两段代码的差别-代码1"><a href="#解释一下下面两段代码的差别-代码1" class="headerlink" title="解释一下下面两段代码的差别// 代码1"></a>解释一下下面两段代码的差别// 代码1</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Sample</span> </span>&#123;</div><div class="line">  <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">int</span> count = <span class="number">0</span>;</div><div class="line">  <span class="function"><span class="keyword">synchronized</span> <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">increment</span><span class="params">()</span> </span>&#123;</div><div class="line">    count++;</div><div class="line">  &#125;</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="comment">// 代码2</span></div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Sample</span> </span>&#123;</div><div class="line">  <span class="keyword">private</span> <span class="keyword">static</span> AtomicInteger count = <span class="keyword">new</span> AtomicInteger(<span class="number">0</span>);</div><div class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">increment</span><span class="params">()</span> </span>&#123;</div><div class="line">    count.getAndIncrement();</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h3 id="参考资料http-book-douban-com-subject-10484692"><a href="#参考资料http-book-douban-com-subject-10484692" class="headerlink" title="参考资料http://book.douban.com/subject/10484692/"></a>参考资料<a href="http://book.douban.com/subject/10484692/" target="_blank" rel="external">http://book.douban.com/subject/10484692/</a></h3><p><a href="http://www.intel.com/content/www/us/en/processors/architectures-software-developer-manuals.html" target="_blank" rel="external">http://www.intel.com/content/www/us/en/processors/architectures-software-developer-manuals.html</a></p>
<h1 id="进阶篇"><a href="#进阶篇" class="headerlink" title="进阶篇"></a>进阶篇</h1><h2 id="Java底层知识"><a href="#Java底层知识" class="headerlink" title="Java底层知识"></a>Java底层知识</h2><h3 id="学习了解字节码、class文件格式"><a href="#学习了解字节码、class文件格式" class="headerlink" title="学习了解字节码、class文件格式"></a>学习了解字节码、class文件格式</h3><p><a href="http://en.wikipedia.org/wiki/Java_class_file" target="_blank" rel="external">http://en.wikipedia.org/wiki/Java_class_file</a><br><a href="http://en.wikipedia.org/wiki/Java_bytecode" target="_blank" rel="external">http://en.wikipedia.org/wiki/Java_bytecode</a><br><a href="http://en.wikipedia.org/wiki/Java_bytecode_instruction_listings" target="_blank" rel="external">http://en.wikipedia.org/wiki/Java_bytecode_instruction_listings</a><br><a href="http://www.csg.ci.i.u-tokyo.ac.jp/~chiba/javassist/" target="_blank" rel="external">http://www.csg.ci.i.u-tokyo.ac.jp/~chiba/javassist/</a><br><a href="http://asm.ow2.org/" target="_blank" rel="external">http://asm.ow2.org/</a></p>
<h3 id="写一个程序要求实现javap的功能（手工完成，不借助ASM等工具）如Java源代码："><a href="#写一个程序要求实现javap的功能（手工完成，不借助ASM等工具）如Java源代码：" class="headerlink" title="写一个程序要求实现javap的功能（手工完成，不借助ASM等工具）如Java源代码："></a>写一个程序要求实现javap的功能（手工完成，不借助ASM等工具）如Java源代码：</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</div><div class="line">  <span class="keyword">int</span> i = <span class="number">0</span>;</div><div class="line">  i += <span class="number">1</span>;</div><div class="line">  i *= <span class="number">1</span>;</div><div class="line">  System.out.println(i);</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>  编译后读取class文件输出以下代码：</p>
<figure class="highlight"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div></pre></td><td class="code"><pre><div class="line">public static void main(java.lang.String[]);</div><div class="line">Code:</div><div class="line"> Stack=2, Locals=2, Args_size=1</div><div class="line"> 0:   iconst_0</div><div class="line"> 1:   istore_1</div><div class="line"> 2:   iinc    1, 1</div><div class="line"> 5:   iload_1</div><div class="line"> 6:   iconst_1</div><div class="line"> 7:   imul</div><div class="line"> 8:   istore_1</div><div class="line"> 9:   getstatic       #2; //Field java/lang/System.out:Ljava/io/PrintStream;</div><div class="line"> 12:  iload_1</div><div class="line"> 13:  invokevirtual   #3; //Method java/io/PrintStream.println:(I)V</div><div class="line"> 16:  return</div><div class="line">LineNumberTable:</div><div class="line"> line 4: 0</div><div class="line"> line 5: 2</div><div class="line"> line 6: 5</div><div class="line"> line 7: 9</div><div class="line"> line 8: 16</div></pre></td></tr></table></figure>
<h3 id="CPU缓存，L1，L2，L3和伪共享"><a href="#CPU缓存，L1，L2，L3和伪共享" class="headerlink" title="CPU缓存，L1，L2，L3和伪共享"></a>CPU缓存，L1，L2，L3和伪共享</h3><p><a href="http://duartes.org/gustavo/blog/post/intel-cpu-caches/" target="_blank" rel="external">http://duartes.org/gustavo/blog/post/intel-cpu-caches/</a><br><a href="http://mechanical-sympathy.blogspot.com/2011/07/false-sharing.html" target="_blank" rel="external">http://mechanical-sympathy.blogspot.com/2011/07/false-sharing.html</a></p>
<h3 id="什么是尾递归"><a href="#什么是尾递归" class="headerlink" title="什么是尾递归"></a>什么是尾递归</h3><h3 id="熟悉位运算用位运算实现加、减、乘、除、取余"><a href="#熟悉位运算用位运算实现加、减、乘、除、取余" class="headerlink" title="熟悉位运算用位运算实现加、减、乘、除、取余"></a>熟悉位运算用位运算实现加、减、乘、除、取余</h3><h3 id="参考资料-1"><a href="#参考资料-1" class="headerlink" title="参考资料"></a>参考资料</h3><p><a href="http://book.douban.com/subject/1138768/" target="_blank" rel="external">http://book.douban.com/subject/1138768/</a><br><a href="http://book.douban.com/subject/6522893/" target="_blank" rel="external">http://book.douban.com/subject/6522893/</a><br><a href="http://en.wikipedia.org/wiki/Java_class_file" target="_blank" rel="external">http://en.wikipedia.org/wiki/Java_class_file</a><br><a href="http://en.wikipedia.org/wiki/Java_bytecode" target="_blank" rel="external">http://en.wikipedia.org/wiki/Java_bytecode</a><br><a href="http://en.wikipedia.org/wiki/Java_bytecode_instruction_listings" target="_blank" rel="external">http://en.wikipedia.org/wiki/Java_bytecode_instruction_listings</a></p>
<h2 id="设计模式"><a href="#设计模式" class="headerlink" title="设计模式"></a>设计模式</h2><h3 id="实现AOPCGLIB和InvocationHandler的区别"><a href="#实现AOPCGLIB和InvocationHandler的区别" class="headerlink" title="实现AOPCGLIB和InvocationHandler的区别"></a>实现AOPCGLIB和InvocationHandler的区别</h3><p><a href="http://cglib.sourceforge.net/" target="_blank" rel="external">http://cglib.sourceforge.net/</a><br>动态代理模式<br>Javassist实现AOP<br><a href="http://www.csg.ci.i.u-tokyo.ac.jp/~chiba/javassist/" target="_blank" rel="external">http://www.csg.ci.i.u-tokyo.ac.jp/~chiba/javassist/</a><br>ASM实现AOP<br><a href="http://asm.ow2.org/" target="_blank" rel="external">http://asm.ow2.org/</a></p>
<h3 id="使用模板方法设计模式和策略设计模式实现IOC"><a href="#使用模板方法设计模式和策略设计模式实现IOC" class="headerlink" title="使用模板方法设计模式和策略设计模式实现IOC"></a>使用模板方法设计模式和策略设计模式实现IOC</h3><h3 id="不用synchronized和lock，实现线程安全的单例模式"><a href="#不用synchronized和lock，实现线程安全的单例模式" class="headerlink" title="不用synchronized和lock，实现线程安全的单例模式"></a>不用synchronized和lock，实现线程安全的单例模式</h3><h3 id="nio和reactor设计模式"><a href="#nio和reactor设计模式" class="headerlink" title="nio和reactor设计模式"></a>nio和reactor设计模式</h3><h3 id="参考资料http-asm-ow2-org"><a href="#参考资料http-asm-ow2-org" class="headerlink" title="参考资料http://asm.ow2.org/"></a>参考资料<a href="http://asm.ow2.org/" target="_blank" rel="external">http://asm.ow2.org/</a></h3><p><a href="http://cglib.sourceforge.net/" target="_blank" rel="external">http://cglib.sourceforge.net/</a><br><a href="http://www.javassist.org/" target="_blank" rel="external">http://www.javassist.org/</a></p>
<h2 id="网络编程知识"><a href="#网络编程知识" class="headerlink" title="网络编程知识"></a>网络编程知识</h2><h3 id="Java-RMI，Socket，HttpClient"><a href="#Java-RMI，Socket，HttpClient" class="headerlink" title="Java RMI，Socket，HttpClient"></a>Java RMI，Socket，HttpClient</h3><h3 id="用Java写一个简单的静态文件的HTTP服务器实现客户端缓存功能，支持返回304"><a href="#用Java写一个简单的静态文件的HTTP服务器实现客户端缓存功能，支持返回304" class="headerlink" title="用Java写一个简单的静态文件的HTTP服务器实现客户端缓存功能，支持返回304"></a>用Java写一个简单的静态文件的HTTP服务器实现客户端缓存功能，支持返回304</h3><ul>
<li>实现可并发下载一个文件</li>
<li>使用线程池处理客户端请求</li>
<li>使用nio处理客户端请求</li>
<li>支持简单的rewrite规则</li>
<li>上述功能在实现的时候需要满足“开闭原则”</li>
</ul>
<h3 id="了解nginx和apache服务器的特性并搭建一个对应的服务器"><a href="#了解nginx和apache服务器的特性并搭建一个对应的服务器" class="headerlink" title="了解nginx和apache服务器的特性并搭建一个对应的服务器"></a>了解nginx和apache服务器的特性并搭建一个对应的服务器</h3><p><a href="http://nginx.org/" target="_blank" rel="external">http://nginx.org/</a><br><a href="http://httpd.apache.org/" target="_blank" rel="external">http://httpd.apache.org/</a></p>
<h3 id="用Java实现FTP、SMTP协议"><a href="#用Java实现FTP、SMTP协议" class="headerlink" title="用Java实现FTP、SMTP协议"></a>用Java实现FTP、SMTP协议</h3><h3 id="什么是CDN？如果实现？DNS起到什么作用？搭建一个DNS服务器"><a href="#什么是CDN？如果实现？DNS起到什么作用？搭建一个DNS服务器" class="headerlink" title="什么是CDN？如果实现？DNS起到什么作用？搭建一个DNS服务器"></a>什么是CDN？如果实现？DNS起到什么作用？搭建一个DNS服务器</h3><p>搭建一个 Squid 或 Apache Traffic Server 服务器<br><a href="http://www.squid-cache.org/" target="_blank" rel="external">http://www.squid-cache.org/</a><br><a href="http://trafficserver.apache.org/" target="_blank" rel="external">http://trafficserver.apache.org/</a><br><a href="http://en.wikipedia.org/wiki/Domain_Name_System" target="_blank" rel="external">http://en.wikipedia.org/wiki/Domain_Name_System</a></p>
<h3 id="参考资料-2"><a href="#参考资料-2" class="headerlink" title="参考资料"></a>参考资料</h3><p><a href="http://www.ietf.org/rfc/rfc2616.txt" target="_blank" rel="external">http://www.ietf.org/rfc/rfc2616.txt</a><br><a href="http://tools.ietf.org/rfc/rfc5321.txt" target="_blank" rel="external">http://tools.ietf.org/rfc/rfc5321.txt</a><br><a href="http://en.wikipedia.org/wiki/Open/closed_principle" target="_blank" rel="external">http://en.wikipedia.org/wiki/Open/closed_principle</a></p>
<h2 id="框架知识spring，spring-mvc，阅读主要源码"><a href="#框架知识spring，spring-mvc，阅读主要源码" class="headerlink" title="框架知识spring，spring mvc，阅读主要源码"></a>框架知识spring，spring mvc，阅读主要源码</h2><p>ibatis，阅读主要源码<br>用spring和ibatis搭建java server</p>
<h2 id="应用服务器知识熟悉使用jboss，https-www-jboss-org-overview"><a href="#应用服务器知识熟悉使用jboss，https-www-jboss-org-overview" class="headerlink" title="应用服务器知识熟悉使用jboss，https://www.jboss.org/overview/"></a>应用服务器知识熟悉使用jboss，<a href="https://www.jboss.org/overview/" target="_blank" rel="external">https://www.jboss.org/overview/</a></h2><ul>
<li>熟悉使用tomcat，<a href="http://tomcat.apache.org/" target="_blank" rel="external">http://tomcat.apache.org/</a></li>
<li>熟悉使用jetty，<a href="http://www.eclipse.org/jetty/" target="_blank" rel="external">http://www.eclipse.org/jetty/</a></li>
</ul>
<h1 id="高级篇"><a href="#高级篇" class="headerlink" title="高级篇"></a>高级篇</h1><h2 id="编译原理知识"><a href="#编译原理知识" class="headerlink" title="编译原理知识"></a>编译原理知识</h2><h3 id="用Java实现以下表达式解析并返回结果（语法和Oracle中的select-sysdate-1-from-dual类似）-sysdate"><a href="#用Java实现以下表达式解析并返回结果（语法和Oracle中的select-sysdate-1-from-dual类似）-sysdate" class="headerlink" title="用Java实现以下表达式解析并返回结果（语法和Oracle中的select sysdate-1 from dual类似） sysdate"></a>用Java实现以下表达式解析并返回结果（语法和Oracle中的select sysdate-1 from dual类似） sysdate</h3><p> sysdate - 1<br> sysdate - 1/24<br> sysdate - 1/(12*2)</p>
<h3 id="实现对一个List通过DSL筛选-QList"><a href="#实现对一个List通过DSL筛选-QList" class="headerlink" title="实现对一个List通过DSL筛选  QList"></a>实现对一个List通过DSL筛选  QList<map<string, object="">&gt; mapList = new QList<map<string, object="">&gt;;</map<string,></map<string,></h3><p>  mapList.add({“name”: “hatter test”});<br>  mapList.add({“id”: -1,”name”: “hatter test”});<br>  mapList.add({“id”: 0, “name”: “hatter test”});<br>  mapList.add({“id”: 1, “name”: “test test”});<br>  mapList.add({“id”: 2, “name”: “hatter test”});<br>  mapList.add({“id”: 3, “name”: “test hatter”});<br>  mapList.query(“id is not null and id &gt; 0 and name like ‘%hatter%’”);<br>要求返回列表中匹配的对象，即最后两个对象；</p>
<h3 id="用Java实现以下程序（语法和变量作用域处理都和JavaScript类似）："><a href="#用Java实现以下程序（语法和变量作用域处理都和JavaScript类似）：" class="headerlink" title="用Java实现以下程序（语法和变量作用域处理都和JavaScript类似）："></a>用Java实现以下程序（语法和变量作用域处理都和JavaScript类似）：</h3><p>代码：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">var a = <span class="number">1</span>;</div><div class="line">var b = <span class="number">2</span>;</div><div class="line">var c = function() &#123;</div><div class="line">  var a = <span class="number">3</span>;</div><div class="line">  println(a);</div><div class="line">  println(b);</div><div class="line">&#125;;</div><div class="line">c();</div><div class="line">println(a);</div><div class="line">println(b);</div></pre></td></tr></table></figure>
<p>输出：<br>3<br>2<br>1<br>2</p>
<h3 id="参考资料-3"><a href="#参考资料-3" class="headerlink" title="参考资料"></a>参考资料</h3><p><a href="http://en.wikipedia.org/wiki/Abstract_syntax_tree" target="_blank" rel="external">http://en.wikipedia.org/wiki/Abstract_syntax_tree</a><br><a href="https://javacc.java.net/" target="_blank" rel="external">https://javacc.java.net/</a><br><a href="http://www.antlr.org/" target="_blank" rel="external">http://www.antlr.org/</a></p>
<h2 id="操作系统知识Ubuntu"><a href="#操作系统知识Ubuntu" class="headerlink" title="操作系统知识Ubuntu"></a>操作系统知识Ubuntu</h2><p>Centos<br>使用linux，熟悉shell脚本</p>
<h2 id="数据存储知识"><a href="#数据存储知识" class="headerlink" title="数据存储知识"></a>数据存储知识</h2><h3 id="关系型数据库MySQL"><a href="#关系型数据库MySQL" class="headerlink" title="关系型数据库MySQL"></a>关系型数据库MySQL</h3><ul>
<li>如何看执行计划</li>
<li>如何搭建MySQL主备</li>
<li>binlog是什么</li>
<li>Derby，H2，PostgreSQL</li>
<li>SQLite</li>
</ul>
<h3 id="NoSQLCache"><a href="#NoSQLCache" class="headerlink" title="NoSQLCache"></a>NoSQLCache</h3><ul>
<li>Redis</li>
<li>Memcached</li>
<li>Leveldb</li>
<li>Bigtable</li>
<li>HBase</li>
<li>Cassandra</li>
<li>Mongodb</li>
<li>图数据库</li>
<li>neo4j</li>
</ul>
<h3 id="参考资料-4"><a href="#参考资料-4" class="headerlink" title="参考资料"></a>参考资料</h3><p><a href="http://db-engines.com/en/ranking" target="_blank" rel="external">http://db-engines.com/en/ranking</a><br><a href="http://redis.io/" target="_blank" rel="external">http://redis.io/</a><br><a href="https://code.google.com/p/leveldb/" target="_blank" rel="external">https://code.google.com/p/leveldb/</a><br><a href="http://hbase.apache.org/" target="_blank" rel="external">http://hbase.apache.org/</a><br><a href="http://cassandra.apache.org/" target="_blank" rel="external">http://cassandra.apache.org/</a><br><a href="http://www.mongodb.org/" target="_blank" rel="external">http://www.mongodb.org/</a><br><a href="http://www.neo4j.org/" target="_blank" rel="external">http://www.neo4j.org/</a></p>
<h2 id="大数据知识"><a href="#大数据知识" class="headerlink" title="大数据知识"></a>大数据知识</h2><h3 id="Zookeeper，在linux上部署zk"><a href="#Zookeeper，在linux上部署zk" class="headerlink" title="Zookeeper，在linux上部署zk"></a>Zookeeper，在linux上部署zk</h3><h3 id="Solr，Lucene，ElasticSearch在linux上部署solr，solrcloud，，新增、删除、查询索引"><a href="#Solr，Lucene，ElasticSearch在linux上部署solr，solrcloud，，新增、删除、查询索引" class="headerlink" title="Solr，Lucene，ElasticSearch在linux上部署solr，solrcloud，，新增、删除、查询索引"></a>Solr，Lucene，ElasticSearch在linux上部署solr，solrcloud，，新增、删除、查询索引</h3><h3 id="Storm，流式计算，了解Spark，S4在linux上部署storm，用zookeeper做协调，运行storm-hello-world，local和remote模式运行调试storm-topology。"><a href="#Storm，流式计算，了解Spark，S4在linux上部署storm，用zookeeper做协调，运行storm-hello-world，local和remote模式运行调试storm-topology。" class="headerlink" title="Storm，流式计算，了解Spark，S4在linux上部署storm，用zookeeper做协调，运行storm hello world，local和remote模式运行调试storm topology。"></a>Storm，流式计算，了解Spark，S4在linux上部署storm，用zookeeper做协调，运行storm hello world，local和remote模式运行调试storm topology。</h3><h3 id="Hadoop，离线计算Hdfs：部署NameNode，SecondaryNameNode，DataNode，上传文件、打开文件、更改文件、删除文件"><a href="#Hadoop，离线计算Hdfs：部署NameNode，SecondaryNameNode，DataNode，上传文件、打开文件、更改文件、删除文件" class="headerlink" title="Hadoop，离线计算Hdfs：部署NameNode，SecondaryNameNode，DataNode，上传文件、打开文件、更改文件、删除文件"></a>Hadoop，离线计算Hdfs：部署NameNode，SecondaryNameNode，DataNode，上传文件、打开文件、更改文件、删除文件</h3><p>MapReduce：部署JobTracker，TaskTracker，编写mr job<br>Hive：部署hive，书写hive sql，得到结果<br>Presto：类hive，不过比hive快，非常值得学习</p>
<h3 id="分布式日志收集flume，kafka，logstash"><a href="#分布式日志收集flume，kafka，logstash" class="headerlink" title="分布式日志收集flume，kafka，logstash"></a>分布式日志收集flume，kafka，logstash</h3><h3 id="数据挖掘，mahout"><a href="#数据挖掘，mahout" class="headerlink" title="数据挖掘，mahout"></a>数据挖掘，mahout</h3><h3 id="参考资料-5"><a href="#参考资料-5" class="headerlink" title="参考资料"></a>参考资料</h3><p><a href="http://zookeeper.apache.org/" target="_blank" rel="external">http://zookeeper.apache.org/</a><br><a href="https://lucene.apache.org/solr/" target="_blank" rel="external">https://lucene.apache.org/solr/</a><br><a href="https://github.com/nathanmarz/storm/wiki" target="_blank" rel="external">https://github.com/nathanmarz/storm/wiki</a><br><a href="http://hadoop.apache.org/" target="_blank" rel="external">http://hadoop.apache.org/</a><br><a href="http://prestodb.io/" target="_blank" rel="external">http://prestodb.io/</a><br><a href="http://flume.apache.org/，http://logstash.net/，http://kafka.apache.org/" target="_blank" rel="external">http://flume.apache.org/，http://logstash.net/，http://kafka.apache.org/</a><br><a href="http://mahout.apache.org/" target="_blank" rel="external">http://mahout.apache.org/</a></p>
<h2 id="网络安全知识"><a href="#网络安全知识" class="headerlink" title="网络安全知识"></a>网络安全知识</h2><h3 id="什么是DES、AES"><a href="#什么是DES、AES" class="headerlink" title="什么是DES、AES"></a>什么是DES、AES</h3><h3 id="什么是RSA、DSA"><a href="#什么是RSA、DSA" class="headerlink" title="什么是RSA、DSA"></a>什么是RSA、DSA</h3><h3 id="什么是MD5，SHA1"><a href="#什么是MD5，SHA1" class="headerlink" title="什么是MD5，SHA1"></a>什么是MD5，SHA1</h3><h3 id="什么是SSL、TLS，为什么HTTPS相对比较安全"><a href="#什么是SSL、TLS，为什么HTTPS相对比较安全" class="headerlink" title="什么是SSL、TLS，为什么HTTPS相对比较安全"></a>什么是SSL、TLS，为什么HTTPS相对比较安全</h3><h3 id="什么是中间人攻击、如果避免中间人攻击"><a href="#什么是中间人攻击、如果避免中间人攻击" class="headerlink" title="什么是中间人攻击、如果避免中间人攻击"></a>什么是中间人攻击、如果避免中间人攻击</h3><h3 id="什么是DOS、DDOS、CC攻击"><a href="#什么是DOS、DDOS、CC攻击" class="headerlink" title="什么是DOS、DDOS、CC攻击"></a>什么是DOS、DDOS、CC攻击</h3><h3 id="什么是CSRF攻击"><a href="#什么是CSRF攻击" class="headerlink" title="什么是CSRF攻击"></a>什么是CSRF攻击</h3><h3 id="什么是CSS攻击"><a href="#什么是CSS攻击" class="headerlink" title="什么是CSS攻击"></a>什么是CSS攻击</h3><h3 id="什么是SQL注入攻击"><a href="#什么是SQL注入攻击" class="headerlink" title="什么是SQL注入攻击"></a>什么是SQL注入攻击</h3><h3 id="什么是Hash碰撞拒绝服务攻击"><a href="#什么是Hash碰撞拒绝服务攻击" class="headerlink" title="什么是Hash碰撞拒绝服务攻击"></a>什么是Hash碰撞拒绝服务攻击</h3><h3 id="了解并学习下面几种增强安全的技术"><a href="#了解并学习下面几种增强安全的技术" class="headerlink" title="了解并学习下面几种增强安全的技术"></a>了解并学习下面几种增强安全的技术</h3><p><a href="http://www.openauthentication.org/" target="_blank" rel="external">http://www.openauthentication.org/</a><br>HOTP <a href="http://www.ietf.org/rfc/rfc4226.txt" target="_blank" rel="external">http://www.ietf.org/rfc/rfc4226.txt</a><br>TOTP <a href="http://tools.ietf.org/rfc/rfc6238.txt" target="_blank" rel="external">http://tools.ietf.org/rfc/rfc6238.txt</a><br>OCRA <a href="http://tools.ietf.org/rfc/rfc6287.txt" target="_blank" rel="external">http://tools.ietf.org/rfc/rfc6287.txt</a><br><a href="http://en.wikipedia.org/wiki/Salt_(cryptography" target="_blank" rel="external">http://en.wikipedia.org/wiki/Salt_(cryptography</a>)</p>
<h3 id="用openssl签一个证书部署到apache或nginx"><a href="#用openssl签一个证书部署到apache或nginx" class="headerlink" title="用openssl签一个证书部署到apache或nginx"></a>用openssl签一个证书部署到apache或nginx</h3><h3 id="参考资料-6"><a href="#参考资料-6" class="headerlink" title="参考资料"></a>参考资料</h3><p><a href="http://en.wikipedia.org/wiki/Cryptographic_hash_function" target="_blank" rel="external">http://en.wikipedia.org/wiki/Cryptographic_hash_function</a><br><a href="http://en.wikipedia.org/wiki/Block_cipher" target="_blank" rel="external">http://en.wikipedia.org/wiki/Block_cipher</a><br><a href="http://en.wikipedia.org/wiki/Public-key_cryptography" target="_blank" rel="external">http://en.wikipedia.org/wiki/Public-key_cryptography</a><br><a href="http://en.wikipedia.org/wiki/Transport_Layer_Security" target="_blank" rel="external">http://en.wikipedia.org/wiki/Transport_Layer_Security</a><br><a href="http://www.openssl.org/" target="_blank" rel="external">http://www.openssl.org/</a><br><a href="https://code.google.com/p/google-authenticator/" target="_blank" rel="external">https://code.google.com/p/google-authenticator/</a></p>
<h1 id="扩展篇"><a href="#扩展篇" class="headerlink" title="扩展篇"></a>扩展篇</h1><h2 id="相关知识"><a href="#相关知识" class="headerlink" title="相关知识"></a>相关知识</h2><h3 id="云计算，分布式，高可用，可扩展"><a href="#云计算，分布式，高可用，可扩展" class="headerlink" title="云计算，分布式，高可用，可扩展"></a>云计算，分布式，高可用，可扩展</h3><h3 id="虚拟化"><a href="#虚拟化" class="headerlink" title="虚拟化"></a>虚拟化</h3><p><a href="https://linuxcontainers.org/" target="_blank" rel="external">https://linuxcontainers.org/</a><br><a href="http://www.linux-kvm.org/page/Main_Page" target="_blank" rel="external">http://www.linux-kvm.org/page/Main_Page</a><br><a href="http://www.xenproject.org/" target="_blank" rel="external">http://www.xenproject.org/</a><br><a href="https://www.docker.io/" target="_blank" rel="external">https://www.docker.io/</a></p>
<h3 id="监控"><a href="#监控" class="headerlink" title="监控"></a>监控</h3><p><a href="http://www.nagios.org/" target="_blank" rel="external">http://www.nagios.org/</a><br><a href="http://ganglia.info/" target="_blank" rel="external">http://ganglia.info/</a></p>
<h3 id="负载均衡"><a href="#负载均衡" class="headerlink" title="负载均衡"></a>负载均衡</h3><p><a href="http://www.linuxvirtualserver.org/" target="_blank" rel="external">http://www.linuxvirtualserver.org/</a></p>
<h3 id="学习使用"><a href="#学习使用" class="headerlink" title="学习使用"></a>学习使用</h3><p>git<a href="https://github.com/" target="_blank" rel="external">https://github.com/</a><br><a href="https://git.oschina.net/" target="_blank" rel="external">https://git.oschina.net/</a></p>
<h3 id="学习使用-1"><a href="#学习使用-1" class="headerlink" title="学习使用"></a>学习使用</h3><p>maven<a href="http://maven.apache.org/" target="_blank" rel="external">http://maven.apache.org/</a></p>
<h3 id="学习使用-2"><a href="#学习使用-2" class="headerlink" title="学习使用"></a>学习使用</h3><p>gradle<a href="http://www.gradle.org/" target="_blank" rel="external">http://www.gradle.org/</a></p>
<h3 id="学习一个小语种语言"><a href="#学习一个小语种语言" class="headerlink" title="学习一个小语种语言"></a>学习一个小语种语言</h3><ul>
<li>Groovy</li>
<li>Scala</li>
<li>LISP, Common LISP, Schema, Clojure</li>
<li>R</li>
<li>Julia</li>
<li>Lua</li>
<li>Ruby</li>
</ul>
<h3 id="尝试了解编码的本质了解以下概念"><a href="#尝试了解编码的本质了解以下概念" class="headerlink" title="尝试了解编码的本质了解以下概念"></a>尝试了解编码的本质了解以下概念</h3><p>ASCII, ISO-8859-1<br>GB2312, GBK, GB18030<br>Unicode, UTF-8<br>不使用 String.getBytes() 等其他工具类/函数完成下面功能</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> IOException </span>&#123;</div><div class="line">    String str = <span class="string">"Hello, 我们是中国人。"</span>;</div><div class="line">    <span class="keyword">byte</span>[] utf8Bytes = toUTF8Bytes(str);</div><div class="line">    FileOutputStream fos = <span class="keyword">new</span> FileOutputStream(<span class="string">"f.txt"</span>);</div><div class="line">    fos.write(utf8Bytes);</div><div class="line">    fos.close();</div><div class="line">&#125;</div><div class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">byte</span>[] toUTF8Bytes(String str) &#123;</div><div class="line">    <span class="keyword">return</span> <span class="keyword">null</span>; <span class="comment">// TODO</span></div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>想一下上面的程序能不能写一个转GBK的？<br>写个程序自动判断一个文件是哪种编码</p>
<h3 id="尝试了解时间的本质时区-amp-冬令时、夏令时"><a href="#尝试了解时间的本质时区-amp-冬令时、夏令时" class="headerlink" title="尝试了解时间的本质时区 &amp; 冬令时、夏令时"></a>尝试了解时间的本质时区 &amp; 冬令时、夏令时</h3><p><a href="http://en.wikipedia.org/wiki/Time_zone" target="_blank" rel="external">http://en.wikipedia.org/wiki/Time_zone</a><br>ftp://ftp.iana.org/tz/data/asia<br><a href="http://zh.wikipedia.org/wiki/%E4%B8%AD%E5%9C%8B%E6%99%82%E5%8D%80" target="_blank" rel="external">http://zh.wikipedia.org/wiki/%E4%B8%AD%E5%9C%8B%E6%99%82%E5%8D%80</a><br>闰年<br><a href="http://en.wikipedia.org/wiki/Leap_year" target="_blank" rel="external">http://en.wikipedia.org/wiki/Leap_year</a><br>闰秒<br>ftp://ftp.iana.org/tz/data/leapseconds<br>System.currentTimeMillis() 返回的时间是什么</p>
<h3 id="参考资料-7"><a href="#参考资料-7" class="headerlink" title="参考资料"></a>参考资料</h3><p><a href="http://git-scm.com/" target="_blank" rel="external">http://git-scm.com/</a><br><a href="http://en.wikipedia.org/wiki/UTF-8" target="_blank" rel="external">http://en.wikipedia.org/wiki/UTF-8</a><br><a href="http://www.iana.org/time-zones" target="_blank" rel="external">http://www.iana.org/time-zones</a></p>
<h2 id="扩展学习"><a href="#扩展学习" class="headerlink" title="扩展学习"></a>扩展学习</h2><h3 id="JavaScript知识"><a href="#JavaScript知识" class="headerlink" title="JavaScript知识"></a>JavaScript知识</h3><h4 id="什么是prototype修改代码，使程序输出“1-3-5”："><a href="#什么是prototype修改代码，使程序输出“1-3-5”：" class="headerlink" title="什么是prototype修改代码，使程序输出“1 3 5”："></a>什么是prototype修改代码，使程序输出“1 3 5”：</h4><p><a href="http://jsfiddle.net/Ts7Fk/" target="_blank" rel="external">http://jsfiddle.net/Ts7Fk/</a></p>
<h4 id="什么是闭包看一下这段代码，并解释一下为什么按Button1时没有alert出“This-is-button-1”，如何修改："><a href="#什么是闭包看一下这段代码，并解释一下为什么按Button1时没有alert出“This-is-button-1”，如何修改：" class="headerlink" title="什么是闭包看一下这段代码，并解释一下为什么按Button1时没有alert出“This is button: 1”，如何修改："></a>什么是闭包看一下这段代码，并解释一下为什么按Button1时没有alert出“This is button: 1”，如何修改：</h4><p><a href="http://jsfiddle.net/FDPj3/1/" target="_blank" rel="external">http://jsfiddle.net/FDPj3/1/</a></p>
<h4 id="了解并学习一个JS框架jQuery"><a href="#了解并学习一个JS框架jQuery" class="headerlink" title="了解并学习一个JS框架jQuery"></a>了解并学习一个JS框架jQuery</h4><p>ExtJS<br>ArgularJS</p>
<h4 id="写一个Greasemonkey插件"><a href="#写一个Greasemonkey插件" class="headerlink" title="写一个Greasemonkey插件"></a>写一个Greasemonkey插件</h4><p><a href="http://en.wikipedia.org/wiki/Greasemonkey" target="_blank" rel="external">http://en.wikipedia.org/wiki/Greasemonkey</a></p>
<h4 id="学习node"><a href="#学习node" class="headerlink" title="学习node."></a>学习node.</h4><p>js<a href="http://nodejs.org/" target="_blank" rel="external">http://nodejs.org/</a></p>
<h4 id="学习html5ArgularJS，"><a href="#学习html5ArgularJS，" class="headerlink" title="学习html5ArgularJS，"></a>学习html5ArgularJS，</h4><p><a href="https://docs.angularjs.org/api" target="_blank" rel="external">https://docs.angularjs.org/api</a></p>
<h3 id="参考资料-8"><a href="#参考资料-8" class="headerlink" title="参考资料"></a>参考资料</h3><p><a href="http://www.ecmascript.org/" target="_blank" rel="external">http://www.ecmascript.org/</a><br><a href="http://jsfiddle.net/" target="_blank" rel="external">http://jsfiddle.net/</a><br><a href="http://jsbin.com/" target="_blank" rel="external">http://jsbin.com/</a><br><a href="http://runjs.cn/" target="_blank" rel="external">http://runjs.cn/</a><br><a href="http://userscripts.org/" target="_blank" rel="external">http://userscripts.org/</a></p>
<h1 id="推荐书籍"><a href="#推荐书籍" class="headerlink" title="推荐书籍"></a>推荐书籍</h1><ul>
<li>《深入Java虚拟机》</li>
<li>《深入理解Java虚拟机》</li>
<li>《Effective Java》</li>
<li>《七周七语言》</li>
<li>《七周七数据》</li>
<li>《Hadoop技术内幕》</li>
<li>《Hbase In Action》</li>
<li>《Mahout In Action》</li>
<li>《这就是搜索引擎》</li>
<li>《Solr In Action》</li>
<li>《深入分析Java Web技术内幕》</li>
<li>《大型网站技术架构》</li>
<li>《高性能MySQL》</li>
<li>《算法导论》</li>
<li>《计算机程序设计艺术》</li>
<li>《代码大全》</li>
<li>《JavaScript权威指南》</li>
</ul>
<hr>
<h1 id="想要说的"><a href="#想要说的" class="headerlink" title="想要说的"></a>想要说的</h1><p>之所以要转载这篇文章，是感觉在做了一年多Java开发之后，发现自己很多的基础知识掌握得很不好，尤其是在面试中发现了自己很多的问题，所以准备系统再去学习一下，好好补补基础部分。</p>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[Kafka之消息传输]]></title>
      <url>http://matt33.com/2016/03/09/kafka-transmit/</url>
      <content type="html"><![CDATA[<p>问题研究：</p>
<ol>
<li>研究Kafka consumer和broker之间的数据传输方式？</li>
<li>Kafka是如何保证可靠性？</li>
<li>消费机制是consumer pull还是broker push？, 如果是push的话，kafka是否知道数据传输成功</li>
</ol>
<h2 id="0-写在前面"><a href="#0-写在前面" class="headerlink" title="0.写在前面"></a>0.写在前面</h2><p>昨天整理完<a href="http://matt33.com/2016/03/08/kafka-store">Kafka之数据存储</a>之后，今天决定再把笔记中kafka消息传输部分整理一下，逐步去完善kafka系列的博文。本文中讲述的kafka是<code>0.8.1</code>版，目前最新版的<code>0.9.0</code>版把consumer的<code>The high-level Consumer API</code>和<code>The SimpleConsumer API</code>结合到了一起，这个是最新版的变化的最大之处，这个以后再讲（本来打算分两篇讲解consumer的，看来这样写了）。</p>
<h2 id="1-消息传递机制"><a href="#1-消息传递机制" class="headerlink" title="1.消息传递机制"></a>1.消息传递机制</h2><p>kafka在保证消息在producer和consumer之间的传输，主要有以下几种可能的delivery guaratee:</p>
<ul>
<li><strong>At most once</strong>：消息可能会丢，但绝不会重复传输;</li>
<li><strong>At least one</strong>：消息绝不会丢，但可能会重复传输;</li>
<li><strong>Exactly once</strong>：每条消息肯定会被传输一次且仅传输一次.</li>
</ul>
<p><strong>producer到broker端</strong>，当kafka的producer向broker发送消息时，一旦这条消息被commit，因为有replication的存在，它就不会丢失。但如果producer发送数据给broker后，遇到的网络问题而造成通信中断，那producer就无法判断该条消息是否已经commit，（这一点有点像向一个自动生成primary key的数据库表中插入数据，虽然Kafka无法确定网络故障期间发生了什么，但是producer可以生成一种类似于primary key的东西，发生故障时幂等性的retry多次，这样就做到了Exactly one。这一feature可能会在kafka未来的版本中实现），目前默认的情况下，一条消息从producer到broker是确保了At least once，但可通过设置producer异步发送实现At most once（可以在<code>request.required.acks</code>中设置）。</p>
<p><strong>broker到consumer端</strong>（对于heigh level API），consumer在从broker读取消息后，可以选择commit，该操作会在zookeeper中存储下该consumer在该partition下读取消息的offset。该consumer下一次再读该partition时会从下一条开始读取。如未commit，下一次读取的开始位置会跟上一次commit之后的开始位置相同。当然可以将consumer设置为autocommit，即consumer一旦读到数据立即自动commit。如果只讨论这一读取消息的过程，那Kafka是确保了Exactly once。但实际上实际使用中consumer并非读取完数据就结束了，而是要进行进一步处理，而数据处理与commit的顺序在很大程度上决定了消息从broker和consumer的delivery guarantee semantic。下面介绍以下这两种情况的区别：</p>
<ol>
<li>读完消息先commit再处理消息。这种模式下，如果consumer在commit后还没来得及处理消息就crash了，下次重新开始工作后就无法读到刚刚已提交而未处理的消息，这就对应于At most once；</li>
<li>读完消息先处理再commit。这种模式下，如果处理完了消息在commit之前consumer crash了，下次重新开始工作时还会处理刚刚未commit的消息，实际上该消息已经被处理过了。这就对应于At least once。</li>
</ol>
<p>如果一定要做到Exactly once，就需要协调offset和实际操作的输出。精典的做法是引入<strong>两阶段提交</strong>。如果能让offset和操作输入存在同一个地方，会更简洁和通用。这种方式可能更好，因为许多输出系统可能不支持两阶段提交。比如，consumer拿到数据后可能把数据放到HDFS，如果把最新的offset和数据本身一起写到HDFS，那就可以保证数据的输出和offset的更新要么都完成，要么都不完成，间接实现Exactly once。（目前就high level API而言，offset是存于Zookeeper中的，无法存于HDFS，而low level API的offset是由自己去维护的，可以将之存于HDFS中）。</p>
<p>总之，kafka默认保证At least once，并且允许通过设置producer异步提交来实现At most once。而Exactly once要求与目标存储系统协作，幸运的是kafka提供的offset可以使用这种方式非常直接非常容易。</p>
<h2 id="2-消费机制"><a href="#2-消费机制" class="headerlink" title="2. 消费机制"></a>2. 消费机制</h2><ul>
<li><strong>Topic</strong>：Topic在逻辑上可以认为是一个queue，每条消息必须指定它的topic，可以简单理解为把这条消息放进哪个queue里；</li>
<li><strong>partition</strong>：为了使kafka的吞吐率可以水平扩展，物理上把topic分成为一个或多个partition，每个partition物理上对应一个文件夹，该文件夹下存储这个partition的所有消息和索引文件。</li>
</ul>
<p>kafka消费高效率的原因：</p>
<ul>
<li>顺序写入磁盘；</li>
<li>broker是无状态的，不需要锁机制；</li>
</ul>
<h3 id="2-1-磁盘顺序写入"><a href="#2-1-磁盘顺序写入" class="headerlink" title="2.1.磁盘顺序写入"></a>2.1.磁盘顺序写入</h3><p>一个和磁盘性能有关的关键事实是：磁盘驱动器的吞吐量跟寻到延迟是相背离的，也就是说，线性写的速度远远大于随机写。比如：在一个6 7200rpm SATA RAID-5 的磁盘阵列上线性写的速度大概是600M/秒，但是随机写的速度只有100K/秒，两者相差将近6000倍。线性读写在大多数应用场景下是可以预测的，因此，操作系统利用read-ahead和write-behind技术来从大的数据块中预取数据，或者将多个逻辑上的写操作组合成一个大写物理写操作中（<a href="http://blog.csdn.net/suifeng3051/article/details/48053965" target="_blank" rel="external">Kafka设计原理详解</a>）。</p>
<h3 id="2-2-broker的无状态"><a href="#2-2-broker的无状态" class="headerlink" title="2.2.broker的无状态"></a>2.2.broker的无状态</h3><p>kafka在为每个consuemr group保留一些metadata信息（当前消费的position，即offset），这个offset由consumer控制，正常情况下consumer会在消费完一条消息后线性增加这个offset。因此，在一些情况下，kafka可以重新设置offset来重新消费一些信息。因为offset由consumer控制，所以broker是无状态的，它不需要标记哪些消息被哪些consumer消费过了，不需要通过broker去保证同一个consumer group只有一个consumer能消费同一条信息，因此不需要锁机制。</p>
<h4 id="2-2-1-replica"><a href="#2-2-1-replica" class="headerlink" title="2.2.1.replica"></a>2.2.1.replica</h4><p>先说一下kafka为何需要Replication，在Kafka在0.8以前的版本中，是没有Replication的，一旦某一个Broker宕机，则其上所有的Partition数据都不可被消费，这与kafka数据持久性及Delivery Guarantee的设计目标相悖。同时Producer都不能再将数据存于这些Partition中。</p>
<ul>
<li>如果Producer使用同步模式则Producer会在尝试重新发送<code>message.send.max.retries</code>（默认值为3）次后抛出Exception，用户可以选择停止发送后续数据也可选择继续选择发送。而前者会造成本应发往该Broker的数据的丢失，后者会造成数据的阻塞。</li>
<li>如果Producer使用异步模式，则Producer会尝试重新发<code>送message.send.max.retries</code>（默认值为3）次后记录该异常并继续发送后续数据，这会造成数据丢失并且用户只能通过日志发现该问题。</li>
</ul>
<p>由此可见，在没有Replication的情况下，一旦某机器宕机或者某个Broker停止工作则会造成整个系统的可用性降低。随着集群规模的增加，整个集群中出现该类异常的几率大大增加，因此对于生产系统而言Replication机制的引入非常重要。 　　</p>
<p>当一个topic有多个partition，而每个partition又有多个replica时，kafka的Replica算法如下：</p>
<ol>
<li>将所有Broker（假设共有n个Broker）和待分配的Partition排序；</li>
<li>将第i个Partition分配到第<code>i mod n</code>个Broker上；</li>
<li>将第i个Partition的第j个Replica分配到第<code>(i + j) mod n</code>个Broker上。</li>
</ol>
<p>下面我们举一个例子，假设topic有3个partition，而每个partition又有3个replica，此时Broker有4个节点，Replica分配效果图如下：</p>
<p><img src="/images/2016-03-08-KafkaTransmit/broker.png" alt="broker"></p>
<h4 id="2-2-2-leader"><a href="#2-2-2-leader" class="headerlink" title="2.2.2.leader"></a>2.2.2.leader</h4><p>接着，我们再说一下kafka为何需要Leader Election。</p>
<p>在引入Replication之后，同一个Partition可能会有多个Replica，而这时需要在这些Replication之间选出一个Leader，Producer和Consumer只与这个Leader交互，其它Replica作为Follower从Leader中复制数据。</p>
<p>因为需要保证同一个Partition的多个Replica之间的数据一致性（其中一台宕机后其它Replica必须要能继续服务并且即不能造成数据重复也不能造成数据丢失）。如果没有一个Leader，所有Replica都可同时读/写数据，那就需要保证多个Replica之间互相（$N×N$条通路）同步数据，数据的一致性和有序性非常难保证，大大增加了Replication实现的复杂性，同时也增加了出现异常的机率。而引入Leader后，只有Leader负责数据读写，Follower只向Leader顺序Fetch数据（N条通路），系统更加简单且高效。</p>
<p>leader的性质有以下几条：</p>
<ul>
<li>每个partition都有一个leader，所有的读写操作都在leader上完成；</li>
<li>一般情况下，partition大于等于broker的数量，并且所有partition的leader均匀分布在broker上，follower上的日志和其leader上的完全一样。</li>
<li>leader会track <code>in sync</code>的node list。如果一个follower宕机或者落后太多(超过预定值)，leader就把它从<code>in sync list</code>中移除。</li>
</ul>
<ul>
<li>一条消息只有被<code>in sync list</code>里的所有follower都从leader复制过来才会被认为已提交（避免了一些数据写入了leader，但还没来得及被任何follower复制就宕机了而造成数据丢失）。对于producer而言，它可以选择是否等待消息commit，这可以通过<code>request.required.acks</code>来设置，这种机制确保了只要<code>in sync list</code>有一个或一个以上的follower，一条被commit的消息就不会丢失。</li>
</ul>
<p>同步复制与异步复制的区别：</p>
<ul>
<li><strong>同步复制</strong>，要求alive状态的follower都复制完，这条消息才会被commit，这种复制方式极大的影响了吞吐率；</li>
<li><strong>异步复制</strong>，follower异步地从leader复制数据，数据只要被写入log就认为已经commit，这种情况下如果follower都落后于leader，而leader都落后于leader，而leader突然宕机则会丢失数据。</li>
</ul>
<p>kafka判断一台broker是否alive的条件有两个：</p>
<ul>
<li>broker必须维护与zookeeper的session（zookeeper的心跳机制）；</li>
<li>follower必须能够及时将leader的writting复制过来，不能落后太多（在<code>config/server.properties</code>设置，如下）；</li>
</ul>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">#If a replica falls more than this many messages behind the leader, the leader will remove the follower from ISR and treat it as dead</div><div class="line">replica.lag.max.messages=4000</div><div class="line">#If a follower hasn't sent any fetch requests for this window of time, the leader will remove the follower from ISR (in-sync replicas) and treat it as dead</div><div class="line">replica.lag.time.max.ms=10000</div></pre></td></tr></table></figure>
<p>而kafka的复制机制既不是完全的同步复制，也不是单纯的异步复制。kafka使用了<code>in sync list</code>的方式，很好的均衡了确保数据不丢失以及吞吐率，follower可以批量的从leader复制数据，这样极大的提高复制能力（批量写入磁盘），极大地减少了follower与leader的差距。</p>
<p>这里介绍一下kafka的<strong>ISR(in-sync replicas)模式</strong>。kafka在zookeeper中动态地维护了一个ISR，这个ISR里的所有Replica都跟的上了leader，只有ISR成员才有被选为leader的可能。在这种模式下，对于f+1个Replica，一个Partition能在保证不丢失（已经commit）的前提下容忍f个Replica的失败。在大多数场景下，这种模式是非常有利的。</p>
<p><strong>当leader宕机的情况，leader election算法</strong></p>
<p>这种情况是很复杂的，当leader宕机时，我们需要在follower中选举出新的leader。因为follower可能落后于许多或者宕机了，所以必须保证“最新”的follower作为leader。一个基本的原则就是，如果leader不在了，新的leader必须拥有原来的leader commit的所有消息。这就需要做一个折衷，如果leader标明一条消息被commit前等待更多的follower确认，那它die之后就会有更多的leader可以作为新的leader，但这也会造成吞吐率的下降。</p>
<p>常见的leader election算法有：</p>
<ul>
<li><a href="http://blog.cloudera.com/blog/2012/10/quorum-based-journaling-in-cdh4-1/" target="_blank" rel="external">HDFS的HA feature</a></li>
<li><a href="http://web.stanford.edu/class/cs347/reading/zab.pdf" target="_blank" rel="external">zookeeper的Zzb</a></li>
<li><a href="http://pmg.csail.mit.edu/papers/vr-revisited.pdf" target="_blank" rel="external">zookeeper的Viewstamped Replication</a></li>
<li><a href="https://ramcloud.stanford.edu/wiki/download/attachments/11370504/raft.pdf" target="_blank" rel="external">zookeeper的Raft</a></li>
<li><a href="http://research.microsoft.com/apps/pubs/default.aspx?id=66814" target="_blank" rel="external">MS的PacificA算法</a></li>
</ul>
<p>kafka使用的leader elcetion算法与微软的Pacifica算法相似，就是上面所讲述的<code>ISR</code>模式。kafka在zookeeper中动态地维护了一个<code>ISR</code>set，这个set里的所有replica都跟上了leader，只有ISR里的成员才有被选为leader的可能。在这种模式下，对于f+1个replica，一个topic在保证不丢失已经commit的消息的前提下最多可以容忍f个replica的失败。</p>
<p><strong>如何处理所有Replica都不工作的情况</strong></p>
<p>前面已经提到，在ISR中至少有一个follower时，Kafka可以确保已经commit的数据不丢失，但如果某个Partition的所有Replica都宕机了，就无法保证数据不丢失了。这种情况下有两种可行的方案：</p>
<ul>
<li>等待ISR中的任一个Replica“活”过来，并且选它作为Leader；</li>
<li>选择第一个“活”过来的Replica（不一定是ISR中的）作为Leader。
　</li>
</ul>
<p>这就需要在可用性和一致性当中作出一个简单的折衷。如果一定要等待ISR中的Replica“活”过来，那不可用的时间就可能会相对较长。而且如果ISR中的所有Replica都无法“活”过来了，或者数据都丢失了，这个Partition将永远不可用。选择第一个“活”过来的Replica作为Leader，而这个Replica不是ISR中的Replica，那即使它并不保证已经包含了所有已commit的消息，它也会成为Leader而作为consumer的数据源（前文有说明，所有读写都由Leader完成）。Kafka0.8.*使用了第二种方式。根据Kafka的文档，在以后的版本中，Kafka支持用户通过配置选择这两种方式中的一种，从而根据不同的使用场景选择高可用性还是强一致性。</p>
<p><strong>如何选举Leader</strong></p>
<p>最简单最直观的方案是，所有Follower都在Zookeeper上设置一个Watch，一旦Leader宕机，其对应的ephemeral znode会自动删除，此时所有Follower都尝试创建该节点，而创建成功者（Zookeeper保证只有一个能创建成功）即是新的Leader，其它Replica即为Follower。</p>
<p>但是该方法会有3个问题： 　　</p>
<ul>
<li>split-brain，这是由Zookeeper的特性引起的，虽然Zookeeper能保证所有Watch按顺序触发，但并不能保证同一时刻所有Replica“看”到的状态是一样的，这就可能造成不同Replica的响应不一致；</li>
<li>herd effect，如果宕机的那个Broker上的Partition比较多，会造成多个Watch被触发，造成集群内大量的调整；</li>
<li>Zookeeper负载过重，每个Replica都要为此在Zookeeper上注册一个Watch，当集群规模增加到几千个Partition时Zookeeper负载会过重。</li>
</ul>
<p>Kafka 0.8.*的Leader Election方案解决了上述问题，它在所有broker中选出一个<strong>controller</strong>，所有Partition的Leader选举都由controller决定。controller会将Leader的改变直接通过RPC的方式（比Zookeeper Queue的方式更高效）通知需为此作出响应的Broker。同时controller也负责增删Topic以及Replica的重新分配。</p>
<h3 id="2-3-consumer的reblance"><a href="#2-3-consumer的reblance" class="headerlink" title="2.3.consumer的reblance"></a>2.3.consumer的reblance</h3><p>kafka保证同一个consumer group中只有一个consumer会消费某条消息，实际上，kafka保证的事稳定状态下每一个consumer实例只会消费某一个或特定partition的数据，而某个partition的数据只会被某一个特定的consumer实例所消费。</p>
<p>这样设计的优点：</p>
<ul>
<li>每个consumer不用都跟broker进行大量的通信，减少通信开销，降低了分配难度；</li>
<li>同一个partition里的数据是有序的，保证每个partition里的数据是有序被消费的。</li>
</ul>
<p>设计的缺点：</p>
<ul>
<li>无法让同一个group里的consumer均匀消费数据。</li>
</ul>
<p>consumer的<strong>reblance算法</strong>如下（去看源码分析）：</p>
<ul>
<li>Sort $PT$ (all partitions in topic T)</li>
<li>Sort $CG$(all consumers in consumer group G)</li>
<li>Let i be the index position of $C_{i}$ in $CG$ and let $N=\lceil\frac{size(PT)}{size(CG)}\rceil$</li>
<li>Remove current entries owned by $C_{i}$ from the partition owner registry</li>
<li>Assign partitions from $iN$ to $(i+1)N-1$ to consumer $C_{i}$</li>
<li>Add newly assigned partitions to the partition owner registry</li>
</ul>
<p>consumer的<strong>reblance算法</strong>如下：</p>
<ol>
<li>对topic下的所有partition进行排序，结果记为$PT$；</li>
<li>对订阅这个topic的Group下的所有consumer进行排序，记为$CG$；</li>
<li>记i为CG中的idex，第i个consumer记为$C_{i}$，$N=\lceil\frac{size(PT)}{size(CG)}\rceil$；</li>
<li>解除原来$C_{i}$对分配的Partition的消费权；</li>
<li>将第 $iN$ 到 $(i+1)N-1$个partitions重新分配给$C_{i}$.</li>
</ol>
<p>目前consumer rebalance的控制策略是由每一个consumer通过Zookeeper完成的。具体的<strong>控制方式</strong>如下（去看源码分析）：</p>
<ul>
<li>Register itself in the consumer id registry under its group.</li>
<li>Register a watch on changes under the consumer id registry.</li>
<li>Register a watch on changes under the broker id registry.</li>
<li>If the consumer creates a message stream using a topic filter, it also registers a watch on changes under the broker topic registry.</li>
<li>Force itself to rebalance within in its consumer group.</li>
</ul>
<p>在这种策略下，每一个consumer或者broker的增加或者减少都会触发consumer rebalance。因为每个consumer只负责调整自己所消费的partition，为了保证整个consumer group的一致性，所以当一个consumer触发了rebalance时，该consumer group内的其它所有consumer也应该同时触发rebalance</p>
<p>这样的缺点是：</p>
<ul>
<li>Herd effect，任何broker或者consumer的增减都会触发所有的consumer的rebalance；</li>
<li>Split Brain，每个consumer分别单独通过Zookeeper判断哪些partition down了，那么不同consumer从Zookeeper“看”到的view就可能不一样，这就会造成错误的reblance尝试。而且有可能所有的consumer都认为rebalance已经完成了，但实际上可能并非如此。</li>
</ul>
<p>根据Kafka官方文档，Kafka作者正在考虑在还未发布的<a href="https://cwiki.apache.org/confluence/display/KAFKA/Kafka+0.9+Consumer+Rewrite+Design" target="_blank" rel="external">0.9.x版本</a>中使用中心协调器(coordinator)。大体思想是选举出一个broker作为<code>coordinator</code>，由它watch Zookeeper，从而判断是否有partition或者consumer的增减，然后生成rebalance命令，并检查是否这些rebalance在所有相关的consumer中被执行成功，如果不成功则重试，若成功则认为此次rebalance成功（这个过程跟replication controller非常类似，所以我很奇怪为什么当初设计replication controller时没有使用类似方式来解决consumer rebalance的问题）</p>
<h2 id="3-pull"><a href="#3-pull" class="headerlink" title="3.pull"></a>3.pull</h2><p>参<a href="http://mp.weixin.qq.com/s?__biz=MzA4MzEzNjA0NA==&amp;mid=222594584&amp;idx=1&amp;sn=d64e5f5768ce48bd0bee1824b30fb1e3&amp;scene=0#rd" target="_blank" rel="external">流式计算-kafka（一）</a></p>
<p>作为一个message system，kafka遵循了传统的方式，选择由kafka的producer向broker push信息，而consumer从broker pull信息。</p>
<p>consumer获取消息，可以使用两种方式：push或pull模式。下面我们简单介绍一下这两种区别：</p>
<p><strong>push模式</strong></p>
<p>常见的push模式如storm的消息处理，由spout负责消息的推送。该模式下需要一个中心节点，负责消息的分配情况（哪段消息分配给consumer1，哪段消息分配给consumer2），同时还要监听consumer的ack消息用于判断消息是否处理成功，如果在timeout时间内为收到响应可以认为该consumer挂掉，需要重新分配sonsumer上失败的消息。这种模式有个问题，不太容易实现我们想要的消息回放功能，因为理想情况下由consumer决定我到底要消费什么，而这种模式完全由master决定。</p>
<p><strong>pull模式</strong></p>
<p>如上图模式，该模式为pull模式，由consumer决定消息的消费情况，这种模式有一个好处是我们不需要返回ack消息，因为当consumer申请消费下一批消息时就可以认为上一批消息已经处理完毕，也不需要处理超时的问题，consumer可以根据自己的消费能力来消费消息。但这个还有一个问题，如何保证处理的消息的不会重复呢，kafka具体做法就是增加队列的并发度（partition），可以一个partition对准一个consumer。</p>
<p>综上，kafka的consumer之所以没有采用push模式，是因为push模式很难适应消费者速率不同的消费者而且很难实现消息的回放功能，因为消息发送速率是由broker决定的。push模式的目标就是尽可能以最快速度传递消息，但是这样很容易造成consumer来不及处理消息，典型的表现就是拒绝服务以及网络拥塞，而pull模式则可以根据consumer的消费能力以适当的速率消费message。</p>
<p>pull与push的区别</p>
<p>pull技术：</p>
<ul>
<li>客户机向服务器请求信息；</li>
<li>kafka中，consuemr根据自己的消费能力以适当的速率消费信息；</li>
</ul>
<p>push技术：</p>
<ul>
<li>服务器主动将信息发往客户端的技术；</li>
<li>push模式的目标就是尽可能以最快的速率传递消息。</li>
</ul>
<hr>
<p>参考：</p>
<ul>
<li><a href="http://developer.51cto.com/art/201501/464491_all.htm" target="_blank" rel="external">发布&amp;订阅的消息系统Kafka的深度解析</a></li>
<li><a href="http://www.jasongj.com/2015/08/09/KafkaColumn4/" target="_blank" rel="external">Kafka Consumer设计解析</a></li>
<li><a href="http://blog.csdn.net/suifeng3051/article/details/48053965" target="_blank" rel="external">Kafka设计与原理详解</a></li>
<li><a href="http://www.jasongj.com/2015/04/24/KafkaColumn2/" target="_blank" rel="external">kafka设计解析2</a></li>
</ul>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[Kafka之数据存储]]></title>
      <url>http://matt33.com/2016/03/08/kafka-store/</url>
      <content type="html"><![CDATA[<p>本文主要讲述以下两部分内容：</p>
<ul>
<li>kafka数据的存储方式；</li>
<li>kafka如何通过offset查找message。</li>
</ul>
<h3 id="1-前言"><a href="#1-前言" class="headerlink" title="1.前言"></a>1.前言</h3><p>写介绍kafka的几个重要概念（可以参考之前的博文<a href="http://matt33.com/2015/11/14/The-Introduce-of-Kafka">Kafka的简单介绍</a>）：</p>
<ul>
<li><strong>Broker</strong>：消息中间件处理结点，一个Kafka节点就是一个broker，多个broker可以组成一个Kafka集群；</li>
<li><strong>Topic</strong>：一类消息，例如page view日志、click日志等都可以以topic的形式存在，Kafka集群能够同时负责多个topic的分发；</li>
<li><strong>Partition</strong>：topic物理上的分组，一个topic可以分为多个partition，每个partition是一个有序的队；</li>
<li><strong>Segment</strong>：每个partition又由多个segment file组成；</li>
<li><strong>offset</strong>：每个partition都由一系列有序的、不可变的消息组成，这些消息被连续的追加到partition中。partition中的每个消息都有一个连续的序列号叫做offset，用于partition唯一标识一条消息；</li>
<li><strong>message</strong>：这个算是kafka文件中最小的存储单位，即是 a commit log。</li>
</ul>
<p>kafka的message是以topic为基本单位，不同topic之间是相互独立的。每个topic又可分为几个不同的partition，每个partition存储一部的分message。topic与partition的关系如下：</p>
<p><img src="/images/2016-03-07-KafkaMessage/topic.png" alt="topic"></p>
<p>其中，partition是以文件夹的形式存储在具体Broker本机上。</p>
<h3 id="2-partition中的数据文件"><a href="#2-partition中的数据文件" class="headerlink" title="2.partition中的数据文件"></a>2.partition中的数据文件</h3><p>有了上面的介绍，下面我们开始介绍Topic中partition的数据文件类型。</p>
<h4 id="2-1-segment中的文件"><a href="#2-1-segment中的文件" class="headerlink" title="2.1.segment中的文件"></a>2.1.segment中的文件</h4><p>对于一个partition（在Broker中以文件夹的形式存在），里面又有很多大小相等的segment数据文件（这个文件的具体大小可以在<code>config/server.properties</code>中进行设置），这种特性可以方便old segment file的快速删除。</p>
<p>下面先介绍一下partition中的segment file的组成：</p>
<ul>
<li>segment file <strong>组成</strong>：由2部分组成，分别为index file和data file，这两个文件是一一对应的，后缀”.index”和”.log”分别表示索引文件和数据文件；</li>
<li>segment file <strong>命名规则</strong>：partition的第一个segment从0开始，后续每个segment文件名为上一个segment文件最后一条消息的offset,ofsset的数值最大为64位（long类型），20位数字字符长度，没有数字用0填充。如下图所示：</li>
</ul>
<p><img src="/images/2016-03-07-KafkaMessage/segment.png" alt="segment"></p>
<p>关于segment file中index与data file对应关系图，这里我们选用网上的一个图片，如下所示：</p>
<p><img src="/images/2016-03-07-KafkaMessage/index.png" alt="index"></p>
<p>segment的索引文件中存储着大量的元数据，数据文件中存储着大量消息，索引文件中的元数据指向对应数据文件中的message的物理偏移地址。以索引文件中的<code>3，497</code>为例，在数据文件中表示第3个message（在全局partition表示第368772个message），以及该消息的物理偏移地址为497。</p>
<p>注：Partition中的每条message由offset来表示它在这个partition中的偏移量，这个offset并不是该Message在partition中实际存储位置，而是逻辑上的一个值（如上面的3），但它却唯一确定了partition中的一条Message（可以认为offset是partition中Message的id）。</p>
<h4 id="2-2-message文件"><a href="#2-2-message文件" class="headerlink" title="2.2.message文件"></a>2.2.message文件</h4><p>message中的物理结构为：</p>
<p><img src="/images/2016-03-07-KafkaMessage/message.png" alt="message"></p>
<p>参数说明：</p>
<table>
<thead>
<tr>
<th>关键字</th>
<th>解释说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>8 byte offset</td>
<td>在parition(分区)内的每条消息都有一个有序的id号，这个id号被称为偏移(offset),它可以唯一确定每条消息在parition(分区)内的位置。即offset表示partiion的第多少message</td>
</tr>
<tr>
<td>4 byte message size</td>
<td>message大小</td>
</tr>
<tr>
<td>4 byte CRC32</td>
<td>用crc32校验message</td>
</tr>
<tr>
<td>1 byte “magic”</td>
<td>表示本次发布Kafka服务程序协议版本号</td>
</tr>
<tr>
<td>1 byte “attributes”</td>
<td>表示为独立版本、或标识压缩类型、或编码类型</td>
</tr>
<tr>
<td>4 byte key length</td>
<td>表示key的长度,当key为-1时，K byte key字段不填</td>
</tr>
<tr>
<td>K byte key</td>
<td>可选</td>
</tr>
<tr>
<td>value bytes payload</td>
<td>表示实际消息数据</td>
</tr>
</tbody>
</table>
<h4 id="2-3-数据文件的内部实现方法"><a href="#2-3-数据文件的内部实现方法" class="headerlink" title="2.3.数据文件的内部实现方法"></a>2.3.数据文件的内部实现方法</h4><p>Partition数据文件包含了若干上述格式的message，按照offset由小到大排列在一起，它实现的类是FileMessageSet，类图如下：</p>
<p><img src="/images/2016-03-07-KafkaMessage/filemessageset.png" alt="filemessageset"></p>
<p>它的主要方法如下：</p>
<ul>
<li><strong>append</strong>: 把给定的ByteBufferMessageSet中的Message写入到这个数据文件中。</li>
<li><strong>searchFor</strong>: 从指定的startingPosition开始搜索，找到第一个Message判断其offset是大于或者等于指定的offset，并返回其在文件中的位置Position。它的实现方式是从startingPosition开始读取12个字节，分别是当前MessageSet的offset和size。如果当前offset小于指定的offset，那么将position向后移动LogOverHead+MessageSize（其中LogOverHead为offset+messagesize，为12个字节）。</li>
<li><strong>read</strong>：准确名字应该是slice，它截取其中一部分返回一个新的FileMessageSet。它不保证截取的位置数据的完整性。</li>
<li><strong>sizeInBytes</strong>: 表示这个FileMessageSet占有了多少字节的空间。</li>
<li><strong>truncateTo</strong>: 把这个文件截断，这个方法不保证截断位置的Message的完整性。</li>
<li><strong>readInto</strong>: 从指定的相对位置开始把文件的内容读取到对应的ByteBuffer中。</li>
</ul>
<h4 id="3-查找"><a href="#3-查找" class="headerlink" title="3.查找"></a>3.查找</h4><h4 id="3-1-遇到的问题"><a href="#3-1-遇到的问题" class="headerlink" title="3.1.遇到的问题"></a>3.1.遇到的问题</h4><p>我们首先试想一下，如果对于Kafka的一个topic而言，如果topic的partition中只有一个数据文件的话会怎么样？</p>
<ul>
<li>新数据是添加在文件末尾（调用FileMessageSet的append方法），不论文件数据文件有多大，这个操作永远都是O(1)的。</li>
<li>查找某个offset的Message（调用FileMessageSet的searchFor方法）是顺序查找的。因此，如果数据文件很大的话，查找的效率就低。</li>
</ul>
<h4 id="3-2-如何去解决这个问题"><a href="#3-2-如何去解决这个问题" class="headerlink" title="3.2.如何去解决这个问题"></a>3.2.如何去解决这个问题</h4><p>由上述我们知道，如果在topic的partition中只有一个数据文件的话，Kafka插入的效率虽然很高，但是查找的效率非常低，那么Kafka在内部是如何解决查找效率的的问题呢？对于这个问题，Kafka有两大法宝：分段和索引。</p>
<p><strong>数据文件的分段</strong></p>
<p>这个是比较好理解的，加入有100条message，它们的offset是从0到99，假设将数据文件分为5端，第一段为0-19，第二段为20-39，依次类推，每段放在一个单独的数据文件里面，数据文件以该段中最小的offset命名。这样在查找指定offset的Message的时候，用二分查找就可以定位到该Message在哪个段中。</p>
<p><strong>为数据文件建索引</strong></p>
<p>数据文件分段使得可以在一个较小的数据文件中查找对应offset的message了，但是这依然需要顺序扫描才能找到对应offset的message。为了进一步提高查找的效率，Kafka为每个分段后的数据文件建立了索引文件，文件名与数据文件的名字是一样的，只是文件扩展名为<code>.index</code>。</p>
<p>索引文件中包含若干个索引条目，每个条目表示数据文件中一条message的索引。索引包含两个部分（均为4个字节的数字），分别为相对offset和position。</p>
<ul>
<li><strong>相对offset</strong>：因为数据文件分段以后，每个数据文件的起始offset不为0，相对offset表示这条message相对于其所属数据文件中最小的offset的大小。举例，分段后的一个数据文件的offset是从20开始，那么offset为25的message在index文件中的相对offset就是25-20 = 5。存储相对offset可以减小索引文件占用的空间。</li>
<li><strong>position</strong>：表示该条message在数据文件中的绝对位置。只要打开文件并移动文件指针到这个position就可以读取对应的message了。</li>
</ul>
<p>在kafka中，索引文件的实现类为OffsetIndex，它的类图如下：</p>
<p><img src="/images/2016-03-07-KafkaMessage/offsetindex.png" alt="offsetindex"></p>
<p>主要的方法有：</p>
<ul>
<li>append方法：添加一对offset和position到index文件中，这里的offset将会被转成相对的offset。</li>
<li>lookup：用二分查找的方式去查找小于或等于给定offset的最大的那个offset</li>
</ul>
<h4 id="3-3-通过offset查找message"><a href="#3-3-通过offset查找message" class="headerlink" title="3.3.通过offset查找message"></a>3.3.通过offset查找message</h4><p>假如我们想要读取offset=368776的message（见前面的第三个图），需要通过下面2个步骤查找。</p>
<ol>
<li><strong>查找segment file</strong><br>00000000000000000000.index表示最开始的文件，起始偏移量(offset)为0.第二个文件00000000000000368769.index的消息量起始偏移量为368770 = 368769 + 1.同样，第三个文件00000000000000737337.index的起始偏移量为737338=737337 + 1，其他后续文件依次类推，以起始偏移量命名并排序这些文件，只要根据offset <strong>二分查找</strong>文件列表，就可以快速定位到具体文件。<br>当offset=368776时定位到00000000000000368769.index|log</li>
<li>通过segment file<strong>查找message</strong><br>通过第一步定位到segment file，当offset=368776时，依次定位到00000000000000368769.index的元数据物理位置和00000000000000368769.log的物理偏移地址，然后再通过00000000000000368769.log顺序查找直到offset=368776为止。</li>
</ol>
<p>segment index file并没有为数据文件中的每条message建立索引，而是采取稀疏索引存储方式，每隔一定字节的数据建立一条索引，它减少了索引文件大小，通过map可以直接内存操作，稀疏索引为数据文件的每个对应message设置一个元数据指针,它比稠密索引节省了更多的存储空间，但查找起来需要消耗更多的时间。</p>
<p>总结：</p>
<p>Kafka高效文件存储设计特点：</p>
<ul>
<li>Kafka把topic中一个parition大文件分成多个小文件段，通过多个小文件段，就容易定期清除或删除已经消费完文件，减少磁盘占用。</li>
<li>通过索引信息可以快速定位message和确定response的最大大小。</li>
<li>通过index元数据全部映射到memory，可以避免segment file的IO磁盘操作。</li>
<li>通过索引文件稀疏存储，可以大幅降低index文件元数据占用空间大小。</li>
</ul>
<hr>
<p>参考：</p>
<ul>
<li><a href="http://blog.csdn.net/jewes/article/details/42970799" target="_blank" rel="external">Kafka的Log存储解析</a></li>
<li><a href="http://tech.meituan.com/kafka-fs-design-theory.html" target="_blank" rel="external">Kakfa文件存储那些事</a></li>
<li><a href="http://blog.csdn.net/jewes/article/details/42744855" target="_blank" rel="external">Kafka的通讯协议</a></li>
</ul>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[MapReduce之Shuffle过程详述]]></title>
      <url>http://matt33.com/2016/03/02/hadoop-shuffle/</url>
      <content type="html"><![CDATA[<h1 id="写在前面"><a href="#写在前面" class="headerlink" title="写在前面"></a>写在前面</h1><p>MapReduce作为Hadoop的编程框架，对于大数据开发或者想要接触大数据开发的开发者来说，是必须要掌握的，它是一种经典大数据计算框架，现在有很多开源项目的内部实现都会直接或间接地借鉴了MR过程的实现。我在经过了一些hadoop项目的开发，然后前几天又系统地学习MapReduc内部实现过程，尤其是学习中间的Shuffle过程之后，准备对这一块做一下总结，希望这篇文章能给需要的人带来一些帮助（文中Shuffle的分析还是以Hadoop1.0为例，这个跟2.0的区别并不是很大）。</p>
<h1 id="总述"><a href="#总述" class="headerlink" title="总述"></a>总述</h1><p>对于MapReduce作业，完整的作业运行流程，这里借用刘军老师的<a href="http://item.jd.com/11315351.html" target="_blank" rel="external">Hadoop大数据处理</a>中的一张图：</p>
<p><img src="/images/hadoop/hadoop.png" alt="hadoop"></p>
<p>完整过程应该是分为7部分，分别是：</p>
<ol>
<li>作业启动：开发者通过控制台启动作业；</li>
<li>作业初始化：这里主要是切分数据、创建作业和提交作业，与第三步紧密相联；</li>
<li>作业/任务调度：对于1.0版的Hadoop来说就是JobTracker来负责任务调度，对于2.0版的Hadoop来说就是Yarn中的Resource Manager负责整个系统的资源管理与分配，Yarn可以参考IBM的一篇博客<a href="https://www.ibm.com/developerworks/cn/opensource/os-cn-hadoop-yarn/" target="_blank" rel="external">Hadoop新MapReduce框架Yarn详解</a>；</li>
<li>Map任务；</li>
<li>Shuffle；</li>
<li>Reduce任务；</li>
<li>作业完成：通知开发者任务完成。</li>
</ol>
<p>而这其中最主要的MapReduce过程，主要是第4、5、6步三部分，这也是本篇博客重点讨论的地方，详细作用如下：</p>
<ol>
<li><strong>Map</strong>:数据输入,做初步的处理,输出形式的中间结果；</li>
<li><strong>Shuffle</strong>:按照partition、key对中间结果进行排序合并,输出给reduce线程；</li>
<li><strong>Reduce</strong>:对相同key的输入进行最终的处理,并将结果写入到文件中。</li>
</ol>
<p>这里先给出官网上关于这个过程的经典流程图：</p>
<p><img src="/images/hadoop/mapreduce.png" alt="mapreduce"></p>
<p>上图是把MapReduce过程分为两个部分，而实际上从两边的Map和Reduce到中间的那一大块都属于Shuffle过程，也就是说，Shuffle过程有一部分是在Map端，有一部分是在Reduce端，下文也将会分两部分来介绍Shuffle过程。</p>
<p>对于Hadoop集群，当我们在运行作业时，大部分的情况下，map task与reduce task的执行是分布在不同的节点上的，因此，很多情况下，reduce执行时需要跨节点去拉取其他节点上的map task结果，这样造成了集群内部的网络资源消耗很严重，而且在节点的内部，相比于内存，磁盘IO对性能的影响是非常严重的。如果集群中运行的作业有很多，那么task的执行对于集群内部网络的资源消费非常大。因此，我们对于MapRedue作业Shuffle过程的期望是：</p>
<ul>
<li>完整地从map task端拉取数据到Reduce端；</li>
<li>在跨节点拉取数据时，尽可能地减少对带宽的不必要消耗；</li>
<li>减少磁盘IO对task执行的影响。</li>
</ul>
<h1 id="Map"><a href="#Map" class="headerlink" title="Map"></a>Map</h1><p>在进行海量数据处理时，外存文件数据<strong>I/O访问</strong>会成为一个制约系统性能的瓶颈，因此，Hadoop的Map过程实现的一个重要原则就是：<strong>计算靠近数据</strong>，这里主要指两个方面：</p>
<ol>
<li>代码靠近数据：<ul>
<li>原则：本地化数据处理（locality），即一个计算节点尽可能处理本地磁盘上所存储的数据；</li>
<li>尽量选择数据所在DataNode启动Map任务；</li>
<li>这样可以减少数据通信，提高计算效率；</li>
</ul>
</li>
<li>数据靠近代码：<ul>
<li>当本地没有数据处理时，尽可能从同一机架或最近其他节点传输数据进行处理（host选择算法）。</li>
</ul>
</li>
</ol>
<p>下面，我们分块去介绍Hadoop的Map过程，map的经典流程图如下：</p>
<p><img src="/images/hadoop/map-shuffle.png" alt="map-shuffle"></p>
<h2 id="输入"><a href="#输入" class="headerlink" title="输入"></a>输入</h2><ol>
<li>map task只读取split分片，split与block（hdfs的最小存储单位，默认为64MB）可能是一对一也能是一对多，但是对于一个split只会对应一个文件的一个block或多个block，不允许一个split对应多个文件的多个block；</li>
<li>这里切分和输入数据的时会涉及到InputFormat的文件切分算法和host选择算法。</li>
</ol>
<p>文件切分算法，主要用于确定InputSplit的个数以及每个InputSplit对应的数据段。FileInputFormat以文件为单位切分生成InputSplit，对于每个文件，由以下三个属性值决定其对应的InputSplit的个数：</p>
<ul>
<li>goalSize： 它是根据用户期望的InputSplit数目计算出来的，即totalSize/numSplits。其中，totalSize为文件的总大小；numSplits为用户设定的Map Task个数，默认情况下是1；</li>
<li>minSize：InputSplit的最小值，由配置参数<code>mapred.min.split.size</code>确定，默认是1；</li>
<li>blockSize：文件在hdfs中存储的block大小，不同文件可能不同，默认是64MB。</li>
</ul>
<p>这三个参数共同决定InputSplit的最终大小，计算方法如下：</p>
<p><code>splitSize=max{minSize, min{gogalSize,blockSize}}</code></p>
<p>FileInputFormat的host选择算法参考《Hadoop技术内幕-深入解析MapReduce架构设计与实现原理》的p50.</p>
<h2 id="Partition"><a href="#Partition" class="headerlink" title="Partition"></a>Partition</h2><ul>
<li>作用：将map的结果发送到相应的reduce端，总的partition的数目等于reducer的数量。</li>
<li>实现功能：<ol>
<li>map输出的是key/value对，决定于当前的mapper的part交给哪个reduce的方法是：mapreduce提供的Partitioner接口，对key进行hash后，再以reducetask数量取模，然后到指定的job上（<strong>HashPartitioner</strong>，可以通过<code>job.setPartitionerClass(MyPartition.class)</code>自定义）。</li>
<li>然后将数据写入到内存缓冲区，缓冲区的作用是批量收集map结果，减少磁盘IO的影响。key/value对以及Partition的结果都会被写入缓冲区。在写入之前，key与value值都会被序列化成字节数组。</li>
</ol>
</li>
<li>要求：负载均衡，效率；</li>
</ul>
<h2 id="spill（溢写）：sort-amp-combiner"><a href="#spill（溢写）：sort-amp-combiner" class="headerlink" title="spill（溢写）：sort &amp; combiner"></a>spill（溢写）：sort &amp; combiner</h2><ul>
<li>作用：把内存缓冲区中的数据写入到本地磁盘，在写入本地磁盘时先按照partition、再按照key进行排序（<code>quick sort</code>）；</li>
<li>注意：<ol>
<li>这个spill是由<strong>另外单独的线程</strong>来完成，不影响往缓冲区写map结果的线程；</li>
<li>内存缓冲区默认大小限制为100MB，它有个溢写比例（<code>spill.percent</code>），默认为0.8，当缓冲区的数据达到阈值时，溢写线程就会启动，先锁定这80MB的内存，执行溢写过程，maptask的输出结果还可以往剩下的20MB内存中写，互不影响。然后再重新利用这块缓冲区，因此Map的内存缓冲区又叫做<strong>环形缓冲区</strong>（两个指针的方向不会变，下面会详述）；</li>
<li>在将数据写入磁盘之前，先要对要写入磁盘的数据进行一次<strong>排序</strong>操作，先按<code>&lt;key,value,partition&gt;</code>中的partition分区号排序，然后再按key排序，这个就是<strong>sort操作</strong>，最后溢出的小文件是分区的，且同一个分区内是保证key有序的；</li>
</ol>
</li>
</ul>
<p><strong>combine</strong>：执行combine操作要求开发者必须在程序中设置了combine（程序中通过<code>job.setCombinerClass(myCombine.class)</code>自定义combine操作）。</p>
<ul>
<li>程序中有两个阶段可能会执行combine操作：<ol>
<li>map输出数据根据分区排序完成后，在写入文件之前会执行一次combine操作（前提是作业中设置了这个操作）；</li>
<li>如果map输出比较大，溢出文件个数大于3（此值可以通过属性<code>min.num.spills.for.combine</code>配置）时，在merge的过程（多个spill文件合并为一个大文件）中还会执行combine操作；</li>
</ol>
</li>
<li>combine主要是把形如<code>&lt;aa,1&gt;,&lt;aa,2&gt;</code>这样的key值相同的数据进行计算，计算规则与reduce一致，比如：当前计算是求key对应的值求和，则combine操作后得到<code>&lt;aa,3&gt;</code>这样的结果。</li>
<li>注意事项：不是每种作业都可以做combine操作的，只有满足以下条件才可以：<ol>
<li>reduce的输入输出类型都一样，因为combine本质上就是reduce操作；</li>
<li>计算逻辑上，combine操作后不会影响计算结果，像求和就不会影响；</li>
</ol>
</li>
</ul>
<h2 id="merge"><a href="#merge" class="headerlink" title="merge"></a>merge</h2><ul>
<li>merge过程：当map很大时，每次溢写会产生一个spill_file，这样会有多个spill_file，而最终的一个map task输出只有一个文件，因此，最终的结果输出之前会对多个中间过程进行多次溢写文件（spill_file）的合并，此过程就是merge过程。也即是，待Map Task任务的所有数据都处理完后，会对任务产生的所有中间数据文件做一次合并操作，以确保一个Map Task最终只生成一个中间数据文件。</li>
<li>注意：<ol>
<li>如果生成的文件太多，可能会执行多次合并，每次最多能合并的文件数默认为10，可以通过属性<code>min.num.spills.for.combine</code>配置；</li>
<li>多个溢出文件合并时，会进行一次排序，排序算法是<strong>多路归并排序</strong>；</li>
<li>是否还需要做combine操作，一是看是否设置了combine，二是看溢出的文件数是否大于等于3；</li>
<li>最终生成的文件格式与单个溢出文件一致，也是按分区顺序存储，并且输出文件会有一个对应的索引文件，记录每个分区数据的起始位置，长度以及压缩长度，这个索引文件名叫做<code>file.out.index</code>。</li>
</ol>
</li>
</ul>
<h2 id="内存缓冲区"><a href="#内存缓冲区" class="headerlink" title="内存缓冲区"></a>内存缓冲区</h2><ol>
<li>在Map Task任务的业务处理方法map()中，最后一步通过<code>OutputCollector.collect(key,value)</code>或<code>context.write(key,value)</code>输出Map Task的中间处理结果，在相关的<code>collect(key,value)</code>方法中，会调用<code>Partitioner.getPartition(K2 key, V2 value, int numPartitions)</code>方法获得输出的key/value对应的分区号(分区号可以认为对应着一个要执行Reduce Task的节点)，然后将<code>&lt;key,value,partition&gt;</code>暂时保存在内存中的MapOutputBuffe内部的环形数据缓冲区，该缓冲区的默认大小是100MB，可以通过参数<code>io.sort.mb</code>来调整其大小。</li>
<li>当缓冲区中的数据使用率达到一定阀值后，触发一次Spill操作，将环形缓冲区中的部分数据写到磁盘上，生成一个临时的Linux本地数据的spill文件；然后在缓冲区的使用率再次达到阀值后，再次生成一个spill文件。直到数据处理完毕，在磁盘上会生成很多的临时文件。</li>
<li>缓存有一个阀值比例配置，当达到整个缓存的这个比例时，会触发spill操作；触发时，map输出还会接着往剩下的空间写入，但是写满的空间会被锁定，数据溢出写入磁盘。当这部分溢出的数据写完后，空出的内存空间可以接着被使用，形成像环一样的被循环使用的效果，所以又叫做<strong>环形内存缓冲区</strong>；</li>
<li>MapOutputBuffe内部存数的数据采用了两个索引结构，涉及三个环形内存缓冲区。下来看一下两级索引结构：</li>
</ol>
<p><img src="/images/hadoop/buffer.jpg" alt="buffer"></p>
<p><strong>写入到缓冲区的数据采取了压缩算法 <a href="http://www.cnblogs.com/edisonchou/p/4298423.html" target="_blank" rel="external">http://www.cnblogs.com/edisonchou/p/4298423.html</a></strong><br>这三个环形缓冲区的含义分别如下：</p>
<ol>
<li><strong>kvoffsets</strong>缓冲区：也叫偏移量索引数组，用于保存<code>key/value</code>信息在位置索引 <code>kvindices</code> 中的偏移量。当 <code>kvoffsets</code> 的使用率超过 <code>io.sort.spill.percent</code> (默认为80%)后，便会触发一次 SpillThread 线程的“溢写”操作，也就是开始一次 Spill 阶段的操作。</li>
<li><strong>kvindices</strong>缓冲区：也叫位置索引数组，用于保存 <code>key/value</code> 在数据缓冲区 <code>kvbuffer</code> 中的起始位置。</li>
<li><strong>kvbuffer</strong>即数据缓冲区：用于保存实际的 <code>key/value</code> 的值。默认情况下该缓冲区最多可以使用 <code>io.sort.mb</code> 的95%，当 <code>kvbuffer</code> 使用率超过 <code>io.sort.spill.percent</code> (默认为80%)后，便会出发一次 SpillThread 线程的“溢写”操作，也就是开始一次 Spill 阶段的操作。</li>
</ol>
<p>写入到本地磁盘时，对数据进行排序，实际上是对<strong>kvoffsets</strong>这个偏移量索引数组进行排序。</p>
<h1 id="Reduce"><a href="#Reduce" class="headerlink" title="Reduce"></a>Reduce</h1><p>Reduce过程的经典流程图如下：</p>
<p><img src="/images/hadoop/reduce-shuffle.png" alt="reduce-shuffle"></p>
<h2 id="copy过程"><a href="#copy过程" class="headerlink" title="copy过程"></a>copy过程</h2><ul>
<li>作用：拉取数据；</li>
<li>过程：Reduce进程启动一些数据copy线程(<code>Fetcher</code>)，通过HTTP方式请求map task所在的TaskTracker获取map task的输出文件。因为这时map task早已结束，这些文件就归TaskTracker管理在本地磁盘中。</li>
<li>默认情况下，当整个MapReduce作业的所有已执行完成的Map Task任务数超过Map Task总数的5%后，JobTracker便会开始调度执行Reduce Task任务。然后Reduce Task任务默认启动<code>mapred.reduce.parallel.copies</code>(默认为5）个MapOutputCopier线程到已完成的Map Task任务节点上分别copy一份属于自己的数据。 这些copy的数据会首先保存的内存缓冲区中，当内冲缓冲区的使用率达到一定阀值后，则写到磁盘上。</li>
</ul>
<p><strong>内存缓冲区</strong></p>
<ul>
<li>这个内存缓冲区大小的控制就不像map那样可以通过<code>io.sort.mb</code>来设定了，而是通过另外一个参数来设置：<code>mapred.job.shuffle.input.buffer.percent（default 0.7）</code>， 这个参数其实是一个百分比，意思是说，shuffile在reduce内存中的数据最多使用内存量为：0.7 × <code>maxHeap of reduce task</code>。</li>
<li>如果该reduce task的最大heap使用量（通常通过<code>mapred.child.java.opts</code>来设置，比如设置为-Xmx1024m）的一定比例用来缓存数据。默认情况下，reduce会使用其heapsize的70%来在内存中缓存数据。如果reduce的heap由于业务原因调整的比较大，相应的缓存大小也会变大，这也是为什么reduce用来做缓存的参数是一个百分比，而不是一个固定的值了。</li>
</ul>
<h2 id="merge过程"><a href="#merge过程" class="headerlink" title="merge过程"></a>merge过程</h2><ul>
<li>Copy过来的数据会先放入内存缓冲区中，这里的缓冲区大小要比 map 端的更为灵活，它基于 JVM 的<code>heap size</code>设置，因为 Shuffle 阶段 Reducer 不运行，所以应该把绝大部分的内存都给 Shuffle 用。</li>
<li>这里需要强调的是，merge 有三种形式：1)内存到内存  2)内存到磁盘  3)磁盘到磁盘。默认情况下第一种形式是不启用的。当内存中的数据量到达一定阈值，就启动内存到磁盘的 merge（图中的第一个merge，之所以进行merge是因为reduce端在从多个map端copy数据的时候，并没有进行sort，只是把它们加载到内存，当达到阈值写入磁盘时，需要进行merge） 。这和map端的很类似，这实际上就是溢写的过程，在这个过程中如果你设置有Combiner，它也是会启用的，然后在磁盘中生成了众多的溢写文件，这种merge方式一直在运行，直到没有 map 端的数据时才结束，然后才会启动第三种磁盘到磁盘的 merge （图中的第二个merge）方式生成最终的那个文件。</li>
<li>在远程copy数据的同时，Reduce Task在后台启动了两个后台线程对内存和磁盘上的数据文件做合并操作，以防止内存使用过多或磁盘生的文件过多。</li>
</ul>
<h2 id="reducer的输入文件"><a href="#reducer的输入文件" class="headerlink" title="reducer的输入文件"></a>reducer的输入文件</h2><ul>
<li>merge的最后会生成一个文件，大多数情况下存在于磁盘中，但是需要将其放入内存中。当reducer 输入文件已定，整个 Shuffle 阶段才算结束。然后就是 Reducer 执行，把结果放到 HDFS 上。</li>
</ul>
<hr>
<h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><ol>
<li><a href="http://vdisk.weibo.com/u/1853811305" target="_blank" rel="external">北邮刘军老师的Hadoop课件</a></li>
<li><a href="http://blog.csdn.net/dianacody/article/details/39502917" target="_blank" rel="external">分Map和Redcue两部分介绍</a></li>
<li><a href="http://flyingdutchman.iteye.com/blog/1879642" target="_blank" rel="external">内存缓冲区的介</a></li>
<li>内存缓冲区以及map的各个阶段介绍:<a href="http://xigan.blog.51cto.com/5200121/1163820" target="_blank" rel="external">mapreduce shuffle过程问答</a></li>
<li><a href="http://blog.csdn.net/ebay/article/details/45722263" target="_blank" rel="external">MapReduce详细过程</a></li>
<li><a href="http://zheming.wang/hadoop-mapreduce-zhi-xing-liu-cheng-xiang-jie.html" target="_blank" rel="external">http://zheming.wang/hadoop-mapreduce-zhi-xing-liu-cheng-xiang-jie.html</a></li>
<li>hadoop中的一些压缩算法，<a href="http://www.cnblogs.com/edisonchou/p/4298423.html" target="_blank" rel="external">http://www.cnblogs.com/edisonchou/p/4298423.html</a></li>
</ol>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[Travel to Nanjing | 元旦南京之旅]]></title>
      <url>http://matt33.com/2016/01/14/TravelToNanjing/</url>
      <content type="html"><![CDATA[<p>这篇文章是我2016年的第一篇博客，之前本来想着新年的开篇应该写一篇掉炸天的技术博客，最后，想了想，还是准备写篇旅行博客吧，因为这次南京游玩不仅仅是旅行。</p>
<h2 id="1-Day1"><a href="#1-Day1" class="headerlink" title="1.Day1"></a>1.Day1</h2><p>第一天应该是最辛苦的，因为去的地方比较多，有：玄武湖，狮子桥，中山陵，明孝陵，美龄宫，秦淮河和夫子庙。大家出去玩的时候一定要穿双舒服的鞋（就是走很多路也不会磨脚的那种），这点要切记，森哥（一同去玩的朋友）就是因为这导致第一天就把脚磨破，再后面两天几非常惨了。</p>
<p>南京火车站南出口一出来就是玄武湖，只不过这天雾霾比较大，景色没有想象中得好。如果南京的空气要是好些的话，还确实是座宜居的城市，在玄武湖的周围有一个专门跑步的跑道，我本身比较喜欢跑步，所以我是特别喜欢这种湖边跑道，要是自己以后能住在湖边，而湖边又有跑道，那该多么幸福！我之所以会羡慕这种城市，可能主要我是北方人的原因，越是缺少什么东西越是喜欢什么吧。好了，先放几张图。</p>
<p>南京火车站南出站口</p>
<p><img src="/images/2016-01-14-TraveToNanJing/nanjing.jpg" alt="nanjing"></p>
<p>火车站对面的玄武湖</p>
<p><img src="/images/2016-01-14-TraveToNanJing/xuanwuhu.jpg" alt="xuanwuhu"></p>
<p>去往玄武湖其中一个岛的小桥（旭桥，来自百度地图），还有森哥的背景</p>
<p><img src="/images/2016-01-14-TraveToNanJing/xuanwuhu3.jpg" alt="xuanwuhu3"></p>
<p>小岛上的景色还是不错的</p>
<p><img src="/images/2016-01-14-TraveToNanJing/xuanwuhu2.jpg" alt="xuanwuhu2"></p>
<p>接下来，我们就是南京很有名的小吃街——湖南路狮子桥，去吃了一家南京本地的饭店——南京大排档，总体感觉还不错吧，算是比较有特色的当地饭店，没有吃的话，还是推荐去吃一下，就是里面椅子不太舒服不能往后靠。</p>
<p><img src="/images/2016-01-14-TraveToNanJing/meishi1.jpg" alt="meishi1"></p>
<p>吃完饭之后，我就坐车直接去了中山陵，到中山陵的时候就已经快一点了，这个时候中山陵的人已经很多了，如果要是还想去明孝陵，美龄宫，灵谷寺的话就得抓紧时间了，我们当时再去完中山陵之后，就去了明孝陵，然后又去了美龄宫，去完美龄宫就已经到五点多了，灵谷寺就没时间玩了。下面又是晒图的时候了。</p>
<p>2016元旦的中山陵</p>
<p><img src="/images/2016-01-14-TraveToNanJing/zhongshan1.jpg" alt="zhongshan1"></p>
<p><img src="/images/2016-01-14-TraveToNanJing/zhongshan2.jpg" alt="zhongshan2"></p>
<p>中山陵这边的天气还是很不错的，虽然此时南京市区都环绕在中度污染之中，在这钟山风景区空气竟然没那么糟，还能清晰地看到蓝天白云。</p>
<p><img src="/images/2016-01-14-TraveToNanJing/zhongshanling3.jpg" alt="zhongshanling3"></p>
<p>明孝陵的方城明楼，还是能感受帝王的气派的，城楼都盖了几百年了，依然屹立不倒，与现在的豆腐渣工程形成鲜明对比</p>
<p><img src="/images/2016-01-14-TraveToNanJing/mingxiaoling.jpg" alt="mingxiaoling"></p>
<p>美龄宫，也曾经是中国的权利中心之一吧</p>
<p><img src="/images/2016-01-14-TraveToNanJing/meilinggong.jpg" alt="meilinggong"></p>
<p>在去完美龄宫之后，我们就基本上没有力气，也没有时间再去灵谷寺和音乐台了，所以就选择了回市区吃饭，本来想着去吃鸭血粉丝的，但是离我们下车的地方太远了，所以就去吃了一个抄手，然后又去吃了南京一家比较有名的笑云开灌汤包。吃完之后就直接奔向了夫子庙。由于是晚上，手机的照相功能又一般般，选两张稍微好看一点的照片吧。</p>
<p><img src="/images/2016-01-14-TraveToNanJing/fuzimiao.jpg" alt="fuzimiao"></p>
<p>夫子庙的聚贤楼，之所以晒这个，主要是因为这张照片感觉照得还不错，其他的照片就不好意思拿出手了。</p>
<p><img src="/images/2016-01-14-TraveToNanJing/fuzimiao2.jpg" alt="fuzimiao2"></p>
<p>经过昨天一晚的长途奔波（北京到南京的硬座）和今天一天的到处转悠，我这天的运动步数也达到了4W+步，第一次取得了微信运动的第一名。晚上就直接住在好友祥子学校（东大九龙湖校区）附近了，祥子很给力，把住宿什么的都给我们安排好了，非常感谢哈。</p>
<h2 id="2-Day2"><a href="#2-Day2" class="headerlink" title="2.Day2"></a>2.Day2</h2><p>因为昨天太过劳累，今天直接睡到了早上9点，然后起床去东大食堂吃点，吃完早饭之后就直接坐地铁准备去南京博物院了，南京博物院号称仅次于故宫博物院和上海博物院的全国第三大博物院，尤其以其民国馆最著名，所以我们准备花半天的时间转。</p>
<p>在进博物院之前，我们先去一家南京本地很出名的糕点店——芳婆糕点去买了中午饭，我们去买饭的时候已经快上午11点了，但是还有很多人在排队。</p>
<p><img src="/images/2016-01-14-TraveToNanJing/meishi2.jpg" alt="meishi2"></p>
<p>买完饭之后，我们直接奔向博物院，先来张博物院的正门。</p>
<p><img src="/images/2016-01-14-TraveToNanJing/bowuyuan.jpg" alt="bowuyuan"></p>
<p>其他的像博物馆里江南的历史这里就不在说了，晒几张民国馆的照片吧。</p>
<p><img src="/images/2016-01-14-TraveToNanJing/minguo1.jpg" alt="minguo1"></p>
<p><img src="/images/2016-01-14-TraveToNanJing/minguo2.jpg" alt="minguo2"></p>
<p><img src="/images/2016-01-14-TraveToNanJing/minguo3.jpg" alt="minguo3"></p>
<p>转完博物院之后就已经三点多了，这时候我们就直接坐车去了总统府，到总统府的时候就已经快4点了，就要停止卖票了。要注意总统府停止卖票时间是<strong>下午4点</strong>，5店闭馆，也就是说我们只有一个小时的时间去转,这点去的时候人还是超多的，尤其到了那个有总统办公室的大楼，人超多，还没看清就被挤出去了。因为时间比较紧，我们转完中间和东边部分之后，西边的地方还没有转完，人家就已经要闭馆了，所以要去总统府的话一定要<strong>早点</strong>去。</p>
<p>总统府的大门，出来后照的，门口有卖明信片的，比总统府里和民国馆里卖得便宜</p>
<p><img src="/images/2016-01-14-TraveToNanJing/zongtongfu.jpg" alt="zongtongfu"></p>
<p>著名“天下为公”，第一次听说这个词，是在《走向共和》里看到，这也是我第一次对孙中山这个人有了稍微深入一点的了解，之前的了解全是从历史课本里得到，了解得很片面，不过依然认为孙中山还是非常伟大的，每个人都会有缺点，但是这些缺点也不能掩盖他的伟大。</p>
<p><img src="/images/2016-01-14-TraveToNanJing/zongtongfu2.jpg" alt="zongtongfu2"></p>
<p>这个好像会议室，具体的忘了。。。</p>
<p><img src="/images/2016-01-14-TraveToNanJing/zongtongfu3.jpg" alt="zongtongfu3"></p>
<p>下面这张是在总统府西边那边顺便照的一张，因为比较时间比较紧，并没有怎么转，就选一张作为代表吧</p>
<p><img src="/images/2016-01-14-TraveToNanJing/zongtongfu4.jpg" alt="zongtongfu4"></p>
<p>再去完总统府之后，我们就直接返回了东大，晚上在东大附近与以前好友们（其中四个在东大读研究生）一起大吃了一顿，非常感谢这几位好朋友的款待。</p>
<h2 id="3-Day3"><a href="#3-Day3" class="headerlink" title="3.Day3"></a>3.Day3</h2><p>前两天基本上把南京比较出名的地方都玩了一遍，所以今天就好好睡了一觉，我跟森哥直接睡到了早上11点才起来，起来之后又在东大吃了中饭，然后就跟着海坤兄一起先去了燕子矶公园，据说在那天气好的话可以看到南京第一长江大桥，而且它离南京第二长江大桥很近。</p>
<p>燕子矶公园，南京第二长江大桥的景色</p>
<p><img src="/images/2016-01-14-TraveToNanJing/changjiang2.jpg" alt="changjiang2"></p>
<p><img src="/images/2016-01-14-TraveToNanJing/changjiang2-2.jpg" alt="changjiang2-2"></p>
<p>然后，我们就坐车去了南京第一长江大桥，因为这个桥建造的时间比较长，它的人行道跟自行车道是在一起，而且很窄，电动车非常多，只想说很<strong>危险</strong>，最好还是直接去长江大桥下面的那个什么公园，公园门票是15，可以直接坐电梯坐到桥，要不然就要绕很远的路才能到桥上，而且还很危险。冒着生命危险，终于走到了长江大桥上，不照照片非好汉啊，又一波照片来袭！</p>
<p>傍晚的大桥</p>
<p><img src="/images/2016-01-14-TraveToNanJing/changjiang1.jpg" alt="changjiang1"></p>
<p>手机相机处理后的效果</p>
<p><img src="/images/2016-01-14-TraveToNanJing/changjiang1-1.jpg" alt="changjiang1-1"></p>
<p>桥前面的石像，桥口还有武警站岗的</p>
<p><img src="/images/2016-01-14-TraveToNanJing/changjiang1-2.jpg" alt="changjiang1-2"></p>
<p>看到大桥之后，我们就去了一家叫做石记鸭血粉丝店专门去吃鸭血粉丝，下面是鸭血粉丝的全家桶的图</p>
<p><img src="/images/2016-01-14-TraveToNanJing/meishi3.jpg" alt="meishi3"></p>
<h2 id="4-好友重逢"><a href="#4-好友重逢" class="headerlink" title="4.好友重逢"></a>4.好友重逢</h2><p>相聚的时间总是短暂的，前面之所以说这次不仅仅旅行，主要是这次更多的是好友的相聚，大学毕业后的（毕业一年半）再次相聚，还感慨颇深的，尤其当在火车站与好友相别，在候车室与森哥相别的时候，心中平添了很多的伤感，下次再聚不知道会是什么时候。三天的相聚，更多的是那种熟悉的感觉，方佛又回到大学时光，让我感到由衷的亲切，这感觉远胜美景千万。希望以后大家还能再一起出去玩，最后附上我们几个合照（另外两位美女就不公开了）。</p>
<p><img src="/images/2016-01-14-TraveToNanJing/hezhao.jpg" alt="hezhao"></p>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[关于Kafka学习的一些资料]]></title>
      <url>http://matt33.com/2015/12/21/kafka-learn/</url>
      <content type="html"><![CDATA[<h2 id="kafka一些重要博客参考"><a href="#kafka一些重要博客参考" class="headerlink" title="kafka一些重要博客参考"></a>kafka一些重要博客参考</h2><p>kafka设计部分的文档：</p>
<ul>
<li><a href="http://kafka.apache.org/documentation.html#design" target="_blank" rel="external">官网设计英文版</a></li>
<li><a href="http://www.oschina.net/translate/kafka-design" target="_blank" rel="external">Kafka设计中文版</a></li>
<li><a href="http://blog.csdn.net/lizhitao/article/details/39499283" target="_blank" rel="external">Kafka资源汇总</a></li>
<li><a href="http://www.jasongj.com/tags/Kafka/" target="_blank" rel="external">Json的Kafka深度解析博客</a></li>
</ul>
<p>kafka设计的一些特殊之处：</p>
<ul>
<li><a href="http://my.oschina.net/u/591402/blog/145090" target="_blank" rel="external">Kafka源码调研系统1 特色</a></li>
</ul>
<p>kafka的存储：</p>
<ul>
<li><a href="http://my.oschina.net/u/591402/blog/152837" target="_blank" rel="external">producer中partition的使用方式</a></li>
</ul>
<p>kafka监控：</p>
<ul>
<li><a href="http://my.oschina.net/u/591402/blog/158139" target="_blank" rel="external">Kafka监控之mx4j-tool</a></li>
<li><a href="http://my.oschina.net/u/591402/blog/158150" target="_blank" rel="external">Kafka监控之mx4jLoader</a></li>
<li><a href="http://matt33.com/2015/12/08/2015-12-8-kafka-monitor/">Kafka监控软件</a></li>
</ul>
<p>Kafka测试：</p>
<ul>
<li><a href="https://engineering.linkedin.com/kafka/benchmarking-apache-kafka-2-million-writes-second-three-cheap-machines#userconsent#" target="_blank" rel="external">Benchmarking Apache Kafka: 2 Million Writes Per Second (On Three Cheap Machines)</a></li>
</ul>
<p>Kafka源码解析：</p>
<ul>
<li><a href="https://github.com/wyzssw/kafka--summary" target="_blank" rel="external">wyzssw/kafka–summary</a></li>
<li><a href="http://www.cnblogs.com/huxi2b/tag/Kafka/" target="_blank" rel="external">胡夕-Kafka详细代码解释</a></li>
<li><a href="http://zqhxuyuan.github.io/2017/01/01/Kafka-Code-Index/" target="_blank" rel="external">Kafka技术内幕</a></li>
<li><a href="https://www.gitbook.com/book/zqhxuyuan1/kafka/details" target="_blank" rel="external">Kafka源码分析的GitBook</a></li>
<li><a href="http://blog.csdn.net/chunlongyu/article/category/6417583" target="_blank" rel="external">Kafka源码深度解析</a></li>
</ul>
<p>Kafka最新动态</p>
<ul>
<li>可以关注<a href="http://www.confluent.io/blog" target="_blank" rel="external">confluent博客</a></li>
</ul>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[Kafka监控软件介绍]]></title>
      <url>http://matt33.com/2015/12/08/2015-12-8-kafka-monitor/</url>
      <content type="html"><![CDATA[<h1 id="KafkaOffsetMonitor"><a href="#KafkaOffsetMonitor" class="headerlink" title="KafkaOffsetMonitor"></a>KafkaOffsetMonitor</h1><h2 id="下载安装"><a href="#下载安装" class="headerlink" title="下载安装"></a>下载安装</h2><ul>
<li><a href="https://github.com/quantifind/KafkaOffsetMonitor" target="_blank" rel="external">源码下载地址</a></li>
<li><a href="https://github.com/quantifind/KafkaOffsetMonitor/releases/download/v0.2.1/KafkaOffsetMonitor-assembly-0.2.1.jar" target="_blank" rel="external">jar下载地址</a></li>
</ul>
<h2 id="使用方法"><a href="#使用方法" class="headerlink" title="使用方法"></a>使用方法</h2><p>This is a small webapp, you can run it locally or on a server, as long as you have access to the ZooKeeper nodes controlling kafka.</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">java -cp KafkaOffsetMonitor-assembly-0.2.1.jar com.quantifind.kafka.offsetapp.OffsetGetterWeb --zk serveIp1,serveIp2,serveIp3 --port 8080 --refresh 10.seconds --retain 2.days</div></pre></td></tr></table></figure>
<p>The arguments are:</p>
<ul>
<li><strong>ZK</strong>: the ZooKeeper hosts;</li>
<li><strong>port</strong>: on what port will the app be available;</li>
<li><strong>refresh</strong>: how often should the app refresh and store a point in the DB;</li>
<li><strong>retain</strong>: how long should points be kept in the DB;</li>
<li><strong>dbName</strong>: where to store the history (default ‘offsetapp’);</li>
</ul>
<h1 id="Kafka-Manager"><a href="#Kafka-Manager" class="headerlink" title="Kafka Manager"></a>Kafka Manager</h1><p><a href="https://github.com/yahoo/kafka-manager" target="_blank" rel="external">源码地址</a></p>
<h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><p><a href="http://hengyunabc.github.io/kafka-manager-install/" target="_blank" rel="external">Kafka Manager安装</a></p>
<h3 id="sbt安装"><a href="#sbt安装" class="headerlink" title="sbt安装"></a>sbt安装</h3><p><a href="http://www.scala-sbt.org/download.html" target="_blank" rel="external">sbt安装</a></p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">curl https://bintray.com/sbt/rpm/rpm &gt; bintray-sbt-rpm.repo</div><div class="line">sudo mv bintray-sbt-rpm.repo /etc/yum.repos.d/</div><div class="line">sudo yum install sbt</div></pre></td></tr></table></figure>
<h3 id="下载，编译"><a href="#下载，编译" class="headerlink" title="下载，编译"></a>下载，编译</h3><p>下载，并编译源码：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">git <span class="built_in">clone</span> https://github.com/yahoo/kafka-manager</div><div class="line"><span class="built_in">cd</span> kafka-manager</div><div class="line">sbt clean dist</div></pre></td></tr></table></figure>
<p>生成的包会在<code>kafka-manager/target/universal</code> 下面。生成的包只需要java环境就可以运行了，在部署的机器上不需要安装sbt.</p>
<h3 id="打包部署"><a href="#打包部署" class="headerlink" title="打包部署"></a>打包部署</h3><p>打好包好，在部署机器上解压，修改好配置文件，就可以运行了。</p>
<p>解压：<br><figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">unzip kafka-manager-1.0-SNAPSHOT.zip</div></pre></td></tr></table></figure></p>
<h2 id="配置运行"><a href="#配置运行" class="headerlink" title="配置运行"></a>配置运行</h2><h3 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h3><p>修改<code>conf/application.conf</code>，把<code>kafka-manager.zkhosts</code>改为自己的zookeeper服务器地址</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">kafka-manager.zkhosts=<span class="string">"localhost:2181"</span></div></pre></td></tr></table></figure>
<h3 id="启动"><a href="#启动" class="headerlink" title="启动"></a>启动</h3><figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">./bin/kafka-manager -Dconfig.file=./conf/application.conf -Dhttp.port=8080</div></pre></td></tr></table></figure>
<h3 id="kafka-manager其他方面"><a href="#kafka-manager其他方面" class="headerlink" title="kafka-manager其他方面"></a>kafka-manager其他方面</h3><p>查看帮助</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">./bin/kafka-manager -h</div></pre></td></tr></table></figure>
<p>后台运行</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">nohup ./kafka-manager -Dconfig.file=../conf/application.conf &gt;/dev/null 2&gt;&amp;1 &amp;</div></pre></td></tr></table></figure>
<p>默认http端口是9000，可以修改配置文件里的http.port的值，或者通过命令行参数传递：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">./kafka-manager -Dhttp.port=9001</div></pre></td></tr></table></figure>
<p>如果不想自己编译源文件，也可以通过下面的地址直接下载，<a href="http://pan.baidu.com/s/1kTtFpGV" target="_blank" rel="external">kafka-manager-1.0-SNAPSHOT.zip下载地址</a></p>
<h1 id="Kafka-web-console"><a href="#Kafka-web-console" class="headerlink" title="Kafka-web-console"></a>Kafka-web-console</h1><p><a href="https://github.com/claudemamo/kafka-web-console" target="_blank" rel="external">源码地址</a></p>
<p>不过这个项目好像不再进行更新了，想了解这个项目的话可以进入github主页去研究研究。</p>
<h1 id="Kafka-Eagle"><a href="#Kafka-Eagle" class="headerlink" title="Kafka Eagle"></a>Kafka Eagle</h1><p>kafka-eagle 是最近新开源的一个 Kafka 监控系统，做得也挺不错的，这里介绍不再详述，感兴趣的同学可以参考以下文章：</p>
<ul>
<li><a href="https://github.com/smartloli/kafka-eagle" target="_blank" rel="external">Github 主页：smartloli/kafka-eagle</a>；</li>
<li><a href="https://blog.csdn.net/whg18526080015/article/details/73642241" target="_blank" rel="external">kafka eagle安装与使用</a>；</li>
<li><a href="https://www.cnblogs.com/smartloli/p/5829395.html" target="_blank" rel="external">Kafka 消息监控 - Kafka Eagle</a></li>
</ul>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[Kafka程序设计之Producer]]></title>
      <url>http://matt33.com/2015/11/27/kafka-code1/</url>
      <content type="html"><![CDATA[<p>本文主要是介绍一下kafka基于<code>Producer API</code>的程序设计，使用的kafka版本为<code>2.10-0.8.1.1</code>。</p>
<h2 id="1-前言"><a href="#1-前言" class="headerlink" title="1.前言"></a>1.前言</h2><p>在写完<a href="http://matt33.com/2015/11/13/kafka-install/">Kafka集群的安装与配置</a>和<a href="http://matt33.com/2015/11/14/The-Introduce-of-Kafka/">Kafka的简单介绍</a>这两篇博客之后，从本文开始准备介绍一下Kafka的程序设计部分，大概会分为三篇介绍，第一篇是基于<code>Kafka Producer API</code>的程序设计，也就是本文，第二篇是基于<code>Kafka High Level Consumer API</code>的程序设计，第三篇是基于<code>Kafka Simple Consumer API</code>的程序设计。本文主要是根据kafka提供的官方文档来介绍，希望能给刚接触kafka程序设计的初学者提供一些帮助。</p>
<p>我们知道，kafka的基本架构其实非常简单，但kafka作为管道传输为了保证其强大的功能与稳定的性能，kafka在内部实现上是做了非常多的努力的，这些我会在后续的文章中慢慢讲解。然而对大部分人而言重要的就是如何进行程序设计来实现所需的功能，kafka给我们提供了丰富而简介的API接口，本文的例子是通过<a href="https://github.com/apache/kafka/tree/trunk/examples/src/main/java/kafka/examples" target="_blank" rel="external">Kafka Examples</a>中的例子来讲解如何使用这些API接口来进行程序设计。本文中使用的kafka的版本为<code>kafka_2.10-0.8.1.1</code>，并且使用maven建立工程，需要在pom.xml文件加入如下的依赖包：</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div></pre></td><td class="code"><pre><div class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></div><div class="line">	<span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.kafka<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></div><div class="line">	<span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>kafka_2.10<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></div><div class="line">	<span class="tag">&lt;<span class="name">version</span>&gt;</span>0.8.1<span class="tag">&lt;/<span class="name">version</span>&gt;</span></div><div class="line">	<span class="tag">&lt;<span class="name">exclusions</span>&gt;</span></div><div class="line">		<span class="tag">&lt;<span class="name">exclusion</span>&gt;</span></div><div class="line">			<span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>jms<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></div><div class="line">			<span class="tag">&lt;<span class="name">groupId</span>&gt;</span>javax.jms<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></div><div class="line">		<span class="tag">&lt;/<span class="name">exclusion</span>&gt;</span></div><div class="line">		<span class="tag">&lt;<span class="name">exclusion</span>&gt;</span></div><div class="line">			<span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>jmxtools<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></div><div class="line">			<span class="tag">&lt;<span class="name">groupId</span>&gt;</span>com.sun.jdmk<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></div><div class="line">		<span class="tag">&lt;/<span class="name">exclusion</span>&gt;</span></div><div class="line">		<span class="tag">&lt;<span class="name">exclusion</span>&gt;</span></div><div class="line">			<span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>jmxri<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></div><div class="line">			<span class="tag">&lt;<span class="name">groupId</span>&gt;</span>com.sun.jmx<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></div><div class="line">		<span class="tag">&lt;/<span class="name">exclusion</span>&gt;</span></div><div class="line">	<span class="tag">&lt;/<span class="name">exclusions</span>&gt;</span></div><div class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></div></pre></td></tr></table></figure>
<p>下面具体讲解一下<code>Producer</code>。</p>
<h2 id="2-实例分析"><a href="#2-实例分析" class="headerlink" title="2.实例分析"></a>2.实例分析</h2><p>Producer是用来把消息发送到Kafka的Broker端，Producer应用非常广泛，在本文中只涉及发送随机消息和本地文件。</p>
<h3 id="2-1-API介绍"><a href="#2-1-API介绍" class="headerlink" title="2.1.API介绍"></a>2.1.API介绍</h3><p>实现Producer程序主要会使用到以下三个类：</p>
<ul>
<li>kafka.producer.ProducerConfig：配置Producer，比如定义metadata.bokers.list、partitioner.class等；</li>
<li>kafka.javaapi.producer.Producer：最主要的类，用来发送消息等；</li>
<li>kafka.producer.KeyedMessage：定义要发送的消息，比如发送到哪个topic的哪个partition等。</li>
</ul>
<h3 id="2-2-示例分析"><a href="#2-2-示例分析" class="headerlink" title="2.2.示例分析"></a>2.2.示例分析</h3><p>借用官方文档<a href="https://cwiki.apache.org/confluence/display/KAFKA/0.8.0+Producer+Example" target="_blank" rel="external">0.8.0 Producer Example</a>中给出的样例程序。</p>
<p>Producer的程序如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">TestProducer</span> </span>&#123;</div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</div><div class="line">        <span class="keyword">long</span> events = Long.parseLong(args[<span class="number">0</span>]);</div><div class="line">        Random rnd = <span class="keyword">new</span> Random();</div><div class="line"></div><div class="line">        Properties props = <span class="keyword">new</span> Properties();</div><div class="line">        props.put(<span class="string">"metadata.broker.list"</span>, <span class="string">"broker1:9092,broker2:9092 "</span>);</div><div class="line">        props.put(<span class="string">"serializer.class"</span>, <span class="string">"kafka.serializer.StringEncoder"</span>);</div><div class="line">        props.put(<span class="string">"partitioner.class"</span>, <span class="string">"example.producer.SimplePartitioner"</span>);</div><div class="line">        props.put(<span class="string">"request.required.acks"</span>, <span class="string">"1"</span>);</div><div class="line"></div><div class="line">        ProducerConfig config = <span class="keyword">new</span> ProducerConfig(props);</div><div class="line"></div><div class="line">        Producer&lt;String, String&gt; producer = <span class="keyword">new</span> Producer&lt;String, String&gt;(config);</div><div class="line"></div><div class="line">        <span class="keyword">for</span> (<span class="keyword">long</span> nEvents = <span class="number">0</span>; nEvents &lt; events; nEvents++) &#123;</div><div class="line">               <span class="keyword">long</span> runtime = <span class="keyword">new</span> Date().getTime();  </div><div class="line">               String ip = <span class="string">"192.168.2."</span> + rnd.nextInt(<span class="number">255</span>);</div><div class="line">               String msg = runtime + <span class="string">",www.example.com,"</span> ip;</div><div class="line">               KeyedMessage&lt;String, String&gt; data = <span class="keyword">new</span> KeyedMessage&lt;String, String&gt;(<span class="string">"page_visits"</span>, ip, msg);</div><div class="line">               producer.send(data);</div><div class="line">        &#125;</div><div class="line">        producer.close();</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>Partitioner的程序如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">SimplePartitioner</span> <span class="keyword">implements</span> <span class="title">Partitioner</span> </span>&#123;</div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="title">SimplePartitioner</span> <span class="params">(VerifiableProperties props)</span> </span>&#123;</div><div class="line"></div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">partition</span><span class="params">(Object key, <span class="keyword">int</span> a_numPartitions)</span> </span>&#123;</div><div class="line">        <span class="keyword">int</span> partition = <span class="number">0</span>;</div><div class="line">        String stringKey = (String) key;</div><div class="line">        <span class="keyword">int</span> offset = stringKey.lastIndexOf(<span class="string">'.'</span>);</div><div class="line">        <span class="keyword">if</span> (offset &gt; <span class="number">0</span>) &#123;</div><div class="line">           partition = Integer.parseInt( stringKey.substring(offset+<span class="number">1</span>)) % a_numPartitions;</div><div class="line">        &#125;</div><div class="line">       <span class="keyword">return</span> partition;</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>这个样例程序实现的功能非常简单，就是发送多条（参数指定）类似于<code>runtime + “,www.example.com,” + “192.168.2.” + rnd.nextInt(255);</code>的消息。通过这个程序可以看出实现Kafka producer功能主要有以下三点需要注意：</p>
<p><strong>Kafka Properties</strong></p>
<p>这是实现代码的第一步，在代码中定义了一个<code>Properties</code>。这个<code>Properties</code>是通过<code>kafka.producer.ProducerConfig</code>将一些参数传递给Producer，告诉Producer如何找到找到集群，怎么序列化消息和消息如何发给Partition等。</p>
<p>样例程序中的这些参数意义为：</p>
<ul>
<li><code>metadata.broker.list</code> 定义Producer为每个Partition选作Leader的broker，应至少有两个，而且这两个broker一定要是开启Kafka服务；</li>
<li><code>serializer.class</code>定义message传送给broker时，应该使用什么类型的序列化方式，但是注意这个类型的编码也一定要能够接受KeyMessage对象定义的类型（Java对象在传输前需要进行序列化）；</li>
<li><code>partitioner.class</code>决定了这个message应该发送给这个topic的哪个Partition（如果程序中为key指定了一个值但是没有定义一个partitioner.class，kafka就会使用默认的partitioner发送到指定的Partition，如果key没有定义，Producer就会把message发送到随机的Partition）；</li>
<li><code>request.required.acks</code>默认是0，可以设置0，1，-1；</li>
</ul>
<p>程序中可以传入的参数参考<a href="http://kafka.apache.org/documentation.html#producerconfigs" target="_blank" rel="external">Producer API</a>，经常使用参数有 <code>producer.type</code>, <code>batch.size</code>, <code>receive.buffer.bytes</code>, <code>send.buffer.bytes</code> 和 <code>acks</code>等。</p>
<p>使用的方法：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">props.put(<span class="string">"producer.type"</span>, async);</div><div class="line">props.put(<span class="string">"batch.num.messages"</span>, batch);</div></pre></td></tr></table></figure>
<p><strong>Producer object</strong></p>
<p>再定义完<code>Properties</code>和<code>Producer object</code>之后，下面就是将topic，partition和message传递给<code>KeyedMessage</code>，然后通过producer的<code>send</code>方法将消息发送出去。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">ProducerConfig config = <span class="keyword">new</span> ProducerConfig(props);</div><div class="line">Producer&lt;String, String&gt; producer = <span class="keyword">new</span> Producer&lt;String, String&gt;(config);</div><div class="line"><span class="comment">/**</span></div><div class="line">* 数据的处理过程</div><div class="line">*/</div><div class="line">KeyedMessage&lt;String, String&gt; data = <span class="keyword">new</span> KeyedMessage&lt;String, String&gt;(<span class="string">"page_visits"</span>, ip, msg);<span class="comment">//KeyedMessage&lt;String, String&gt;(topicName, partitionKey, msg)</span></div><div class="line">producer.send(data);</div></pre></td></tr></table></figure>
<p><strong>自定义Partition</strong></p>
<p>样例代码中的<code>SimplePartitioner</code>是自定义的，PartitionKey的值通过十进制ip地址小数点最后一位与a_numPartitions取余得到。在自定义Partition时，需要在程序（如：<code>props.put(&quot;partitioner.class&quot;, &quot;example.producer.SimplePartitioner&quot;)</code>）中指定Partitioner的位置。</p>
<h2 id="3-实例程序设计"><a href="#3-实例程序设计" class="headerlink" title="3.实例程序设计"></a>3.实例程序设计</h2><p>在解析完样例程序之后，下面我们通过一个实际案例来设计Producer程序。</p>
<h3 id="3-1-实现功能"><a href="#3-1-实现功能" class="headerlink" title="3.1.实现功能"></a>3.1.实现功能</h3><p>程序要实现的功能是监控本地一个文件目录，将此目录中文件数据发送到Kafka的Broker端，并且每当发送完一个文件后就删除该文件，然后当有新的文件传进来之后就发送这个文件。</p>
<h3 id="3-2-程序设计"><a href="#3-2-程序设计" class="headerlink" title="3.2.程序设计"></a>3.2.程序设计</h3><p>本例我们就不在使用自定义的Partition，而直接由参数传入PartitionKey的值。程序设计的思路：</p>
<ol>
<li>监控给定的目录；</li>
<li>如果目录没有文件，sleep一段时间（sleep的时间需要根据具体的应用来设置），返回第1步；</li>
<li>当目录中有文件时，将文件中的数据按行发送；</li>
<li>这个文件发送完，就将该文件删除，继续发送下一个文件，知道目录中文件发送完毕，再返回第1步。</li>
</ol>
<p>根据这个思路，程序主要实现如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">producer</span> </span>&#123;</div><div class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> IOException </span>&#123;</div><div class="line">		<span class="keyword">if</span> (args.length!=<span class="number">3</span>) &#123;</div><div class="line">			System.err.println(<span class="string">"please input &lt;input&gt; &lt;topic&gt; &lt;partitionKey&gt; "</span>);</div><div class="line">			System.exit(<span class="number">1</span>);</div><div class="line">		&#125;</div><div class="line">		String input = args[<span class="number">0</span>];</div><div class="line">		String topic = args[<span class="number">1</span>];</div><div class="line">		String partitionKey=args[<span class="number">2</span>];</div><div class="line">		Properties props = <span class="keyword">new</span> Properties();</div><div class="line">		props.put(<span class="string">"metadata.broker.list"</span>, <span class="string">"ip1:9092,ip2:9092"</span>);</div><div class="line">		props.put(<span class="string">"serializer.class"</span>, <span class="string">"kafka.serializer.StringEncoder"</span>);</div><div class="line">		props.put(<span class="string">"key.serializer.class"</span>, <span class="string">"kafka.serializer.StringEncoder"</span>);</div><div class="line"></div><div class="line">		ProducerConfig config = <span class="keyword">new</span> ProducerConfig(props);</div><div class="line">		BufferedReader reader=<span class="keyword">null</span>;</div><div class="line">		<span class="keyword">int</span> fileLength = <span class="number">0</span>;</div><div class="line"></div><div class="line">		File file = <span class="keyword">new</span> File(inputFold);<span class="comment">//输入目录由参数给定</span></div><div class="line"></div><div class="line">		<span class="keyword">if</span> (file.exists()) &#123;</div><div class="line">		    <span class="keyword">while</span> (<span class="keyword">true</span>) &#123;<span class="comment">//一直监控目录</span></div><div class="line">		    	File[] files = file.listFiles();</div><div class="line">			    <span class="keyword">if</span> (files.length == <span class="number">0</span>) &#123;</div><div class="line">			        System.out.println(<span class="string">"文件夹是空的!"</span>);</div><div class="line">			        <span class="keyword">try</span> &#123;</div><div class="line">			            Thread.sleep(<span class="number">60000</span>);<span class="comment">//sleep1min</span></div><div class="line">					&#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</div><div class="line">						e.printStackTrace();</div><div class="line">					&#125;</div><div class="line">			        <span class="keyword">continue</span>;</div><div class="line">			    &#125; <span class="keyword">else</span> &#123;</div><div class="line">			        <span class="keyword">for</span> (File file2 : files) &#123;</div><div class="line">			        	<span class="keyword">if</span> (file2.isDirectory()) &#123;</div><div class="line">							System.out.println(<span class="string">"有递归目录："</span> + file2.getAbsolutePath());</div><div class="line">						&#125; <span class="keyword">else</span> &#123;</div><div class="line">							<span class="keyword">try</span> &#123;</div><div class="line">								reader = <span class="keyword">new</span> BufferedReader(<span class="keyword">new</span> InputStreamReader(<span class="keyword">new</span> FileInputStream(file2.getAbsolutePath())));</div><div class="line">							&#125; <span class="keyword">catch</span> (Exception e) &#123;</div><div class="line">								System.err.println(<span class="string">"输入文件错误"</span>);</div><div class="line">								System.exit(<span class="number">2</span>);</div><div class="line">						&#125;</div><div class="line">						<span class="keyword">while</span> (<span class="keyword">true</span>) &#123;</div><div class="line">							String line=<span class="keyword">null</span>;</div><div class="line">							<span class="keyword">try</span> &#123;</div><div class="line">								line = reader.readLine();</div><div class="line">							&#125; <span class="keyword">catch</span> (IOException e) &#123;</div><div class="line">            					System.err.println(<span class="string">"输入文件错误"</span>);</div><div class="line">            					e.printStackTrace();</div><div class="line">            					System.exit(<span class="number">2</span>);</div><div class="line">							&#125;</div><div class="line">							<span class="keyword">if</span>(line==<span class="keyword">null</span>)</div><div class="line">							&#123;</div><div class="line">								<span class="keyword">break</span>;</div><div class="line">							&#125;</div><div class="line">							KeyedMessage&lt;String, String&gt; data = <span class="keyword">new</span> KeyedMessage&lt;String, String&gt;(topic,partitionKey,line);</div><div class="line">							producer.send(data);</div><div class="line">						&#125;</div><div class="line">						<span class="keyword">try</span> &#123;</div><div class="line">							reader.close();</div><div class="line">						&#125; <span class="keyword">catch</span> (IOException e) &#123;</div><div class="line">							e.printStackTrace();</div><div class="line">						&#125;</div><div class="line">					&#125;</div><div class="line">					file2.delete();</div><div class="line">				&#125;</div><div class="line">			&#125;</div><div class="line">		&#125;</div><div class="line">    &#125; <span class="keyword">else</span> &#123;</div><div class="line">          System.out.println(<span class="string">"目录不存在!"</span>);</div><div class="line">    &#125;</div><div class="line">    producer.close();</div><div class="line">	&#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<hr>
<h4 id="参考："><a href="#参考：" class="headerlink" title="参考："></a>参考：</h4><ul>
<li><a href="http://kafka.apache.org/documentation.html" target="_blank" rel="external">Kafka Documentation</a></li>
<li><a href="https://cwiki.apache.org/confluence/display/KAFKA/0.8.0+Producer+Example" target="_blank" rel="external">0.8.0 Producer Example</a></li>
</ul>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[Kafka的简单介绍]]></title>
      <url>http://matt33.com/2015/11/14/The-Introduce-of-Kafka/</url>
      <content type="html"><![CDATA[<p>这篇文章主要是简单地把Kafka的背景，基础知识和应用场景介绍一下，算是一篇入门的文章。</p>
<h2 id="1-kafka介绍"><a href="#1-kafka介绍" class="headerlink" title="1.kafka介绍"></a>1.kafka介绍</h2><p>关于kafka入门的文章最好的就莫过于kafka的<a href="http://kafka.apache.org/documentation.html" target="_blank" rel="external">官方文档</a>了，这上面对kafka的定义是：</p>
<blockquote>
<p>Kafka is a distributed, partitioned, replicated commit log service. It provides the functionality of a messaging system, but with a unique design.</p>
</blockquote>
<p>kafka是一个分布式的，可分区的，可备份的日志提交服务，它使用独特的设计实现了一个消息系统的功能。</p>
<p>到底kafka使用什么独特的设计可以让它在消息处理领域独占鳌头呢？这就涉及到kafka的内部机制，这些我会在后续的文章中向大家慢慢介绍，这里先介绍一下kafka集群的基本结构和kafka的一些专业术语。</p>
<h3 id="1-1-kafka集群的基本架构"><a href="#1-1-kafka集群的基本架构" class="headerlink" title="1.1.kafka集群的基本架构"></a>1.1.kafka集群的基本架构</h3><p>一个典型的kafka集群架构如下图所示：</p>
<p><img src="/images/2015-11-14-kafka-introduce/kafka.png" alt="kafka"></p>
<p>kafka集群常用的场景就是，producer把日志信息推送（push）到broker节点上，然后consumer（可以是写入到hdfs或者其他的一些应用）再从broker拉取（pull）信息。kafka的push&amp;pull机制如下图所示，具体的这样设计的原因我会在后续的文章中进行介绍。</p>
<p><img src="/images/2015-11-14-kafka-introduce/pull.png" alt="pull"></p>
<p>作为一个message system，kafka遵循了传统的方式，选择由kafka的producer向broker push信息，而consumer从broker pull信息。kafka的consumer之所以没有采用push模式，主要是因为push模式很难适应速率不同的consumer，因为消息发送速率是由broker决定的。push模式的目标就是尽可能以最快速度传递消息，但是这样很容易造成consumer来不及处理消息，典型的表现就是拒绝服务以及网络拥塞，而pull模式则可以根据consumer的消费能力以适当的速率消费message。</p>
<h3 id="1-2-专业术语"><a href="#1-2-专业术语" class="headerlink" title="1.2.专业术语"></a>1.2.专业术语</h3><p>kafka使用的一些主要的专业术语：</p>
<ul>
<li><strong>Topic</strong>：特指Kafka处理的消息源的不同分类，其实也可以理解为对不同消息源的区分的一个标识；</li>
<li><strong>Partition</strong>：Topic物理上的分组，一个topic可以设置为多个partition，每个partition都是一个有序的队列，partition中的每条消息都会被分配一个有序的id（offset）；</li>
<li><strong>Message</strong>：消息，是通信的基本单位，每个producer可以向一个topic（主题）发送一些消息；</li>
<li><strong>Producers</strong>：消息和数据生产者，向Kafka的一个topic发送消息的过程叫做producers（producer可以选择向topic哪一个partition发送数据）。</li>
<li><strong>Consumers</strong>：消息和数据消费者，接收topics并处理其发布的消息的过程叫做consumer，同一个topic的数据可以被多个consumer接收；</li>
<li><strong>Broker</strong>：缓存代理，Kafka集群中的一台或多台服务器统称为broker。</li>
</ul>
<p>理解了上述概念之后，再来看kafka就容易了。</p>
<h3 id="1-3-kafka的应用场景"><a href="#1-3-kafka的应用场景" class="headerlink" title="1.3.kafka的应用场景"></a>1.3.kafka的应用场景</h3><p>Kafka主要用于处理流式数据。流式数据在web网站应用中非常常见，这些数据包括网站的pv、用户访问了什么内容，搜索了什么内容等。这些数据通常以日志的形式记录下来，然后每隔一段时间进行一次统计处理。Kafka的作用类似于缓存，能够很好地处理实时和离线应用。</p>
<h2 id="2-概念详解"><a href="#2-概念详解" class="headerlink" title="2.概念详解"></a>2.概念详解</h2><h3 id="2-1-topic"><a href="#2-1-topic" class="headerlink" title="2.1.topic"></a>2.1.topic</h3><p>正如前面介绍的，topic是kafka发送消息的一个标识，一般以目录的形式存在，对于一个有三个partition的topic而言，它日志信息结构大概如下图所示：</p>
<p><img src="/images/2015-11-14-kafka-introduce/log.png" alt="log"></p>
<p>每一个partition实际上都是一个有序的，不可变的消息序列，producer发送到broker的消息会写入到相应的partition目录下，每个partition都会有一个有序的id（<code>offset</code>），这个offset确定这个消息在partition中的具体位置。</p>
<p>举一个例子，我们在一个kafka集群中建立的名为<code>wangzzu</code>，partition数为3的topic，kafka就会在broker的<code>/tmp/kafka-logs</code>（目录可以修改，可参考我<a href="http://matt33.com/2015/11/13/kafka-install/">kafka集群安装与配置</a>）新建三个目录，这里我们直接指定将三个partition建立在同一个broker上，如下图所示：</p>
<p><img src="/images/2015-11-14-kafka-introduce/topic.png" alt="topic"></p>
<p>当启动producer程序时，就会向kafka集群发送信息，而kafka就会把中间信息存储在这三个目录下，具体的发送方式和消息存储结构会在以后的文章中介绍。</p>
<h3 id="2-2-producer"><a href="#2-2-producer" class="headerlink" title="2.2.producer"></a>2.2.producer</h3><p>producer这部分相比较而言，是比较简单的，就是把消息发送给它所选择的topic，也可以具体指定发给这个topic的哪个一个partition，否则producer就会使用<code>hashing-based partitioner</code>来决定发送到哪个partition，这个问题还是需要多说一些，之前我在测试kafka速度的时候就遇到了这个问题，当我们增加broker的数量时，kafka的发送速度并没有线性增加，最后发现就是因为这个原因，没有指明发送数据到哪个partition，具体的解释我就引用官网<a href="https://cwiki.apache.org/confluence/display/KAFKA/FAQ" target="_blank" rel="external">WIKI</a>中给出回答：</p>
<blockquote>
<p>In Kafka producer, a partition key can be specified to indicate the destination partition of the message. By default, a hashing-based partitioner is used to determine the partition id given the key, and people can use customized partitioners also.<br>To reduce # of open sockets, in 0.8.0(<a href="https://issues.apache.org/jira/browse/KAFKA-1017" target="_blank" rel="external">High number of open file handles in 0.8 producer</a>), when the partitioning key is not specified or null, a producer will pick a random partition and stick to it for some time (default is 10 mins) before switching to another one. So, if there are fewer producers than partitions, at a given point of time, some partitions may not receive any data. To alleviate this problem, one can either reduce the metadata refresh interval or specify a message key and a customized random partitioner. For more detail see <a href="http://mail-archives.apache.org/mod_mbox/kafka-dev/201310.mbox/%3CCAFbh0Q0aVh%2Bvqxfy7H-%2BMnRFBt6BnyoZk1LWBoMspwSmTqUKMg%40mail.gmail.com%3E" target="_blank" rel="external">this thread</a></p>
</blockquote>
<h3 id="2-3-consumer"><a href="#2-3-consumer" class="headerlink" title="2.3.consumer"></a>2.3.consumer</h3><p>这里的consumer部分，主要是以<code>High Level Consumer API</code>为例。</p>
<p>consumer是一个抽象的概念，调用<code>Consumer API</code>的程序都可以称作为一个consumer，它从broker端订阅某个topic的消息。如果只有一个consumer的话，该topic（可能含有多个partition）下所有消息都会被这个consumer接收。但是在分布式的环境中，我们可能会遇到这样一种情景，对于一个有多个partition的topic，我们希望启动多个consumer去消费这些partition（如果发送速度较快，一个consumer是无法消费完的），并且要求topic的一条消息只能发给其中一个consumer，不希望这些conusmer出现重复接收一条消息的情况。对于这种情况，我们应该怎么办呢？kafka给我们提供了一种机制，可以很好来适应这种情况，那就是<strong>consumer group</strong>（当然也可以应用在第一种情况，实际上，如果只有一个consumer时，是不需要指定consumer group，这时kafka会自动给这个consumer生成一个group名）。</p>
<p>在调用conusmer API时，一般都会指定一个consumer group，该group订阅的topic的每一条消息都发送到这个group的某一台机器上。借用官网一张图来详细介绍一下这种情况，假如kafka集群有两台broker，集群上有一个topic，它有4个partition，partition 0和1在broker1上，partition 2和3在broker2上，这时有两个consumer group同时订阅这个topic，其中一个group有2个consumer，另一个consumer有4个consumer，则它们的订阅消息情况如下图所示：</p>
<p><img src="/images/2015-11-14-kafka-introduce/consumerGroup.png" alt="consumerGroup"></p>
<p>因为group A只有两个consumer，所以一个consumer会消费两个partition；而group B有4个consumer，一个consumer会去消费一个partition。这里要注意的是，kafka可以保证一个<strong>partition内的数据是有序的</strong>，所以group B中的consumer收到的数据是可以保证有序的，但是Group A中的consumer就无法保证了。</p>
<p>group读取topic，<strong>partition分配</strong>机制是：</p>
<ul>
<li>如果group中的consumer数小于topic中的partition数，那么group中的consumer就会消费多个partition；</li>
<li>如果group中的consumer数等于topic中的partition数，那么group中的一个consumer就会消费topic中的一个partition；</li>
<li>如果group中的consumer数大于topic中的partition数，那么group中就会有一部分的consumer处于空闲状态。</li>
</ul>
<h2 id="3-kafka的简单使用"><a href="#3-kafka的简单使用" class="headerlink" title="3.kafka的简单使用"></a>3.kafka的简单使用</h2><p>这部分是利用kafka自带的<code>kafka-console-producer.sh</code>和<code>kafka-console-consumer.sh</code>来发送和接收消息，而具体如何调用 kafka  API使用kafka会在后续的文章中介绍。</p>
<p>首先要启动kafka和建立topic，可参考<a href="http://matt33.com/2015/05/20/KafkaOrder/">Kafka常用的一些命令</a></p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">nohup bin/kafka-server-start.sh config/server.properties &amp; <span class="comment">#启动kafka，并且使用nohup将日志输出到当前目录的nohup.out中，使用&amp;后台运行</span></div></pre></td></tr></table></figure>
<p>topic还接着使用<code>wangzzu</code>（建立topic命令参考2.1中的图片），下面开启<code>kafka-console-producer.sh</code>并发送几条消息</p>
<p><img src="/images/2015-11-14-kafka-introduce/produce.png" alt="producer"></p>
<p>然后，启动<code>kafka-console-consumer.sh</code>就可以收到我们发送的这几条消息</p>
<p><img src="/images/2015-11-14-kafka-introduce/consumer.png" alt="consumer"></p>
<p>这个就是kafka的最简单的使用情况了。</p>
<p>希望这篇文章对初学者能有所帮助（<code>转载请注明出处</code>）。</p>
<hr>
<h4 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h4><ul>
<li><a href="http://kafka.apache.org/documentation.html" target="_blank" rel="external">Kafka官方文档</a></li>
</ul>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[Kafka集群的安装与配置]]></title>
      <url>http://matt33.com/2015/11/13/kafka-install/</url>
      <content type="html"><![CDATA[<p>使用过kafka的童鞋应该都知道，kafka的安装是比较简单的，尤其跟hadoop，storm这类相比。本文就主要介绍kafka集群的安装和配置方法。</p>
<h1 id="安装环境"><a href="#安装环境" class="headerlink" title="安装环境"></a>安装环境</h1><p>本人在安装kafka集群时，因为集群已经配置好了CDH的环境，在CDH环境安装kafka就变得非常简单。集群环境如下：</p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Value</th>
</tr>
</thead>
<tbody>
<tr>
<td>Java版本</td>
<td>java 1.6.0_31</td>
</tr>
<tr>
<td>Linux版本</td>
<td>Centos 6.6</td>
</tr>
<tr>
<td>CDH版本</td>
<td>CDH 5.4.0</td>
</tr>
<tr>
<td>zookeeper版本</td>
<td>Zookeeper 3.4.5-cdh5.4.0</td>
</tr>
</tbody>
</table>
<h1 id="安装Kafka"><a href="#安装Kafka" class="headerlink" title="安装Kafka"></a>安装Kafka</h1><h2 id="下载相应kafka版本"><a href="#下载相应kafka版本" class="headerlink" title="下载相应kafka版本"></a>下载相应kafka版本</h2><p>这是kafka的<a href="http://kafka.apache.org/downloads.html" target="_blank" rel="external">官网Download地址</a>，我们安装的kafka版本为<code>2.10-0.8.1.1</code>，就选择下载<code>kafka-0.8.1.1-src.tgz</code>.</p>
<h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><p>这个安装就是解压对应的压缩文件：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">tar -zxvf kafka-0.8.1.1-src.tgz</div></pre></td></tr></table></figure>
<h1 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h1><p>这里的配置主要是<code>broker</code>的配置，修改<code>kafka-0.8.1.1-src/config/server.properties</code>文件，<a href="http://kafka.apache.org/08/configuration.html" target="_blank" rel="external">参数意义</a>,重要的设置参数，在下面的配置文件我们会加以说明：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div><div class="line">113</div><div class="line">114</div><div class="line">115</div><div class="line">116</div><div class="line">117</div><div class="line">118</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># Licensed to the Apache Software Foundation (ASF) under one or more</span></div><div class="line"><span class="comment"># contributor license agreements. See the NOTICE file distributed with</span></div><div class="line"><span class="comment"># this work for additional information regarding copyright ownership.</span></div><div class="line"><span class="comment"># The ASF licenses this file to You under the Apache License, Version 2.0</span></div><div class="line"><span class="comment"># (the "License"); you may not use this file except in compliance with</span></div><div class="line"><span class="comment"># the License. You may obtain a copy of the License at</span></div><div class="line"><span class="comment">#</span></div><div class="line"><span class="comment"># http://www.apache.org/licenses/LICENSE-2.0</span></div><div class="line"><span class="comment">#</span></div><div class="line"><span class="comment"># Unless required by applicable law or agreed to in writing, software</span></div><div class="line"><span class="comment"># distributed under the License is distributed on an "AS IS" BASIS,</span></div><div class="line"><span class="comment"># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span></div><div class="line"><span class="comment"># See the License for the specific language governing permissions and</span></div><div class="line"><span class="comment"># limitations under the License.</span></div><div class="line"><span class="comment"># see kafka.server.KafkaConfig for additional details and defaults</span></div><div class="line"></div><div class="line"><span class="comment">############################# Server Basics #############################</span></div><div class="line"></div><div class="line"><span class="comment"># The id of the broker. This must be set to a unique integer for each broker.</span></div><div class="line">broker.id=1    <span class="comment">#broker的标识，id为正数，kafka集群内不能重复，推荐用ip地址设置</span></div><div class="line"></div><div class="line"><span class="comment">############################# Socket Server Settings #############################</span></div><div class="line"></div><div class="line"><span class="comment"># The port the socket server listens on</span></div><div class="line">port=9092     <span class="comment">#侦听的相应端口，Producer或Consumer在此端口建立连接</span></div><div class="line"></div><div class="line"><span class="comment"># Hostname the broker will bind to. If not set, the server will bind to all interfaces</span></div><div class="line">host.name=192.168.80.1     <span class="comment">#指定broke绑定的网络接口地址</span></div><div class="line"></div><div class="line"><span class="comment"># Hostname the broker will advertise to producers and consumers. If not set, it uses the</span></div><div class="line"><span class="comment"># value for "host.name" if configured. Otherwise, it will use the value returned from</span></div><div class="line"><span class="comment"># java.net.InetAddress.getCanonicalHostName().</span></div><div class="line"><span class="comment">#advertised.host.name=&lt;hostname routable by clients&gt;</span></div><div class="line"></div><div class="line"><span class="comment"># The port to publish to ZooKeeper for clients to use. If this is not set,</span></div><div class="line"><span class="comment"># it will publish the same port that the broker binds to.</span></div><div class="line"><span class="comment">#advertised.port=&lt;port accessible by clients&gt;</span></div><div class="line"></div><div class="line"><span class="comment"># The number of threads handling network requests</span></div><div class="line">num.network.threads=2 <span class="comment">#处理网络请求的线程数</span></div><div class="line"></div><div class="line"><span class="comment"># The number of threads doing disk I/O</span></div><div class="line">num.io.threads=8 <span class="comment">#磁盘读写的线程数</span></div><div class="line"></div><div class="line"><span class="comment"># The send buffer (SO_SNDBUF) used by the socket server</span></div><div class="line">socket.send.buffer.bytes=1048576 <span class="comment">#节点端口使用的发送缓存大小</span></div><div class="line"></div><div class="line"><span class="comment"># The receive buffer (SO_RCVBUF) used by the socket server</span></div><div class="line">socket.receive.buffer.bytes=1048576 <span class="comment">#节点端口使用的接收缓存大小</span></div><div class="line"></div><div class="line"><span class="comment"># The maximum size of a request that the socket server will accept (protection against OOM)</span></div><div class="line">socket.request.max.bytes=104857600 <span class="comment">#节点端口能接收一个请求的最大大小</span></div><div class="line"></div><div class="line"></div><div class="line"><span class="comment">############################# Log Basics #############################</span></div><div class="line"></div><div class="line"><span class="comment"># A comma seperated list of directories under which to store log files</span></div><div class="line"></div><div class="line">log.dirs=/tmp/kafka-logs,/hdfs/data1/tmp/kafka-logs    <span class="comment">#日志文件保存的目录，一台broker上可以设置多个</span></div><div class="line"></div><div class="line"><span class="comment"># The default number of log partitions per topic. More partitions allow greater</span></div><div class="line"><span class="comment"># parallelism for consumption, but this will also result in more files across</span></div><div class="line"><span class="comment"># the brokers.</span></div><div class="line">num.partitions=2     <span class="comment">#此值越大将导致各个Server上同步时需要的延迟越高</span></div><div class="line"></div><div class="line"><span class="comment">############################# Log Flush Policy #############################</span></div><div class="line"></div><div class="line"><span class="comment"># Messages are immediately written to the filesystem but by default we only fsync() to sync</span></div><div class="line"><span class="comment"># the OS cache lazily. The following configurations control the flush of data to disk.</span></div><div class="line"><span class="comment"># There are a few important trade-offs here:</span></div><div class="line"><span class="comment"># 1. Durability: Unflushed data may be lost if you are not using replication.</span></div><div class="line"><span class="comment"># 2. Latency: Very large flush intervals may lead to latency spikes when the flush does occur as there will be a lot of data to flush.</span></div><div class="line"><span class="comment"># 3. Throughput: The flush is generally the most expensive operation, and a small flush interval may lead to exceessive seeks.</span></div><div class="line"><span class="comment"># The settings below allow one to configure the flush policy to flush data after a period of time or</span></div><div class="line"><span class="comment"># every N messages (or both). This can be done globally and overridden on a per-topic basis.</span></div><div class="line"></div><div class="line"><span class="comment"># The number of messages to accept before forcing a flush of data to disk</span></div><div class="line"><span class="comment">#log.flush.interval.messages=10000     #partition的buffer中，message达到阈值时，将flush到磁盘</span></div><div class="line"></div><div class="line"><span class="comment"># The maximum amount of time a message can sit in a log before we force a flush</span></div><div class="line"><span class="comment">#log.flush.interval.ms=1000</span></div><div class="line"></div><div class="line"><span class="comment">############################# Log Retention Policy #############################</span></div><div class="line"></div><div class="line"><span class="comment"># The following configurations control the disposal of log segments. The policy can</span></div><div class="line"><span class="comment"># be set to delete segments after a period of time, or after a given size has accumulated.</span></div><div class="line"><span class="comment"># A segment will be deleted whenever *either* of these criteria are met. Deletion always happens</span></div><div class="line"><span class="comment"># from the end of the log.</span></div><div class="line"></div><div class="line"><span class="comment"># The minimum age of a log file to be eligible for deletion</span></div><div class="line">log.retention.hours=168 <span class="comment">#信息保存时间</span></div><div class="line"></div><div class="line"><span class="comment"># A size-based retention policy for logs. Segments are pruned from the log as long as the remaining</span></div><div class="line"><span class="comment"># segments don't drop below log.retention.bytes.</span></div><div class="line"><span class="comment">#log.retention.bytes=1073741824 #logs目录下保存信息的最大大小</span></div><div class="line"></div><div class="line"><span class="comment"># The maximum size of a log segment file. When this size is reached a new log segment will be created.</span></div><div class="line">log.segment.bytes=536870912 <span class="comment">#保存的一个segment file的大小</span></div><div class="line"></div><div class="line"><span class="comment"># The interval at which log segments are checked to see if they can be deleted according</span></div><div class="line"><span class="comment"># to the retention policies</span></div><div class="line">log.retention.check.interval.ms=60000</div><div class="line"></div><div class="line"><span class="comment"># By default the log cleaner is disabled and the log retention policy will default to just delete segments after their retention expires.</span></div><div class="line"><span class="comment"># If log.cleaner.enable=true is set the cleaner will be enabled and individual logs can then be marked for log compaction.</span></div><div class="line">log.cleaner.enable=<span class="literal">false</span></div><div class="line"></div><div class="line"><span class="comment">############################# Zookeeper #############################</span></div><div class="line"></div><div class="line"><span class="comment"># Zookeeper connection string (see zookeeper docs for details).</span></div><div class="line"><span class="comment"># This is a comma separated host:port pairs, each corresponding to a zk</span></div><div class="line"><span class="comment"># server. e.g. "127.0.0.1:3000,127.0.0.1:3001,127.0.0.1:3002".</span></div><div class="line"><span class="comment"># You can also append an optional chroot string to the urls to specify the</span></div><div class="line"><span class="comment"># root directory for all kafka znodes.</span></div><div class="line">zookeeper.connect=192.168.80.1:2181,192.168.80.2:2181,192.168.80.3:2181     <span class="comment">#连接的zookeeper对应的IP和端口</span></div><div class="line"></div><div class="line"><span class="comment"># Timeout in ms for connecting to zookeeper</span></div><div class="line">zookeeper.connection.timeout.ms=1000000</div></pre></td></tr></table></figure>
<p>配置好以上信息之后，单个节点的kafka环境也就配置好了，同样的我们在其他节点也这样安装配置即可。</p>
<p>最后，再补充一点，经过我之前对kafka速度的测试，发现这上面<code>Socket Server Settings</code>下的几个参数对于速度的提升比较重要（<a href="http://kafka.apache.org/documentation.html#brokerconfigs" target="_blank" rel="external">brokerconfigs</a>），根据服务器的配置情况，可以适当增大一些参数，比如我用的集群可以设置为下面这样：</p>
<ul>
<li><code>num.network.threads</code>:20</li>
<li><code>num.io.threads</code>:8</li>
<li><code>socket.send.buffer.bytes</code>:1048576</li>
<li><code>socket.receive.buffer.bytes</code>:1073741824</li>
<li><code>socket.request.max.buytes</code>:1073741824</li>
</ul>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[收藏的一些不错的网站]]></title>
      <url>http://matt33.com/2015/11/12/WebsiteCollect/</url>
      <content type="html"><![CDATA[<p>这篇主要是整理一下自己书签里收藏一些个人感觉不错的网站，它们大都是一些比较小众的网站，因为是技术出身，推荐的很大一部分网站可能都是偏技术类的，这点希望大家能够理解～。</p>
<h1 id="在线教育"><a href="#在线教育" class="headerlink" title="在线教育"></a>在线教育</h1><p>主要是推荐一些我自己用过的，感觉对自己比较有帮助的一些网站，当然免费是最好的了。</p>
<ul>
<li><a href="https://www.coursera.org/" target="_blank" rel="external">Coursera</a>，大名鼎鼎的 Coursera；</li>
<li><a href="https://www.shiyanlou.com/courses/" target="_blank" rel="external">实验楼</a>，这个感觉非常不错，尤其是学习一些技术的基础课程很nice；</li>
<li><a href="http://mooc.guokr.com/" target="_blank" rel="external">MOOC学院</a>，果壳的MOOC学院，课程种类和数量很多，对于想学习国外课程的童鞋来说，简直是福利啊；</li>
<li><a href="http://www.jikexueyuan.com/" target="_blank" rel="external">极客学院</a>，这种类型的网站就有很多了，比如：小象学院等，名气也比较大而且它们的模式基本上也一样，就不再推荐别的了；</li>
<li><a href="http://www.julyedu.com/" target="_blank" rel="external">七月算法</a>，July的公司，不说其它的，他的博客对于找工作还是很有帮助的；</li>
<li><a href="http://www.yiihuu.com/" target="_blank" rel="external">翼虎网</a>，一家关于做创意方面的教学网站；</li>
<li><a href="http://yun.lu/student/homepage" target="_blank" rel="external">云路-在线课堂</a>，目前关于看到课程主要是关于编程以及会计方面，有很大一部分是免费课程；</li>
</ul>
<h1 id="视频及节目"><a href="#视频及节目" class="headerlink" title="视频及节目"></a>视频及节目</h1><p>这些视频的内容比较广泛，应该会涉及到方方面面，都是些很不错的节目，看完也会给人很多的感触。</p>
<ul>
<li><a href="https://www.ted.com/" target="_blank" rel="external">TED</a>，这个大家应该都知道；</li>
<li><a href="http://yixi.tv/" target="_blank" rel="external">一席</a>，这个就是中国版的TED，也是在我看到了方励那个讲座之后才听说的；</li>
<li><a href="http://www.soku.com/search_video/q_%E6%99%93%E6%9D%BE%E5%A5%87%E8%B0%88?f=1&amp;kb=04126020kv41000__%E6%99%93%E6%9D%BE%E5%A5%87%E8%B0%AD&amp;_rp=1447420045800KOVWIn&amp;_rp=1447420045800KOVWIn" target="_blank" rel="external">晓松奇谈</a>，高晓松的一些节目（奇葩说）质量都挺不错，没事的时候可以看一下，也可以弄成音频跑步的时候听听；</li>
<li><a href="http://v.youku.com/v_show/id_XMTM4NDM1ODM3Ng==.html" target="_blank" rel="external">罗辑思维</a>，当然也有很多人并不推荐这个节目，说有些地方根本没有任何逻辑性，可是我个人感觉这个节目还是不错的，可能因为我读书比较少的原因，这个节目确实也弥补了我很多知识的空白；</li>
<li><a href="http://www.iqiyi.com/a_19rrhadzit.html" target="_blank" rel="external">奇葩说</a>，一个网上辩论节目，个人感觉很不错的一个节目，尤其是对于接受了国内那么多年应试教育的童鞋而言，对于一个问题它能让你看到不一样的视角，而不是只有一个正确答案；</li>
</ul>
<h1 id="技术网站"><a href="#技术网站" class="headerlink" title="技术网站"></a>技术网站</h1><p>这类网站都是互联网技术类方面的，内容比较多而且大都是偏基础性的资料，很多都是一些基础知识文档，对于不熟悉某方面但又希望去了解的人还是很不错的选择。</p>
<ul>
<li><a href="http://www.w3school.com.cn/" target="_blank" rel="external">w3school</a>，这个大都是前端方面的，很多技术文档，偏基础；</li>
<li><a href="http://www.runoob.com/" target="_blank" rel="external">菜鸟教程</a>，不仅仅涉及前端，大都也是些基础类的文档；</li>
<li><a href="http://www.yiibai.com/" target="_blank" rel="external">易百教程</a>，大都也是些基础类的文档；</li>
<li><a href="http://www.kancloud.cn/explore" target="_blank" rel="external">看云</a>，最近才发现网站，资料还挺多的，很多都是新型技术，这个网站相当于是把那些厚厚技术类书籍提炼一下，出了一本精简版的，对于我这种不喜欢看厚书的人来说简直是福利；</li>
<li><a href="http://lxw1234.com/" target="_blank" rel="external">lxw的大数据田地</a>，这个专门针对于大数据技术学习的网站；</li>
<li><a href="http://toutiao.io/" target="_blank" rel="external">开发者头条</a>，这里面的文章质量还是蛮高的；</li>
<li><a href="http://ifeve.com/" target="_blank" rel="external">并发编程网</a>，很好的网站；</li>
<li><a href="http://wiki.jikexueyuan.com/#all-project" target="_blank" rel="external">极客学院的WIKI</a>，有很多的技术学习文档；</li>
<li><a href="http://www.slideshare.net/" target="_blank" rel="external">slideshare</a>，这个是的PPT分享的网站，主要是偏技术类，一般一些国际会议或者一些公司技术分享的PPT都会在这上面向大家分享；</li>
</ul>
<h2 id="技术博客"><a href="#技术博客" class="headerlink" title="技术博客"></a>技术博客</h2><p>一些公司或个人的博客：</p>
<ul>
<li><a href="http://dongxicheng.org/" target="_blank" rel="external">董的博客</a>，偏大数据这一块，业内挺出名的；</li>
<li><a href="http://colobu.com/archives/" target="_blank" rel="external">鸟窝</a>，这个博客的质量还不挺不错的；</li>
<li><a href="http://www.ruanyifeng.com/blog/" target="_blank" rel="external">阮一峰的网络日志</a>，很适合入门者，博客言简意骇；</li>
<li><a href="http://www.ibm.com/developerworks/cn/topics/" target="_blank" rel="external">IBM博客</a>，IBM的官方博客，质量很高，推荐；</li>
<li><a href="http://tech.meituan.com/" target="_blank" rel="external">美团技术团队博客</a>，涉及到了很多大数据方面的架构和设计;</li>
<li><a href="http://jm.taobao.org/" target="_blank" rel="external">阿里巴巴中间件博客</a>，有很多关于阿里消息中间件RocketMQ的一些内容，以及其它的一些分布式技术；</li>
<li><a href="https://code.facebook.com/" target="_blank" rel="external">Code Facebook</a>，里面有很多前沿的内容，不过需要 fq；</li>
<li><a href="http://mogu.io/" target="_blank" rel="external">蘑菇街的技术博客</a>，里面的文章比较接地气；</li>
<li><a href="http://data.qq.com/blog" target="_blank" rel="external">腾讯大数据-博客</a>，关于腾讯大数据的官网博客网站；</li>
<li><a href="https://engineering.linkedin.com/blog" target="_blank" rel="external">LinkedIn Blog</a>，LinkedIn 的一些博客；</li>
</ul>
<h1 id="旅行"><a href="#旅行" class="headerlink" title="旅行"></a>旅行</h1><ul>
<li><a href="http://www.clctrip.com/" target="_blank" rel="external">草履虫旅行</a>，这个俱乐部，每周都会有一些短途的旅行，假期会有远途旅行，不过这个活动出发地仅仅局限在北京，其他城市还没有涉足，真心很赞的一个俱乐部；</li>
<li><a href="http://www.yerenbang.org/forum.php" target="_blank" rel="external">野人帮</a>，这个主要是对准户外过夜那种，比较有挑战性；</li>
<li><a href="http://www.iqingyi.com/" target="_blank" rel="external">青驿</a>，看别人推荐，还没有用过，感觉还不错。</li>
</ul>
<h1 id="媒体内容类"><a href="#媒体内容类" class="headerlink" title="媒体内容类"></a>媒体内容类</h1><ul>
<li><a href="http://36kr.com/" target="_blank" rel="external">36氪</a>，第一个肯定要推荐36氪，毕竟创始人是我们校友，主要是一些关于互联网圈内发生的一些事情，也经常会介绍一些国内外新兴的互联网创业公司；</li>
<li><a href="http://www.jianshu.com/" target="_blank" rel="external">简书</a>，可以使用Markdown写文章，大家通过文章来交流一些想法；</li>
<li><a href="http://dataunion.org/" target="_blank" rel="external">数盟</a>，暂时把它归于媒体类吧，偏程序员的媒体网站。</li>
</ul>
<h1 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h1><p>一些挺有用的小网站</p>
<ul>
<li><a href="http://www.zimuku.net/" target="_blank" rel="external">字幕库</a>，美剧迷的福利；</li>
<li><a href="http://www.haitou.cc/" target="_blank" rel="external">海投网</a>，可查看高校工作宣讲会；</li>
<li><a href="https://www.zybuluo.com/" target="_blank" rel="external">作业部落</a>，Markdown的在线编辑器；</li>
<li><a href="https://selfstore.io/" target="_blank" rel="external">selfstore</a>，专门由专业人士翻译国外技术书籍，然后买电子书的网站，当然，它们的翻译质量确实比某些出版社高太多了；</li>
<li><a href="http://www.meetup.com/" target="_blank" rel="external">Meetup</a>，通过Meetup可以组织一些专业的线下活动，像Spark这种线下技术分享活动都会在这上面发布；</li>
<li><a href="http://www.zhibimo.com/explore/books" target="_blank" rel="external">李笑来-个人网站</a>，李笑来书籍的一些网络公开版；</li>
</ul>
<blockquote>
<p>注：本文为会一直保持更新，只要遇到一些比较优秀的网站，都会更新到这篇博客上。</p>
</blockquote>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[Java的几个基本类型之间的相互转换]]></title>
      <url>http://matt33.com/2015/10/27/TheTransformOfJava/</url>
      <content type="html"><![CDATA[<p>之前在写java程序的时候，经常会遇到很多的需要需要转换基础数据类型的情况，然后我就一直去记录这些情况，今天做了一下总结，当然转换的方法肯定不止我写的这些，有的我可能只会写其中的一种，以后再遇到其他的情况的话，我会慢慢来补充，希望这篇文章会对大家能有所帮助。</p>
<hr>
<h1 id="String的转换"><a href="#String的转换" class="headerlink" title="String的转换"></a>String的转换</h1><p>首先介绍一下String类型的转换，一般遇到的情况可能会有以下几种：Strng转int，String转long，String转byte数组，String转float，下面主要介绍这四种情况。</p>
<h2 id="String转int"><a href="#String转int" class="headerlink" title="String转int"></a>String转int</h2><p>把String类型转换为int类型，常用的有以下三种方法：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">StringToInt</span> </span>&#123;</div><div class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</div><div class="line">		String number = <span class="string">"123456"</span>;</div><div class="line">		<span class="keyword">int</span> num1 = Integer.parseInt(number);<span class="comment">//使用Integer的parseInt方法</span></div><div class="line">		<span class="keyword">int</span> num2 = <span class="keyword">new</span> Integer(number);<span class="comment">//强制转换</span></div><div class="line">		<span class="keyword">int</span> num3 = Integer.valueOf(number).intValue();<span class="comment">//先转Integer类型，再调用intValue()转为int</span></div><div class="line">	&#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h2 id="String转long"><a href="#String转long" class="headerlink" title="String转long"></a>String转long</h2><p>把String类型转换为long类型的方法跟上面的方法类似。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">StringToLong</span> </span>&#123;</div><div class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</div><div class="line">		String number = <span class="string">"1234567890"</span>;</div><div class="line">		<span class="keyword">long</span> num1 = Long.parseLong(number);<span class="comment">//调用Long类型的parseLong方法</span></div><div class="line">		<span class="keyword">long</span> num2 = <span class="keyword">new</span> Long(number);<span class="comment">//强制转换</span></div><div class="line">		<span class="keyword">long</span> num3 = Long.valueOf(number).longValue();<span class="comment">//先转换Long类型，再使用longValue方法转为long</span></div><div class="line">	&#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h2 id="String转float"><a href="#String转float" class="headerlink" title="String转float"></a>String转float</h2><p>把String类型转换为float类型的方法也跟上面的类似。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">StringToFloat</span> </span>&#123;</div><div class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</div><div class="line">		String number = <span class="string">"1234.202"</span>;</div><div class="line">		<span class="keyword">float</span> num1 = Float.parseFloat(number);<span class="comment">//调用Float的parseFloat方法</span></div><div class="line">		<span class="keyword">float</span> num2 = <span class="keyword">new</span> Float(number);<span class="comment">//强制转换</span></div><div class="line">		<span class="keyword">float</span> num3 = Float.valueOf(number).floatValue();<span class="comment">//先转为Float类型再使用floatValue转为float</span></div><div class="line">	&#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h2 id="String转byte"><a href="#String转byte" class="headerlink" title="String转byte[]"></a>String转byte[]</h2><p>String类型转byte数组方法一般使用String类自带的<code>getBytes()</code>方法。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">StringToByte</span> </span>&#123;</div><div class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</div><div class="line">		<span class="keyword">byte</span>[] num = <span class="keyword">new</span> <span class="keyword">byte</span>[<span class="number">200</span>];</div><div class="line">		String number = <span class="string">"1234567890"</span>;</div><div class="line">		num = number.getBytes();</div><div class="line">	&#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>这里补充一个path类型转换为String类型的方法：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">String fileName=path.getFileName().toString();</div></pre></td></tr></table></figure>
<hr>
<h1 id="long类型转换"><a href="#long类型转换" class="headerlink" title="long类型转换"></a>long类型转换</h1><p>long类型的转换，这一部分用的情况也很多，下面介绍几种常见的情况。</p>
<h2 id="long转String"><a href="#long转String" class="headerlink" title="long转String"></a>long转String</h2><p>long类型转String类型，这里主要介绍三种方法：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">LongToString</span> </span>&#123;</div><div class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</div><div class="line">		<span class="keyword">long</span> number = <span class="number">1234567890l</span>;</div><div class="line">		String num1 = Long.toString(number);<span class="comment">//Long的tostring方法</span></div><div class="line">		String num2 = String.valueOf(number);<span class="comment">//使用String的valueOf方法</span></div><div class="line">		String num3 = <span class="string">""</span> + number;<span class="comment">//这个应该属于强制转换吧</span></div><div class="line">	&#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h2 id="long转int"><a href="#long转int" class="headerlink" title="long转int"></a>long转int</h2><p>long类型转换为int类型，这里也主要介绍三种方法：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">LongToInt</span> </span>&#123;</div><div class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</div><div class="line">		<span class="keyword">long</span> number = <span class="number">121121121l</span>;</div><div class="line">		<span class="keyword">int</span> num1 = (<span class="keyword">int</span>) number;<span class="comment">// 强制类型转换</span></div><div class="line">		<span class="keyword">int</span> num2 = <span class="keyword">new</span> Long(number).intValue();<span class="comment">// 调用intValue方法</span></div><div class="line">		<span class="keyword">int</span> num3 = Integer.parseInt(String.valueOf(number));<span class="comment">// 先把long转换位字符串String，然后转换为Integer</span></div><div class="line">	&#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h2 id="long与byte数组的相互转换"><a href="#long与byte数组的相互转换" class="headerlink" title="long与byte数组的相互转换"></a>long与byte数组的相互转换</h2><p>一直都感觉byte数组转换比较繁琐，这里也不再叙述，我就给出一篇别人的博客让大家作为参考吧，这里面byte数组与多种数据类型的转换——<a href="http://blog.csdn.net/cshichao/article/details/9813973" target="_blank" rel="external"> java Byte和各数据类型(short,int,long,float,double)之间的转换</a></p>
<hr>
<h1 id="int类型的转换"><a href="#int类型的转换" class="headerlink" title="int类型的转换"></a>int类型的转换</h1><p>int类型的转换也是我们经常使用的情况，下面也主要介绍几种常见的情况。</p>
<h2 id="int转String"><a href="#int转String" class="headerlink" title="int转String"></a>int转String</h2><p>int类型转换为String类型与long转String的类似，一般也有以下三种方法。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">IntToString</span> </span>&#123;</div><div class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</div><div class="line">		<span class="keyword">int</span> number = <span class="number">121121</span>;</div><div class="line">		String num1 = Integer.toString(number);<span class="comment">//使用Integer的toString方法</span></div><div class="line">		String num2 = String.valueOf(number);<span class="comment">//使用String的valueOf方法</span></div><div class="line">		String num3 = <span class="string">""</span> + number;<span class="comment">//也是强制转换吧</span></div><div class="line">	&#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h2 id="int与Byte的相互转换"><a href="#int与Byte的相互转换" class="headerlink" title="int与Byte的相互转换"></a>int与Byte的相互转换</h2><p>关于int类型与byte[]数组的转换，一般情况下，我们使用条件都是在这里转换过来，在另外一个地方就要转换回来，这里介绍两种int与byte数组互相转换的方式。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//int类型转换为byte[]数组</span></div><div class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">byte</span>[] intToByteArray(<span class="keyword">int</span> i) &#123;</div><div class="line">	<span class="keyword">byte</span>[] result = <span class="keyword">new</span> <span class="keyword">byte</span>[<span class="number">4</span>];</div><div class="line">	<span class="comment">// 由高位到低位</span></div><div class="line">	result[<span class="number">0</span>] = (<span class="keyword">byte</span>) ((i &gt;&gt; <span class="number">24</span>) &amp; <span class="number">0xFF</span>);</div><div class="line">	result[<span class="number">1</span>] = (<span class="keyword">byte</span>) ((i &gt;&gt; <span class="number">16</span>) &amp; <span class="number">0xFF</span>);</div><div class="line">	result[<span class="number">2</span>] = (<span class="keyword">byte</span>) ((i &gt;&gt; <span class="number">8</span>) &amp; <span class="number">0xFF</span>);</div><div class="line">	result[<span class="number">3</span>] = (<span class="keyword">byte</span>) (i &amp; <span class="number">0xFF</span>);</div><div class="line">	<span class="keyword">return</span> result;</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="comment">//byte数组转换为int类型</span></div><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">int</span> <span class="title">byteArrayToInt</span><span class="params">(<span class="keyword">byte</span>[] bytes)</span> </span>&#123;</div><div class="line">	<span class="keyword">int</span> value = <span class="number">0</span>;</div><div class="line">	<span class="comment">// 由高位到低位</span></div><div class="line">	<span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">4</span>; i++) &#123;</div><div class="line">		<span class="keyword">int</span> shift = (<span class="number">4</span> - <span class="number">1</span> - i) * <span class="number">8</span>;</div><div class="line">		value += (bytes[i] &amp; <span class="number">0x000000FF</span>) &lt;&lt; shift;<span class="comment">// 往高位游</span></div><div class="line">	&#125;</div><div class="line">	<span class="keyword">return</span> value;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>还有一种为：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//int类型转换为byte[]数组</span></div><div class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">byte</span>[] intToByteArray(<span class="keyword">int</span> x) &#123;</div><div class="line">	<span class="keyword">byte</span>[] bb = <span class="keyword">new</span> <span class="keyword">byte</span>[<span class="number">4</span>];</div><div class="line">	bb[<span class="number">3</span>] = (<span class="keyword">byte</span>) (x &gt;&gt; <span class="number">24</span>);</div><div class="line">	bb[<span class="number">2</span>] = (<span class="keyword">byte</span>) (x &gt;&gt; <span class="number">16</span>);</div><div class="line">	bb[<span class="number">1</span>] = (<span class="keyword">byte</span>) (x &gt;&gt; <span class="number">8</span>);</div><div class="line">	bb[<span class="number">0</span>] = (<span class="keyword">byte</span>) (x &gt;&gt; <span class="number">0</span>);</div><div class="line">	<span class="keyword">return</span> bb;</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="comment">//byte数组转换为int类型</span></div><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">int</span> <span class="title">byteArrayToInt</span><span class="params">(<span class="keyword">byte</span>[] bb)</span> </span>&#123;</div><div class="line">	<span class="keyword">return</span> (<span class="keyword">int</span>) ((((bb[<span class="number">3</span>] &amp; <span class="number">0xff</span>) &lt;&lt; <span class="number">24</span>) | ((bb[<span class="number">2</span>] &amp; <span class="number">0xff</span>) &lt;&lt; <span class="number">16</span>) | ((bb[<span class="number">1</span>] &amp; <span class="number">0xff</span>) &lt;&lt; <span class="number">8</span>) | ((bb[<span class="number">0</span>] &amp; <span class="number">0xff</span>) &lt;&lt; <span class="number">0</span>)));</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h2 id="int转long"><a href="#int转long" class="headerlink" title="int转long"></a>int转long</h2><p>int类型转换为long类型的情况并不是大多，这里主要接收几种转换方法：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">IntToLong</span> </span>&#123;</div><div class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</div><div class="line">		<span class="keyword">int</span> number = <span class="number">123111</span>;</div><div class="line">		<span class="keyword">long</span> num1 = (<span class="keyword">long</span>) number;<span class="comment">//强制</span></div><div class="line">		<span class="keyword">long</span> num2 = Long.parseLong(<span class="keyword">new</span> Integer(number).toString());<span class="comment">//先转String再进行转换</span></div><div class="line">		<span class="keyword">long</span> num3 = Long.valueOf(number);</div><div class="line">	&#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h2 id="int转Interger"><a href="#int转Interger" class="headerlink" title="int转Interger"></a>int转Interger</h2><p>int类型转换为Interger类型的情况，我是基本上每怎么遇到过，在这里也上网查询一些资料找到了两种方法。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">IntToInterge</span> </span>&#123;</div><div class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</div><div class="line">		<span class="keyword">int</span> number = <span class="number">123456</span>;</div><div class="line">		Integer num1 = Integer.valueOf(number);</div><div class="line">		Integer num2 = <span class="keyword">new</span> Integer(number);</div><div class="line">	&#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<hr>
<h1 id="byte数组的转换"><a href="#byte数组的转换" class="headerlink" title="byte数组的转换"></a>byte数组的转换</h1><p>关于byte数组的转换，上面有几个都是它们只见相互转换的，所以这里就不再介绍那么多，只介绍一个byte数组转换String类型的方法，其他的类型可以通过String类型再进行转换。</p>
<p>byte数组转String类型的方法经常用的可能就是下面这种方法。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ByteToString</span> </span>&#123;</div><div class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</div><div class="line">		<span class="keyword">byte</span>[] number = <span class="string">"121121"</span>.getBytes();</div><div class="line">		String num1 = <span class="keyword">new</span> String(number);</div><div class="line">	&#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<hr>
<p>最后简单补充以下Java基本数据类型的一些知识：</p>
<table>
<thead>
<tr>
<th>类型</th>
<th>字节数</th>
<th>类名称</th>
<th>范围</th>
</tr>
</thead>
<tbody>
<tr>
<td>int</td>
<td>4字节</td>
<td>Interger</td>
<td>-2147483648 ~ 2147483647</td>
</tr>
<tr>
<td>short</td>
<td>2字节</td>
<td>Short</td>
<td>-32768 ～ 32767</td>
</tr>
<tr>
<td>long</td>
<td>8字节</td>
<td>Long</td>
<td>-9223372036854775808 ～ 9223372036854775807</td>
</tr>
<tr>
<td>byte</td>
<td>1字节</td>
<td>Byte</td>
<td>-128 ～ 127</td>
</tr>
<tr>
<td>float</td>
<td>4字节</td>
<td>Float</td>
<td></td>
</tr>
<tr>
<td>double</td>
<td>8字节</td>
<td>Double</td>
</tr>
</tbody>
</table>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[Java关键字之final和static]]></title>
      <url>http://matt33.com/2015/10/17/The-keyword-of-java/</url>
      <content type="html"><![CDATA[<p>本篇文章主要对java中经常使用<code>final</code>和<code>static</code>两个关键字的用法做一下总结，主要参考了《Java编程思想》和网上的一些博客。</p>
<h1 id="final"><a href="#final" class="headerlink" title="final"></a>final</h1><p>final应该是程序中经常使用的关键字之一，final关键字使用的对象是：类、方法、变量，下面依次介绍这几种使用final的情况。</p>
<h2 id="final类"><a href="#final类" class="headerlink" title="final类"></a>final类</h2><p>当一个类声明为final类，也就证明这个类是不能够被继承的，即禁止继承，因此final类的成员方法是没有机会被覆盖的，这个final类的功能是完整的。在Java中有很多类是final的，如String、Interger以及其他包装类。</p>
<p>final类的好处：</p>
<ul>
<li>不可变类有很多的好处，它们的对象是只读的，可以在多线程环境下安全的共享，不用额外的开销。</li>
</ul>
<p>下面是final类的实例：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">final</span> <span class="class"><span class="keyword">class</span> <span class="title">PersonalLoan</span></span>&#123;</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">CheapPersonalLoan</span> <span class="keyword">extends</span> <span class="title">PersonalLoan</span></span>&#123; <span class="comment">//compilation error: cannot inherit from final class</span></div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h2 id="final方法"><a href="#final方法" class="headerlink" title="final方法"></a>final方法</h2><p>如果一个类不允许其子类覆盖某个方法，即不能被重写，则可以把这个方法声明为final方法。（类中所有的private方法都隐式的指定为final）。</p>
<p>使用final方法的原因：</p>
<ul>
<li>方法锁定，防止任何继承类修改它的含义，确保在继承中使方法行为保持不变且不被覆盖；</li>
<li>效率，将一个方法指明为final，就是同意编译器将针对该方法的所有调用都转化为内嵌调用（相当于在编译的时候已经静态绑定，不需要在运行时再动态绑定）。</li>
</ul>
<p>下面是final方法的实例：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Test1</span> </span>&#123;</div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</div><div class="line">    &#125;</div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">f1</span><span class="params">()</span> </span>&#123;</div><div class="line">        System.out.println(<span class="string">"f1"</span>);</div><div class="line">    &#125;</div><div class="line">    <span class="comment">//final方法</span></div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">final</span> <span class="keyword">void</span> <span class="title">f2</span><span class="params">()</span> </span>&#123;</div><div class="line">        System.out.println(<span class="string">"f2"</span>);</div><div class="line">    &#125;</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Test2</span> <span class="keyword">extends</span> <span class="title">Test1</span> </span>&#123;</div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">f1</span><span class="params">()</span></span>&#123;     </div><div class="line">        System.out.println(<span class="string">"Test1父类方法f1被覆盖!"</span>);</div><div class="line">    &#125;</div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</div><div class="line">        Test2 t=<span class="keyword">new</span> Test2();</div><div class="line">        t.f1(); <span class="comment">//子类重写父类的方法</span></div><div class="line">        t.f2(); <span class="comment">//调用从父类继承过来的final方法</span></div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h2 id="final变量"><a href="#final变量" class="headerlink" title="final变量"></a>final变量</h2><p>程序中有些数据的恒定不变是很有必要的，比如：</p>
<ul>
<li>一个永不改变的<strong>编译时常量</strong>；</li>
<li>一个在运行时被初始化的值，而在程序的后面不希望它被改变。</li>
</ul>
<p>这种类型的变量只能被赋值一次，一旦被赋值之后，就不能够再更改了。</p>
<p>有几点要注意的：</p>
<ul>
<li>一个既是static又是final的域只占据一段不能改变的存储空间，一般用大写来表示；</li>
<li>final使数值恒定不变，而当用于对象时，final使引用恒定不变（一旦引用指向一个对象，就无法再把它改为指向另一个对象）；</li>
</ul>
<p>final变量的好处：</p>
<ul>
<li>提高性能，JVM和Java应用程序都会缓存final变量；</li>
<li>final变量可以在安全的在多线程环境下进行共享，而不需要额外的开销。</li>
</ul>
<p>下面是final类的实例：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Test</span> </span>&#123;</div><div class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> PI = <span class="number">3.14</span>;<span class="comment">//这个变量是只读的</span></div><div class="line">    <span class="keyword">public</span> <span class="keyword">final</span> <span class="keyword">int</span> INIT; <span class="comment">//final空白,必须在初始化对象的时候赋初值</span></div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="title">Test</span><span class="params">(<span class="keyword">int</span> x)</span> </span>&#123;</div><div class="line">        INIT = x;</div><div class="line">    &#125;</div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</div><div class="line">        Test t = <span class="keyword">new</span> Test(<span class="number">2</span>);</div><div class="line">        <span class="comment">//t.PI=3.1415;//出错,final变量的值一旦给定就无法改变</span></div><div class="line">        System.out.println(t.INIT);</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>final数据还有另外三个比较特殊的情况：与static合用，空白final和final参数。</p>
<h3 id="static-final"><a href="#static-final" class="headerlink" title="static final"></a>static final</h3><p>一个既是static又是final的域只占据一段不能改变的存储空间:</p>
<ul>
<li>对于变量，它表示一旦给定就不可更改，并且可以通过类名直接访问（使用大写和下划线命名）；</li>
<li>对于方法，表示不可覆盖，并且可以通过类名直接访问。</li>
</ul>
<h3 id="空白final"><a href="#空白final" class="headerlink" title="空白final"></a>空白final</h3><p>从上面的例子中，我们就可以看到<code>空白final</code>的使用方法，它指的是：被声明为final但又未给出初值的域。无论什么情况下，编译器都确保空白final在使用前必须被初始化（在域的定义处或每个构造器中用表达式对final赋值）。</p>
<h3 id="final参数"><a href="#final参数" class="headerlink" title="final参数"></a>final参数</h3><p>Java时允许在参数列表的声明中以声明的方式将参数指明为final。</p>
<ul>
<li>当对象被指明为final时，这就意味着我们无法在方法中更改参数引用所指向的对象。</li>
<li>当基本类型的参数被指明为final时，我们可以读取参数但是无法修改参数。</li>
</ul>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>总结一下final关键字的一些重要特点：</p>
<ol>
<li>本地变量必须在声明的时候赋值；</li>
<li>在匿名类中所有变量都必须是final变量；</li>
<li>final方法不能被重写；</li>
<li>final类不能被继承；</li>
<li>final成员变量必须在声明的时候初始化或者在构造器中初始化，否则就会报编译错误；</li>
<li>接口中声明的所有变量本身是final的；</li>
<li>final方法在编译阶段绑定，称为<strong>静态绑定</strong>(static binding)；</li>
<li><strong>对于集合对象声明为final指的是引用不能被更改</strong>，但是你可以向其中增加，删除或者改变内容；</li>
</ol>
<h1 id="static关键字"><a href="#static关键字" class="headerlink" title="static关键字"></a>static关键字</h1><p>通常来说，当我们创建类时，就是在描述那个类的外观与行为。除非使用<code>new</code>创建那个类的对象，否则并为获得任何对象。执行<code>new</code>来创建对象时，数据存储空间才被分配，其方法才能被外界调用。</p>
<p>但是，试想在一种情况下，我们只想为某一特定区域分配单一存储空间，而不用去考虑它创建了多少对象。另一种情形是，希望某个方法不与包含它的类的任何对象联系在一起，也就是说，即使没有创建对象，也能够调用这个方法。这就是<code>static</code>关键字主要使用的地方。</p>
<p>static一个很重要的用途就是多个对象可以共享一些存储空间，static关键字使用的对象为：类、方法、代码块。</p>
<p>static关键字有几个需要注意的地方：</p>
<ul>
<li>被static修饰的成员变量和成员方法<strong>独立</strong>于该类的任何对象，它不依赖类的特定实例，被类的所有实例共享；</li>
<li>用public修饰的static成员变量和成员方法本质是全局变量和全局方法，当声明它类的对象市，不生成static变量的副本，而是类的所有实例<strong>共享</strong>同一个static变量；</li>
<li>static变量前可以有private修饰，这时就不能使用类名直接访问流。</li>
</ul>
<p>static修饰的成员变量和成员方法习惯上称为静态变量和静态方法，可以直接通过类名来访问，访问语法为：</p>
<ul>
<li>ClassName.Varibale</li>
<li>ClassName.method()</li>
</ul>
<h2 id="static变量"><a href="#static变量" class="headerlink" title="static变量"></a>static变量</h2><p>按照是否静态的对类成员变量进行分类可分两种：</p>
<ul>
<li>一种是被static修饰的变量，叫<strong>静态变量</strong>或<strong>类变量</strong>；</li>
<li>另一种是没有被static修饰的变量，叫<strong>实例变量</strong>。</li>
</ul>
<p>两者的区别是：</p>
<ul>
<li>对于静态变量在内存中只有一个拷贝（节省内存），JVM只为静态分配一次内存，在加载类的过程中完成静态变量的内存分配，可用类名直接访问（方便），当然也可以通过对象来访问；</li>
<li>对于实例变量，每创建一个实例，就会为实例变量分配一次内存，实例变量可以在内存中有多个拷贝，互不影响（灵活）。</li>
</ul>
<p>一般在在对象之间使用共享值和方便访问变量时，就会去使用静态变量。</p>
<p>例子如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Test</span> </span>&#123;</div><div class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">int</span> i;</div><div class="line">    <span class="keyword">int</span> j;</div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="title">Test</span><span class="params">(<span class="keyword">int</span> j)</span> </span>&#123;</div><div class="line">        <span class="keyword">this</span>.j=j;</div><div class="line">    &#125;</div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span>     </span>&#123;</div><div class="line">        System.out.println(<span class="string">"Test.i="</span> + Test.i);</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h2 id="static方法"><a href="#static方法" class="headerlink" title="static方法"></a>static方法</h2><p><strong>静态方法</strong>也叫做<strong>类方法</strong>，静态方法可以直接通过类名调用，任何的实例也都可以调用，因此静态方法中不能用<code>this</code>和<code>super</code>关键字，不能直接访问所属类的实例变量和实例方法（因为它们是与具体方法关联的），只能访问所属类的静态成员变量和成员方法。</p>
<p>因为static方法独立于任何实例，因此static方法必须被实现，而不能是抽象的abstract。</p>
<p>Java中很多使用static的方法，如Math类中所有的方法都是静态的，而一般类内部的static方法也是方便其它类对该方法的调用。</p>
<p>例子如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Test</span> </span>&#123;</div><div class="line">    <span class="function"><span class="keyword">static</span> <span class="keyword">int</span> <span class="title">sum</span><span class="params">(<span class="keyword">int</span> x, <span class="keyword">int</span> y)</span></span>&#123;</div><div class="line">        <span class="keyword">return</span> x + y;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</div><div class="line">        <span class="keyword">int</span> sum = Test.sum(<span class="number">10</span>, <span class="number">10</span>);</div><div class="line">        System.out.println(<span class="string">"10+10="</span> + sum);</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h2 id="static代码块"><a href="#static代码块" class="headerlink" title="static代码块"></a>static代码块</h2><p>static代码块也叫静态代码块，是在类中独立于类成员的static语句块，可以有多个，位置可以随便放，它不在任何的方法体内，JVM加载类时会执行这些静态的代码块，如果static代码块有多个，JVM将按照它们在类中出现的先后顺序依次执行它们，每个代码块只会被执行一次。</p>
<p>如：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Test</span> </span>&#123;</div><div class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">int</span> i;</div><div class="line">    <span class="keyword">static</span>&#123;</div><div class="line">        i = <span class="number">10</span>;</div><div class="line">        System.out.println(<span class="string">"Now in static block."</span>);</div><div class="line">    &#125;</div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">test</span><span class="params">()</span> </span>&#123;</div><div class="line">        System.out.println(<span class="string">"test method: i="</span> + i);</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</div><div class="line">        System.out.println(<span class="string">"Test.i="</span> + Test.i);</div><div class="line">        <span class="keyword">new</span> Test().test();</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h2 id="总结-1"><a href="#总结-1" class="headerlink" title="总结"></a>总结</h2><p>下面是关于静态变量和静态方法的一些总结：</p>
<ul>
<li>一个类的静态方法只能访问其静态变量；</li>
<li>一个类的静态方法不能够直接调用非静态方法；</li>
<li>静态方法中不存在当前对象，因而不能使用 this，当然也不能使用 super；</li>
<li>静态方法不能被非静态方法覆盖；</li>
<li>构造方法不允许声明为 static 的；</li>
<li>局部变量不能使用static修饰。</li>
</ul>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[Maven之仓库配置]]></title>
      <url>http://matt33.com/2015/10/14/the-setting-of-repertory-maven/</url>
      <content type="html"><![CDATA[<p>徐晓斌的《Maven实战》，实在是一本很不错的书，本文也是在我读过这本书的仓库一章后，根据自己的经验，做的一个总结。</p>
<h1 id="仓库"><a href="#仓库" class="headerlink" title="仓库"></a>仓库</h1><p>先介绍一个构件和仓库的概念。</p>
<p>构件：在Maven中，任何一个依赖、插件或者项目构建的输出，都是一个构件。如：依赖包是一个构件、编译的插件是一个构件；</p>
<p>仓库：Maven在某个位置统一存储所有Maven项目共享的构件，这个统一的位置就是仓库。</p>
<h1 id="仓库的分类"><a href="#仓库的分类" class="headerlink" title="仓库的分类"></a>仓库的分类</h1><p>对于Maven来说，仓库只有两种：本地仓库和远程仓库。但是还有一类特殊的远程仓库——私服，它是在局域网内架设的私有仓库服务器。</p>
<p><img src="/images/2015-10-14-theSettingOfRepertoryOfMaven/repertory.jpg" alt="Repertory"></p>
<h2 id="本地仓库"><a href="#本地仓库" class="headerlink" title="本地仓库"></a>本地仓库</h2><h3 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h3><p>默认情况下，不管在window还是在Linux系统上，每一个用户在自己用户目录下都有一个<code>.m2/repository/</code>的仓库目录。</p>
<p>当然，Maven是允许我们自定义本地仓库目录地址的，在Maven的安装目录的<code>conf</code>下找到<code>settings.xml</code>文件，配置如下：</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="tag">&lt;<span class="name">settings</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">localRepository</span>&gt;</span>/home/matt/maven/repo<span class="tag">&lt;/<span class="name">localRepository</span>&gt;</span></div><div class="line"><span class="tag">&lt;/<span class="name">settings</span>&gt;</span></div></pre></td></tr></table></figure>
<p>这样本地仓库就被设置在<code>/home/matt/maven/repo</code>下。</p>
<p>关于<code>settings.xml</code>文件，有一点需要注意的是：</p>
<ul>
<li><code>$M2_HOME/conf/settings.xml</code>：是全局范围的，整台机器上的所有用户都会直接受到该配置的影响；</li>
<li><code>~/.m2/settings.xml</code>：是用户范围的，只有当前用户才会受到该配置的影响（若目录下没有此文件，可将上个<code>settings.xml</code>复制一份到本目录下再去修改）。</li>
</ul>
<h3 id="本地项目安装到本地仓库"><a href="#本地项目安装到本地仓库" class="headerlink" title="本地项目安装到本地仓库"></a>本地项目安装到本地仓库</h3><p>在这个本地项目下，执行</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">mvn clwan install</div></pre></td></tr></table></figure>
<p>Install插件的install目标就是将项目的构建输出文件安装到本地仓库。</p>
<h2 id="中央仓库"><a href="#中央仓库" class="headerlink" title="中央仓库"></a>中央仓库</h2><p>最原始的本地仓库是空的，Maven的安装文件中自带了中央仓库的配置。在Maven的安装目录下的<code>/lib/maven-model-builder-XX.jar</code>的jar包中的<code>pom-4.0.0.xml</code>中有如下的配置：</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line"><span class="tag">&lt;<span class="name">repositories</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">repository</span>&gt;</span></div><div class="line">        <span class="tag">&lt;<span class="name">id</span>&gt;</span>central<span class="tag">&lt;/<span class="name">id</span>&gt;</span></div><div class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>Central Repository<span class="tag">&lt;/<span class="name">name</span>&gt;</span></div><div class="line">        <span class="tag">&lt;<span class="name">url</span>&gt;</span>https://repo.maven.apache.org/maven2<span class="tag">&lt;/<span class="name">url</span>&gt;</span></div><div class="line">        <span class="tag">&lt;<span class="name">layout</span>&gt;</span>default<span class="tag">&lt;/<span class="name">layout</span>&gt;</span></div><div class="line">        <span class="tag">&lt;<span class="name">snapshots</span>&gt;</span></div><div class="line">            <span class="tag">&lt;<span class="name">enabled</span>&gt;</span>false<span class="tag">&lt;/<span class="name">enabled</span>&gt;</span></div><div class="line">        <span class="tag">&lt;/<span class="name">snapshots</span>&gt;</span></div><div class="line">    <span class="tag">&lt;/<span class="name">repository</span>&gt;</span></div><div class="line"><span class="tag">&lt;/<span class="name">repositories</span>&gt;</span></div></pre></td></tr></table></figure>
<p>配置了默认的中央仓库，所有的Maven项目都会继承这个POM，所以都会有这个配置。该中央仓库包含了世界上绝大多数流行的开源Java构件，以及源码、作者信息、SCM、信息、许可证等。上面的<code>snapshots</code>元素的子元素<code>enabled</code>设置为<code>false</code>，表示不会从该中央仓库下载快照版本的构件。</p>
<h2 id="私服"><a href="#私服" class="headerlink" title="私服"></a>私服</h2><p>私服是架设在局域网内的仓库服务，私服代理广域网上的远程仓库，供局域网用户使用。当Maven需要下载构件的时候，他从私服请求，如果私服不存在当前构件，则从外部的远程仓库缓存到私服上之后再为Maven的下载请求提供服务，此外一些无法从外部仓库下载到的构件也可以手工上传到私服上供大家使用。</p>
<p>它主要有以下几个优点：</p>
<ul>
<li>节省外网带宽；</li>
<li>加速Maven构建；</li>
<li>部署第三方构件（尤其是组织内部的构件）；</li>
<li>提高稳定性，增强控制；</li>
<li>降低中央仓库的负荷。</li>
</ul>
<h1 id="远程仓库的配置"><a href="#远程仓库的配置" class="headerlink" title="远程仓库的配置"></a>远程仓库的配置</h1><h2 id="配置远程仓库"><a href="#配置远程仓库" class="headerlink" title="配置远程仓库"></a>配置远程仓库</h2><p>很多情况下，默认的中央仓库无法满足项目的需求，可能项目需要的构件存在于另外一个远程仓库，可以在<code>POM</code>进行配置：</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line"><span class="tag">&lt;<span class="name">repositories</span>&gt;</span></div><div class="line">	<span class="tag">&lt;<span class="name">repository</span>&gt;</span></div><div class="line">		<span class="tag">&lt;<span class="name">id</span>&gt;</span>jboss<span class="tag">&lt;/<span class="name">id</span>&gt;</span></div><div class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>JBoss Repository<span class="tag">&lt;/<span class="name">name</span>&gt;</span></div><div class="line">		<span class="tag">&lt;<span class="name">url</span>&gt;</span>http://repository.jboss.com/maven2/<span class="tag">&lt;/<span class="name">url</span>&gt;</span></div><div class="line">		<span class="tag">&lt;<span class="name">releases</span>&gt;</span></div><div class="line">			<span class="tag">&lt;<span class="name">enabled</span>&gt;</span>true<span class="tag">&lt;/<span class="name">enabled</span>&gt;</span></div><div class="line">		<span class="tag">&lt;/<span class="name">releases</span>&gt;</span></div><div class="line">		<span class="tag">&lt;<span class="name">snapshots</span>&gt;</span></div><div class="line">			<span class="tag">&lt;<span class="name">enabled</span>&gt;</span>false<span class="tag">&lt;/<span class="name">enabled</span>&gt;</span></div><div class="line">		<span class="tag">&lt;/<span class="name">snapshots</span>&gt;</span></div><div class="line">	<span class="tag">&lt;/<span class="name">repository</span>&gt;</span></div><div class="line"><span class="tag">&lt;/<span class="name">repositories</span>&gt;</span></div></pre></td></tr></table></figure>
<p>关于配置远程仓库，主要有以下几点需要注意：</p>
<ul>
<li>任何仓库的<code>id</code>必须唯一；</li>
<li>在<code>repositories</code>元素下，可以使用<code>repository</code>子元素声明一个或者多个远程仓库；</li>
<li>元素<code>releases</code>和<code>snapshots</code>用来控制Maven对于发布版本构件和快照版构件的下载。</li>
</ul>
<p>对于元素<code>releases</code>和<code>snapshots</code>，除了<code>enabled</code>子元素外，它们还包括另外两个子元素<code>updatePolicy</code>和<code>checksumPolicy</code>：</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="tag">&lt;<span class="name">snapshots</span>&gt;</span></div><div class="line">	<span class="tag">&lt;<span class="name">enabled</span>&gt;</span>false<span class="tag">&lt;/<span class="name">enabled</span>&gt;</span></div><div class="line">	<span class="tag">&lt;<span class="name">checksumPolicy</span>&gt;</span>ignore<span class="tag">&lt;/<span class="name">checksumPolicy</span>&gt;</span></div><div class="line">	<span class="tag">&lt;<span class="name">updatePolicy</span>&gt;</span>daily<span class="tag">&lt;/<span class="name">updatePolicy</span>&gt;</span></div><div class="line"><span class="tag">&lt;/<span class="name">snapshots</span>&gt;</span></div></pre></td></tr></table></figure>
<ul>
<li><code>updatePolicy</code>:配置Maven从远程仓库检查更新的频率，默认值是<code>daily</code>（<code>never</code>：从不检查、<code>always</code>：每次构建时都检查、<code>interval：X</code>：每隔X分钟检查一次）；</li>
<li><code>checksumPolicy</code>：配置Maven检验和文件的策略，默认值为<code>warn</code>：在执行构建时输出警告信息（<code>ignore</code>：完全忽略校验和错误，<code>fail</code>：遇到校验和错误就让构建失败）。</li>
</ul>
<h2 id="认证"><a href="#认证" class="headerlink" title="认证"></a>认证</h2><p>有些远程仓库基于安全的考虑需要提供认证信息才可以访问。配置认证信息需要在<code>settings.xml</code>文件中配置：</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="tag">&lt;<span class="name">server</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">id</span>&gt;</span>deploymentRepo<span class="tag">&lt;/<span class="name">id</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">username</span>&gt;</span>repouser<span class="tag">&lt;/<span class="name">username</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">password</span>&gt;</span>repopwd<span class="tag">&lt;/<span class="name">password</span>&gt;</span></div><div class="line"><span class="tag">&lt;/<span class="name">server</span>&gt;</span></div></pre></td></tr></table></figure>
<p>Maven使用<code>settings.xml</code>文件中并不显而易见的<code>server</code>子元素配置仓库认证信息。</p>
<p>配置认证信息和配置仓库信息不同，仓库信息可以这配置在<code>POM</code>文件中，但是认证信息必须配置在<code>settings.xml</code>文件中。、</p>
<h2 id="部署到远程仓库"><a href="#部署到远程仓库" class="headerlink" title="部署到远程仓库"></a>部署到远程仓库</h2><p>Maven除了对项目进行编译，测试和打包之外，还能将项目部署到仓库中，首先编辑POM文件添加<code>distributionManagementy</code>元素。</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line"><span class="tag">&lt;<span class="name">distributionManagement</span>&gt;</span></div><div class="line">	<span class="tag">&lt;<span class="name">repository</span>&gt;</span></div><div class="line">		<span class="tag">&lt;<span class="name">id</span>&gt;</span>proj-releases<span class="tag">&lt;/<span class="name">id</span>&gt;</span></div><div class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>Proj Releases Repository<span class="tag">&lt;/<span class="name">name</span>&gt;</span></div><div class="line">		<span class="tag">&lt;<span class="name">url</span>&gt;</span>http://192.168.1.100/content/repositories/proj-releases<span class="tag">&lt;/<span class="name">url</span>&gt;</span></div><div class="line">	<span class="tag">&lt;/<span class="name">repository</span>&gt;</span></div><div class="line">	<span class="tag">&lt;<span class="name">snapshotRepository</span>&gt;</span></div><div class="line">		<span class="tag">&lt;<span class="name">id</span>&gt;</span>proj-snapshots<span class="tag">&lt;/<span class="name">id</span>&gt;</span></div><div class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>Proj Snapshots Repository<span class="tag">&lt;/<span class="name">name</span>&gt;</span></div><div class="line">		<span class="tag">&lt;<span class="name">url</span>&gt;</span>http://192.168.1.100/content/repositories/proj-snapshots<span class="tag">&lt;/<span class="name">url</span>&gt;</span></div><div class="line"><span class="tag">&lt;/<span class="name">snapshotRepository</span>&gt;</span></div></pre></td></tr></table></figure>
<p><code>distributionManagement</code>包含<code>repository</code>和<code>snapshotRepository</code>子元素，前者表示发布版本构件的仓库，后者表示快照版本的仓库。这两个元素下都需要配置<code>id</code>、<code>name</code>和<code>url</code>，<code>id</code>为该仓库的唯一标识，<code>name</code>是为了方便人阅读，关键的<code>url</code>表示该仓库的地址。</p>
<p>配置正确后，执行：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">mvn clean deploy</div></pre></td></tr></table></figure>
<p>Maven就会将构建输出的构件部署到配置对应的远程仓库，如果项目当前的版本是快照版本，则部署到快照版本仓库地址，否则就部署到发布版本仓库地址。</p>
<h1 id="镜像"><a href="#镜像" class="headerlink" title="镜像"></a>镜像</h1><p>如果仓库X可以提供仓库Y存储的所有内容，那么就可以认为X是Y的镜像。配置如下：</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="tag">&lt;<span class="name">mirrors</span>&gt;</span></div><div class="line">  <span class="tag">&lt;<span class="name">mirror</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">id</span>&gt;</span>mirrorId<span class="tag">&lt;/<span class="name">id</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">mirrorOf</span>&gt;</span>repositoryId<span class="tag">&lt;/<span class="name">mirrorOf</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>Human Readable Name for this Mirror.<span class="tag">&lt;/<span class="name">name</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">url</span>&gt;</span>http://my.repository.com/repo/path<span class="tag">&lt;/<span class="name">url</span>&gt;</span></div><div class="line">  <span class="tag">&lt;/<span class="name">mirror</span>&gt;</span></div><div class="line"><span class="tag">&lt;/<span class="name">mirrors</span>&gt;</span></div></pre></td></tr></table></figure>
<p><code>&lt;mirrorOf&gt; central&lt;/mirrorOf&gt;</code>表示只为central仓库做镜像，如果想为所有的仓库做镜像那么可以改为：</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="tag">&lt;<span class="name">mirrorOf</span>&gt;</span>*<span class="tag">&lt;/<span class="name">mirrorOf</span>&gt;</span></div></pre></td></tr></table></figure>
<p><code>mirrorOf</code>可选择的配置主要有以下几个：</p>
<ul>
<li><strong>*</strong>：配置所有的仓库；</li>
<li><strong>external*</strong>：匹配所有的远程仓库，使用localhost的除外，使用<code>file：//</code>的除外；</li>
<li><strong>repo1,repo2</strong>：匹配仓库repo1和repo2，使用逗号分隔多个仓库；</li>
<li><strong>*,!repo1</strong>：匹配所有的远程仓库除了repo1.</li>
</ul>
<h1 id="仓库的内部机制"><a href="#仓库的内部机制" class="headerlink" title="仓库的内部机制"></a>仓库的内部机制</h1><p>这一部分主要介绍一下Maven仓库的三个内部机制，一个仓库的布局方式，两个是仓库的解析机制和更新策略。</p>
<h2 id="仓库的布局方式"><a href="#仓库的布局方式" class="headerlink" title="仓库的布局方式"></a>仓库的布局方式</h2><p>任何一个构件都有其唯一的坐标，根据这个坐标可以定义其在仓库中的唯一存储路径，这便是Maven仓库布局方式。例如，<code>log4j:log4j:1.2.15</code>这一依赖，其对应的仓库路径为<code>log4j/log4j/1.2.15/log4j-1.2.15.jar</code>。该路径与坐标的大致对应关系为<code>groupId/artifactId/version/artifactId-version.packaging</code>。</p>
<p>具体的可以参看Maven参考布局的源码部分，也可以参考<a href="http://www.amazon.cn/Maven%E5%AE%9E%E6%88%98-%E8%AE%B8%E6%99%93%E6%96%8C/dp/B004CLZ7BA/ref=sr_1_1?ie=UTF8&amp;qid=1444818561&amp;sr=8-1&amp;keywords=maven%E5%AE%9E%E6%88%98" target="_blank" rel="external">《Maven实战》</a>P76-77。</p>
<h2 id="仓库解析依赖机制"><a href="#仓库解析依赖机制" class="headerlink" title="仓库解析依赖机制"></a>仓库解析依赖机制</h2><p>Maven是根据怎么的跪着从仓库解析并使用依赖构件的呢？</p>
<p>当本地仓库没有依赖构件的时候，Maven会自动从远程仓库下载相应构件，当依赖版本为快照版本的时候，Maven会自动找到最新的快照。详细的依赖机制为：</p>
<ol>
<li>当依赖的范围是<code>system</code>的时候，Maven直接从本地文件系统解析构件；</li>
<li>根据依赖坐标计算仓库路径后，尝试直接从本地仓库寻找构件，如果发现相应构件，则解析成功;</li>
<li>在本地仓库不存在相应构件的情况下，如果依赖的版本是显式的发布版本构件，如：1.2，2.1等，则遍历所有的远程仓库，发现后，下载并解析使用;</li>
<li>如果依赖的版本是<code>RELEASE</code>或者<code>LATEST</code>，则基于更新策略读取所有远程仓库的元数据<code>groupId/artifactId/mavenmetadata.xml</code>，将其与本地仓库的对应元数据合并后，计算出<code>RELEASE</code>或者<code>LATEST</code>真实的值，然后基于这个真实的值检查本地和远程仓库，如步骤1和3;</li>
<li>如果依赖的版本是<code>SNAPSHOT</code>，则基于更新策略读取所有远程仓库的元数据<code>groupId/artifactId/version/mavenmetadata.xml</code>，将其与本地仓库的对应元数据合并后，得到最新快照版本的值，然后基于该值检查本地仓库，或者从远程仓库下载;</li>
<li>.如果最后解析得到的构件版本是时间戳格式的快照，如：<code>1.4-20091104.121450-121</code>,则复制其时间戳格式的文件到非时间戳格式，如：<code>SNAPSHOT</code>，并使用该非时间戳格式的构件.</li>
</ol>
<p>当依赖的版本不明晰的时候，如:<code>RELEASE</code>,<code>LATEST</code>和<code>SNAPSHOT</code>，Maven就需要基于更新远程仓库的更新策略来检查更新。</p>
<h2 id="仓库的更新策略"><a href="#仓库的更新策略" class="headerlink" title="仓库的更新策略"></a>仓库的更新策略</h2><p>主要有以下几个配置与Maven仓库的更新有关：</p>
<ul>
<li>首先是<code>&lt;releases&gt;&lt;enabled&gt;</code>和<code>&lt;snapshots&gt;&lt;enabled&gt;</code>，只有仓库开启了对于发布版本的支持时，才能访问该仓库的发布版本构件信息，对于快照版本也是同理；</li>
<li>其次要注意的是<br><code>&lt;releases&gt;</code>和<code>&lt;snapshots&gt;</code>的子元素<code>&lt;updatePolicy&gt;</code>，该元素配置了检查更新的频率;</li>
<li>最后，用户还可以从命令行加入参数<code>-U</code>,强制检查更新，使用参数后，Maven就会忽略<code>&lt;updatePolicy&gt;</code>的配置。</li>
</ul>
<p>当Maven检查完更新策略，并决定检查依赖更新的时候，就需要检查仓库元数据<code>maven-metadata.xml</code>。前面提到的<code>RELEASE</code>和<code>LATEST</code>版本，它们分别对应了仓库中存在的该构件的最新发布版本和最新版本(包含快照)，而这两个”最新”是基于<code>groupId/artifactId/maven-metadata.xml</code>计算出来的，如：</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div></pre></td><td class="code"><pre><div class="line">&lt;?xml version="1.0" encoding="UTF-8"?&gt;</div><div class="line"><span class="tag">&lt;<span class="name">metadata</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.sonatype.nexus<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>nexus<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">versioning</span>&gt;</span></div><div class="line">        <span class="tag">&lt;<span class="name">latest</span>&gt;</span>1.4.2-SNAPSHOT<span class="tag">&lt;/<span class="name">latest</span>&gt;</span></div><div class="line">        <span class="tag">&lt;<span class="name">release</span>&gt;</span>1.4.0<span class="tag">&lt;/<span class="name">release</span>&gt;</span></div><div class="line">        <span class="tag">&lt;<span class="name">versions</span>&gt;</span></div><div class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.3.5<span class="tag">&lt;/<span class="name">version</span>&gt;</span></div><div class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.3.6<span class="tag">&lt;/<span class="name">version</span>&gt;</span></div><div class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.4.0-SNAPSHOT<span class="tag">&lt;/<span class="name">version</span>&gt;</span></div><div class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.4.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></div><div class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.4.0.1-SNAPSHOT<span class="tag">&lt;/<span class="name">version</span>&gt;</span></div><div class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.4.1-SNAPSHOT<span class="tag">&lt;/<span class="name">version</span>&gt;</span></div><div class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.4.2-SNAPSHOT<span class="tag">&lt;/<span class="name">version</span>&gt;</span></div><div class="line">        <span class="tag">&lt;/<span class="name">versions</span>&gt;</span></div><div class="line">    <span class="tag">&lt;/<span class="name">versioning</span>&gt;</span></div><div class="line"><span class="tag">&lt;/<span class="name">metadata</span>&gt;</span></div></pre></td></tr></table></figure>
<p>在XML文件列出了仓库中存在的该构件所有可用的版本，同时<code>latest</code>元素指向了这些版本中最新的那个版本。而<code>release</code>元素指向了这些版本中最新的发布版本。Maven通过合并多个远程仓库及本地仓库的元数据，就能计算出基于所有仓库的<code>latest</code>和<code>release</code>分别是什么，然后再解析具体的构件。</p>
<p> 有几点需要的注意的：</p>
<ul>
<li>在依赖声明中使用LATEST和RELEASE是<strong>不推荐</strong>的做法（因为Maven随时都可能解析到不同的构件，可能今天<code>LATEST</code>是<code>1.3.6</code>,明天就成了<code>1.4.0-SNAPSHOT</code>了，且Maven不会明确告诉用户这样的变化）；</li>
<li>Maven3不再支持在插件配置中使用<code>LATEST</code>和<code>RELEASE</code>；</li>
<li>如果不设置插件版本，其效果就和RELEASE一样，Maven只会解析最新的发布版本构件；</li>
</ul>
<p>当依赖的版本设为<strong>快照版本</strong>的时候，Maven也需要检查更新，这时，Maven会检查仓库元数据<code>groupId/artifactId/version/maven-metadata.xml</code>，这个与发布版本的有所不同。</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line">&lt;?xml version="1.0" encoding="UTF-8"?&gt;</div><div class="line"><span class="tag">&lt;<span class="name">metadata</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.sonatype.nexus<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>nexus<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.4.2-SNAPSHOT<span class="tag">&lt;/<span class="name">version</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">versioning</span>&gt;</span></div><div class="line">        <span class="tag">&lt;<span class="name">snapshot</span>&gt;</span></div><div class="line">            <span class="tag">&lt;<span class="name">timestamp</span>&gt;</span>20091214.221414<span class="tag">&lt;/<span class="name">timestamp</span>&gt;</span></div><div class="line">            <span class="tag">&lt;<span class="name">buildNumber</span>&gt;</span>13<span class="tag">&lt;/<span class="name">buildNumber</span>&gt;</span></div><div class="line">        <span class="tag">&lt;/<span class="name">snapshot</span>&gt;</span></div><div class="line">        <span class="tag">&lt;<span class="name">lastUpdated</span>&gt;</span>20091214221558<span class="tag">&lt;/<span class="name">lastUpdated</span>&gt;</span></div><div class="line">    <span class="tag">&lt;/<span class="name">versioning</span>&gt;</span></div><div class="line"><span class="tag">&lt;/<span class="name">metadata</span>&gt;</span></div></pre></td></tr></table></figure>
<p>该xml文件的<code>snapshot</code>元素包含<code>timestamp</code>和<code>buildNumber</code>两个子元素，分别代表了这一快照的时间戳和构建号，基于这两个元素可以得到该仓库中此快照的最新构件版本实际为<code>1.4.2-20091213.221414-13</code>。通过合并所有远程仓库和本地仓库的元数据，Maven就能知道所有仓库中该构件的最新快照。</p>
<h1 id="快照版本"><a href="#快照版本" class="headerlink" title="快照版本"></a>快照版本</h1><p>在Maven的世界中，任何一个项目或者构件都必须有自己的版本。版本的值可能是<code>1.0.0,1.3-alpha-4</code>,<code>2.0</code>,<code>2.1-SNAPSHOT</code>或者<code>2.1-20091214.221414-13</code>。其中，<code>1.0</code>、<code>1.3-alpha-4</code>和<code>2.0</code>是稳定的发布版本，而<code>2.1-SNAPSHOT</code>和<code>2.1-20091214.221414-13</code>是不稳定的快照版本。</p>
<p>快照版本对于Maven来说是很重要的，下面举个例子来说明。小张在开发模块A的2.1版本，该版本还未正式发布，与模块A一同开发的还有模块B，它由小张的同事季MM开发，B的功能依赖于A。在开发的过程中，小张需要经常将自己最新的构建输出，交给季MM，供她开发和集成调试，问题是，这个工作如何进行呢？如果不停更新版本2.1.1、2.1.2、2.1.3….呢？首先，小张和季MM两人都需要频繁地更改POM，如果有更多的模块依赖于模块A，就会涉及更多的POM更改；其次，大量的版本其实仅仅包含了微小的差异，这样也会造成为版本号的滥用。</p>
<p>Maven的快照版本机制就是为了解决上述问题。在该例中，小张只需要将模块A的版本设定为<code>2.1-SNAPSHOT</code>，然后发布到私服中，在发布的过程中，Maven会自动为构件打上时间戳。比如:<code>2.1-20091214.221414-13</code>就表示2009年12月14日 22点14分14秒的第13次快照。有了该时间戳，Maven就能随时找到仓库中该构件<code>2.1-SNAPSHOT</code>版本最新的文件。这时，季MM配置对于模块A的<code>2.1-SNAPSHOT</code>版本的依赖，当她构件模块B的时候，Maven会自动从仓库中检查模块A的<code>2.1-SNAPSHOT</code>的最新构件，当发现有更新时便进行下载。默认情况下，Maven每天检查一次更新(由仓库配置的<code>updatePolicy</code>控制)，用户也可以使用命令行-U参数强制让Maven检查更新，如：<code>mvn clean install-U</code>。</p>
<p>基于快照版本机制，小张在构建成功之后才能将构件部署至仓库，而季MM可以完全不用考虑模块A的构建，并且她能确保随时得到模块A的最新可用的快照构件，而这一切都不需要额外的手工操作。</p>
<p>最后要注意的是，快照版本一般只在组织内部的项目或模块间依赖使用，而且项目不应该依赖于组织外部的快照版本依赖（因为快照版本是不稳定的）。</p>
<hr>
<p>参考：</p>
<ul>
<li><a href="http://item.jd.com/10476794.html" target="_blank" rel="external">Maven实战</a></li>
</ul>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[Maven之依赖]]></title>
      <url>http://matt33.com/2015/10/11/the-dependency-of-maven/</url>
      <content type="html"><![CDATA[<p>最近一年做项目时，一直在与Maven打交道，在网上也看了很多的博客，也看了《Maven实战》这本书，感觉受益匪浅，但是过一段时间很多东西也会忘记，所以就想根据这本书上看到的，还有自己的经验，写几篇Maven的博客来梳理一下核心点。</p>
<h1 id="依赖配置"><a href="#依赖配置" class="headerlink" title="依赖配置"></a>依赖配置</h1><p>一个依赖包的声明主要包括以下的一些元素：</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div></pre></td><td class="code"><pre><div class="line"><span class="tag">&lt;<span class="name">project</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">dependencies</span>&gt;</span></div><div class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></div><div class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>...<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></div><div class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>...<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></div><div class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>...<span class="tag">&lt;/<span class="name">version</span>&gt;</span></div><div class="line">            <span class="tag">&lt;<span class="name">type</span>&gt;</span>...<span class="tag">&lt;/<span class="name">type</span>&gt;</span></div><div class="line">            <span class="tag">&lt;<span class="name">scope</span>&gt;</span>...<span class="tag">&lt;/<span class="name">scope</span>&gt;</span></div><div class="line">            <span class="tag">&lt;<span class="name">optional</span>&gt;</span>...<span class="tag">&lt;/<span class="name">optional</span>&gt;</span></div><div class="line">            <span class="tag">&lt;<span class="name">exclusions</span>&gt;</span></div><div class="line">                <span class="tag">&lt;<span class="name">exclusion</span>&gt;</span></div><div class="line">                ...</div><div class="line">                <span class="tag">&lt;/<span class="name">exclusion</span>&gt;</span></div><div class="line">                ...</div><div class="line">            <span class="tag">&lt;/<span class="name">exclusions</span>&gt;</span></div><div class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></div><div class="line">        ...</div><div class="line">    <span class="tag">&lt;/<span class="name">dependencies</span>&gt;</span></div><div class="line">    ...</div><div class="line"><span class="tag">&lt;/<span class="name">project</span>&gt;</span></div></pre></td></tr></table></figure>
<p>先简单介绍一下上面这几个元素的意义：</p>
<ul>
<li><strong>groupId、artifactId和version</strong>：依赖的基本坐标（这个本文就不在讲解了）；</li>
<li><strong>type</strong>：依赖的类型，对应于项目坐标定义的<code>packaging</code>，一般情况下，该元素不用声明，默认为<code>jar</code>；</li>
<li><strong>scope</strong>：依赖的范围；</li>
<li><strong>optional</strong>：标记依赖是否可选；</li>
<li><strong>exclusions</strong>：用来排除传递性依赖。</li>
</ul>
<h1 id="依赖范围"><a href="#依赖范围" class="headerlink" title="依赖范围"></a>依赖范围</h1><p>Maven依赖的依赖范围有一下几类，分别是：<code>compile</code>、<code>test</code>、<code>provided</code>、<code>runtime</code>、<code>system</code>和<code>import</code>。</p>
<p>之所以Maven会有这么多依赖范围，主要原因是：Maven在编译项目主代码的时候需要使用一套classpath；Maven在编译和执行测试的时候会使用另外一套classpath；Maven实际运行项目的时候，又会使用一套classpath。依赖范围就是用来控制依赖与这三种classpath的关系。</p>
<ul>
<li><strong>compile</strong>：编译依赖范围（默认值），对编译、测试、运行三种classpath都有效；</li>
<li><strong>test</strong>：测试依赖范围，只对测试classpath有效；</li>
<li><strong>provided</strong>：已提供依赖范围，对编译和测试classpath有效；</li>
<li><strong>runtime</strong>：运行时依赖范围，对测试和运行classpath有效；</li>
<li><strong>system</strong>：系统依赖范围，以provided依赖范围一致，但使用<code>system</code>范围时必须通过<code>systemPath</code>元素显示地制定依赖文件的路径；</li>
<li><strong>import</strong>：导入依赖范围，该依赖不会对三种classpath产生实际影响。</li>
</ul>
<p>使用<code>system</code>的例子如下：</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>commons-collections<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>commons-collection<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>3.2.1<span class="tag">&lt;/<span class="name">version</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">type</span>&gt;</span>system<span class="tag">&lt;/<span class="name">type</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">systemPath</span>&gt;</span>$&#123;java.home&#125;/lib/rt.jar<span class="tag">&lt;/<span class="name">systemPath</span>&gt;</span></div><div class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></div></pre></td></tr></table></figure>
<p>用表格的形式表示以上依赖如下所示：</p>
<table>
<thead>
<tr>
<th>scope</th>
<th>对编译有效</th>
<th>对测试有效</th>
<th>对运行有效</th>
</tr>
</thead>
<tbody>
<tr>
<td>compile</td>
<td>Y</td>
<td>Y</td>
<td>Y</td>
</tr>
<tr>
<td>test</td>
<td>-</td>
<td>Y</td>
<td>-</td>
</tr>
<tr>
<td>provided</td>
<td>Y</td>
<td>Y</td>
<td>-</td>
</tr>
<tr>
<td>runtime</td>
<td>-</td>
<td>Y</td>
<td>Y</td>
</tr>
<tr>
<td>system</td>
<td>Y</td>
<td>Y</td>
<td>-</td>
</tr>
</tbody>
</table>
<h1 id="传递性依赖"><a href="#传递性依赖" class="headerlink" title="传递性依赖"></a>传递性依赖</h1><p><strong>传递性依赖</strong>：比如一个项目<code>account-email</code>有一个compile范围的<code>spring-core</code>依赖，而<code>spring-core</code>有一个compile范围的<code>commons-logging</code>的依赖，那么<code>commons-logging</code>就会成为<code>account-email</code>的compile范围依赖，<code>commons-logging</code>是<code>account-email</code>的一个传递性依赖。</p>
<p>有个传递性依赖机制，在使用<code>account-email</code>的时候就不用去考虑它依赖了什么。明白了传递性依赖，下面就看一下传递性依赖和依赖范围的关系，假设A依赖于B，B依赖于C，我们说A对于B是第一直接依赖范围，B对于C是第二依赖范围，A对于C是传递性依赖。第一直接依赖的范围和第二直接依赖的范围决定了传递性依赖的范围，如下表所示，最左边一列表示第一直接依赖，最上面一行表示第二直接依赖范围，中间的结果就表示传递性依赖范围。</p>
<table>
<thead>
<tr>
<th>依赖范围</th>
<th>compile</th>
<th>test</th>
<th>provided</th>
<th>runtime</th>
</tr>
</thead>
<tbody>
<tr>
<td>compile</td>
<td>compile</td>
<td>——</td>
<td>——</td>
<td>runtime</td>
</tr>
<tr>
<td>test</td>
<td>test</td>
<td>——</td>
<td>——</td>
<td>test</td>
</tr>
<tr>
<td>provided</td>
<td>provided</td>
<td>——</td>
<td>provided</td>
<td>provided</td>
</tr>
<tr>
<td>runtime</td>
<td>runtime</td>
<td>——</td>
<td>——</td>
<td>runtime</td>
</tr>
</tbody>
</table>
<p>仔细观察上表，我们可以得到以下结论：</p>
<ol>
<li>当第二直接依赖的范围是<code>compile</code>的时候，传递性依赖的范围与第一直接依赖的范围一致；</li>
<li>当第二直接依赖的范围是<code>test</code>的时候，依赖不会得以传递；</li>
<li>当第二直接依赖的范围是<code>provided</code>的时候，只传递第一直接依赖范围也为<code>provided</code>的依赖，且传递性依赖的范围同样为<code>provided</code>；</li>
<li>当第二直接依赖的范围是<code>runtime</code>的时候，传递性依赖的范围与第一依赖的范围一致，但<code>compile</code>例外，此时传递性依赖的范围为<code>runtime</code>。</li>
</ol>
<h1 id="依赖调解"><a href="#依赖调解" class="headerlink" title="依赖调解"></a>依赖调解</h1><p>假如项目A有这样的依赖的关系：A-&gt;B-&gt;C-&gt;X(1.0)，A-&gt;D-&gt;X(2.0)，X是A的传递性依赖，但是有两条路径，那么应该选择哪个版本呢？</p>
<p>Maven依赖调解（Dependency Mediation）有两个原则：</p>
<ul>
<li>路径最近者优先；</li>
<li>第一声明者优先（路径相等的前提下，在POM中依赖声明的顺序决定了谁会被解析使用）；</li>
</ul>
<h1 id="可选依赖"><a href="#可选依赖" class="headerlink" title="可选依赖"></a>可选依赖</h1><p>假设有这样一个依赖关系，项目A依赖与项目B，项目B依赖于项目X和Y，B对于X和Y的依赖都是可选依赖：A-&gt;B、B-&gt;X（可选）、B-&gt;Y（可选），那么X、Y就是A的传递性依赖。然而，由于这里X、Y是可选依赖，依赖将不会得以传递。</p>
<p>下面是设置可选依赖的一个例子：</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span>  </div><div class="line">  <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>commons-logging<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span>   </div><div class="line">  <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>commons-logging<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span>   </div><div class="line">  <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.1.1<span class="tag">&lt;/<span class="name">version</span>&gt;</span>   </div><div class="line">  <span class="tag">&lt;<span class="name">optional</span>&gt;</span>true<span class="tag">&lt;<span class="name">optional</span>&gt;</span>  </div><div class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></div></pre></td></tr></table></figure>
<p>一般情况下，不应该使用可选依赖，使用可选依赖的原因是某一个项目实现了多个特性，在面向对象设计中，有个单一职责性原则，意指一个类应该只有一项职责，而不应该糅合太多的功能。当项目需要某个依赖的可选依赖，可以显式地声明这一依赖。</p>
<h1 id="排除依赖"><a href="#排除依赖" class="headerlink" title="排除依赖"></a>排除依赖</h1><p>有时候会出现这样的情况，你的<code>Hibernate</code>依赖于<code>Sun JTA API</code>，但是因为版权原因，<code>Sun JTA API</code>并不在仓库中。而<code>Apache Geronimo</code>项目有一个对应的实现。这时你就可以排除<code>Sun JAT API</code>，再声明<code>Geronimo</code>的<code>JTA API</code>实现，见代码清单：</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line"> <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>com.juvenxu.mvnbook<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>project-b<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.0.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">exclusions</span>&gt;</span></div><div class="line">        <span class="tag">&lt;<span class="name">exclusion</span>&gt;</span></div><div class="line">            <span class="comment">&lt;!-- 排除对project-c的依赖 --&gt;</span></div><div class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>com.juvenxu.mvnbook<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></div><div class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>project-c<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></div><div class="line">        <span class="tag">&lt;/<span class="name">exclusion</span>&gt;</span></div><div class="line">    <span class="tag">&lt;/<span class="name">exclusions</span>&gt;</span></div><div class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></div></pre></td></tr></table></figure>
<p>上述代码中，项目A依赖于项目B，但是由于一些原因，不想引入传递性依赖C，而是自己显示声明对于项目C1.0.0版本的依赖。代码中用exclusions元素可以包含<strong>多个</strong>exclusion子元素。需要注意的是声明exslusion的时候只需要groupId和artifactId，而<strong>不需要</strong>version元素(Maven解析后的依赖中，不可能出现groupId和artifactId相同，但是version不同的两个依赖)。</p>
<h1 id="归类依赖"><a href="#归类依赖" class="headerlink" title="归类依赖"></a>归类依赖</h1><p>当我们使用<code>Spring Framework</code>的依赖时，会有许多依赖，如：<code>spring-core:2.5.6.org</code>、<code>org.springframework:spring-beans:2.5.6</code>等，它们是来自同一项目下的不同模块。它们依赖的版本都是相同时，当需要升级<code>Spring Framework</code>时，这些依赖的版本都会一起升级。这时候我们可以用Maven属性的方式来定义一个名为<code>springframework.version</code>的属性，让所有的<code>spring framework</code>子模块都引用它。</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div></pre></td><td class="code"><pre><div class="line">&lt;?xml version="1.0" encoding="UTF-8"?&gt;</div><div class="line"><span class="tag">&lt;<span class="name">project</span> <span class="attr">xmlns</span>=<span class="string">"http://maven.apache.org/POM/4.0.0"</span> <span class="attr">xmlns:xsi</span>=<span class="string">"http://www.w3.org/2001/XMLSchema-instance"</span> <span class="attr">xsi:schemaLocation</span>=<span class="string">"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/maven-v4_0_0.xsd"</span>&gt;</span></div><div class="line"></div><div class="line">    <span class="tag">&lt;<span class="name">modelVersion</span>&gt;</span>4.0.0<span class="tag">&lt;/<span class="name">modelVersion</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>com.juvenxu.mvnbook<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>project-a<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.0.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></div><div class="line"></div><div class="line">    <span class="tag">&lt;<span class="name">properties</span>&gt;</span></div><div class="line">        <span class="comment">&lt;!--类似于设置一个变量--&gt;</span></div><div class="line">        <span class="tag">&lt;<span class="name">springframework.version</span>&gt;</span>3.1.2.RELEASE<span class="tag">&lt;/<span class="name">springframework.version</span>&gt;</span></div><div class="line">    <span class="tag">&lt;/<span class="name">properties</span>&gt;</span></div><div class="line"></div><div class="line">    <span class="tag">&lt;<span class="name">dependencies</span>&gt;</span></div><div class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></div><div class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></div><div class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-core<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></div><div class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>$&#123;springframework.version&#125;<span class="tag">&lt;/<span class="name">version</span>&gt;</span></div><div class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></div><div class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></div><div class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></div><div class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-context<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></div><div class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>$&#123;springframework.version&#125;<span class="tag">&lt;/<span class="name">version</span>&gt;</span></div><div class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></div><div class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></div><div class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></div><div class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-context-support<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></div><div class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>$&#123;springframework.version&#125;<span class="tag">&lt;/<span class="name">version</span>&gt;</span></div><div class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></div><div class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></div><div class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></div><div class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-aop<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></div><div class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>$&#123;springframework.version&#125;<span class="tag">&lt;/<span class="name">version</span>&gt;</span></div><div class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></div><div class="line">    <span class="tag">&lt;/<span class="name">dependencies</span>&gt;</span></div><div class="line"><span class="tag">&lt;/<span class="name">project</span>&gt;</span></div></pre></td></tr></table></figure>
<p>这样当我们需要升级的时候,就只需要改属性值<code>springframework.version</code>就可以了。</p>
<h1 id="优化依赖"><a href="#优化依赖" class="headerlink" title="优化依赖"></a>优化依赖</h1><ul>
<li>使用<code>mvn dependency:list</code>命令可以查看项目已解析的依赖;</li>
<li>使用<code>mvn dependency:tree</code>命令可以查看项目构成的依赖树;</li>
<li>使用<code>mvn dependency:analyze</code>命令可以分析当前项目的依赖.</li>
</ul>
<hr>
<p>参考：</p>
<ul>
<li><a href="http://item.jd.com/10476794.html" target="_blank" rel="external">Maven实战</a></li>
</ul>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[Travel to Qinghai Lake | 青海湖骑行之旅]]></title>
      <url>http://matt33.com/2015/09/27/Travel-to-Qinghai-Lake/</url>
      <content type="html"><![CDATA[<p>今年的青海湖之行给我留下了很美好的回忆，骑行的过程确实是很艰辛，但我们每一个人都按照原计划到达了终点。</p>
<h3 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h3><p>这一段姑且算作是前言吧。首先介绍一下我自己，我是北京邮电大学的一名研究生，17年毕业，也就是明年就要找工作了，所以今年暑假是学生时代的最后一个暑假了。之前我一直有个梦想，就是想来一段说走就走的旅行，刚好在朋友圈看到朋友经常骑行的照片，而我也是一个热爱旅行、热爱骑行的人，所以就想来一段短期的旅行————去青海。</p>
<h3 id="骑行前准备"><a href="#骑行前准备" class="headerlink" title="骑行前准备"></a>骑行前准备</h3><p>骑行前第一步首先是招募小伙伴。我就在学校的BBS上，发了一个帖子（征友去青海骑行），第二天帖子居然被坛友们顶上了十大，有很多小伙伴跟我的想法一样，我们就很顺利组建了我们的青海小分队。</p>
<p>先说一下骑行的需要的准备的东西：</p>
<ol>
<li><strong>骑行相关物件</strong>：头盔、雨衣、驮包、码表、硅胶坐垫、束带、简易修理工具和备胎（一辆一车至少准备一个备胎，也可以多带几个，大不了回来的时再还给老板）这些都是可以在租车的地方一并租到（顺便宣传一下我们选的<a href="http://www.qinghaihu.cc/ShowGongyi?id=164" target="_blank" rel="external">圣湖单车俱乐部</a>）,墨镜、骑行手套、魔术巾等(这些是需要自己准备的);</li>
<li><strong>旅行需要物品</strong>：现金、手机、身份证、银行卡、相机、充电宝、电池充电器、水壶（喝热水）、报纸、防晒霜（必备，尽量买防晒级别偏高的那种）等；</li>
<li><strong>衣物</strong>：8月不算特别冷，但早晚温差大，下雨的时候还是很冷的，建议带上一件厚外套（冲锋衣）；</li>
<li><strong>药品</strong>：抗高反的药（高原安，红景天）、感冒药（连花清瘟等）、发烧（感康）、肠胃药（藿香正气液）、外伤药（创可贴）等；</li>
<li><strong>食物</strong>：士力架、巧克力、棒棒糖（补充糖），自己再带一些想吃的零食用来路上补充能量。另外，也可以带好充足的食物中午时候找一块合适的地方来野餐。</li>
</ol>
<p>旅行途中需要注意的：</p>
<ul>
<li>一定保护自己的脸，首先涂上防晒霜，然后用魔术巾遮住脸，再带个鸭舌帽，最后套头盔，这样是最保险的（不担心自己脸被晒黑的小伙伴就不用这样了哈）；</li>
<li>以防万一会下雨，可能提前在淘宝买双防雨鞋，要不下雨的话，鞋会被雨水打湿的；</li>
<li>人多的话，住宿可以提前定，不过到地方再找住宿也没事，镇上青旅特别多；</li>
</ul>
<p>下面就是我们当时骑行的行程：</p>
<h3 id="8-1西宁集合"><a href="#8-1西宁集合" class="headerlink" title="8.1西宁集合"></a>8.1西宁集合</h3><p>1号上午11点半，我们一行七人在西宁火车站集合，那天西宁的天气很不错的，一出火车站就能感受到青海火辣的太阳，外面很晒，防晒霜是绝对对不能缺少的。我们人员到齐之后，就在火车站旁边一家川菜馆饭店吃的中饭，大家第一次是在一起吃饭，吃得还是满开心的，那里东西也不贵。下面一张是在西宁汽车站旁边的拍得一张照片。<br><img src="/images/2015-09-27-TraveltoQinghaiLake/2015-09-27-station.jpg" alt="station"></p>
<p>吃完中饭后，我们就在火车站旁边的汽车站买了去西海镇的汽车票，每人25元（回西宁的时候买的票是23一个人，不知道这怎么回事）。西宁汽车站给我的第一印象就是，很安静。虽然汽车站等车的人很多，但是相比于内地而言，非常安静，可能在内地吵杂的环境呆的时间长了，有点不习惯吧。</p>
<p>下午达到西海镇时，西海镇给我的第一个印象是：这是一个很干净、很宁静的一个小镇，西海镇就像是江浙那边的小镇一样，感觉挺发达的，可能因为这是环青海湖的起点，旅游业很发达吧。下面这张是雨后的西海镇：</p>
<p><img src="/images/2015-09-27-TraveltoQinghaiLake/2015-09-27-XihaiZhen.jpg" alt="XihaiZhen"></p>
<p>我们在西海镇下了车之后，我们就跟提前联系的圣湖自行车俱乐部打了电话，老板特别热情，老板娘亲自开车来车站接我们。在俱乐部休整一下之后，基本上就到了该吃晚饭的时间，我们就去了老板推荐的西宁肥牛烤肉去吃烤肉，那里烤肉吃着的确很爽，尤其烤羊排，都是大块的羊肉（烤羊排是80元/斤，有点小贵）。不幸的是在吃烤肉的时候，外面突然下起了暴雨，我们就只能在店里边聊天边吃饭了。暴雨下的快走的也快，等雨停的时候，我们准备赶紧回去，不过就那一会的暴雨，镇中心那一块已经全部被淹了，不得不感慨一下西海镇的水利系统（不过这个问题，貌似全国都一样）。青海的天气变化很快，暴雨过后，天气突然又转晴了。</p>
<p>西海肥牛烤肉的美食：<br><img src="/images/2015-09-27-TraveltoQinghaiLake/2015-09-27-XHFood.jpg" alt="XHFood"></p>
<p>雨后西海镇的镇中心：<br><img src="/images/2015-09-27-TraveltoQinghaiLake/2015-09-27-XHRain.jpg" alt="XHRain"></p>
<p>今天的花费：<br>中饭27，晚饭44，西海镇车费25，水6。</p>
<h3 id="8-2-DAY1-西海镇——江西沟（96-3km）"><a href="#8-2-DAY1-西海镇——江西沟（96-3km）" class="headerlink" title="8.2 DAY1.西海镇——江西沟（96.3km）"></a>8.2 DAY1.西海镇——江西沟（96.3km）</h3><p>今天应该整个行程最兴奋的一天，景色也相当的不错。早上起来我们整理好东西之后，就在西海镇随便找了一家早餐馆吃饭，早上每个早餐店人都很多，这里的早餐还算可以，跟后面的几天比，应该算是最好的，大概人均10块。吃完早饭，买了一些必需品之后（一定、一定、一定要买包<strong>夜用大包</strong>的卫生巾，在屁股上垫上一个，重要的事情说三遍，要不然屁股会非常、非常、非常疼），就向着我们的目标出发了。今天的风景还是很不错的，远处的山可以感受山在云上的感觉。今天天气也不算特别，中间还滴了点小雨。</p>
<p><img src="/images/2015-09-27-TraveltoQinghaiLake/2015-09-27-XHStart.jpg" alt="XHSart"></p>
<p><img src="/images/2015-09-27-TraveltoQinghaiLake/j6.jpg" alt="j6"></p>
<p>Notes：</p>
<ol>
<li>从西海镇出发时，有很多上下坡，下坡很多，也非常刺激，最高的速度可以达到50Km/h；</li>
<li>上午的话，路上可以看到沙漠、草原的景观，不过进去玩的话都是都要收费的；</li>
<li>在快要进入109国道的时候会看到另外一个湖，当地人们好像叫它叫小湖（名字记不太清楚了，大体意思就是比青海湖小的湖），周边有直接通到湖边的小路，不过进去要收费的，每个人10元。这里感觉没必要进去，第三天的时候去湖边应该最爽的，而且去的是真正的青海湖（不是小湖）旁边。</li>
<li>109国道车很多，不过在到二郎剑之前，路的右边一直有一条骑行专用的小路（感觉路上不是特别好，没有前面的路好走），在这条专用路上不必担心车辆的问题。这条小路上有很多专门提供给游客照相的油菜花地，同样进去的话每人10元，可以路边拍几张，当地人可能说你俩句，不过也没什么问题。第四天的时候也有油菜花，不过感觉第一天的油菜花地应该最漂亮的，应该油菜花前面就是湖。</li>
<li>至于过了二郎剑之后，小心点其实也没啥事。</li>
</ol>
<p><img src="/images/2015-09-27-TraveltoQinghaiLake/2015-09-27-qh1.jpg" alt="qh1"></p>
<p>旁边的沙漠<br><img src="/images/2015-09-27-TraveltoQinghaiLake/2015-09-27-qh2.jpg" alt="qh2"></p>
<p>远处的湖：<br><img src="/images/2015-09-27-TraveltoQinghaiLake/2015-09-27-qh3.jpg" alt="qh3"></p>
<p>青海湖的油菜花、很美的油菜花：<br><img src="/images/2015-09-27-TraveltoQinghaiLake/2015-09-27-qh4.jpg" alt="qh4"></p>
<p>骑行专用的小道：<br><img src="/images/2015-09-27-TraveltoQinghaiLake/2015-09-27-qh5.jpg" alt="qh5"></p>
<p>中饭我们是在109国道的丁字路口的一个蒙古包里解决的，我当时吃得是拉面，好像12块钱一碗，不过量很少，吃不饱，吃碗面之后就接着吃了自己带的一些饼干。下面是我们吃饭的那个蒙古包：</p>
<p><img src="/images/2015-09-27-TraveltoQinghaiLake/2015-09-27-qh6.jpg" alt="qh6"></p>
<p>下午五点到达江西沟之后，先到提前预定的青年旅舍（<a href="http://hotels.ctrip.com/hotel/1232070.html" target="_blank" rel="external">仓央嘉措青年旅舍</a>），感觉这个青旅一般般吧，我们住的是八人间，60元/人，不过是可以洗澡的。晚饭我们就在江西沟乡镇上找的一家，当时我们是在大众点评上找的，具体叫什么忘了，在那里我们点了牦牛肉（80元/斤）吃，饭菜还可以吧。吃完饭之后，我们就直接回去休息了，然后大概在八点多的时候，突然就开始下暴雨了，而且还下了冰雹，这种大雨在内地应该是很少见的。<br>下面是大块的牦牛肉：<br><img src="/images/2015-09-27-TraveltoQinghaiLake/2015-09-27-maoniurou.jpg" alt="maoniurou"></p>
<p>今天的花费：<br>早饭10，中饭14，晚饭47，水10，住宿60。</p>
<h3 id="8-3-Day2-江西沟——黑马河-（50-2km）"><a href="#8-3-Day2-江西沟——黑马河-（50-2km）" class="headerlink" title="8.3 Day2.江西沟——黑马河 （50.2km）"></a>8.3 Day2.江西沟——黑马河 （50.2km）</h3><p>今天是最悲催的一天，早上起来之后依然下着中雨。我们收拾完东西之后，等雨小一点的时候，就赶紧去吃了早饭，江西沟的早饭比较贵，平均一个人都快20了。等我们出发的时候，天气仍然是阴沉沉，还有点小雨，因为我们的行程之前已经全定好了，没有什么备选计划，所以我们打算冒雨前行了。穿上雨衣之后，我们就开始出发了，刚出发之后，就有一名队友的前胎被扎破了，那会雨已经下大了。因为我们没人会修自行车，我们就在路上向其他的骑友求救，骑友们都很热情，马上就有人停下来帮我们换胎了，前胎比较好换，看了一遍之后我们就学会了。修好之后，我们就开始出发，结果过了一会又有两位队友车胎被扎破了，一路上感觉都很曲折。而且这会基本上一直都是中雨，我们身上很鞋上都湿透了（提前在网上买双防雨鞋套非常有必要）。而且下雨骑车的时候尽量骑在白线以内，因为白线外很多小石子，特别容易扎破胎，所以只能占一点机动车车道了。</p>
<p><img src="/images/2015-09-27-TraveltoQinghaiLake/2015-09-27-Rain.jpg" alt="Rain"></p>
<p>骑到十一点多的时候，我们在路上补充了一些能量，感觉吃到这辈子最好吃的饼干、最好喝的热水、最好吃的士力架。补充完能量后，我们接着骑行，前方又遇到了大堵车，很多时候我们都是在推着自行车走的。</p>
<p><img src="/images/2015-09-27-TraveltoQinghaiLake/2015-09-27-traffic.jpg" alt="traffic"></p>
<p>中午13点的时候，终于到达了我们定的青旅，因为定的这个青旅离黑马河镇上还有四公里多，结果导致骑在最前面的学长，骑过头了，很悲催，就只能骑回来了。定的这个青旅是八人间65元/人（住蒙古包的话50元/人，蒙古包晚上比较冷，而且是地铺，没有60的住得舒服），名字叫做<a href="http://bnb.qunar.com/city/hainanzangzu/dt-7481/?citytag=hainanzangzu#fromDate=2015-08-02&amp;toDate=2015-08-03&amp;q=%E9%BB%91%E9%A9%AC%E6%B2%B3&amp;filterid=92179149-08a2-4cea-a564-1e83a5abae19&amp;from=bnbDSearch%7Csug&amp;showMap=0&amp;QHFP=KZL_B682D07A&amp;QHPR=1_7_0_0" target="_blank" rel="external">青海湖拉毛叶措天堂牧家宾馆</a>。在青旅里休息一会之后，因为天气的原因，我们就在犹豫还是否去茶卡盐湖，为了不留遗憾，我们最后决定去茶卡盐湖。我们就让青旅的老板帮我联系去茶卡的车，我们6个人包了两辆车（300元/辆），在黑马河镇上买了一些零食以及泡面（晚饭，晚上可能会回来很晚）。在去黑马河的路上，感觉每翻过一座山，天气就不一样，黑马河这边还是阴天，结果翻了一座山之后，在去茶卡的路上都是晴天。到达茶卡镇的时候又遇到了堵车，虽然茶卡是阴天，但是来的人依然是路易不绝，两公里的路走了快一个小时。茶卡的门票是25元/人（学生票，成人票50），茶卡里有卖鞋套，鞋套是没有必要，盐湖里可以直接脱掉鞋下去玩的，不过要注意，湖里有很多黑色的洞，那些洞都很深，我们有一个队友就一下子掉进两次，水都到大腿那。在那呆了两个多小时之后，我们开始返回黑马河，到青旅的时候都快九点了，吃完泡面之后，我们就赶紧睡了。</p>
<p>Notes：</p>
<ul>
<li>黑马黑镇上去茶卡的车很多，基本上都是300一辆；</li>
<li>在茶卡那不用买什么鞋套，晴天比较好看，如果是阴天就差很多了；</li>
<li>下雨天骑车尽量=骑在白线以内，防止小石头扎破胎；</li>
<li>黑马河是青海观看日出的最佳地点（有日出的情况下）；</li>
</ul>
<p>茶卡盐湖：</p>
<p><img src="/images/2015-09-27-TraveltoQinghaiLake/2015-09-27-chaka.jpg" alt="chaka"></p>
<p>今日花费：<br>早饭19，中饭晚饭34，住宿65，茶卡门票25，包车86。</p>
<h3 id="8-4-Day3-黑马河——刚察县（115km）"><a href="#8-4-Day3-黑马河——刚察县（115km）" class="headerlink" title="8.4 Day3.黑马河——刚察县（115km）"></a>8.4 Day3.黑马河——刚察县（115km）</h3><p>今天应该是最期待的一天，因为黑马河是青海湖看日出的最佳地点，而且今天还是离湖最近的一天，不过今天也是骑行距离最远的一天。队友兵哥哥就是因为害怕骑不完，所以一路上基本上没怎么欣赏风景，一直在骑车，中饭都是带的干粮，结果是最早到达刚察县的。</p>
<p>早上五点多的时候，被师兄喊醒，说想看日出可以看日出了，当时那是一个困，黑马河那天睡的是最安稳的一个觉，但是为了看日出，还是决定起来了。那会天空中最东边有一道光，天空的其他地方都是阴沉沉的。而且那会有转晴的趋势，我们都很期待能看到日出，但是结果还是很令我们失望的，没看到青海湖的日出。带着遗憾我们开始出发了。好在我们出发的时候已经没有雨了，天气开始转晴了。在黑马河镇上吃完早饭（比江西沟便宜一些）之后，我们按着计划出发了。今天的天气非常好，我们看到了最美的青海湖，中间我们在青海湖湖边（去青海湖一个人5块钱）玩了将近一个小时。上午有三四个小时车程风景都特别好，这段路可以稍微骑慢一点，因为过了石乃亥之后，风景就一般了，就可以好好赶路程了，前面的风景还是好好欣赏才能不留遗憾。</p>
<p><img src="/images/2015-09-27-TraveltoQinghaiLake/2015-09-27-qh7.jpg" alt="qh7"></p>
<p>那天对我来说，还是挺悲催的，因为那边天气很干燥（感觉比北京要干燥很多，大家一定要多喝水），然后因为下雨的时候有点感冒，今天早上一起来的鼻子就流鼻血了。更悲催的是，在骑车的时候，突然流鼻血了，然后就是用卫生纸边塞着鼻子边骑车。骑到八十多公里时，还躺在草坪上休息半个多小时（那叫一个爽啊）。最后终于在七点多的时候骑到了刚察，我们定的是<a href="http://you.ctrip.com/food/qinghaihu281/151539-food.html#restaurant" target="_blank" rel="external">德吉央宗青年旅舍</a>，这个青旅（50元/人，可以洗澡）还不错。</p>
<p><img src="/images/2015-09-27-TraveltoQinghaiLake/2015-09-27-qh13.jpg" alt="qh13"></p>
<p>下面放几张自认为风景不错的照片（包括本人照哈）</p>
<p><img src="/images/2015-09-27-TraveltoQinghaiLake/j1.jpg" alt="j1"></p>
<p><img src="/images/2015-09-27-TraveltoQinghaiLake/j4.jpg" alt="j4"></p>
<p><img src="/images/2015-09-27-TraveltoQinghaiLake/j5.jpg" alt="j5"></p>
<p><img src="/images/2015-09-27-TraveltoQinghaiLake/j3.jpg" alt="j3"></p>
<p><img src="/images/2015-09-27-TraveltoQinghaiLake/j2.jpg" alt="j2"><br>因为刚擦是个县城，住宿的地方、吃饭的地方特别多，晚上就在大众点评上评价比较好的那家店吃的饭。下面这家的美食，很不错的。</p>
<p><img src="/images/2015-09-27-TraveltoQinghaiLake/2015-09-27-food.jpg" alt="food"></p>
<p>今天师兄带的无人机终于派上了用场，下面晒几张师兄用无人机拍的照片。</p>
<p><img src="/images/2015-09-27-TraveltoQinghaiLake/2015-09-27-qh8.JPG" alt="qh8"></p>
<p><img src="/images/2015-09-27-TraveltoQinghaiLake/2015-09-27-qh9.JPG" alt="qh9"></p>
<p><img src="/images/2015-09-27-TraveltoQinghaiLake/2015-09-27-qh10.JPG" alt="qh10"></p>
<p><img src="/images/2015-09-27-TraveltoQinghaiLake/2015-09-27-qh11.JPG" alt="qh11"></p>
<p><img src="/images/2015-09-27-TraveltoQinghaiLake/2015-09-27-qh12.JPG" alt="qh12"></p>
<p>Notes：</p>
<ul>
<li>在青海一定要多喝水；</li>
<li>今天行程比较远，大家一定要注意好时间，上午风景比较好，大家可以多玩玩，中午过了石乃亥之后就要抓紧时间赶路了；</li>
<li>今天也有几个比较大的坡，大家要注意了，还是多补充点能量，路上有卖西瓜的，大概1块一斤，还挺便宜的；</li>
</ul>
<p>今天的花费：<br>早饭13，中饭13，晚饭44，车胎14，看病59，住宿50。</p>
<h3 id="8-5-Day4-刚察县——西海镇（90km）"><a href="#8-5-Day4-刚察县——西海镇（90km）" class="headerlink" title="8.5 Day4.刚察县——西海镇（90km）"></a>8.5 Day4.刚察县——西海镇（90km）</h3><p>几天的路径虽然不算太长，但是今天是最后一天，而且前面50公里大部分都是在上坡，最蛋疼的是这段距离是逆风，基本上全程逆风，所以今天感觉是最累的，骑到西海镇的时候，我直接躺在床上休息了一个多小时才缓过劲。</p>
<p>第四天的油菜花：<br><img src="/images/2015-09-27-TraveltoQinghaiLake/2015-09-27-qh14.jpg" alt="qh14"></p>
<p>漫漫的长路：<br><img src="/images/2015-09-27-TraveltoQinghaiLake/2015-09-27-qh15.jpg" alt="qh15"></p>
<p>快到西海镇的那个小摊：<br><img src="/images/2015-09-27-TraveltoQinghaiLake/2015-09-27-qh16.jpg" alt="qh16"></p>
<p>晚饭我们是在西宁吃的，是师兄请的客，非常感谢谷歌那位师兄，下面晒几张西宁的美食：</p>
<p><img src="/images/2015-09-27-TraveltoQinghaiLake/2015-09-27-food3.jpg" alt="food3"></p>
<p><img src="/images/2015-09-27-TraveltoQinghaiLake/2015-09-27-food4.jpg" alt="food4"></p>
<p><img src="/images/2015-09-27-TraveltoQinghaiLake/2015-09-27-food2.jpg" alt="food2"></p>
<p>这几天的记录的骑行路线：</p>
<p><img src="/images/2015-09-27-TraveltoQinghaiLake/2015-09-27-qixing.jpg" alt="qixing"></p>
<p>Notes：</p>
<ul>
<li>刚察的早餐挺便宜的，比前面几个镇都好吃、都便宜；</li>
<li>刚出刚察的时候会有一个比较难爬的大坡，这个坡并不是最长的那个坡，中间有个坡当时我直接绝望了，推着上去的，因为又是逆风，所以不是一般的累。</li>
<li>前面三分之一的路还算比较好走，大多是平路，还有一些比较好的风景，而且有一段较长油菜花地，但我感觉没有第一天的油菜花好看。虽然是大都是平路，但逆风的原因，骑着还是很累的。</li>
<li>中间三分之一的路程是最困难的，最令人绝望的路段，这段路程开始进入山地，其间有几个个很长很高的上坡（其中最长有至少有三公里，爬的时候翻过一个山坡之后，发现前面居然还有一个山坡，这个坡真的用惨绝人寰才能形容）。</li>
<li>最后三分之一，也就是最后二十多公里的路段，有个超长的下坡，是这几天最爽的一段，一路狂奔，基本上不用怎么骑，一口气可以跑出二十公里，不过大家还是一定要注意安全的。</li>
</ul>
<p>今日花费：<br>吃饭35（晚饭是师兄请的，很感谢师兄），到西宁车费23，青旅住宿65.</p>
<h3 id="结束语"><a href="#结束语" class="headerlink" title="结束语"></a>结束语</h3><p>这次行程终于圆了我的环骑青海湖的梦，很高兴我当时能找到这几个小伙伴，在这几天里我们一起玩耍，给我留下很深刻的影响。</p>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[Storm之配置文件]]></title>
      <url>http://matt33.com/2015/07/27/storm-configuration/</url>
      <content type="html"><![CDATA[<p>Storm的配置文件一般存放在<code>$STORM_HOME/conf</code>下，通常名为<code>storm.yaml</code>，它符合yaml格式要求。Storm的配置参数对任务的稳定运行以及吞吐率至关重要，这里介绍一下storm常见的配置项参数。</p>
<h1 id="storm基本配置"><a href="#storm基本配置" class="headerlink" title="storm基本配置"></a>storm基本配置</h1><ul>
<li><strong>storm.local.dir</strong>: nimbus 和supervisor进程存储一些状态信息（conf或者jars）的本地路径，需要每台storm node单独创建该目录并保证该目录有正确的读写权限;</li>
<li><strong>storm.log4j2.conf.dir</strong>： log4j的配置目录;</li>
<li><strong>storm.zookeeper.servers</strong>: storm严重依赖zookeeper存储状态信息，要保证zookeeper的高可用，最好设置多个zk地址;</li>
<li><strong>storm.zookeeper.port</strong>: 默认2181;</li>
<li><strong>storm.zookeeper.root</strong>: 在zookeeper中存储的根目录，如果多个storm集群公用一个zk集群，需要修改其根目录名称即可;</li>
<li><strong>storm.session.timeout</strong>: 默认20s，nimbus和supervisor和zk的session超时时间，如果log中常用sessiontimeout错误，考虑增加其值或者修改gc参数。该值并不能无限设置，zk有自己的最大session时间（默认20 ticktime）；</li>
<li><strong>storm.zookeeper.connection.timeout</strong>：连接超时时间；</li>
<li><strong>storm.zookeeper.retry.times</strong>: 默认5，执行zk操作重试次数；</li>
<li><strong>storm.zookeeper.retry.interval</strong>: 默认1000，即间隔1s；</li>
<li><strong>storm.zookeeper.retry.intervalceiling.millis</strong>: 300000 （5分钟）执行重试的时间间隔最长时间；</li>
<li><strong>storm.messaging.transport</strong>：”backtype.storm.messaging.netty.Context” task之间的消息传输协议，默认使用netty传输；</li>
<li><strong>storm.cluster.mode</strong>: “distributed” storm集群模式；</li>
<li><strong>storm.id</strong>：运行中拓扑的id,由storm name和一个唯一随机数组成；</li>
<li><strong>storm.local.mode.zmq</strong>：Local模式下是否使用ZeroMQ作消息系统，如果设置为false则使用java消息系统。默认为false；<br>注：Storm严重依赖zookeeper，而且zk在分布式使用中扮演了非常重要的角色。</li>
</ul>
<h1 id="nimbus相关设置"><a href="#nimbus相关设置" class="headerlink" title="nimbus相关设置"></a>nimbus相关设置</h1><ul>
<li><strong>storm.nimbus.retry.times</strong>： 5 nimbus操作的重试次数</li>
<li><strong>storm.nimbus.retry.interval.millis</strong>： 2s 重试间隔</li>
<li><strong>storm.nimbus.retry.intervalceiling.millis</strong>: 60000 最大重试时间 10分钟</li>
<li><strong>nimbus.seeds</strong>: [] 用于leader nimbus发现的nimbus hosts 列表，解决nimbus的单点故障问题，代替了原来的nimbus.host 配置</li>
<li><strong>nimbus.thrift.port</strong>: 6627 nimbus工作的thrift端口，客户端上传jar和提交拓扑的端口（nimbus的thrift监听端口）</li>
<li><strong>nimbus.thrift.threads</strong>: 64 nimbus thrift 线程数目</li>
<li><strong>nimbus.thrift.max_buffer_size</strong>: 1048576 1m</li>
<li><strong>nimbus.childopts</strong>: “-Xmx1024m” nimbus java 进程jvm设置</li>
<li><strong>nimbus.task.timeout.secs</strong>：30 与task没有心跳时多久nimbus可以认为该task已经死掉并且可以重新分配该task</li>
<li><strong>nimbus.supervisor.timeout.secs</strong>: 60 一分钟没有心跳 nimbus可以认为该supervisor已经dead，不会分配新的work</li>
<li><strong>nimbus.monitor.freq.secs</strong>: 10 nimbus多久查询下supervisor心跳信息并且重新分配工作。注意当一台机子曾经挂掉，nimbus会立即采取一些操作</li>
<li><strong>nimbus.reassign</strong>：当发现task失败时nimbus是否重新分配执行。默认为真，不建议修改。</li>
<li><strong>nimbus.cleanup.inbox.freq.secs</strong>: 600 多久时间启动清理inbox文件的线程</li>
<li><strong>nimbus.inbox.jar.expiration.secs</strong>: 3600 一个小时 jar过期时间</li>
<li><strong>nimbus.code.sync.freq.secs</strong>: 300 5分钟同步一次未执行的拓扑的代码</li>
<li><strong>nimbus.task.launch.secs</strong>: 120 用于task 第一次启动时的超时时间</li>
<li><strong>nimbus.file.copy.expiration.secs</strong>: 600 上传下载文件超时时间</li>
<li><strong>nimbus.topology.validator</strong>: “backtype.storm.nimbus.DefaultTopologyValidator” 拓扑验证，控制该拓扑是否可以执行</li>
<li><strong>topology.min.replication.count</strong>: 1 当nimbus seeds中该拓扑代码的备份达到最小数目时leader nimbus才可以执行拓扑动作。</li>
<li><strong>topology.max.replication.wait.time.sec</strong>: 60 当代码备份在nimbus list中达到topology.min.replication.count设置的最大等待时间，如果超时，不管有没有最小备份个数，都要执行该拓扑</li>
</ul>
<h1 id="supervisor相关配置"><a href="#supervisor相关配置" class="headerlink" title="supervisor相关配置"></a>supervisor相关配置</h1><ul>
<li><strong>supervisor.slots.ports</strong>: 设置当台机子上可跑的worker数目，每个worker对应一个port，通常情况下多少个cpu core就设置多少个worker，类似与hadoop中nodemanager中slot的设置</li>
<li><strong>supervisor.childopts</strong>: “-Xmx256m” supervisor jvm参数设置</li>
<li><strong>supervisor.worker.start.timeout.secs</strong>: 120 supervisor等待worker启动的最长时间</li>
<li><strong>supervisor.worker.timeout.secs</strong>: 30 worker的最长超时时间</li>
<li><strong>supervisor.worker.shutdown.sleep.secs</strong>: 1秒 supervisor shutdown worker需要等待的时间</li>
<li><strong>supervisor.monitor.frequency.secs</strong>: 3s检查一次worker的心跳确保是否要重启这些worker</li>
<li><strong>supervisor.heartbeat.frequency.secs</strong>: 5s supervisor和nimbus心跳的频率</li>
<li><strong>supervisor.enable</strong>: true supervisor是否要启动分配它的worker</li>
</ul>
<h1 id="worker-配置"><a href="#worker-配置" class="headerlink" title="worker 配置"></a>worker 配置</h1><ul>
<li><strong>worker.childopts</strong>: “-Xmx768m”</li>
<li><strong>worker.gc.childopts</strong>: “” worker gc set 可以被topology.worker.gc.childopts.覆盖</li>
<li><strong>worker.heartbeat.frequency.secs</strong>: 1 worker 和supervisor的heartbeat时间</li>
<li><strong>topology.worker.receiver.thread.count</strong>: 1 每个worker设置的receiver 线程个数</li>
<li><strong>task.heartbeat.frequency.secs</strong>: 3s task向nimbus发送心跳的频率</li>
<li><strong>task.refresh.poll.secs</strong>: 10 多久和其他task同步连接（如果task重新分配，发往该task信息的那些task需要重练他们之间的连接）</li>
</ul>
<h1 id="message传递相关参数"><a href="#message传递相关参数" class="headerlink" title="message传递相关参数"></a>message传递相关参数</h1><ul>
<li><strong>storm.messaging.netty.server_worker_threads</strong>：1， server端接收信息的线程个数</li>
<li><strong>storm.messaging.netty.client_worker_threads</strong>: 1， client端发送信息的线程个数</li>
<li><strong>storm.messaging.netty.buffer_size</strong>: 5M，netty buffer大小</li>
<li><strong>storm.messaging.netty.max_retries</strong>: 300 重试次数</li>
<li><strong>storm.messaging.netty.max_wait_ms</strong>: 1000ms=1s 最大等待时间要大于task launchtime and worker launch time默认120s，重连间隔要大于zk的sessiontimeout 以确保worker是否已挂</li>
<li><strong>storm.messaging.netty.min_wait_ms</strong>: 100</li>
<li><strong>storm.messaging.netty.transfer.batch.size</strong>: 262144 如果netty 发送消息非常忙，client客户端可以batch发送消息，否则尽快的flush消息以减少延迟。</li>
</ul>
<blockquote>
<p>注：我们的使用场景是storm kafka读取kafka里面的数据，发现运行一段时间以后，kafka消费的offset不再更新（2s更新一次消费的offset），spout 中的task不断重启导致offset一直不更新，查看log发现task失败的原因是gc设置不对以致netty连接超时，task会重新分配。在生产环境中应该调大该值，我们在线上设置该值为20s，并且调整worker的gc参数。</p>
</blockquote>
<h1 id="topology相关的设置，-针对特定拓扑的配置"><a href="#topology相关的设置，-针对特定拓扑的配置" class="headerlink" title="topology相关的设置， 针对特定拓扑的配置"></a>topology相关的设置， 针对特定拓扑的配置</h1><p>正如上一讲的，以下参数控制消息是否被完全处理：</p>
<ul>
<li><strong>topology.enable.message.timeouts</strong>: true 保证数据完全处理；</li>
<li><strong>topology.acker.executors</strong>: null 设置acker线程个数；</li>
<li><strong>topology.message.timeout.secs</strong>: 30 当一个消息的处理超时多长时间多少认为该tuple处理失败；</li>
<li><strong>topology.max.spout.pending</strong>: null 当spout 发送一个tuple时会将该tuple放到一个pending list，此字段控制在storm中处理的spout tuple数，可以根据超时时间以及每秒处理的消息数估算；</li>
</ul>
<p>下面这几个参数和拓扑的并行度（parallelism)，并行度的概念就是为该拓扑启动的线程数，TopologyBuilder#setSpout() 和TopologyBuilder#setbolt()中可以指定excutor数目，该excutor是从worker进程spawn的线程，task是处理数据的实际工作单元，跑在一个excutor上。</p>
<ul>
<li><strong>topology.workers</strong>: 1，Config#setNumWorkers，设置worker数，一个worker执行一个拓扑的一个子集任务，其上可以跑多个excutors，可能是多个bolt或者spout；</li>
<li><strong>topology.tasks</strong>: null，top.setNumtasks，设置task数目；</li>
<li><strong>topology.max.task.parallelism</strong>: null，拓扑最大线程数；</li>
</ul>
<p>worker <strong>gc设置</strong></p>
<ul>
<li><strong>topology.worker.childopts</strong>: null；</li>
<li><strong>topology.worker.logwriter.childopts</strong>: “-Xmx64m”；</li>
<li><strong>topology.worker.shared.thread.pool.size</strong>: 4 worker task 共享线程池大小；</li>
</ul>
<p>worker内消息传送的参数，与disruptor相关：</p>
<ul>
<li><strong>topology.executor.receive.buffer.size</strong>: 1024 #batched；</li>
<li><strong>topology.executor.send.buffer.size</strong>: 1024 #individual messages；</li>
<li><strong>topology.transfer.buffer.size</strong>: 1024 # batched；</li>
<li><strong>topology.disruptor.wait.strategy</strong>:com.lmax.disruptor.BlockingWaitStrategy 延迟和吞吐率权衡；</li>
<li><strong>topology.disruptor.wait.timeout.millis</strong>: 1000 延迟和cpu使用权衡，使用长延时时会减少cpu使用，减少等待时间可以保证延时小，但cpu负载高；</li>
</ul>
<p>其他参数配置：</p>
<ul>
<li><strong>topology.debug</strong>: false debug模式关闭；</li>
<li><strong>topology.tick.tuple.freq.secs</strong>: null 用于定时处理逻辑的拓扑使用；</li>
<li><strong>topology.spout.wait.strategy</strong>: “backtype.storm.spout.SleepSpoutWaitStrategy” 两种情形下等待1. no data 2. 达到最大pending大小；</li>
<li><strong>topology.sleep.spout.wait.strategy.time.ms</strong>: 1 sleep时间；</li>
</ul>
<p>drpc logview ui的设置就不介绍了。</p>
<p>通过上面所讲的设置参数，可以发现gc设置和zookeeper设置非常重要，而且在message传输的相关设置中，有一系列参数如：receiver buffer size 、transfer buffer size，transfer buffer size，以及netty receiver thread 和worker receiver count 又有什么关系，上面提到到disruptor是什么东东，还有很多问题。所以在设置参数这个主题下还会再详细介绍下面三个问题：</p>
<ul>
<li>jvm 参数设置和调整，这个对于java程序的稳定运行至关重要（尤其是在大数据平台下，因为目前开源的大数据工具大部分都是java写的，jvm调优是必不可少的;</li>
<li>zookeeper的维护和管理，在hadoop生态系统以及分布式系统中中必不可少的工具</li>
<li>storm worker间和worker内的消息传递，包含disruptor的使用，通过这一节的介绍就会知道buffer size 设置为啥都是2的幂次方，这里buffer size 的单位是字节还是其他等等一些疑惑</li>
</ul>
<hr>
<p>参考：</p>
<ul>
<li><a href="http://xstarcd.github.io/wiki/Cloud/storm_config_detail.html" target="_blank" rel="external">Storm配置项详解</a></li>
</ul>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[Json文件的读取]]></title>
      <url>http://matt33.com/2015/07/13/json/</url>
      <content type="html"><![CDATA[<p>本人遇到的情况：在一个工程中需要引用另外一个jar包，而引用的jar里有Json配置文件，这里出现了Json文件找不到的错误。这实际上也是java从jar包中读取配置文件的问题。</p>
<h1 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a>问题描述</h1><p>取stackoverflow上的一个例子来说明。<br>我们的Json文件为：</p>
<figure class="highlight json"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">&#123;</div><div class="line">    <span class="attr">"pagination"</span>: &#123;</div><div class="line">        <span class="attr">"time"</span>: <span class="number">1</span>,</div><div class="line">        <span class="attr">"url"</span>: <span class="number">2</span>,</div><div class="line">        <span class="attr">"host"</span>: <span class="number">3</span>,</div><div class="line">        <span class="attr">"serverip"</span>: <span class="number">4</span>,</div><div class="line">        <span class="attr">"clientip"</span>: <span class="number">5</span></div><div class="line">    &#125;,</div><div class="line">    <span class="attr">"separator"</span>: <span class="string">"\t"</span></div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>下面是与Json文件对应的类：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div></pre></td><td class="code"><pre><div class="line"></div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">jsonLog</span> </span>&#123;</div><div class="line">	<span class="keyword">private</span> String separator;</div><div class="line">	<span class="keyword">private</span> Map&lt;String, Integer&gt; map;</div><div class="line"></div><div class="line">	<span class="function"><span class="keyword">public</span> String <span class="title">getSeparator</span><span class="params">()</span> </span>&#123;</div><div class="line">		<span class="keyword">return</span> separator;</div><div class="line">	&#125;</div><div class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setSeparator</span><span class="params">(String separator)</span> </span>&#123;</div><div class="line">		<span class="keyword">this</span>.separator = separator;</div><div class="line">	&#125;</div><div class="line">	<span class="function"><span class="keyword">public</span> Map&lt;String, Integer&gt; <span class="title">getMap</span><span class="params">()</span> </span>&#123;</div><div class="line">		<span class="keyword">return</span> map;</div><div class="line">	&#125;</div><div class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setMap</span><span class="params">(Map&lt;String, Integer&gt; map)</span> </span>&#123;</div><div class="line">		<span class="keyword">this</span>.map = map;</div><div class="line">	&#125;</div><div class="line"></div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>目的是将Json文件的内容读取到jsonLog对象中，遇到两个问题：</p>
<ol>
<li>Json文件是存在config目录下，打jar包时如何将Json文件连同config目录一同打入jar包；</li>
<li>Json文件打进jar包，其他工程再引用该jar包时，此时Json所在目录已经变化，如何动态获取Json文件所在位置。</li>
</ol>
<h1 id="打jar包"><a href="#打jar包" class="headerlink" title="打jar包"></a>打jar包</h1><p>这里需要修改Maven工程的pom文件，加入以下内容：</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">&lt;build<span class="string">&gt;</span></div><div class="line">	&lt;resources&gt;</div><div class="line">		&lt;resource&gt;</div><div class="line">			&lt;directory&gt;config&lt;/directory&gt;</div><div class="line">				&lt;includes&gt;</div><div class="line">					&lt;include&gt;**/*.json&lt;/include&gt;</div><div class="line">				&lt;/includes&gt;</div><div class="line">			&lt;targetPath&gt;config&lt;/targetPath&gt;</div><div class="line">		&lt;/resource&gt;</div><div class="line">	&lt;/resources&gt;</div><div class="line">&lt;/build&gt;</div></pre></td></tr></table></figure>
<p>这几行的意思就是打包时把目录<code>config</code>（directory）下的json文件也打进去，并且放<code>在config</code>（targetPath）目录下。</p>
<h1 id="读取Json文件"><a href="#读取Json文件" class="headerlink" title="读取Json文件"></a>读取Json文件</h1><p>动态获得json文件位置并读取的代码实现：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">objectMapper = <span class="keyword">new</span> ObjectMapper();</div><div class="line">InputStream inputstream = <span class="keyword">this</span>.getClass().getResourceAsStream(<span class="string">"/config/xx.json"</span>);</div><div class="line">LogConfig config = objectMapper.readValue(inputstream, LogConfig.class);</div></pre></td></tr></table></figure>
<p>通过<code>Class</code>类的<code>getResourceAsStream()</code>方法来获取Json文件，这种方法是专门读取jar中的资源文件的。可参考<a href="http://blog.csdn.net/b_h_l/article/details/7767829" target="_blank" rel="external">java从jar包中读取资源文件</a>一文。</p>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[Storm简单介绍]]></title>
      <url>http://matt33.com/2015/05/26/the-basis-of-storm/</url>
      <content type="html"><![CDATA[<p>本文是参考网上的博客以及一些书籍根据自己的一些理解整理得到的，主要是为了更好地理解storm的内部机制（当时使用Storm的版本是<code>0.9.3</code>）。</p>
<h1 id="基础"><a href="#基础" class="headerlink" title="基础"></a>基础</h1><h2 id="Storm的Topology模型"><a href="#Storm的Topology模型" class="headerlink" title="Storm的Topology模型"></a>Storm的Topology模型</h2><p>一个storm Topology的一般模型为：</p>
<p><img src="/images/2015-05-26-theBasisOfStorm/2015-05-26-topology.png" alt="topology"></p>
<h3 id="tuple"><a href="#tuple" class="headerlink" title="tuple"></a>tuple</h3><p>storm中传输的数据类型是tuple，tuple到底是什么？感觉还是用英语来说比较容易理解吧，”A tuple is a named of values where each value can be any type.”  tuple是一个类似于列表的东西，存储的每个元素叫做field（字段）。我们用getString(i)可以获得tuple的第i个字段。而其中的每个字段都可以任意类型的，也可以一个很长的字符串。我们可以用：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">String A = tuple.getString(<span class="number">0</span>);</div><div class="line"><span class="keyword">long</span> a= tuple.getLong(<span class="number">1</span>);</div></pre></td></tr></table></figure>
<p>来拿到我们所需的数据，不过前提你是要知道你的tuple的组成。具体tuple是什么类型，完全取决于自己的程序，取决于spout中nextTuple()方法中emit发送的类型。<br>storm的streams就是一个无限的tuple流，我们可以把storm tuples当做CEP(complex event processing)中events来理解。</p>
<h3 id="spout"><a href="#spout" class="headerlink" title="spout"></a>spout</h3><p>spout是storm topology的数据入口，连接到数据源，将数据转换为一个个tuple，并将tuple作为数据流进行发射。一个spout可以供多个topology使用。通常spouts从外部资源读取元组，然后发射元组到拓扑中（例如，Kestrel队列或Twitter API）。Spouts即可以是可靠的，也可是不可靠的。可靠的spout可以重新执行一个失败元组，但一个不可靠的spout一发射元组就会忘记它。</p>
<p>Spouts可以发射多个流。要发射多个流，使用OutputFieldDeclarer的declareStream方法声明多个流，并在使用SpoutOutputCollector的emit方法时指定流ID。但是由于由spouts和bolts组成的单流应用最为普遍，因此OutputFieldDeclarer提供便利的方法声明一个不需要指定ID的单流，此时，流被分配一个默认ID为“default”。</p>
<p>Spouts的重要方法是nextTuple方法。nextTuple方法发射一个新的元组到拓扑，或如果没有新的元组发射，简单的返回。注意任务spout的nextTuple方法都不要实现成阻塞的，因为storm是在相同的线程中调用spout的方法。</p>
<p>Spout的另外两个重要方法是ack和fail方法。当spout发射的元组被拓扑成功处理时，调用ack方法；当处理失败时，调用fail方法。Ack和fail方法仅被可靠spouts调用。</p>
<h3 id="bolt"><a href="#bolt" class="headerlink" title="bolt"></a>bolt</h3><p>bolt可以理解为计算机程序中的运算或函数，将一个或者多个数据流作为输入，对数据实施运算后，选择性地输出一个或者多个数据流。一个bolt可以订阅(subscribe)多个由spout或其他bolt发射的数据流。</p>
<p>Topology中的所有处理都在bolts中完成。Bolts什么都可以做，如过滤、业务功能、聚合、连接（合并）、访问数据库等等。</p>
<p>Bolts可以做简单的流转换。复杂的流转换经常需要多步完成，因此也需要多个bolts。例如，转换tweets数据流到流行图片数据流至少需要两步：一个bolt 对retweets的图片进行滚动计数，另外的bolt找出Top X（前几位）的图片（你可以用更具伸缩性的方式处理这部分流）。</p>
<p>Bolts可以发射多个流。要发射多个流，使用OutputFieldDeclarer的declareStream方法声明多个流，并在使用SpoutOutputCollector的emit方法时指定流ID。</p>
<p>当你声明一个bolt的输入流时，你总是以另一个组件的指定流作为输入。如果你想订阅另一个组件的所有流，你必须分别订阅每一个流。InputDeclarer提供了使用默认流ID订阅流的语法糖，调用declarer.shuffleGrouping(“1”)订阅组件“1”上的默认流，作用等同于declarer.shuffleGrouping(“1”, DEFAULT_STREAM_ID)。</p>
<p>Bolts的主要方法是execute方法，任务在一个新的元组输入时执行该方法。Bolts使用OutputCollector对象发射新的元组。Bolts必须对每个处理的元组调用OutputCollector的ack方法，因此storm知道这个元组完成处理（并且能最终确定ack原始元组是安全的）。一般情况，处理一个输入元组，基于此元组再发射0-N个元组，然后ack输入元组。Strom提供了一个IBasicBolt接口自动调用ack方法。</p>
<p>在Bolts中载入新的线程进行异步处理。OutputCollector是线程安全的，并随时都可调用它。</p>
<h3 id="Streams"><a href="#Streams" class="headerlink" title="Streams"></a>Streams</h3><p>Storm核心的抽象概念是“流”。流是一个分布式并行创建和处理的无界的连续元组（tuple）。流通过一种模式来定义，该模式是给流元组中字段命名。默认情况下，元组可以包含整型、长整型、短整型、字节、字符串、双精度浮点数、单精度浮点数、布尔型和字节数组。您还可以自定义序列化，在元组中使用自定义类型。</p>
<p>而消息流Streams是storm里的最关键的抽象。一个消息流是一个没有边界的tuple序列，而这些tuples会被以一种分布式的方式并行地创建和处理。对消息流的定义主要是对消息流里面的tuple的定义， 我们会给tuple里的每个字段一个名字。 并且不同tuple的对应字段的类型必须一样。 也就是说： 两个tuple的第一个字段的类型必须一样， 第二个字段的类型必须一样， 但是第一个字段和第二个字段可以有不同的类型。 在默认的情况下， tuple的字段类型可以是： integer, long, short, byte, string, double, float, boolean和byte array。 你还可以自定义类型 — 只要你实现对应的序列化器。</p>
<h2 id="storm并发机制"><a href="#storm并发机制" class="headerlink" title="storm并发机制"></a>storm并发机制</h2><p>在 Storm 的间接中提到过,Storm 计算支持在多台机器上水平扩容,通过将计算切分为多个独立的 tasks 在集群上并发执行来实现。在 Storm 中,一个 <strong>task</strong> 可以简单地理解为在集群某节点上运行的一个spout 或者 bolt 实例。</p>
<ul>
<li><p><strong>Nodes</strong>： 指配置在一个 Storm 集群中的服务器,会执行 topology 的一部分运算。一个 Storm 集群可以包括一个或者多个工作 node。</p>
</li>
<li><p><strong>Workers</strong>(JVM虚拟机)：指一个 node 上相互独立运行的 JVM 进程。每个 node 可以配置运行一个或者多个 worker。一个 topology 会分配到一个或者多个 worker 上运行。</p>
</li>
<li><strong>Executeor</strong>：指一个 worker 的 jvm 进程中运行的 Java 线程。多个 task 可以指派给同一个 executer 来执行。除非是明确指定,Storm 默认会给每个 executor 分配一个 task。</li>
<li><strong>Task</strong>：task 是 spout 和 bolt 的 实 例, 它 们 的 nextTuple() 和execute() 方法会被executors 线程调用执行。</li>
</ul>
<h3 id="默认的并发机制"><a href="#默认的并发机制" class="headerlink" title="默认的并发机制"></a>默认的并发机制</h3><p>在我们修改 topology 的并发度之前,先来看默认配置下 topology 是如何执行的。假设<br>我们有一台服务器(node),为 topology 分配了一个 worker,并且每个 executer 执行一个<br>task。我们的 topology 执行过程如下图：</p>
<p><img src="/images/2015-05-26-theBasisOfStorm/2015-05-26-Node1.png" alt="Node1"></p>
<p>正如在图中看到的,唯一的并发机制出现在线程级。每个任务在同一个 JVM 的不<br>同线程中执行。如何增加并发度以充分利用硬件能力?让我们来增加分配给 topology 的<br>worker 和 executer 的数量。</p>
<h3 id="给topology增加worker"><a href="#给topology增加worker" class="headerlink" title="给topology增加worker"></a>给topology增加worker</h3><p>增加额外的 worker 是增加 topology 计算能力的简单方法。为此 Storm 提供了 API 和修改配置项两种修改方法。无论采取哪种方法,spout 和 bolt 组件都不需要做变更,可以直接复用。<br>为了增加分配给一个 topology 的worker 数量,只需要简单的调用一下Config对象的setNumWorkers()方法:</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">Config.config = <span class="keyword">new</span> Config();</div><div class="line">config.setNumworkers(<span class="number">2</span>);</div></pre></td></tr></table></figure>
<p>这样就给 topology 分配了两个 worker 而不是默认的一个。从而增加了 topology 的计算资源,也更有效的利用了计算资源。我们还可以调整 topology 中的 executor 个数以及每个 executor 分配的 task 数量。</p>
<h3 id="配置executor和task"><a href="#配置executor和task" class="headerlink" title="配置executor和task"></a>配置executor和task</h3><p>我们已经知道,Storm 给 topology 中定义的每个组件建立一个 task,默认的情况下,每个 task 分配一个 executor。Storm 的并发机制 API 对此提供了控制方法,允许设定每个task 对应的 executor 个数和每个 executor 可执行的 task 的个数。<br>在定义数据流分组时,可以设置给一个组件指派的 executor 的数量。为了说明这个功能,修改 topology 的定义代码,设置 SentenceSpout 并发为两个 task,每个 task 指派各自的 executor 线程。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">builder.setSpout (SENTENCE_SPOUT_ID, spout, <span class="number">2</span>);</div></pre></td></tr></table></figure>
<p>如果只使用一个 worker,topology 的执行如下图所示：</p>
<p><img src="/images/2015-05-26-theBasisOfStorm/2015-05-26-Node2.png" alt="Node2"></p>
<p>我们给语句分割 bolt SplitSentenceBolt 设置 4 个 task 和 2 个 executor。每个executor 线程指派 2 个 task 来执行(4/2=2)。还将配置单词计数 bolt 运行四个 task,每个task 由一个 executor 线程执行:</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">builder.setBolt(SPLIT_BOLT_ID, splitBolt, <span class="number">2</span>).setNumTasks(<span class="number">4</span>).shuffleGrouping(SENTENCE_SPOUT_ID);</div><div class="line"></div><div class="line">builder.setBolt(COUNT_BOLT_ID, countBolt, <span class="number">4</span>).fieldsGrouping(SPLIT_SPOUT_ID, <span class="keyword">new</span> Fields(<span class="string">"word"</span>));</div></pre></td></tr></table></figure>
<p>在2个worker的情况下，topology的执行如图所示：</p>
<p><img src="/images/2015-05-26-theBasisOfStorm/2015-05-26-Node3.png" alt="Node3"></p>
<p>要重点指出的是,当 topology 执行在本地模式时,增加 worker 的数量不会达到提高速度的效果。因为 topology 在本地模式下是在同一个 JVM 进程中执行的,所以只有增加 task 和 executor 的并发度配置才会生效。Storm 的本地模式提供了接近集群模式的模拟,对开发是否有帮助。但程序在投入生产环境之前,必须在真实的集群环境下进行测试。</p>
<h2 id="数据流分组"><a href="#数据流分组" class="headerlink" title="数据流分组"></a>数据流分组</h2><p>Storm 定义了七种内置数据流分组的方式:</p>
<ul>
<li><strong>Shuffle grouping</strong>(随即分组)：这种方式会随机分发 tuple 给 bolt 的各个 task,每个bolt 实例接收到的相同数量的 tuple;</li>
<li><strong>Fields grouping</strong>(按字段分组)：根据指定字段的值进行分组。比如说,一个数据流根据“ word ”字段进行分组,所有具有相同“ word ”字段值的 tuple 会路由到同一个 bolt 的 task 中；</li>
<li><strong>All grouping</strong>(全复制分组)：将所有的 tuple 复制后分发给所有 bolt task。每个订阅数据流的 task 都会接收到 tuple 的拷贝；</li>
<li><strong>Globle Grouping</strong>(全局分组)：这种分组方式将所有的 tuples 路由到唯一一个 task 上。Storm 按照最小的 task ID 来选取接收数据的 task。注意,当使用全局分组方式时,设置 bolt 的 task 并发度是没有意义的,因为所有 tuple 都转发到同一个 task 上了。使用全局分组的时候需要注意,因为所有的 tuple 都转发到一个 JVM 实例上,可能会引起 Storm 集群中某个 JVM 或者服务器出现性能瓶颈或崩溃；</li>
<li><strong>None grouping</strong>(不分组)：在功能上和随机分组相同,是为将来预留的；</li>
<li><strong>Direct gouping</strong>(直接分组/指向型分组)：数据源会调用 emitDirect() 方法来判断一个 tuple 应该由哪个 Storm 组件来接收。只能在声明了是指向型的数据流上使用；</li>
<li><strong>Local or shuffle grouping</strong>(本地或随即分组)：和随机分组类似,但是,会将 tuple 分发给同一个 worker 内的 bolt task(如果 worker 内有接收数据的 bolt task)。其他情况下,采用随机分组的方式。取决于 topology 的并发度,本地或随机分组可以减少网络传输,从而提高 topology 性能。</li>
</ul>
<p>除了预定义好的分组方式之外,还可以通过实现 CustomStreamGrouping(自定义分组)<br>接口来自定义分组方式:</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> backtype.storm.generated.GlobalStreamId;</div><div class="line"><span class="keyword">import</span> backtype.storm.task.WorkerTopologyContext;</div><div class="line"><span class="keyword">import</span> java.io.Serializable;</div><div class="line"><span class="keyword">import</span> java.util.List;</div><div class="line"></div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">CustomStreamGrouping</span> <span class="keyword">extends</span> <span class="title">Serializable</span> </span>&#123;</div><div class="line">     <span class="function"><span class="keyword">void</span> <span class="title">prepare</span><span class="params">(WorkerTopologyContext context, GlobalStreamId stream, List&lt;Integer&gt; targetTasks)</span></span>;<span class="comment">//prepare()方法在调用时，用来初始化分组信息，分组的具体实现会使用这些信息决定如何向接收task分发tuple。WorkerTopologyContext 对象提供了topology的上下文信息，GlobalStreamId提供了待分组数据流的属性，targetTasks时分组所有待选task的标识符列表。</span></div><div class="line"></div><div class="line">     <span class="comment">//会将 targetTasks 的引用存在变量里作为 chooseTasks() 的参数</span></div><div class="line">    <span class="function">List&lt;Integer&gt; <span class="title">chooseTasks</span><span class="params">(<span class="keyword">int</span> taskId, List&lt;Object&gt; values)</span></span>; <span class="comment">//chooseTasks() 方法返回一个 tuple 发送目标 task 的标识符列表。它的两个参数是发送tuple 的组件的 id 和 tuple 的值。</span></div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h2 id="可靠的消息处理机制"><a href="#可靠的消息处理机制" class="headerlink" title="可靠的消息处理机制"></a>可靠的消息处理机制</h2><p>Storm 提供了一种 API 能够保证 spout 发送出来的每个 tuple 都能够执行完整的处理过程。</p>
<p>在storm里一个tuple被完全处理的意思是：这个tuple以及由这个tuple所导致的所有的tuple都被成功处理。而一个tuple会被认为处理失败了如果这个tuple在timeout所指定的时间内没有成功处理。而这个<code>timeout</code>可以通过<code>Config.TOPOLOGY_MESSAGE_TIMEOUT_SECS</code>来指定。</p>
<p>作为storm的使用者，有两件事情要做以更好的利用storm的可靠性特征。 首先，在你生成一个新的tuple的时候要通知storm; 其次，完成处理一个tuple之后要通知storm。 这样storm就可以检测整个tuple树有没有完成处理，并且通知源spout处理结果。storm提供了一些简洁的api来做这些事情。</p>
<h3 id="spout的可靠性"><a href="#spout的可靠性" class="headerlink" title="spout的可靠性"></a>spout的可靠性</h3><p>在有保障数据的处理过程中,bolt每收到一个 tuple,都需要向上游确认应答(ack)者报错。对主干 tuple 中的一个 tuple,如果 tuple 树上的每个 bolt 进行了确认应答,spout 会调用 ack 方法来标明这条消息已经完全处理了。如果树中任何一个 bolt 处理 tuple 报错,或者处理超时,spout 会调用 fail方法。<br>tuple树的结构如图：</p>
<p><img src="/images/2015-05-26-theBasisOfStorm/2015-05-26-tuple_tree.png" alt="tuple_tree"></p>
<p>Spout的nextuple()发送一个tuple，为了实现可靠的消息处理，首先要给每个发出的tuple带上唯一的ID，并且将ID作为参数传递给SpoutOutputCollector的emit()方法：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">collector.emit(<span class="keyword">new</span> Values(<span class="string">"value1"</span>,<span class="string">"value2"</span>),msgId);</div></pre></td></tr></table></figure>
<p>接下来，这个发射的tuple被传送到消息处理者bolt那里，storm会跟踪由此所产生的这课tuple树。如果storm检测到一个tuple被完全处理了，那么storm会以最开始的那个message-id作为参数来调用消息源的ack方法；反之storm会调用spout的fail方法。要注意的是，storm调用ack或者fail的task始终是产生这个tuple的那个task。所以如果一个spout被分成很多个task来执行，消息执行的成功失败与否始终会通知最开始发出tuple的那个task。</p>
<p>给tuple指定ID告诉Storm系统，无论执行成功还是失败，spout都要接收所有发出tuple返回的通知。如果处理成功，spout的ack()方法将会对编号是ID的消息应答确认，如果执行失败或者超时，会调用fail()方法。</p>
<h3 id="bolt的可靠性"><a href="#bolt的可靠性" class="headerlink" title="bolt的可靠性"></a>bolt的可靠性</h3><p>bolt要实现可靠的消息处理机制要包含两个步骤：</p>
<ol>
<li>当发射衍生的tuple时，需要锚定读入的tuple；</li>
<li>当处理消息成功或者失败时分别确认应答或者报错。</li>
</ol>
<p>由一个tuple产生一个新的tuple称为：anchoring(锚定)。你发射一个新tuple的同时也就完成了以西anchring。</p>
<p>锚定一个tuple的意思是，建立读入tuple和衍生出的tuple之间的对应关系，这样下游的bolt就可以通过应答确认，报错或超时来加入到tuple树结构中。<br>可以通过调用OutputCollect中emit()的一个重载函数锚定一个或者一组tuple：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">collector.emit(tuple, <span class="keyword">new</span> Values(word));<span class="comment">//anchoring</span></div></pre></td></tr></table></figure>
<p>这里，我们将读入的tuple和发射的新tuple锚定(anchoring)起来，下游的bolt就需要对输出的tuple进行确认应答或者报错。因为这个tuple被anchoring在上一个tuple， 这整个就构成了tuple树，如果这一级tuple处理出错了，那么这整个tuple处理过程都会被重新处理。</p>
<p>另外一个emit()方法会发射非锚定的tuple：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">collector.emit(<span class="keyword">new</span> Values(word));<span class="comment">// unanchoring</span></div></pre></td></tr></table></figure>
<p>用这种方法发射会导致新发射的这个tuple脱离原来的tuple树(unanchoring), unanchoring的tuple不会对数据流的可靠性起作用。如果一个unanchoring的tuple在下游处理过程中失败了，原始的根tuple是不会重新发送，到底要anchoring还是要 unanchoring则完全取决于你的业务需求。﻿</p>
<p>当处理完成或者发送了新tuple之后，可靠数据流中的bolt需要应答读入的tuple：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">this</span>.collector.ack(tuple);</div></pre></td></tr></table></figure>
<p>如果处理失败，这样的话spout必须发射tuple，bolt就要明确地对处理失败的tuple报错：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">this</span>.collector.fail(tuple);</div></pre></td></tr></table></figure>
<p>如果因为超时的原因，或者显式调用OutputCollector.fail()方法，spout都会重新发送源是的tuple。</p>
<p>每个处理tuple，都必须进行ack或者fail。因为storm会追踪每个tuple要占用内存。所以如果你不ack/fail每一个tuple，那么最终年会看到<code>OutOfMemory</code>错误。</p>
<p>对于SplitSentence这一部分，如果用IRichBolt来做：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">SplitSentence</span> <span class="keyword">implements</span> <span class="title">IRichBolt</span> </span>&#123;</div><div class="line">        OutputCollector _collector;</div><div class="line"></div><div class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">prepare</span><span class="params">(Map conf,</span></span></div><div class="line">                            TopologyContext context,</div><div class="line">                            OutputCollector collector) &#123;</div><div class="line">            _collector = collector;</div><div class="line">        &#125;</div><div class="line"></div><div class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">execute</span><span class="params">(Tuple tuple)</span> </span>&#123;</div><div class="line">            String sentence = tuple.getString(<span class="number">0</span>);</div><div class="line">            <span class="keyword">for</span>(String word: sentence.split(<span class="string">" "</span>)) &#123;</div><div class="line">                _collector.emit(tuple, <span class="keyword">new</span> Values(word));</div><div class="line">            &#125;</div><div class="line">            _collector.ack(tuple);</div><div class="line">        &#125;</div><div class="line"></div><div class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">cleanup</span><span class="params">()</span> </span>&#123;</div><div class="line">        &#125;</div><div class="line"></div><div class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">declareOutputFields</span><span class="params">(OutputFieldsDeclarer declarer)</span> </span>&#123;</div><div class="line">            declarer.declare(<span class="keyword">new</span> Fields(<span class="string">"word"</span>));</div><div class="line">        &#125;</div><div class="line">    &#125;</div></pre></td></tr></table></figure>
<p>大多数Bolt遵循这样的规律：读取一个tuple；发射一些新的tuple；在execute的结束的时候ack这个tuple。这些Bolt往往是一些过滤器或者简单函数。Storm为这类规律封装了一个BasicBolt类。如果用BasicBolt来做， 上面那个SplitSentence可以写成这样：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">SplitSentence</span> <span class="keyword">implements</span> <span class="title">IBasicBolt</span> </span>&#123;</div><div class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">prepare</span><span class="params">(Map conf,</span></span></div><div class="line">                            TopologyContext context) &#123;</div><div class="line">        &#125;</div><div class="line"></div><div class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">execute</span><span class="params">(Tuple tuple,</span></span></div><div class="line">                            BasicOutputCollector collector) &#123;</div><div class="line">            String sentence = tuple.getString(<span class="number">0</span>);</div><div class="line">            <span class="keyword">for</span>(String word: sentence.split(<span class="string">" "</span>)) &#123;</div><div class="line">                collector.emit(<span class="keyword">new</span> Values(word));</div><div class="line">            &#125;</div><div class="line">        &#125;</div><div class="line"></div><div class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">cleanup</span><span class="params">()</span> </span>&#123;</div><div class="line">        &#125;</div><div class="line"></div><div class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">declareOutputFields</span><span class="params">(</span></span></div><div class="line">                        OutputFieldsDeclarer declarer) &#123;</div><div class="line">            declarer.declare(<span class="keyword">new</span> Fields(<span class="string">"word"</span>));</div><div class="line">        &#125;</div><div class="line">    &#125;</div></pre></td></tr></table></figure>
<p>这个实现比之前的实现简单多了， 但是功能上是一样的。发送到BasicOutputCollector的tuple会自动和输入tuple相关联，而在execute方法结束的时候那个输入tuple会被自动ack的。</p>
<h3 id="acker"><a href="#acker" class="headerlink" title="acker"></a>acker</h3><p>storm里面有一类特殊的task称为：acker， 他们负责跟踪spout发出的每一个tuple的tuple树。当acker发现一个tuple树已经处理完成了。它会发送一个消息给产生这个tuple的那个task。你可以通过<code>Config.TOPOLOGY_ACKERS</code>来设置一个topology里面的acker的数量， 默认值是一。 如果你的topology里面的tuple比较多的话， 那么把acker的数量设置多一点，效率会高一点.</p>
<p>理解storm的可靠性的最好的方法是来看看tuple和tuple树的生命周期， 当一个tuple被创建， 不管是spout还是bolt创建的， 它会被赋予一个64位的id，而acker就是利用这个id去跟踪所有的tuple的。每个tuple知道它的祖宗的id(从spout发出来的那个tuple的id), 每当你新发射一个tuple， 它的祖宗id都会传给这个新的tuple。所以当一个tuple被ack的时候，它会发一个消息给acker，告诉它这个tuple树发生了怎么样的变化。具体来说就是：它告诉acker： 我呢已经完成了， 我有这些儿子tuple, 你跟踪一下他们吧。下面这个图演示了C被ack了之后，这个tuple树所发生的变化。<br>tuple ack示例:</p>
<p><img src="/images/2015-05-26-theBasisOfStorm/2015-05-26-acker.png" alt="acker"></p>
<p>关于storm怎么跟踪tuple还有一些细节， 前面已经提到过了， 你可以自己设定你的topology里面有多少个acker。而这又给我们带来一个问题， 当一个tuple需要ack的时候，它到底选择<code>哪个acker</code>来发送这个信息呢？</p>
<p>storm使用一致性哈希来把一个spout-tuple-id对应到acker， 因为每一个tuple知道它所有的祖宗的tuple-id， 所以它自然可以算出要通知哪个acker来ack。（这里所有的祖宗是指这个tuple所对应的所有的根tuple。这里注意因为一个tuple可能存在于多个tuple树，所以才有所有一说）。</p>
<p>storm的另一个细节是acker是怎么知道每一个spout tuple应该交给哪个task来处理。当一个spout发射一个新的tuple， 它会简单的发一个消息给一个合适的acker，并且告诉acker它自己的id(taskid)， 这样storm就有了taskid-tupleid的对应关系。 当acker发现一个树完成处理了， 它知道给哪个task发送成功的消息.</p>
<p>acker task并不现式的跟踪tuple树。对于那些有成千上万个节点的tuple树，把那么多的tuple信息都跟踪起来会消耗太多的内存。相反，acker永了一种不同的凡是，使得对于每一个spout tuple所需要的内存量都是恒定的(20bytes)。这个<strong>跟踪算法</strong>是storm如何工作的关键。</p>
<h1 id="Storm集群框架"><a href="#Storm集群框架" class="headerlink" title="Storm集群框架"></a>Storm集群框架</h1><h2 id="nimbus守护进程"><a href="#nimbus守护进程" class="headerlink" title="nimbus守护进程"></a>nimbus守护进程</h2><p>nimbus守护进程的主要职责是管理，协调和监控在集群上运行的topology。包括topology的发布，任务支派，事件处理失败时重新指派任务。</p>
<p>将topology发布到Storm集群，将预先打包的jar文件的topology和配置信息提交到nimbus服务器上，一旦nimbus接收到了topology的压缩包，会将jar包分发到足够数量的supervisor节点上。当supervisor节点接收到了topology压缩文件，nimbus就会指派task(bolt和spout实例)到每个supervisor并且发送信号指示supervisor生成足够的worker来执行指派的task。</p>
<p>nimbus记录所有supervisor节点的状态和分配给它们的task。如果nimbus发现某个supervisor没有上报心跳或者已经不可达了，它会将故障supervisor分配的task重新分配到集群中的其他supervisor节点。</p>
<p>严格意义上讲 nimbus 不会引起单点故障。这个特性是因为 nimubs 并不参与 topology 的数据处理过程,它仅仅是管理 topology 的初始化,任务分发和进行监控。实际上,如果 nimbus 守护进程在 topology 运行时停止了,只要分配的 supervisor 和worker 健康运行,topology 一直继续数据处理。要注意的是,在 nimbus 已经停止的情况下 supervisor 异常终止,因为没有 nimbus 守护进程来重新指派失败这个终止的 supervisor的任务,数据处理就会失败。</p>
<h2 id="supervisor守护进程"><a href="#supervisor守护进程" class="headerlink" title="supervisor守护进程"></a>supervisor守护进程</h2><p>supervisor守护进程等待nimbus分配任务后生成并监控workers(JVM进程)执行任务。supervisor和worker都是运行在不同的 JVM 进程上,如果由 supervisor 拉起的一个woker 进程因为错误(或者因为 Unix 终端的 kill-9 命令,Window 的 tskkill 命令强制结束)异常退出,supervisor 守护进程会尝试重新生成新的 worker 进程。</p>
<p>如果一个worker甚至整个supervisor节点都故障了，Storm怎么保障出错时正在处理的tuples的传输呢？答案就在Storm的tuple的锚定和应答确认机制中。当打开了可靠i传输的选项，传输到故障节点上的tuples将不会收到应答确认，spout会因为超时而重新发射原始的tuple。这样的过程会一直重复直到topology从故障中恢复开始正常处理数据。</p>
<h2 id="Zookeeper的作用"><a href="#Zookeeper的作用" class="headerlink" title="Zookeeper的作用"></a>Zookeeper的作用</h2><p>Storm 主要使用 ZooKeeper 来协调一个集群中的状态信息,比如任务的分配情况,worker 的状态,supervisor 之间的 nimbus 的拓扑度量。nimbus 和 supervisor 节点之间的通信主要是结合 ZooKeeper 的状态变更通知和监控通知来处理的。</p>
<h1 id="Storm程序框架"><a href="#Storm程序框架" class="headerlink" title="Storm程序框架"></a>Storm程序框架</h1><h2 id="topology提交"><a href="#topology提交" class="headerlink" title="topology提交"></a>topology提交</h2><h3 id="本地模式"><a href="#本地模式" class="headerlink" title="本地模式"></a>本地模式</h3><p>使用LocalCluster类将topolog运行在本地模式：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">LocalCluster cluster=<span class="keyword">new</span> LocalCluster();</div><div class="line">cluster.submitTopology(TOPOLOGY_NAME, config, builder.createTopology());</div></pre></td></tr></table></figure>
<p>一般得例子为：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">LocalRunningTopology</span> <span class="keyword">extends</span> <span class="title">ExclaimBasicTopo</span> </span>&#123;</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</div><div class="line"></div><div class="line">        LocalRunningTopology topo = <span class="keyword">new</span> LocalRunningTopology();</div><div class="line">        Config conf = <span class="keyword">new</span> Config();</div><div class="line">        conf.setDebug(<span class="keyword">true</span>);</div><div class="line"></div><div class="line">        LocalCluster cluster = <span class="keyword">new</span> LocalCluster();</div><div class="line">        cluster.submitTopology(<span class="string">"test"</span>, conf, topo.buildTopology());</div><div class="line">        Utils.sleep(<span class="number">100000</span>);</div><div class="line">        cluster.killTopology(<span class="string">"test"</span>);</div><div class="line">        cluster.shutdown();</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h3 id="集群模式"><a href="#集群模式" class="headerlink" title="集群模式"></a>集群模式</h3><p>提交一个topology到远程集群就非常简单了，只需要利用StormSubmitter类中同样的方法和名称：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">StormSubmitter.submitTopology(TOPOLOGY_NAME, config, builder.createrTopology());</div></pre></td></tr></table></figure>
<p>一般的例子：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ClusterRunningTopology</span> <span class="keyword">extends</span> <span class="title">ExclaimBasicTopo</span> </span>&#123;</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</div><div class="line"></div><div class="line">        String topoName = <span class="string">"test"</span>;</div><div class="line"></div><div class="line">        ClusterRunningTopology topo = <span class="keyword">new</span> ClusterRunningTopology();</div><div class="line">        Config conf = <span class="keyword">new</span> Config();</div><div class="line">        conf.setDebug(<span class="keyword">true</span>);</div><div class="line"></div><div class="line">        conf.setNumWorkers(<span class="number">3</span>);</div><div class="line"></div><div class="line">        StormSubmitter.submitTopology(topoName, conf, topo.buildTopology());</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h3 id="实际的例子"><a href="#实际的例子" class="headerlink" title="实际的例子"></a>实际的例子</h3><p>在实际的程序里，本地和集群是混绑在一起的，用传入参数以示区别：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</div><div class="line"></div><div class="line">        ExclaimBasicTopo topo = <span class="keyword">new</span> ExclaimBasicTopo();</div><div class="line">        Config conf = <span class="keyword">new</span> Config();</div><div class="line">        conf.setDebug(<span class="keyword">false</span>);</div><div class="line"></div><div class="line">        <span class="keyword">if</span> (args != <span class="keyword">null</span> &amp;&amp; args.length &gt; <span class="number">0</span>) &#123;</div><div class="line">            conf.setNumWorkers(<span class="number">3</span>);</div><div class="line"></div><div class="line">            StormSubmitter.submitTopology(args[<span class="number">0</span>], conf, topo.buildTopology());</div><div class="line">        &#125; <span class="keyword">else</span> &#123;</div><div class="line"></div><div class="line">            LocalCluster cluster = <span class="keyword">new</span> LocalCluster();</div><div class="line">            cluster.submitTopology(<span class="string">"test"</span>, conf, topo.buildTopology());</div><div class="line">            Utils.sleep(<span class="number">100000</span>);</div><div class="line">            cluster.killTopology(<span class="string">"test"</span>);</div><div class="line">            cluster.shutdown();</div><div class="line">        &#125;</div><div class="line">    &#125;</div></pre></td></tr></table></figure>
<h2 id="Spout"><a href="#Spout" class="headerlink" title="Spout"></a>Spout</h2><p><img src="/images/2015-05-26-theBasisOfStorm/2015-05-26-spout.jpg" alt="spout"></p>
<p>Spout最顶层抽象的是<strong>ISPout</strong>接口：</p>
<p><img src="/images/2015-05-26-theBasisOfStorm/2015-05-26-ISpout.jpg" alt="ISpout"></p>
<h2 id="Bolt"><a href="#Bolt" class="headerlink" title="Bolt"></a>Bolt</h2><p>自带的Blot类的关系见下图：</p>
<p><img src="/images/2015-05-26-theBasisOfStorm/2015-05-26-bolt.jpg" alt="bolt"></p>
<p><img src="/images/2015-05-26-theBasisOfStorm/2015-05-26-IBolt.jpg" alt="IBolt"></p>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[CentOS7.0的常用配置]]></title>
      <url>http://matt33.com/2015/05/25/centos70/</url>
      <content type="html"><![CDATA[<h1 id="Windows开机引导"><a href="#Windows开机引导" class="headerlink" title="Windows开机引导"></a>Windows开机引导</h1><p>在<code>/etc/grub.d/40_custom</code>中加入以下代码：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">menuentry <span class="string">"Windows"</span>&#123;</div><div class="line">    <span class="built_in">set</span> root=(hd0,1)</div><div class="line">    chainloader +1</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>然后更新引导</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">grub2-mkconfig -o /boot/grub2/grub.conf</div></pre></td></tr></table></figure>
<h1 id="挂载NTFS分区的硬盘"><a href="#挂载NTFS分区的硬盘" class="headerlink" title="挂载NTFS分区的硬盘"></a>挂载NTFS分区的硬盘</h1><p><a href="http://www.rpmfind.net/linux/rpm2html/search.php" target="_blank" rel="external">linux仓库</a><br>用yum安装ntfs-3g</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">yum install fuse-ntfs-3g</div></pre></td></tr></table></figure>
<p>安装好ntfs-3g之后，系统就可以识别NTFS分区的硬盘了。</p>
<h1 id="开机自动挂载Windows下的ntfs磁盘"><a href="#开机自动挂载Windows下的ntfs磁盘" class="headerlink" title="开机自动挂载Windows下的ntfs磁盘"></a>开机自动挂载Windows下的ntfs磁盘</h1><p><code>fdisk -l</code>查看windows分区信息</p>
<p>用/mnt/winE挂载Windows下的E盘:</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="built_in">cd</span> /mnt</div><div class="line">mkdir winE</div><div class="line">mount -t ntfs-3g /dev/sda3 /mnt/winE</div></pre></td></tr></table></figure>
<p>输入以下命令，查看信息：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">df -Th</div></pre></td></tr></table></figure>
<p>实现开机自动挂载，需要编辑<code>/etc/fstab</code>文件(编辑之前尽量先备份)</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">cp /etc/fstab /etc/fstab_cp</div><div class="line">vim /etc/fstab</div></pre></td></tr></table></figure>
<p>保存后退出就可以实现开机自动挂载了。</p>
<h1 id="为软件建立桌面快捷方式"><a href="#为软件建立桌面快捷方式" class="headerlink" title="为软件建立桌面快捷方式"></a>为软件建立桌面快捷方式</h1><p>在<code>/usr/share/applications</code>下建立一个.desktop文件即可。<br>以eclipse为例：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div></pre></td><td class="code"><pre><div class="line">[Desktop Entry]</div><div class="line">Categories=Development;</div><div class="line">Comment[zh_CN]=</div><div class="line">Comment=</div><div class="line">Exec=/home/Matt/Software/eclipse/eclipse</div><div class="line">GenericName[zh_CN]=IDE</div><div class="line">GenericName=IDE</div><div class="line">Icon=/home/Matt/Software/eclipse/icon0.png</div><div class="line">MimeType=</div><div class="line">Name[zh_CN]=Eclipse</div><div class="line">Name=eclipse</div><div class="line">Path=</div><div class="line">StartupNotify=<span class="literal">true</span></div><div class="line">Terminal=<span class="literal">false</span></div><div class="line">Type=Application</div><div class="line">X-DBUS-ServiceName=</div><div class="line">X-DBUS-StartupType=</div><div class="line">X-KDE-SubstituteUID=<span class="literal">false</span></div><div class="line">X-KDE-Username=owen</div></pre></td></tr></table></figure>
<p>一般只有三个地方<code>Exec, Icon, Name</code>需要我们去修改。<br>建立好eclipse.desktop文件后，把这个文件移到<code>/home/WM/Desktop</code>下，并改变这个文件的所有者和所属用户组。</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"> chmod +x IntelliJIDE.desktop</div><div class="line">cp IntelliJIDE.desktop /home/Matt/Desktop/</div><div class="line"><span class="built_in">cd</span> /home/Matt/Desktop</div><div class="line">chown Matt IntelliJIDE.desktop</div><div class="line">chgrp Matt IntelliJIDE.desktop</div></pre></td></tr></table></figure>
<h1 id="安装chrome"><a href="#安装chrome" class="headerlink" title="安装chrome"></a>安装chrome</h1><p><a href="http://chrome.richardlloyd.org.uk/install_chrome.sh" target="_blank" rel="external">下载</a>自动安装脚本<br>然后使用gedit编辑install—chrome.sh，使用find功能查找并将</p>
<p>其中的<code>http://omahaproxy.appspot.com</code>改为<code>https://dl.google.com/linux/direct
/google-chrome-stable_current_x86_64.rpm</code></p>
<p>打开终端，进入chrome.sh文件所在目录：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">chmod u+x install_chrome.sh</div><div class="line">./install_chrome.sh</div></pre></td></tr></table></figure>
<p><a href="http://www.google.cn/intl/zh-CN/chrome/browser/thankyou.html?brand=CHUN&amp;installdataindex=chinabookmarkcontrol&amp;platform=linux" target="_blank" rel="external">下载chrome最新版rpm包</a></p>
<h1 id="为Terminal设置快捷键"><a href="#为Terminal设置快捷键" class="headerlink" title="为Terminal设置快捷键"></a>为Terminal设置快捷键</h1><p>一般设置为：Ctrl+Alt+T</p>
<p> <a href="http://jingyan.baidu.com/album/cb5d61053598ed005d2fe05c.html?picindex=7" target="_blank" rel="external">Terminal</a></p>
<p>Setting》》点击Keyboard》》选择左边Shortcuts –&gt;Custom Shortcuts：</p>
<p>点击旁边的+号，然后输入（Name那儿随便写）,Command填写<code>/usr/bin/gnome-terminal</code>.</p>
<p>点Apply，然后将它的快捷键设置为Ctrl+Alt+T:</p>
<h1 id="网络配置"><a href="#网络配置" class="headerlink" title="网络配置"></a>网络配置</h1><p><a href="http://www.centoscn.com/CentOS/config/2014/1023/3993.html" target="_blank" rel="external">网络配置</a></p>
<h1 id="局域网内共享文件夹"><a href="#局域网内共享文件夹" class="headerlink" title="局域网内共享文件夹"></a>局域网内共享文件夹</h1><p>进入文件内，输入以下命令：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">python -m SimpleHTTPServer 8080</div></pre></td></tr></table></figure>
<p>然后用在firewall中把端口8080打开即可，用tcp连接。</p>
<h1 id="软件库"><a href="#软件库" class="headerlink" title="软件库"></a>软件库</h1><p>安装软件库：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">rpm -Uvh http://li.nux.ro/download/nux/dextop/el7/x86_64/nux-dextop-release-0-1.el7.nux.noarch.rpm</div><div class="line">rpm -Uvh http://ftp6.sjtu.edu.cn/fedora/epel/7/x86_64/e/epel-release-7-5.noarch.rpm</div></pre></td></tr></table></figure>
<p><a href="http://www.dedoimedo.com/computers/centos-7-perfect-desktop.html" target="_blank" rel="external">常用软件</a></p>
<h1 id="中文乱码问题"><a href="#中文乱码问题" class="headerlink" title="中文乱码问题"></a>中文乱码问题</h1><p><a href="http://dargonjack.blog.51cto.com/6294601/1334685" target="_blank" rel="external">乱码问题</a></p>
<h2 id="gedit中文乱码"><a href="#gedit中文乱码" class="headerlink" title="gedit中文乱码"></a>gedit中文乱码</h2><p>在终端输入一下两条命令：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">$ gsettings <span class="built_in">set</span> org.gnome.gedit.preferences.encodings auto-detected <span class="string">"['UTF-8', 'GB18030', 'GB2312', 'GBK', 'BIG5', 'CURRENT', 'UTF-16']"</span></div><div class="line">$ gsettings <span class="built_in">set</span> org.gnome.gedit.preferences.encodings shown-in-menu <span class="string">"['UTF-8', 'GB18030', 'GB2312', 'GBK', 'BIG5', 'CURRENT', 'UTF-16']"</span></div></pre></td></tr></table></figure>
<h2 id="Vim中文编码"><a href="#Vim中文编码" class="headerlink" title="Vim中文编码"></a>Vim中文编码</h2><p>编辑用户主目录下.vimrc(如果没有这创建touch  .vimrc)</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"><span class="variable">$vim</span> .vimrc</div><div class="line"><span class="keyword">if</span> (has(<span class="string">"gui_running"</span>))</div><div class="line">    <span class="built_in">set</span> guifont=Bitstream\ Vera\ Sans\ Mono\ 10</div><div class="line">endif</div><div class="line"><span class="built_in">set</span> fencs=utf-8,ucs-bom,<span class="built_in">shift</span>-jis,gb18030,gbk,gb2312,cp936</div><div class="line"><span class="built_in">set</span> termencoding=utf-8</div><div class="line"><span class="built_in">set</span> encoding=utf-8</div><div class="line"><span class="built_in">set</span> fileencodings=ucs-bom,utf-8,cp936</div><div class="line"><span class="built_in">set</span> fileencoding=utf-8</div></pre></td></tr></table></figure>
<p>保存退出<br>此时不论是正文还是标题都不会有乱码出现。</p>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[Strom之tuple]]></title>
      <url>http://matt33.com/2015/05/21/stromtuple/</url>
      <content type="html"><![CDATA[<p>这几天一直在看storm，其中注意到了storm中主要的数据结构类型tuple，刚开始对这种数据还是很不理解，看几个程序之后，才豁然开朗，下面就主要介绍一些storm中最简单的、最基础的东西——tuple。</p>
<p>storm中的数据首先是有spout收集，类似于一个消息源，spout的open()函数一般就是接收数据的地方，然后spout的 nextTuple()是发送(emit)tuple的地方。tuple到底是什么？感觉还是用英语来说比较容易理解吧，”A tuple is a named of values where each value can be any type.”  tuple是一个类似于列表的东西，存储的每个元素叫做field（字段）。我们用getString(i)可以获得tuple的第i个字段。而其中的每个字段都可以任意类型的，也可以一个很长的字符串。我们可以用：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">String A = tuple.getString(<span class="number">0</span>);</div><div class="line"><span class="keyword">long</span> a= tuple.getLong(<span class="number">1</span>);</div></pre></td></tr></table></figure>
<p>来得到我想要的数据，不过前提你是要知道你的tuple的组成。具体tuple是什么类型，完全取决于自己的程序，取决于spout中nextTuple()方法中emit发送的类型。</p>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[Kafka常用的一些命令]]></title>
      <url>http://matt33.com/2015/05/20/KafkaOrder/</url>
      <content type="html"><![CDATA[<h1 id="开启Kafka"><a href="#开启Kafka" class="headerlink" title="开启Kafka"></a>开启Kafka</h1><p>先进入kafka的安装目录</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">bin/kafka-server-start.sh config/server.properties</div></pre></td></tr></table></figure>
<h1 id="运行程序"><a href="#运行程序" class="headerlink" title="运行程序"></a>运行程序</h1><p>有以下两种方式来运行程序：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">java -Djava.ext.dirs=/opt/kafka_2.10-0.8.1.1/libs -jar <span class="built_in">test</span>Producer.jar  </div><div class="line">java -cp traffic-distribution.jar producer.producer /home/matt/<span class="built_in">test</span>/ topicName ...</div></pre></td></tr></table></figure>
<p>第一种是jar包中没有打入相关依赖包的情况；<br>第二种是jar宝中已经包含相关依赖包。</p>
<h1 id="列出所有的topic"><a href="#列出所有的topic" class="headerlink" title="列出所有的topic"></a>列出所有的topic</h1><p>列出当前集群上的所有topic：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">bin/kafka-topics.sh --list --zookeeper serverIP:serverPort</div></pre></td></tr></table></figure>
<p>注：serverIP为zookeeper所在机器的IP，serverPort为对应的端口。</p>
<h1 id="删除topic"><a href="#删除topic" class="headerlink" title="删除topic"></a>删除topic</h1><p>删除topic的命令：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">bin/kafka-run-class.sh kafka.admin.DeleteTopicCommand -topic <span class="built_in">test</span> -zookeeper serverIP:serverPort</div></pre></td></tr></table></figure>
<p>这种删除方式只是删除了topic，但是该topic中Partition的数据依然存在，等数据过期之后就会自动删除。（也可以手动删除/tmp/kafka-logs/下的partition信息）</p>
<h1 id="kafka集群设置"><a href="#kafka集群设置" class="headerlink" title="kafka集群设置"></a>kafka集群设置</h1><p>主要是配置kafka的config的<code>server.properties</code>文件，后面我写一篇kafka安装配置的blog。</p>
<h1 id="查看topic的信息"><a href="#查看topic的信息" class="headerlink" title="查看topic的信息"></a>查看topic的信息</h1><figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">bin/kafka-topics.sh --describe --zookeeper serverIP:serverPort --topic <span class="built_in">test</span></div></pre></td></tr></table></figure>
<h1 id="删除group"><a href="#删除group" class="headerlink" title="删除group"></a>删除group</h1><p>进入zookeeper的安装目录，如<code>/opt/cloudera/parcels/CDH/bin/</code></p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">sh zookeeper-client</div><div class="line">ls /consumers</div><div class="line">rmr /consumers/groupName</div></pre></td></tr></table></figure>
<h1 id="开启topic"><a href="#开启topic" class="headerlink" title="开启topic"></a>开启topic</h1><p>建立topic的几种方式：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">bin/kafka-topics.sh --zookeeper serverIP:serverPort --create --topic <span class="built_in">test</span> --partitions 1 --replication-factor 1</div><div class="line">bin/kafka-topics.sh --zookeeper serverIP:serverPort --create --topic <span class="built_in">test</span> --replica-assignment 29,29</div></pre></td></tr></table></figure>
<p>第一种是一般的方式，建立的topic的partition为1，replication为1；<br>第二种是直接指定partition所在机器。</p>
<h1 id="KafkaOffsetMonitor"><a href="#KafkaOffsetMonitor" class="headerlink" title="KafkaOffsetMonitor"></a>KafkaOffsetMonitor</h1><p>使用KafkaOffsetMonitor对kafka集群进行监控。</p>
<p>KafkaOffsetMonitor的<a href="https://github.com/quantifind/KafkaOffsetMonitor/releases/download/v0.2.1/KafkaOffsetMonitor-assembly-0.2.1.jar" target="_blank" rel="external">jar包下载</a>,<a href="https://github.com/quantifind/KafkaOffsetMonitor" target="_blank" rel="external">源码地址</a>。</p>
<p>运行命令：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">java -cp KafkaOffsetMonitor-assembly-0.2.1.jar com.quantifind.kafka.offsetapp.OffsetGetterWeb --zk serverIP1,serverIP2 --port 8080 --refresh 10.seconds --retain 2.days</div></pre></td></tr></table></figure>
<p>参数的意思是：</p>
<ul>
<li><strong>ZK</strong> the ZooKeeper hosts</li>
<li><strong>port</strong> on what port will the app be available</li>
<li><strong>refresh</strong> how often should the app refresh and store a point in the DB</li>
<li><strong>retain</strong> how long should points be kept in the DB</li>
<li><strong>dbName</strong> where to store the history (default ‘offsetapp’)</li>
</ul>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[为什么你应该（从现在就开始）写博客【转】]]></title>
      <url>http://matt33.com/2014/10/24/hello-world/</url>
      <content type="html"><![CDATA[<p>向大家推荐一篇blog，刘未鹏大神的<a href="http://mindhacks.cn/2009/02/15/why-you-should-start-blogging-now/" target="_blank" rel="external">为什么你应该（从现在开始就）写博客</a>.下面的内容<strong>转载</strong>于这篇博文。</p>
<h3 id="1-为什么你应该（从现在开始就）写博客"><a href="#1-为什么你应该（从现在开始就）写博客" class="headerlink" title="1.为什么你应该（从现在开始就）写博客"></a>1.为什么你应该（从现在开始就）写博客</h3><p>用一句话来说就是，写一个博客有很多好处，却没有任何明显的坏处。（阿灵顿的情况属于例外，而非常态，就像不能拿抽烟活到一百岁的英国老太太的个例来反驳抽烟对健康的极大损伤一样）</p>
<p>让我说得更明确一点：用博客的形式来记录下你有价值的思考，会带来很多好处，却没有任何明显的坏处。Note：碎碎念不算思考、心情琐记不算思考、唠唠叨叨也不算思考、没话找话也不算思考，请以此类推。</p>
<p>下面是我个人认为写一个长期的<strong>价值博客</strong>的最大的几点好处：</p>
<p>1). <strong>能够交到很多志同道合的朋友</strong>。我自己既写博客，也读别人的博客，在这个时代，对于生活中的绝大多数人来说，拓宽朋友圈子的途径几乎只有一个，通过网络，而如何在网络中寻找到气味相投的朋友，如何判断别人和自己是否有共同语言？显然，通过天天在SNS上碎碎念的那些日记是难以做到的。我佩服的一些朋友几乎全都是长期用博客记录想法的人，<strong>因此，和他们即便不打照面，也是心照不宣</strong>。即便素未谋面也能坐下来就聊得热火朝天。</p>
<p>为什么博客在结交志同道合的朋友方面的潜力要远胜于原始的交谈方式？很简单，<strong>第一，博客无地域限制，整个互联网上从A到B只有一个点击的距离</strong>，而传统的建立朋友圈子的方法则受到地域限制,<strong>第二</strong>，也是更重要的一点，即如果按照以前结交朋友的方式，需要互相聊天，交流观点，然后才逐渐熟悉起来，这需要一个较长的过程，而且更糟糕的是，当你遇到另一个陌生人，又要把整个过程重复一次，表达你已经对老友表达过的那番想法。可博客却做到了“<strong>一次表达，无数次阅读</strong>”，当我看到一个写了好几年的博客，看完了之后我仿佛和这个人交谈了很久，用程序员们喜欢听的话来说就是，“<strong>博客极大地增强了话语的复用性</strong>”。</p>
<p>我曾在CSDN上写了近六年的博客，在一年半前建立了一个Google Groups（TopLanguage），由于我的博客的长期阅读者都是互相有共同语言的，因此这个Group一开始就热火朝天，而高质量的技术讨论则进一步吸引了更多的牛人的参与，雪球滚起来之后，就很难停下来了，将近一年半下来，从这个Group的讨论中我获益良多[1]。而对于非程序员朋友，科学松鼠会则是一个很好的例子。</p>
<p>2). <strong>书写是为了更好的思考</strong>。我在<a href="http://delicious.com/pongba/toplanguage" target="_blank" rel="external">《书写是为了更好的思考》</a>里面详细总结了书写的好处，这里就不拷贝粘贴了。有些想法如果不写下来，也就忘掉了，有一个广为流传的《数学牛人们的轶事》（荣耀属于ukim）里面讲了希尔伯特的一个故事：一次在Hilbert的讨论班上，一个年轻人报告，其中用了一个很漂亮的定理，Hilbert说“这真是一个妙不可言（wunderbaschon）的定理呀,是谁发现的？”那个年轻人茫然的站了很久，对Hilbert说：“是你.……”。</p>
<p>3). <strong>“教”是最好的“学”。如果一件事情你不能讲清楚，十有八九你还没有完全理解</strong>。绝大多数人应该都知道在程序员行业面试官经常要求你讲解一个东西给他听，他会说他不懂这个东西（他如果真的不懂的话效果其实是最好的），而你的任务则是说到让他理解为止。</p>
<p>为了让一个不明白的人做到明白，你必须要知道从明白到不明白他究竟需要掌握哪些概念，这就迫使我们对我们大脑中整个的知识体系来个寻根究底，把藏在水面之下的那些东西统统挖出来，把大脑中的那些我们知道、但不知道自己知道的潜在概念或假设（assumptions）都挖出来，把它们从内隐记忆拉扯到外显记忆中。因为只有完全知道、并知道自己知道一切来龙去脉的人，才能真正把一件事情讲得通通透透。</p>
<p>但是，你可能会怀疑，那除了能够讲清楚之外，弄清自己到底知道哪些东西还有其他什么好处吗？如果没有其他好处，那我又何必费这个劲呢？我又不当老师。</p>
<p>TopLanguage上的一位朋友sagasw曾经讲了这样一个小故事：<strong>据说在某个著名软件公司里，开发组的桌上会放着一只小熊，大家互相问问题之前，先对着小熊把问题说一遍，看能不能把问题描述的清晰，基本上说的比较有条理以后，答案也就随之而来了</strong>。当然，你不一定要对小熊说，你可以在大脑中虚构一个听众，一个不懂行的听众，然后你说给他听。这是可行的，我经常在路上用。不过如果你能坐下来，我建议你还是说给实际的听众听——即写下你的思考，因为书写是更好的思考。</p>
<p>我们的绝大多数知识在绝大多数时候都隐藏在潜意识中，其实我们意识的窗口很小，我们的工作记忆只能容纳寥寥数个条目（记得那个“看你能够记住屏幕上同时闪现的多少个数字”的flash小游戏吗？），我们平时所作的推理过程很大部分都是自动的，发生在潜意识中，而我们只能感知到一些中间结论。不信你回忆一下你在和别人讨论问题的时候有多少次觉得“<strong>反正就是这样，我感觉得到它是对的，但是你问我，我也说不清到底怎么回事”，对此你不觉得很奇怪吗？如果你都不能从逻辑上支持你的结论，你怎么就能确信它是对的呢？仅仅因为你的直觉强烈地告诉你它是对的？那如果旁边有另一个人，他和你持相反的观念，而他的直觉也强烈地告诉他他是对的。这时候你又怎么想？“他的直觉错了，我的直觉是对的”？难道你这么自信你的直觉是世界上最可靠的？</strong></p>
<p>我自己则是非常珍惜类似这样的机会，即当“我强烈地觉得它是对的，但我却说不出所以然来”，这时候<strong>往往是到大脑中翻箱倒柜的时候，弄清来龙去脉的时候，深入反思的时候，纠正一直以来错误的潜在前提假设的时候。另一方面，“我强烈地觉得这个说法有问题，但我却说不清它为什么有问题，到底哪有问题”</strong>，这也是一个极有意义的瞬间，它几乎总是意味着你对一个问题的认识有潜在的偏差，肯定是在你自己都没有觉知到的地方引入了一个潜在的假设、偷换了一个重要的概念，等等。而这种时候就是深入反思的时候，当你终于潜到问题的底层，触摸到问题的实质，把水面之下的冰山整体看清了的时候你会有一种通体舒泰的感觉。</p>
<p>为什么说以上这些？因为刚才说的是你必须等待这样的反思机会，<strong>但如果你选择经常总结自己的知识体系，并说出来给你的读者听，你就会发现你自己创造了这样的机会</strong>。如果我们平时不反思，我们觉得很多事情都是当然的，但结果如果要你一开口说给别人听，常常会发现事情就开始变得不那么明显了，你说着说着，就开始莫名其妙地发现自己需要用到“反正”这个词了。</p>
<p>于是，反思的机会就来了。</p>
<p><strong>一旦你把自己潜意识里面的东西从幕后拉出来，你就有了面对并反思它们的可能，而不是任它们在幕后阴险地左右你的思维</strong>。很多时候我们的思路出了问题并不是我们不会反思，而是不知道自己的思维中有那些隐含的假设（assumptions），如果你只感觉到答案，却不知道你大脑得到这个答案之前做了哪些推理，你又怎么知道哪一环可能出了问题呢？另一方面，一旦你弄清了自己到底是怎么想的，离意识到问题就不远了，很简单的道理——如果别人和你争辩的时候总是只摆立场，你就很难和他辩，但如果他把自己的推理过程原原本本暴露给你，批判起来总是容易得多的。（也正因为这个原因有很多人总是把逻辑藏在背后，不敢暴露出来）</p>
<p>绝大多数时候其实我们都会不假思索地得出一些结论，就像上了发条的自动机，但其实我们并不知道这些结论到底怎么来的，在思维的背后到底发生了哪些事情，故而当我们发现我们的结论错了的时候，一头雾水，没法着手寻找到底在哪错了。如果你注意一下很多人的发言（论坛、博客等等），如果你把他们的发言分为“前提”、“假设”、“逻辑”、“结论”这四个部分，你会发现一大堆人只会不停地下结论，摆立场，却见不到这些结论或离场的前提、假设和个中逻辑，倒也不是他们不愿意写出逻辑，而是因为反思自己的思维过程实在是一件困难非常的事情，我们的推理过程很大一部分发生在意识的水面之下，只有当有了重要结论的时候这条逻辑链才会浮出来冒一个泡，让我们的意识捕捉到。更何况绝大多数时候我们用的其实并不是完整严密的逻辑思维，而是思维捷径。</p>
<p><strong>去教一个完全不懂的人，则是一种最最强大和彻底的反思途径</strong>——因为他没有任何预备的知识，所以要让他弄懂你所知道的，你就必须彻底反思你的知识体系，弄清这座大厦的根基在什么地方，弄清它的骨架在什么地方，一砖一瓦到底是怎么垒起来的，你不能自己站在11层上，然后假设你的读者站在第10层，指望着只要告诉他第11层有那些内容就让他明白。你的读者站在第一层，你必须知道你脚下踩着的另外10层到底是怎么构造的。<strong>这就迫使你对你所掌握的、或之前认为正确的那些东西作彻彻底底的、深刻的反思，你的受众越是不懂，你需要反思得就越深刻</strong>。</p>
<p>4). <strong>讨论是绝佳的反思</strong>。另一方面，<strong>很多时候我们并不是有机会说给完全不懂的人听，更大的可能性是说给同领域有一定基础的人听</strong>，这个时候并不代表就不能促使反思了，实际上，你会发现，如果你公开你的想法，<strong>几乎总能看到与你持不同意见的人</strong>，然后你通过比较你和他的观念之间的差别，会发现你们在一开始的思路上就存在差异，差异从哪里来的？在进一步讨论中你们就会不断地迫使对方拿出更深层次的理由，这同样也是一种非常有效地促使自己反思的方法，在讨论的过程中双方的理由自然会变得越来越深入，越来越接近问题的本质，<strong>一些平时难以注意到的深层面的差异性就会逐渐浮现出来，你也就多了一次难得的机会去审视自己的思维中到底存放了哪些错误的信息</strong>。</p>
<p>5). <strong>激励你去持续学习和思考</strong>。如果你没有持续学习和思考的习惯，你的博客很快就会没有内容可写，就只能整点碎碎念或者转载，然后你就会失去读者，然后你就会关掉博客，然后一旦关掉博客之后你也就死了写博客的心，然后就少了一条激励你去思考和总结的途径，然后你变得更不高兴总结和思考，然后…</p>
<p>为了打破这个死循环，不要永久停止更新你的博客，就算你两个月，三个月都不写，只要你每篇都是写自己思考的产物，写有价值的东西，在互联网上，金子的确总是会发光的，因为有无数的信息聚合平台在期待这些有价值的内容，有搜索引擎为你的内容提供海量的潜在读者，有海量的人肉在手动挖掘和转载那些有价值的东西。<strong>我们所能做的最差的一个决策莫过于停止做一件没有任何坏处，却有一大堆好处的事情</strong>。</p>
<p>为了让你的博客有价值，你必须不断总结自己学习的结果，你必须不断思考，给出比别人深刻、独到的见解。这看起来有点本末倒置，但很快本和末就会正过来。</p>
<p>6). <strong>学会持之以恒地做一件事情</strong>。很多人在生活中容易觉得迷失，不知道想要做什么，是因为没有一件能够持续地做的事情，用俗话来说就是没有主心骨。用积极心理学的话来说就是没有一件能够创造流体验的事情，而书写自己的思想则是一件容易产生流体验的事情，在书写的时候，特别是理性地书写的时候，大脑逐渐进入推理分析模块，一切不愉快的情绪，烦躁感都会逐渐消隐下去。不过前提是你得开始，并且坚持过一开始的困难期，以后的一切便成了习惯成自然。</p>
<p>7). <strong>一个长期的价值博客是一份很好的简历</strong>。这里的“简历”并非是狭义上的求职简历，毕竟现在还没有到<strong>价值博客的时代</strong>，很多人写博客都是到处转载或者干脆碎碎念，正因此面试官未必拿个人博客当成了解一个人的更可靠窗口。这里的“简历”是指一个让别人了解自己的窗口，虽然我们未必做得到像罗永浩、Keso这样的博客，个人的影响力已经足以支撑出一份事业（牛博和5gme），但<strong>至少你会因此而结识更多的人，你的博客价值越高，你结识的人就越牛，跟牛人交流又会让你的眼界得到极大的开阔，打开一扇又一扇你原本不知道的门，于是你就变得更牛… 这是一个良性循环</strong>。</p>
<h3 id="2-怎么做到长期写一个价值博客"><a href="#2-怎么做到长期写一个价值博客" class="headerlink" title="2.怎么做到长期写一个价值博客"></a>2.怎么做到长期写一个价值博客</h3><p>注意到我并没有说“怎么做到长期<strong>坚持</strong>写一个价值博客”，因为当思考和总结成为习惯之后，诉诸文字以及借助书写来进一步思考就变成了一件自然而然的事情，就变成了一件“因为你在思考和总结从而必须书写下来”的事情，博客就变成了副产品。</p>
<p>一开始的时候你是因为要写博客而去使劲地思考和总结，指望给出令人眼睛一亮的东西，到了后来，就变成了因为你习惯了思考和总结，因为你意识到书写是更好的思考，你就必须使你的想法成为文字。至此本和末就会各归原位，不再颠倒。</p>
<p>怎样做到长期写一个价值博客？也许有人会给出很多有趣有用的小技巧来提供动机和激励，譬如如何做SEO，如何鼓励读者留言等等，但是这些我都不想说，我只想说最最重要的，那就是：</p>
<p><strong>让你自己成为一个持续学习和思考的人，并只写你真正思考和总结之后的产物，其他一切就会随之而来</strong>。</p>
<p>就像那句经常被人传阅的话：只做你最感兴趣的事情，钱会随之而来[2]。</p>
<p>这方面的具体例子大家可以留意一下，随处可见，就不一一举了。我想再重复一下的是，千万不要碎碎念，我能理解每个人都想偶尔发发牢骚的冲动，但是现在已经有了一个很好的窗口：twitter，所以立即停止在你的博客上碎碎念，阅读博客的人希望得到信息而非噪音。<strong>如果实在忍不住想碎碎念的话不妨换一下位置，这么来告诉自己：如果你看到别人博客来上这么一段，你会有兴趣看吗？</strong></p>
<h3 id="3-可能出现的问题以及怎样应付"><a href="#3-可能出现的问题以及怎样应付" class="headerlink" title="3.可能出现的问题以及怎样应付"></a>3.可能出现的问题以及怎样应付</h3><p>即便上文给出了N条写博客的理由，但有时候只要一条不写的理由就会让人停止做一件事情。所以我特别加上一节“可能出现的问题以及怎样应付”，《影响力2》[3]第五章雄辩地证明，“Much of Will is Skill”，<strong>意志力很大程度上来源于有正确的方法，而非天生</strong>。</p>
<p>1). <strong>担心别人认为没有价值</strong>。事实是，你面临过的问题总会有人面临过，你独立思考了，别人没有，你的文章对他们就会有价值。当然，肯定会对某些人没有价值，他们早就知道了，但就算你再厉害，也总是有人比你厉害的，不能说因为这些原因就不记录你自己的想法了，你自己思考了之后理解得最深刻，就算有别人想过了，总有人没有想到的。况且，思考成了习惯，你的思考能力也会越来越强，你的文章也会越来越有价值。重复，<strong>无论你面临什么困惑，总会有很多人同样面临过，于是你苦苦思索之后的结果，肯定会对很多人有意义</strong>。</p>
<p>或者，<strong>你想通了之后觉得其实也很简单于是不愿意或者不好意思写了，但要知道，问题在想通了之后总是简单的，问题的困难程度不在于想通了之后还觉得有多难，而在于从你觉得它难到你觉得它简单需要耗费多少思维体力</strong>，你耗费的时间越长，说明有越多的人最终还是没有想明白（路越长走到底的人越少）。</p>
<p>最后，虽然我现在看一年前的文章觉得挺不成熟，但是如果没有那些不成熟的思考，也不会有现在更成熟的思考，我几年后来看现在写的东西，还是会觉得不成熟。</p>
<p>2). <strong>担心想法太幼稚或有漏洞等等被别人笑话</strong>。人非圣贤。正是因为单个人的想法总是有漏洞，才值得拿出来交流（《书写是更好的思考》，讨论是绝佳的反思），被别人指出问题正是改进的空间，藏着掖着的想法永远不可能变得更成熟。</p>
<p>Much of intelligence is knowledge，有这么一个非常发人深省的经典心理学实验[4]：</p>
<p>将孩子们分成两组，通过给他们不同的阅读材料让一组相信智力是天生的，不可在后天改变的，另一组则让他们相信智力其实只是知识和技能的代名词，完全是后天习得的。接下来让他们做一组任务，那些被相信智力天生说的孩子，倾向于回避困难的任务，选择较容易的任务，这里的逻辑想必是这样的：如果做困难的任务，就增大了失败的几率，就在降低了自己在别人和自己心目中的智力的值。为了保护这个智力的值不被降低，应该避免那些有失败风险的项目。而另一组孩子则对于有挑战性的事情跃跃欲试，并且在失败的时候明显没有前者沮丧，因为失败也是学得新的东西，不管怎样都是“智力”的提高。</p>
<p>况且，只会批判乃至嘲笑别人的人是最不知道怎么建设的人，忽略他们。</p>
<p>3).  <strong>得不到激励</strong>。这其实是个最无聊的问题了，只有写碎碎念的博客才会面对“激励”的问题。如果写自己的总结，写自己独立的思考，那么书写下来、理解通透，本身就是一个极大的激励。就算放在自己的私密笔记本里面也一样有成就感。况且，如果你真做到了书写价值博客，那么绝对不用担心你的观点得不到传播，也许一开始会耗时长一点，但是这在任何事情上都是必要的初始阶段，Gmail小组的核心人物、FriendFeed创始人Paul Buchheit，和编程界名博Coding Horror的博主Jeff Atwood都曾经感叹过：Overnight success takes a long time （(1)，(2)），不过对于价值博客来说，现在网络上的聚合类服务这么多，机器的、人肉的、半人肉的都有，情况又要好得多了，而且我相信情况还会越来越好。</p>
<p>4). <strong>写不出来</strong>。这个问题也比较无聊，思考本不是一件急于求成的事情。长期订阅我的博客的朋友知道我一般发文频率在一个月三五篇，实际上有不少次我个把月也不发布文章，原因很简单，要么是有手头的事情要处理思考的时间被压缩了，要么是遇到比较大或者比较困难的问题需要长时间的思考和积淀，没有关系，如果没有想清楚就再想想，爱思考的人和不爱思考的人有一个本质的区别，前者在生活中总是挂着几个问题在大脑中，它们时常都会冒出来骚扰你一下，让你琢磨琢磨，不爱思考的则是没事不主动想问题，遇到问题还要先想想是否能找捷径（找人帮忙）解决。</p>
<p>无论如何，不用急于求成，在一个主题上深入下去思考，总能挖到别人挖不到的角落。你能让一个问题在大脑中停留的时间越长，就越是能够发现新的东西，一般来说，我认为有价值的问题我会让他在意识或潜意识中待短则一个星期，长则一个月（视问题大小而定），利用走路吃饭的时间琢磨（我发现很多我佩服的人也都有这个习惯），<strong>有时即便已经想通了写下来了发出去了，大脑仍然还是会在回味问题，还没有把它撤出潜意识，然后看到某篇文章或某本书的时候忽然又有所新的感悟</strong>。</p>
<p><strong>能够把问题长时间停靠在潜意识中是一种技能，能够带来很大的好处，停留得越长你越琢磨得透彻，比别人看到的就越多</strong>。我们必须要带着问题的眼镜看待事物才能发现新的视角，否则就会出现视而不见效应，别的不说，广为人知的例子是阿基米德的“尤里卡！”，如果不是长时间琢磨着一个问题，一直把它放在思维中，是不会从洗澡领悟到“排水测体积”的，否则他洗了那么多年澡怎么不早发现呢？[5]</p>
<p>所以，如果你习惯了思考问题，就总会有东西写，先有思考，然后有总结，然后在总结中进一步思考。</p>
<p>当然你也可以试试把不成熟的想法写下来，试图整理成条理清晰的文字，然后看看能否在整理的过程中走得更远。这往往是可行的。比如这篇文章在我的简记里面原本其实只有三行字（包含大约十来个备忘关键词），而最初在我的大脑里面其实只有一个走路时冒出来的问题——为什么要写博客？</p>
<p>–</p>
<p>[1] 你可以看一下我<a href="http://delicious.com/pongba/toplanguage" target="_blank" rel="external">收藏的一些精彩主题</a>。</p>
<p>[2] 尽管我并不完全同意这句话本身，但它这种解决问题链上更基本环节的问题的精神是我赞同的。</p>
<p>[3] 《影响力2》这个名字起得很聪明，其实它并不是《影响力》的作者写的。</p>
<p>[4] 我忘了这则实验的出处了，但实验的精神是记忆犹新的，哪位同学记得原始出处的麻烦提醒我一下。</p>
<p>[5] 对于阿基米德这个故事的真实性是有争议的，毕竟几千年久远的事情谁弄得清呢。但是故事的道理是很本质的，我们平时也经常有类似的体验，加上阿基米德的“尤里卡”实在太出名了，所以我相信用用无妨。</p>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[Matt 的中文简历]]></title>
      <url>http://matt33.com/2014/09/01/resume/</url>
      <content type="html"><![CDATA[<hr>
<h1 id="个人信息"><a href="#个人信息" class="headerlink" title="个人信息"></a>个人信息</h1><ul>
<li>王蒙/男/1992</li>
<li>硕士/北京邮电大学信息与通信工程（2014-2017） 本科/郑州大学电子信息工程专业（2010-2014）</li>
<li>技术博客：<a href="http://matt33.com/">Matt’s Blog</a></li>
<li><p>Github：<a href="http://github.com/wangzzu" target="_blank" rel="external">wangzzu</a></p>
<hr>
</li>
</ul>
<h1 id="联系方式"><a href="#联系方式" class="headerlink" title="联系方式"></a>联系方式</h1><ul>
<li>Email：wangm92 # 163.com</li>
<li><p>微博：<a href="http://weibo.com/wangzzu" target="_blank" rel="external">柳年思水</a></p>
<hr>
</li>
</ul>
<h1 id="工作实习经历"><a href="#工作实习经历" class="headerlink" title="工作实习经历"></a>工作实习经历</h1><h2 id="美团点评-（-2016年7月-至今-）"><a href="#美团点评-（-2016年7月-至今-）" class="headerlink" title="美团点评 （ 2016年7月 ~ 至今 ）"></a>美团点评 （ 2016年7月 ~ 至今 ）</h2><p>技术工程部-数据平台组  后台开发工程师</p>
<ul>
<li>专注但不限于 Kafka 平台及数据通道建设。</li>
</ul>
<h2 id="北邮网络体系构建与融合实验室-（2014年9月-2016年6月）"><a href="#北邮网络体系构建与融合实验室-（2014年9月-2016年6月）" class="headerlink" title="北邮网络体系构建与融合实验室 （2014年9月 ~ 2016年6月）"></a>北邮网络体系构建与融合实验室 （2014年9月 ~ 2016年6月）</h2><p>流式数据平台建设。</p>
<hr>
<h1 id="开源项目和作品"><a href="#开源项目和作品" class="headerlink" title="开源项目和作品"></a>开源项目和作品</h1><h2 id="开源项目"><a href="#开源项目" class="headerlink" title="开源项目"></a>开源项目</h2><h3 id="Apache-Kafka"><a href="#Apache-Kafka" class="headerlink" title="Apache Kafka"></a>Apache Kafka</h3><p> 为开源社区做的贡献：</p>
<ul>
<li><a href="https://issues.apache.org/jira/browse/KAFKA-4328" target="_blank" rel="external">KAFKA-4328</a>：在阅读源码中，发现其中在创建 zk 实例时，参数调用有误；</li>
</ul>
<h2 id="技术文章"><a href="#技术文章" class="headerlink" title="技术文章"></a>技术文章</h2><ul>
<li><a href="http://matt33.com/2016/07/21/kafka-new-consumer/">Apache Kafka 0.9 Consumer Client 介绍【译】</a>：翻译自 Confluent 官网博客；</li>
<li><a href="http://matt33.com/2015/11/14/The-Introduce-of-Kafka/">Kafka的简单介绍</a>：Kafka 基本入门文章；</li>
<li><a href="http://matt33.com/2016/03/02/hadoop-shuffle/">MapReduce之Shuffle过程详述</a>：介绍 MapReduce 中最核心部分—— Shuffle 的一篇文章。</li>
</ul>
<h2 id="游记"><a href="#游记" class="headerlink" title="游记"></a>游记</h2><p>个人非常喜欢户外跟旅行，经常会在<a href="http://www.jianshu.com/users/e50b355579a9/latest_articles" target="_blank" rel="external">简书</a>上分享一些个人的旅行攻略。</p>
<ul>
<li><a href="http://www.jianshu.com/p/778513f9ce4c" target="_blank" rel="external">Travel to Haituo | 2016河北海坨山露营</a>：第一次去海坨，人生第一次重装爬山露营；</li>
<li><a href="http://www.jianshu.com/p/afffa111edd0" target="_blank" rel="external">Travel to Kubuqi | 2016端午库布其穿越</a>：这一次穿越遇到了很多臭味相投的朋友；</li>
<li><a href="http://www.jianshu.com/p/183cb4b10ed5" target="_blank" rel="external">Travel to Qinghai Lake | 2015暑假环骑青海湖</a>：从最开始的在学校论坛上发帖征集队友，到最后带领着七人的校友小分队完成环骑旅行；</li>
</ul>
<hr>
<h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p>简历模板参考<a href="https://github.com/geekcompany/ResumeSample/blob/master/java.md" target="_blank" rel="external">jobdeer java</a></p>
]]></content>
    </entry>
    
  
  
</search>
