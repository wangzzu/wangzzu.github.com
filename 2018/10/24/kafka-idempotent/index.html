<!DOCTYPE html><html lang="zh-CN"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description" content="与一群有趣的人，做一些有趣的事."><title>Kafka 事务性之幂等性实现 | Matt's Blog</title><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/normalize/4.2.0/normalize.min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/0.6.0/pure-min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/0.6.0/grids-responsive-min.css"><link rel="stylesheet" type="text/css" href="/css/style.css?v=0.0.0"><link rel="stylesheet" href="//cdn.bootcss.com/font-awesome/4.6.3/css/font-awesome.min.css"><script type="text/javascript" src="//cdn.bootcss.com/jquery/3.0.0/jquery.min.js"></script><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"><link rel="alternate" type="application/atom+xml" href="/atom.xml"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">Kafka 事务性之幂等性实现</h1><a id="logo" href="/.">Matt's Blog</a><p class="description">王蒙</p></div><div id="nav-menu"><a href="/." class="current"><i class="fa fa-home"> 首页</i></a><a href="/archives/"><i class="fa fa-archive"> 归档</i></a><a href="/about/"><i class="fa fa-user"> 关于</i></a><a href="/atom.xml"><i class="fa fa-rss"> 订阅</i></a></div></div><div id="layout" class="pure-g"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">Kafka 事务性之幂等性实现</h1><div class="post-meta">Oct 24, 2018<span> | </span><span class="category"><a href="/categories/技术/">技术</a></span><span> | </span><span class="post-count">9,628</span><span> 字</span><script src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" async></script><span id="busuanzi_container_page_pv"> | <span id="busuanzi_value_page_pv"></span><span> Times</span></span></div><a data-disqus-identifier="2018/10/24/kafka-idempotent/" href="/2018/10/24/kafka-idempotent/#disqus_thread" class="disqus-comment-count"></a><div class="clear"><div id="toc" class="toc-article"><div class="toc-title">文章目录</div><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#Producer-幂等性"><span class="toc-number">1.</span> <span class="toc-text">Producer 幂等性</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#幂等性示例"><span class="toc-number">2.</span> <span class="toc-text">幂等性示例</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#幂等性要解决的问题"><span class="toc-number">3.</span> <span class="toc-text">幂等性要解决的问题</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#幂等性的实现原理"><span class="toc-number">4.</span> <span class="toc-text">幂等性的实现原理</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#PID"><span class="toc-number">4.1.</span> <span class="toc-text">PID</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Producer-PID-申请"><span class="toc-number">4.1.1.</span> <span class="toc-text">Producer PID 申请</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Server-PID-管理"><span class="toc-number">4.1.2.</span> <span class="toc-text">Server PID 管理</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#sequence-numbers"><span class="toc-number">4.2.</span> <span class="toc-text">sequence numbers</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#幂等性实现整体流程"><span class="toc-number">5.</span> <span class="toc-text">幂等性实现整体流程</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Client-幂等性时发送流程"><span class="toc-number">5.1.</span> <span class="toc-text">Client 幂等性时发送流程</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#幂等性时-Server-端如何处理-ProduceRequest-请求"><span class="toc-number">5.2.</span> <span class="toc-text">幂等性时 Server 端如何处理 ProduceRequest 请求</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#小思考"><span class="toc-number">6.</span> <span class="toc-text">小思考</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#为什么要求-MAX-IN-FLIGHT-REQUESTS-PER-CONNECTION-小于等于5"><span class="toc-number">6.1.</span> <span class="toc-text">为什么要求 MAX_IN_FLIGHT_REQUESTS_PER_CONNECTION 小于等于5</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#当-MAX-IN-FLIGHT-REQUESTS-PER-CONNECTION-配置大于1时，是否保证有序"><span class="toc-number">6.2.</span> <span class="toc-text">当 MAX_IN_FLIGHT_REQUESTS_PER_CONNECTION 配置大于1时，是否保证有序</span></a></li></ol></li></ol></div></div><div class="post-content"><p>Apache Kafka 从 0.11.0 开始，支持了一个非常大的 feature，就是对事务性的支持，在 Kafka 中关于事务性，是有三种层面上的含义：一是幂等性的支持；二是事务性的支持；三是 Kafka Streams 的 exactly once 的实现，关于 Kafka 事务性系列的文章我们只重点关注前两种层面上的事务性，与 Kafka Streams 相关的内容暂时不做讨论。社区从开始讨论事务性，前后持续近半年时间，相关的设计文档有六十几页（参考 <a href="https://docs.google.com/document/d/11Jqy_GjUGtdXJK94XGsEIK7CP1SnQGdp2eF0wSw9ra8/edit" target="_blank" rel="external">Exactly Once Delivery and Transactional Messaging in Kafka</a>）。事务性这部分的实现也是非常复杂的，之前 Producer 端的代码实现其实是非常简单的，增加事务性的逻辑之后，这部分代码复杂度提高了很多，本篇及后面几篇关于事务性的文章会以 2.0.0 版的代码实现为例，对这部分做了一下分析，计划分为五篇文章：</p>
<ol>
<li>第一篇：Kafka 幂等性实现；</li>
<li>第二篇：Kafka 事务性实现；</li>
<li>第三篇：Kafka 事务性相关处理请求在 Server 端如何处理及其实现细节；</li>
<li>第四篇：关于 Kafka 事务性实现的一些思考，也会简单介绍一下 RocketMQ 事务性的实现，做一下对比；</li>
<li>第五篇：Flink + Kafka 如何实现 Exactly Once；</li>
</ol>
<p>这篇是 Kafka 事务性系列的第一篇文章，主要讲述幂等性实现的整体流程，幂等性的实现相对于事务性的实现简单很多，也是事务性实现的基础。</p>
<h2 id="Producer-幂等性"><a href="#Producer-幂等性" class="headerlink" title="Producer 幂等性"></a>Producer 幂等性</h2><p>Producer 的幂等性指的是当发送同一条消息时，数据在 Server 端只会被持久化一次，数据不丟不重，但是这里的幂等性是有条件的：</p>
<ul>
<li>只能保证 Producer 在单个会话内不丟不重，如果 Producer 出现意外挂掉再重启是无法保证的（幂等性情况下，是无法获取之前的状态信息，因此是无法做到跨会话级别的不丢不重）;</li>
<li>幂等性不能跨多个 Topic-Partition，只能保证单个 partition 内的幂等性，当涉及多个 Topic-Partition 时，这中间的状态并没有同步。</li>
</ul>
<p>如果需要跨会话、跨多个 topic-partition 的情况，需要使用 Kafka 的事务性来实现。</p>
<h2 id="幂等性示例"><a href="#幂等性示例" class="headerlink" title="幂等性示例"></a>幂等性示例</h2><p>Producer 使用幂等性的示例非常简单，与正常情况下 Producer 使用相比变化不大，只需要把 Producer 的配置 enable.idempotence 设置为 true 即可，如下所示：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">Properties props = <span class="keyword">new</span> Properties();</span><br><span class="line">props.put(ProducerConfig.ENABLE_IDEMPOTENCE_CONFIG, <span class="string">"true"</span>);</span><br><span class="line">props.put(<span class="string">"acks"</span>, <span class="string">"all"</span>); <span class="comment">// 当 enable.idempotence 为 true，这里默认为 all</span></span><br><span class="line">props.put(<span class="string">"bootstrap.servers"</span>, <span class="string">"localhost:9092"</span>);</span><br><span class="line">props.put(<span class="string">"key.serializer"</span>, <span class="string">"org.apache.kafka.common.serialization.StringSerializer"</span>);</span><br><span class="line">props.put(<span class="string">"value.serializer"</span>, <span class="string">"org.apache.kafka.common.serialization.StringSerializer"</span>);</span><br><span class="line"></span><br><span class="line">KafkaProducer producer = <span class="keyword">new</span> KafkaProducer(props);</span><br><span class="line"></span><br><span class="line">producer.send(<span class="keyword">new</span> ProducerRecord(topic, <span class="string">"test"</span>);</span><br></pre></td></tr></table></figure>
<p>Prodcuer 幂等性对外保留的接口非常简单，其底层的实现对上层应用做了很好的封装，应用层并不需要去关心具体的实现细节，对用户非常友好。</p>
<h2 id="幂等性要解决的问题"><a href="#幂等性要解决的问题" class="headerlink" title="幂等性要解决的问题"></a>幂等性要解决的问题</h2><p>在看 Producer 是如何实现幂等性之前，首先先考虑一个问题：<strong>幂等性是来解决什么问题的？</strong> 在 0.11.0 之前，Kafka 通过 Producer 端和 Server 端的相关配置可以做到<strong>数据不丢</strong>，也就是 at least once，但是在一些情况下，可能会导致数据重复，比如：网络请求延迟等导致的重试操作，在发送请求重试时 Server 端并不知道这条请求是否已经处理（没有记录之前的状态信息），所以就会有可能导致数据请求的重复发送，这是 Kafka 自身的机制（异常时请求重试机制）导致的数据重复。</p>
<p>对于大多数应用而言，数据保证不丢是可以满足其需求的，但是对于一些其他的应用场景（比如支付数据等），它们是要求精确计数的，这时候如果上游数据有重复，下游应用只能在消费数据时进行相应的去重操作，应用在去重时，最常用的手段就是根据唯一 id 键做 check 去重。</p>
<p>在这种场景下，因为上游生产导致的数据重复问题，会导致所有有精确计数需求的下游应用都需要做这种复杂的、重复的去重处理。试想一下：如果在发送时，系统就能保证 exactly once，这对下游将是多么大的解脱。这就是幂等性要解决的问题，主要是解决数据重复的问题，正如前面所述，数据重复问题，通用的解决方案就是加唯一 id，然后根据 id 判断数据是否重复，Producer 的幂等性也是这样实现的，这一小节就让我们看下 Kafka 的 Producer 如何保证数据的 exactly once 的。</p>
<h2 id="幂等性的实现原理"><a href="#幂等性的实现原理" class="headerlink" title="幂等性的实现原理"></a>幂等性的实现原理</h2><p>在讲述幂等性处理流程之前，先看下 Producer 是如何来保证幂等性的，正如前面所述，幂等性要解决的问题是：Producer 设置 at least once 时，由于异常触发重试机制导致数据重复，幂等性的目的就是为了解决这个数据重复的问题，简单来说就是：</p>
<p><strong>at least once + 幂等 = exactly once</strong></p>
<p>通过在 al least once 的基础上加上 幂等性来坐到 exactly once，当然这个层面的 exactly once 是有限制的，比如它会要求单会话内有效或者跨会话使用事务性有效等。这里我们先分析最简单的情况，那就是在单会话内如何做到幂等性，进而保证 exactly once。</p>
<p>要做到幂等性，要解决下面的问题：</p>
<ol>
<li>系统需要有能力鉴别一条数据到底是不是重复的数据？常用的手段是通过 <strong>唯一键/唯一 id</strong> 来判断，这时候系统一般是需要缓存已经处理的唯一键记录，这样才能更有效率地判断一条数据是不是重复；</li>
<li>唯一键应该选择什么粒度？对于分布式存储系统来说，肯定不能用全局唯一键（全局是针对集群级别），核心的解决思路依然是 <strong>分而治之</strong>，数据密集型系统为了实现分布式都是有分区概念的，而分区之间是有相应的隔离，对于 Kafka 而言，这里的解决方案就是在分区的维度上去做，重复数据的判断让 partition 的 leader 去判断处理，前提是 Produce 请求需要把唯一键值告诉 leader；</li>
<li>分区粒度实现唯一键会不会有其他问题？这里需要考虑的问题是当一个 Partition 有来自多个 client 写入的情况，这些 client 之间是很难做到使用同一个唯一键（一个是它们之间很难做到唯一键的实时感知，另一个是这样实现是否有必要）。而如果系统在实现时做到了  <strong>client + partition</strong> 粒度，这样实现的好处是每个 client 都是完全独立的（它们之间不需要有任何的联系，这是非常大的优点），只是在 Server 端对不同的 client 做好相应的区分即可，当然同一个 client 在处理多个 Topic-Partition 时是完全可以使用同一个 PID 的。</li>
</ol>
<p>有了上面的分析（都是个人见解，如果有误，欢迎指教），就不难理解 Producer 幂等性的实现原理，Kafka Producer 在实现时有以下两个重要机制：</p>
<ol>
<li>PID（Producer ID），用来标识每个 producer client；</li>
<li>sequence numbers，client 发送的每条消息都会带相应的 sequence number，Server 端就是根据这个值来判断数据是否重复。</li>
</ol>
<p>下面详细讲述这两个实现机制。</p>
<h3 id="PID"><a href="#PID" class="headerlink" title="PID"></a>PID</h3><p>每个 Producer 在初始化时都会被分配一个唯一的 PID，这个 PID 对应用是透明的，完全没有暴露给用户。对于一个给定的 PID，sequence number 将会从0开始自增，每个 Topic-Partition 都会有一个独立的 sequence number。Producer 在发送数据时，将会给每条 msg 标识一个 sequence number，Server 也就是通过这个来验证数据是否重复。这里的 PID 是全局唯一的，Producer 故障后重新启动后会被分配一个新的 PID，这也是幂等性无法做到跨会话的一个原因。</p>
<h4 id="Producer-PID-申请"><a href="#Producer-PID-申请" class="headerlink" title="Producer PID 申请"></a>Producer PID 申请</h4><p>这里看下 PID 在 Server 端是如何分配的？Client 通过向 Server 发送一个 InitProducerIdRequest 请求获取 PID（幂等性时，是选择一台连接数最少的 Broker 发送这个请求），这里看下 Server 端是如何处理这个请求的？KafkaApis 中 <code>handleInitProducerIdRequest()</code> 方法的实现如下：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">handleInitProducerIdRequest</span></span>(request: <span class="type">RequestChannel</span>.<span class="type">Request</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">  <span class="keyword">val</span> initProducerIdRequest = request.body[<span class="type">InitProducerIdRequest</span>]</span><br><span class="line">  <span class="keyword">val</span> transactionalId = initProducerIdRequest.transactionalId</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> (transactionalId != <span class="literal">null</span>) &#123; <span class="comment">//note: 设置 txn.id 时，验证对 txn.id 的权限</span></span><br><span class="line">    <span class="keyword">if</span> (!authorize(request.session, <span class="type">Write</span>, <span class="type">Resource</span>(<span class="type">TransactionalId</span>, transactionalId, <span class="type">LITERAL</span>))) &#123;</span><br><span class="line">      sendErrorResponseMaybeThrottle(request, <span class="type">Errors</span>.<span class="type">TRANSACTIONAL_ID_AUTHORIZATION_FAILED</span>.exception)</span><br><span class="line">      <span class="keyword">return</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125; <span class="keyword">else</span> <span class="keyword">if</span> (!authorize(request.session, <span class="type">IdempotentWrite</span>, <span class="type">Resource</span>.<span class="type">ClusterResource</span>)) &#123; <span class="comment">//note: 没有设置 txn.id 时，验证对集群是否有幂等性权限</span></span><br><span class="line">    sendErrorResponseMaybeThrottle(request, <span class="type">Errors</span>.<span class="type">CLUSTER_AUTHORIZATION_FAILED</span>.exception)</span><br><span class="line">    <span class="keyword">return</span></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">sendResponseCallback</span></span>(result: <span class="type">InitProducerIdResult</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">createResponse</span></span>(requestThrottleMs: <span class="type">Int</span>): <span class="type">AbstractResponse</span> = &#123;</span><br><span class="line">      <span class="keyword">val</span> responseBody = <span class="keyword">new</span> <span class="type">InitProducerIdResponse</span>(requestThrottleMs, result.error, result.producerId, result.producerEpoch)</span><br><span class="line">      trace(<span class="string">s"Completed <span class="subst">$transactionalId</span>'s InitProducerIdRequest with result <span class="subst">$result</span> from client <span class="subst">$&#123;request.header.clientId&#125;</span>."</span>)</span><br><span class="line">      responseBody</span><br><span class="line">    &#125;</span><br><span class="line">    sendResponseMaybeThrottle(request, createResponse)</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">//note: 生成相应的了 pid，返回给 producer</span></span><br><span class="line">  txnCoordinator.handleInitProducerId(transactionalId, initProducerIdRequest.transactionTimeoutMs, sendResponseCallback)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这里实际上是调用了 TransactionCoordinator （Broker 在启动 server 服务时都会初始化这个实例）的 <code>handleInitProducerId()</code> 方法做了相应的处理，其实现如下（这里只关注幂等性的处理）：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">handleInitProducerId</span></span>(transactionalId: <span class="type">String</span>,</span><br><span class="line">                         transactionTimeoutMs: <span class="type">Int</span>,</span><br><span class="line">                         responseCallback: <span class="type">InitProducerIdCallback</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> (transactionalId == <span class="literal">null</span>) &#123; <span class="comment">//note: 只设置幂等性时，直接分配 pid 并返回</span></span><br><span class="line">    <span class="comment">// if the transactional id is null, then always blindly accept the request</span></span><br><span class="line">    <span class="comment">// and return a new producerId from the producerId manager</span></span><br><span class="line">    <span class="keyword">val</span> producerId = producerIdManager.generateProducerId()</span><br><span class="line">    responseCallback(<span class="type">InitProducerIdResult</span>(producerId, producerEpoch = <span class="number">0</span>, <span class="type">Errors</span>.<span class="type">NONE</span>))</span><br><span class="line">  &#125;</span><br><span class="line">  ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>Server 在给一个 client 初始化 PID 时，实际上是通过 ProducerIdManager 的 <code>generateProducerId()</code> 方法产生一个 PID。</p>
<h4 id="Server-PID-管理"><a href="#Server-PID-管理" class="headerlink" title="Server PID 管理"></a>Server PID 管理</h4><p>如前面所述，在幂等性的情况下，直接通过 ProducerIdManager 的 <code>generateProducerId()</code> 方法产生一个 PID，其中 ProducerIdManager 是在 TransactionCoordinator 对象初始化时初始化的，这个对象主要是用来管理 PID 信息：</p>
<ul>
<li>在本地的 PID 端用完了或者处于新建状态时，申请 PID 段（默认情况下，每次申请 1000 个 PID）；</li>
<li>TransactionCoordinator 对象通过 <code>generateProducerId()</code> 方法获取下一个可以使用的 PID；</li>
</ul>
<p><strong>PID 端申请是向 ZooKeeper 申请</strong>，zk 中有一个 <code>/latest_producer_id_block</code> 节点，每个 Broker 向 zk 申请一个 PID 段后，都会把自己申请的 PID 段信息写入到这个节点，这样当其他 Broker 再申请 PID 段时，会首先读写这个节点的信息，然后根据 block_end 选择一个 PID 段，最后再把信息写会到 zk 的这个节点，这个节点信息格式如下所示：</p>
<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#123;<span class="attr">"version"</span>:<span class="number">1</span>,<span class="attr">"broker"</span>:<span class="number">35</span>,<span class="attr">"block_start"</span>:<span class="string">"4000"</span>,<span class="attr">"block_end"</span>:<span class="string">"4999"</span>&#125;</span><br></pre></td></tr></table></figure>
<p>ProducerIdManager 向 zk 申请 PID 段的方法如下：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">getNewProducerIdBlock</span></span>(): <span class="type">Unit</span> = &#123;</span><br><span class="line">  <span class="keyword">var</span> zkWriteComplete = <span class="literal">false</span></span><br><span class="line">  <span class="keyword">while</span> (!zkWriteComplete) &#123; <span class="comment">//note: 直到从 zk 拿取到分配的 PID 段</span></span><br><span class="line">    <span class="comment">// refresh current producerId block from zookeeper again</span></span><br><span class="line">    <span class="keyword">val</span> (dataOpt, zkVersion) = zkClient.getDataAndVersion(<span class="type">ProducerIdBlockZNode</span>.path)</span><br><span class="line"></span><br><span class="line">    <span class="comment">// generate the new producerId block</span></span><br><span class="line">    currentProducerIdBlock = dataOpt <span class="keyword">match</span> &#123;</span><br><span class="line">      <span class="keyword">case</span> <span class="type">Some</span>(data) =&gt;</span><br><span class="line">        <span class="comment">//note: 从 zk 获取当前最新的 pid 信息，如果后面更新失败，这里也会重新从 zk 获取</span></span><br><span class="line">        <span class="keyword">val</span> currProducerIdBlock = <span class="type">ProducerIdManager</span>.parseProducerIdBlockData(data)</span><br><span class="line">        debug(<span class="string">s"Read current producerId block <span class="subst">$currProducerIdBlock</span>, Zk path version <span class="subst">$zkVersion</span>"</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (currProducerIdBlock.blockEndId &gt; <span class="type">Long</span>.<span class="type">MaxValue</span> - <span class="type">ProducerIdManager</span>.<span class="type">PidBlockSize</span>) &#123;<span class="comment">//note: 不足以分配1000个 PID</span></span><br><span class="line">          <span class="comment">// we have exhausted all producerIds (wow!), treat it as a fatal error</span></span><br><span class="line">          <span class="comment">//note: 当 PID 分配超过限制时，直接报错了（每秒分配1个，够用2百亿年了）</span></span><br><span class="line">          fatal(<span class="string">s"Exhausted all producerIds as the next block's end producerId is will has exceeded long type limit (current block end producerId is <span class="subst">$&#123;currProducerIdBlock.blockEndId&#125;</span>)"</span>)</span><br><span class="line">          <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">KafkaException</span>(<span class="string">"Have exhausted all producerIds."</span>)</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="type">ProducerIdBlock</span>(brokerId, currProducerIdBlock.blockEndId + <span class="number">1</span>L, currProducerIdBlock.blockEndId + <span class="type">ProducerIdManager</span>.<span class="type">PidBlockSize</span>)</span><br><span class="line">      <span class="keyword">case</span> <span class="type">None</span> =&gt; <span class="comment">//note: 该节点还不存在，第一次初始化</span></span><br><span class="line">        debug(<span class="string">s"There is no producerId block yet (Zk path version <span class="subst">$zkVersion</span>), creating the first block"</span>)</span><br><span class="line">        <span class="type">ProducerIdBlock</span>(brokerId, <span class="number">0</span>L, <span class="type">ProducerIdManager</span>.<span class="type">PidBlockSize</span> - <span class="number">1</span>)</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> newProducerIdBlockData = <span class="type">ProducerIdManager</span>.generateProducerIdBlockJson(currentProducerIdBlock)</span><br><span class="line"></span><br><span class="line">    <span class="comment">// try to write the new producerId block into zookeeper</span></span><br><span class="line">    <span class="comment">//note: 将新的 pid 信息写入到 zk，如果写入失败（写入之前会比对 zkVersion，如果这个有变动，证明这期间有别的 Broker 在操作，那么写入失败），重新申请</span></span><br><span class="line">    <span class="keyword">val</span> (succeeded, version) = zkClient.conditionalUpdatePath(<span class="type">ProducerIdBlockZNode</span>.path,</span><br><span class="line">      newProducerIdBlockData, zkVersion, <span class="type">Some</span>(checkProducerIdBlockZkData))</span><br><span class="line">    zkWriteComplete = succeeded</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (zkWriteComplete)</span><br><span class="line">      info(<span class="string">s"Acquired new producerId block <span class="subst">$currentProducerIdBlock</span> by writing to Zk with path version <span class="subst">$version</span>"</span>)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>ProducerIdManager 申请 PID 段的流程如下：</p>
<ol>
<li>先从 zk 的 <code>/latest_producer_id_block</code> 节点读取最新已经分配的 PID 段信息；</li>
<li>如果该节点不存在，直接从 0 开始分配，选择 0~1000 的 PID 段（ProducerIdManager 的 PidBlockSize 默认为 1000，即是每次申请的 PID 段大小）；</li>
<li>如果该节点存在，读取其中数据，根据 block_end 选择 <block_end+1, block_end+1000> 这个 PID 段（如果 PID 段超过 Long 类型的最大值，这里会直接返回一个异常）；</block_end+1,></li>
<li>在选择了相应的 PID 段后，将这个 PID 段信息写回到 zk 的这个节点中，如果写入成功，那么 PID 段就证明申请成功，如果写入失败（写入时会判断当前节点的 zkVersion 是否与步骤1获取的 zkVersion 相同，如果相同，那么可以成功写入，否则写入就会失败，证明这个节点被修改过），证明此时可能其他的 Broker 已经更新了这个节点（当前的 PID 段可能已经被其他 Broker 申请），那么从步骤 1 重新开始，直到写入成功。</li>
</ol>
<p>明白了 ProducerIdManager 如何申请 PID 段之后，再看 <code>generateProducerId()</code> 这个方法就简单很多了，这个方法在每次调用时，都会更新 nextProducerId 值（下一次可以使用 PID 值），如下所示：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">generateProducerId</span></span>(): <span class="type">Long</span> = &#123;</span><br><span class="line">  <span class="keyword">this</span> synchronized &#123;</span><br><span class="line">    <span class="comment">// grab a new block of producerIds if this block has been exhausted</span></span><br><span class="line">    <span class="keyword">if</span> (nextProducerId &gt; currentProducerIdBlock.blockEndId) &#123;</span><br><span class="line">      <span class="comment">//note: 如果分配的 pid 用完了，重新再向 zk 申请一批</span></span><br><span class="line">      getNewProducerIdBlock()</span><br><span class="line">      nextProducerId = currentProducerIdBlock.blockStartId + <span class="number">1</span></span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      nextProducerId += <span class="number">1</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    nextProducerId - <span class="number">1</span> <span class="comment">//note: 返回当前分配的 pid</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这里就是 Producer PID 如何申请（事务性情况下 PID 的申请会复杂一些，下篇文章再讲述）以及 Server 端如何管理 PID 的。</p>
<h3 id="sequence-numbers"><a href="#sequence-numbers" class="headerlink" title="sequence numbers"></a>sequence numbers</h3><p>再有了 PID 之后，在 PID + Topic-Partition 级别上添加一个 sequence numbers 信息，就可以实现 Producer 的幂等性了。ProducerBatch 也提供了一个 <code>setProducerState()</code> 方法，它可以给一个 batch 添加一些 meta 信息（pid、baseSequence、isTransactional），这些信息是会伴随着 ProduceRequest 发到 Server 端，Server 端也正是通过这些 meta 来做相应的判断，如下所示：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// ProducerBatch</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setProducerState</span><span class="params">(ProducerIdAndEpoch producerIdAndEpoch, <span class="keyword">int</span> baseSequence, <span class="keyword">boolean</span> isTransactional)</span> </span>&#123;</span><br><span class="line">    recordsBuilder.setProducerState(producerIdAndEpoch.producerId, producerIdAndEpoch.epoch, baseSequence, isTransactional);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// MemoryRecordsBuilder</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setProducerState</span><span class="params">(<span class="keyword">long</span> producerId, <span class="keyword">short</span> producerEpoch, <span class="keyword">int</span> baseSequence, <span class="keyword">boolean</span> isTransactional)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (isClosed()) &#123;</span><br><span class="line">        <span class="comment">// Sequence numbers are assigned when the batch is closed while the accumulator is being drained.</span></span><br><span class="line">        <span class="comment">// If the resulting ProduceRequest to the partition leader failed for a retriable error, the batch will</span></span><br><span class="line">        <span class="comment">// be re queued. In this case, we should not attempt to set the state again, since changing the producerId and sequence</span></span><br><span class="line">        <span class="comment">// once a batch has been sent to the broker risks introducing duplicates.</span></span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> IllegalStateException(<span class="string">"Trying to set producer state of an already closed batch. This indicates a bug on the client."</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">this</span>.producerId = producerId;</span><br><span class="line">    <span class="keyword">this</span>.producerEpoch = producerEpoch;</span><br><span class="line">    <span class="keyword">this</span>.baseSequence = baseSequence;</span><br><span class="line">    <span class="keyword">this</span>.isTransactional = isTransactional;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="幂等性实现整体流程"><a href="#幂等性实现整体流程" class="headerlink" title="幂等性实现整体流程"></a>幂等性实现整体流程</h2><p>在前面讲述完 Kafka 幂等性的两个实现机制（PID+sequence numbers）之后，这里详细讲述一下，幂等性时其整体的处理流程，主要讲述幂等性相关的内容，其他的部分会简单介绍（可以参考前面【Kafka 源码分析系列文章】了解 Producer 端处理流程以及 Server 端关于 ProduceRequest 请求的处理流程），其流程如下图所示：</p>
<p><img src="/images/kafka/kafka-idemoptent.png" alt="Producer 幂等性时处理流程"></p>
<p>这个图只展示了幂等性情况下，Producer 的大概流程，很多部分在前面的文章中做过分析，本文不再讲述，这里重点关注与幂等性相关的内容（事务性实现更加复杂，后面的文章再讲述），首先 KafkaProducer 在初始化时会初始化一个 TransactionManager 实例，它的作用有以下几个部分：</p>
<ol>
<li>记录本地的事务状态（事务性时必须）；</li>
<li>记录一些状态信息以保证幂等性，比如：每个 topic-partition 对应的下一个 sequence numbers 和 last acked batch（最近一个已经确认的 batch）的最大的 sequence number 等；</li>
<li>记录 ProducerIdAndEpoch 信息（PID 信息）。</li>
</ol>
<h3 id="Client-幂等性时发送流程"><a href="#Client-幂等性时发送流程" class="headerlink" title="Client 幂等性时发送流程"></a>Client 幂等性时发送流程</h3><p>如前面图中所示，幂等性时，Producer 的发送流程如下：</p>
<ol>
<li>应用通过 KafkaProducer 的 <code>send()</code> 方法将数据添加到 RecordAccumulator 中，添加时会判断是否需要新建一个 ProducerBatch，这时这个 ProducerBatch 还是没有 PID 和 sequence number 信息的；</li>
<li>Producer 后台发送线程 Sender，在 <code>run()</code> 方法中，会先根据 TransactionManager 的 <code>shouldResetProducerStateAfterResolvingSequences()</code> 方法判断当前的 PID 是否需要重置，重置的原因是因为：如果有 topic-partition 的 batch 重试多次失败最后因为超时而被移除，这时 sequence number 将无法做到连续，因为 sequence number 有部分已经分配出去，这时系统依赖自身的机制无法继续进行下去（因为幂等性是要保证不丢不重的），相当于程序遇到了一个 fatal 异常，PID 会进行重置，TransactionManager 相关的缓存信息被清空（Producer 不会重启），只是保存状态信息的 TransactionManager 做了 <code>clear+new</code> 操作，遇到这个问题时是无法保证 exactly once 的（有数据已经发送失败了，并且超过了重试次数）；</li>
<li>Sender 线程通过 <code>maybeWaitForProducerId()</code> 方法判断是否需要申请 PID，如果需要的话，这里会阻塞直到获取到相应的 PID 信息；</li>
<li>Sender 线程通过 <code>sendProducerData()</code> 方法发送数据，整体流程与之前的 Producer 流程相似，不同的地方是在 RecordAccumulator 的 <code>drain()</code> 方法中，在加了幂等性之后，<code>drain()</code> 方法多了如下几步判断：<ol>
<li>常规的判断：判断这个 topic-partition 是否可以继续发送（如果出现前面2中的情况是不允许发送的）、判断 PID 是否有效、如果这个 batch 是重试的 batch，那么需要判断这个 batch 之前是否还有 batch 没有发送完成，如果有，这里会先跳过这个 Topic-Partition 的发送，直到前面的 batch 发送完成，<strong>最坏情况下，这个 Topic-Partition 的 in-flight request 将会减少到1</strong>（这个涉及也是考虑到 server 端的一个设置，文章下面会详细分析）；</li>
<li>如果这个 ProducerBatch 还没有这个相应的 PID 和 sequence number 信息，会在这里进行相应的设置；</li>
</ol>
</li>
<li>最后 Sender 线程再调用 <code>sendProduceRequests()</code> 方法发送 ProduceRequest 请求，后面的就跟之前正常的流程保持一致了。</li>
</ol>
<p>这里看下几个关键方法的实现，首先是 Sender 线程获取 PID 信息的方法  <code>maybeWaitForProducerId()</code> ，其实现如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//note: 等待直到 Producer 获取到相应的 PID 和 epoch 信息</span></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">maybeWaitForProducerId</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">while</span> (!transactionManager.hasProducerId() &amp;&amp; !transactionManager.hasError()) &#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            Node node = awaitLeastLoadedNodeReady(requestTimeoutMs); <span class="comment">//note: 选取 node（本地连接数最少的 node）</span></span><br><span class="line">            <span class="keyword">if</span> (node != <span class="keyword">null</span>) &#123;</span><br><span class="line">                ClientResponse response = sendAndAwaitInitProducerIdRequest(node); <span class="comment">//note: 发送 InitPidRequest</span></span><br><span class="line">                InitProducerIdResponse initProducerIdResponse = (InitProducerIdResponse) response.responseBody();</span><br><span class="line">                Errors error = initProducerIdResponse.error();</span><br><span class="line">                <span class="keyword">if</span> (error == Errors.NONE) &#123; <span class="comment">//note: 更新 Producer 的 PID 和 epoch 信息</span></span><br><span class="line">                    ProducerIdAndEpoch producerIdAndEpoch = <span class="keyword">new</span> ProducerIdAndEpoch(</span><br><span class="line">                            initProducerIdResponse.producerId(), initProducerIdResponse.epoch());</span><br><span class="line">                    transactionManager.setProducerIdAndEpoch(producerIdAndEpoch);</span><br><span class="line">                    <span class="keyword">return</span>;</span><br><span class="line">                &#125; <span class="keyword">else</span> <span class="keyword">if</span> (error.exception() <span class="keyword">instanceof</span> RetriableException) &#123;</span><br><span class="line">                    log.debug(<span class="string">"Retriable error from InitProducerId response"</span>, error.message());</span><br><span class="line">                &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                    transactionManager.transitionToFatalError(error.exception());</span><br><span class="line">                    <span class="keyword">break</span>;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                log.debug(<span class="string">"Could not find an available broker to send InitProducerIdRequest to. "</span> +</span><br><span class="line">                        <span class="string">"We will back off and try again."</span>);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; <span class="keyword">catch</span> (UnsupportedVersionException e) &#123;</span><br><span class="line">            transactionManager.transitionToFatalError(e);</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">        &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">            log.debug(<span class="string">"Broker &#123;&#125; disconnected while awaiting InitProducerId response"</span>, e);</span><br><span class="line">        &#125;</span><br><span class="line">        log.trace(<span class="string">"Retry InitProducerIdRequest in &#123;&#125;ms."</span>, retryBackoffMs);</span><br><span class="line">        time.sleep(retryBackoffMs);</span><br><span class="line">        metadata.requestUpdate();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>再看下 RecordAccumulator 的 <code>drain()</code> 方法，重点需要关注的是关于幂等性和事务性相关的处理，具体如下所示，这里面关于事务性相关的判断在上面的流程中已经讲述。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Drain all the data for the given nodes and collate them into a list of batches that will fit within the specified</span></span><br><span class="line"><span class="comment"> * size on a per-node basis. This method attempts to avoid choosing the same topic-node over and over.</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> cluster The current cluster metadata</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> nodes The list of node to drain</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> maxSize The maximum number of bytes to drain</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> now The current unix time in milliseconds</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@return</span> A list of &#123;<span class="doctag">@link</span> ProducerBatch&#125; for each node specified with total size less than the requested maxSize.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> Map&lt;Integer, List&lt;ProducerBatch&gt;&gt; drain(Cluster cluster,</span><br><span class="line">                                               Set&lt;Node&gt; nodes,</span><br><span class="line">                                               <span class="keyword">int</span> maxSize,</span><br><span class="line">                                               <span class="keyword">long</span> now) &#123;</span><br><span class="line">    <span class="keyword">if</span> (nodes.isEmpty())</span><br><span class="line">        <span class="keyword">return</span> Collections.emptyMap();</span><br><span class="line"></span><br><span class="line">    Map&lt;Integer, List&lt;ProducerBatch&gt;&gt; batches = <span class="keyword">new</span> HashMap&lt;&gt;();</span><br><span class="line">    <span class="keyword">for</span> (Node node : nodes) &#123;</span><br><span class="line">        <span class="keyword">int</span> size = <span class="number">0</span>;</span><br><span class="line">        List&lt;PartitionInfo&gt; parts = cluster.partitionsForNode(node.id());</span><br><span class="line">        List&lt;ProducerBatch&gt; ready = <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line">        <span class="comment">/* to make starvation less likely this loop doesn't start at 0 */</span></span><br><span class="line">        <span class="keyword">int</span> start = drainIndex = drainIndex % parts.size();</span><br><span class="line">        <span class="keyword">do</span> &#123;</span><br><span class="line">            PartitionInfo part = parts.get(drainIndex);</span><br><span class="line">            TopicPartition tp = <span class="keyword">new</span> TopicPartition(part.topic(), part.partition());</span><br><span class="line">            <span class="comment">// Only proceed if the partition has no in-flight batches.</span></span><br><span class="line">            <span class="keyword">if</span> (!isMuted(tp, now)) &#123;</span><br><span class="line">                Deque&lt;ProducerBatch&gt; deque = getDeque(tp);</span><br><span class="line">                <span class="keyword">if</span> (deque != <span class="keyword">null</span>) &#123;</span><br><span class="line">                    <span class="keyword">synchronized</span> (deque) &#123; <span class="comment">//note: 先判断有没有数据，然后后面真正处理时再加锁处理</span></span><br><span class="line">                        ProducerBatch first = deque.peekFirst();</span><br><span class="line">                        <span class="keyword">if</span> (first != <span class="keyword">null</span>) &#123;</span><br><span class="line">                            <span class="keyword">boolean</span> backoff = first.attempts() &gt; <span class="number">0</span> &amp;&amp; first.waitedTimeMs(now) &lt; retryBackoffMs;</span><br><span class="line">                            <span class="comment">// Only drain the batch if it is not during backoff period.</span></span><br><span class="line">                            <span class="keyword">if</span> (!backoff) &#123;</span><br><span class="line">                                <span class="keyword">if</span> (size + first.estimatedSizeInBytes() &gt; maxSize &amp;&amp; !ready.isEmpty()) &#123;</span><br><span class="line">                                    <span class="comment">// there is a rare case that a single batch size is larger than the request size due</span></span><br><span class="line">                                    <span class="comment">// to compression; in this case we will still eventually send this batch in a single</span></span><br><span class="line">                                    <span class="comment">// request</span></span><br><span class="line">                                    <span class="keyword">break</span>;</span><br><span class="line">                                &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                                    ProducerIdAndEpoch producerIdAndEpoch = <span class="keyword">null</span>;</span><br><span class="line">                                    <span class="keyword">boolean</span> isTransactional = <span class="keyword">false</span>;</span><br><span class="line">                                    <span class="keyword">if</span> (transactionManager != <span class="keyword">null</span>) &#123; <span class="comment">//note: 幂等性或事务性时， 做一些检查判断</span></span><br><span class="line">                                        <span class="keyword">if</span> (!transactionManager.isSendToPartitionAllowed(tp))</span><br><span class="line">                                            <span class="keyword">break</span>;</span><br><span class="line"></span><br><span class="line">                                        producerIdAndEpoch = transactionManager.producerIdAndEpoch();</span><br><span class="line">                                        <span class="keyword">if</span> (!producerIdAndEpoch.isValid()) <span class="comment">//note: pid 是否有效</span></span><br><span class="line">                                            <span class="comment">// we cannot send the batch until we have refreshed the producer id</span></span><br><span class="line">                                            <span class="keyword">break</span>;</span><br><span class="line"></span><br><span class="line">                                        isTransactional = transactionManager.isTransactional();</span><br><span class="line"></span><br><span class="line">                                        <span class="keyword">if</span> (!first.hasSequence() &amp;&amp; transactionManager.hasUnresolvedSequence(first.topicPartition))</span><br><span class="line">                                            <span class="comment">//note: 当前这个 topic-partition 的数据出现过超时,不能发送,如果是新的 batch 数据直接跳过（没有 seq  number 信息）</span></span><br><span class="line">                                            <span class="comment">// Don't drain any new batches while the state of previous sequence numbers</span></span><br><span class="line">                                            <span class="comment">// is unknown. The previous batches would be unknown if they were aborted</span></span><br><span class="line">                                            <span class="comment">// on the client after being sent to the broker at least once.</span></span><br><span class="line">                                            <span class="keyword">break</span>;</span><br><span class="line"></span><br><span class="line">                                        <span class="keyword">int</span> firstInFlightSequence = transactionManager.firstInFlightSequence(first.topicPartition);</span><br><span class="line">                                        <span class="keyword">if</span> (firstInFlightSequence != RecordBatch.NO_SEQUENCE &amp;&amp; first.hasSequence()</span><br><span class="line">                                                &amp;&amp; first.baseSequence() != firstInFlightSequence)</span><br><span class="line">                                            <span class="comment">//note: 重试操作（seq number 不为0）,如果这个 batch 的 baseSequence 与 in-flight</span></span><br><span class="line">                                            <span class="comment">//note: queue 中第一个 request batch 的 baseSequence不同的话（证明它前面还有请求未成功）,</span></span><br><span class="line">                                            <span class="comment">//note: 会等待下次循环再判断, 最坏的情况下会导致 in-flight request 为1（只影响这个 partition）</span></span><br><span class="line">                                            <span class="comment">//note: 这种情况下,继续发送这个是没有意义的,因为幂等性时保证顺序的,只有前面的都成功,后面的再发送才有意义</span></span><br><span class="line">                                            <span class="comment">//note: 这里是 break,相当于在这次发送中直接跳过了这个 topic-partition 的发送</span></span><br><span class="line">                                            <span class="comment">// If the queued batch already has an assigned sequence, then it is being</span></span><br><span class="line">                                            <span class="comment">// retried. In this case, we wait until the next immediate batch is ready</span></span><br><span class="line">                                            <span class="comment">// and drain that. We only move on when the next in line batch is complete (either successfully</span></span><br><span class="line">                                            <span class="comment">// or due to a fatal broker error). This effectively reduces our</span></span><br><span class="line">                                            <span class="comment">// in flight request count to 1.</span></span><br><span class="line">                                            <span class="keyword">break</span>;</span><br><span class="line">                                    &#125;</span><br><span class="line"></span><br><span class="line">                                    ProducerBatch batch = deque.pollFirst();</span><br><span class="line">                                    <span class="keyword">if</span> (producerIdAndEpoch != <span class="keyword">null</span> &amp;&amp; !batch.hasSequence()) &#123;<span class="comment">//note: batch 的相关信息（seq id）是在这里设置的</span></span><br><span class="line">                                        <span class="comment">//note: 这个 batch 还没有 seq number 信息</span></span><br><span class="line">                                        <span class="comment">// If the batch already has an assigned sequence, then we should not change the producer id and</span></span><br><span class="line">                                        <span class="comment">// sequence number, since this may introduce duplicates. In particular,</span></span><br><span class="line">                                        <span class="comment">// the previous attempt may actually have been accepted, and if we change</span></span><br><span class="line">                                        <span class="comment">// the producer id and sequence here, this attempt will also be accepted,</span></span><br><span class="line">                                        <span class="comment">// causing a duplicate.</span></span><br><span class="line">                                        <span class="comment">//</span></span><br><span class="line">                                        <span class="comment">// Additionally, we update the next sequence number bound for the partition,</span></span><br><span class="line">                                        <span class="comment">// and also have the transaction manager track the batch so as to ensure</span></span><br><span class="line">                                        <span class="comment">// that sequence ordering is maintained even if we receive out of order</span></span><br><span class="line">                                        <span class="comment">// responses.</span></span><br><span class="line">                                        <span class="comment">//note: 给这个 batch 设置相应的 pid、seq id 等信息</span></span><br><span class="line">                                        batch.setProducerState(producerIdAndEpoch, transactionManager.sequenceNumber(batch.topicPartition), isTransactional);</span><br><span class="line">                                        transactionManager.incrementSequenceNumber(batch.topicPartition, batch.recordCount); <span class="comment">//note: 增加 partition 对应的下一个 seq id 值</span></span><br><span class="line">                                        log.debug(<span class="string">"Assigned producerId &#123;&#125; and producerEpoch &#123;&#125; to batch with base sequence "</span> +</span><br><span class="line">                                                        <span class="string">"&#123;&#125; being sent to partition &#123;&#125;"</span>, producerIdAndEpoch.producerId,</span><br><span class="line">                                                producerIdAndEpoch.epoch, batch.baseSequence(), tp);</span><br><span class="line"></span><br><span class="line">                                        transactionManager.addInFlightBatch(batch);</span><br><span class="line">                                    &#125;</span><br><span class="line">                                    batch.close();</span><br><span class="line">                                    size += batch.records().sizeInBytes();</span><br><span class="line">                                    ready.add(batch);</span><br><span class="line">                                    batch.drained(now);</span><br><span class="line">                                &#125;</span><br><span class="line">                            &#125;</span><br><span class="line">                        &#125;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">this</span>.drainIndex = (<span class="keyword">this</span>.drainIndex + <span class="number">1</span>) % parts.size();</span><br><span class="line">        &#125; <span class="keyword">while</span> (start != drainIndex);</span><br><span class="line">        batches.put(node.id(), ready);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> batches;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="幂等性时-Server-端如何处理-ProduceRequest-请求"><a href="#幂等性时-Server-端如何处理-ProduceRequest-请求" class="headerlink" title="幂等性时 Server 端如何处理 ProduceRequest 请求"></a>幂等性时 Server 端如何处理 ProduceRequest 请求</h3><p>如前面途中所示，当 Broker 收到 ProduceRequest 请求之后，会通过 <code>handleProduceRequest()</code> 做相应的处理，其处理流程如下（这里只讲述关于幂等性相关的内容）：</p>
<ol>
<li>如果请求是事务请求，检查是否对 TXN.id 有 Write 权限，没有的话返回 TRANSACTIONAL_ID_AUTHORIZATION_FAILED；</li>
<li>如果请求设置了幂等性，检查是否对 ClusterResource 有 IdempotentWrite 权限，没有的话返回 CLUSTER_AUTHORIZATION_FAILED；</li>
<li>验证对 topic 是否有 Write 权限以及 Topic 是否存在，否则返回 TOPIC_AUTHORIZATION_FAILED 或 UNKNOWN_TOPIC_OR_PARTITION 异常；</li>
<li>检查是否有 PID 信息，没有的话走正常的写入流程；</li>
<li>LOG 对象会在 <code>analyzeAndValidateProducerState()</code> 方法先根据 batch 的 sequence number 信息检查这个 batch 是否重复（server 端会缓存 PID 对应这个 Topic-Partition 的最近5个 batch 信息），如果有重复，这里当做写入成功返回（不更新 LOG 对象中相应的状态信息，比如这个 replica 的 the end offset 等）；</li>
<li>有了 PID 信息，并且不是重复 batch 时，在更新 producer 信息时，会做以下校验：<ol>
<li>检查该 PID 是否已经缓存中存在（主要是在 ProducerStateManager 对象中检查）；</li>
<li>如果不存在，那么判断 sequence number 是否 从0 开始，是的话，在缓存中记录 PID 的 meta（PID，epoch， sequence number），并执行写入操作，否则返回 UnknownProducerIdException（PID 在 server 端已经过期或者这个 PID 写的数据都已经过期了，但是 Client 还在接着上次的 sequence number 发送数据）；</li>
<li>如果该 PID 存在，先检查 PID epoch 与 server 端记录的是否相同；</li>
<li>如果不同并且 sequence number 不从 0 开始，那么返回 OutOfOrderSequenceException 异常；</li>
<li>如果不同并且 sequence number 从 0 开始，那么正常写入；</li>
<li>如果相同，那么根据缓存中记录的最近一次 sequence number（currentLastSeq）检查是否为连续（会区分为 0、Int.MaxValue 等情况），不连续的情况下返回 OutOfOrderSequenceException 异常。</li>
</ol>
</li>
<li>下面与正常写入相同。</li>
</ol>
<p>幂等性时，Broker 在处理 ProduceRequest 请求时，多了一些校验操作，这里重点看一下其中一些重要实现，先看下 <code>analyzeAndValidateProducerState()</code> 方法的实现，如下所示：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">analyzeAndValidateProducerState</span></span>(records: <span class="type">MemoryRecords</span>, isFromClient: <span class="type">Boolean</span>): (mutable.<span class="type">Map</span>[<span class="type">Long</span>, <span class="type">ProducerAppendInfo</span>], <span class="type">List</span>[<span class="type">CompletedTxn</span>], <span class="type">Option</span>[<span class="type">BatchMetadata</span>]) = &#123;</span><br><span class="line">  <span class="keyword">val</span> updatedProducers = mutable.<span class="type">Map</span>.empty[<span class="type">Long</span>, <span class="type">ProducerAppendInfo</span>]</span><br><span class="line">  <span class="keyword">val</span> completedTxns = <span class="type">ListBuffer</span>.empty[<span class="type">CompletedTxn</span>]</span><br><span class="line">  <span class="keyword">for</span> (batch &lt;- records.batches.asScala <span class="keyword">if</span> batch.hasProducerId) &#123; <span class="comment">//note: 有 pid 时,才会做相应的判断</span></span><br><span class="line">    <span class="keyword">val</span> maybeLastEntry = producerStateManager.lastEntry(batch.producerId)</span><br><span class="line"></span><br><span class="line">    <span class="comment">// if this is a client produce request, there will be up to 5 batches which could have been duplicated.</span></span><br><span class="line">    <span class="comment">// If we find a duplicate, we return the metadata of the appended batch to the client.</span></span><br><span class="line">    <span class="keyword">if</span> (isFromClient) &#123;</span><br><span class="line">      maybeLastEntry.flatMap(_.findDuplicateBatch(batch)).foreach &#123; duplicate =&gt;</span><br><span class="line">        <span class="keyword">return</span> (updatedProducers, completedTxns.toList, <span class="type">Some</span>(duplicate)) <span class="comment">//note: 如果这个 batch 已经收到过，这里直接返回</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> maybeCompletedTxn = updateProducers(batch, updatedProducers, isFromClient = isFromClient) <span class="comment">//note: 这里</span></span><br><span class="line">    maybeCompletedTxn.foreach(completedTxns += _)</span><br><span class="line">  &#125;</span><br><span class="line">  (updatedProducers, completedTxns.toList, <span class="type">None</span>)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>如果这个 batch 有 PID 信息，会首先检查这个 batch 是否为重复的 batch 数据，其实现如下，batchMetadata 会缓存最新 5个 batch 的数据（如果超过5个，添加时会进行删除，这个也是幂等性要求 MAX_IN_FLIGHT_REQUESTS_PER_CONNECTION 小于等于5 的原因，与这个值的设置有关），根据 batchMetadata 缓存的 batch 数据来判断这个 batch 是否为重复的数据。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">findDuplicateBatch</span></span>(batch: <span class="type">RecordBatch</span>): <span class="type">Option</span>[<span class="type">BatchMetadata</span>] = &#123;</span><br><span class="line">  <span class="keyword">if</span> (batch.producerEpoch != producerEpoch)</span><br><span class="line">     <span class="type">None</span></span><br><span class="line">  <span class="keyword">else</span></span><br><span class="line">    batchWithSequenceRange(batch.baseSequence, batch.lastSequence)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Return the batch metadata of the cached batch having the exact sequence range, if any.</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">batchWithSequenceRange</span></span>(firstSeq: <span class="type">Int</span>, lastSeq: <span class="type">Int</span>): <span class="type">Option</span>[<span class="type">BatchMetadata</span>] = &#123;</span><br><span class="line">  <span class="keyword">val</span> duplicate = batchMetadata.filter &#123; metadata =&gt;</span><br><span class="line">    firstSeq == metadata.firstSeq &amp;&amp; lastSeq == metadata.lastSeq</span><br><span class="line">  &#125;</span><br><span class="line">  duplicate.headOption</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">addBatchMetadata</span></span>(batch: <span class="type">BatchMetadata</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">  <span class="keyword">if</span> (batchMetadata.size == <span class="type">ProducerStateEntry</span>.<span class="type">NumBatchesToRetain</span>)</span><br><span class="line">    batchMetadata.dequeue() <span class="comment">//note: 只会保留最近 5 个 batch 的记录</span></span><br><span class="line">  batchMetadata.enqueue(batch) <span class="comment">//note: 添加到 batchMetadata 中记录，便于后续根据 seq id 判断是否重复</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>如果 batch 不是重复的数据，<code>analyzeAndValidateProducerState()</code> 会通过 <code>updateProducers()</code> 更新 producer 的相应记录，在更新的过程中，会做一步校验，校验方法如下所示：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//note: 检查 seq number</span></span><br><span class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">checkSequence</span></span>(producerEpoch: <span class="type">Short</span>, appendFirstSeq: <span class="type">Int</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">  <span class="keyword">if</span> (producerEpoch != updatedEntry.producerEpoch) &#123; <span class="comment">//note: epoch 不同时</span></span><br><span class="line">    <span class="keyword">if</span> (appendFirstSeq != <span class="number">0</span>) &#123; <span class="comment">//note: 此时要求 seq number 必须从0开始（如果不是的话，pid 可能是新建的或者 PID 在 Server 端已经过期）</span></span><br><span class="line">      <span class="comment">//note: pid 已经过期（updatedEntry.producerEpoch 不是-1，证明时原来的 pid 过期了）</span></span><br><span class="line">      <span class="keyword">if</span> (updatedEntry.producerEpoch != <span class="type">RecordBatch</span>.<span class="type">NO_PRODUCER_EPOCH</span>) &#123;</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">OutOfOrderSequenceException</span>(<span class="string">s"Invalid sequence number for new epoch: <span class="subst">$producerEpoch</span> "</span> +</span><br><span class="line">          <span class="string">s"(request epoch), <span class="subst">$appendFirstSeq</span> (seq. number)"</span>)</span><br><span class="line">      &#125; <span class="keyword">else</span> &#123; <span class="comment">//note: pid 已经过期（updatedEntry.producerEpoch 为-1，证明 server 端 meta 新建的，PID 在 server 端已经过期，client 还在接着上次的 seq 发数据）</span></span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">UnknownProducerIdException</span>(<span class="string">s"Found no record of producerId=<span class="subst">$producerId</span> on the broker. It is possible "</span> +</span><br><span class="line">          <span class="string">s"that the last message with t（）he producerId=<span class="subst">$producerId</span> has been removed due to hitting the retention limit."</span>)</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="keyword">val</span> currentLastSeq = <span class="keyword">if</span> (!updatedEntry.isEmpty)</span><br><span class="line">      updatedEntry.lastSeq</span><br><span class="line">    <span class="keyword">else</span> <span class="keyword">if</span> (producerEpoch == currentEntry.producerEpoch)</span><br><span class="line">      currentEntry.lastSeq</span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">      <span class="type">RecordBatch</span>.<span class="type">NO_SEQUENCE</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (currentLastSeq == <span class="type">RecordBatch</span>.<span class="type">NO_SEQUENCE</span> &amp;&amp; appendFirstSeq != <span class="number">0</span>) &#123;</span><br><span class="line">      <span class="comment">//note: 此时期望的 seq number 是从 0 开始,因为 currentLastSeq 是 -1,也就意味着这个 pid 还没有写入过数据</span></span><br><span class="line">      <span class="comment">// the epoch was bumped by a control record, so we expect the sequence number to be reset</span></span><br><span class="line">      <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">OutOfOrderSequenceException</span>(<span class="string">s"Out of order sequence number for producerId <span class="subst">$producerId</span>: found <span class="subst">$appendFirstSeq</span> "</span> +</span><br><span class="line">        <span class="string">s"(incoming seq. number), but expected 0"</span>)</span><br><span class="line">    &#125; <span class="keyword">else</span> <span class="keyword">if</span> (!inSequence(currentLastSeq, appendFirstSeq)) &#123;</span><br><span class="line">      <span class="comment">//note: 判断是否连续</span></span><br><span class="line">      <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">OutOfOrderSequenceException</span>(<span class="string">s"Out of order sequence number for producerId <span class="subst">$producerId</span>: <span class="subst">$appendFirstSeq</span> "</span> +</span><br><span class="line">        <span class="string">s"(incoming seq. number), <span class="subst">$currentLastSeq</span> (current end sequence number)"</span>)</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>其校验逻辑如前面流程中所述。</p>
<h2 id="小思考"><a href="#小思考" class="headerlink" title="小思考"></a>小思考</h2><p>这里主要思考两个问题：</p>
<ol>
<li>Producer 在设置幂等性时，为什么要求 MAX_IN_FLIGHT_REQUESTS_PER_CONNECTION 小于等于 5，如果设置大于 5（不考虑 Producer 端参数校验的报错），会带来什么后果？</li>
<li>Producer 在设置幂等性时，如果我们设置 MAX_IN_FLIGHT_REQUESTS_PER_CONNECTION 大于 1，那么是否可以保证有序，如果可以，是怎么做到的？</li>
</ol>
<p>先说一下结论，问题 1 的这个设置要求其实上面分析的时候已经讲述过了，主要跟 server 端只会缓存最近 5 个 batch 的机制有关；问题 2，即使 MAX_IN_FLIGHT_REQUESTS_PER_CONNECTION 大于 1，幂等性时依然可以做到有序，下面来详细分析一下这两个问题。</p>
<h3 id="为什么要求-MAX-IN-FLIGHT-REQUESTS-PER-CONNECTION-小于等于5"><a href="#为什么要求-MAX-IN-FLIGHT-REQUESTS-PER-CONNECTION-小于等于5" class="headerlink" title="为什么要求 MAX_IN_FLIGHT_REQUESTS_PER_CONNECTION 小于等于5"></a>为什么要求 MAX_IN_FLIGHT_REQUESTS_PER_CONNECTION 小于等于5</h3><p>其实这里，要求 MAX_IN_FLIGHT_REQUESTS_PER_CONNECTION 小于等于 5 的主要原因是：Server 端的 ProducerStateManager 实例会缓存每个 PID 在每个 Topic-Partition 上发送的最近 5 个batch 数据（这个 5 是写死的，至于为什么是 5，可能跟经验有关，当不设置幂等性时，当这个设置为 5 时，性能相对来说较高，社区是有一个相关测试文档，忘记在哪了），如果超过 5，ProducerStateManager 就会将最旧的 batch 数据清除。</p>
<p>假设应用将 MAX_IN_FLIGHT_REQUESTS_PER_CONNECTION 设置为 6，假设发送的请求顺序是 1、2、3、4、5、6，这时候 server 端只能缓存 2、3、4、5、6 请求对应的 batch 数据，这时候假设请求 1 发送失败，需要重试，当重试的请求发送过来后，首先先检查是否为重复的 batch，这时候检查的结果是否，之后会开始 check 其 sequence number 值，这时候只会返回一个 OutOfOrderSequenceException 异常，client 在收到这个异常后，会再次进行重试，直到超过最大重试次数或者超时，这样不但会影响 Producer 性能，还可能给 Server 带来压力（相当于client 狂发错误请求）。</p>
<p>那有没有更好的方案呢？我认为是有的，那就是对于 OutOfOrderSequenceException 异常，再进行细分，区分这个 sequence number 是大于 nextSeq （期望的下次 sequence number  值）还是小于 nextSeq，如果是小于，那么肯定是重复的数据。</p>
<h3 id="当-MAX-IN-FLIGHT-REQUESTS-PER-CONNECTION-配置大于1时，是否保证有序"><a href="#当-MAX-IN-FLIGHT-REQUESTS-PER-CONNECTION-配置大于1时，是否保证有序" class="headerlink" title="当 MAX_IN_FLIGHT_REQUESTS_PER_CONNECTION 配置大于1时，是否保证有序"></a>当 MAX_IN_FLIGHT_REQUESTS_PER_CONNECTION 配置大于1时，是否保证有序</h3><p>先来分析一下，在什么情况下 Producer 会出现乱序的问题？没有幂等性时，乱序的问题是在重试时出现的，举个例子：client 依然发送了 6 个请求 1、2、3、4、5、6（它们分别对应了一个 batch），这 6 个请求只有 2-6 成功 ack 了，1 失败了，这时候需要重试，重试时就会把 batch 1 的数据添加到待发送的数据列队中），那么下次再发送时，batch 1 的数据将会被发送，这时候数据就已经出现了乱序，因为 batch 1 的数据已经晚于了 batch 2-6。</p>
<p>当 MAX_IN_FLIGHT_REQUESTS_PER_CONNECTION 设置为 1 时，是可以解决这个为题，因为同时只允许一个请求正在发送，只有当前的请求发送完成（成功 ack 后），才能继续下一条请求的发送，类似单线程处理这种模式，每次请求发送时都会等待上次的完成，效率非常差，但是可以解决乱序的问题（当然这里有序只是针对单 client 情况，多 client 并发写是无法做到的）。</p>
<p>系统能提供的方案，基本上就是有序性与性能之间二选一，无法做到兼容，实际上系统出现请求重试的几率是很小的（一般都是网络问题触发的），可能连 0.1% 的时间都不到，但是就是为了这 0.1% 时间都不到的情况，应用需要牺牲性能问题来解决，在大数据场景下，我们是希望有更友好的方式来解决这个问题。简单来说，就是当出现重试时，max-in-flight-request 可以动态减少到 1，在正常情况下还是按 5 （5是举例说明）来处理，这有点类似于分布式系统 CAP 理论中关于 P 的考虑，当出现问题时，可以容忍性能变差，但是其他的情况下，我们希望的是能拥有原来的性能，而不是一刀切。令人高兴的，在 Kafka 2.0.0 版本中，如果 Producer 开始了幂等性，Kafka 是可以做到这一点的，如果不开启幂等性，是无法做到的，因为它的实现是依赖了 sequence number。</p>
<p>当请求出现重试时，batch 会重新添加到队列中，这时候是根据 sequence number 添加到队列的合适位置（有些 batch 如果还没有 sequence number，那么就保持其相对位置不变），也就是队列中排在这个 batch 前面的 batch，其 sequence number 都比这个 batch 的 sequence number 小，其实现如下，这个方法保证了在重试时，其 batch 会被放到合适的位置：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Re-enqueue the given record batch in the accumulator to retry</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">reenqueue</span><span class="params">(ProducerBatch batch, <span class="keyword">long</span> now)</span> </span>&#123;</span><br><span class="line">    batch.reenqueued(now); <span class="comment">//note: 重试,更新相应的 meta</span></span><br><span class="line">    Deque&lt;ProducerBatch&gt; deque = getOrCreateDeque(batch.topicPartition);</span><br><span class="line">    <span class="keyword">synchronized</span> (deque) &#123;</span><br><span class="line">        <span class="keyword">if</span> (transactionManager != <span class="keyword">null</span>)</span><br><span class="line">            insertInSequenceOrder(deque, batch); <span class="comment">//note: 将 batch 添加到队列的合适位置（根据 seq num 信息）</span></span><br><span class="line">        <span class="keyword">else</span></span><br><span class="line">            deque.addFirst(batch);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>另外 Sender 在发送请求时，会首先通过 RecordAccumulator 的 <code>drain()</code> 方法获取其发送的数据，在遍历 Topic-Partition 对应的 queue 中的 batch 时，如果发现 batch 已经有了 sequence number 的话，则证明这个 batch 是重试的 batch，因为没有重试的 batch 其 sequence number 还没有设置，这时候会做一个判断，会等待其 in-flight-requests 中请求发送完成，才允许再次发送这个 Topic-Partition 的数据，其判断实现如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//note: 获取 inFlightBatches 中第一个 batch 的 baseSequence, inFlightBatches 为 null 的话返回 RecordBatch.NO_SEQUENCE</span></span><br><span class="line"><span class="keyword">int</span> firstInFlightSequence = transactionManager.firstInFlightSequence(first.topicPartition);</span><br><span class="line"><span class="keyword">if</span> (firstInFlightSequence != RecordBatch.NO_SEQUENCE &amp;&amp; first.hasSequence()</span><br><span class="line">        &amp;&amp; first.baseSequence() != firstInFlightSequence)</span><br><span class="line">    <span class="comment">//note: 重试操作（seq number 不为0）,如果这个 batch 的 baseSequence 与 in-flight</span></span><br><span class="line">    <span class="comment">//note: queue 中第一个 request batch 的 baseSequence不同的话（证明它前面还有请求未成功）,</span></span><br><span class="line">    <span class="comment">//note: 会等待下次循环再判断, 最坏的情况下会导致 in-flight request 为1（只影响这个 partition）</span></span><br><span class="line">    <span class="comment">//note: 这种情况下,继续发送这个是没有意义的,因为幂等性时保证顺序的,只有前面的都成功,后面的再发送才有意义</span></span><br><span class="line">    <span class="comment">//note: 这里是 break,相当于在这次发送中直接跳过了这个 topic-partition 的发送</span></span><br><span class="line">    <span class="comment">// If the queued batch already has an assigned sequence, then it is being</span></span><br><span class="line">    <span class="comment">// retried. In this case, we wait until the next immediate batch is ready</span></span><br><span class="line">    <span class="comment">// and drain that. We only move on when the next in line batch is complete (either successfully</span></span><br><span class="line">    <span class="comment">// or due to a fatal broker error). This effectively reduces our</span></span><br><span class="line">    <span class="comment">// in flight request count to 1.</span></span><br><span class="line">    <span class="keyword">break</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>仅有 client 端这两个机制还不够，Server 端在处理 ProduceRequest 请求时，还会检查 batch 的 sequence number 值，它会要求这个值必须是连续的，如果不连续都会返回异常，Client 会进行相应的重试，举个栗子：假设 Client 发送的请求顺序是 1、2、3、4、5（分别对应了一个 batch），如果中间的请求 2 出现了异常，那么会导致 3、4、5 都返回异常进行重试（因为 sequence number 不连续），也就是说此时 2、3、4、5 都会进行重试操作添加到对应的 queue 中。</p>
<p>Producer 的 TransactionManager 实例的 inflightBatchesBySequence 成员变量会维护这个 Topic-Partition 与目前正在发送的 batch 的对应关系（通过 <code>addInFlightBatch()</code> 方法添加 batch 记录），只有这个 batch 成功 ack 后，才会通过 <code>removeInFlightBatch()</code> 方法将这个 batch 从 inflightBatchesBySequence 中移除。接着前面的例子，此时 inflightBatchesBySequence 中还有 2、3、4、5 这几个 batch（有顺序的，2 在前面），根据前面的 RecordAccumulator 的 <code>drain()</code> 方法可以知道只有这个 Topic-Partition 下次要发送的 batch 是 batch 2（跟 transactionManager 的这个 <code>firstInFlightSequence()</code> 方法获取 inFlightBatches 中第一个 batch 的 baseSequence 来判断） 时，才可以发送，否则会直接 break，跳过这个 Topic-Partition 的数据发送。这里相当于有一个等待，等待 batch 2 重新加入到 queue 中，才可以发送，不能跳过 batch 2，直接重试 batch 3、4、5，这是不允许的。</p>
<p>简单来说，其实现机制概括为：</p>
<ol>
<li>Server 端验证 batch 的 sequence number 值，不连续时，直接返回异常；</li>
<li>Client 端请求重试时，batch 在 reenqueue 时会根据 sequence number 值放到合适的位置（有序保证之一）；</li>
<li>Sender 线程发送时，在遍历 queue 中的 batch 时，会检查这个 batch 是否是重试的 batch，如果是的话，只有这个 batch 是最旧的那个需要重试的 batch，才允许发送，否则本次发送跳过这个 Topic-Partition 数据的发送等待下次发送。</li>
</ol>
<hr>
<p>参考：</p>
<ol>
<li><a href="https://docs.google.com/document/d/11Jqy_GjUGtdXJK94XGsEIK7CP1SnQGdp2eF0wSw9ra8/edit" target="_blank" rel="external">Exactly Once Delivery and Transactional Messaging in Kafka</a>；</li>
<li><a href="https://cwiki.apache.org/confluence/display/KAFKA/Idempotent+Producer" target="_blank" rel="external">Idempotent Producer</a>；</li>
</ol>
</div><script type="text/javascript" src="/js/share.js?v=0.0.0" async></script><a data-url="http://matt33.com/2018/10/24/kafka-idempotent/" data-id="cjsjn6de5009x3i9kw6p1o2u8" class="article-share-link">分享到</a><div class="copyright"><a href="http://matt33.com/copyright/">博客版权说明</a></div><div class="tags"><a href="/tags/kafka/">kafka</a></div><div class="post-nav"><a href="/2018/11/04/kafka-transaction/" class="pre">Kafka Exactly-Once 之事务性实现</a><a href="/2018/10/19/bk-cluster-install-and-use/" class="next">BookKeeper 集群搭建及使用</a></div><div id="disqus_thread"><div class="btn_click_load"><button class="disqus_click_btn">阅读评论 「请确保 disqus.com 可以正常加载」</button></div><script>var disqus_shortname = 'http-matt33-com';
var disqus_identifier = '2018/10/24/kafka-idempotent/';
var disqus_title = 'Kafka 事务性之幂等性实现';
var disqus_url = 'http://matt33.com/2018/10/24/kafka-idempotent/';
$('.btn_click_load').click(function() {
  (function() {
    var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
    dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
  })();
  $('.btn_click_load').css('display','none');
});
$.ajax({
  url: 'https://disqus.com/favicon.ico',
  timeout: 3000,
  type: 'GET',
  success: (function() {
    var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
    dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    $('.btn_click_load').css('display','none');
  })(),
  error: function() {
    $('.btn_click_load').css('display','block');
  }
});</script><script id="dsq-count-scr" src="//http-matt33-com.disqus.com/count.js" async></script></div></div></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><div class="widget-title"><i class="fa fa-weibo"> 微博</i></div><iframe width="100%" height="90" class="share_self"  frameborder="0" scrolling="no" src="http://widget.weibo.com/weiboshow/index.php?language=&width=0&height=100&fansRow=1&ptype=1&speed=0&skin=1&isTitle=0&noborder=1&isWeibo=0&isFans=0&uid=2650396571&verifier=f2f0e397&colors=D8D8D8,ffffff,666666,0082cb,ecfbfd&dpc=1"></iframe></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> 分类</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/书屋/">书屋</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/影如人生/">影如人生</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/技术/">技术</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/旅行/">旅行</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/转载/">转载</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/随笔/">随笔</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> 标签</i></div><div class="tagcloud"><a href="/tags/mac/" style="font-size: 15px;">mac</a> <a href="/tags/思考/" style="font-size: 15px;">思考</a> <a href="/tags/database/" style="font-size: 15px;">database</a> <a href="/tags/storm/" style="font-size: 15px;">storm</a> <a href="/tags/java/" style="font-size: 15px;">java</a> <a href="/tags/linux/" style="font-size: 15px;">linux</a> <a href="/tags/learn/" style="font-size: 15px;">learn</a> <a href="/tags/hexo/" style="font-size: 15px;">hexo</a> <a href="/tags/bug/" style="font-size: 15px;">bug</a> <a href="/tags/cv/" style="font-size: 15px;">cv</a> <a href="/tags/maven/" style="font-size: 15px;">maven</a> <a href="/tags/travel/" style="font-size: 15px;">travel</a> <a href="/tags/hadoop/" style="font-size: 15px;">hadoop</a> <a href="/tags/kafka/" style="font-size: 15px;">kafka</a> <a href="/tags/tcp/" style="font-size: 15px;">tcp</a> <a href="/tags/电影随想/" style="font-size: 15px;">电影随想</a> <a href="/tags/随笔/" style="font-size: 15px;">随笔</a> <a href="/tags/转载/" style="font-size: 15px;">转载</a> <a href="/tags/algorithm/" style="font-size: 15px;">algorithm</a> <a href="/tags/jvm/" style="font-size: 15px;">jvm</a> <a href="/tags/web/" style="font-size: 15px;">web</a> <a href="/tags/分布式系统/" style="font-size: 15px;">分布式系统</a> <a href="/tags/rpc/" style="font-size: 15px;">rpc</a> <a href="/tags/thrift/" style="font-size: 15px;">thrift</a> <a href="/tags/bk/" style="font-size: 15px;">bk</a> <a href="/tags/zookeeper/" style="font-size: 15px;">zookeeper</a> <a href="/tags/calcite/" style="font-size: 15px;">calcite</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> 最新文章</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2019/03/17/apache-calcite-planner/">Apache Calcite 优化器详解（二）</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/03/07/apache-calcite-process-flow/">Apache Calcite 处理流程详解（一）</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/11/21/effective-learning/">如何高效学习</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/11/04/kafka-transaction/">Kafka Exactly-Once 之事务性实现</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/10/24/kafka-idempotent/">Kafka 事务性之幂等性实现</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/10/19/bk-cluster-install-and-use/">BookKeeper 集群搭建及使用</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/09/01/yarn-architecture-learn/">YARN 架构学习总结</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/08/01/system-learn-summary/">如何学习开源项目</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/07/28/jvm-cms/">JVM 之 ParNew 和 CMS 日志分析</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/07/15/hdfs-architecture-learn/">HDFS 架构学习总结</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-external-link"> 友情链接</i></div><ul></ul><a href="http://tech.meituan.com/" title="美团点评技术团队" target="_blank">美团点评技术团队</a><ul></ul><a href="http://jm.taobao.org/" title="阿里中间件团队博客" target="_blank">阿里中间件团队博客</a><ul></ul><a href="http://www.jianshu.com/" title="简书" target="_blank">简书</a></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">© <a href="/." rel="nofollow">Matt's Blog 柳年思水.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a id="rocket" href="#top" class="show"></a><script type="text/javascript" src="/js/totop.js?v=0.0.0" async></script><div class="analytics"><script>var cnzz_protocol = (("https:" == document.location.protocol) ? " https://" : " http://");
document.write(unescape("%3Cspan id='cnzz_stat_icon_1256517224'%3E%3C/span%3E%3Cscript src='" + cnzz_protocol + "s95.cnzz.com/z_stat.php%3Fid%3D1256517224%26show%3Dpic' type='text/javascript'%3E%3C/script%3E"));</script></div><script type="text/javascript" src="//cdn.bootcss.com/fancybox/2.1.5/jquery.fancybox.pack.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=0.0.0" async></script><link rel="stylesheet" type="text/css" href="/css/jquery.fancybox.css?v=0.0.0"><script>(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
ga('create','UA-64518924-1','auto');ga('send','pageview');
</script><script>var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "//hm.baidu.com/hm.js?5cf44757fa0d23bc7637935e44a9104a";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
  })();
</script><script type="text/javascript" src="/js/codeblock-resizer.js?v=0.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=0.0.0"></script></div></body></html>