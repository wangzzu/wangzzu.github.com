<!DOCTYPE html><html lang="zh-CN"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description" content="与一群有趣的人，做一些有趣的事."><title>Kafka 源码解析之副本同步机制实现（十四） | Matt's Blog</title><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/normalize/4.2.0/normalize.min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/0.6.0/pure-min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/0.6.0/grids-responsive-min.css"><link rel="stylesheet" type="text/css" href="/css/style.css?v=0.0.0"><link rel="stylesheet" href="//cdn.bootcss.com/font-awesome/4.6.3/css/font-awesome.min.css"><script type="text/javascript" src="//cdn.bootcss.com/jquery/3.0.0/jquery.min.js"></script><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"><link rel="alternate" type="application/atom+xml" href="/atom.xml"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">Kafka 源码解析之副本同步机制实现（十四）</h1><a id="logo" href="/.">Matt's Blog</a><p class="description">王蒙</p></div><div id="nav-menu"><a href="/." class="current"><i class="fa fa-home"> 首页</i></a><a href="/archives/"><i class="fa fa-archive"> 归档</i></a><a href="/about/"><i class="fa fa-user"> 关于</i></a><a href="/atom.xml"><i class="fa fa-rss"> 订阅</i></a></div></div><div id="layout" class="pure-g"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">Kafka 源码解析之副本同步机制实现（十四）</h1><div class="post-meta">Apr 29, 2018<span> | </span><span class="category"><a href="/categories/技术/">技术</a></span><span> | </span><span class="post-count">7,908</span><span> 字</span><script src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" async></script><span id="busuanzi_container_page_pv"> | <span id="busuanzi_value_page_pv"></span><span> Times</span></span></div><a data-disqus-identifier="2018/04/29/kafka-replica-fetcher-thread/" href="/2018/04/29/kafka-replica-fetcher-thread/#disqus_thread" class="disqus-comment-count"></a><div class="clear"><div id="toc" class="toc-article"><div class="toc-title">文章目录</div><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#整体流程"><span class="toc-number">1.</span> <span class="toc-text">整体流程</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#replica-fetcher-线程何时启动"><span class="toc-number">2.</span> <span class="toc-text">replica fetcher 线程何时启动</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#replica-fetcher-线程参数设置"><span class="toc-number">2.1.</span> <span class="toc-text">replica fetcher 线程参数设置</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#replica-fetcher-线程启动"><span class="toc-number">3.</span> <span class="toc-text">replica fetcher 线程启动</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#addFetcherForPartitions"><span class="toc-number">3.1.</span> <span class="toc-text">addFetcherForPartitions</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#createFetcherThread"><span class="toc-number">3.2.</span> <span class="toc-text">createFetcherThread</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#replica-fetcher-线程处理过程"><span class="toc-number">4.</span> <span class="toc-text">replica fetcher 线程处理过程</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#doWoker"><span class="toc-number">4.1.</span> <span class="toc-text">doWoker</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#buildFetchRequest"><span class="toc-number">4.2.</span> <span class="toc-text">buildFetchRequest</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#processFetchRequest"><span class="toc-number">4.3.</span> <span class="toc-text">processFetchRequest</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#fetch"><span class="toc-number">4.3.1.</span> <span class="toc-text">fetch</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#processPartitionData"><span class="toc-number">4.3.2.</span> <span class="toc-text">processPartitionData</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#副本同步异常情况的处理"><span class="toc-number">5.</span> <span class="toc-text">副本同步异常情况的处理</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#replica-fetcher-线程的关闭"><span class="toc-number">6.</span> <span class="toc-text">replica fetcher 线程的关闭</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#关闭副本同步"><span class="toc-number">6.1.</span> <span class="toc-text">关闭副本同步</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#stopReplica"><span class="toc-number">6.1.1.</span> <span class="toc-text">stopReplica</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#makeLeaders"><span class="toc-number">6.1.2.</span> <span class="toc-text">makeLeaders</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#makeFollowers"><span class="toc-number">6.1.3.</span> <span class="toc-text">makeFollowers</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#removeFetcherForPartitions"><span class="toc-number">6.2.</span> <span class="toc-text">removeFetcherForPartitions</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#removePartitions"><span class="toc-number">6.3.</span> <span class="toc-text">removePartitions</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#ReplicaFetcherThread-的关闭"><span class="toc-number">6.4.</span> <span class="toc-text">ReplicaFetcherThread 的关闭</span></a></li></ol></li></ol></div></div><div class="post-content"><p>在上篇文章中讲述了 Fetch 请求是如何处理的，其中包括来自副本同步的 Fetch 请求和 Consumer 的 Fetch 请求，副本同步是 Kafka 多副本机制（可靠性）实现的基础，它也是通过向 leader replica 发送 Fetch 请求来实现数据同步的。本篇文章我们就来看一下 Kafka 副本同步这块的内容，对于每个 broker 来说，它上面的 replica 对象，除了 leader 就是 follower，只要这台 broker 有 follower replica，broker 就会启动副本同步流程从 leader 同步数据，副本同步机制的实现是 Kafka Server 端非常重要的内容，在这篇文章中，主要会从以下几块来讲解：</p>
<ol>
<li>Kafka 在什么情况下会启动副本同步线程？</li>
<li>Kafka 副本同步线程启动流程及付副本同步流程的处理逻辑；</li>
<li>Kafka 副本同步需要解决的问题以及 Kafka 是如何解决这些问题的？</li>
<li>Kafka 在什么情况下会关闭一个副本同步线程。</li>
</ol>
<blockquote>
<p>小插曲：本来想先介绍一下与 LeaderAndIsr 请求相关的，因为副本同步线程的启动与这部分是息息相关的，但是发现涉及到了很多 controller 端的内容，而 controller 这部分还没开始涉及，所以本篇文章涉及到 LeaderAndIsr 请求的部分先简单讲述一下其处理逻辑，在 controller 这块再详细介绍。</p>
</blockquote>
<h2 id="整体流程"><a href="#整体流程" class="headerlink" title="整体流程"></a>整体流程</h2><p>Kafka Server 端的副本同步，是由 replica fetcher 线程来负责的，而它又是由 ReplicaManager 来控制的。关于 ReplicaManger，不知道大家还记不记得在 <a href="http://matt33.com/2018/03/18/kafka-server-handle-produce-request/">Kafka 源码解析之 Server 端如何处理 Produce 请求（十二）</a> 有一个简单的表格，如下所示。ReplicaManager 通过对 Partition 对象的管理，来控制着 Partition 对应的 Replica 实例，而 Replica 实例又是通过 Log 对象实例来管理着其底层的存储内容。</p>
<table>
<thead>
<tr>
<th></th>
<th>管理对象</th>
<th>组成部分</th>
</tr>
</thead>
<tbody>
<tr>
<td>日志管理器（LogManager）</td>
<td>日志（Log）</td>
<td>日志分段（LogSegment）</td>
</tr>
<tr>
<td>副本管理器（ReplicaManager）</td>
<td>分区（Partition）</td>
<td>副本（Replica）</td>
</tr>
</tbody>
</table>
<p>关于 ReplicaManager 的内容准备专门写一篇文章来介绍，刚好也作为对 Kafka 存储层内容的一个总结。</p>
<p>下面回到这篇文章的主题 —— 副本同步机制，在 ReplicaManager 中有一个实例变量 <code>replicaFetcherManager</code>，它负责管理所有副本同步线程，副本同步线程的启动和关闭都是由这个实例来操作的，关于副本同步相关处理逻辑，下面这张图可以作为一个整体流程，包括了 replica fetcher 线程的启动、工作流程、关闭三个部分，如下图所示：</p>
<p><img src="/images/kafka/fetcher_thread.png" alt="副本同步机制"></p>
<p>后面的讲述会围绕着这张图开始，这里看不懂或不理解也没有关系，后面会一一讲解。</p>
<h2 id="replica-fetcher-线程何时启动"><a href="#replica-fetcher-线程何时启动" class="headerlink" title="replica fetcher 线程何时启动"></a>replica fetcher 线程何时启动</h2><p>Broker 会在什么情况下启动副本同步线程呢？简单想一下这部分的逻辑：首先 broker 分配的任何一个 partition 都是以 Replica 对象实例的形式存在，而 Replica 在 Kafka 上是有两个角色： leader 和 follower，只要这个 Replica 是 follower，它便会向 leader 进行数据同步。</p>
<p>反应在 ReplicaManager 上就是如果 Broker 的本地副本被选举为 follower，那么它将会启动副本同步线程，其具体实现如下所示：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div><div class="line">113</div><div class="line">114</div><div class="line">115</div><div class="line">116</div><div class="line">117</div><div class="line">118</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//note: 对于给定的这些副本，将本地副本设置为 follower</span></div><div class="line"><span class="comment">//note: 1. 从 leader partition 集合移除这些 partition；</span></div><div class="line"><span class="comment">//note: 2. 将这些 partition 标记为 follower，之后这些 partition 就不会再接收 produce 的请求了；</span></div><div class="line"><span class="comment">//note: 3. 停止对这些 partition 的副本同步，这样这些副本就不会再有（来自副本请求线程）的数据进行追加了；</span></div><div class="line"><span class="comment">//note: 4. 对这些 partition 的 offset 进行 checkpoint，如果日志需要截断就进行截断操作；</span></div><div class="line"><span class="comment">//note: 5. 清空 purgatory 中的 produce 和 fetch 请求；</span></div><div class="line"><span class="comment">//note: 6. 如果 broker 没有掉线，向这些 partition 的新 leader 启动副本同步线程；</span></div><div class="line"><span class="comment">//note: 上面这些操作的顺序性，保证了这些副本在 offset checkpoint 之前将不会接收新的数据，这样的话，在 checkpoint 之前这些数据都可以保证刷到磁盘</span></div><div class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">makeFollowers</span></span>(controllerId: <span class="type">Int</span>,</div><div class="line">                          epoch: <span class="type">Int</span>,</div><div class="line">                          partitionState: <span class="type">Map</span>[<span class="type">Partition</span>, <span class="type">PartitionState</span>],</div><div class="line">                          correlationId: <span class="type">Int</span>,</div><div class="line">                          responseMap: mutable.<span class="type">Map</span>[<span class="type">TopicPartition</span>, <span class="type">Short</span>],</div><div class="line">                          metadataCache: <span class="type">MetadataCache</span>) : <span class="type">Set</span>[<span class="type">Partition</span>] = &#123;</div><div class="line">  partitionState.keys.foreach &#123; partition =&gt;</div><div class="line">    stateChangeLogger.trace((<span class="string">"Broker %d handling LeaderAndIsr request correlationId %d from controller %d epoch %d "</span> +</div><div class="line">      <span class="string">"starting the become-follower transition for partition %s"</span>)</div><div class="line">      .format(localBrokerId, correlationId, controllerId, epoch, partition.topicPartition))</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  <span class="keyword">for</span> (partition &lt;- partitionState.keys)</div><div class="line">    responseMap.put(partition.topicPartition, <span class="type">Errors</span>.<span class="type">NONE</span>.code)</div><div class="line"></div><div class="line">  <span class="comment">//note: 统计 follower 的集合</span></div><div class="line">  <span class="keyword">val</span> partitionsToMakeFollower: mutable.<span class="type">Set</span>[<span class="type">Partition</span>] = mutable.<span class="type">Set</span>()</div><div class="line"></div><div class="line">  <span class="keyword">try</span> &#123;</div><div class="line"></div><div class="line">    <span class="comment">// <span class="doctag">TODO:</span> Delete leaders from LeaderAndIsrRequest</span></div><div class="line">    partitionState.foreach&#123; <span class="keyword">case</span> (partition, partitionStateInfo) =&gt;</div><div class="line">      <span class="keyword">val</span> newLeaderBrokerId = partitionStateInfo.leader</div><div class="line">      metadataCache.getAliveBrokers.find(_.id == newLeaderBrokerId) <span class="keyword">match</span> &#123; <span class="comment">//note: leader 是可用的</span></div><div class="line">        <span class="comment">// Only change partition state when the leader is available</span></div><div class="line">        <span class="keyword">case</span> <span class="type">Some</span>(_) =&gt; <span class="comment">//note: partition 的本地副本设置为 follower</span></div><div class="line">          <span class="keyword">if</span> (partition.makeFollower(controllerId, partitionStateInfo, correlationId))</div><div class="line">            partitionsToMakeFollower += partition</div><div class="line">          <span class="keyword">else</span> <span class="comment">//note: 这个 partition 的本地副本已经是 follower 了</span></div><div class="line">            stateChangeLogger.info((<span class="string">"Broker %d skipped the become-follower state change after marking its partition as follower with correlation id %d from "</span> +</div><div class="line">              <span class="string">"controller %d epoch %d for partition %s since the new leader %d is the same as the old leader"</span>)</div><div class="line">              .format(localBrokerId, correlationId, controllerId, partitionStateInfo.controllerEpoch,</div><div class="line">              partition.topicPartition, newLeaderBrokerId))</div><div class="line">        <span class="keyword">case</span> <span class="type">None</span> =&gt;</div><div class="line">          <span class="comment">// The leader broker should always be present in the metadata cache.</span></div><div class="line">          <span class="comment">// If not, we should record the error message and abort the transition process for this partition</span></div><div class="line">          stateChangeLogger.error((<span class="string">"Broker %d received LeaderAndIsrRequest with correlation id %d from controller"</span> +</div><div class="line">            <span class="string">" %d epoch %d for partition %s but cannot become follower since the new leader %d is unavailable."</span>)</div><div class="line">            .format(localBrokerId, correlationId, controllerId, partitionStateInfo.controllerEpoch,</div><div class="line">            partition.topicPartition, newLeaderBrokerId))</div><div class="line">          <span class="comment">// Create the local replica even if the leader is unavailable. This is required to ensure that we include</span></div><div class="line">          <span class="comment">// the partition's high watermark in the checkpoint file (see KAFKA-1647)</span></div><div class="line">          partition.getOrCreateReplica()</div><div class="line">      &#125;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="comment">//note: 删除对这些 partition 的副本同步线程</span></div><div class="line">    replicaFetcherManager.removeFetcherForPartitions(partitionsToMakeFollower.map(_.topicPartition))</div><div class="line">    partitionsToMakeFollower.foreach &#123; partition =&gt;</div><div class="line">      stateChangeLogger.trace((<span class="string">"Broker %d stopped fetchers as part of become-follower request from controller "</span> +</div><div class="line">        <span class="string">"%d epoch %d with correlation id %d for partition %s"</span>)</div><div class="line">        .format(localBrokerId, controllerId, epoch, correlationId, partition.topicPartition))</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="comment">//note: Truncate the partition logs to the specified offsets and checkpoint the recovery point to this offset</span></div><div class="line">    logManager.truncateTo(partitionsToMakeFollower.map &#123; partition =&gt;</div><div class="line">      (partition.topicPartition, partition.getOrCreateReplica().highWatermark.messageOffset)</div><div class="line">    &#125;.toMap)</div><div class="line">    <span class="comment">//note: 完成那些延迟请求的处理</span></div><div class="line">    partitionsToMakeFollower.foreach &#123; partition =&gt;</div><div class="line">      <span class="keyword">val</span> topicPartitionOperationKey = <span class="keyword">new</span> <span class="type">TopicPartitionOperationKey</span>(partition.topicPartition)</div><div class="line">      tryCompleteDelayedProduce(topicPartitionOperationKey)</div><div class="line">      tryCompleteDelayedFetch(topicPartitionOperationKey)</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    partitionsToMakeFollower.foreach &#123; partition =&gt;</div><div class="line">      stateChangeLogger.trace((<span class="string">"Broker %d truncated logs and checkpointed recovery boundaries for partition %s as part of "</span> +</div><div class="line">        <span class="string">"become-follower request with correlation id %d from controller %d epoch %d"</span>).format(localBrokerId,</div><div class="line">        partition.topicPartition, correlationId, controllerId, epoch))</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="keyword">if</span> (isShuttingDown.get()) &#123;</div><div class="line">      partitionsToMakeFollower.foreach &#123; partition =&gt;</div><div class="line">        stateChangeLogger.trace((<span class="string">"Broker %d skipped the adding-fetcher step of the become-follower state change with correlation id %d from "</span> +</div><div class="line">          <span class="string">"controller %d epoch %d for partition %s since it is shutting down"</span>).format(localBrokerId, correlationId,</div><div class="line">          controllerId, epoch, partition.topicPartition))</div><div class="line">      &#125;</div><div class="line">    &#125;</div><div class="line">    <span class="keyword">else</span> &#123;</div><div class="line">      <span class="comment">// we do not need to check if the leader exists again since this has been done at the beginning of this process</span></div><div class="line">      <span class="comment">//note: 启动副本同步线程</span></div><div class="line">      <span class="keyword">val</span> partitionsToMakeFollowerWithLeaderAndOffset = partitionsToMakeFollower.map(partition =&gt;</div><div class="line">        partition.topicPartition -&gt; <span class="type">BrokerAndInitialOffset</span>(</div><div class="line">          metadataCache.getAliveBrokers.find(_.id == partition.leaderReplicaIdOpt.get).get.getBrokerEndPoint(config.interBrokerListenerName),</div><div class="line">          partition.getReplica().get.logEndOffset.messageOffset)).toMap <span class="comment">//note: leader 信息+本地 replica 的 offset</span></div><div class="line">      replicaFetcherManager.addFetcherForPartitions(partitionsToMakeFollowerWithLeaderAndOffset)</div><div class="line"></div><div class="line">      partitionsToMakeFollower.foreach &#123; partition =&gt;</div><div class="line">        stateChangeLogger.trace((<span class="string">"Broker %d started fetcher to new leader as part of become-follower request from controller "</span> +</div><div class="line">          <span class="string">"%d epoch %d with correlation id %d for partition %s"</span>)</div><div class="line">          .format(localBrokerId, controllerId, epoch, correlationId, partition.topicPartition))</div><div class="line">      &#125;</div><div class="line">    &#125;</div><div class="line">  &#125; <span class="keyword">catch</span> &#123;</div><div class="line">    <span class="keyword">case</span> e: <span class="type">Throwable</span> =&gt;</div><div class="line">      <span class="keyword">val</span> errorMsg = (<span class="string">"Error on broker %d while processing LeaderAndIsr request with correlationId %d received from controller %d "</span> +</div><div class="line">        <span class="string">"epoch %d"</span>).format(localBrokerId, correlationId, controllerId, epoch)</div><div class="line">      stateChangeLogger.error(errorMsg, e)</div><div class="line">      <span class="comment">// Re-throw the exception for it to be caught in KafkaApis</span></div><div class="line">      <span class="keyword">throw</span> e</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  partitionState.keys.foreach &#123; partition =&gt;</div><div class="line">    stateChangeLogger.trace((<span class="string">"Broker %d completed LeaderAndIsr request correlationId %d from controller %d epoch %d "</span> +</div><div class="line">      <span class="string">"for the become-follower transition for partition %s"</span>)</div><div class="line">      .format(localBrokerId, correlationId, controllerId, epoch, partition.topicPartition))</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  partitionsToMakeFollower</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>简单来说，<code>makeFollowers()</code> 的处理过程如下：</p>
<ol>
<li>先从本地记录 leader partition 的集合中将这些 partition 移除，因为这些 partition 已经被选举为了 follower；</li>
<li>将这些 partition 的本地副本设置为 follower，后面就不会接收关于这个 partition 的 Produce 请求了，如果依然有 client 在向这台 broker 发送数据，那么它将会返回相应的错误；</li>
<li>先停止关于这些 partition 的副本同步线程（如果本地副本之前是 follower 现在还是 follower，先关闭的原因是：这个 partition 的 leader 发生了变化，如果 leader 没有发生变化，那么 <code>makeFollower</code> 方法返回的是 False，这个 Partition 就不会被添加到 partitionsToMakeFollower 集合中），这样的话可以保证这些 partition 的本地副本将不会再有新的数据追加；</li>
<li>对这些 partition 本地副本日志文件进行截断操作并进行 checkpoint 操作；</li>
<li>完成那些延迟处理的 Produce 和 Fetch 请求；</li>
<li>如果本地的 broker 没有掉线，那么向这些 partition 新选举出来的 leader 启动副本同步线程。</li>
</ol>
<p>关于第6步，并不一定会为每一个 partition 都启动一个 fetcher 线程，对于一个目的 broker，只会启动 <code>num.replica.fetchers</code> 个线程，具体这个 topic-partition 会分配到哪个 fetcher 线程上，是根据 topic 名和 partition id 进行计算得到，实现所示：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//note: 获取分配到这个 topic-partition 的 fetcher 线程 id</span></div><div class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">getFetcherId</span></span>(topic: <span class="type">String</span>, partitionId: <span class="type">Int</span>) : <span class="type">Int</span> = &#123;</div><div class="line">  <span class="type">Utils</span>.abs(<span class="number">31</span> * topic.hashCode() + partitionId) % numFetchers</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h3 id="replica-fetcher-线程参数设置"><a href="#replica-fetcher-线程参数设置" class="headerlink" title="replica fetcher 线程参数设置"></a>replica fetcher 线程参数设置</h3><p>关于副本同步线程有一些参数配置，具体如下表所示：</p>
<table>
<thead>
<tr>
<th>参数</th>
<th>说明</th>
<th>默认值</th>
</tr>
</thead>
<tbody>
<tr>
<td>num.replica.fetchers</td>
<td>从一个 broker 同步数据的 fetcher 线程数，增加这个值时也会增加该 broker 的 Io 并行度（也就是说：从一台 broker 同步数据，最多能开这么大的线程数）</td>
<td>1</td>
</tr>
<tr>
<td>replica.fetch.wait.max.ms</td>
<td>对于 follower replica 而言，每个 Fetch 请求的最大等待时间，这个值应该比 <code>replica.lag.time.max.ms</code> 要小，否则对于那些吞吐量特别低的 topic 可能会导致 isr 频繁抖动</td>
<td>500</td>
</tr>
<tr>
<td>replica.high.watermark.checkpoint.interval.ms</td>
<td>hw 刷到磁盘频率</td>
<td>500</td>
</tr>
<tr>
<td>replica.lag.time.max.ms</td>
<td>如果一个 follower 在这个时间内没有发送任何 fetch 请求或者在这个时间内没有追上 leader 当前的 log end offset，那么将会从 isr 中移除</td>
<td>10000</td>
</tr>
<tr>
<td>replica.fetch.min.bytes</td>
<td>每次 fetch 请求最少拉取的数据量，如果不满足这个条件，那么要等待 replicaMaxWaitTimeMs</td>
<td>1</td>
</tr>
<tr>
<td>replica.fetch.backoff.ms</td>
<td>拉取时，如果遇到错误，下次拉取等待的时间</td>
<td>1000</td>
</tr>
<tr>
<td>replica.fetch.max.bytes</td>
<td>在对每个 partition 拉取时，最大的拉取数量，这并不是一个绝对值，如果拉取的第一条 msg 的大小超过了这个值，只要不超过这个 topic 设置（defined via message.max.bytes (broker config) or max.message.bytes (topic config)）的单条大小限制，依然会返回。</td>
<td>1048576</td>
</tr>
<tr>
<td>replica.fetch.response.max.bytes</td>
<td>对于一个 fetch 请求，返回的最大数据量（可能会涉及多个 partition），这并不是一个绝对值，如果拉取的第一条 msg 的大小超过了这个值，只要不超过这个 topic 设置（defined via message.max.bytes (broker config) or max.message.bytes (topic config)）的单条大小限制，依然会返回。</td>
<td>10MB</td>
</tr>
</tbody>
</table>
<h2 id="replica-fetcher-线程启动"><a href="#replica-fetcher-线程启动" class="headerlink" title="replica fetcher 线程启动"></a>replica fetcher 线程启动</h2><p>如上面的图所示，在 ReplicaManager 调用 <code>makeFollowers()</code> 启动 replica fetcher 线程后，它实际上是通过 ReplicaFetcherManager 实例进行相关 topic-partition 同步线程的启动和关闭，其启动过程分为下面两步：</p>
<ol>
<li>ReplicaFetcherManager 调用 <code>addFetcherForPartitions()</code> 添加对这些 topic-partition 的数据同步流程；</li>
<li>ReplicaFetcherManager 调用 <code>createFetcherThread()</code> 初始化相应的 ReplicaFetcherThread 线程。</li>
</ol>
<h3 id="addFetcherForPartitions"><a href="#addFetcherForPartitions" class="headerlink" title="addFetcherForPartitions"></a>addFetcherForPartitions</h3><p><code>addFetcherForPartitions()</code> 的具体实现如下所示：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//note: 为一个 topic-partition 添加 replica-fetch 线程</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">addFetcherForPartitions</span></span>(partitionAndOffsets: <span class="type">Map</span>[<span class="type">TopicPartition</span>, <span class="type">BrokerAndInitialOffset</span>]) &#123;</div><div class="line">  mapLock synchronized &#123;</div><div class="line">    <span class="comment">//note: 为这些 topic-partition 分配相应的 fetch 线程 id</span></div><div class="line">    <span class="keyword">val</span> partitionsPerFetcher = partitionAndOffsets.groupBy &#123; <span class="keyword">case</span>(topicPartition, brokerAndInitialOffset) =&gt;</div><div class="line">      <span class="type">BrokerAndFetcherId</span>(brokerAndInitialOffset.broker, getFetcherId(topicPartition.topic, topicPartition.partition))&#125;</div><div class="line">    <span class="keyword">for</span> ((brokerAndFetcherId, partitionAndOffsets) &lt;- partitionsPerFetcher) &#123;</div><div class="line">      <span class="comment">//note: 为 BrokerAndFetcherId 构造 fetcherThread 线程</span></div><div class="line">      <span class="keyword">var</span> fetcherThread: <span class="type">AbstractFetcherThread</span> = <span class="literal">null</span></div><div class="line">      fetcherThreadMap.get(brokerAndFetcherId) <span class="keyword">match</span> &#123;</div><div class="line">        <span class="keyword">case</span> <span class="type">Some</span>(f) =&gt; fetcherThread = f</div><div class="line">        <span class="keyword">case</span> <span class="type">None</span> =&gt;</div><div class="line">          <span class="comment">//note: 创建 fetcher 线程</span></div><div class="line">          fetcherThread = createFetcherThread(brokerAndFetcherId.fetcherId, brokerAndFetcherId.broker)</div><div class="line">          fetcherThreadMap.put(brokerAndFetcherId, fetcherThread)</div><div class="line">          fetcherThread.start</div><div class="line">      &#125;</div><div class="line"></div><div class="line">      <span class="comment">//note: 添加 topic-partition 列表</span></div><div class="line">      fetcherThreadMap(brokerAndFetcherId).addPartitions(partitionAndOffsets.map &#123; <span class="keyword">case</span> (tp, brokerAndInitOffset) =&gt;</div><div class="line">        tp -&gt; brokerAndInitOffset.initOffset</div><div class="line">      &#125;)</div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  info(<span class="string">"Added fetcher for partitions %s"</span>.format(partitionAndOffsets.map &#123; <span class="keyword">case</span> (topicPartition, brokerAndInitialOffset) =&gt;</div><div class="line">    <span class="string">"["</span> + topicPartition + <span class="string">", initOffset "</span> + brokerAndInitialOffset.initOffset + <span class="string">" to broker "</span> + brokerAndInitialOffset.broker + <span class="string">"] "</span>&#125;))</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>这个方法其实是做了下面这几件事：</p>
<ol>
<li>先计算这个 topic-partition 对应的 fetcher id；</li>
<li>根据 leader 和 fetcher id 获取对应的 replica fetcher 线程，如果没有找到，就调用 <code>createFetcherThread()</code> 创建一个新的 fetcher 线程；</li>
<li>如果是新启动的 replica fetcher 线程，那么就启动这个线程；</li>
<li>将 topic-partition 记录到 <code>fetcherThreadMap</code> 中，这个变量记录每个 replica fetcher 线程要同步的 topic-partition 列表。</li>
</ol>
<h3 id="createFetcherThread"><a href="#createFetcherThread" class="headerlink" title="createFetcherThread"></a>createFetcherThread</h3><p>ReplicaFetcherManager 创建 replica Fetcher 线程的实现如下：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//note: 创建 replica-fetch 线程</span></div><div class="line"><span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">createFetcherThread</span></span>(fetcherId: <span class="type">Int</span>, sourceBroker: <span class="type">BrokerEndPoint</span>): <span class="type">AbstractFetcherThread</span> = &#123;</div><div class="line">  <span class="keyword">val</span> threadName = threadNamePrefix <span class="keyword">match</span> &#123;</div><div class="line">    <span class="keyword">case</span> <span class="type">None</span> =&gt;</div><div class="line">      <span class="string">"ReplicaFetcherThread-%d-%d"</span>.format(fetcherId, sourceBroker.id)</div><div class="line">    <span class="keyword">case</span> <span class="type">Some</span>(p) =&gt;</div><div class="line">      <span class="string">"%s:ReplicaFetcherThread-%d-%d"</span>.format(p, fetcherId, sourceBroker.id)</div><div class="line">  &#125;</div><div class="line">  <span class="keyword">new</span> <span class="type">ReplicaFetcherThread</span>(threadName, fetcherId, sourceBroker, brokerConfig,</div><div class="line">    replicaMgr, metrics, time, quotaManager) <span class="comment">//note: replica-fetch 线程</span></div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h2 id="replica-fetcher-线程处理过程"><a href="#replica-fetcher-线程处理过程" class="headerlink" title="replica fetcher 线程处理过程"></a>replica fetcher 线程处理过程</h2><p>replica fetcher 线程在启动之后就开始进行正常数据同步流程了，在文章最开始流程图中的第二部分（线程处理过程）已经给出了大概的处理过程，这节会详细介绍一下，这个过程都是在 ReplicaFetcherThread 线程中实现的。</p>
<h3 id="doWoker"><a href="#doWoker" class="headerlink" title="doWoker"></a>doWoker</h3><p>ReplicaFetcherThread 的 <code>doWork()</code> 方法是一直在这个线程中的 <code>run()</code> 中调用的，实现方法如下：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">run</span></span>(): <span class="type">Unit</span> = &#123;</div><div class="line">  info(<span class="string">"Starting "</span>)</div><div class="line">  <span class="keyword">try</span>&#123;</div><div class="line">    <span class="keyword">while</span>(isRunning.get())&#123;</div><div class="line">      doWork()</div><div class="line">    &#125;</div><div class="line">  &#125; <span class="keyword">catch</span>&#123;</div><div class="line">    <span class="keyword">case</span> e: <span class="type">Throwable</span> =&gt;</div><div class="line">      <span class="keyword">if</span>(isRunning.get())</div><div class="line">        error(<span class="string">"Error due to "</span>, e)</div><div class="line">  &#125;</div><div class="line">  shutdownLatch.countDown()</div><div class="line">  info(<span class="string">"Stopped "</span>)</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">doWork</span></span>() &#123;</div><div class="line">  <span class="comment">//note: 构造 fetch request</span></div><div class="line">  <span class="keyword">val</span> fetchRequest = inLock(partitionMapLock) &#123;</div><div class="line">    <span class="keyword">val</span> fetchRequest = buildFetchRequest(partitionStates.partitionStates.asScala.map &#123; state =&gt;</div><div class="line">      state.topicPartition -&gt; state.value</div><div class="line">    &#125;)</div><div class="line">    <span class="keyword">if</span> (fetchRequest.isEmpty) &#123; <span class="comment">//note: 如果没有活跃的 partition，在下次调用之前，sleep fetchBackOffMs 时间</span></div><div class="line">      trace(<span class="string">"There are no active partitions. Back off for %d ms before sending a fetch request"</span>.format(fetchBackOffMs))</div><div class="line">      partitionMapCond.await(fetchBackOffMs, <span class="type">TimeUnit</span>.<span class="type">MILLISECONDS</span>)</div><div class="line">    &#125;</div><div class="line">    fetchRequest</div><div class="line">  &#125;</div><div class="line">  <span class="keyword">if</span> (!fetchRequest.isEmpty)</div><div class="line">    processFetchRequest(fetchRequest) <span class="comment">//note: 发送 fetch 请求，处理 fetch 的结果</span></div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>在 <code>doWork()</code> 方法中主要做了两件事：</p>
<ol>
<li>构造相应的 Fetch 请求（<code>buildFetchRequest()</code>）；</li>
<li>通过 <code>processFetchRequest()</code> 方法发送 Fetch 请求，并对其结果进行相应的处理。</li>
</ol>
<h3 id="buildFetchRequest"><a href="#buildFetchRequest" class="headerlink" title="buildFetchRequest"></a>buildFetchRequest</h3><p>通过 <code>buildFetchRequest()</code> 方法构造相应的 Fetcher 请求时，会设置 replicaId，该值会代表了这个 Fetch 请求是来自副本同步，而不是来自 consumer。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//note: 构造 Fetch 请求</span></div><div class="line"><span class="keyword">protected</span> <span class="function"><span class="keyword">def</span> <span class="title">buildFetchRequest</span></span>(partitionMap: <span class="type">Seq</span>[(<span class="type">TopicPartition</span>, <span class="type">PartitionFetchState</span>)]): <span class="type">FetchRequest</span> = &#123;</div><div class="line">  <span class="keyword">val</span> requestMap = <span class="keyword">new</span> util.<span class="type">LinkedHashMap</span>[<span class="type">TopicPartition</span>, <span class="type">JFetchRequest</span>.<span class="type">PartitionData</span>]</div><div class="line"></div><div class="line">  partitionMap.foreach &#123; <span class="keyword">case</span> (topicPartition, partitionFetchState) =&gt;</div><div class="line">    <span class="comment">// We will not include a replica in the fetch request if it should be throttled.</span></div><div class="line">    <span class="keyword">if</span> (partitionFetchState.isActive &amp;&amp; !shouldFollowerThrottle(quota, topicPartition))</div><div class="line">      requestMap.put(topicPartition, <span class="keyword">new</span> <span class="type">JFetchRequest</span>.<span class="type">PartitionData</span>(partitionFetchState.offset, fetchSize))</div><div class="line">  &#125;</div><div class="line">  <span class="comment">//note: 关键在于 setReplicaId 方法,设置了 replicaId, 对于 consumer, 该值为 CONSUMER_REPLICA_ID（-1）</span></div><div class="line">  <span class="keyword">val</span> requestBuilder = <span class="keyword">new</span> <span class="type">JFetchRequest</span>.<span class="type">Builder</span>(maxWait, minBytes, requestMap).</div><div class="line">      setReplicaId(replicaId).setMaxBytes(maxBytes)</div><div class="line">  requestBuilder.setVersion(fetchRequestVersion)</div><div class="line">  <span class="keyword">new</span> <span class="type">FetchRequest</span>(requestBuilder)</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h3 id="processFetchRequest"><a href="#processFetchRequest" class="headerlink" title="processFetchRequest"></a>processFetchRequest</h3><p><code>processFetchRequest()</code> 这个方法的作用是发送 Fetch 请求，并对返回的结果进行处理，最终写入到本地副本的 Log 实例中，其具体实现：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">processFetchRequest</span></span>(fetchRequest: <span class="type">REQ</span>) &#123;</div><div class="line">  <span class="keyword">val</span> partitionsWithError = mutable.<span class="type">Set</span>[<span class="type">TopicPartition</span>]()</div><div class="line"></div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">updatePartitionsWithError</span></span>(partition: <span class="type">TopicPartition</span>): <span class="type">Unit</span> = &#123;</div><div class="line">    partitionsWithError += partition</div><div class="line">    partitionStates.moveToEnd(partition)</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  <span class="keyword">var</span> responseData: <span class="type">Seq</span>[(<span class="type">TopicPartition</span>, <span class="type">PD</span>)] = <span class="type">Seq</span>.empty</div><div class="line"></div><div class="line">  <span class="keyword">try</span> &#123;</div><div class="line">    trace(<span class="string">"Issuing to broker %d of fetch request %s"</span>.format(sourceBroker.id, fetchRequest))</div><div class="line">    responseData = fetch(fetchRequest) <span class="comment">//note: 发送 fetch 请求，获取 fetch 结果</span></div><div class="line">  &#125; <span class="keyword">catch</span> &#123;</div><div class="line">    <span class="keyword">case</span> t: <span class="type">Throwable</span> =&gt;</div><div class="line">      <span class="keyword">if</span> (isRunning.get) &#123;</div><div class="line">        warn(<span class="string">s"Error in fetch <span class="subst">$fetchRequest</span>"</span>, t)</div><div class="line">        inLock(partitionMapLock) &#123; <span class="comment">//note: fetch 时发生错误，sleep 一会</span></div><div class="line">          partitionStates.partitionSet.asScala.foreach(updatePartitionsWithError)</div><div class="line">          <span class="comment">// there is an error occurred while fetching partitions, sleep a while</span></div><div class="line">          <span class="comment">// note that `ReplicaFetcherThread.handlePartitionsWithError` will also introduce the same delay for every</span></div><div class="line">          <span class="comment">// partition with error effectively doubling the delay. It would be good to improve this.</span></div><div class="line">          partitionMapCond.await(fetchBackOffMs, <span class="type">TimeUnit</span>.<span class="type">MILLISECONDS</span>)</div><div class="line">        &#125;</div><div class="line">      &#125;</div><div class="line">  &#125;</div><div class="line">  fetcherStats.requestRate.mark()</div><div class="line"></div><div class="line">  <span class="keyword">if</span> (responseData.nonEmpty) &#123; <span class="comment">//note: fetch 结果不为空</span></div><div class="line">    <span class="comment">// process fetched data</span></div><div class="line">    inLock(partitionMapLock) &#123;</div><div class="line"></div><div class="line">      responseData.foreach &#123; <span class="keyword">case</span> (topicPartition, partitionData) =&gt;</div><div class="line">        <span class="keyword">val</span> topic = topicPartition.topic</div><div class="line">        <span class="keyword">val</span> partitionId = topicPartition.partition</div><div class="line">        <span class="type">Option</span>(partitionStates.stateValue(topicPartition)).foreach(currentPartitionFetchState =&gt;</div><div class="line">          <span class="comment">// we append to the log if the current offset is defined and it is the same as the offset requested during fetch</span></div><div class="line">          <span class="comment">//note: 如果 fetch 的 offset 与返回结果的 offset 相同，并且返回没有异常，那么就将拉取的数据追加到对应的 partition 上</span></div><div class="line">          <span class="keyword">if</span> (fetchRequest.offset(topicPartition) == currentPartitionFetchState.offset) &#123;</div><div class="line">            <span class="type">Errors</span>.forCode(partitionData.errorCode) <span class="keyword">match</span> &#123;</div><div class="line">              <span class="keyword">case</span> <span class="type">Errors</span>.<span class="type">NONE</span> =&gt;</div><div class="line">                <span class="keyword">try</span> &#123;</div><div class="line">                  <span class="keyword">val</span> records = partitionData.toRecords</div><div class="line">                  <span class="keyword">val</span> newOffset = records.shallowEntries.asScala.lastOption.map(_.nextOffset).getOrElse(</div><div class="line">                    currentPartitionFetchState.offset)</div><div class="line"></div><div class="line">                  fetcherLagStats.getAndMaybePut(topic, partitionId).lag = <span class="type">Math</span>.max(<span class="number">0</span>L, partitionData.highWatermark - newOffset)</div><div class="line">                  <span class="comment">// Once we hand off the partition data to the subclass, we can't mess with it any more in this thread</span></div><div class="line">                  <span class="comment">//note: 将 fetch 的数据追加到日志文件中</span></div><div class="line">                  processPartitionData(topicPartition, currentPartitionFetchState.offset, partitionData)</div><div class="line"></div><div class="line">                  <span class="keyword">val</span> validBytes = records.validBytes</div><div class="line">                  <span class="keyword">if</span> (validBytes &gt; <span class="number">0</span>) &#123;</div><div class="line">                    <span class="comment">// Update partitionStates only if there is no exception during processPartitionData</span></div><div class="line">                    <span class="comment">//note: 更新 fetch 的 offset 位置</span></div><div class="line">                    partitionStates.updateAndMoveToEnd(topicPartition, <span class="keyword">new</span> <span class="type">PartitionFetchState</span>(newOffset))</div><div class="line">                    fetcherStats.byteRate.mark(validBytes) <span class="comment">//note: 更新 metrics</span></div><div class="line">                  &#125;</div><div class="line">                &#125; <span class="keyword">catch</span> &#123;</div><div class="line">                  <span class="keyword">case</span> ime: <span class="type">CorruptRecordException</span> =&gt;</div><div class="line">                    <span class="comment">// we log the error and continue. This ensures two things</span></div><div class="line">                    <span class="comment">// 1. If there is a corrupt message in a topic partition, it does not bring the fetcher thread down and cause other topic partition to also lag</span></div><div class="line">                    <span class="comment">// 2. If the message is corrupt due to a transient state in the log (truncation, partial writes can cause this), we simply continue and</span></div><div class="line">                    <span class="comment">// should get fixed in the subsequent fetches</span></div><div class="line">                    <span class="comment">//note: CRC 验证失败时，打印日志，并继续进行（这个线程还会有其他的 tp 拉取，防止影响其他副本同步）</span></div><div class="line">                    logger.error(<span class="string">"Found invalid messages during fetch for partition ["</span> + topic + <span class="string">","</span> + partitionId + <span class="string">"] offset "</span> + currentPartitionFetchState.offset  + <span class="string">" error "</span> + ime.getMessage)</div><div class="line">                    updatePartitionsWithError(topicPartition);</div><div class="line">                  <span class="keyword">case</span> e: <span class="type">Throwable</span> =&gt;</div><div class="line">                    <span class="comment">//note: 这里还会抛出异常，是 RUNTimeException</span></div><div class="line">                    <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">KafkaException</span>(<span class="string">"error processing data for partition [%s,%d] offset %d"</span></div><div class="line">                      .format(topic, partitionId, currentPartitionFetchState.offset), e)</div><div class="line">                &#125;</div><div class="line">              <span class="keyword">case</span> <span class="type">Errors</span>.<span class="type">OFFSET_OUT_OF_RANGE</span> =&gt; <span class="comment">//note: Out-of-range 的情况处理</span></div><div class="line">                <span class="keyword">try</span> &#123;</div><div class="line">                  <span class="keyword">val</span> newOffset = handleOffsetOutOfRange(topicPartition)</div><div class="line">                  partitionStates.updateAndMoveToEnd(topicPartition, <span class="keyword">new</span> <span class="type">PartitionFetchState</span>(newOffset))</div><div class="line">                  error(<span class="string">"Current offset %d for partition [%s,%d] out of range; reset offset to %d"</span></div><div class="line">                    .format(currentPartitionFetchState.offset, topic, partitionId, newOffset))</div><div class="line">                &#125; <span class="keyword">catch</span> &#123; <span class="comment">//note: 处理 out-of-range 是抛出的异常</span></div><div class="line">                  <span class="keyword">case</span> e: <span class="type">Throwable</span> =&gt;</div><div class="line">                    error(<span class="string">"Error getting offset for partition [%s,%d] to broker %d"</span>.format(topic, partitionId, sourceBroker.id), e)</div><div class="line">                    updatePartitionsWithError(topicPartition)</div><div class="line">                &#125;</div><div class="line">              <span class="keyword">case</span> _ =&gt; <span class="comment">//note: 其他的异常情况</span></div><div class="line">                <span class="keyword">if</span> (isRunning.get) &#123;</div><div class="line">                  error(<span class="string">"Error for partition [%s,%d] to broker %d:%s"</span>.format(topic, partitionId, sourceBroker.id,</div><div class="line">                    partitionData.exception.get))</div><div class="line">                  updatePartitionsWithError(topicPartition)</div><div class="line">                &#125;</div><div class="line">            &#125;</div><div class="line">          &#125;)</div><div class="line">      &#125;</div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  <span class="comment">//note: 处理拉取遇到的错误读的 tp</span></div><div class="line">  <span class="keyword">if</span> (partitionsWithError.nonEmpty) &#123;</div><div class="line">    debug(<span class="string">"handling partitions with error for %s"</span>.format(partitionsWithError))</div><div class="line">    handlePartitionsWithErrors(partitionsWithError)</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>其处理过程简单总结一下：</p>
<ol>
<li>通过 <code>fetch()</code> 方法，发送 Fetch 请求，获取相应的 response（如果遇到异常，那么在下次发送 Fetch 请求之前，会 sleep 一段时间再发）；</li>
<li>如果返回的结果 不为空，并且 Fetch 请求的 offset 信息与返回结果的 offset 信息对得上，那么就会调用 <code>processPartitionData()</code> 方法将拉取到的数据追加本地副本的日志文件中，如果返回结果有错误信息，那么就对相应错误进行相应的处理；</li>
<li>对在 Fetch 过程中遇到异常或返回错误的 topic-partition，会进行 delay 操作，下次 Fetch 请求的发生至少要间隔 <code>replica.fetch.backoff.ms</code> 时间。</li>
</ol>
<h4 id="fetch"><a href="#fetch" class="headerlink" title="fetch"></a>fetch</h4><p><code>fetch()</code> 方法作用是发送 Fetch 请求，并返回相应的结果，其具体的实现，如下：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//note: 发送 fetch 请求，获取拉取结果</span></div><div class="line"><span class="keyword">protected</span> <span class="function"><span class="keyword">def</span> <span class="title">fetch</span></span>(fetchRequest: <span class="type">FetchRequest</span>): <span class="type">Seq</span>[(<span class="type">TopicPartition</span>, <span class="type">PartitionData</span>)] = &#123;</div><div class="line">  <span class="keyword">val</span> clientResponse = sendRequest(fetchRequest.underlying)</div><div class="line">  <span class="keyword">val</span> fetchResponse = clientResponse.responseBody.asInstanceOf[<span class="type">FetchResponse</span>]</div><div class="line">  fetchResponse.responseData.asScala.toSeq.map &#123; <span class="keyword">case</span> (key, value) =&gt;</div><div class="line">    key -&gt; <span class="keyword">new</span> <span class="type">PartitionData</span>(value)</div><div class="line">  &#125;</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="comment">//note: 发送请求</span></div><div class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">sendRequest</span></span>(requestBuilder: <span class="type">AbstractRequest</span>.<span class="type">Builder</span>[_ &lt;: <span class="type">AbstractRequest</span>]): <span class="type">ClientResponse</span> = &#123;</div><div class="line">  <span class="keyword">import</span> kafka.utils.<span class="type">NetworkClientBlockingOps</span>._</div><div class="line">  <span class="keyword">try</span> &#123;</div><div class="line">    <span class="keyword">if</span> (!networkClient.blockingReady(sourceNode, socketTimeout)(time))</div><div class="line">      <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">SocketTimeoutException</span>(<span class="string">s"Failed to connect within <span class="subst">$socketTimeout</span> ms"</span>)</div><div class="line">    <span class="keyword">else</span> &#123;</div><div class="line">      <span class="keyword">val</span> clientRequest = networkClient.newClientRequest(sourceBroker.id.toString, requestBuilder,</div><div class="line">        time.milliseconds(), <span class="literal">true</span>)</div><div class="line">      networkClient.blockingSendAndReceive(clientRequest)(time) <span class="comment">//note: 阻塞直到获取返回结果</span></div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line">  <span class="keyword">catch</span> &#123;</div><div class="line">    <span class="keyword">case</span> e: <span class="type">Throwable</span> =&gt;</div><div class="line">      networkClient.close(sourceBroker.id.toString)</div><div class="line">      <span class="keyword">throw</span> e</div><div class="line">  &#125;</div><div class="line"></div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h4 id="processPartitionData"><a href="#processPartitionData" class="headerlink" title="processPartitionData"></a>processPartitionData</h4><p>这个方法的作用是，处理 Fetch 请求的具体数据内容，简单来说就是：检查一下数据大小是否超过限制、将数据追加到本地副本的日志文件中、更新本地副本的 hw 值。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// process fetched data</span></div><div class="line"><span class="comment">//note: 处理 fetch 的数据，将 fetch 的数据追加的日志文件中</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">processPartitionData</span></span>(topicPartition: <span class="type">TopicPartition</span>, fetchOffset: <span class="type">Long</span>, partitionData: <span class="type">PartitionData</span>) &#123;</div><div class="line">  <span class="keyword">try</span> &#123;</div><div class="line">    <span class="keyword">val</span> replica = replicaMgr.getReplica(topicPartition).get</div><div class="line">    <span class="keyword">val</span> records = partitionData.toRecords</div><div class="line"></div><div class="line">    <span class="comment">//note: 检查 records</span></div><div class="line">    maybeWarnIfOversizedRecords(records, topicPartition)</div><div class="line"></div><div class="line">    <span class="keyword">if</span> (fetchOffset != replica.logEndOffset.messageOffset)</div><div class="line">      <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">RuntimeException</span>(<span class="string">"Offset mismatch for partition %s: fetched offset = %d, log end offset = %d."</span>.format(topicPartition, fetchOffset, replica.logEndOffset.messageOffset))</div><div class="line">    <span class="keyword">if</span> (logger.isTraceEnabled)</div><div class="line">      trace(<span class="string">"Follower %d has replica log end offset %d for partition %s. Received %d messages and leader hw %d"</span></div><div class="line">        .format(replica.brokerId, replica.logEndOffset.messageOffset, topicPartition, records.sizeInBytes, partitionData.highWatermark))</div><div class="line">    replica.log.get.append(records, assignOffsets = <span class="literal">false</span>) <span class="comment">//note: 将 fetch 的数据追加到 log 中</span></div><div class="line">    <span class="keyword">if</span> (logger.isTraceEnabled)</div><div class="line">      trace(<span class="string">"Follower %d has replica log end offset %d after appending %d bytes of messages for partition %s"</span></div><div class="line">        .format(replica.brokerId, replica.logEndOffset.messageOffset, records.sizeInBytes, topicPartition))</div><div class="line">    <span class="comment">//note: 更新 replica 的 hw（logEndOffset 在追加数据后也会立马进行修改)</span></div><div class="line">    <span class="keyword">val</span> followerHighWatermark = replica.logEndOffset.messageOffset.min(partitionData.highWatermark)</div><div class="line">    <span class="comment">// for the follower replica, we do not need to keep</span></div><div class="line">    <span class="comment">// its segment base offset the physical position,</span></div><div class="line">    <span class="comment">// these values will be computed upon making the leader</span></div><div class="line">    <span class="comment">//note: 这个值主要是用在 leader replica 上的</span></div><div class="line">    replica.highWatermark = <span class="keyword">new</span> <span class="type">LogOffsetMetadata</span>(followerHighWatermark)</div><div class="line">    <span class="keyword">if</span> (logger.isTraceEnabled)</div><div class="line">      trace(<span class="string">s"Follower <span class="subst">$&#123;replica.brokerId&#125;</span> set replica high watermark for partition <span class="subst">$topicPartition</span> to <span class="subst">$followerHighWatermark</span>"</span>)</div><div class="line">    <span class="keyword">if</span> (quota.isThrottled(topicPartition))</div><div class="line">      quota.record(records.sizeInBytes)</div><div class="line">  &#125; <span class="keyword">catch</span> &#123;</div><div class="line">    <span class="keyword">case</span> e: <span class="type">KafkaStorageException</span> =&gt;</div><div class="line">      fatal(<span class="string">s"Disk error while replicating data for <span class="subst">$topicPartition</span>"</span>, e)</div><div class="line">      <span class="type">Runtime</span>.getRuntime.halt(<span class="number">1</span>)</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h2 id="副本同步异常情况的处理"><a href="#副本同步异常情况的处理" class="headerlink" title="副本同步异常情况的处理"></a>副本同步异常情况的处理</h2><p>在副本同步的过程中，会遇到哪些异常情况呢？</p>
<p>大家一定会想到关于 offset 的问题，在 Kafka 中，关于 offset 的处理，无论是 producer 端、consumer 端还是其他地方，offset 似乎都是一个形影不离的问题。在副本同步时，关于 offset，会遇到什么问题呢？下面举两个异常的场景：</p>
<ol>
<li>假如当前本地（id：1）的副本现在是 leader，其 LEO 假设为1000，而另一个在 isr 中的副本（id：2）其 LEO 为800，此时出现网络抖动，id 为1 的机器掉线后又上线了，但是此时副本的 leader 实际上已经变成了 2，而2的 LEO 为800，这时候1启动副本同步线程去2上拉取数据，希望从 offset=1000 的地方开始拉取，但是2上最大的 offset 才是800，这种情况该如何处理呢？</li>
<li>假设一个 replica （id：1）其 LEO 是10，它已经掉线好几天，这个 partition leader 的 offset 范围是 [100, 800]，那么 1 重启启动时，它希望从 offset=10 的地方开始拉取数据时，这时候发生了 OutOfRange，不过跟上面不同的是这里是小于了 leader offset 的范围，这种情况又该怎么处理？</li>
</ol>
<p>以上两种情况都是 offset OutOfRange 的情况，只不过：一是 Fetch Offset 超过了 leader 的 LEO，二是 Fetch Offset 小于 leader 最小的 offset，在介绍 Kafka 解决方案之前，我们先来自己思考一下这两种情况应该怎么处理？</p>
<ol>
<li>如果 fetch offset 超过 leader 的 offset，这时候副本应该是回溯到 leader 的 LEO 位置（超过这个值的数据删除），然后再去进行副本同步，当然这种解决方案其实是无法保证 leader 与 follower 数据的完全一致，再次发生 leader 切换时，可能会导致数据的可见性不一致，但既然用户允许了脏选举的发生，其实我们是可以认为用户是可以接收这种情况发生的；</li>
<li>这种就比较容易处理，首先清空本地的数据，因为本地的数据都已经过期了，然后从 leader 的最小 offset 位置开始拉取数据。</li>
</ol>
<p>上面是我们比较容易想出的解决方案，而在 Kafka 中，其解决方案也很类似，不过遇到情况比上面我们列出的两种情况多了一些复杂，其解决方案如下：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div></pre></td><td class="code"><pre><div class="line">  <span class="comment">/**</span></div><div class="line">   * Unclean leader election: A follower goes down, in the meanwhile the leader keeps appending messages. The follower comes back up</div><div class="line">   * and before it has completely caught up with the leader's logs, all replicas in the ISR go down. The follower is now uncleanly</div><div class="line">   * elected as the new leader, and it starts appending messages from the client. The old leader comes back up, becomes a follower</div><div class="line">   * and it may discover that the current leader's end offset is behind its own end offset.</div><div class="line">   *</div><div class="line">   * In such a case, truncate the current follower's log to the current leader's end offset and continue fetching.</div><div class="line">   *</div><div class="line">   * There is a potential for a mismatch between the logs of the two replicas here. We don't fix this mismatch as of now.</div><div class="line">   */</div><div class="line">  <span class="comment">//note: 脏选举的发生</span></div><div class="line">  <span class="comment">//note: 获取最新的 offset</span></div><div class="line">  <span class="keyword">val</span> leaderEndOffset: <span class="type">Long</span> = earliestOrLatestOffset(topicPartition, <span class="type">ListOffsetRequest</span>.<span class="type">LATEST_TIMESTAMP</span>,</div><div class="line">    brokerConfig.brokerId)</div><div class="line"></div><div class="line">  <span class="keyword">if</span> (leaderEndOffset &lt; replica.logEndOffset.messageOffset) &#123; <span class="comment">//note: leaderEndOffset 小于 副本 LEO 的情况</span></div><div class="line">    <span class="comment">// Prior to truncating the follower's log, ensure that doing so is not disallowed by the configuration for unclean leader election.</span></div><div class="line">    <span class="comment">// This situation could only happen if the unclean election configuration for a topic changes while a replica is down. Otherwise,</span></div><div class="line">    <span class="comment">// we should never encounter this situation since a non-ISR leader cannot be elected if disallowed by the broker configuration.</span></div><div class="line">    <span class="comment">//note: 这种情况只是发生在 unclear election 的情况下</span></div><div class="line">    <span class="keyword">if</span> (!<span class="type">LogConfig</span>.fromProps(brokerConfig.originals, <span class="type">AdminUtils</span>.fetchEntityConfig(replicaMgr.zkUtils,</div><div class="line">      <span class="type">ConfigType</span>.<span class="type">Topic</span>, topicPartition.topic)).uncleanLeaderElectionEnable) &#123; <span class="comment">//note: 不允许 unclear elect 时,直接退出进程</span></div><div class="line">      <span class="comment">// Log a fatal error and shutdown the broker to ensure that data loss does not unexpectedly occur.</span></div><div class="line">      fatal(<span class="string">"Exiting because log truncation is not allowed for partition %s,"</span>.format(topicPartition) +</div><div class="line">        <span class="string">" Current leader %d's latest offset %d is less than replica %d's latest offset %d"</span></div><div class="line">        .format(sourceBroker.id, leaderEndOffset, brokerConfig.brokerId, replica.logEndOffset.messageOffset))</div><div class="line">      <span class="type">System</span>.exit(<span class="number">1</span>)</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="comment">//note: warn 日志信息</span></div><div class="line">    warn(<span class="string">"Replica %d for partition %s reset its fetch offset from %d to current leader %d's latest offset %d"</span></div><div class="line">      .format(brokerConfig.brokerId, topicPartition, replica.logEndOffset.messageOffset, sourceBroker.id, leaderEndOffset))</div><div class="line">    <span class="comment">//note: 进行截断操作,将offset 大于等于targetOffset 的数据和索引删除</span></div><div class="line">    replicaMgr.logManager.truncateTo(<span class="type">Map</span>(topicPartition -&gt; leaderEndOffset))</div><div class="line">    leaderEndOffset</div><div class="line">  &#125; <span class="keyword">else</span> &#123; <span class="comment">//note: leader 的 LEO 大于 follower 的 LEO 的情况下,还发生了 OutOfRange</span></div><div class="line">    <span class="comment">//note: 1. follower 下线了很久,其 LEO 已经小于了 leader 的 StartOffset;</span></div><div class="line">    <span class="comment">//note: 2. 脏选举发生时, 如果 old leader 的 HW 大于 new leader 的 LEO,此时 old leader 回溯到 HW,并且这个位置开始拉取数据发生了 Out of range</span></div><div class="line">    <span class="comment">//note:    当这个方法调用时,随着 produce 持续产生数据,可能出现 leader LEO 大于 Follower LEO 的情况（不做任何处理,重试即可解决,但</span></div><div class="line">    <span class="comment">//note:    无法保证数据的一致性）。</span></div><div class="line">    <span class="comment">/**</span></div><div class="line">     * If the leader's log end offset is greater than the follower's log end offset, there are two possibilities:</div><div class="line">     * 1. The follower could have been down for a long time and when it starts up, its end offset could be smaller than the leader's</div><div class="line">     * start offset because the leader has deleted old logs (log.logEndOffset &lt; leaderStartOffset).</div><div class="line">     * 2. When unclean leader election occurs, it is possible that the old leader's high watermark is greater than</div><div class="line">     * the new leader's log end offset. So when the old leader truncates its offset to its high watermark and starts</div><div class="line">     * to fetch from the new leader, an OffsetOutOfRangeException will be thrown. After that some more messages are</div><div class="line">     * produced to the new leader. While the old leader is trying to handle the OffsetOutOfRangeException and query</div><div class="line">     * the log end offset of the new leader, the new leader's log end offset becomes higher than the follower's log end offset.</div><div class="line">     *</div><div class="line">     * In the first case, the follower's current log end offset is smaller than the leader's log start offset. So the</div><div class="line">     * follower should truncate all its logs, roll out a new segment and start to fetch from the current leader's log</div><div class="line">     * start offset.</div><div class="line">     * In the second case, the follower should just keep the current log segments and retry the fetch. In the second</div><div class="line">     * case, there will be some inconsistency of data between old and new leader. We are not solving it here.</div><div class="line">     * If users want to have strong consistency guarantees, appropriate configurations needs to be set for both</div><div class="line">     * brokers and producers.</div><div class="line">     *</div><div class="line">     * Putting the two cases together, the follower should fetch from the higher one of its replica log end offset</div><div class="line">     * and the current leader's log start offset.</div><div class="line">     *</div><div class="line">     */</div><div class="line">    <span class="keyword">val</span> leaderStartOffset: <span class="type">Long</span> = earliestOrLatestOffset(topicPartition, <span class="type">ListOffsetRequest</span>.<span class="type">EARLIEST_TIMESTAMP</span>,</div><div class="line">      brokerConfig.brokerId)</div><div class="line">    warn(<span class="string">"Replica %d for partition %s reset its fetch offset from %d to current leader %d's start offset %d"</span></div><div class="line">      .format(brokerConfig.brokerId, topicPartition, replica.logEndOffset.messageOffset, sourceBroker.id, leaderStartOffset))</div><div class="line">    <span class="keyword">val</span> offsetToFetch = <span class="type">Math</span>.max(leaderStartOffset, replica.logEndOffset.messageOffset)</div><div class="line">    <span class="comment">// Only truncate log when current leader's log start offset is greater than follower's log end offset.</span></div><div class="line">    <span class="keyword">if</span> (leaderStartOffset &gt; replica.logEndOffset.messageOffset) <span class="comment">//note: 如果 leader 的 startOffset 大于副本的最大 offset</span></div><div class="line">      <span class="comment">//note: 将这个 log 的数据全部清空,并且从 leaderStartOffset 开始拉取数据</span></div><div class="line">      replicaMgr.logManager.truncateFullyAndStartAt(topicPartition, leaderStartOffset)</div><div class="line">    offsetToFetch</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>针对第一种情况，在 Kafka 中，实际上还会发生这样一种情况，1 在收到 OutOfRange 错误时，这时去 leader 上获取的 LEO 值与最小的 offset 值，这时候却发现 leader 的 LEO 已经从 800 变成了 1100（这个 topic-partition 的数据量增长得比较快），再按照上面的解决方案就不太合理，Kafka 这边的解决方案是：遇到这种情况，进行重试就可以了，下次同步时就会正常了，但是依然会有上面说的那个问题。</p>
<h2 id="replica-fetcher-线程的关闭"><a href="#replica-fetcher-线程的关闭" class="headerlink" title="replica fetcher 线程的关闭"></a>replica fetcher 线程的关闭</h2><p>最后我们再来介绍一下 replica fetcher 线程在什么情况下会关闭，同样，看一下最开始那张图的第三部分，图中已经比较清晰地列出了 replica fetcher 线程关闭的条件，在三种情况下会关闭对这个 topic-partition 的拉取操作（<code>becomeLeaderOrFollower()</code> 这个方法会在对 LeaderAndIsr 请求处理的文章中讲解，这里先忽略）：</p>
<ol>
<li><code>stopReplica()</code>：broker 收到了 controller 发来的 StopReplica 请求，这时会开始关闭对指定 topic-partition 的同步线程；</li>
<li><code>makeLeaders</code>：这些 partition 的本地副本被选举成了 leader，这时候就会先停止对这些 topic-partition 副本同步线程；</li>
<li><code>makeFollowers()</code>：前面已经介绍过，这里实际上停止副本同步，然后再开启副本同步线程，因为这些 topic-partition 的 leader 可能发生了切换。</li>
</ol>
<blockquote>
<p>这里直接说线程关闭，其实不是很准确，因为每个 replica fetcher 线程操作的是多个 topic-partition，而在关闭的粒度是 partition 级别，只有这个线程分配的 partition 全部关闭后，这个线程才会真正被关闭。</p>
</blockquote>
<h3 id="关闭副本同步"><a href="#关闭副本同步" class="headerlink" title="关闭副本同步"></a>关闭副本同步</h3><p>看下 ReplicaManager 中触发 replica fetcher 线程关闭的三个方法。</p>
<h4 id="stopReplica"><a href="#stopReplica" class="headerlink" title="stopReplica"></a>stopReplica</h4><p>StopReplica 的请求实际上是 Controller 发送过来的，这个在 controller 部分会讲述，它触发的条件有多种，比如：broker 下线、partition replica 迁移等等，ReplicaManager 这里的实现如下：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//note: 获取 tp 的 leader replica</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">getLeaderReplicaIfLocal</span></span>(topicPartition: <span class="type">TopicPartition</span>): <span class="type">Replica</span> =  &#123;</div><div class="line">  <span class="keyword">val</span> partitionOpt = getPartition(topicPartition) <span class="comment">//note: 获取对应的 Partiion 对象</span></div><div class="line">  partitionOpt <span class="keyword">match</span> &#123;</div><div class="line">    <span class="keyword">case</span> <span class="type">None</span> =&gt;</div><div class="line">      <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">UnknownTopicOrPartitionException</span>(<span class="string">s"Partition <span class="subst">$topicPartition</span> doesn't exist on <span class="subst">$localBrokerId</span>"</span>)</div><div class="line">    <span class="keyword">case</span> <span class="type">Some</span>(partition) =&gt;</div><div class="line">      partition.leaderReplicaIfLocal <span class="keyword">match</span> &#123;</div><div class="line">        <span class="keyword">case</span> <span class="type">Some</span>(leaderReplica) =&gt; leaderReplica <span class="comment">//note: 返回 leader 对应的副本</span></div><div class="line">        <span class="keyword">case</span> <span class="type">None</span> =&gt;</div><div class="line">          <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">NotLeaderForPartitionException</span>(<span class="string">s"Leader not local for partition <span class="subst">$topicPartition</span> on broker <span class="subst">$localBrokerId</span>"</span>)</div><div class="line">      &#125;</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h4 id="makeLeaders"><a href="#makeLeaders" class="headerlink" title="makeLeaders"></a>makeLeaders</h4><p><code>makeLeaders()</code> 方法的调用是在 broker 上这个 partition 的副本被设置为 leader 时触发的，其实现如下：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/*</span></div><div class="line"> * Make the current broker to become leader for a given set of partitions by:</div><div class="line"> *</div><div class="line"> * 1. Stop fetchers for these partitions</div><div class="line"> * 2. Update the partition metadata in cache</div><div class="line"> * 3. Add these partitions to the leader partitions set</div><div class="line"> *</div><div class="line"> * If an unexpected error is thrown in this function, it will be propagated to KafkaApis where</div><div class="line"> * the error message will be set on each partition since we do not know which partition caused it. Otherwise,</div><div class="line"> * return the set of partitions that are made leader due to this method</div><div class="line"> *</div><div class="line"> *  <span class="doctag">TODO:</span> the above may need to be fixed later</div><div class="line"> */</div><div class="line"><span class="comment">//note: 选举当前副本作为 partition 的 leader，处理过程：</span></div><div class="line"><span class="comment">//note: 1. 停止这些 partition 的 副本同步请求；</span></div><div class="line"><span class="comment">//note: 2. 更新缓存中的 partition metadata；</span></div><div class="line"><span class="comment">//note: 3. 将这些 partition 添加到 leader partition 集合中。</span></div><div class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">makeLeaders</span></span>(controllerId: <span class="type">Int</span>,</div><div class="line">                        epoch: <span class="type">Int</span>,</div><div class="line">                        partitionState: <span class="type">Map</span>[<span class="type">Partition</span>, <span class="type">PartitionState</span>],</div><div class="line">                        correlationId: <span class="type">Int</span>,</div><div class="line">                        responseMap: mutable.<span class="type">Map</span>[<span class="type">TopicPartition</span>, <span class="type">Short</span>]): <span class="type">Set</span>[<span class="type">Partition</span>] = &#123;</div><div class="line">  partitionState.keys.foreach &#123; partition =&gt;</div><div class="line">    stateChangeLogger.trace((<span class="string">"Broker %d handling LeaderAndIsr request correlationId %d from controller %d epoch %d "</span> +</div><div class="line">      <span class="string">"starting the become-leader transition for partition %s"</span>)</div><div class="line">      .format(localBrokerId, correlationId, controllerId, epoch, partition.topicPartition))</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  <span class="keyword">for</span> (partition &lt;- partitionState.keys)</div><div class="line">    responseMap.put(partition.topicPartition, <span class="type">Errors</span>.<span class="type">NONE</span>.code)</div><div class="line"></div><div class="line">  <span class="keyword">val</span> partitionsToMakeLeaders: mutable.<span class="type">Set</span>[<span class="type">Partition</span>] = mutable.<span class="type">Set</span>()</div><div class="line"></div><div class="line">  <span class="keyword">try</span> &#123;</div><div class="line">    <span class="comment">// First stop fetchers for all the partitions</span></div><div class="line">    <span class="comment">//note: 停止这些副本同步请求</span></div><div class="line">    replicaFetcherManager.removeFetcherForPartitions(partitionState.keySet.map(_.topicPartition))</div><div class="line">    <span class="comment">// Update the partition information to be the leader</span></div><div class="line">    <span class="comment">//note: 更新这些 partition 的信息（这些 partition 成为 leader 了）</span></div><div class="line">    partitionState.foreach&#123; <span class="keyword">case</span> (partition, partitionStateInfo) =&gt;</div><div class="line">      <span class="comment">//note: 在 partition 对象将本地副本设置为 leader</span></div><div class="line">      <span class="keyword">if</span> (partition.makeLeader(controllerId, partitionStateInfo, correlationId))</div><div class="line">        partitionsToMakeLeaders += partition <span class="comment">//note: 成功选为 leader 的 partition 集合</span></div><div class="line">      <span class="keyword">else</span></div><div class="line">        <span class="comment">//note: 本地 replica 已经是 leader replica，可能是接收了重试的请求</span></div><div class="line">        stateChangeLogger.info((<span class="string">"Broker %d skipped the become-leader state change after marking its partition as leader with correlation id %d from "</span> +</div><div class="line">          <span class="string">"controller %d epoch %d for partition %s since it is already the leader for the partition."</span>)</div><div class="line">          .format(localBrokerId, correlationId, controllerId, epoch, partition.topicPartition))</div><div class="line">    &#125;</div><div class="line">    partitionsToMakeLeaders.foreach &#123; partition =&gt;</div><div class="line">      stateChangeLogger.trace((<span class="string">"Broker %d stopped fetchers as part of become-leader request from controller "</span> +</div><div class="line">        <span class="string">"%d epoch %d with correlation id %d for partition %s"</span>)</div><div class="line">        .format(localBrokerId, controllerId, epoch, correlationId, partition.topicPartition))</div><div class="line">    &#125;</div><div class="line">  &#125; <span class="keyword">catch</span> &#123;</div><div class="line">    <span class="keyword">case</span> e: <span class="type">Throwable</span> =&gt;</div><div class="line">      partitionState.keys.foreach &#123; partition =&gt;</div><div class="line">        <span class="keyword">val</span> errorMsg = (<span class="string">"Error on broker %d while processing LeaderAndIsr request correlationId %d received from controller %d"</span> +</div><div class="line">          <span class="string">" epoch %d for partition %s"</span>).format(localBrokerId, correlationId, controllerId, epoch, partition.topicPartition)</div><div class="line">        stateChangeLogger.error(errorMsg, e)</div><div class="line">      &#125;</div><div class="line">      <span class="comment">// Re-throw the exception for it to be caught in KafkaApis</span></div><div class="line">      <span class="keyword">throw</span> e</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  <span class="comment">//note: LeaderAndIsr 请求处理完成</span></div><div class="line">  partitionState.keys.foreach &#123; partition =&gt;</div><div class="line">    stateChangeLogger.trace((<span class="string">"Broker %d completed LeaderAndIsr request correlationId %d from controller %d epoch %d "</span> +</div><div class="line">      <span class="string">"for the become-leader transition for partition %s"</span>)</div><div class="line">      .format(localBrokerId, correlationId, controllerId, epoch, partition.topicPartition))</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  partitionsToMakeLeaders</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>简单来说，这个方法的过程逻辑如下：</p>
<ol>
<li>先停止对这些 partition 的副本同步流程，因为这些 partition 的本地副本已经被选举成为了 leader；</li>
<li>将这些 partition 的本地副本设置为 leader，并且开始更新相应 meta 信息（主要是记录其他 follower 副本的相关信息）；</li>
<li>将这些 partition 添加到本地记录的 leader partition 集合中。</li>
</ol>
<h4 id="makeFollowers"><a href="#makeFollowers" class="headerlink" title="makeFollowers"></a>makeFollowers</h4><p>这个在前面已经讲述过了，参考前面的讲述。</p>
<h3 id="removeFetcherForPartitions"><a href="#removeFetcherForPartitions" class="headerlink" title="removeFetcherForPartitions"></a>removeFetcherForPartitions</h3><p>调用 ReplicaFetcherManager 的 <code>removeFetcherForPartitions()</code> 删除对这些 topic-partition 的副本同步设置，这里在实现时，会遍历所有的 replica fetcher 线程，都执行 <code>removePartitions()</code> 方法来移除对应的 topic-partition 集合。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//note: 删除一个 partition 的 replica-fetch 线程</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">removeFetcherForPartitions</span></span>(partitions: <span class="type">Set</span>[<span class="type">TopicPartition</span>]) &#123;</div><div class="line">  mapLock synchronized &#123;</div><div class="line">    <span class="keyword">for</span> (fetcher &lt;- fetcherThreadMap.values) <span class="comment">//note: 遍历所有的 fetchThread 去移除这个 topic-partition 集合</span></div><div class="line">      fetcher.removePartitions(partitions)</div><div class="line">  &#125;</div><div class="line">  info(<span class="string">"Removed fetcher for partitions %s"</span>.format(partitions.mkString(<span class="string">","</span>)))</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h3 id="removePartitions"><a href="#removePartitions" class="headerlink" title="removePartitions"></a>removePartitions</h3><p>这个方法的作用是：ReplicaFetcherThread 将这些 topic-partition 从自己要拉取的 partition 列表中移除。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">removePartitions</span></span>(topicPartitions: <span class="type">Set</span>[<span class="type">TopicPartition</span>]) &#123;</div><div class="line">  partitionMapLock.lockInterruptibly()</div><div class="line">  <span class="keyword">try</span> &#123;</div><div class="line">    topicPartitions.foreach &#123; topicPartition =&gt;</div><div class="line">      partitionStates.remove(topicPartition)</div><div class="line">      fetcherLagStats.unregister(topicPartition.topic, topicPartition.partition)</div><div class="line">    &#125;</div><div class="line">  &#125; <span class="keyword">finally</span> partitionMapLock.unlock()</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h3 id="ReplicaFetcherThread-的关闭"><a href="#ReplicaFetcherThread-的关闭" class="headerlink" title="ReplicaFetcherThread 的关闭"></a>ReplicaFetcherThread 的关闭</h3><p>前面介绍那么多，似乎还是没有真正去关闭，那么 ReplicaFetcherThread 真正关闭是哪里操作的呢？</p>
<p>实际上 ReplicaManager 每次处理完 LeaderAndIsr 请求后，都会调用 ReplicaFetcherManager 的 <code>shutdownIdleFetcherThreads()</code> 方法，如果 fetcher 线程要拉取的 topic-partition 集合为空，那么就会关闭掉对应的 fetcher 线程。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//note: 关闭没有拉取 topic-partition 任务的拉取线程</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">shutdownIdleFetcherThreads</span></span>() &#123;</div><div class="line">  mapLock synchronized &#123;</div><div class="line">    <span class="keyword">val</span> keysToBeRemoved = <span class="keyword">new</span> mutable.<span class="type">HashSet</span>[<span class="type">BrokerAndFetcherId</span>]</div><div class="line">    <span class="keyword">for</span> ((key, fetcher) &lt;- fetcherThreadMap) &#123;</div><div class="line">      <span class="keyword">if</span> (fetcher.partitionCount &lt;= <span class="number">0</span>) &#123; <span class="comment">//note: 如果该线程拉取的 partition 数小于 0</span></div><div class="line">        fetcher.shutdown()</div><div class="line">        keysToBeRemoved += key</div><div class="line">      &#125;</div><div class="line">    &#125;</div><div class="line">    fetcherThreadMap --= keysToBeRemoved</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>关于 Replica Fetcher 线程这部分的内容终于讲解完了，希望能对大家有所帮助，有问题欢迎通过留言、微博或邮件进行交流。</p>
</div><script type="text/javascript" src="/js/share.js?v=0.0.0" async></script><a data-url="http://matt33.com/2018/04/29/kafka-replica-fetcher-thread/" data-id="cjo2v4k5u007ythagirfeezdu" class="article-share-link">分享到</a><div class="copyright"><a href="http://matt33.com/copyright/">博客版权说明</a></div><div class="tags"><a href="/tags/kafka/">kafka</a></div><div class="post-nav"><a href="/2018/05/01/kafka-replica-manager/" class="pre">Kafka 源码解析之 ReplicaManager 详解（十五）</a><a href="/2018/04/15/kafka-server-handle-fetch-request/" class="next">Kafka 源码解析之 Server 端如何处理 Fetch 请求（十三）</a></div><div id="disqus_thread"><div class="btn_click_load"><button class="disqus_click_btn">阅读评论 「请确保 disqus.com 可以正常加载」</button></div><script>var disqus_shortname = 'http-matt33-com';
var disqus_identifier = '2018/04/29/kafka-replica-fetcher-thread/';
var disqus_title = 'Kafka 源码解析之副本同步机制实现（十四）';
var disqus_url = 'http://matt33.com/2018/04/29/kafka-replica-fetcher-thread/';
$('.btn_click_load').click(function() {
  (function() {
    var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
    dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
  })();
  $('.btn_click_load').css('display','none');
});
$.ajax({
  url: 'https://disqus.com/favicon.ico',
  timeout: 3000,
  type: 'GET',
  success: (function() {
    var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
    dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    $('.btn_click_load').css('display','none');
  })(),
  error: function() {
    $('.btn_click_load').css('display','block');
  }
});</script><script id="dsq-count-scr" src="//http-matt33-com.disqus.com/count.js" async></script></div></div></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><div class="widget-title"><i class="fa fa-weibo"> 微博</i></div><iframe width="100%" height="90" class="share_self"  frameborder="0" scrolling="no" src="http://widget.weibo.com/weiboshow/index.php?language=&width=0&height=100&fansRow=1&ptype=1&speed=0&skin=1&isTitle=0&noborder=1&isWeibo=0&isFans=0&uid=2650396571&verifier=f2f0e397&colors=D8D8D8,ffffff,666666,0082cb,ecfbfd&dpc=1"></iframe></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> 分类</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/书屋/">书屋</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/影如人生/">影如人生</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/技术/">技术</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/旅行/">旅行</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/转载/">转载</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/随笔/">随笔</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> 标签</i></div><div class="tagcloud"><a href="/tags/rpc/" style="font-size: 15px;">rpc</a> <a href="/tags/kafka/" style="font-size: 15px;">kafka</a> <a href="/tags/database/" style="font-size: 15px;">database</a> <a href="/tags/storm/" style="font-size: 15px;">storm</a> <a href="/tags/java/" style="font-size: 15px;">java</a> <a href="/tags/linux/" style="font-size: 15px;">linux</a> <a href="/tags/转载/" style="font-size: 15px;">转载</a> <a href="/tags/travel/" style="font-size: 15px;">travel</a> <a href="/tags/maven/" style="font-size: 15px;">maven</a> <a href="/tags/learn/" style="font-size: 15px;">learn</a> <a href="/tags/hadoop/" style="font-size: 15px;">hadoop</a> <a href="/tags/hexo/" style="font-size: 15px;">hexo</a> <a href="/tags/algorithm/" style="font-size: 15px;">algorithm</a> <a href="/tags/思考/" style="font-size: 15px;">思考</a> <a href="/tags/thrift/" style="font-size: 15px;">thrift</a> <a href="/tags/zookeeper/" style="font-size: 15px;">zookeeper</a> <a href="/tags/mac/" style="font-size: 15px;">mac</a> <a href="/tags/tcp/" style="font-size: 15px;">tcp</a> <a href="/tags/jvm/" style="font-size: 15px;">jvm</a> <a href="/tags/bug/" style="font-size: 15px;">bug</a> <a href="/tags/随笔/" style="font-size: 15px;">随笔</a> <a href="/tags/电影随想/" style="font-size: 15px;">电影随想</a> <a href="/tags/web/" style="font-size: 15px;">web</a> <a href="/tags/分布式系统/" style="font-size: 15px;">分布式系统</a> <a href="/tags/bk/" style="font-size: 15px;">bk</a> <a href="/tags/cv/" style="font-size: 15px;">cv</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> 最新文章</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2018/11/04/kafka-transaction/">Kafka Exactly-Once 之事务性实现</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/10/24/kafka-idempotent/">Kafka 事务性之幂等性实现</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/10/19/bk-cluster-install-and-use/">BookKeeper 集群搭建及使用</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/09/01/yarn-architecture-learn/">YARN 架构学习总结</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/08/01/system-learn-summary/">如何学习开源项目</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/07/28/jvm-cms/">JVM 之 ParNew 和 CMS 日志分析</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/07/15/hdfs-architecture-learn/">HDFS 架构学习总结</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/07/14/kafka-controller-redesign/">Kafka Controller Redesign 方案</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/07/08/distribute-system-consistency-protocol/">分布式系统的一致性协议之 2PC 和 3PC</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/07/07/java-daemon-thread/">Java 守护线程</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-external-link"> 友情链接</i></div><ul></ul><a href="http://tech.meituan.com/" title="美团点评技术团队" target="_blank">美团点评技术团队</a><ul></ul><a href="http://jm.taobao.org/" title="阿里中间件团队博客" target="_blank">阿里中间件团队博客</a><ul></ul><a href="http://www.jianshu.com/" title="简书" target="_blank">简书</a></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">© <a href="/." rel="nofollow">Matt's Blog 柳年思水.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a id="rocket" href="#top" class="show"></a><script type="text/javascript" src="/js/totop.js?v=0.0.0" async></script><div class="analytics"><script>var cnzz_protocol = (("https:" == document.location.protocol) ? " https://" : " http://");
document.write(unescape("%3Cspan id='cnzz_stat_icon_1256517224'%3E%3C/span%3E%3Cscript src='" + cnzz_protocol + "s95.cnzz.com/z_stat.php%3Fid%3D1256517224%26show%3Dpic' type='text/javascript'%3E%3C/script%3E"));</script></div><script type="text/javascript" src="//cdn.bootcss.com/fancybox/2.1.5/jquery.fancybox.pack.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=0.0.0" async></script><link rel="stylesheet" type="text/css" href="/css/jquery.fancybox.css?v=0.0.0"><script>(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
ga('create','UA-64518924-1','auto');ga('send','pageview');
</script><script>var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "//hm.baidu.com/hm.js?5cf44757fa0d23bc7637935e44a9104a";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
  })();
</script><script type="text/javascript" src="/js/codeblock-resizer.js?v=0.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=0.0.0"></script></div></body></html>