<!DOCTYPE html><html lang="zh-CN"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description" content="与一群有趣的人，做一些有趣的事."><title>Paper 阅读: Real-Time Machine Learning: The Missing Pieces | Matt's Blog</title><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/normalize/4.2.0/normalize.min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/0.6.0/pure-min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/0.6.0/grids-responsive-min.css"><link rel="stylesheet" type="text/css" href="/css/style.css?v=0.0.0"><link rel="stylesheet" href="//cdn.bootcss.com/font-awesome/4.6.3/css/font-awesome.min.css"><script type="text/javascript" src="//cdn.bootcss.com/jquery/3.0.0/jquery.min.js"></script><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"><link rel="alternate" type="application/atom+xml" href="/atom.xml"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">Paper 阅读: Real-Time Machine Learning: The Missing Pieces</h1><a id="logo" href="/.">Matt's Blog</a><p class="description">王蒙</p></div><div id="nav-menu"><a href="/." class="current"><i class="fa fa-home"> 首页</i></a><a href="/archives/"><i class="fa fa-archive"> 归档</i></a><a href="/about/"><i class="fa fa-user"> 关于</i></a><a href="/atom.xml"><i class="fa fa-rss"> 订阅</i></a></div></div><div id="layout" class="pure-g"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">Paper 阅读: Real-Time Machine Learning: The Missing Pieces</h1><div class="post-meta">Oct 19, 2019<span> | </span><span class="category"><a href="/categories/技术/">技术</a></span><span> | </span><span class="post-count">3,570</span><span> 字</span><script src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" async></script><span id="busuanzi_container_page_pv"> | <span id="busuanzi_value_page_pv"></span><span> Times</span></span></div><a data-disqus-identifier="2019/10/19/paper-ray1/" href="/2019/10/19/paper-ray1/#disqus_thread" class="disqus-comment-count"></a><div class="clear"><div id="toc" class="toc-article"><div class="toc-title">文章目录</div><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#问题"><span class="toc-number">1.</span> <span class="toc-text">问题</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#举个例子"><span class="toc-number">1.1.</span> <span class="toc-text">举个例子</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#场景对计算模型的要求"><span class="toc-number">1.2.</span> <span class="toc-text">场景对计算模型的要求</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#性能要求"><span class="toc-number">1.2.1.</span> <span class="toc-text">性能要求</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#执行模型要求"><span class="toc-number">1.2.2.</span> <span class="toc-text">执行模型要求</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#实践要求"><span class="toc-number">1.2.3.</span> <span class="toc-text">实践要求</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#业内现况"><span class="toc-number">2.</span> <span class="toc-text">业内现况</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#解决方案：一套新的架构模型"><span class="toc-number">3.</span> <span class="toc-text">解决方案：一套新的架构模型</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#API-和-执行模型"><span class="toc-number">3.1.</span> <span class="toc-text">API 和 执行模型</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#架构设计"><span class="toc-number">3.2.</span> <span class="toc-text">架构设计</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Centralized-Control-State"><span class="toc-number">3.2.1.</span> <span class="toc-text">Centralized Control State</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Hybrid-Scheduler"><span class="toc-number">3.2.2.</span> <span class="toc-text">Hybrid Scheduler</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#其他"><span class="toc-number">3.3.</span> <span class="toc-text">其他</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#总结"><span class="toc-number">3.4.</span> <span class="toc-text">总结</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#业内实践"><span class="toc-number">4.</span> <span class="toc-text">业内实践</span></a></li></ol></div></div><div class="post-content"><p>这周抽空看了关于 ray 的一篇论文，论文是 2017 年发表的（见：<a href="https://arxiv.org/pdf/1703.03924.pdf" target="_blank" rel="external">Real-Time Machine Learning: The Missing Pieces</a>，他们比较新的论文是 18 年发表的，见：<a href="https://www.usenix.org/system/files/osdi18-moritz.pdf" target="_blank" rel="external">Ray: A Distributed Framework for Emerging AI Applications</a>），虽然论文描述的架构与现在 ray 真正的构架实现已经有了较大的不同，主要也是 ray 这两年发展比较快，架构做了很多的优化，不过本篇论文依然值得仔细阅读学习 一下的，这篇论文也展示了 ray 最初设计实现的出发点。</p>
<blockquote>
<p>本章不会严格按照论文翻译，整体会按照下面的思路来叙述：</p>
<ol>
<li>遇到的问题什么？</li>
<li>当前业内的方案是什么？</li>
<li>论文提出了什么样的解决方案？达到了什么效果？</li>
</ol>
</blockquote>
<h2 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h2><p>现在有越来越多的 ML 应用，不仅仅使用静态模型进行训练预测，它们会使用动态、实时决策的反馈来实时调整应用，这种场景就给计算模型提出了一些新的要求：</p>
<ul>
<li>高吞吐低延迟；</li>
<li>自适应创建任意的 task graph；</li>
<li>针对不同的数据集使用的不同内核（可以理解为融合计算）；</li>
</ul>
<p>这些要求如果单独去实现的话，并不是很难，但是把它们在一套系统里同时实现就非常有挑战性了，而目前业内并没有这样的一套方案（指的是这套系统设计之前，业内还没有）。</p>
<h3 id="举个例子"><a href="#举个例子" class="headerlink" title="举个例子"></a>举个例子</h3><p>这里，我们看个示例，下图 a 是一个传统的 ML 应用架构，它主要使用离线数据做训练和预测（ML 中监督式学习），但是现在有个趋势，就是如下图 b 所示的构架越来越多，即 ML 应用与实时反馈的回路紧密集成，它会依赖实时数据做训练和预测。</p>
<p><img src="/images/paper/ray1-1.png" alt="ML 应用实例"></p>
<h3 id="场景对计算模型的要求"><a href="#场景对计算模型的要求" class="headerlink" title="场景对计算模型的要求"></a>场景对计算模型的要求</h3><p>对于前面提出的场景，对模型的灵活性和性能有了新的要求，在满足这些要求的同时，还要保持现代分布式执行模型的优势（比如：应用级别的容错保证等等），挑战性很大，根据之前在 Spark、MPI 和 TensorFlow 开发 ML 和 RL（强化学习）的经历，这些痛点更加明显。当然这些要求也是通用的，并不仅仅使用在 ML 和 RL 中。</p>
<h4 id="性能要求"><a href="#性能要求" class="headerlink" title="性能要求"></a>性能要求</h4><p>这些 ML 应用也是有严格的延迟和吞吐要求：</p>
<ul>
<li>R1：<strong>low latency</strong>，ML 应用的实时性、reactive 和 interactive 特性都是需要端到端执行的毫秒级延迟；</li>
<li>R2：<strong>High throughput</strong>，训练和部署期间的计算都是需要支持每秒几百万 task 执行的高吞吐任务；</li>
</ul>
<h4 id="执行模型要求"><a href="#执行模型要求" class="headerlink" title="执行模型要求"></a>执行模型要求</h4><p>尽管现在业内很多的执行模型已经对常见计算模式的识别和优化取得了很大进展，但 ML 应用还需要更大的灵活性：</p>
<ul>
<li>R3：<strong>dynamic task creation</strong>，诸如蒙卡洛树搜索（Monte Carlo Tree）的 RL 基本算法在执行期间会根据其他 task 执行的结果动态创建新的 task；</li>
<li>R4：<strong>heterogeneous tasks（异构任务）</strong>，深度学习和 RL 在执行时间和资源需求上差异很大，因此对执行异构任务和资源的支持是非常有必要的；</li>
<li>R5：<strong>arbitrary dataflow dependencies</strong>，深度学习和 RL 应用会产生任意且更细粒度的任务依赖；</li>
</ul>
<h4 id="实践要求"><a href="#实践要求" class="headerlink" title="实践要求"></a>实践要求</h4><ul>
<li>R6：<strong>transparent fault tolerance</strong>：容错是一个非常重要和核心的要求，但与高吞吐、非确定性 task 执行放在一起实现就有一定难度了；</li>
<li>R7：<strong>debuggablitity and profiling（调试和性能分析）</strong>：调试和性能分析是编写任何分布式作业最耗时的方面，ML 应用尤其如此，这些应用通常是计算密集和随机的。</li>
</ul>
<p>上面的要求与我们常见的大数据计算系统，如：Flink 和 Spark，最大的区别是 R3~R5，对于 Flink 和 Spark 来说，向集群提交的 dataflow graph 是固定的，提交之后是不能改变的，这种模式在 ML 场景就显得非常不灵活了。</p>
<h2 id="业内现况"><a href="#业内现况" class="headerlink" title="业内现况"></a>业内现况</h2><p><strong>Static dataflow Systems</strong>，它们需要开发者提前设计好 dataflow graph，比如：MR 和 Spark。对于其他的像 Dryad 和 Naiad 的系统，它们是支持复杂的依赖结构（R5）；TensorFlow 和 MXNet，它们对深度学习场景做了很多优化。然而没有一个系统，可以完全支持根据输入数据和 task 执行任意动态扩展 dataflow graph。</p>
<p><strong>Dynamic Dataflow Systems</strong>，像 CIEL 和 Dask 不但支持上面 static dataflow Systems 的很多特性，还支持动态 task 创建（R3），这些模型符合我们 R3~R5 的需要。然而，它们有一些受限的地方，比如：完全中心化的调度，它们会导致我们不得不在吞吐和 latency 之间做取舍。</p>
<p><strong>Other Systems</strong> 像 Open MPI 和基于 actor 模型变体的系统（Orleans 和 Erlang）提供了低延迟（R1）和高吞吐（R2）的分布式计算。尽管这些系统也可以支持我们执行模型的需要（R3-R5，并且已经在 ML 中应用了），但是很多系统 level 的逻辑需求却需要应用程序自己去实现，比如：容错和 task 调度的本地感知。</p>
<p>综上，业内并没有一套可以完全符合我们的需求的系统，所以最好的办法就是重新造轮子，从头开始设计和写一套系统，业内对这块也有了很多的实践，虽然是重头开始设计，但还是可以从业内现有的系统中借鉴很多的经验（毕竟这套系统设计的出发点，也考虑到了通用性，而不仅仅用在 ML 领域）。</p>
<h2 id="解决方案：一套新的架构模型"><a href="#解决方案：一套新的架构模型" class="headerlink" title="解决方案：一套新的架构模型"></a>解决方案：一套新的架构模型</h2><p>论文发表的时候，ray 还处于初期，当时的一些架构设计后来也有了一些变化，但本文依然以论文中的架构为主来介绍。</p>
<h3 id="API-和-执行模型"><a href="#API-和-执行模型" class="headerlink" title="API 和 执行模型"></a>API 和 执行模型</h3><p>新提出的架构与 Flink 和 Spark 最大区别是在 R3~R5，为了支持这三个执行模型要求，这里设计了一套 API，它允许任意的 function 作为远程的 task 执行（并且还是在 dataflow 中的一环）。</p>
<ol>
<li><strong>task 创建是非阻塞的</strong>：当一个 task 创建后，会以 <code>future</code> 做 task 的返回值，task 是在系统中异步执行的；</li>
<li><strong>任意 function 的执行都可以作为远程 task 执行</strong>：为了支持 R4，function 都可以作为远程 task 执行的；task 创建的参数可以是一个 <code>future</code>，这样的话，新创建的 task 就会依赖这个 future 对应的 task，它也就实现了任意的 DAG 依赖（R5）；</li>
<li><strong>任何执行的 task 都可以在不阻塞它们计算的同时创建新的 task</strong>，因此，task 的吞吐不会受到 worker 带宽的限制（R2），并且可以做到动态创建 graph（R3）；</li>
<li>一个 task 的返回值可以通过调用 <code>get</code> 方法得到，它会阻塞直到 task 执行结束；</li>
<li><code>wait</code> 方法可以执行批量任务等待，该方法需要指定一个 future 列表、timeout 参数和要返回的 task number 的数量，这个方法会返回 future 任务的子集，它们是在 timeout 达到或满足数量要求时返回的。</li>
</ol>
<p>这里看这些 API 可能会有一些不太理解，给大家推荐一篇文章：<a href="https://www.cnblogs.com/fanzhidongyzby/p/7901139.html" target="_blank" rel="external">高性能分布式执行框架——Ray</a>，这篇文章对于这些 API 在 ray 上的实现都有详细的示例，有兴趣的可以看下。</p>
<h3 id="架构设计"><a href="#架构设计" class="headerlink" title="架构设计"></a>架构设计</h3><p>这里设计的架构也是 Master/Slave 模型，它包含：运行在每个 node 上的 worker 进程、每个 node 会有一个 local scheduler、一个或多个 global scheduler 以及在 worker 间做数据共享的内存对象存储，如下图所示（大家依然可以看下这篇文章 <a href="https://www.cnblogs.com/fanzhidongyzby/p/7901139.html" target="_blank" rel="external">高性能分布式执行框架——Ray</a>，它介绍了 Ray 的落地实现架构，但论文中更多的还是模型设计）。</p>
<p><img src="/images/paper/ray1-2.png" alt="架构模型"></p>
<p>Master 负责全局协调和状态维护，Slave 执行分布式计算任务，不同与传统计算系统的是，它使用了混合任务调度的思路：</p>
<ul>
<li><strong>Global Scheduler</strong>：Master上启动了一个全局调度器，用于接收本地调度器提交的任务，并将任务分发给合适的本地任务调度器执行；</li>
<li><strong>Control State（db 服务）</strong>：Master 上启动了一到多个 db server 用于保存分布式任务的状态信息，包括对象机器的映射、任务描述、任务debug信息等；</li>
<li><strong>Local Scheduler</strong>：每个 Slave 上启动了一个本地调度器，用于接收本地 worker 提交任务的请求以及提交任务请求到全局调度器；</li>
<li><strong>Worker</strong>：每个 Slave 上可以启动多个 Worker 进程执行分布式任务，并将计算结果存储到 ObjectStore；</li>
<li><strong>Object Store</strong>：每个 Slave 上启动了一个 Object Store 存储只读数据对象，Worker 可以通过共享内存的方式访问这些对象数据，这样可以有效地减少内存拷贝和对象序列化成本（Object Store 底层由 Apache Arrow 实现）。</li>
</ul>
<h4 id="Centralized-Control-State"><a href="#Centralized-Control-State" class="headerlink" title="Centralized Control State"></a>Centralized Control State</h4><p>如前面图中所示，这套架构是依赖一个逻辑中心控制器，为了实现这套架构，设计时使用了一个 database 来做 Control State 的工作，存储系统的状态信息以及用于系统组件间的通信信息。</p>
<p>在这个设计中，除了 Control State，其他组件都是无状态的，所以只要 Control State 具有容错性，系统就可以简单恢复任务中失败的节点（因为 dataflow graph 是不固定，所以真正实现时 recover 的逻辑与 Spark 和 Flink 这类系统是不同的）(R6<br>)。为了实现高吞吐，在写数据库的时候，允许按 key hash 写入（R1-R2）。</p>
<h4 id="Hybrid-Scheduler"><a href="#Hybrid-Scheduler" class="headerlink" title="Hybrid Scheduler"></a>Hybrid Scheduler</h4><p>这套架构采用混度调度器的模式，简单来说，在 task 调度时，实现如下：</p>
<ol>
<li>worker 提交 task 到本地调度器，它会决定是 assign 到本地本机其他 worker 还是上报到 global 调度器，global 调度器会根据全局信息（资源利用率和计算本地化等因素）来决定把 task 分配到哪个节点上；</li>
<li>因为 task 是允许创建其他 task，所以一个集群里的 task 调度请求是可能来自任何的 worker 的；</li>
<li>系统允许本地调度器处理本地的调度工作，可以减少与全局调度器的交互，最大限度减少了通信开销。</li>
</ol>
<h3 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h3><p>ray 在真正实现时，提交给作业是一个更细粒度的 remote function，任务 DAG 依赖关系由函数依赖关系自由控制，像 Flink 和 Spark 系统，提交的是任务的 DAG，一旦提交就不能修改。</p>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>就像在前面文中说的一样，个人感觉这套架构与目前主流大数据计算引擎最大的区别还是 R3~R5，这样设计也是因为业务场景驱动，static dataflow graph 在一些 ML 和图计算的场景下无法很好的满足业务需求，每套计算引擎最开始要解决的问题都不太一样，都有一个自己的切入点，只不过做着做着大家发现自己的场景很有限，都想切入到更多的领域，做一个更加通用的引擎，通用引擎对于一些简单业务场景来说可能会显得特别重、对另一些复杂业务场景来说可能又显得不能完全支持，这也是计算引擎最近几年遍地开花的原因，而且相信未来还会有很大变化。而且现在有个趋势：对于业务来说，大家发现没有必要非要使用什么统一的引擎，引擎（包括存储和计算）是什么我可以完全不 care，面向用户的是统一的 DSL，用什么引擎由平台来帮业务选择，这个或许是一个趋势，但从另一个方面来说维护多套引擎的成本有点高，就像现在公司不会选择在服务器维护很多套操作系统一样，最终会是什么样子，过几年再看。</p>
<h2 id="业内实践"><a href="#业内实践" class="headerlink" title="业内实践"></a>业内实践</h2><p>关于 ray，目前国内看到的是蚂蚁金服有在使用，其他公司好像没有听说过，ray 目前已经在蚂蚁金服的很多业务上落地，这个大家可以参考今年阿里云栖大会上蚂蚁金服的分享（见：<a href="https://developer.aliyun.com/article/721329" target="_blank" rel="external">开放计算架构：蚂蚁金服是如何用一套架构容纳所有计算的？</a>），可以看到 ray 中落地比较好的场景还是 ML 和图计算相关的业务，关于图计算，国内估计也只有蚂蚁和腾讯有这么强烈的业务需求。刚好今天看到一篇文章 —— <a href="https://mp.weixin.qq.com/s/bSpm72WIx061cFMFgkaMlw" target="_blank" rel="external">腾讯开源全栈机器学习平台 Angel 3.0，支持三大类型图计算算法</a>，腾讯这边在图计算这块选择了他们开源的 Angel 平台做图计算，他们有兴趣地的可以深入看下。</p>
<p>最后，说点题外话，笔者本来计划今年每个月都要输出一篇经典论文的阅读笔记的，但不料的是，今年工作实在是太忙太累，很多计划并没有落地执行，后面会多花点工作之外的时间把今年欠的博客补一下，最近也会开始写 Apache Flink1.9 源码分析系列以及 Paper 阅读总结系列，文章会在公众号同步发布，大家多多关注。</p>
<p><img src="/images/wangm92-2.jpg" alt="个人公众号，欢迎关注"></p>
<hr>
<p>参考：</p>
<ul>
<li><a href="https://arxiv.org/pdf/1703.03924.pdf" target="_blank" rel="external">Real-Time Machine Learning: The Missing Pieces</a>;</li>
<li><a href="https://www.usenix.org/system/files/osdi18-moritz.pdf" target="_blank" rel="external">Ray: A Distributed Framework for Emerging AI Applications</a>；</li>
<li><a href="https://developer.aliyun.com/article/721329" target="_blank" rel="external">开放计算架构：蚂蚁金服是如何用一套架构容纳所有计算的？</a>；</li>
<li><a href="https://mp.weixin.qq.com/s/bSpm72WIx061cFMFgkaMlw" target="_blank" rel="external">腾讯开源全栈机器学习平台 Angel 3.0，支持三大类型图计算算法</a>；</li>
<li><a href="https://www.cnblogs.com/fanzhidongyzby/p/7901139.html" target="_blank" rel="external">高性能分布式执行框架——Ray</a>；</li>
</ul>
</div><script type="text/javascript" src="/js/share.js?v=0.0.0" async></script><a data-url="http://matt33.com/2019/10/19/paper-ray1/" data-id="ck1z3ydfq0057qpjhohrpl450" class="article-share-link">分享到</a><div class="copyright"><a href="http://matt33.com/copyright/">博客版权说明</a></div><div class="tags"><a href="/tags/paper/">paper</a></div><div class="post-nav"><a href="/2019/10/20/paper-flink-snapshot/" class="pre">Paper 阅读: Lightweight Asynchronous Snapshots for Distributed Dataflow</a><a href="/2019/03/17/apache-calcite-planner/" class="next">Apache Calcite 优化器详解（二）</a></div><div id="disqus_thread"><div class="btn_click_load"><button class="disqus_click_btn">阅读评论 「请确保 disqus.com 可以正常加载」</button></div><script>var disqus_shortname = 'http-matt33-com';
var disqus_identifier = '2019/10/19/paper-ray1/';
var disqus_title = 'Paper 阅读: Real-Time Machine Learning: The Missing Pieces';
var disqus_url = 'http://matt33.com/2019/10/19/paper-ray1/';
$('.btn_click_load').click(function() {
  (function() {
    var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
    dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
  })();
  $('.btn_click_load').css('display','none');
});
$.ajax({
  url: 'https://disqus.com/favicon.ico',
  timeout: 3000,
  type: 'GET',
  success: (function() {
    var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
    dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    $('.btn_click_load').css('display','none');
  })(),
  error: function() {
    $('.btn_click_load').css('display','block');
  }
});</script><script id="dsq-count-scr" src="//http-matt33-com.disqus.com/count.js" async></script></div></div></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><div class="widget-title"><i class="fa fa-weibo"> 微博</i></div><iframe width="100%" height="90" class="share_self"  frameborder="0" scrolling="no" src="http://widget.weibo.com/weiboshow/index.php?language=&width=0&height=100&fansRow=1&ptype=1&speed=0&skin=1&isTitle=0&noborder=1&isWeibo=0&isFans=0&uid=2650396571&verifier=f2f0e397&colors=D8D8D8,ffffff,666666,0082cb,ecfbfd&dpc=1"></iframe></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> 分类</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/书屋/">书屋</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/影如人生/">影如人生</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/技术/">技术</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/旅行/">旅行</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/转载/">转载</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/随笔/">随笔</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> 标签</i></div><div class="tagcloud"><a href="/tags/hadoop/" style="font-size: 15px;">hadoop</a> <a href="/tags/思考/" style="font-size: 15px;">思考</a> <a href="/tags/storm/" style="font-size: 15px;">storm</a> <a href="/tags/java/" style="font-size: 15px;">java</a> <a href="/tags/kafka/" style="font-size: 15px;">kafka</a> <a href="/tags/linux/" style="font-size: 15px;">linux</a> <a href="/tags/learn/" style="font-size: 15px;">learn</a> <a href="/tags/hexo/" style="font-size: 15px;">hexo</a> <a href="/tags/bug/" style="font-size: 15px;">bug</a> <a href="/tags/cv/" style="font-size: 15px;">cv</a> <a href="/tags/paper/" style="font-size: 15px;">paper</a> <a href="/tags/maven/" style="font-size: 15px;">maven</a> <a href="/tags/travel/" style="font-size: 15px;">travel</a> <a href="/tags/database/" style="font-size: 15px;">database</a> <a href="/tags/mac/" style="font-size: 15px;">mac</a> <a href="/tags/tcp/" style="font-size: 15px;">tcp</a> <a href="/tags/电影随想/" style="font-size: 15px;">电影随想</a> <a href="/tags/随笔/" style="font-size: 15px;">随笔</a> <a href="/tags/转载/" style="font-size: 15px;">转载</a> <a href="/tags/algorithm/" style="font-size: 15px;">algorithm</a> <a href="/tags/jvm/" style="font-size: 15px;">jvm</a> <a href="/tags/web/" style="font-size: 15px;">web</a> <a href="/tags/分布式系统/" style="font-size: 15px;">分布式系统</a> <a href="/tags/bk/" style="font-size: 15px;">bk</a> <a href="/tags/rpc/" style="font-size: 15px;">rpc</a> <a href="/tags/thrift/" style="font-size: 15px;">thrift</a> <a href="/tags/zookeeper/" style="font-size: 15px;">zookeeper</a> <a href="/tags/calcite/" style="font-size: 15px;">calcite</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> 最新文章</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2019/10/20/paper-flink-snapshot/">Paper 阅读: Lightweight Asynchronous Snapshots for Distributed Dataflow</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/10/19/paper-ray1/">Paper 阅读: Real-Time Machine Learning: The Missing Pieces</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/03/17/apache-calcite-planner/">Apache Calcite 优化器详解（二）</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/03/07/apache-calcite-process-flow/">Apache Calcite 处理流程详解（一）</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/01/28/bk-store-realize/">BookKeeper 原理浅谈</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/11/21/effective-learning/">如何高效学习</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/11/04/kafka-transaction/">Kafka Exactly-Once 之事务性实现</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/10/24/kafka-idempotent/">Kafka 事务性之幂等性实现</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/10/19/bk-cluster-install-and-use/">BookKeeper 集群搭建及使用</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/09/01/yarn-architecture-learn/">YARN 架构学习总结</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-external-link"> 友情链接</i></div><ul></ul><a href="http://matt33.com/about/" title="个人公众号：柳年思水" target="_blank">个人公众号：柳年思水</a><ul></ul><a href="http://tech.meituan.com/" title="美团点评技术团队" target="_blank">美团点评技术团队</a><ul></ul><a href="http://jm.taobao.org/" title="阿里中间件团队博客" target="_blank">阿里中间件团队博客</a><ul></ul><a href="http://www.jianshu.com/" title="简书" target="_blank">简书</a></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">© <a href="/." rel="nofollow">Matt's Blog 柳年思水.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a id="rocket" href="#top" class="show"></a><script type="text/javascript" src="/js/totop.js?v=0.0.0" async></script><div class="analytics"><script>var cnzz_protocol = (("https:" == document.location.protocol) ? " https://" : " http://");
document.write(unescape("%3Cspan id='cnzz_stat_icon_1256517224'%3E%3C/span%3E%3Cscript src='" + cnzz_protocol + "s95.cnzz.com/z_stat.php%3Fid%3D1256517224%26show%3Dpic' type='text/javascript'%3E%3C/script%3E"));</script></div><script type="text/javascript" src="//cdn.bootcss.com/fancybox/2.1.5/jquery.fancybox.pack.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=0.0.0" async></script><link rel="stylesheet" type="text/css" href="/css/jquery.fancybox.css?v=0.0.0"><script>(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
ga('create','UA-64518924-1','auto');ga('send','pageview');
</script><script>var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "//hm.baidu.com/hm.js?5cf44757fa0d23bc7637935e44a9104a";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
  })();
</script><script type="text/x-mathjax-config">MathJax.Hub.Config({
  tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
  });
</script><script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML" async></script><script type="text/javascript" src="/js/codeblock-resizer.js?v=0.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=0.0.0"></script></div></body></html>