<!DOCTYPE html><html lang="zh-CN"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description" content="与一群有趣的人，做一些有趣的事."><title>Flink Streaming 作业如何转化为 JobGraph | Matt's Blog</title><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/normalize/4.2.0/normalize.min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/0.6.0/pure-min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/0.6.0/grids-responsive-min.css"><link rel="stylesheet" type="text/css" href="/css/style.css?v=0.0.0"><link rel="stylesheet" href="//cdn.bootcss.com/font-awesome/4.6.3/css/font-awesome.min.css"><script type="text/javascript" src="//cdn.bootcss.com/jquery/3.0.0/jquery.min.js"></script><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"><link rel="alternate" type="application/atom+xml" href="/atom.xml"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">Flink Streaming 作业如何转化为 JobGraph</h1><a id="logo" href="/.">Matt's Blog</a><p class="description">王蒙</p></div><div id="nav-menu"><a href="/." class="current"><i class="fa fa-home"> 首页</i></a><a href="/archives/"><i class="fa fa-archive"> 归档</i></a><a href="/about/"><i class="fa fa-user"> 关于</i></a><a href="/atom.xml"><i class="fa fa-rss"> 订阅</i></a></div></div><div id="layout" class="pure-g"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">Flink Streaming 作业如何转化为 JobGraph</h1><div class="post-meta">Dec 9, 2019<span> | </span><span class="category"><a href="/categories/技术/">技术</a></span><span> | </span><span class="post-count">5,083</span><span> 字</span><script src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" async></script><span id="busuanzi_container_page_pv"> | <span id="busuanzi_value_page_pv"></span><span> Times</span></span></div><a data-disqus-identifier="2019/12/09/flink-job-graph-3/" href="/2019/12/09/flink-job-graph-3/#disqus_thread" class="disqus-comment-count"></a><div class="clear"><div id="toc" class="toc-article"><div class="toc-title">文章目录</div><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#生成-JobGraph-的整体流程"><span class="toc-number">1.</span> <span class="toc-text">生成 JobGraph 的整体流程</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#具体实现流程"><span class="toc-number">2.</span> <span class="toc-text">具体实现流程</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#基本概念"><span class="toc-number">2.1.</span> <span class="toc-text">基本概念</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#算子是如何-Chain-到一起的"><span class="toc-number">2.2.</span> <span class="toc-text">算子是如何 Chain 到一起的</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#如何判断算子是否可以-Chain-在一起"><span class="toc-number">2.2.1.</span> <span class="toc-text">如何判断算子是否可以 Chain 在一起</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#slotSharingGroup"><span class="toc-number">2.2.1.1.</span> <span class="toc-text">slotSharingGroup</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#Partitioner"><span class="toc-number">2.2.1.2.</span> <span class="toc-text">Partitioner</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#创建-JobVertex-节点"><span class="toc-number">2.2.2.</span> <span class="toc-text">创建 JobVertex 节点</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#connect-创建-JobEdge-和-IntermediateDataSet-对象"><span class="toc-number">2.2.3.</span> <span class="toc-text">connect() 创建 JobEdge 和 IntermediateDataSet 对象</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#JobGraph-的其他配置"><span class="toc-number">2.3.</span> <span class="toc-text">JobGraph 的其他配置</span></a></li></ol></li></ol></div></div><div class="post-content"><p>本篇文章是 <strong>Flink 系列</strong> 的第三篇，紧接着上一篇文章，本文主要讲述 StreamGraph 是如何转换成 JobGraph 的，在前面的文章中，我们知道 StreamGraph 是根据用户作业的处理逻生成初始的逻辑计划，它并没有做任何的优化，而 JobGraph 将会在原来的基础上做相应的优化（主要是算子的 Chain 操作，Chain 在一起的算子将会在同一个 task 上运行，会极大减少 shuffle 的开销）。刚开始接触的同学可能会有一个疑问，为什么要有 StreamGraph 和 JobGraph 两层的 Graph，这里最主要的原因是为兼容 batch process，Streaming process 最初产生的是 StreamGraph，而 batch process 产生的则是 OptimizedPlan，但是它们最后都会转换为 JobGraph，本文主要是以 Streaming 作业的 StreamGraph 转换为 JobGraph 的处理流程来介绍。</p>
<h2 id="生成-JobGraph-的整体流程"><a href="#生成-JobGraph-的整体流程" class="headerlink" title="生成 JobGraph 的整体流程"></a>生成 JobGraph 的整体流程</h2><p>这里我们先看下 FlinkPlan 的实现，它主要有两个实现类：StreamGraph 和 OptimizedPlan，分别对应 Streaming 和 Batch process，不管是哪种类型最后可以转换为 JobGraph：</p>
<p><img src="/images/flink/3-FlinkPlan.png" alt="FlinkPlan 的实现"></p>
<p>OptimizedPlan 可以通过 JobGraphGenerator 的 <code>compileJobGraph()</code> 方法来转换为 JobGraph，而 StreamGraph 则可以通过 StreamingJobGraphGenerator 的 <code>createJobGraph()</code> 方法来转换为相应的 JobGraph。其中，StreamGraph 的整体转换流程如下图所示（下图主要展示了这个流程涉及到主要方法调用，比较核心的方法图中也加了颜色，也是本文会着重讲述的方法）：</p>
<p><img src="/images/flink/3-create-job-graph.png" alt="生成 JobGraph 的流程"></p>
<h2 id="具体实现流程"><a href="#具体实现流程" class="headerlink" title="具体实现流程"></a>具体实现流程</h2><p>StreamingJobGraphGenerator 的 <code>createJobGraph()</code> 的方法实现如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//note: 根据 StreamGraph 生成 JobGraph</span></span><br><span class="line"><span class="function"><span class="keyword">private</span> JobGraph <span class="title">createJobGraph</span><span class="params">()</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// make sure that all vertices start immediately</span></span><br><span class="line">    <span class="comment">//note: 设置调度模式</span></span><br><span class="line">    jobGraph.setScheduleMode(streamGraph.getScheduleMode());</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Generate deterministic hashes for the nodes in order to identify them across</span></span><br><span class="line">    <span class="comment">// submission iff they didn't change.</span></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * note: 为每个 SteamNode 生成一个确定的 hash id，如果提交的拓扑没有改变，则每次生成的 hash id 都是一样的</span></span><br><span class="line"><span class="comment">     * note: 这里只要保证 source 的顺序是确定的，就可以保证最后生产的 hash id 不变</span></span><br><span class="line"><span class="comment">     * note: 它是利用 input 节点的 hash 值及该节点在 map 中位置（实际上是 map.size 算的）来计算确定的</span></span><br><span class="line"><span class="comment">     * note: 实现逻辑见 &#123;<span class="doctag">@link</span> StreamGraphHasherV2#traverseStreamGraphAndGenerateHashes(StreamGraph)&#125;</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    Map&lt;Integer, <span class="keyword">byte</span>[]&gt; hashes = defaultStreamGraphHasher.traverseStreamGraphAndGenerateHashes(streamGraph);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Generate legacy version hashes for backwards compatibility</span></span><br><span class="line">    <span class="comment">//note: 这个设置主要是为了防止 hash 机制变化时出现不兼容的情况</span></span><br><span class="line">    List&lt;Map&lt;Integer, <span class="keyword">byte</span>[]&gt;&gt; legacyHashes = <span class="keyword">new</span> ArrayList&lt;&gt;(legacyStreamGraphHashers.size());</span><br><span class="line">    <span class="keyword">for</span> (StreamGraphHasher hasher : legacyStreamGraphHashers) &#123;</span><br><span class="line">        legacyHashes.add(hasher.traverseStreamGraphAndGenerateHashes(streamGraph));</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    Map&lt;Integer, List&lt;Tuple2&lt;<span class="keyword">byte</span>[], <span class="keyword">byte</span>[]&gt;&gt;&gt; chainedOperatorHashes = <span class="keyword">new</span> HashMap&lt;&gt;();</span><br><span class="line"></span><br><span class="line">    <span class="comment">//note: 最重要的函数，生成 JobVertex/JobEdge 等，并尽可能地将多个节点 chain 在一起</span></span><br><span class="line">    setChaining(hashes, legacyHashes, chainedOperatorHashes);</span><br><span class="line"></span><br><span class="line">    <span class="comment">//note: 将每个 JobVertex 的入边集合也序列化到该 JobVertex 的 StreamConfig 中 (出边集合已经在 setChaining 的时候写入了)</span></span><br><span class="line">    setPhysicalEdges();</span><br><span class="line"></span><br><span class="line">    <span class="comment">//note: 为每个 JobVertex 指定所属的 SlotSharingGroup 以及设置 CoLocationGroup</span></span><br><span class="line">    setSlotSharingAndCoLocation();</span><br><span class="line"></span><br><span class="line">    <span class="comment">//note: checkpoint相关的配置</span></span><br><span class="line">    configureCheckpointing();</span><br><span class="line"></span><br><span class="line">    <span class="comment">//note: 用户的第三方依赖包就是在这里（cacheFile）传给 JobGraph</span></span><br><span class="line">    JobGraphGenerator.addUserArtifactEntries(streamGraph.getUserArtifacts(), jobGraph);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// set the ExecutionConfig last when it has been finalized</span></span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="comment">//note: 将 StreamGraph 的 ExecutionConfig 序列化到 JobGraph 的配置中</span></span><br><span class="line">        jobGraph.setExecutionConfig(streamGraph.getExecutionConfig());</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> IllegalConfigurationException(<span class="string">"Could not serialize the ExecutionConfig."</span> +</span><br><span class="line">                <span class="string">"This indicates that non-serializable types (like custom serializers) were registered"</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> jobGraph;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>核心步骤如下：</p>
<ol>
<li>先给每个 StreamNode 生成一个唯一确定的 hash id；</li>
<li><code>setChaining()</code> 方法将可以 Chain 到一起的 StreamNode Chain 在一起，这里会生成相应的 JobVertex 、JobEdge 、 IntermediateDataSet 对象，JobGraph 的 Graph 在这一步就已经完全构建出来了；</li>
<li><code>setPhysicalEdges()</code> 方法会将每个 JobVertex 的入边集合也序列化到该 JobVertex 的 StreamConfig 中 (出边集合已经在 setChaining 的时候写入了)；</li>
<li><code>setSlotSharingAndCoLocation()</code> 方法主要是 JobVertex 的 SlotSharingGroup 和 CoLocationGroup 设置；</li>
<li><code>configureCheckpointing()</code> 方法主要是 checkpoint 相关的设置。</li>
</ol>
<h3 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h3><p>JobGraph 又引入了几个概念，这里先简单介绍一下。</p>
<ol>
<li><strong>StreamConfig</strong>: 它会记录一个 StreamOperator 的配置信息，它保存了这个 StreamOperator 的基本信息，在这里它会将 StreamGraph 中的 StreamNode 的详细信息同步到它对应的 StreamConfig 对象中；</li>
<li><strong>JobVertex</strong>: JobVertex 相当于是 JobGraph 的顶点，跟 StreamNode 的区别是，它是 Operator Chain 之后的顶点，会包含多个 StreamNode；</li>
<li><strong>IntermediateDataSet</strong>: 它是由一个 Operator（可能是 source，也可能是某个中间算子）产生的一个中间数据集；</li>
<li><strong>JobEdge</strong>: 它相当于是 JobGraph 中的边（连接通道），这个边连接的是一个 IntermediateDataSet 跟一个要消费的 JobVertex。</li>
</ol>
<p>如果跟前面的 StreamGraph 做对比，JobGraph 这里不但会对算子做 Chain 操作，还多抽象了一个概念 —— IntermediateDataSet，IntermediateDataSet 的抽象主要是为了后面 ExecutionGraph 的生成。</p>
<h3 id="算子是如何-Chain-到一起的"><a href="#算子是如何-Chain-到一起的" class="headerlink" title="算子是如何 Chain 到一起的"></a>算子是如何 Chain 到一起的</h3><p>这里，我们来介绍一下生成的 JobGraph 过程中最核心一步，算子如何 Chain 到一起，先看一下示例，示例与前面两篇文章的示例是一样的（这里因为图片大小限制，去掉了 filter 算子），StreamGraph 及转换后的 JobGraph 如何下图所示：</p>
<p><img src="/images/flink/3-operator-chain.png" alt="Operator Chain 的示例"></p>
<p>StreamGraph 转换为 JobGraph 的处理过程主要是在 <code>setChaining()</code> 中完成，先看下这个方法的实现：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//org.apache.flink.streaming.api.graph.StreamingJobGraphGenerator</span></span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Sets up task chains from the source &#123;<span class="doctag">@link</span> StreamNode&#125; instances.</span></span><br><span class="line"><span class="comment"> * note：从 Source StreamNode 实例开始设置 task chain，它将会递归地创建所有的 JobVertex 实例</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * &lt;p&gt;This will recursively create all &#123;<span class="doctag">@link</span> JobVertex&#125; instances.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">setChaining</span><span class="params">(Map&lt;Integer, <span class="keyword">byte</span>[]&gt; hashes, List&lt;Map&lt;Integer, <span class="keyword">byte</span>[]&gt;&gt; legacyHashes, Map&lt;Integer, List&lt;Tuple2&lt;<span class="keyword">byte</span>[], <span class="keyword">byte</span>[]&gt;&gt;&gt; chainedOperatorHashes)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">for</span> (Integer sourceNodeId : streamGraph.getSourceIDs()) &#123;</span><br><span class="line">        <span class="comment">//note: 处理每个 Source StreamNode</span></span><br><span class="line">        createChain(sourceNodeId, sourceNodeId, hashes, legacyHashes, <span class="number">0</span>, chainedOperatorHashes);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">private</span> List&lt;StreamEdge&gt; <span class="title">createChain</span><span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">        Integer startNodeId,</span></span></span><br><span class="line"><span class="function"><span class="params">        Integer currentNodeId,</span></span></span><br><span class="line"><span class="function"><span class="params">        Map&lt;Integer, <span class="keyword">byte</span>[]&gt; hashes,</span></span></span><br><span class="line"><span class="function"><span class="params">        List&lt;Map&lt;Integer, <span class="keyword">byte</span>[]&gt;&gt; legacyHashes,</span></span></span><br><span class="line"><span class="function"><span class="params">        <span class="keyword">int</span> chainIndex,</span></span></span><br><span class="line"><span class="function"><span class="params">        Map&lt;Integer, List&lt;Tuple2&lt;<span class="keyword">byte</span>[], <span class="keyword">byte</span>[]&gt;&gt;&gt; chainedOperatorHashes)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (!builtVertices.contains(startNodeId)) &#123;</span><br><span class="line"></span><br><span class="line">        List&lt;StreamEdge&gt; transitiveOutEdges = <span class="keyword">new</span> ArrayList&lt;StreamEdge&gt;();</span><br><span class="line"></span><br><span class="line">        <span class="comment">//note: 以 Edge 的粒度，记录上下游算子能 chain 在一起的 Edge</span></span><br><span class="line">        List&lt;StreamEdge&gt; chainableOutputs = <span class="keyword">new</span> ArrayList&lt;StreamEdge&gt;();</span><br><span class="line">        List&lt;StreamEdge&gt; nonChainableOutputs = <span class="keyword">new</span> ArrayList&lt;StreamEdge&gt;();</span><br><span class="line"></span><br><span class="line">        <span class="comment">//note: 当前要处理的 StreamNode</span></span><br><span class="line">        StreamNode currentNode = streamGraph.getStreamNode(currentNodeId);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//note: 遍历当前的输出节点，判断是否可以 chain 在一起</span></span><br><span class="line">        <span class="keyword">for</span> (StreamEdge outEdge : currentNode.getOutEdges()) &#123;</span><br><span class="line">            <span class="keyword">if</span> (isChainable(outEdge, streamGraph)) &#123; <span class="comment">//note: 如果可以 chain 在一起的话</span></span><br><span class="line">                chainableOutputs.add(outEdge);</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                nonChainableOutputs.add(outEdge);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">//note: 递归调用</span></span><br><span class="line">        <span class="keyword">for</span> (StreamEdge chainable : chainableOutputs) &#123;</span><br><span class="line">            <span class="comment">//note: 如果可以 chain 在一起的话，这里的 chainIndex 会加 1</span></span><br><span class="line">            transitiveOutEdges.addAll(</span><br><span class="line">                    createChain(startNodeId, chainable.getTargetId(), hashes, legacyHashes, chainIndex + <span class="number">1</span>, chainedOperatorHashes));</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> (StreamEdge nonChainable : nonChainableOutputs) &#123;</span><br><span class="line">            transitiveOutEdges.add(nonChainable);</span><br><span class="line">            <span class="comment">//note: 不能 chain 一起的话，这里的 chainIndex 是从 0 开始算的，后面也肯定会走到 createJobVertex 的逻辑</span></span><br><span class="line">            createChain(nonChainable.getTargetId(), nonChainable.getTargetId(), hashes, legacyHashes, <span class="number">0</span>, chainedOperatorHashes);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">//note: 记录每个 startNodeId 的 hash id（主要是 legacyHashes 中记录的）</span></span><br><span class="line">        List&lt;Tuple2&lt;<span class="keyword">byte</span>[], <span class="keyword">byte</span>[]&gt;&gt; operatorHashes =</span><br><span class="line">            chainedOperatorHashes.computeIfAbsent(startNodeId, k -&gt; <span class="keyword">new</span> ArrayList&lt;&gt;());</span><br><span class="line"></span><br><span class="line">        <span class="keyword">byte</span>[] primaryHashBytes = hashes.get(currentNodeId);</span><br><span class="line">        <span class="comment">//note: OperatorID</span></span><br><span class="line">        OperatorID currentOperatorId = <span class="keyword">new</span> OperatorID(primaryHashBytes);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> (Map&lt;Integer, <span class="keyword">byte</span>[]&gt; legacyHash : legacyHashes) &#123;</span><br><span class="line">            operatorHashes.add(<span class="keyword">new</span> Tuple2&lt;&gt;(primaryHashBytes, legacyHash.get(currentNodeId)));</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">//note: 记录 chainedName</span></span><br><span class="line">        chainedNames.put(currentNodeId, createChainedName(currentNodeId, chainableOutputs));</span><br><span class="line">        <span class="comment">//note: 计算 Chain 之后 node 的 minResources</span></span><br><span class="line">        chainedMinResources.put(currentNodeId, createChainedMinResources(currentNodeId, chainableOutputs));</span><br><span class="line">        <span class="comment">//note: 计算 Chain 之后 node 的资源上限</span></span><br><span class="line">        chainedPreferredResources.put(currentNodeId, createChainedPreferredResources(currentNodeId, chainableOutputs));</span><br><span class="line"></span><br><span class="line">        <span class="comment">//note: InputFormat &amp; OutputFormat 的处理</span></span><br><span class="line">        <span class="keyword">if</span> (currentNode.getInputFormat() != <span class="keyword">null</span>) &#123;</span><br><span class="line">            getOrCreateFormatContainer(startNodeId).addInputFormat(currentOperatorId, currentNode.getInputFormat());</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (currentNode.getOutputFormat() != <span class="keyword">null</span>) &#123;</span><br><span class="line">            getOrCreateFormatContainer(startNodeId).addOutputFormat(currentOperatorId, currentNode.getOutputFormat());</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">//note: 如果当前节点是 chain 的起始节点, 则直接创建 JobVertex 并返回 StreamConfig, 否则先创建一个空的 StreamConfig</span></span><br><span class="line">        <span class="comment">//note: 这里实际上，如果节点不能 chain 在一起，那么 currentNodeId 跟 startNodeId 肯定是不相等的</span></span><br><span class="line">        <span class="comment">//note: createJobVertex 函数就是根据 StreamNode 创建对应的 JobVertex, 并返回了空的 StreamConfig</span></span><br><span class="line">        StreamConfig config = currentNodeId.equals(startNodeId)</span><br><span class="line">                ? createJobVertex(startNodeId, hashes, legacyHashes, chainedOperatorHashes)<span class="comment">//note: chain 的起始 StreamNode</span></span><br><span class="line">                : <span class="keyword">new</span> StreamConfig(<span class="keyword">new</span> Configuration());</span><br><span class="line"></span><br><span class="line">        <span class="comment">//note: 设置 JobVertex 的 StreamConfig, 基本上是将 StreamNode 中的配置设置到 StreamConfig 中</span></span><br><span class="line">        setVertexConfig(currentNodeId, config, chainableOutputs, nonChainableOutputs);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (currentNodeId.equals(startNodeId)) &#123; <span class="comment">//note: 如果走到这里，证明这个 chain 已经完成</span></span><br><span class="line">            <span class="comment">//note: chain 中起始 StreamNode</span></span><br><span class="line">            config.setChainStart();</span><br><span class="line">            config.setChainIndex(<span class="number">0</span>);</span><br><span class="line">            config.setOperatorName(streamGraph.getStreamNode(currentNodeId).getOperatorName());</span><br><span class="line">            <span class="comment">//note: Config 中也会记录这个 chain 的出边</span></span><br><span class="line">            config.setOutEdgesInOrder(transitiveOutEdges);</span><br><span class="line">            config.setOutEdges(streamGraph.getStreamNode(currentNodeId).getOutEdges());</span><br><span class="line"></span><br><span class="line">            <span class="keyword">for</span> (StreamEdge edge : transitiveOutEdges) &#123;</span><br><span class="line">                <span class="comment">//note: 构建 graph</span></span><br><span class="line">                connect(startNodeId, edge);</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            <span class="comment">//note: 将 chain 中所有子节点的 StreamConfig 写入到 headOfChain 节点的 CHAINED_TASK_CONFIG 配置中</span></span><br><span class="line">            config.setTransitiveChainedTaskConfigs(chainedConfigs.get(startNodeId));</span><br><span class="line"></span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="comment">//note: 如果是 chain 中子节点</span></span><br><span class="line">            chainedConfigs.computeIfAbsent(startNodeId, k -&gt; <span class="keyword">new</span> HashMap&lt;Integer, StreamConfig&gt;());</span><br><span class="line"></span><br><span class="line">            config.setChainIndex(chainIndex);</span><br><span class="line">            StreamNode node = streamGraph.getStreamNode(currentNodeId);</span><br><span class="line">            config.setOperatorName(node.getOperatorName());</span><br><span class="line">            <span class="comment">//note: 将当前 StreamNode 的 config 记录到该 chain 的 config 集合中</span></span><br><span class="line">            chainedConfigs.get(startNodeId).put(currentNodeId, config);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        config.setOperatorID(currentOperatorId);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (chainableOutputs.isEmpty()) &#123;</span><br><span class="line">            config.setChainEnd();</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> transitiveOutEdges;</span><br><span class="line"></span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这段代码处理完成后，整个 JobGraph 就构建完成了，它首先从会遍历这个 StreamGraph 的 source 节点，然后选择从 source 节点开始执行 <code>createChain()</code> 方法，在具体的实现里，主要逻辑如下（需要配合前面的代码去看，这里会把多个 StreamNode Chain 在一起的 Node 叫做 ChainNode，方便讲述）：</p>
<ol>
<li><code>createChain()</code> 当前要处理的节点是 <code>currentNodeId</code>，先从 StreamGraph 中拿到这个 StreamNode 的 outEdge（<code>currentNode.getOutEdges()</code>），然后判断这个 outEdge 连接的两个 StreamNode 是否可以 Chain 在一起，判断方法是 <code>isChainable()</code>；</li>
<li>紧接着会有一个递归调用：<ul>
<li>对于可以 Chain 在一起的 StreamEdge（这个 Edge 连接两个 StreamNode 是可以 Chain 在一起），会再次调用 <code>createChain()</code> 方法，并且 <code>createChain()</code> 中的 <code>startNodeId</code> 还是最开始的 <code>startNodeId</code>（这个标识了这个 ChainNode 的开始 NodeId），而 <code>chainIndex</code> 会自增加 1；</li>
<li>而对于不能 Chain 在一起的 StreamEdge，<code>createChain()</code> 中的 <code>startNodeId</code>  变成了这个 StreamEdge 的 target StreamNode（相当于如果 Chain 在一起，ChainNode 中的 startNodeId 会赋值为下一个节点的 NodeId，然后再依次类推），<code>chainIndex</code> 又从 0 开始计；</li>
<li>也就是说：<code>createChain()</code> 中的 <code>startNodeId</code> 表示了当前可以 Chain 之后 Node 的 startId，这里，会一直递归调用，直到达到 Sink 节点。</li>
</ul>
</li>
<li>然后在生成 <code>StreamConfig</code> 对象时，判断当前的 <code>currentNodeId</code> 与 <code>startNodeId</code> 是否相等，如果相等的话，证明当前 Node 就是这个 ChainNode 的 StartNode，这里会调用 <code>createJobVertex()</code> 方法给这个 ChainNode 创建一个 JobVertex 对象，最后会返回一个 StreamConfig 对象，如果前面的 id 不相等的话，这里会直接返回一个 StreamConfig 对象（这个对象主要是记录当前 StreamNode 的一些配置，它会同步 StreamGraph 中相关的配置）；</li>
<li>最后还会分两种情况判断：<ul>
<li>如果 id 相等，相当于这个 ChainNode 已经完成，先做一些相关的配置（比如：标识当前 StreamNode 为这个 JobVertex 的起始 node），最后再通过 <code>connect()</code> 方法创建 JobEdge 和 IntermediateDataSet 对象，把这个 Graph 连接起来；</li>
<li>如果 id 不相等，那么证明当前 StreamNode 只是这个 ChainNode 的一部分，这里只是同步一下信息，并记录到缓存。</li>
</ul>
</li>
</ol>
<p>上面就是这个方法的主要实现逻辑，下面会详细把这个方法展开，重点介绍其中的一些方法实现。</p>
<h4 id="如何判断算子是否可以-Chain-在一起"><a href="#如何判断算子是否可以-Chain-在一起" class="headerlink" title="如何判断算子是否可以 Chain 在一起"></a>如何判断算子是否可以 Chain 在一起</h4><p>两个 StreamNode 是否可以 Chain 到一起，是通过 <code>isChainable()</code> 方法来判断的，这里判断的粒度是 StreamEdge，实际上就是判断 StreamEdge 连接的两个 StreamNode 是否 Chain 在一起：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//note: 是否可以 chain 在一起</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">boolean</span> <span class="title">isChainable</span><span class="params">(StreamEdge edge, StreamGraph streamGraph)</span> </span>&#123;</span><br><span class="line">    StreamNode upStreamVertex = streamGraph.getSourceVertex(edge); <span class="comment">//note: edge 的 source node</span></span><br><span class="line">    StreamNode downStreamVertex = streamGraph.getTargetVertex(edge); <span class="comment">//note: edge 的 sink node</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">//note: 获取输入和输出的 Operator Factory</span></span><br><span class="line">    StreamOperatorFactory&lt;?&gt; headOperator = upStreamVertex.getOperatorFactory();</span><br><span class="line">    StreamOperatorFactory&lt;?&gt; outOperator = downStreamVertex.getOperatorFactory();</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> downStreamVertex.getInEdges().size() == <span class="number">1</span> <span class="comment">//note: 下游 Operator 的 Edge 只有一个（如果是多个合并，是无法 Chain 在一起的）</span></span><br><span class="line">            &amp;&amp; outOperator != <span class="keyword">null</span></span><br><span class="line">            &amp;&amp; headOperator != <span class="keyword">null</span></span><br><span class="line">            &amp;&amp; upStreamVertex.isSameSlotSharingGroup(downStreamVertex) <span class="comment">//note: 对应的 slotSharingGroup 一样</span></span><br><span class="line">            &amp;&amp; outOperator.getChainingStrategy() == ChainingStrategy.ALWAYS <span class="comment">//note: out operator 允许 chain 操作</span></span><br><span class="line">            &amp;&amp; (headOperator.getChainingStrategy() == ChainingStrategy.HEAD || <span class="comment">//note: head Operator 允许跟后面的 chain 在一起</span></span><br><span class="line">                headOperator.getChainingStrategy() == ChainingStrategy.ALWAYS)</span><br><span class="line">            &amp;&amp; (edge.getPartitioner() <span class="keyword">instanceof</span> ForwardPartitioner) <span class="comment">//note: partitioner 是 ForwardPartitioner 类型</span></span><br><span class="line">            &amp;&amp; edge.getShuffleMode() != ShuffleMode.BATCH</span><br><span class="line">            &amp;&amp; upStreamVertex.getParallelism() == downStreamVertex.getParallelism() <span class="comment">//note: 并发相等</span></span><br><span class="line">            &amp;&amp; streamGraph.isChainingEnabled(); <span class="comment">//note: StreamGraph 允许 Chain 在一起</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这个方法判断的指标有很多，具体看上面代码就可以明白，这里着重介绍两个：<code>slotSharingGroup</code> 和 <code>edge.getPartitioner()</code>。</p>
<h5 id="slotSharingGroup"><a href="#slotSharingGroup" class="headerlink" title="slotSharingGroup"></a>slotSharingGroup</h5><p>先看下一个 StreamNode 的 <code>slotSharingGroup</code> 是如何生成的：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// org.apache.flink.streaming.api.graph.StreamGraphGenerator</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> String DEFAULT_SLOT_SHARING_GROUP = <span class="string">"default"</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Determines the slot sharing group for an operation based on the slot sharing group set by</span></span><br><span class="line"><span class="comment"> * the user and the slot sharing groups of the inputs.</span></span><br><span class="line"><span class="comment"> * note: 根据这个 operation 设置的 slot sharing group 和 inputs 的 slot sharing group 来确定其 slot sharing group</span></span><br><span class="line"><span class="comment"> * note：1. 如果用户指定了 group name，直接使用这个 name；</span></span><br><span class="line"><span class="comment"> * note：2. 如果所有的 input 都是同一个 group name，使用这个即可；</span></span><br><span class="line"><span class="comment"> * note：3. 否则使用 default group；</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * &lt;p&gt;If the user specifies a group name, this is taken as is. If nothing is specified and</span></span><br><span class="line"><span class="comment"> * the input operations all have the same group name then this name is taken. Otherwise the</span></span><br><span class="line"><span class="comment"> * default group is chosen.</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> specifiedGroup The group specified by the user. note: 用户指定的 group name</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> inputIds The IDs of the input operations. note: 输入 operation 的 id 集合</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">private</span> String <span class="title">determineSlotSharingGroup</span><span class="params">(String specifiedGroup, Collection&lt;Integer&gt; inputIds)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (!isSlotSharingEnabled) &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (specifiedGroup != <span class="keyword">null</span>) &#123;</span><br><span class="line">        <span class="keyword">return</span> specifiedGroup;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        String inputGroup = <span class="keyword">null</span>;</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> id: inputIds) &#123;</span><br><span class="line">            String inputGroupCandidate = streamGraph.getSlotSharingGroup(id);</span><br><span class="line">            <span class="keyword">if</span> (inputGroup == <span class="keyword">null</span>) &#123;</span><br><span class="line">                inputGroup = inputGroupCandidate;</span><br><span class="line">            &#125; <span class="keyword">else</span> <span class="keyword">if</span> (!inputGroup.equals(inputGroupCandidate)) &#123;</span><br><span class="line">                <span class="keyword">return</span> DEFAULT_SLOT_SHARING_GROUP;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> inputGroup == <span class="keyword">null</span> ? DEFAULT_SLOT_SHARING_GROUP : inputGroup;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>一个 StreamNode 的 SlotSharingGroup 会按照下面这个逻辑来确定:</p>
<ol>
<li>如果用户指定了 SlotSharingGroup，直接使用这个 SlotSharingGroup name；</li>
<li>如果所有的 input 都是同一个 group name，使用这个即可；</li>
<li>否则使用 default group；</li>
</ol>
<h5 id="Partitioner"><a href="#Partitioner" class="headerlink" title="Partitioner"></a>Partitioner</h5><p>这个 StreamEdge 的属性，在创建 StreamEdge 对象会配置这个属性，先看 Flink 中提供的 Partitioner 有哪几种：</p>
<p><img src="/images/flink/3-StreamPartitioner.png" alt="StreamPartitioner 的实现"></p>
<p>用户可以在自己的代码中调用 DataStream API （比如：<code>broadcast()</code>、<code>shuffle()</code> 等）配置相应的 StreamPartitioner，如果这个没有指定 StreamPartitioner 的话，则会走下面的逻辑创建默认的 StreamPartitioner：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//org.apache.flink.streaming.api.graph.StreamGraph</span></span><br><span class="line"><span class="comment">//note: 未指定 partitioner 的话，会为其选择 forward（并发设置相同时） 或 rebalance（并发设置不同时）</span></span><br><span class="line"><span class="keyword">if</span> (partitioner == <span class="keyword">null</span> &amp;&amp; upstreamNode.getParallelism() == downstreamNode.getParallelism()) &#123;</span><br><span class="line">    partitioner = <span class="keyword">new</span> ForwardPartitioner&lt;Object&gt;();</span><br><span class="line">&#125; <span class="keyword">else</span> <span class="keyword">if</span> (partitioner == <span class="keyword">null</span>) &#123;</span><br><span class="line">    partitioner = <span class="keyword">new</span> RebalancePartitioner&lt;Object&gt;();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="创建-JobVertex-节点"><a href="#创建-JobVertex-节点" class="headerlink" title="创建 JobVertex 节点"></a>创建 JobVertex 节点</h4><p>JobVertex 对象的创建是在 <code>createJobVertex()</code> 方法中实现的，这个方法实现比较简单，创建相应的 JobVertex 对象，并把相关的配置信息设置到 JobVertex 对象中就完成了，这里就不再展开详细介绍了。</p>
<h4 id="connect-创建-JobEdge-和-IntermediateDataSet-对象"><a href="#connect-创建-JobEdge-和-IntermediateDataSet-对象" class="headerlink" title="connect() 创建 JobEdge 和 IntermediateDataSet 对象"></a><code>connect()</code> 创建 JobEdge 和 IntermediateDataSet 对象</h4><p><code>connect()</code> 方法在执行的时候，它会遍历 <code>transitiveOutEdges</code> 中的 StreamEdge，也就是这个 ChainNode 的 out StreamEdge（这些 StreamEdge 是不能与前面的 ChainNode Chain 在一起）</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// org.apache.flink.streaming.api.graph.StreamGraphGenerator</span></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">connect</span><span class="params">(Integer headOfChain, StreamEdge edge)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//note: 记录 StreamEdge，这个主要是 chain 之间的边</span></span><br><span class="line">    physicalEdgesInOrder.add(edge);</span><br><span class="line"></span><br><span class="line">    Integer downStreamvertexID = edge.getTargetId();</span><br><span class="line"></span><br><span class="line">    <span class="comment">//note: 这里 headVertex 指的是 headOfChain 对应的 JobVertex（也是当前 node 对应的 vertex）</span></span><br><span class="line">    JobVertex headVertex = jobVertices.get(headOfChain);</span><br><span class="line">    JobVertex downStreamVertex = jobVertices.get(downStreamvertexID);</span><br><span class="line"></span><br><span class="line">    StreamConfig downStreamConfig = <span class="keyword">new</span> StreamConfig(downStreamVertex.getConfiguration());</span><br><span class="line"></span><br><span class="line">    <span class="comment">//note: 这个节点的输入数增加 1</span></span><br><span class="line">    downStreamConfig.setNumberOfInputs(downStreamConfig.getNumberOfInputs() + <span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">    StreamPartitioner&lt;?&gt; partitioner = edge.getPartitioner();</span><br><span class="line"></span><br><span class="line">    ResultPartitionType resultPartitionType;</span><br><span class="line">    <span class="keyword">switch</span> (edge.getShuffleMode()) &#123;</span><br><span class="line">        <span class="keyword">case</span> PIPELINED:</span><br><span class="line">            resultPartitionType = ResultPartitionType.PIPELINED_BOUNDED;</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">        <span class="keyword">case</span> BATCH:</span><br><span class="line">            resultPartitionType = ResultPartitionType.BLOCKING;</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">        <span class="keyword">case</span> UNDEFINED:</span><br><span class="line">            resultPartitionType = streamGraph.isBlockingConnectionsBetweenChains() ?</span><br><span class="line">                    ResultPartitionType.BLOCKING : ResultPartitionType.PIPELINED_BOUNDED;</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">        <span class="keyword">default</span>:</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> UnsupportedOperationException(<span class="string">"Data exchange mode "</span> +</span><br><span class="line">                edge.getShuffleMode() + <span class="string">" is not supported yet."</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//note: 创建 JobEdge（它会连接上下游的 node）</span></span><br><span class="line">    JobEdge jobEdge;</span><br><span class="line">    <span class="keyword">if</span> (partitioner <span class="keyword">instanceof</span> ForwardPartitioner || partitioner <span class="keyword">instanceof</span> RescalePartitioner) &#123;</span><br><span class="line">        jobEdge = downStreamVertex.connectNewDataSetAsInput( <span class="comment">//note: 这个方法会创建 IntermediateDataSet 对象</span></span><br><span class="line">            headVertex,</span><br><span class="line">            DistributionPattern.POINTWISE, <span class="comment">//note: 上游与下游的消费模式，（每个生产任务的 sub-task 会连接到消费任务的一个或多个 sub-task）</span></span><br><span class="line">            resultPartitionType);</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        jobEdge = downStreamVertex.connectNewDataSetAsInput(</span><br><span class="line">                headVertex,</span><br><span class="line">                DistributionPattern.ALL_TO_ALL, <span class="comment">//note: 每个生产任务的 sub-task 都会连接到每个消费任务的 sub-task</span></span><br><span class="line">                resultPartitionType);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// set strategy name so that web interface can show it.</span></span><br><span class="line">    <span class="comment">//note: 设置 partitioner</span></span><br><span class="line">    jobEdge.setShipStrategyName(partitioner.toString());</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (LOG.isDebugEnabled()) &#123;</span><br><span class="line">        LOG.debug(<span class="string">"CONNECTED: &#123;&#125; - &#123;&#125; -&gt; &#123;&#125;"</span>, partitioner.getClass().getSimpleName(),</span><br><span class="line">                headOfChain, downStreamvertexID);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>真正创建 JobEdge 和 IntermediateDataSet 对象是在 JobVertex 中的 <code>connectNewDataSetAsInput()</code> 方法中，在这里也会把 JobVertex、JobEdge、IntermediateDataSet 三者连接起来（JobGraph 的 graph 就是这样构建的）：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//org.apache.flink.runtime.jobgraph.JobVertex</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> JobEdge <span class="title">connectNewDataSetAsInput</span><span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">        JobVertex input,</span></span></span><br><span class="line"><span class="function"><span class="params">        DistributionPattern distPattern,</span></span></span><br><span class="line"><span class="function"><span class="params">        ResultPartitionType partitionType)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//note: 连接 Vertex 的中间数据集</span></span><br><span class="line">    IntermediateDataSet dataSet = input.createAndAddResultDataSet(partitionType);</span><br><span class="line"></span><br><span class="line">    <span class="comment">//note: 创建对应的 edge</span></span><br><span class="line">    JobEdge edge = <span class="keyword">new</span> JobEdge(dataSet, <span class="keyword">this</span>, distPattern);</span><br><span class="line">    <span class="keyword">this</span>.inputs.add(edge);</span><br><span class="line">    dataSet.addConsumer(edge);</span><br><span class="line">    <span class="keyword">return</span> edge;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>到这里，<code>createChain()</code> 方法就执行完了，在 JobGraph 总共会涉及到三个对象：JobVertex、JobEdge 和 IntermediateDataSet，最后生成的 JobGraph 大概下面这个样子：</p>
<p><img src="/images/flink/3-JobGraph.png" alt="JobGraph"></p>
<h3 id="JobGraph-的其他配置"><a href="#JobGraph-的其他配置" class="headerlink" title="JobGraph 的其他配置"></a>JobGraph 的其他配置</h3><p>执行完 <code>setChaining()</code> 方法后，下面还有几步操作：</p>
<ol>
<li><code>setPhysicalEdges()</code>: 将每个 JobVertex 的入边集合也序列化到该 JobVertex 的 StreamConfig 中 (出边集合已经在 setChaining 的时候写入了)；</li>
<li><code>setSlotSharingAndCoLocation()</code>: 为每个 JobVertex 指定所属的 SlotSharingGroup 以及设置 CoLocationGroup；</li>
<li><code>configureCheckpointing()</code>: checkpoint相关的配置；</li>
<li><code>JobGraphGenerator.addUserArtifactEntries()</code>: 用户依赖的第三方包就是在这里（cacheFile）传给 JobGraph；</li>
</ol>
<p>这几个方法的实现比较简单，这里简单看下 <code>configureCheckpointing()</code> 这个方法，其他三个就不再叙述了。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// org.apache.flink.streaming.api.graph.StreamGraphGenerator</span></span><br><span class="line"><span class="comment">//note: 主要是 checkpoint 相关的配置</span></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">configureCheckpointing</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    CheckpointConfig cfg = streamGraph.getCheckpointConfig();</span><br><span class="line"></span><br><span class="line">    <span class="keyword">long</span> interval = cfg.getCheckpointInterval();</span><br><span class="line">    <span class="keyword">if</span> (interval &lt; MINIMAL_CHECKPOINT_TIME) &#123;</span><br><span class="line">        <span class="comment">// interval of max value means disable periodic checkpoint</span></span><br><span class="line">        interval = Long.MAX_VALUE;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//  --- configure the participating vertices ---</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">//note: 配置 checkpoint 中要参与的 vertices 节点信息</span></span><br><span class="line">    <span class="comment">// collect the vertices that receive "trigger checkpoint" messages.</span></span><br><span class="line">    <span class="comment">// currently, these are all the sources</span></span><br><span class="line">    <span class="comment">//note: 记录接收 trigger checkpoint msg 的 vertices，当前都是 source 的情况</span></span><br><span class="line">    List&lt;JobVertexID&gt; triggerVertices = <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line"></span><br><span class="line">    <span class="comment">// collect the vertices that need to acknowledge the checkpoint</span></span><br><span class="line">    <span class="comment">// currently, these are all vertices</span></span><br><span class="line">    <span class="comment">//note: 记录当前需要向 checkpoint coordinator 发送 ack 的 vertices，当前指的是所有的 vertices</span></span><br><span class="line">    List&lt;JobVertexID&gt; ackVertices = <span class="keyword">new</span> ArrayList&lt;&gt;(jobVertices.size());</span><br><span class="line"></span><br><span class="line">    <span class="comment">// collect the vertices that receive "commit checkpoint" messages</span></span><br><span class="line">    <span class="comment">// currently, these are all vertices</span></span><br><span class="line">    <span class="comment">//note: 记录接收 'commit checkpoint' 的 vertices，当前也指的是所有 vertices</span></span><br><span class="line">    List&lt;JobVertexID&gt; commitVertices = <span class="keyword">new</span> ArrayList&lt;&gt;(jobVertices.size());</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> (JobVertex vertex : jobVertices.values()) &#123;</span><br><span class="line">        <span class="keyword">if</span> (vertex.isInputVertex()) &#123;</span><br><span class="line">            triggerVertices.add(vertex.getID());</span><br><span class="line">        &#125;</span><br><span class="line">        commitVertices.add(vertex.getID());</span><br><span class="line">        ackVertices.add(vertex.getID());</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//  --- configure options ---</span></span><br><span class="line"></span><br><span class="line">    CheckpointRetentionPolicy retentionAfterTermination;</span><br><span class="line">    <span class="keyword">if</span> (cfg.isExternalizedCheckpointsEnabled()) &#123;</span><br><span class="line">        CheckpointConfig.ExternalizedCheckpointCleanup cleanup = cfg.getExternalizedCheckpointCleanup();</span><br><span class="line">        <span class="comment">// Sanity check</span></span><br><span class="line">        <span class="keyword">if</span> (cleanup == <span class="keyword">null</span>) &#123;</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> IllegalStateException(<span class="string">"Externalized checkpoints enabled, but no cleanup mode configured."</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        retentionAfterTermination = cleanup.deleteOnCancellation() ?</span><br><span class="line">                CheckpointRetentionPolicy.RETAIN_ON_FAILURE :</span><br><span class="line">                CheckpointRetentionPolicy.RETAIN_ON_CANCELLATION;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="comment">//note: 默认是 NEVER_RETAIN_AFTER_TERMINATION，作业只要进入终止 checkpoint 就会删除</span></span><br><span class="line">        retentionAfterTermination = CheckpointRetentionPolicy.NEVER_RETAIN_AFTER_TERMINATION;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//note: 默认是 EXACTLY_ONCE</span></span><br><span class="line">    CheckpointingMode mode = cfg.getCheckpointingMode();</span><br><span class="line"></span><br><span class="line">    <span class="keyword">boolean</span> isExactlyOnce;</span><br><span class="line">    <span class="keyword">if</span> (mode == CheckpointingMode.EXACTLY_ONCE) &#123;</span><br><span class="line">        isExactlyOnce = <span class="keyword">true</span>;</span><br><span class="line">    &#125; <span class="keyword">else</span> <span class="keyword">if</span> (mode == CheckpointingMode.AT_LEAST_ONCE) &#123;</span><br><span class="line">        isExactlyOnce = <span class="keyword">false</span>;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> IllegalStateException(<span class="string">"Unexpected checkpointing mode. "</span> +</span><br><span class="line">            <span class="string">"Did not expect there to be another checkpointing mode besides "</span> +</span><br><span class="line">            <span class="string">"exactly-once or at-least-once."</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//  --- configure the master-side checkpoint hooks ---</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">final</span> ArrayList&lt;MasterTriggerRestoreHook.Factory&gt; hooks = <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> (StreamNode node : streamGraph.getStreamNodes()) &#123;</span><br><span class="line">        <span class="keyword">if</span> (node.getOperatorFactory() <span class="keyword">instanceof</span> UdfStreamOperatorFactory) &#123;</span><br><span class="line">            Function f = ((UdfStreamOperatorFactory) node.getOperatorFactory()).getUserFunction();</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> (f <span class="keyword">instanceof</span> WithMasterCheckpointHook) &#123;</span><br><span class="line">                <span class="comment">//note: 它会在 CheckpointCoordinator 端在每次 checkpoint 及 restore 时触发一个 'global action'</span></span><br><span class="line">                <span class="comment">//note: 比如这里可以通过这个接口将状态刷到外部存储</span></span><br><span class="line">                hooks.add(<span class="keyword">new</span> FunctionMasterCheckpointHookFactory((WithMasterCheckpointHook&lt;?&gt;) f));</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// because the hooks can have user-defined code, they need to be stored as</span></span><br><span class="line">    <span class="comment">// eagerly serialized values</span></span><br><span class="line">    <span class="comment">//note: 这里对 hooks 做一下序列化</span></span><br><span class="line">    <span class="keyword">final</span> SerializedValue&lt;MasterTriggerRestoreHook.Factory[]&gt; serializedHooks;</span><br><span class="line">    <span class="keyword">if</span> (hooks.isEmpty()) &#123;</span><br><span class="line">        serializedHooks = <span class="keyword">null</span>;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            MasterTriggerRestoreHook.Factory[] asArray =</span><br><span class="line">                    hooks.toArray(<span class="keyword">new</span> MasterTriggerRestoreHook.Factory[hooks.size()]);</span><br><span class="line">            serializedHooks = <span class="keyword">new</span> SerializedValue&lt;&gt;(asArray);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> FlinkRuntimeException(<span class="string">"Trigger/restore hook is not serializable"</span>, e);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// because the state backend can have user-defined code, it needs to be stored as</span></span><br><span class="line">    <span class="comment">// eagerly serialized value</span></span><br><span class="line">    <span class="comment">//note: 对 state backend 类做下序列化</span></span><br><span class="line">    <span class="keyword">final</span> SerializedValue&lt;StateBackend&gt; serializedStateBackend;</span><br><span class="line">    <span class="keyword">if</span> (streamGraph.getStateBackend() == <span class="keyword">null</span>) &#123;</span><br><span class="line">        serializedStateBackend = <span class="keyword">null</span>;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            serializedStateBackend =</span><br><span class="line">                <span class="keyword">new</span> SerializedValue&lt;StateBackend&gt;(streamGraph.getStateBackend());</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> FlinkRuntimeException(<span class="string">"State backend is not serializable"</span>, e);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//  --- done, put it all together ---</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">//note: 创建一个 JobCheckpointingSettings 对象</span></span><br><span class="line">    JobCheckpointingSettings settings = <span class="keyword">new</span> JobCheckpointingSettings(</span><br><span class="line">        triggerVertices,</span><br><span class="line">        ackVertices,</span><br><span class="line">        commitVertices,</span><br><span class="line">        <span class="keyword">new</span> CheckpointCoordinatorConfiguration( <span class="comment">//note: 创建一个 CheckpointCoordinatorConfiguration 对象</span></span><br><span class="line">            interval,</span><br><span class="line">            cfg.getCheckpointTimeout(),</span><br><span class="line">            cfg.getMinPauseBetweenCheckpoints(),</span><br><span class="line">            cfg.getMaxConcurrentCheckpoints(),</span><br><span class="line">            retentionAfterTermination,</span><br><span class="line">            isExactlyOnce,</span><br><span class="line">            cfg.isPreferCheckpointForRecovery(),</span><br><span class="line">            cfg.getTolerableCheckpointFailureNumber()),</span><br><span class="line">        serializedStateBackend,</span><br><span class="line">        serializedHooks);</span><br><span class="line"></span><br><span class="line">    jobGraph.setSnapshotSettings(settings);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>到这里，StreamGraph 转换为 JobGraph 的流程已经梳理完成了，个人感觉这部分还有一些绕的，不过这种开源代码，只要看多几遍，多 debug 看看具体的执行流程，基本都可以搞明白。</p>
<hr>
<p>参考</p>
<ul>
<li><a href="http://asterios.katsifodimos.com/assets/publications/flink-deb.pdf" target="_blank" rel="external">Apache Flink: Stream and Batch Processing in a Single Engine</a>；</li>
<li><a href="http://chenyuzhao.me/2016/12/03/Flink%E5%9F%BA%E6%9C%AC%E7%BB%84%E4%BB%B6%E5%92%8C%E9%80%BB%E8%BE%91%E8%AE%A1%E5%88%92/" target="_blank" rel="external">Flink 集群构建 &amp; 逻辑计划生成</a>；</li>
<li><a href="http://wuchong.me/blog/2016/05/10/flink-internals-how-to-build-jobgraph/" target="_blank" rel="external">Flink 原理与实现：如何生成 JobGraph</a>；</li>
<li><a href="https://zhuanlan.zhihu.com/p/22736103" target="_blank" rel="external">Flink源码解析-从API到JobGraph</a>；</li>
<li><a href="https://mp.weixin.qq.com/s/tmB7q9MTg3c_uhI51ZDAWQ" target="_blank" rel="external">Apache Flink 进阶（六）：Flink 作业执行深度解析</a>；</li>
<li><a href="https://mp.weixin.qq.com/s/l-x3wSxuIvPMgxZzwYxZkA" target="_blank" rel="external">Flink CookBook—Apach Flink核心知识介绍</a>；</li>
</ul>
</div><script type="text/javascript" src="/js/share.js?v=0.0.0" async></script><a data-url="http://matt33.com/2019/12/09/flink-job-graph-3/" data-id="ck4imvxqv00af5zza8tjy4f2s" class="article-share-link">分享到</a><div class="copyright"><a href="http://matt33.com/copyright/">博客版权说明</a></div><div class="tags"><a href="/tags/flink/">flink</a></div><div class="post-nav"><a href="/2019/12/19/flink-execution-graph-4/" class="pre">Flink 如何生成 ExecutionGraph</a><a href="/2019/12/08/flink-stream-graph-2/" class="next">Flink DataStream API 概述及作业如何转换为 StreamGraph</a></div><div id="disqus_thread"><div class="btn_click_load"><button class="disqus_click_btn">阅读评论 「请确保 disqus.com 可以正常加载」</button></div><script>var disqus_shortname = 'http-matt33-com';
var disqus_identifier = '2019/12/09/flink-job-graph-3/';
var disqus_title = 'Flink Streaming 作业如何转化为 JobGraph';
var disqus_url = 'http://matt33.com/2019/12/09/flink-job-graph-3/';
$('.btn_click_load').click(function() {
  (function() {
    var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
    dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
  })();
  $('.btn_click_load').css('display','none');
});
$.ajax({
  url: 'https://disqus.com/favicon.ico',
  timeout: 3000,
  type: 'GET',
  success: (function() {
    var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
    dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    $('.btn_click_load').css('display','none');
  })(),
  error: function() {
    $('.btn_click_load').css('display','block');
  }
});</script><script id="dsq-count-scr" src="//http-matt33-com.disqus.com/count.js" async></script></div></div></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><div class="widget-title"><i class="fa fa-weibo"> 微博</i></div><iframe width="100%" height="90" class="share_self"  frameborder="0" scrolling="no" src="http://widget.weibo.com/weiboshow/index.php?language=&width=0&height=100&fansRow=1&ptype=1&speed=0&skin=1&isTitle=0&noborder=1&isWeibo=0&isFans=0&uid=2650396571&verifier=f2f0e397&colors=D8D8D8,ffffff,666666,0082cb,ecfbfd&dpc=1"></iframe></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> 分类</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/书屋/">书屋</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/影如人生/">影如人生</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/技术/">技术</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/旅行/">旅行</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/转载/">转载</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/随笔/">随笔</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> 标签</i></div><div class="tagcloud"><a href="/tags/tcp/" style="font-size: 15px;">tcp</a> <a href="/tags/思考/" style="font-size: 15px;">思考</a> <a href="/tags/kafka/" style="font-size: 15px;">kafka</a> <a href="/tags/storm/" style="font-size: 15px;">storm</a> <a href="/tags/java/" style="font-size: 15px;">java</a> <a href="/tags/linux/" style="font-size: 15px;">linux</a> <a href="/tags/learn/" style="font-size: 15px;">learn</a> <a href="/tags/hexo/" style="font-size: 15px;">hexo</a> <a href="/tags/bug/" style="font-size: 15px;">bug</a> <a href="/tags/cv/" style="font-size: 15px;">cv</a> <a href="/tags/maven/" style="font-size: 15px;">maven</a> <a href="/tags/travel/" style="font-size: 15px;">travel</a> <a href="/tags/hadoop/" style="font-size: 15px;">hadoop</a> <a href="/tags/mac/" style="font-size: 15px;">mac</a> <a href="/tags/database/" style="font-size: 15px;">database</a> <a href="/tags/电影随想/" style="font-size: 15px;">电影随想</a> <a href="/tags/随笔/" style="font-size: 15px;">随笔</a> <a href="/tags/paper/" style="font-size: 15px;">paper</a> <a href="/tags/flink/" style="font-size: 15px;">flink</a> <a href="/tags/转载/" style="font-size: 15px;">转载</a> <a href="/tags/algorithm/" style="font-size: 15px;">algorithm</a> <a href="/tags/jvm/" style="font-size: 15px;">jvm</a> <a href="/tags/web/" style="font-size: 15px;">web</a> <a href="/tags/分布式系统/" style="font-size: 15px;">分布式系统</a> <a href="/tags/bk/" style="font-size: 15px;">bk</a> <a href="/tags/rpc/" style="font-size: 15px;">rpc</a> <a href="/tags/thrift/" style="font-size: 15px;">thrift</a> <a href="/tags/zookeeper/" style="font-size: 15px;">zookeeper</a> <a href="/tags/calcite/" style="font-size: 15px;">calcite</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> 最新文章</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2019/12/23/flink-master-5/">Flink Master 详解</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/12/19/flink-execution-graph-4/">Flink 如何生成 ExecutionGraph</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/12/09/flink-job-graph-3/">Flink Streaming 作业如何转化为 JobGraph</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/12/08/flink-stream-graph-2/">Flink DataStream API 概述及作业如何转换为 StreamGraph</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/11/23/flink-learn-start-1/">Apache Flink 初探</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/10/27/paper-chandy-lamport/">Paper 阅读: Distributed Snapshots: Determining Global States of Distributed Systems</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/10/20/paper-flink-snapshot/">Paper 阅读: Lightweight Asynchronous Snapshots for Distributed Dataflow</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/10/19/paper-ray1/">Paper 阅读: Real-Time Machine Learning: The Missing Pieces</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/03/17/apache-calcite-planner/">Apache Calcite 优化器详解（二）</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/03/07/apache-calcite-process-flow/">Apache Calcite 处理流程详解（一）</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-external-link"> 友情链接</i></div><ul></ul><a href="http://matt33.com/about/" title="个人公众号：柳年思水" target="_blank">个人公众号：柳年思水</a><ul></ul><a href="http://tech.meituan.com/" title="美团点评技术团队" target="_blank">美团点评技术团队</a><ul></ul><a href="http://jm.taobao.org/" title="阿里中间件团队博客" target="_blank">阿里中间件团队博客</a><ul></ul><a href="http://www.jianshu.com/" title="简书" target="_blank">简书</a></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">© <a href="/." rel="nofollow">Matt's Blog 柳年思水.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a id="rocket" href="#top" class="show"></a><script type="text/javascript" src="/js/totop.js?v=0.0.0" async></script><div class="analytics"><script>var cnzz_protocol = (("https:" == document.location.protocol) ? " https://" : " http://");
document.write(unescape("%3Cspan id='cnzz_stat_icon_1256517224'%3E%3C/span%3E%3Cscript src='" + cnzz_protocol + "s95.cnzz.com/z_stat.php%3Fid%3D1256517224%26show%3Dpic' type='text/javascript'%3E%3C/script%3E"));</script></div><script type="text/javascript" src="//cdn.bootcss.com/fancybox/2.1.5/jquery.fancybox.pack.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=0.0.0" async></script><link rel="stylesheet" type="text/css" href="/css/jquery.fancybox.css?v=0.0.0"><script>(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
ga('create','UA-64518924-1','auto');ga('send','pageview');
</script><script>var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "//hm.baidu.com/hm.js?5cf44757fa0d23bc7637935e44a9104a";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
  })();
</script><script type="text/x-mathjax-config">MathJax.Hub.Config({
  tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
  });
</script><script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML" async></script><script type="text/javascript" src="/js/codeblock-resizer.js?v=0.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=0.0.0"></script></div></body></html>