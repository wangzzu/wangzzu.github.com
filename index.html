<!DOCTYPE html><html lang="zh-CN"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description" content="与一群有趣的人，做一些有趣的事."><title>Matt's Blog | 王蒙</title><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/normalize/4.2.0/normalize.min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/0.6.0/pure-min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/0.6.0/grids-responsive-min.css"><link rel="stylesheet" type="text/css" href="/css/style.css?v=0.0.0"><link rel="stylesheet" href="//cdn.bootcss.com/font-awesome/4.6.3/css/font-awesome.min.css"><script type="text/javascript" src="//cdn.bootcss.com/jquery/3.0.0/jquery.min.js"></script><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"><link rel="alternate" type="application/atom+xml" href="/atom.xml"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">Matt's Blog</h1><a id="logo" href="/.">Matt's Blog</a><p class="description">王蒙</p></div><div id="nav-menu"><a href="/." class="current"><i class="fa fa-home"> 首页</i></a><a href="/archives/"><i class="fa fa-archive"> 归档</i></a><a href="/about/"><i class="fa fa-user"> 关于</i></a><a href="/atom.xml"><i class="fa fa-rss"> 订阅</i></a></div></div><div id="layout" class="pure-g"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h2 class="post-title"><a href="/2018/06/25/leaderAndIsr-process/">Kafka 源码解析之 LeaderAndIsr 请求的处理（二十二）</a></h2><div class="post-meta">2018-06-25</div><a data-disqus-identifier="2018/06/25/leaderAndIsr-process/" href="/2018/06/25/leaderAndIsr-process/#disqus_thread" class="disqus-comment-count"></a><div class="post-content"><p>本篇算是 Controller 部分的最后一篇，在前面讲述 ReplicaManager 时，留一个地方没有讲解，是关于 Broker 对 Controller 发送的 LeaderAndIsr 请求的处理，这个请求的处理实现会稍微复杂一些，本篇文章主要就是讲述 Kafka Server 是如何处理 LeaderAndIsr 请求的。</p></div><p class="readmore"><a href="/2018/06/25/leaderAndIsr-process/">阅读更多</a></p></div><div class="post"><h2 class="post-title"><a href="/2018/06/23/controller-request-model/">Kafka 源码解析之 Controller 发送模型（二十一）</a></h2><div class="post-meta">2018-06-23</div><a data-disqus-identifier="2018/06/23/controller-request-model/" href="/2018/06/23/controller-request-model/#disqus_thread" class="disqus-comment-count"></a><div class="post-content"><p>本篇主要讲述 Controller 向各个 Broker 发送请求的模型，算是对 <a href="http://matt33.com/2018/06/15/kafka-controller-start/#Controller-Channel-Manager">Controller Channel Manager</a> 部分的一个补充，在这篇文章中，将会看到 Controller 在处理 leader 切换、ShutDown 请求时如何向 Broker 发送相应的请求。</p></div><p class="readmore"><a href="/2018/06/23/controller-request-model/">阅读更多</a></p></div><div class="post"><h2 class="post-title"><a href="/2018/06/18/topic-create-alter-delete/">Kafka 源码解析之 Topic 的新建/扩容/删除（二十）</a></h2><div class="post-meta">2018-06-18</div><a data-disqus-identifier="2018/06/18/topic-create-alter-delete/" href="/2018/06/18/topic-create-alter-delete/#disqus_thread" class="disqus-comment-count"></a><div class="post-content"><p>本篇接着讲述 Controller 的功能方面的内容，在 Kafka 中，一个 Topic 的新建、扩容或者删除都是由 Controller 来操作的，本篇文章也是主要聚焦在 Topic 的操作处理上（新建、扩容、删除），实际上 Topic 的创建在 <a href="http://matt33.com/2017/07/21/kafka-topic-create/">Kafka 源码解析之 topic 创建过程（三）</a> 中已经讲述过了，本篇与前面不同的是，本篇主要是从 Controller 角度来讲述，而且是把新建、扩容、删除这三个 Topic 级别的操作放在一起做一个总结。</p></div><p class="readmore"><a href="/2018/06/18/topic-create-alter-delete/">阅读更多</a></p></div><div class="post"><h2 class="post-title"><a href="/2018/06/17/broker-online-offline/">Kafka 源码解析之 Broker 上线下线（十九）</a></h2><div class="post-meta">2018-06-17</div><a data-disqus-identifier="2018/06/17/broker-online-offline/" href="/2018/06/17/broker-online-offline/#disqus_thread" class="disqus-comment-count"></a><div class="post-content"><p>本篇接着讲述 Controller 对于监听器的处理内容 —— Broker 节点上下线的处理流程。每台 Broker 在上线时，都会与 ZK 建立一个建立一个 session，并在 <code>/brokers/ids</code> 下注册一个节点，节点名字就是 broker id，这个节点是临时节点，该节点内部会有这个 Broker 的详细节点信息。Controller 会监听 <code>/brokers/ids</code> 这个路径下的所有子节点，如果有新的节点出现，那么就代表有新的 Broker 上线，如果有节点消失，就代表有 broker 下线，Controller 会进行相应的处理，Kafka 就是利用 ZK 的这种 watch 机制及临时节点的特性来完成集群 Broker 的上下线，本文将会深入讲解这一过程。</p></div><p class="readmore"><a href="/2018/06/17/broker-online-offline/">阅读更多</a></p></div><div class="post"><h2 class="post-title"><a href="/2018/06/16/partition-reassignment/">Kafka 源码解析之 Partition 副本迁移实现（十八）</a></h2><div class="post-meta">2018-06-16</div><a data-disqus-identifier="2018/06/16/partition-reassignment/" href="/2018/06/16/partition-reassignment/#disqus_thread" class="disqus-comment-count"></a><div class="post-content"><p>前面两篇关于 Controller 的内容分别讲述了 Controller 选举和启动，以及副本状态机和分区状态机的内容，从本文开始会详细讲述 Controller 的一些其他功能，主要是 Controller 的对不同类型监听器的处理，这部分预计分三篇左右的文章讲述。Controller 在初始化时，会利用 ZK 的 watch 机制注册很多不同类型的监听器，当监听的事件被触发时，Controller 就会触发相应的操作。</p></div><p class="readmore"><a href="/2018/06/16/partition-reassignment/">阅读更多</a></p></div><div class="post"><h2 class="post-title"><a href="/2018/06/16/controller-state-machine/">Kafka 源码解析之副本状态机与分区状态机（十七）</a></h2><div class="post-meta">2018-06-16</div><a data-disqus-identifier="2018/06/16/controller-state-machine/" href="/2018/06/16/controller-state-machine/#disqus_thread" class="disqus-comment-count"></a><div class="post-content"><p>上篇讲述了 KafkaController 的启动流程，但是关于分区状态机和副本状态机的初始化并没有触及，分区状态机和副本状态机的内容将在本篇文章深入讲述。分区状态机记录着当前集群所有 Partition 的状态信息以及如何对 Partition 状态转移进行相应的处理；副本状态机则是记录着当前集群所有 Replica 的状态信息以及如何对 Replica 状态转变进行相应的处理。</p></div><p class="readmore"><a href="/2018/06/16/controller-state-machine/">阅读更多</a></p></div><div class="post"><h2 class="post-title"><a href="/2018/06/15/kafka-controller-start/">Kafka 源码解析之 Controller 选举及服务启动流程（十六）</a></h2><div class="post-meta">2018-06-15</div><a data-disqus-identifier="2018/06/15/kafka-controller-start/" href="/2018/06/15/kafka-controller-start/#disqus_thread" class="disqus-comment-count"></a><div class="post-content"><p>从本篇文章开始，Kafka 源码解析就正式进入了 Controller 部分，Controller 作为 Kafka Server 端一个重要的组件，它的角色类似于其他分布式系统 Master 的角色，跟其他系统不一样的是，Kafka 集群的任何一台 Broker 都可以作为 Controller，但是在一个集群中同时只会有一个 Controller 是 alive 状态。Controller 在集群中负责的事务很多，比如：集群 meta 信息的一致性保证、Partition leader 的选举、broker 上下线等都是由 Controller 来具体负责。Controller 部分的内容还是比较多的，计划分5篇左右的文章讲述，本文先来看下 Controller 的简介、Controller 的选举、Controller 选举后服务的启动流程以及 Controller 的四种不同 leader 选举机制。分区状态机、副本副本状态机以及对各种 listener 的处理将在后续的文章中展开。</p></div><p class="readmore"><a href="/2018/06/15/kafka-controller-start/">阅读更多</a></p></div><div class="post"><h2 class="post-title"><a href="/2018/05/01/kafka-replica-manager/">Kafka 源码解析之 ReplicaManager 详解（十五）</a></h2><div class="post-meta">2018-05-01</div><a data-disqus-identifier="2018/05/01/kafka-replica-manager/" href="/2018/05/01/kafka-replica-manager/#disqus_thread" class="disqus-comment-count"></a><div class="post-content"><p>前面几篇文章讲述了 LogManager 的实现、Produce 请求、Fetch 请求的处理以及副本同步机制的实现，Kafka 存储层的主要内容基本上算是讲完了（还有几个小块的内容后面会结合 Controller 再详细介绍）。本篇文章以 ReplicaManager 类为入口，通过对 ReplicaManager 的详解，顺便再把 Kafka 存储层的内容做一个简单的总结。</p></div><p class="readmore"><a href="/2018/05/01/kafka-replica-manager/">阅读更多</a></p></div><div class="post"><h2 class="post-title"><a href="/2018/04/29/kafka-replica-fetcher-thread/">Kafka 源码解析之副本同步机制实现（十四）</a></h2><div class="post-meta">2018-04-29</div><a data-disqus-identifier="2018/04/29/kafka-replica-fetcher-thread/" href="/2018/04/29/kafka-replica-fetcher-thread/#disqus_thread" class="disqus-comment-count"></a><div class="post-content"><p>在上篇文章中讲述了 Fetch 请求是如何处理的，其中包括来自副本同步的 Fetch 请求和 Consumer 的 Fetch 请求，副本同步是 Kafka 多副本机制（可靠性）实现的基础，它也是通过向 leader replica 发送 Fetch 请求来实现数据同步的。本篇文章我们就来看一下 Kafka 副本同步这块的内容，对于每个 broker 来说，它上面的 replica 对象，除了 leader 就是 follower，只要这台 broker 有 follower replica，broker 就会启动副本同步流程从 leader 同步数据，副本同步机制的实现是 Kafka Server 端非常重要的内容，在这篇文章中，主要会从以下几块来讲解：</p></div><p class="readmore"><a href="/2018/04/29/kafka-replica-fetcher-thread/">阅读更多</a></p></div><div class="post"><h2 class="post-title"><a href="/2018/04/15/kafka-server-handle-fetch-request/">Kafka 源码解析之 Server 端如何处理 Fetch 请求（十三）</a></h2><div class="post-meta">2018-04-15</div><a data-disqus-identifier="2018/04/15/kafka-server-handle-fetch-request/" href="/2018/04/15/kafka-server-handle-fetch-request/#disqus_thread" class="disqus-comment-count"></a><div class="post-content"><p>上一篇讲述完 Kafka 如何处理 Produce 请求以及日志写操作之后，这篇文章开始讲述 Kafka 如何处理 Fetch 请求以及日志读操作。日志的读写操作是 Kafka 存储层最重要的内容，本文会以 Server 端处理 Fetch 请求的过程为入口，一步步深入到底层的 Log 实例部分。与 Produce 请求不一样的地方是，对于 Fetch 请求，是有两种不同的来源：consumer 和 follower，consumer 读取数据与副本同步数据都是通过向 leader 发送 Fetch 请求来实现的，在对这两种不同情况处理过程中，其底层的实现是统一的，只是实现方法的参数不同而已，在本文中会详细讲述对这两种不同情况的处理。</p></div><p class="readmore"><a href="/2018/04/15/kafka-server-handle-fetch-request/">阅读更多</a></p></div><div class="post"><h2 class="post-title"><a href="/2018/03/18/kafka-server-handle-produce-request/">Kafka 源码解析之 Server 端如何处理 Produce 请求（十二）</a></h2><div class="post-meta">2018-03-18</div><a data-disqus-identifier="2018/03/18/kafka-server-handle-produce-request/" href="/2018/03/18/kafka-server-handle-produce-request/#disqus_thread" class="disqus-comment-count"></a><div class="post-content"><p>这部分想了很久应该怎么去写才能更容易让大家明白，本来是计划先把 Kafka 存储层 Log 这块的写操作处理流程先详细介绍一下，但是这块属于比较底层的部分，大家可能对于这部分在整个处理过程处在哪个位置并不是很清楚，所以还是准备以 Server 端如何处理 Producer Client 的 Produce 请求为入口。但是 Server 端的内容较多，本篇文章并不能全部涵盖，涉及到其他内容，在本篇文章暂时先不详细讲述，后面会再分析，本篇文章会以 Server 处理 produce 为主线，主要详细讲解 Kafka 存储层的内容。</p></div><p class="readmore"><a href="/2018/03/18/kafka-server-handle-produce-request/">阅读更多</a></p></div><div class="post"><h2 class="post-title"><a href="/2018/03/12/kafka-log-manager/">Kafka 源码解析之日志管理（十一）</a></h2><div class="post-meta">2018-03-12</div><a data-disqus-identifier="2018/03/12/kafka-log-manager/" href="/2018/03/12/kafka-log-manager/#disqus_thread" class="disqus-comment-count"></a><div class="post-content"><p>上篇文章在介绍完 Kafka 的 GroupCoordinator 之后，下面开始介绍 Kafka 存储层的内容，也就是 Kafka Server 端 Log 部分的内容，Log 部分是 Kafka 比较底层的代码，日志的读写、分段、清理和管理都是在这一部分完成的，内容还是比较多的，会分为三篇左右的文章介绍，本篇先介绍最简单的部分，主要是日志的基本概念、日志管理、日志刷新和日志清理四部分（后两个其实也属于日志管理，为便于讲解，这里分开讲述），日志的读写和分段将在下一篇讲述。</p></div><p class="readmore"><a href="/2018/03/12/kafka-log-manager/">阅读更多</a></p></div><div class="post"><h2 class="post-title"><a href="/2018/02/04/linux-mmap/">操作系统之共享对象学习</a></h2><div class="post-meta">2018-02-04</div><a data-disqus-identifier="2018/02/04/linux-mmap/" href="/2018/02/04/linux-mmap/#disqus_thread" class="disqus-comment-count"></a><div class="post-content"><p>在 Kafka 的存储层这部分代码时，看到了很多地方使用操作系统的共享内存机制，Kafka 中所有日志文件的索引都是使用了 <code>mmap</code> 做内存映射，<code>mmap</code> 这块刚好也是一个值得深入学习的知识点，于是就就深入地看了一下、做了一下总结，本文的内容主要来自《深入理解操作系统》第三版 9.8 存储器映射部分。</p></div><p class="readmore"><a href="/2018/02/04/linux-mmap/">阅读更多</a></p></div><div class="post"><h2 class="post-title"><a href="/2018/01/28/server-group-coordinator/">Kafka 源码解析之 GroupCoordinator 详解（十）</a></h2><div class="post-meta">2018-01-28</div><a data-disqus-identifier="2018/01/28/server-group-coordinator/" href="/2018/01/28/server-group-coordinator/#disqus_thread" class="disqus-comment-count"></a><div class="post-content"><p>突然发现距离上一篇文章，已经过去两个多月了，有两个月没有写博客了，之前定的是年前把这个系列写完，现在看来只能往后拖了，后面估计还有五篇文章左右，尽量在春节前完成吧。继续之前的内容开始讲解，这篇文章，主要是想把 GroupCoordinator 的内容总结一下，也算是开始了 Kafka Server 端的讲解，Kafka 的 Server 端主要有三块内容：GroupCoordinator、Controller 和 ReplicaManager，其中，GroupCoordinator 的内容是与 Consumer 端紧密结合在一起的，有一部分内容在前面已经断断续续介绍过，这里会做一个总结。</p></div><p class="readmore"><a href="/2018/01/28/server-group-coordinator/">阅读更多</a></p></div><div class="post"><h2 class="post-title"><a href="/2017/11/19/consumer-two-summary/">Kafka 源码解析之 Consumer 两种 commit 机制和 partition 分配机制（九）</a></h2><div class="post-meta">2017-11-19</div><a data-disqus-identifier="2017/11/19/consumer-two-summary/" href="/2017/11/19/consumer-two-summary/#disqus_thread" class="disqus-comment-count"></a><div class="post-content"><p>紧接着上篇文章，这篇文章讲述 Consumer 提供的两种 commit 机制和两种 partition 分配机制，具体如何使用是需要用户结合具体的场景进行选择，本文讲述一下其底层实现。</p></div><p class="readmore"><a href="/2017/11/19/consumer-two-summary/">阅读更多</a></p></div><div class="post"><h2 class="post-title"><a href="/2017/11/18/consumer-subscribe/">Kafka 源码解析之 Consumer 两种订阅模式（八）</a></h2><div class="post-meta">2017-11-18</div><a data-disqus-identifier="2017/11/18/consumer-subscribe/" href="/2017/11/18/consumer-subscribe/#disqus_thread" class="disqus-comment-count"></a><div class="post-content"><p>在前面两篇 Kafka Consumer 的文章中，Consumer Poll 模型这部分基本上已经完整结束，Consumer 这块的文章计划是要写五篇，这篇是 Consumer 这块的第三篇，本来计划是要从其中的三个小块细节内容着手，这三个地方有一个相同之处，那就是在 Kafka Consumer 中都提供了两个不同的解决方案，但具体怎么去使用是需要用户根据自己的业务场景去配置，这里会讲述其底层的具体实现（但为了阅读得更为方便，本来计划的这篇文章将拆分为两篇来，第一篇先讲述第一点，后面两点放在一起讲述）。</p></div><p class="readmore"><a href="/2017/11/18/consumer-subscribe/">阅读更多</a></p></div><div class="post"><h2 class="post-title"><a href="/2017/11/11/consumer-pollonce/">Kafka 源码解析之 Consumer Poll 模型（七）</a></h2><div class="post-meta">2017-11-11</div><a data-disqus-identifier="2017/11/11/consumer-pollonce/" href="/2017/11/11/consumer-pollonce/#disqus_thread" class="disqus-comment-count"></a><div class="post-content"><p>在上一篇问文章中已经介绍一个 Consumer 实例如何加入到一个 group 中，它是 Consumer Poll 模型第一步要做的事件，本文会完整讲述一个 Consumer 实例在 poll 模型过程中会做哪些事情，只有理解了 poll 模型才能更好地理解 Consumer 端的处理逻辑。</p></div><p class="readmore"><a href="/2017/11/11/consumer-pollonce/">阅读更多</a></p></div><div class="post"><h2 class="post-title"><a href="/2017/10/22/consumer-join-group/">Kafka 源码解析之 Consumer 如何加入一个 Group（六）</a></h2><div class="post-meta">2017-10-22</div><a data-disqus-identifier="2017/10/22/consumer-join-group/" href="/2017/10/22/consumer-join-group/#disqus_thread" class="disqus-comment-count"></a><div class="post-content"><p>距离上一篇博客（2017-09-10），到现在已经过去一个多月了，理论上这篇文章在上个月就应该写完，无奈拖延症又犯了，一直以这部分过于复杂为借口拖了好久，这两天逼了自己一把，先整理出其中的一篇，后续要加把劲，要不然今年的年度计划（年底前把这个系列写完）就完不成了，废话到此为止，下面步入正文。在 Kafka 中，Consumer 的复杂度要比 producer 高出很多，对于 Producer 而言，没有 producer 组的概念的、也不需要 care offset 等问题，而 Consumer 就不一样了，它需要关注的内容很多，需要考虑分布式消费（Consumer Group），为了防止重复消费或者部分数据未消费需要考虑 offset，这些都对 Consumer 的设计以及 Server 对其处理提出了很高的要求。本来计划是先进行综述，然后再分别介绍各个模块，现在打算反过来，先介绍各个模块，最后再进行综述，本篇为 Consumer 源码分析开篇，先从一个 Consumer 实例如何加入一个 Consumer Group 讲起。</p></div><p class="readmore"><a href="/2017/10/22/consumer-join-group/">阅读更多</a></p></div><div class="post"><h2 class="post-title"><a href="/2017/09/10/produccer-end/">Kafka 源码解析之 Producer 单 Partition 顺序性实现及配置说明（五）</a></h2><div class="post-meta">2017-09-10</div><a data-disqus-identifier="2017/09/10/produccer-end/" href="/2017/09/10/produccer-end/#disqus_thread" class="disqus-comment-count"></a><div class="post-content"><p>今天把 Kafka Producer 最后一部分给讲述一下，Producer 大部分内容都已经在前面几篇文章介绍过了，这里简单做个收尾，但并不是对前面的总结，本文从两块来讲述：RecordAccumulator 类的实现、Kafka Producer 如何保证其顺序性以及 Kafka Producer 的配置说明，每个 Producer 线程都会有一个 RecordAccumulator 对象，它负责缓存要发送 RecordBatch、记录发送的状态并且进行相应的处理，这里会详细讲述 Kafka Producer 如何保证单 Partition 的有序性。最后，简单介绍一下 Producer 的参数配置说明，只有正确地理解 Producer 相关的配置参数，才能更好地使用 Producer，发挥其相应的作用。</p></div><p class="readmore"><a href="/2017/09/10/produccer-end/">阅读更多</a></p></div><div class="post"><h2 class="post-title"><a href="/2017/09/04/kafka-best-pratice/">Kafka 最佳实践【译】</a></h2><div class="post-meta">2017-09-04</div><a data-disqus-identifier="2017/09/04/kafka-best-pratice/" href="/2017/09/04/kafka-best-pratice/#disqus_thread" class="disqus-comment-count"></a><div class="post-content"><p>这里翻译一篇关于 Kafka 实践的文章，内容来自 DataWorks Summit/Hadoop Summit（<a href="https://dataworkssummit.com/munich-2017/sessions/apache-kafka-best-practices/" target="_blank" rel="external">Hadoop Summit</a>）上一篇分享，PPT 见<a href="https://www.slideshare.net/HadoopSummit/apache-kafka-best-practices" target="_blank" rel="external">Apache Kafka Best Pratices</a>，里面讲述了很多关于 Kafka 配置、监控、优化的内容，绝对是在实践中总结出的精华，有很大的借鉴参考意义，本文主要是根据 PPT 的内容进行翻译及适当补充。</p></div><p class="readmore"><a href="/2017/09/04/kafka-best-pratice/">阅读更多</a></p></div><nav class="page-navigator"><span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="page-number" href="/page/3/">3</a><span class="space">&hellip;</span><a class="page-number" href="/page/5/">5</a><a class="extend next" rel="next" href="/page/2/">下一页</a></nav><script id="dsq-count-scr" src="//http-matt33-com.disqus.com/count.js" async></script></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><div class="widget-title"><i class="fa fa-weibo"> 微博</i></div><iframe width="100%" height="90" class="share_self"  frameborder="0" scrolling="no" src="http://widget.weibo.com/weiboshow/index.php?language=&width=0&height=100&fansRow=1&ptype=1&speed=0&skin=1&isTitle=0&noborder=1&isWeibo=0&isFans=0&uid=2650396571&verifier=f2f0e397&colors=D8D8D8,ffffff,666666,0082cb,ecfbfd&dpc=1"></iframe></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> 分类</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/书屋/">书屋</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/影如人生/">影如人生</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/技术/">技术</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/旅行/">旅行</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/转载/">转载</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/随笔/">随笔</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> 标签</i></div><div class="tagcloud"><a href="/tags/hexo/" style="font-size: 15px;">hexo</a> <a href="/tags/思考/" style="font-size: 15px;">思考</a> <a href="/tags/kafka/" style="font-size: 15px;">kafka</a> <a href="/tags/storm/" style="font-size: 15px;">storm</a> <a href="/tags/java/" style="font-size: 15px;">java</a> <a href="/tags/linux/" style="font-size: 15px;">linux</a> <a href="/tags/转载/" style="font-size: 15px;">转载</a> <a href="/tags/travel/" style="font-size: 15px;">travel</a> <a href="/tags/maven/" style="font-size: 15px;">maven</a> <a href="/tags/learn/" style="font-size: 15px;">learn</a> <a href="/tags/hadoop/" style="font-size: 15px;">hadoop</a> <a href="/tags/algorithm/" style="font-size: 15px;">algorithm</a> <a href="/tags/database/" style="font-size: 15px;">database</a> <a href="/tags/rpc/" style="font-size: 15px;">rpc</a> <a href="/tags/thrift/" style="font-size: 15px;">thrift</a> <a href="/tags/zookeeper/" style="font-size: 15px;">zookeeper</a> <a href="/tags/mac/" style="font-size: 15px;">mac</a> <a href="/tags/tcp/" style="font-size: 15px;">tcp</a> <a href="/tags/jvm/" style="font-size: 15px;">jvm</a> <a href="/tags/bug/" style="font-size: 15px;">bug</a> <a href="/tags/随笔/" style="font-size: 15px;">随笔</a> <a href="/tags/电影随想/" style="font-size: 15px;">电影随想</a> <a href="/tags/web/" style="font-size: 15px;">web</a> <a href="/tags/cv/" style="font-size: 15px;">cv</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> 最新文章</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2018/06/25/leaderAndIsr-process/">Kafka 源码解析之 LeaderAndIsr 请求的处理（二十二）</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/06/23/controller-request-model/">Kafka 源码解析之 Controller 发送模型（二十一）</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/06/18/topic-create-alter-delete/">Kafka 源码解析之 Topic 的新建/扩容/删除（二十）</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/06/17/broker-online-offline/">Kafka 源码解析之 Broker 上线下线（十九）</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/06/16/partition-reassignment/">Kafka 源码解析之 Partition 副本迁移实现（十八）</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/06/16/controller-state-machine/">Kafka 源码解析之副本状态机与分区状态机（十七）</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/06/15/kafka-controller-start/">Kafka 源码解析之 Controller 选举及服务启动流程（十六）</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/05/01/kafka-replica-manager/">Kafka 源码解析之 ReplicaManager 详解（十五）</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/04/29/kafka-replica-fetcher-thread/">Kafka 源码解析之副本同步机制实现（十四）</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/04/15/kafka-server-handle-fetch-request/">Kafka 源码解析之 Server 端如何处理 Fetch 请求（十三）</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-external-link"> 友情链接</i></div><ul></ul><a href="http://tech.meituan.com/" title="美团点评技术团队" target="_blank">美团点评技术团队</a><ul></ul><a href="http://jm.taobao.org/" title="阿里中间件团队博客" target="_blank">阿里中间件团队博客</a><ul></ul><a href="http://www.jianshu.com/" title="简书" target="_blank">简书</a></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">© <a href="/." rel="nofollow">Matt's Blog 柳年思水.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a id="rocket" href="#top" class="show"></a><script type="text/javascript" src="/js/totop.js?v=0.0.0" async></script><div class="analytics"><script>var cnzz_protocol = (("https:" == document.location.protocol) ? " https://" : " http://");
document.write(unescape("%3Cspan id='cnzz_stat_icon_1256517224'%3E%3C/span%3E%3Cscript src='" + cnzz_protocol + "s95.cnzz.com/z_stat.php%3Fid%3D1256517224%26show%3Dpic' type='text/javascript'%3E%3C/script%3E"));</script></div><script type="text/javascript" src="//cdn.bootcss.com/fancybox/2.1.5/jquery.fancybox.pack.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=0.0.0" async></script><link rel="stylesheet" type="text/css" href="/css/jquery.fancybox.css?v=0.0.0"><script>(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
ga('create','UA-64518924-1','auto');ga('send','pageview');
</script><script>var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "//hm.baidu.com/hm.js?5cf44757fa0d23bc7637935e44a9104a";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
  })();
</script><script type="text/javascript" src="/js/codeblock-resizer.js?v=0.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=0.0.0"></script></div></body></html>