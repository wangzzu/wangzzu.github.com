<!DOCTYPE html><html lang="zh-CN"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description" content="与一群有趣的人，做一些有趣的事."><title>Matt's Blog | 王蒙</title><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/normalize/4.2.0/normalize.min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/0.6.0/pure-min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/0.6.0/grids-responsive-min.css"><link rel="stylesheet" type="text/css" href="/css/style.css?v=0.0.0"><link rel="stylesheet" href="//cdn.bootcss.com/font-awesome/4.6.3/css/font-awesome.min.css"><script type="text/javascript" src="//cdn.bootcss.com/jquery/3.0.0/jquery.min.js"></script><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"><link rel="alternate" type="application/atom+xml" href="/atom.xml"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">Matt's Blog</h1><a id="logo" href="/.">Matt's Blog</a><p class="description">王蒙</p></div><div id="nav-menu"><a href="/." class="current"><i class="fa fa-home"> 首页</i></a><a href="/archives/"><i class="fa fa-archive"> 归档</i></a><a href="/about/"><i class="fa fa-user"> 关于</i></a><a href="/atom.xml"><i class="fa fa-rss"> 订阅</i></a></div></div><div id="layout" class="pure-g"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h2 class="post-title"><a href="/2018/06/15/kafka-controller-start/">Kafka 源码解析之 Controller 选举及服务启动流程（十六）</a></h2><div class="post-meta">2018-06-15</div><a data-disqus-identifier="2018/06/15/kafka-controller-start/" href="/2018/06/15/kafka-controller-start/#disqus_thread" class="disqus-comment-count"></a><div class="post-content"><p>从本篇文章开始，Kafka 源码解析就正式进入了 Controller 部分，Controller 作为 Kafka Server 端一个重要的组件，它的角色类似于其他分布式系统 Master 的角色，跟其他系统不一样的是，Kafka 集群的任何一台 Broker 都可以作为 Controller，但是在一个集群中同时只会有一个 Controller 是 alive 状态。Controller 在集群中负责的事务很多，比如：集群 meta 信息的一致性保证、Partition leader 的选举、broker 上下线等都是由 Controller 来具体负责。Controller 部分的内容还是比较多的，计划分5篇左右的文章讲述，本文先来看下 Controller 的简介、Controller 的选举、Controller 选举后服务的启动流程以及 Controller 的四种不同 leader 选举机制。分区状态机、副本副本状态机以及对各种 listener 的处理将在后续的文章中展开。</p></div><p class="readmore"><a href="/2018/06/15/kafka-controller-start/">阅读更多</a></p></div><div class="post"><h2 class="post-title"><a href="/2018/05/01/kafka-replica-manager/">Kafka 源码解析之 ReplicaManager 详解（十五）</a></h2><div class="post-meta">2018-05-01</div><a data-disqus-identifier="2018/05/01/kafka-replica-manager/" href="/2018/05/01/kafka-replica-manager/#disqus_thread" class="disqus-comment-count"></a><div class="post-content"><p>前面几篇文章讲述了 LogManager 的实现、Produce 请求、Fetch 请求的处理以及副本同步机制的实现，Kafka 存储层的主要内容基本上算是讲完了（还有几个小块的内容后面会结合 Controller 再详细介绍）。本篇文章以 ReplicaManager 类为入口，通过对 ReplicaManager 的详解，顺便再把 Kafka 存储层的内容做一个简单的总结。</p></div><p class="readmore"><a href="/2018/05/01/kafka-replica-manager/">阅读更多</a></p></div><div class="post"><h2 class="post-title"><a href="/2018/04/29/kafka-replica-fetcher-thread/">Kafka 源码解析之副本同步机制实现（十四）</a></h2><div class="post-meta">2018-04-29</div><a data-disqus-identifier="2018/04/29/kafka-replica-fetcher-thread/" href="/2018/04/29/kafka-replica-fetcher-thread/#disqus_thread" class="disqus-comment-count"></a><div class="post-content"><p>在上篇文章中讲述了 Fetch 请求是如何处理的，其中包括来自副本同步的 Fetch 请求和 Consumer 的 Fetch 请求，副本同步是 Kafka 多副本机制（可靠性）实现的基础，它也是通过向 leader replica 发送 Fetch 请求来实现数据同步的。本篇文章我们就来看一下 Kafka 副本同步这块的内容，对于每个 broker 来说，它上面的 replica 对象，除了 leader 就是 follower，只要这台 broker 有 follower replica，broker 就会启动副本同步流程从 leader 同步数据，副本同步机制的实现是 Kafka Server 端非常重要的内容，在这篇文章中，主要会从以下几块来讲解：</p></div><p class="readmore"><a href="/2018/04/29/kafka-replica-fetcher-thread/">阅读更多</a></p></div><div class="post"><h2 class="post-title"><a href="/2018/04/15/kafka-server-handle-fetch-request/">Kafka 源码解析之 Server 端如何处理 Fetch 请求（十三）</a></h2><div class="post-meta">2018-04-15</div><a data-disqus-identifier="2018/04/15/kafka-server-handle-fetch-request/" href="/2018/04/15/kafka-server-handle-fetch-request/#disqus_thread" class="disqus-comment-count"></a><div class="post-content"><p>上一篇讲述完 Kafka 如何处理 Produce 请求以及日志写操作之后，这篇文章开始讲述 Kafka 如何处理 Fetch 请求以及日志读操作。日志的读写操作是 Kafka 存储层最重要的内容，本文会以 Server 端处理 Fetch 请求的过程为入口，一步步深入到底层的 Log 实例部分。与 Produce 请求不一样的地方是，对于 Fetch 请求，是有两种不同的来源：consumer 和 follower，consumer 读取数据与副本同步数据都是通过向 leader 发送 Fetch 请求来实现的，在对这两种不同情况处理过程中，其底层的实现是统一的，只是实现方法的参数不同而已，在本文中会详细讲述对这两种不同情况的处理。</p></div><p class="readmore"><a href="/2018/04/15/kafka-server-handle-fetch-request/">阅读更多</a></p></div><div class="post"><h2 class="post-title"><a href="/2018/03/18/kafka-server-handle-produce-request/">Kafka 源码解析之 Server 端如何处理 Produce 请求（十二）</a></h2><div class="post-meta">2018-03-18</div><a data-disqus-identifier="2018/03/18/kafka-server-handle-produce-request/" href="/2018/03/18/kafka-server-handle-produce-request/#disqus_thread" class="disqus-comment-count"></a><div class="post-content"><p>这部分想了很久应该怎么去写才能更容易让大家明白，本来是计划先把 Kafka 存储层 Log 这块的写操作处理流程先详细介绍一下，但是这块属于比较底层的部分，大家可能对于这部分在整个处理过程处在哪个位置并不是很清楚，所以还是准备以 Server 端如何处理 Producer Client 的 Produce 请求为入口。但是 Server 端的内容较多，本篇文章并不能全部涵盖，涉及到其他内容，在本篇文章暂时先不详细讲述，后面会再分析，本篇文章会以 Server 处理 produce 为主线，主要详细讲解 Kafka 存储层的内容。</p></div><p class="readmore"><a href="/2018/03/18/kafka-server-handle-produce-request/">阅读更多</a></p></div><div class="post"><h2 class="post-title"><a href="/2018/03/12/kafka-log-manager/">Kafka 源码解析之日志管理（十一）</a></h2><div class="post-meta">2018-03-12</div><a data-disqus-identifier="2018/03/12/kafka-log-manager/" href="/2018/03/12/kafka-log-manager/#disqus_thread" class="disqus-comment-count"></a><div class="post-content"><p>上篇文章在介绍完 Kafka 的 GroupCoordinator 之后，下面开始介绍 Kafka 存储层的内容，也就是 Kafka Server 端 Log 部分的内容，Log 部分是 Kafka 比较底层的代码，日志的读写、分段、清理和管理都是在这一部分完成的，内容还是比较多的，会分为三篇左右的文章介绍，本篇先介绍最简单的部分，主要是日志的基本概念、日志管理、日志刷新和日志清理四部分（后两个其实也属于日志管理，为便于讲解，这里分开讲述），日志的读写和分段将在下一篇讲述。</p></div><p class="readmore"><a href="/2018/03/12/kafka-log-manager/">阅读更多</a></p></div><div class="post"><h2 class="post-title"><a href="/2018/02/04/linux-mmap/">操作系统之共享对象学习</a></h2><div class="post-meta">2018-02-04</div><a data-disqus-identifier="2018/02/04/linux-mmap/" href="/2018/02/04/linux-mmap/#disqus_thread" class="disqus-comment-count"></a><div class="post-content"><p>在 Kafka 的存储层这部分代码时，看到了很多地方使用操作系统的共享内存机制，Kafka 中所有日志文件的索引都是使用了 <code>mmap</code> 做内存映射，<code>mmap</code> 这块刚好也是一个值得深入学习的知识点，于是就就深入地看了一下、做了一下总结，本文的内容主要来自《深入理解操作系统》第三版 9.8 存储器映射部分。</p></div><p class="readmore"><a href="/2018/02/04/linux-mmap/">阅读更多</a></p></div><div class="post"><h2 class="post-title"><a href="/2018/01/28/server-group-coordinator/">Kafka 源码解析之 GroupCoordinator 详解（十）</a></h2><div class="post-meta">2018-01-28</div><a data-disqus-identifier="2018/01/28/server-group-coordinator/" href="/2018/01/28/server-group-coordinator/#disqus_thread" class="disqus-comment-count"></a><div class="post-content"><p>突然发现距离上一篇文章，已经过去两个多月了，有两个月没有写博客了，之前定的是年前把这个系列写完，现在看来只能往后拖了，后面估计还有五篇文章左右，尽量在春节前完成吧。继续之前的内容开始讲解，这篇文章，主要是想把 GroupCoordinator 的内容总结一下，也算是开始了 Kafka Server 端的讲解，Kafka 的 Server 端主要有三块内容：GroupCoordinator、Controller 和 ReplicaManager，其中，GroupCoordinator 的内容是与 Consumer 端紧密结合在一起的，有一部分内容在前面已经断断续续介绍过，这里会做一个总结。</p></div><p class="readmore"><a href="/2018/01/28/server-group-coordinator/">阅读更多</a></p></div><div class="post"><h2 class="post-title"><a href="/2017/12/17/shawshank-redemption/">自我救赎</a></h2><div class="post-meta">2017-12-17</div><a data-disqus-identifier="2017/12/17/shawshank-redemption/" href="/2017/12/17/shawshank-redemption/#disqus_thread" class="disqus-comment-count"></a><div class="post-content"><p>今天是第三次刷<a href="https://movie.douban.com/subject/1292052/" target="_blank" rel="external">《肖生克的救赎》</a>，记得第一次看的时候应该是在大学，具体是哪一年级，已经忘记了，第二次看的时候隐隐约约记得应该是假期在家的时候看的。这部电影就是让人有一种：心里不爽的时候，刷一遍就豁然开朗。如果你真正投入其中，这部电影可能会引起你得共鸣。触及你内心的深处，它会让你思考：</p></div><p class="readmore"><a href="/2017/12/17/shawshank-redemption/">阅读更多</a></p></div><div class="post"><h2 class="post-title"><a href="/2017/11/19/consumer-two-summary/">Kafka 源码解析之 Consumer 两种 commit 机制和 partition 分配机制（九）</a></h2><div class="post-meta">2017-11-19</div><a data-disqus-identifier="2017/11/19/consumer-two-summary/" href="/2017/11/19/consumer-two-summary/#disqus_thread" class="disqus-comment-count"></a><div class="post-content"><p>紧接着上篇文章，这篇文章讲述 Consumer 提供的两种 commit 机制和两种 partition 分配机制，具体如何使用是需要用户结合具体的场景进行选择，本文讲述一下其底层实现。</p></div><p class="readmore"><a href="/2017/11/19/consumer-two-summary/">阅读更多</a></p></div><div class="post"><h2 class="post-title"><a href="/2017/11/18/consumer-subscribe/">Kafka 源码解析之 Consumer 两种订阅模式（八）</a></h2><div class="post-meta">2017-11-18</div><a data-disqus-identifier="2017/11/18/consumer-subscribe/" href="/2017/11/18/consumer-subscribe/#disqus_thread" class="disqus-comment-count"></a><div class="post-content"><p>在前面两篇 Kafka Consumer 的文章中，Consumer Poll 模型这部分基本上已经完整结束，Consumer 这块的文章计划是要写五篇，这篇是 Consumer 这块的第三篇，本来计划是要从其中的三个小块细节内容着手，这三个地方有一个相同之处，那就是在 Kafka Consumer 中都提供了两个不同的解决方案，但具体怎么去使用是需要用户根据自己的业务场景去配置，这里会讲述其底层的具体实现（但为了阅读得更为方便，本来计划的这篇文章将拆分为两篇来，第一篇先讲述第一点，后面两点放在一起讲述）。</p></div><p class="readmore"><a href="/2017/11/18/consumer-subscribe/">阅读更多</a></p></div><div class="post"><h2 class="post-title"><a href="/2017/11/11/consumer-pollonce/">Kafka 源码解析之 Consumer Poll 模型（七）</a></h2><div class="post-meta">2017-11-11</div><a data-disqus-identifier="2017/11/11/consumer-pollonce/" href="/2017/11/11/consumer-pollonce/#disqus_thread" class="disqus-comment-count"></a><div class="post-content"><p>在上一篇问文章中已经介绍一个 Consumer 实例如何加入到一个 group 中，它是 Consumer Poll 模型第一步要做的事件，本文会完整讲述一个 Consumer 实例在 poll 模型过程中会做哪些事情，只有理解了 poll 模型才能更好地理解 Consumer 端的处理逻辑。</p></div><p class="readmore"><a href="/2017/11/11/consumer-pollonce/">阅读更多</a></p></div><div class="post"><h2 class="post-title"><a href="/2017/10/22/consumer-join-group/">Kafka 源码解析之 Consumer 如何加入一个 Group（六）</a></h2><div class="post-meta">2017-10-22</div><a data-disqus-identifier="2017/10/22/consumer-join-group/" href="/2017/10/22/consumer-join-group/#disqus_thread" class="disqus-comment-count"></a><div class="post-content"><p>距离上一篇博客（2017-09-10），到现在已经过去一个多月了，理论上这篇文章在上个月就应该写完，无奈拖延症又犯了，一直以这部分过于复杂为借口拖了好久，这两天逼了自己一把，先整理出其中的一篇，后续要加把劲，要不然今年的年度计划（年底前把这个系列写完）就完不成了，废话到此为止，下面步入正文。在 Kafka 中，Consumer 的复杂度要比 producer 高出很多，对于 Producer 而言，没有 producer 组的概念的、也不需要 care offset 等问题，而 Consumer 就不一样了，它需要关注的内容很多，需要考虑分布式消费（Consumer Group），为了防止重复消费或者部分数据未消费需要考虑 offset，这些都对 Consumer 的设计以及 Server 对其处理提出了很高的要求。本来计划是先进行综述，然后再分别介绍各个模块，现在打算反过来，先介绍各个模块，最后再进行综述，本篇为 Consumer 源码分析开篇，先从一个 Consumer 实例如何加入一个 Consumer Group 讲起。</p></div><p class="readmore"><a href="/2017/10/22/consumer-join-group/">阅读更多</a></p></div><div class="post"><h2 class="post-title"><a href="/2017/09/10/produccer-end/">Kafka 源码解析之 Producer 单 Partition 顺序性实现及配置说明（五）</a></h2><div class="post-meta">2017-09-10</div><a data-disqus-identifier="2017/09/10/produccer-end/" href="/2017/09/10/produccer-end/#disqus_thread" class="disqus-comment-count"></a><div class="post-content"><p>今天把 Kafka Producer 最后一部分给讲述一下，Producer 大部分内容都已经在前面几篇文章介绍过了，这里简单做个收尾，但并不是对前面的总结，本文从两块来讲述：RecordAccumulator 类的实现、Kafka Producer 如何保证其顺序性以及 Kafka Producer 的配置说明，每个 Producer 线程都会有一个 RecordAccumulator 对象，它负责缓存要发送 RecordBatch、记录发送的状态并且进行相应的处理，这里会详细讲述 Kafka Producer 如何保证单 Partition 的有序性。最后，简单介绍一下 Producer 的参数配置说明，只有正确地理解 Producer 相关的配置参数，才能更好地使用 Producer，发挥其相应的作用。</p></div><p class="readmore"><a href="/2017/09/10/produccer-end/">阅读更多</a></p></div><div class="post"><h2 class="post-title"><a href="/2017/09/04/kafka-best-pratice/">Kafka 最佳实践【译】</a></h2><div class="post-meta">2017-09-04</div><a data-disqus-identifier="2017/09/04/kafka-best-pratice/" href="/2017/09/04/kafka-best-pratice/#disqus_thread" class="disqus-comment-count"></a><div class="post-content"><p>这里翻译一篇关于 Kafka 实践的文章，内容来自 DataWorks Summit/Hadoop Summit（<a href="https://dataworkssummit.com/munich-2017/sessions/apache-kafka-best-practices/" target="_blank" rel="external">Hadoop Summit</a>）上一篇分享，PPT 见<a href="https://www.slideshare.net/HadoopSummit/apache-kafka-best-practices" target="_blank" rel="external">Apache Kafka Best Pratices</a>，里面讲述了很多关于 Kafka 配置、监控、优化的内容，绝对是在实践中总结出的精华，有很大的借鉴参考意义，本文主要是根据 PPT 的内容进行翻译及适当补充。</p></div><p class="readmore"><a href="/2017/09/04/kafka-best-pratice/">阅读更多</a></p></div><div class="post"><h2 class="post-title"><a href="/2017/08/22/producer-nio/">Kafka 源码解析之 Producer NIO 网络模型（四）</a></h2><div class="post-meta">2017-08-22</div><a data-disqus-identifier="2017/08/22/producer-nio/" href="/2017/08/22/producer-nio/#disqus_thread" class="disqus-comment-count"></a><div class="post-content"><p>本文是 Kafka 源码解析的第四篇，在写这篇文章之前，专门看了一下 Java NIO 相关的内容，只有理解了 Java NIO 模型才能更好地理解 NIO 在 Kafka 中是如何应用的以及 Producer 如何利用 Java NIO 构建其网络模型（不了解的，可以先看一下上一篇文章：<a href="http://matt33.com/2017/08/12/java-nio/">谈一谈 Java IO 模型</a>），同时，本文也是对 Producer 整个流程的一个总结，主要讲述以下两个问题：</p></div><p class="readmore"><a href="/2017/08/22/producer-nio/">阅读更多</a></p></div><div class="post"><h2 class="post-title"><a href="/2017/08/12/java-nio/">谈一谈 Java IO 模型</a></h2><div class="post-meta">2017-08-12</div><a data-disqus-identifier="2017/08/12/java-nio/" href="/2017/08/12/java-nio/#disqus_thread" class="disqus-comment-count"></a><div class="post-content"><p>Java IO 模型对于 Java 开发工程师来说，是日常工作中经常接触的内容，特别是随着分布式系统的兴起，IO 也显得越来越重要，Java 的 IO 模型本质上还是利用操作系统提供的接口来实现，不熟悉这一部分内容的话，可以先看一下上篇文章<a href="http://matt33.com/2017/08/06/unix-io/">Unix 网络 IO 模型及 Linux 的 IO 多路复用模型</a>，本文跟上篇的内容是紧密相连的，特别是本文的重点 —— Java NIO 部分，其底层原理就是 UNIX 的 IO 多路复用，IO 多路复用在上篇文章中讲述了很多。</p></div><p class="readmore"><a href="/2017/08/12/java-nio/">阅读更多</a></p></div><div class="post"><h2 class="post-title"><a href="/2017/08/06/unix-io/">Unix 网络 IO 模型及 Linux 的 IO 多路复用模型</a></h2><div class="post-meta">2017-08-06</div><a data-disqus-identifier="2017/08/06/unix-io/" href="/2017/08/06/unix-io/#disqus_thread" class="disqus-comment-count"></a><div class="post-content"><p>近段在看 Kafka 的网络模型时，遇到了很多 Java NIO 的内容，在学习 Java NIO 的过程中，发现需要把 UNIX 的这几种网络 IO 模型以及 Linux 的 IO 多路复用理解清楚，才能更好地理解 Java NIO，本文就是在学习 UNIX 的五种网络 IO 模型以及 Linux IO 多路复用模型后，做的一篇总结。</p></div><p class="readmore"><a href="/2017/08/06/unix-io/">阅读更多</a></p></div><div class="post"><h2 class="post-title"><a href="/2017/07/21/kafka-topic-create/">Kafka 源码解析之 topic 创建过程（三）</a></h2><div class="post-meta">2017-07-21</div><a data-disqus-identifier="2017/07/21/kafka-topic-create/" href="/2017/07/21/kafka-topic-create/#disqus_thread" class="disqus-comment-count"></a><div class="post-content"><p>本文是 Kafka 源码解析的第三篇，主要讲述一个 topic 的创建过程，从 topic 是如何创建到 topic 真正创建成功的中间详细过程，文章主要内容可以分为以下几个部分：</p></div><p class="readmore"><a href="/2017/07/21/kafka-topic-create/">阅读更多</a></p></div><div class="post"><h2 class="post-title"><a href="/2017/07/16/linux-system-cmd/">Linux 常用的一些系统命令</a></h2><div class="post-meta">2017-07-16</div><a data-disqus-identifier="2017/07/16/linux-system-cmd/" href="/2017/07/16/linux-system-cmd/#disqus_thread" class="disqus-comment-count"></a><div class="post-content"><p>文章的内容，基本来自<a href="http://www.cnblogs.com/peida/tag/%E6%AF%8F%E6%97%A5%E4%B8%80linux%E5%91%BD%E4%BB%A4/" target="_blank" rel="external">每日一个 linux 命令</a>，选取了几个在工作常用的命令，有：top、iostat、netstat 、free 和 ps，本文的主要目的是在学习这几条命令的过程中，简单做一些记录，便于日后工作中更加熟练地使用这些命令。</p></div><p class="readmore"><a href="/2017/07/16/linux-system-cmd/">阅读更多</a></p></div><nav class="page-navigator"><a class="extend prev" rel="prev" href="/">上一页</a><a class="page-number" href="/">1</a><span class="page-number current">2</span><a class="page-number" href="/page/3/">3</a><a class="page-number" href="/page/4/">4</a><span class="space">&hellip;</span><a class="page-number" href="/page/6/">6</a><a class="extend next" rel="next" href="/page/3/">下一页</a></nav><script id="dsq-count-scr" src="//http-matt33-com.disqus.com/count.js" async></script></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><div class="widget-title"><i class="fa fa-weibo"> 微博</i></div><iframe width="100%" height="90" class="share_self"  frameborder="0" scrolling="no" src="http://widget.weibo.com/weiboshow/index.php?language=&width=0&height=100&fansRow=1&ptype=1&speed=0&skin=1&isTitle=0&noborder=1&isWeibo=0&isFans=0&uid=2650396571&verifier=f2f0e397&colors=D8D8D8,ffffff,666666,0082cb,ecfbfd&dpc=1"></iframe></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> 分类</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/书屋/">书屋</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/影如人生/">影如人生</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/技术/">技术</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/旅行/">旅行</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/转载/">转载</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/随笔/">随笔</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> 标签</i></div><div class="tagcloud"><a href="/tags/mac/" style="font-size: 15px;">mac</a> <a href="/tags/kafka/" style="font-size: 15px;">kafka</a> <a href="/tags/database/" style="font-size: 15px;">database</a> <a href="/tags/storm/" style="font-size: 15px;">storm</a> <a href="/tags/java/" style="font-size: 15px;">java</a> <a href="/tags/linux/" style="font-size: 15px;">linux</a> <a href="/tags/learn/" style="font-size: 15px;">learn</a> <a href="/tags/hexo/" style="font-size: 15px;">hexo</a> <a href="/tags/bug/" style="font-size: 15px;">bug</a> <a href="/tags/cv/" style="font-size: 15px;">cv</a> <a href="/tags/maven/" style="font-size: 15px;">maven</a> <a href="/tags/travel/" style="font-size: 15px;">travel</a> <a href="/tags/hadoop/" style="font-size: 15px;">hadoop</a> <a href="/tags/思考/" style="font-size: 15px;">思考</a> <a href="/tags/tcp/" style="font-size: 15px;">tcp</a> <a href="/tags/电影随想/" style="font-size: 15px;">电影随想</a> <a href="/tags/随笔/" style="font-size: 15px;">随笔</a> <a href="/tags/转载/" style="font-size: 15px;">转载</a> <a href="/tags/algorithm/" style="font-size: 15px;">algorithm</a> <a href="/tags/jvm/" style="font-size: 15px;">jvm</a> <a href="/tags/web/" style="font-size: 15px;">web</a> <a href="/tags/分布式系统/" style="font-size: 15px;">分布式系统</a> <a href="/tags/rpc/" style="font-size: 15px;">rpc</a> <a href="/tags/thrift/" style="font-size: 15px;">thrift</a> <a href="/tags/bk/" style="font-size: 15px;">bk</a> <a href="/tags/zookeeper/" style="font-size: 15px;">zookeeper</a> <a href="/tags/calcite/" style="font-size: 15px;">calcite</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> 最新文章</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2019/03/17/apache-calcite-planner/">Apache Calcite 优化器详解（二）</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/03/07/apache-calcite-process-flow/">Apache Calcite 处理流程详解（一）</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/11/21/effective-learning/">如何高效学习</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/11/04/kafka-transaction/">Kafka Exactly-Once 之事务性实现</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/10/24/kafka-idempotent/">Kafka 事务性之幂等性实现</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/10/19/bk-cluster-install-and-use/">BookKeeper 集群搭建及使用</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/09/01/yarn-architecture-learn/">YARN 架构学习总结</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/08/01/system-learn-summary/">如何学习开源项目</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/07/28/jvm-cms/">JVM 之 ParNew 和 CMS 日志分析</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/07/15/hdfs-architecture-learn/">HDFS 架构学习总结</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-external-link"> 友情链接</i></div><ul></ul><a href="http://tech.meituan.com/" title="美团点评技术团队" target="_blank">美团点评技术团队</a><ul></ul><a href="http://jm.taobao.org/" title="阿里中间件团队博客" target="_blank">阿里中间件团队博客</a><ul></ul><a href="http://www.jianshu.com/" title="简书" target="_blank">简书</a></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">© <a href="/." rel="nofollow">Matt's Blog 柳年思水.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a id="rocket" href="#top" class="show"></a><script type="text/javascript" src="/js/totop.js?v=0.0.0" async></script><div class="analytics"><script>var cnzz_protocol = (("https:" == document.location.protocol) ? " https://" : " http://");
document.write(unescape("%3Cspan id='cnzz_stat_icon_1256517224'%3E%3C/span%3E%3Cscript src='" + cnzz_protocol + "s95.cnzz.com/z_stat.php%3Fid%3D1256517224%26show%3Dpic' type='text/javascript'%3E%3C/script%3E"));</script></div><script type="text/javascript" src="//cdn.bootcss.com/fancybox/2.1.5/jquery.fancybox.pack.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=0.0.0" async></script><link rel="stylesheet" type="text/css" href="/css/jquery.fancybox.css?v=0.0.0"><script>(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
ga('create','UA-64518924-1','auto');ga('send','pageview');
</script><script>var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "//hm.baidu.com/hm.js?5cf44757fa0d23bc7637935e44a9104a";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
  })();
</script><script type="text/javascript" src="/js/codeblock-resizer.js?v=0.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=0.0.0"></script></div></body></html>