<!DOCTYPE html><html lang="zh-CN"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description" content="与一群有趣的人，做一些有趣的事."><title>MapReduce之Shuffle过程详述 | Matt's Blog</title><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/normalize/4.2.0/normalize.min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/0.6.0/pure-min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/0.6.0/grids-responsive-min.css"><link rel="stylesheet" type="text/css" href="/css/style.css?v=0.0.0"><link rel="stylesheet" href="//cdn.bootcss.com/font-awesome/4.6.3/css/font-awesome.min.css"><script type="text/javascript" src="//cdn.bootcss.com/jquery/3.0.0/jquery.min.js"></script><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"><link rel="alternate" type="application/atom+xml" href="/atom.xml"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">MapReduce之Shuffle过程详述</h1><a id="logo" href="/.">Matt's Blog</a><p class="description">王蒙</p></div><div id="nav-menu"><a href="/." class="current"><i class="fa fa-home"> 首页</i></a><a href="/archives/"><i class="fa fa-archive"> 归档</i></a><a href="/about/"><i class="fa fa-user"> 关于</i></a><a href="/atom.xml"><i class="fa fa-rss"> 订阅</i></a></div></div><div id="layout" class="pure-g"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">MapReduce之Shuffle过程详述</h1><div class="post-meta">Mar 2, 2016<span> | </span><span class="category"><a href="/categories/技术/">技术</a></span><span> | </span><span class="post-count">4,017</span><span> 字</span><script src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js" async></script><span id="busuanzi_container_page_pv"> | <span id="busuanzi_value_page_pv"></span><span> Times</span></span></div><a data-disqus-identifier="2016/03/02/hadoop-shuffle/" href="/2016/03/02/hadoop-shuffle/#disqus_thread" class="disqus-comment-count"></a><div class="clear"><div id="toc" class="toc-article"><div class="toc-title">文章目录</div><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#写在前面"><span class="toc-number">1.</span> <span class="toc-text">写在前面</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#总述"><span class="toc-number">2.</span> <span class="toc-text">总述</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Map"><span class="toc-number">3.</span> <span class="toc-text">Map</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#输入"><span class="toc-number">3.1.</span> <span class="toc-text">输入</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Partition"><span class="toc-number">3.2.</span> <span class="toc-text">Partition</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#spill（溢写）：sort-amp-combiner"><span class="toc-number">3.3.</span> <span class="toc-text">spill（溢写）：sort & combiner</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#merge"><span class="toc-number">3.4.</span> <span class="toc-text">merge</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#内存缓冲区"><span class="toc-number">3.5.</span> <span class="toc-text">内存缓冲区</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Reduce"><span class="toc-number">4.</span> <span class="toc-text">Reduce</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#copy过程"><span class="toc-number">4.1.</span> <span class="toc-text">copy过程</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#merge过程"><span class="toc-number">4.2.</span> <span class="toc-text">merge过程</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#reducer的输入文件"><span class="toc-number">4.3.</span> <span class="toc-text">reducer的输入文件</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#参考"><span class="toc-number">5.</span> <span class="toc-text">参考</span></a></li></ol></div></div><div class="post-content"><h1 id="写在前面"><a href="#写在前面" class="headerlink" title="写在前面"></a>写在前面</h1><p>MapReduce作为Hadoop的编程框架，对于大数据开发或者想要接触大数据开发的开发者来说，是必须要掌握的，它是一种经典大数据计算框架，现在有很多开源项目的内部实现都会直接或间接地借鉴了MR过程的实现。我在经过了一些hadoop项目的开发，然后前几天又系统地学习MapReduc内部实现过程，尤其是学习中间的Shuffle过程之后，准备对这一块做一下总结，希望这篇文章能给需要的人带来一些帮助（文中Shuffle的分析还是以Hadoop1.0为例，这个跟2.0的区别并不是很大）。</p>
<h1 id="总述"><a href="#总述" class="headerlink" title="总述"></a>总述</h1><p>对于MapReduce作业，完整的作业运行流程，这里借用刘军老师的<a href="http://item.jd.com/11315351.html" target="_blank" rel="external">Hadoop大数据处理</a>中的一张图：</p>
<p><img src="/images/2016-03-02-HadoopShuffle/hadoop.png" alt="hadoop"></p>
<p>完整过程应该是分为7部分，分别是：</p>
<ol>
<li>作业启动：开发者通过控制台启动作业；</li>
<li>作业初始化：这里主要是切分数据、创建作业和提交作业，与第三步紧密相联；</li>
<li>作业/任务调度：对于1.0版的Hadoop来说就是JobTracker来负责任务调度，对于2.0版的Hadoop来说就是Yarn中的Resource Manager负责整个系统的资源管理与分配，Yarn可以参考IBM的一篇博客<a href="https://www.ibm.com/developerworks/cn/opensource/os-cn-hadoop-yarn/" target="_blank" rel="external">Hadoop新MapReduce框架Yarn详解</a>；</li>
<li>Map任务；</li>
<li>Shuffle；</li>
<li>Reduce任务；</li>
<li>作业完成：通知开发者任务完成。</li>
</ol>
<p>而这其中最主要的MapReduce过程，主要是第4、5、6步三部分，这也是本篇博客重点讨论的地方，详细作用如下：</p>
<ol>
<li><strong>Map</strong>:数据输入,做初步的处理,输出形式的中间结果；</li>
<li><strong>Shuffle</strong>:按照partition、key对中间结果进行排序合并,输出给reduce线程；</li>
<li><strong>Reduce</strong>:对相同key的输入进行最终的处理,并将结果写入到文件中。</li>
</ol>
<p>这里先给出官网上关于这个过程的经典流程图：</p>
<p><img src="/images/2016-03-02-HadoopShuffle/mapreduce.png" alt="mapreduce"></p>
<p>上图是把MapReduce过程分为两个部分，而实际上从两边的Map和Reduce到中间的那一大块都属于Shuffle过程，也就是说，Shuffle过程有一部分是在Map端，有一部分是在Reduce端，下文也将会分两部分来介绍Shuffle过程。</p>
<p>对于Hadoop集群，当我们在运行作业时，大部分的情况下，map task与reduce task的执行是分布在不同的节点上的，因此，很多情况下，reduce执行时需要跨节点去拉取其他节点上的map task结果，这样造成了集群内部的网络资源消耗很严重，而且在节点的内部，相比于内存，磁盘IO对性能的影响是非常严重的。如果集群中运行的作业有很多，那么task的执行对于集群内部网络的资源消费非常大。因此，我们对于MapRedue作业Shuffle过程的期望是：</p>
<ul>
<li>完整地从map task端拉取数据到Reduce端；</li>
<li>在跨节点拉取数据时，尽可能地减少对带宽的不必要消耗；</li>
<li>减少磁盘IO对task执行的影响。</li>
</ul>
<h1 id="Map"><a href="#Map" class="headerlink" title="Map"></a>Map</h1><p>在进行海量数据处理时，外存文件数据<strong>I/O访问</strong>会成为一个制约系统性能的瓶颈，因此，Hadoop的Map过程实现的一个重要原则就是：<strong>计算靠近数据</strong>，这里主要指两个方面：</p>
<ol>
<li>代码靠近数据：<ul>
<li>原则：本地化数据处理（locality），即一个计算节点尽可能处理本地磁盘上所存储的数据；</li>
<li>尽量选择数据所在DataNode启动Map任务；</li>
<li>这样可以减少数据通信，提高计算效率；</li>
</ul>
</li>
<li>数据靠近代码：<ul>
<li>当本地没有数据处理时，尽可能从同一机架或最近其他节点传输数据进行处理（host选择算法）。</li>
</ul>
</li>
</ol>
<p>下面，我们分块去介绍Hadoop的Map过程，map的经典流程图如下：</p>
<p><img src="/images/2016-03-02-HadoopShuffle/map-shuffle.png" alt="map-shuffle"></p>
<h2 id="输入"><a href="#输入" class="headerlink" title="输入"></a>输入</h2><ol>
<li>map task只读取split分片，split与block（hdfs的最小存储单位，默认为64MB）可能是一对一也能是一对多，但是对于一个split只会对应一个文件的一个block或多个block，不允许一个split对应多个文件的多个block；</li>
<li>这里切分和输入数据的时会涉及到InputFormat的文件切分算法和host选择算法。</li>
</ol>
<p>文件切分算法，主要用于确定InputSplit的个数以及每个InputSplit对应的数据段。FileInputFormat以文件为单位切分生成InputSplit，对于每个文件，由以下三个属性值决定其对应的InputSplit的个数：</p>
<ul>
<li>goalSize： 它是根据用户期望的InputSplit数目计算出来的，即totalSize/numSplits。其中，totalSize为文件的总大小；numSplits为用户设定的Map Task个数，默认情况下是1；</li>
<li>minSize：InputSplit的最小值，由配置参数<code>mapred.min.split.size</code>确定，默认是1；</li>
<li>blockSize：文件在hdfs中存储的block大小，不同文件可能不同，默认是64MB。</li>
</ul>
<p>这三个参数共同决定InputSplit的最终大小，计算方法如下：</p>
<p><code>splitSize=max{minSize, min{gogalSize,blockSize}}</code></p>
<p>FileInputFormat的host选择算法参考《Hadoop技术内幕-深入解析MapReduce架构设计与实现原理》的p50.</p>
<h2 id="Partition"><a href="#Partition" class="headerlink" title="Partition"></a>Partition</h2><ul>
<li>作用：将map的结果发送到相应的reduce端，总的partition的数目等于reducer的数量。</li>
<li>实现功能：<ol>
<li>map输出的是key/value对，决定于当前的mapper的part交给哪个reduce的方法是：mapreduce提供的Partitioner接口，对key进行hash后，再以reducetask数量取模，然后到指定的job上（<strong>HashPartitioner</strong>，可以通过<code>job.setPartitionerClass(MyPartition.class)</code>自定义）。</li>
<li>然后将数据写入到内存缓冲区，缓冲区的作用是批量收集map结果，减少磁盘IO的影响。key/value对以及Partition的结果都会被写入缓冲区。在写入之前，key与value值都会被序列化成字节数组。</li>
</ol>
</li>
<li>要求：负载均衡，效率；</li>
</ul>
<h2 id="spill（溢写）：sort-amp-combiner"><a href="#spill（溢写）：sort-amp-combiner" class="headerlink" title="spill（溢写）：sort &amp; combiner"></a>spill（溢写）：sort &amp; combiner</h2><ul>
<li>作用：把内存缓冲区中的数据写入到本地磁盘，在写入本地磁盘时先按照partition、再按照key进行排序（<code>quick sort</code>）；</li>
<li>注意：<ol>
<li>这个spill是由<strong>另外单独的线程</strong>来完成，不影响往缓冲区写map结果的线程；</li>
<li>内存缓冲区默认大小限制为100MB，它有个溢写比例（<code>spill.percent</code>），默认为0.8，当缓冲区的数据达到阈值时，溢写线程就会启动，先锁定这80MB的内存，执行溢写过程，maptask的输出结果还可以往剩下的20MB内存中写，互不影响。然后再重新利用这块缓冲区，因此Map的内存缓冲区又叫做<strong>环形缓冲区</strong>（两个指针的方向不会变，下面会详述）；</li>
<li>在将数据写入磁盘之前，先要对要写入磁盘的数据进行一次<strong>排序</strong>操作，先按<code>&lt;key,value,partition&gt;</code>中的partition分区号排序，然后再按key排序，这个就是<strong>sort操作</strong>，最后溢出的小文件是分区的，且同一个分区内是保证key有序的；</li>
</ol>
</li>
</ul>
<p><strong>combine</strong>：执行combine操作要求开发者必须在程序中设置了combine（程序中通过<code>job.setCombinerClass(myCombine.class)</code>自定义combine操作）。</p>
<ul>
<li>程序中有两个阶段可能会执行combine操作：<ol>
<li>map输出数据根据分区排序完成后，在写入文件之前会执行一次combine操作（前提是作业中设置了这个操作）；</li>
<li>如果map输出比较大，溢出文件个数大于3（此值可以通过属性<code>min.num.spills.for.combine</code>配置）时，在merge的过程（多个spill文件合并为一个大文件）中还会执行combine操作；</li>
</ol>
</li>
<li>combine主要是把形如<code>&lt;aa,1&gt;,&lt;aa,2&gt;</code>这样的key值相同的数据进行计算，计算规则与reduce一致，比如：当前计算是求key对应的值求和，则combine操作后得到<code>&lt;aa,3&gt;</code>这样的结果。</li>
<li>注意事项：不是每种作业都可以做combine操作的，只有满足以下条件才可以：<ol>
<li>reduce的输入输出类型都一样，因为combine本质上就是reduce操作；</li>
<li>计算逻辑上，combine操作后不会影响计算结果，像求和就不会影响；</li>
</ol>
</li>
</ul>
<h2 id="merge"><a href="#merge" class="headerlink" title="merge"></a>merge</h2><ul>
<li>merge过程：当map很大时，每次溢写会产生一个spill_file，这样会有多个spill_file，而最终的一个map task输出只有一个文件，因此，最终的结果输出之前会对多个中间过程进行多次溢写文件（spill_file）的合并，此过程就是merge过程。也即是，待Map Task任务的所有数据都处理完后，会对任务产生的所有中间数据文件做一次合并操作，以确保一个Map Task最终只生成一个中间数据文件。</li>
<li>注意：<ol>
<li>如果生成的文件太多，可能会执行多次合并，每次最多能合并的文件数默认为10，可以通过属性<code>min.num.spills.for.combine</code>配置；</li>
<li>多个溢出文件合并时，会进行一次排序，排序算法是<strong>多路归并排序</strong>；</li>
<li>是否还需要做combine操作，一是看是否设置了combine，二是看溢出的文件数是否大于等于3；</li>
<li>最终生成的文件格式与单个溢出文件一致，也是按分区顺序存储，并且输出文件会有一个对应的索引文件，记录每个分区数据的起始位置，长度以及压缩长度，这个索引文件名叫做<code>file.out.index</code>。</li>
</ol>
</li>
</ul>
<h2 id="内存缓冲区"><a href="#内存缓冲区" class="headerlink" title="内存缓冲区"></a>内存缓冲区</h2><ol>
<li>在Map Task任务的业务处理方法map()中，最后一步通过<code>OutputCollector.collect(key,value)</code>或<code>context.write(key,value)</code>输出Map Task的中间处理结果，在相关的<code>collect(key,value)</code>方法中，会调用<code>Partitioner.getPartition(K2 key, V2 value, int numPartitions)</code>方法获得输出的key/value对应的分区号(分区号可以认为对应着一个要执行Reduce Task的节点)，然后将<code>&lt;key,value,partition&gt;</code>暂时保存在内存中的MapOutputBuffe内部的环形数据缓冲区，该缓冲区的默认大小是100MB，可以通过参数<code>io.sort.mb</code>来调整其大小。</li>
<li>当缓冲区中的数据使用率达到一定阀值后，触发一次Spill操作，将环形缓冲区中的部分数据写到磁盘上，生成一个临时的Linux本地数据的spill文件；然后在缓冲区的使用率再次达到阀值后，再次生成一个spill文件。直到数据处理完毕，在磁盘上会生成很多的临时文件。</li>
<li>缓存有一个阀值比例配置，当达到整个缓存的这个比例时，会触发spill操作；触发时，map输出还会接着往剩下的空间写入，但是写满的空间会被锁定，数据溢出写入磁盘。当这部分溢出的数据写完后，空出的内存空间可以接着被使用，形成像环一样的被循环使用的效果，所以又叫做<strong>环形内存缓冲区</strong>；</li>
<li>MapOutputBuffe内部存数的数据采用了两个索引结构，涉及三个环形内存缓冲区。下来看一下两级索引结构：</li>
</ol>
<p><img src="/images/2016-03-02-HadoopShuffle/buffer.jpg" alt="buffer"></p>
<p><strong>写入到缓冲区的数据采取了压缩算法 <a href="http://www.cnblogs.com/edisonchou/p/4298423.html" target="_blank" rel="external">http://www.cnblogs.com/edisonchou/p/4298423.html</a></strong><br>这三个环形缓冲区的含义分别如下：</p>
<ol>
<li><strong>kvoffsets</strong>缓冲区：也叫偏移量索引数组，用于保存<code>key/value</code>信息在位置索引 <code>kvindices</code> 中的偏移量。当 <code>kvoffsets</code> 的使用率超过 <code>io.sort.spill.percent</code> (默认为80%)后，便会触发一次 SpillThread 线程的“溢写”操作，也就是开始一次 Spill 阶段的操作。</li>
<li><strong>kvindices</strong>缓冲区：也叫位置索引数组，用于保存 <code>key/value</code> 在数据缓冲区 <code>kvbuffer</code> 中的起始位置。</li>
<li><strong>kvbuffer</strong>即数据缓冲区：用于保存实际的 <code>key/value</code> 的值。默认情况下该缓冲区最多可以使用 <code>io.sort.mb</code> 的95%，当 <code>kvbuffer</code> 使用率超过 <code>io.sort.spill.percent</code> (默认为80%)后，便会出发一次 SpillThread 线程的“溢写”操作，也就是开始一次 Spill 阶段的操作。</li>
</ol>
<p>写入到本地磁盘时，对数据进行排序，实际上是对<strong>kvoffsets</strong>这个偏移量索引数组进行排序。</p>
<h1 id="Reduce"><a href="#Reduce" class="headerlink" title="Reduce"></a>Reduce</h1><p>Reduce过程的经典流程图如下：</p>
<p><img src="/images/2016-03-02-HadoopShuffle/reduce-shuffle.png" alt="reduce-shuffle"></p>
<h2 id="copy过程"><a href="#copy过程" class="headerlink" title="copy过程"></a>copy过程</h2><ul>
<li>作用：拉取数据；</li>
<li>过程：Reduce进程启动一些数据copy线程(<code>Fetcher</code>)，通过HTTP方式请求map task所在的TaskTracker获取map task的输出文件。因为这时map task早已结束，这些文件就归TaskTracker管理在本地磁盘中。</li>
<li>默认情况下，当整个MapReduce作业的所有已执行完成的Map Task任务数超过Map Task总数的5%后，JobTracker便会开始调度执行Reduce Task任务。然后Reduce Task任务默认启动<code>mapred.reduce.parallel.copies</code>(默认为5）个MapOutputCopier线程到已完成的Map Task任务节点上分别copy一份属于自己的数据。 这些copy的数据会首先保存的内存缓冲区中，当内冲缓冲区的使用率达到一定阀值后，则写到磁盘上。</li>
</ul>
<p><strong>内存缓冲区</strong></p>
<ul>
<li>这个内存缓冲区大小的控制就不像map那样可以通过<code>io.sort.mb</code>来设定了，而是通过另外一个参数来设置：<code>mapred.job.shuffle.input.buffer.percent（default 0.7）</code>， 这个参数其实是一个百分比，意思是说，shuffile在reduce内存中的数据最多使用内存量为：0.7 × <code>maxHeap of reduce task</code>。</li>
<li>如果该reduce task的最大heap使用量（通常通过<code>mapred.child.java.opts</code>来设置，比如设置为-Xmx1024m）的一定比例用来缓存数据。默认情况下，reduce会使用其heapsize的70%来在内存中缓存数据。如果reduce的heap由于业务原因调整的比较大，相应的缓存大小也会变大，这也是为什么reduce用来做缓存的参数是一个百分比，而不是一个固定的值了。</li>
</ul>
<h2 id="merge过程"><a href="#merge过程" class="headerlink" title="merge过程"></a>merge过程</h2><ul>
<li>Copy过来的数据会先放入内存缓冲区中，这里的缓冲区大小要比 map 端的更为灵活，它基于 JVM 的<code>heap size</code>设置，因为 Shuffle 阶段 Reducer 不运行，所以应该把绝大部分的内存都给 Shuffle 用。</li>
<li>这里需要强调的是，merge 有三种形式：1)内存到内存  2)内存到磁盘  3)磁盘到磁盘。默认情况下第一种形式是不启用的。当内存中的数据量到达一定阈值，就启动内存到磁盘的 merge（图中的第一个merge，之所以进行merge是因为reduce端在从多个map端copy数据的时候，并没有进行sort，只是把它们加载到内存，当达到阈值写入磁盘时，需要进行merge） 。这和map端的很类似，这实际上就是溢写的过程，在这个过程中如果你设置有Combiner，它也是会启用的，然后在磁盘中生成了众多的溢写文件，这种merge方式一直在运行，直到没有 map 端的数据时才结束，然后才会启动第三种磁盘到磁盘的 merge （图中的第二个merge）方式生成最终的那个文件。</li>
<li>在远程copy数据的同时，Reduce Task在后台启动了两个后台线程对内存和磁盘上的数据文件做合并操作，以防止内存使用过多或磁盘生的文件过多。</li>
</ul>
<h2 id="reducer的输入文件"><a href="#reducer的输入文件" class="headerlink" title="reducer的输入文件"></a>reducer的输入文件</h2><ul>
<li>merge的最后会生成一个文件，大多数情况下存在于磁盘中，但是需要将其放入内存中。当reducer 输入文件已定，整个 Shuffle 阶段才算结束。然后就是 Reducer 执行，把结果放到 HDFS 上。</li>
</ul>
<hr>
<h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><ol>
<li><a href="http://vdisk.weibo.com/u/1853811305" target="_blank" rel="external">北邮刘军老师的Hadoop课件</a></li>
<li><a href="http://blog.csdn.net/dianacody/article/details/39502917" target="_blank" rel="external">分Map和Redcue两部分介绍</a></li>
<li><a href="http://flyingdutchman.iteye.com/blog/1879642" target="_blank" rel="external">内存缓冲区的介</a></li>
<li>内存缓冲区以及map的各个阶段介绍:<a href="http://xigan.blog.51cto.com/5200121/1163820" target="_blank" rel="external">mapreduce shuffle过程问答</a></li>
<li><a href="http://blog.csdn.net/ebay/article/details/45722263" target="_blank" rel="external">MapReduce详细过程</a></li>
<li><a href="http://zheming.wang/hadoop-mapreduce-zhi-xing-liu-cheng-xiang-jie.html" target="_blank" rel="external">http://zheming.wang/hadoop-mapreduce-zhi-xing-liu-cheng-xiang-jie.html</a></li>
<li>hadoop中的一些压缩算法，<a href="http://www.cnblogs.com/edisonchou/p/4298423.html" target="_blank" rel="external">http://www.cnblogs.com/edisonchou/p/4298423.html</a></li>
</ol>
</div><script type="text/javascript" src="/js/share.js?v=0.0.0" async></script><a data-url="http://matt33.com/2016/03/02/hadoop-shuffle/" data-id="cjewjnuz2002e5vag996s5tg0" class="article-share-link">分享到</a><div class="copyright"><a href="http://matt33.com/copyright/">博客版权说明</a></div><div class="tags"><a href="/tags/hadoop/">hadoop</a></div><div class="post-nav"><a href="/2016/03/08/kafka-store/" class="pre">Kafka之数据存储</a><a href="/2016/01/14/TravelToNanjing/" class="next">Travel to Nanjing | 元旦南京之旅</a></div><div id="disqus_thread"><div class="btn_click_load"><button class="disqus_click_btn">阅读评论 「请确保 disqus.com 可以正常加载」</button></div><script>var disqus_shortname = 'http-matt33-com';
var disqus_identifier = '2016/03/02/hadoop-shuffle/';
var disqus_title = 'MapReduce之Shuffle过程详述';
var disqus_url = 'http://matt33.com/2016/03/02/hadoop-shuffle/';
$('.btn_click_load').click(function() {
  (function() {
    var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
    dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
  })();
  $('.btn_click_load').css('display','none');
});
$.ajax({
  url: 'https://disqus.com/favicon.ico',
  timeout: 3000,
  type: 'GET',
  success: (function() {
    var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
    dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    $('.btn_click_load').css('display','none');
  })(),
  error: function() {
    $('.btn_click_load').css('display','block');
  }
});</script><script id="dsq-count-scr" src="//http-matt33-com.disqus.com/count.js" async></script></div></div></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><div class="widget-title"><i class="fa fa-weibo"> 微博</i></div><iframe width="100%" height="90" class="share_self"  frameborder="0" scrolling="no" src="http://widget.weibo.com/weiboshow/index.php?language=&width=0&height=100&fansRow=1&ptype=1&speed=0&skin=1&isTitle=0&noborder=1&isWeibo=0&isFans=0&uid=2650396571&verifier=f2f0e397&colors=D8D8D8,ffffff,666666,0082cb,ecfbfd&dpc=1"></iframe></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> 分类</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/书屋/">书屋</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/影如人生/">影如人生</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/技术/">技术</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/旅行/">旅行</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/转载/">转载</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/随笔/">随笔</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> 标签</i></div><div class="tagcloud"><a href="/tags/algorithm/" style="font-size: 15px;">algorithm</a> <a href="/tags/思考/" style="font-size: 15px;">思考</a> <a href="/tags/database/" style="font-size: 15px;">database</a> <a href="/tags/storm/" style="font-size: 15px;">storm</a> <a href="/tags/java/" style="font-size: 15px;">java</a> <a href="/tags/转载/" style="font-size: 15px;">转载</a> <a href="/tags/linux/" style="font-size: 15px;">linux</a> <a href="/tags/travel/" style="font-size: 15px;">travel</a> <a href="/tags/maven/" style="font-size: 15px;">maven</a> <a href="/tags/learn/" style="font-size: 15px;">learn</a> <a href="/tags/hadoop/" style="font-size: 15px;">hadoop</a> <a href="/tags/hexo/" style="font-size: 15px;">hexo</a> <a href="/tags/kafka/" style="font-size: 15px;">kafka</a> <a href="/tags/rpc/" style="font-size: 15px;">rpc</a> <a href="/tags/thrift/" style="font-size: 15px;">thrift</a> <a href="/tags/zookeeper/" style="font-size: 15px;">zookeeper</a> <a href="/tags/mac/" style="font-size: 15px;">mac</a> <a href="/tags/tcp/" style="font-size: 15px;">tcp</a> <a href="/tags/jvm/" style="font-size: 15px;">jvm</a> <a href="/tags/bug/" style="font-size: 15px;">bug</a> <a href="/tags/随笔/" style="font-size: 15px;">随笔</a> <a href="/tags/电影随想/" style="font-size: 15px;">电影随想</a> <a href="/tags/web/" style="font-size: 15px;">web</a> <a href="/tags/cv/" style="font-size: 15px;">cv</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> 最新文章</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2018/03/18/kafka-server-handle-produce-request/">Kafka 源码解析之 Server 端如何处理 Produce 请求（十二）</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/03/12/kafka-log-manager/">Kafka 源码解析之日志管理（十一）</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/02/04/linux-mmap/">操作系统之共享对象学习</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/01/28/server-group-coordinator/">Kafka 源码解析之 GroupCoordinator 详解（十）</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/11/19/consumer-two-summary/">Kafka 源码解析之 Consumer 两种 commit 机制和 partition 分配机制（九）</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/11/18/consumer-subscribe/">Kafka 源码解析之 Consumer 两种订阅模式（八）</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/11/11/consumer-pollonce/">Kafka 源码解析之 Consumer Poll 模型（七）</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/10/22/consumer-join-group/">Kafka 源码解析之 Consumer 如何加入一个 Group（六）</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/09/10/produccer-end/">Kafka 源码解析之 Producer 单 Partition 顺序性实现及配置说明（五）</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/09/04/kafka-best-pratice/">Kafka 最佳实践【译】</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-external-link"> 友情链接</i></div><ul></ul><a href="http://tech.meituan.com/" title="美团点评技术团队" target="_blank">美团点评技术团队</a><ul></ul><a href="http://jm.taobao.org/" title="阿里中间件团队博客" target="_blank">阿里中间件团队博客</a><ul></ul><a href="http://www.jianshu.com/" title="简书" target="_blank">简书</a></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">© <a href="/." rel="nofollow">Matt's Blog 柳年思水.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a id="rocket" href="#top" class="show"></a><script type="text/javascript" src="/js/totop.js?v=0.0.0" async></script><div class="analytics"><script>var cnzz_protocol = (("https:" == document.location.protocol) ? " https://" : " http://");
document.write(unescape("%3Cspan id='cnzz_stat_icon_1256517224'%3E%3C/span%3E%3Cscript src='" + cnzz_protocol + "s95.cnzz.com/z_stat.php%3Fid%3D1256517224%26show%3Dpic' type='text/javascript'%3E%3C/script%3E"));</script></div><script type="text/javascript" src="//cdn.bootcss.com/fancybox/2.1.5/jquery.fancybox.pack.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=0.0.0" async></script><link rel="stylesheet" type="text/css" href="/css/jquery.fancybox.css?v=0.0.0"><script>(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
ga('create','UA-64518924-1','auto');ga('send','pageview');
</script><script>var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "//hm.baidu.com/hm.js?5cf44757fa0d23bc7637935e44a9104a";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
  })();
</script><script type="text/javascript" src="/js/codeblock-resizer.js?v=0.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=0.0.0"></script></div></body></html>